[{"aid": "1510.04390", "authors": ["Manolis C. Tsakiris", "Rene Vidal"], "title": "Dual Principal Component Pursuit", "url": "http://arxiv.org/pdf/1510.04390v5", "summary": "We consider the problem of learning a linear subspace from data corrupted by\noutliers. Classical approaches are typically designed for the case in which the\nsubspace dimension is small relative to the ambient dimension. Our approach\nworks with a dual representation of the subspace and hence aims to find its\northogonal complement; as such, it is particularly suitable for subspaces whose\ndimension is close to the ambient dimension (subspaces of high relative\ndimension). We pose the problem of computing normal vectors to the inlier\nsubspace as a non-convex $\\ell_1$ minimization problem on the sphere, which we\ncall Dual Principal Component Pursuit (DPCP) problem. We provide theoretical\nguarantees under which every global solution to DPCP is a vector in the\northogonal complement of the inlier subspace. Moreover, we relax the non-convex\nDPCP problem to a recursion of linear programs whose solutions are shown to\nconverge in a finite number of steps to a vector orthogonal to the subspace. In\nparticular, when the inlier subspace is a hyperplane, the solutions to the\nrecursion of linear programs converge to the global minimum of the non-convex\nDPCP problem in a finite number of steps. We also propose algorithms based on\nalternating minimization and iteratively re-weighted least squares, which are\nsuitable for dealing with large-scale data. Experiments on synthetic data show\nthat the proposed methods are able to handle more outliers and higher relative\ndimensions than current state-of-the-art methods, while experiments in the\ncontext of the three-view geometry problem in computer vision suggest that the\nproposed methods can be a useful or even superior alternative to traditional\nRANSAC-based approaches for computer vision and other applications.", "published": "2015-10-15T03:50:01Z", "version": 5}, {"aid": "1511.00255", "authors": ["Carina Curto", "Nora Youngs"], "title": "Neural ring homomorphisms and maps between neural codes", "url": "http://arxiv.org/pdf/1511.00255v3", "summary": "Neural codes are binary codes that are used for information processing and\nrepresentation in the brain. In previous work, we have shown how an algebraic\nstructure, called the {\\it neural ring}, can be used to efficiently encode\ngeometric and combinatorial properties of a neural code [1]. In this work, we\nconsider maps between neural codes and the associated homomorphisms of their\nneural rings. In order to ensure that these maps are meaningful and preserve\nrelevant structure, we find that we need additional constraints on the ring\nhomomorphisms. This motivates us to define {\\it neural ring homomorphisms}. Our\nmain results characterize all code maps corresponding to neural ring\nhomomorphisms as compositions of 5 elementary code maps. As an application, we\nfind that neural ring homomorphisms behave nicely with respect to convexity. In\nparticular, if $\\mathcal{C}$ and $\\mathcal{D}$ are convex codes, the existence\nof a surjective code map $\\mathcal{C}\\rightarrow \\mathcal{D}$ with a\ncorresponding neural ring homomorphism implies that the minimal embedding\ndimensions satisfy $d(\\mathcal{D}) \\leq d(\\mathcal{C})$.", "published": "2015-11-01T14:29:03Z", "version": 3}, {"aid": "1511.08861", "authors": ["Hang Zhao", "Orazio Gallo", "Iuri Frosio", "Jan Kautz"], "title": "Loss Functions for Neural Networks for Image Processing", "url": "http://arxiv.org/pdf/1511.08861v3", "summary": "Neural networks are becoming central in several areas of computer vision and\nimage processing and different architectures have been proposed to solve\nspecific problems. The impact of the loss layer of neural networks, however,\nhas not received much attention in the context of image processing: the default\nand virtually only choice is L2. In this paper, we bring attention to\nalternative choices for image restoration. In particular, we show the\nimportance of perceptually-motivated losses when the resulting image is to be\nevaluated by a human observer. We compare the performance of several losses,\nand propose a novel, differentiable error function. We show that the quality of\nthe results improves significantly with better loss functions, even when the\nnetwork architecture is left unchanged.", "published": "2015-11-28T02:02:44Z", "version": 3}, {"aid": "1512.07030", "authors": ["Xiaojie Jin", "Chunyan Xu", "Jiashi Feng", "Yunchao Wei", "Junjun Xiong", "Shuicheng Yan"], "title": "Deep Learning with S-shaped Rectified Linear Activation Units", "url": "http://arxiv.org/pdf/1512.07030v1", "summary": "Rectified linear activation units are important components for\nstate-of-the-art deep convolutional networks. In this paper, we propose a novel\nS-shaped rectified linear activation unit (SReLU) to learn both convex and\nnon-convex functions, imitating the multiple function forms given by the two\nfundamental laws, namely the Webner-Fechner law and the Stevens law, in\npsychophysics and neural sciences. Specifically, SReLU consists of three\npiecewise linear functions, which are formulated by four learnable parameters.\nThe SReLU is learned jointly with the training of the whole deep network\nthrough back propagation. During the training phase, to initialize SReLU in\ndifferent layers, we propose a \"freezing\" method to degenerate SReLU into a\npredefined leaky rectified linear unit in the initial several training epochs\nand then adaptively learn the good initial values. SReLU can be universally\nused in the existing deep networks with negligible additional parameters and\ncomputation cost. Experiments with two popular CNN architectures, Network in\nNetwork and GoogLeNet on scale-various benchmarks including CIFAR10, CIFAR100,\nMNIST and ImageNet demonstrate that SReLU achieves remarkable improvement\ncompared to other activation functions.", "published": "2015-12-22T10:54:26Z", "version": 1}, {"aid": "1602.08199", "authors": ["Makoto Naruse", "Song-Ju Kim", "Masashi Aono", "Martin Berthel", "Aur\u00e9lien Drezet", "Serge Huant", "Hirokazu Hori"], "title": "Category Theoretic Analysis of Photon-based Decision Making", "url": "http://arxiv.org/pdf/1602.08199v3", "summary": "Decision making is a vital function in this age of machine learning and\nartificial intelligence, yet its physical realization and theoretical\nfundamentals are still not completely understood. In our former study, we\ndemonstrated that single-photons can be used to make decisions in uncertain,\ndynamically changing environments. The two-armed bandit problem was\nsuccessfully solved using the dual probabilistic and particle attributes of\nsingle photons. In this study, we present a category theoretic modeling and\nanalysis of single-photon-based decision making, including a quantitative\nanalysis that is in agreement with the experimental results. A category\ntheoretic model reveals the complex interdependencies of subject matter\nentities in a simplified manner, even in dynamically changing environments. In\nparticular, the octahedral and braid structures in triangulated categories\nprovide a better understanding and quantitative metrics of the underlying\nmechanisms of a single-photon decision maker. This study provides both insight\nand a foundation for analyzing more complex and uncertain problems, to further\nmachine learning and artificial intelligence.", "published": "2016-02-26T05:28:42Z", "version": 3}, {"aid": "1603.08253", "authors": ["Devon Merrill"], "title": "Negative Learning Rates and P-Learning", "url": "http://arxiv.org/pdf/1603.08253v3", "summary": "We present a method of training a differentiable function approximator for a\nregression task using negative examples. We effect this training using negative\nlearning rates. We also show how this method can be used to perform direct\npolicy learning in a reinforcement learning setting.", "published": "2016-03-27T20:02:13Z", "version": 3}, {"aid": "1606.06160", "authors": ["Shuchang Zhou", "Yuxin Wu", "Zekun Ni", "Xinyu Zhou", "He Wen", "Yuheng Zou"], "title": "DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients", "url": "http://arxiv.org/pdf/1606.06160v3", "summary": "We propose DoReFa-Net, a method to train convolutional neural networks that\nhave low bitwidth weights and activations using low bitwidth parameter\ngradients. In particular, during backward pass, parameter gradients are\nstochastically quantized to low bitwidth numbers before being propagated to\nconvolutional layers. As convolutions during forward/backward passes can now\noperate on low bitwidth weights and activations/gradients respectively,\nDoReFa-Net can use bit convolution kernels to accelerate both training and\ninference. Moreover, as bit convolutions can be efficiently implemented on CPU,\nFPGA, ASIC and GPU, DoReFa-Net opens the way to accelerate training of low\nbitwidth neural network on these hardware. Our experiments on SVHN and ImageNet\ndatasets prove that DoReFa-Net can achieve comparable prediction accuracy as\n32-bit counterparts. For example, a DoReFa-Net derived from AlexNet that has\n1-bit weights, 2-bit activations, can be trained from scratch using 6-bit\ngradients to get 46.1\\% top-1 accuracy on ImageNet validation set. The\nDoReFa-Net AlexNet model is released publicly.", "published": "2016-06-20T15:02:31Z", "version": 3}, {"aid": "1607.06450", "authors": ["Jimmy Lei Ba", "Jamie Ryan Kiros", "Geoffrey E. Hinton"], "title": "Layer Normalization", "url": "http://arxiv.org/pdf/1607.06450v1", "summary": "Training state-of-the-art, deep neural networks is computationally expensive.\nOne way to reduce the training time is to normalize the activities of the\nneurons. A recently introduced technique called batch normalization uses the\ndistribution of the summed input to a neuron over a mini-batch of training\ncases to compute a mean and variance which are then used to normalize the\nsummed input to that neuron on each training case. This significantly reduces\nthe training time in feed-forward neural networks. However, the effect of batch\nnormalization is dependent on the mini-batch size and it is not obvious how to\napply it to recurrent neural networks. In this paper, we transpose batch\nnormalization into layer normalization by computing the mean and variance used\nfor normalization from all of the summed inputs to the neurons in a layer on a\nsingle training case. Like batch normalization, we also give each neuron its\nown adaptive bias and gain which are applied after the normalization but before\nthe non-linearity. Unlike batch normalization, layer normalization performs\nexactly the same computation at training and test times. It is also\nstraightforward to apply to recurrent neural networks by computing the\nnormalization statistics separately at each time step. Layer normalization is\nvery effective at stabilizing the hidden state dynamics in recurrent networks.\nEmpirically, we show that layer normalization can substantially reduce the\ntraining time compared with previously published techniques.", "published": "2016-07-21T19:57:52Z", "version": 1}, {"aid": "1611.02302", "authors": ["Mario Mastriani"], "title": "Quantum spectral analysis: frequency in time, with applications to signal and image processing", "url": "http://arxiv.org/pdf/1611.02302v8", "summary": "A quantum time-dependent spectrum analysis, or simply, quantum spectral\nanalysis (QSA) is presented in this work, and it is based on Schrodinger\nequation, which is a partial differential equation that describes how the\nquantum state of a non-relativistic physical system changes with time. In\nclassic world is named frequency in time (FIT), which is presented here in\nopposition and as a complement of traditional spectral analysis\nfrequency-dependent based on Fourier theory. Besides, FIT is a metric, which\nassesses the impact of the flanks of a signal on its frequency spectrum, which\nis not taken into account by Fourier theory and even less in real time. Even\nmore, and unlike all derived tools from Fourier Theory (i.e., continuous,\ndiscrete, fast, short-time, fractional and quantum Fourier Transform, as well\nas, Gabor) FIT has the following advantages: a) compact support with excellent\nenergy output treatment, b) low computational cost, O(N) for signals and O(N2)\nfor images, c) it does not have phase uncertainties (indeterminate phase for\nmagnitude = 0) as Discrete and Fast Fourier Transform (DFT, FFT, respectively),\nd) among others. In fact, FIT constitutes one side of a triangle (which from\nnow on is closed) and it consists of the original signal in time, spectral\nanalysis based on Fourier Theory and FIT. Thus a toolbox is completed, which it\nis essential for all applications of Digital Signal Processing (DSP) and\nDigital Image Processing (DIP); and, even, in the latter, FIT allows edge\ndetection (which is called flank detection in case of signals), denoising,\ndespeckling, compression, and superresolution of still images. Such\napplications include signals intelligence and imagery intelligence. On the\nother hand, we will present other DIP tools, which are also derived from the\nSchrodinger equation.", "published": "2016-10-11T18:37:33Z", "version": 8}, {"aid": "1611.01773", "authors": ["Yong Guo", "Jian Chen", "Qing Du", "Anton Van Den Hengel", "Qinfeng Shi", "Mingkui Tan"], "title": "The Shallow End: Empowering Shallower Deep-Convolutional Networks through Auxiliary Outputs", "url": "http://arxiv.org/pdf/1611.01773v6", "summary": "Depth is one of the key factors behind the success of convolutional neural\nnetworks (CNNs). Since ResNet, we are able to train very deep CNNs as the\ngradient vanishing issue has been largely addressed by the introduction of skip\nconnections. However, we observe that, when the depth is very large, the\nintermediate layers (especially shallow layers) may fail to receive sufficient\nsupervision from the loss due to the severe transformation through a long\nbackpropagation path. As a result, the representation power of intermediate\nlayers can be very weak and the model becomes very redundant with limited\nperformance. In this paper, we first investigate the supervision vanishing\nissue in existing backpropagation (BP) methods. And then, we propose to address\nit via an effective method, called Multi-way BP (MW-BP), which relies on\nmultiple auxiliary losses added to the intermediate layers of the network. The\nproposed MW-BP method can be applied to most deep architectures with slight\nmodifications, such as ResNet and MobileNet. Our method often gives rise to\nmuch more compact models (denoted by \"Mw+Architecture\") than existing methods.\nFor example, MwResNet-44 with 44 layers performs better than ResNet-110 with\n110 layers on CIFAR-10 and CIFAR-100. More critically, the resultant models\neven outperform the light models obtained by state-of-the-art model compression\nmethods. Last, our method inherently produces multiple compact models with\ndifferent depths at the same time, which is helpful for model selection.", "published": "2016-11-06T13:20:06Z", "version": 6}, {"aid": "1701.02434", "authors": ["Michael Betancourt"], "title": "A Conceptual Introduction to Hamiltonian Monte Carlo", "url": "http://arxiv.org/pdf/1701.02434v2", "summary": "Hamiltonian Monte Carlo has proven a remarkable empirical success, but only\nrecently have we begun to develop a rigorous understanding of why it performs\nso well on difficult problems and how it is best applied in practice.\nUnfortunately, that understanding is confined within the mathematics of\ndifferential geometry which has limited its dissemination, especially to the\napplied communities for which it is particularly important. In this review I\nprovide a comprehensive conceptual account of these theoretical foundations,\nfocusing on developing a principled intuition behind the method and its optimal\nimplementations rather of any exhaustive rigor. Whether a practitioner or a\nstatistician, the dedicated reader will acquire a solid grasp of how\nHamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly,\nwhen it fails.", "published": "2017-01-10T04:26:06Z", "version": 2}, {"aid": "1701.07875", "authors": ["Martin Arjovsky", "Soumith Chintala", "L\u00e9on Bottou"], "title": "Wasserstein GAN", "url": "http://arxiv.org/pdf/1701.07875v3", "summary": "We introduce a new algorithm named WGAN, an alternative to traditional GAN\ntraining. In this new model, we show that we can improve the stability of\nlearning, get rid of problems like mode collapse, and provide meaningful\nlearning curves useful for debugging and hyperparameter searches. Furthermore,\nwe show that the corresponding optimization problem is sound, and provide\nextensive theoretical work highlighting the deep connections to other distances\nbetween distributions.", "published": "2017-01-26T21:10:29Z", "version": 3}, {"aid": "1703.00443", "authors": ["Brandon Amos", "J. Zico Kolter"], "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks", "url": "http://arxiv.org/pdf/1703.00443v5", "summary": "This paper presents OptNet, a network architecture that integrates\noptimization problems (here, specifically in the form of quadratic programs) as\nindividual layers in larger end-to-end trainable deep networks. These layers\nencode constraints and complex dependencies between the hidden states that\ntraditional convolutional and fully-connected layers often cannot capture. We\nexplore the foundations for such an architecture: we show how techniques from\nsensitivity analysis, bilevel optimization, and implicit differentiation can be\nused to exactly differentiate through these layers and with respect to layer\nparameters; we develop a highly efficient solver for these layers that exploits\nfast GPU-based batch solves within a primal-dual interior point method, and\nwhich provides backpropagation gradients with virtually no additional cost on\ntop of the solve; and we highlight the application of these approaches in\nseveral problems. In one notable example, the method is learns to play\nmini-Sudoku (4x4) given just input and output games, with no a-priori\ninformation about the rules of the game; this highlights the ability of OptNet\nto learn hard constraints better than other neural architectures.", "published": "2017-03-01T18:58:48Z", "version": 5}, {"aid": "1703.01203", "authors": ["A. N. Gorban", "I. Y. Tyukin"], "title": "Stochastic Separation Theorems", "url": "http://arxiv.org/pdf/1703.01203v3", "summary": "The problem of non-iterative one-shot and non-destructive correction of\nunavoidable mistakes arises in all Artificial Intelligence applications in the\nreal world. Its solution requires robust separation of samples with errors from\nsamples where the system works properly. We demonstrate that in (moderately)\nhigh dimension this separation could be achieved with probability close to one\nby linear discriminants. Surprisingly, separation of a new image from a very\nlarge set of known images is almost always possible even in moderately high\ndimensions by linear functionals, and coefficients of these functionals can be\nfound explicitly. Based on fundamental properties of measure concentration, we\nshow that for $M<a\\exp(b{n})$ random $M$-element sets in $\\mathbb{R}^n$ are\nlinearly separable with probability $p$, $p>1-\\vartheta$, where $1>\\vartheta>0$\nis a given small constant. Exact values of $a,b>0$ depend on the probability\ndistribution that determines how the random $M$-element sets are drawn, and on\nthe constant $\\vartheta$. These {\\em stochastic separation theorems} provide a\nnew instrument for the development, analysis, and assessment of machine\nlearning methods and algorithms in high dimension. Theoretical statements are\nillustrated with numerical examples.", "published": "2017-03-03T15:27:38Z", "version": 3}, {"aid": "1705.11190", "authors": ["Xerxes D. Arsiwalla", "Ricard Sole", "Clement Moulin-Frier", "Ivan Herreros", "Marti Sanchez-Fibla", "Paul Verschure"], "title": "The Morphospace of Consciousness", "url": "http://arxiv.org/pdf/1705.11190v3", "summary": "We construct a complexity-based morphospace to study systems-level properties\nof conscious & intelligent systems. The axes of this space label 3 complexity\ntypes: autonomous, cognitive & social. Given recent proposals to synthesize\nconsciousness, a generic complexity-based conceptualization provides a useful\nframework for identifying defining features of conscious & synthetic systems.\nBased on current clinical scales of consciousness that measure cognitive\nawareness and wakefulness, we take a perspective on how contemporary\nartificially intelligent machines & synthetically engineered life forms measure\non these scales. It turns out that awareness & wakefulness can be associated to\ncomputational & autonomous complexity respectively. Subsequently, building on\ninsights from cognitive robotics, we examine the function that consciousness\nserves, & argue the role of consciousness as an evolutionary game-theoretic\nstrategy. This makes the case for a third type of complexity for describing\nconsciousness: social complexity. Having identified these complexity types,\nallows for a representation of both, biological & synthetic systems in a common\nmorphospace. A consequence of this classification is a taxonomy of possible\nconscious machines. We identify four types of consciousness, based on\nembodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii)\ngroup consciousness (resulting from group interactions), & (iv) simulated\nconsciousness (embodied by virtual agents within a simulated reality). This\ntaxonomy helps in the investigation of comparative signatures of consciousness\nacross domains, in order to highlight design principles necessary to engineer\nconscious machines. This is particularly relevant in the light of recent\ndevelopments at the crossroads of cognitive neuroscience, biomedical\nengineering, artificial intelligence & biomimetics.", "published": "2017-05-31T17:45:39Z", "version": 3}, {"aid": "1706.10283", "authors": ["Davis W Blalock", "John V Guttag"], "title": "Bolt: Accelerated Data Mining with Fast Vector Compression", "url": "http://arxiv.org/pdf/1706.10283v1", "summary": "Vectors of data are at the heart of machine learning and data mining.\nRecently, vector quantization methods have shown great promise in reducing both\nthe time and space costs of operating on vectors. We introduce a vector\nquantization algorithm that can compress vectors over 12x faster than existing\ntechniques while also accelerating approximate vector operations such as\ndistance and dot product computations by up to 10x. Because it can encode over\n2GB of vectors per second, it makes vector quantization cheap enough to employ\nin many more circumstances. For example, using our technique to compute\napproximate dot products in a nested loop can multiply matrices faster than a\nstate-of-the-art BLAS implementation, even when our algorithm must first\ncompress the matrices.\n  In addition to showing the above speedups, we demonstrate that our approach\ncan accelerate nearest neighbor search and maximum inner product search by over\n100x compared to floating point operations and up to 10x compared to other\nvector quantization methods. Our approximate Euclidean distance and dot product\ncomputations are not only faster than those of related algorithms with slower\nencodings, but also faster than Hamming distance computations, which have\ndirect hardware support on the tested platforms. We also assess the errors of\nour algorithm's approximate distances and dot products, and find that it is\ncompetitive with existing, slower vector quantization algorithms.", "published": "2017-06-30T17:31:59Z", "version": 1}, {"aid": "1707.05649", "authors": ["Leo Kozachkov", "Konstantinos P. Michmizos"], "title": "Sequence learning in Associative Neuronal-Astrocytic Network", "url": "http://arxiv.org/pdf/1707.05649v2", "summary": "The neuronal paradigm of studying the brain has left us with limitations in\nboth our understanding of how neurons process information to achieve biological\nintelligence and how such knowledge may be translated into artificial\nintelligence and its most brain-derived branch, neuromorphic computing.\nOverturning our fundamental assumptions of how the brain works, the recent\nexploration of astrocytes is revealing that these long-neglected brain cells\ndynamically regulate learning by interacting with neuronal activity at the\nsynaptic level. Following recent experimental evidence, we designed an\nassociative, Hopfield-type, neuronal-astrocytic network and analyzed the\ndynamics of the interaction between neurons and astrocytes. We show that\nastrocytes were sufficient to trigger transitions between learned memories in\nthe neuronal component of the network. Further, we mathematically derived the\ntiming of the transitions that was governed by the dynamics of the\ncalcium-dependent slow-currents in the astrocytic processes. Overall, we\nprovide a brain-morphic mechanism for sequence learning that is inspired by,\nand aligns with, recent experimental findings. To evaluate our model, we\nemulated astrocytic atrophy and showed that memory recall becomes significantly\nimpaired after a critical point of affected astrocytes was reached. This\nbrain-inspired and brain-validated approach supports our ongoing efforts to\nincorporate non-neuronal computing elements in neuromorphic information\nprocessing.", "published": "2017-07-16T18:16:27Z", "version": 2}, {"aid": "1707.06347", "authors": ["John Schulman", "Filip Wolski", "Prafulla Dhariwal", "Alec Radford", "Oleg Klimov"], "title": "Proximal Policy Optimization Algorithms", "url": "http://arxiv.org/pdf/1707.06347v2", "summary": "We propose a new family of policy gradient methods for reinforcement\nlearning, which alternate between sampling data through interaction with the\nenvironment, and optimizing a \"surrogate\" objective function using stochastic\ngradient ascent. Whereas standard policy gradient methods perform one gradient\nupdate per data sample, we propose a novel objective function that enables\nmultiple epochs of minibatch updates. The new methods, which we call proximal\npolicy optimization (PPO), have some of the benefits of trust region policy\noptimization (TRPO), but they are much simpler to implement, more general, and\nhave better sample complexity (empirically). Our experiments test PPO on a\ncollection of benchmark tasks, including simulated robotic locomotion and Atari\ngame playing, and we show that PPO outperforms other online policy gradient\nmethods, and overall strikes a favorable balance between sample complexity,\nsimplicity, and wall-time.", "published": "2017-07-20T02:32:33Z", "version": 2}, {"aid": "1707.09669", "authors": ["Xiaobin Chang", "Tao Xiang", "Timothy M. Hospedales"], "title": "Scalable and Effective Deep CCA via Soft Decorrelation", "url": "http://arxiv.org/pdf/1707.09669v2", "summary": "Recently the widely used multi-view learning model, Canonical Correlation\nAnalysis (CCA) has been generalised to the non-linear setting via deep neural\nnetworks. Existing deep CCA models typically first decorrelate the feature\ndimensions of each view before the different views are maximally correlated in\na common latent space. This feature decorrelation is achieved by enforcing an\nexact decorrelation constraint; these models are thus computationally expensive\ndue to the matrix inversion or SVD operations required for exact decorrelation\nat each training iteration. Furthermore, the decorrelation step is often\nseparated from the gradient descent based optimisation, resulting in\nsub-optimal solutions. We propose a novel deep CCA model Soft CCA to overcome\nthese problems. Specifically, exact decorrelation is replaced by soft\ndecorrelation via a mini-batch based Stochastic Decorrelation Loss (SDL) to be\noptimised jointly with the other training objectives. Extensive experiments\nshow that the proposed soft CCA is more effective and efficient than existing\ndeep CCA models. In addition, our SDL loss can be applied to other deep models\nbeyond multi-view learning, and obtains superior performance compared to\nexisting decorrelation losses.", "published": "2017-07-30T20:53:54Z", "version": 2}, {"aid": "1708.04020", "authors": ["Natalia Z. Bielczyk", "Sebo Uithol", "Tim van Mourik", "Paul Anderson", "Jeffrey C. Glennon", "Jan K. Buitelaar"], "title": "Disentangling causal webs in the brain using functional Magnetic Resonance Imaging: A review of current approaches", "url": "http://arxiv.org/pdf/1708.04020v4", "summary": "In the past two decades, functional Magnetic Resonance Imaging has been used\nto relate neuronal network activity to cognitive processing and behaviour.\nRecently this approach has been augmented by algorithms that allow us to infer\ncausal links between component populations of neuronal networks. Multiple\ninference procedures have been proposed to approach this research question but\nso far, each method has limitations when it comes to establishing whole-brain\nconnectivity patterns. In this work, we discuss eight ways to infer causality\nin fMRI research: Bayesian Nets, Dynamical Causal Modelling, Granger Causality,\nLikelihood Ratios, LiNGAM, Patel's Tau, Structural Equation Modelling, and\nTransfer Entropy. We finish with formulating some recommendations for the\nfuture directions in this area.", "published": "2017-08-14T07:13:17Z", "version": 4}, {"aid": "1708.05714", "authors": ["Mark Inman"], "title": "A Stronger Foundation for Computer Science and P=NP", "url": "http://arxiv.org/pdf/1708.05714v2", "summary": "This article describes a Turing machine which can solve for $\\beta^{'}$ which\nis RE-complete. RE-complete problems are proven to be undecidable by Turing's\naccepted proof on the Entscheidungsproblem. Thus, constructing a machine which\ndecides over $\\beta^{'}$ implies inconsistency in ZFC. We then discover that\nunrestricted use of the axiom of substitution can lead to hidden assumptions in\na certain class of proofs by contradiction. These hidden assumptions create an\nimplied axiom of incompleteness for ZFC. Later, we offer a restriction on the\naxiom of substitution by introducing a new axiom which prevents impredicative\ntautologies from producing theorems. Our discovery in regards to these\nfoundational arguments, disproves the SPACE hierarchy theorem which allows us\nto solve the P vs NP problem using a TIME-SPACE equivalence oracle.", "published": "2017-08-18T22:36:07Z", "version": 2}, {"aid": "1708.07120", "authors": ["Leslie N. Smith", "Nicholay Topin"], "title": "Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates", "url": "http://arxiv.org/pdf/1708.07120v3", "summary": "In this paper, we describe a phenomenon, which we named \"super-convergence\",\nwhere neural networks can be trained an order of magnitude faster than with\nstandard training methods. The existence of super-convergence is relevant to\nunderstanding why deep networks generalize well. One of the key elements of\nsuper-convergence is training with one learning rate cycle and a large maximum\nlearning rate. A primary insight that allows super-convergence training is that\nlarge learning rates regularize the training, hence requiring a reduction of\nall other forms of regularization in order to preserve an optimal\nregularization balance. We also derive a simplification of the Hessian Free\noptimization method to compute an estimate of the optimal learning rate.\nExperiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet\ndatasets, and resnet, wide-resnet, densenet, and inception architectures. In\naddition, we show that super-convergence provides a greater boost in\nperformance relative to standard training when the amount of labeled training\ndata is limited. The architectures and code to replicate the figures in this\npaper are available at github.com/lnsmith54/super-convergence. See\nhttp://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of\nsuper-convergence to win the DAWNBench challenge (see\nhttps://dawn.cs.stanford.edu/benchmark/).", "published": "2017-08-23T17:51:57Z", "version": 3}, {"aid": "1709.02341", "authors": ["Kai Ueltzh\u00f6ffer"], "title": "Deep Active Inference", "url": "http://arxiv.org/pdf/1709.02341v5", "summary": "This work combines the free energy principle from cognitive neuroscience and\nthe ensuing active inference dynamics with recent advances in variational\ninference in deep generative models, and evolution strategies to introduce the\n\"deep active inference\" agent. This agent minimises a variational free energy\nbound on the average surprise of its sensations, which is motivated by a\nhomeostatic argument. It does so by optimising the parameters of a generative\nlatent variable model of its sensory inputs, together with a variational\ndensity approximating the posterior distribution over the latent variables,\ngiven its observations, and by acting on its environment to actively sample\ninput that is likely under this generative model. The internal dynamics of the\nagent are implemented using deep and recurrent neural networks, as used in\nmachine learning, making the deep active inference agent a scalable and very\nflexible class of active inference agent. Using the mountain car problem, we\nshow how goal directed behaviour can be implemented by defining appropriate\npriors on the latent states in the agent's model. Furthermore, we show that the\ndeep active inference agent can learn a generative model of the environment,\nwhich can be sampled from to understand the agent's beliefs about the\nenvironment and its interaction therewith.", "published": "2017-09-07T16:36:52Z", "version": 5}, {"aid": "1709.06196", "authors": ["Zachary Sunberg", "Mykel Kochenderfer"], "title": "Online algorithms for POMDPs with continuous state, action, and observation spaces", "url": "http://arxiv.org/pdf/1709.06196v6", "summary": "Online solvers for partially observable Markov decision processes have been\napplied to problems with large discrete state spaces, but continuous state,\naction, and observation spaces remain a challenge. This paper begins by\ninvestigating double progressive widening (DPW) as a solution to this\nchallenge. However, we prove that this modification alone is not sufficient\nbecause the belief representations in the search tree collapse to a single\nparticle causing the algorithm to converge to a policy that is suboptimal\nregardless of the computation time. This paper proposes and evaluates two new\nalgorithms, POMCPOW and PFT-DPW, that overcome this deficiency by using\nweighted particle filtering. Simulation results show that these modifications\nallow the algorithms to be successful where previous approaches fail.", "published": "2017-09-18T22:57:30Z", "version": 6}, {"aid": "1709.06247", "authors": ["Gangming Zhao", "Zhaoxiang Zhang", "He Guan", "Peng Tang", "Jingdong Wang"], "title": "Rethink ReLU to Training Better CNNs", "url": "http://arxiv.org/pdf/1709.06247v2", "summary": "Most of convolutional neural networks share the same characteristic: each\nconvolutional layer is followed by a nonlinear activation layer where Rectified\nLinear Unit (ReLU) is the most widely used. In this paper, we argue that the\ndesigned structure with the equal ratio between these two layers may not be the\nbest choice since it could result in the poor generalization ability. Thus, we\ntry to investigate a more suitable method on using ReLU to explore the better\nnetwork architectures. Specifically, we propose a proportional module to keep\nthe ratio between convolution and ReLU amount to be N:M (N>M). The proportional\nmodule can be applied in almost all networks with no extra computational cost\nto improve the performance. Comprehensive experimental results indicate that\nthe proposed method achieves better performance on different benchmarks with\ndifferent network architectures, thus verify the superiority of our work.", "published": "2017-09-19T04:27:56Z", "version": 2}, {"aid": "1710.02298", "authors": ["Matteo Hessel", "Joseph Modayil", "Hado van Hasselt", "Tom Schaul", "Georg Ostrovski", "Will Dabney", "Dan Horgan", "Bilal Piot", "Mohammad Azar", "David Silver"], "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1710.02298v1", "summary": "The deep reinforcement learning community has made several independent\nimprovements to the DQN algorithm. However, it is unclear which of these\nextensions are complementary and can be fruitfully combined. This paper\nexamines six extensions to the DQN algorithm and empirically studies their\ncombination. Our experiments show that the combination provides\nstate-of-the-art performance on the Atari 2600 benchmark, both in terms of data\nefficiency and final performance. We also provide results from a detailed\nablation study that shows the contribution of each component to overall\nperformance.", "published": "2017-10-06T07:45:46Z", "version": 1}, {"aid": "1710.10328", "authors": ["Lixin Fan"], "title": "Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU with Generalized Hamming Network", "url": "http://arxiv.org/pdf/1710.10328v1", "summary": "We revisit fuzzy neural network with a cornerstone notion of generalized\nhamming distance, which provides a novel and theoretically justified framework\nto re-interpret many useful neural network techniques in terms of fuzzy logic.\nIn particular, we conjecture and empirically illustrate that, the celebrated\nbatch normalization (BN) technique actually adapts the normalized bias such\nthat it approximates the rightful bias induced by the generalized hamming\ndistance. Once the due bias is enforced analytically, neither the optimization\nof bias terms nor the sophisticated batch normalization is needed. Also in the\nlight of generalized hamming distance, the popular rectified linear units\n(ReLU) can be treated as setting a minimal hamming distance threshold between\nnetwork inputs and weights. This thresholding scheme, on the one hand, can be\nimproved by introducing double thresholding on both extremes of neuron outputs.\nOn the other hand, ReLUs turn out to be non-essential and can be removed from\nnetworks trained for simple tasks like MNIST classification. The proposed\ngeneralized hamming network (GHN) as such not only lends itself to rigorous\nanalysis and interpretation within the fuzzy logic theory but also demonstrates\nfast learning speed, well-controlled behaviour and state-of-the-art\nperformances on a variety of learning tasks.", "published": "2017-10-27T20:48:57Z", "version": 1}, {"aid": "1711.00937", "authors": ["Aaron van den Oord", "Oriol Vinyals", "Koray Kavukcuoglu"], "title": "Neural Discrete Representation Learning", "url": "http://arxiv.org/pdf/1711.00937v2", "summary": "Learning useful representations without supervision remains a key challenge\nin machine learning. In this paper, we propose a simple yet powerful generative\nmodel that learns such discrete representations. Our model, the Vector\nQuantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways:\nthe encoder network outputs discrete, rather than continuous, codes; and the\nprior is learnt rather than static. In order to learn a discrete latent\nrepresentation, we incorporate ideas from vector quantisation (VQ). Using the\nVQ method allows the model to circumvent issues of \"posterior collapse\" --\nwhere the latents are ignored when they are paired with a powerful\nautoregressive decoder -- typically observed in the VAE framework. Pairing\nthese representations with an autoregressive prior, the model can generate high\nquality images, videos, and speech as well as doing high quality speaker\nconversion and unsupervised learning of phonemes, providing further evidence of\nthe utility of the learnt representations.", "published": "2017-11-02T21:14:44Z", "version": 2}, {"aid": "1711.05246", "authors": ["Sean Welleck", "Zixin Yao", "Yu Gai", "Jialin Mao", "Zheng Zhang", "Kyunghyun Cho"], "title": "Loss Functions for Multiset Prediction", "url": "http://arxiv.org/pdf/1711.05246v2", "summary": "We study the problem of multiset prediction. The goal of multiset prediction\nis to train a predictor that maps an input to a multiset consisting of multiple\nitems. Unlike existing problems in supervised learning, such as classification,\nranking and sequence generation, there is no known order among items in a\ntarget multiset, and each item in the multiset may appear more than once,\nmaking this problem extremely challenging. In this paper, we propose a novel\nmultiset loss function by viewing this problem from the perspective of\nsequential decision making. The proposed multiset loss function is empirically\nevaluated on two families of datasets, one synthetic and the other real, with\nvarying levels of difficulty, against various baseline loss functions including\nreinforcement learning, sequence, and aggregated distribution matching loss\nfunctions. The experiments reveal the effectiveness of the proposed loss\nfunction over the others.", "published": "2017-11-14T18:43:22Z", "version": 2}, {"aid": "1711.08141", "authors": ["Bichen Wu", "Alvin Wan", "Xiangyu Yue", "Peter Jin", "Sicheng Zhao", "Noah Golmant", "Amir Gholaminejad", "Joseph Gonzalez", "Kurt Keutzer"], "title": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions", "url": "http://arxiv.org/pdf/1711.08141v2", "summary": "Neural networks rely on convolutions to aggregate spatial information.\nHowever, spatial convolutions are expensive in terms of model size and\ncomputation, both of which grow quadratically with respect to kernel size. In\nthis paper, we present a parameter-free, FLOP-free \"shift\" operation as an\nalternative to spatial convolutions. We fuse shifts and point-wise convolutions\nto construct end-to-end trainable shift-based modules, with a hyperparameter\ncharacterizing the tradeoff between accuracy and efficiency. To demonstrate the\noperation's efficacy, we replace ResNet's 3x3 convolutions with shift-based\nmodules for improved CIFAR10 and CIFAR100 accuracy using 60% fewer parameters;\nwe additionally demonstrate the operation's resilience to parameter reduction\non ImageNet, outperforming ResNet family members. We finally show the shift\noperation's applicability across domains, achieving strong performance with\nfewer parameters on classification, face verification and style transfer.", "published": "2017-11-22T05:52:19Z", "version": 2}, {"aid": "1711.08393", "authors": ["Zuxuan Wu", "Tushar Nagarajan", "Abhishek Kumar", "Steven Rennie", "Larry S. Davis", "Kristen Grauman", "Rogerio Feris"], "title": "BlockDrop: Dynamic Inference Paths in Residual Networks", "url": "http://arxiv.org/pdf/1711.08393v4", "summary": "Very deep convolutional neural networks offer excellent recognition results,\nyet their computational expense limits their impact for many real-world\napplications. We introduce BlockDrop, an approach that learns to dynamically\nchoose which layers of a deep network to execute during inference so as to best\nreduce total computation without degrading prediction accuracy. Exploiting the\nrobustness of Residual Networks (ResNets) to layer dropping, our framework\nselects on-the-fly which residual blocks to evaluate for a given novel image.\nIn particular, given a pretrained ResNet, we train a policy network in an\nassociative reinforcement learning setting for the dual reward of utilizing a\nminimal number of blocks while preserving recognition accuracy. We conduct\nextensive experiments on CIFAR and ImageNet. The results provide strong\nquantitative and qualitative evidence that these learned policies not only\naccelerate inference but also encode meaningful visual information. Built upon\na ResNet-101 model, our method achieves a speedup of 20\\% on average, going as\nhigh as 36\\% for some images, while maintaining the same 76.4\\% top-1 accuracy\non ImageNet.", "published": "2017-11-22T17:01:59Z", "version": 4}, {"aid": "1711.10563", "authors": ["Ronald Kemker", "Christopher Kanan"], "title": "FearNet: Brain-Inspired Model for Incremental Learning", "url": "http://arxiv.org/pdf/1711.10563v2", "summary": "Incremental class learning involves sequentially learning classes in bursts\nof examples from the same class. This violates the assumptions that underlie\nmethods for training standard deep neural networks, and will cause them to\nsuffer from catastrophic forgetting. Arguably, the best method for incremental\nclass learning is iCaRL, but it requires storing training examples for each\nclass, making it challenging to scale. Here, we propose FearNet for incremental\nclass learning. FearNet is a generative model that does not store previous\nexamples, making it memory efficient. FearNet uses a brain-inspired dual-memory\nsystem in which new memories are consolidated from a network for recent\nmemories inspired by the mammalian hippocampal complex to a network for\nlong-term storage inspired by medial prefrontal cortex. Memory consolidation is\ninspired by mechanisms that occur during sleep. FearNet also uses a module\ninspired by the basolateral amygdala for determining which memory system to use\nfor recall. FearNet achieves state-of-the-art performance at incremental class\nlearning on image (CIFAR-100, CUB-200) and audio classification (AudioSet)\nbenchmarks.", "published": "2017-11-28T21:26:15Z", "version": 2}, {"aid": "1712.02408", "authors": ["Hongyu Xu", "Xutao Lv", "Xiaoyu Wang", "Zhou Ren", "Navaneeth Bodla", "Rama Chellappa"], "title": "Deep Regionlets for Object Detection", "url": "http://arxiv.org/pdf/1712.02408v3", "summary": "In this paper, we propose a novel object detection framework named \"Deep\nRegionlets\" by establishing a bridge between deep neural networks and\nconventional detection schema for accurate generic object detection. Motivated\nby the abilities of regionlets for modeling object deformation and multiple\naspect ratios, we incorporate regionlets into an end-to-end trainable deep\nlearning framework. The deep regionlets framework consists of a region\nselection network and a deep regionlet learning module. Specifically, given a\ndetection bounding box proposal, the region selection network provides guidance\non where to select regions to learn the features from. The regionlet learning\nmodule focuses on local feature selection and transformation to alleviate local\nvariations. To this end, we first realize non-rectangular region selection\nwithin the detection framework to accommodate variations in object appearance.\nMoreover, we design a \"gating network\" within the regionlet leaning module to\nenable soft regionlet selection and pooling. The Deep Regionlets framework is\ntrained end-to-end without additional efforts. We perform ablation studies and\nconduct extensive experiments on the PASCAL VOC and Microsoft COCO datasets.\nThe proposed framework outperforms state-of-the-art algorithms, such as\nRetinaNet and Mask R-CNN, even without additional segmentation labels.", "published": "2017-12-06T21:05:21Z", "version": 3}, {"aid": "1712.02616", "authors": ["Samuel Rota Bul\u00f2", "Lorenzo Porzi", "Peter Kontschieder"], "title": "In-Place Activated BatchNorm for Memory-Optimized Training of DNNs", "url": "http://arxiv.org/pdf/1712.02616v3", "summary": "In this work we present In-Place Activated Batch Normalization (InPlace-ABN)\n- a novel approach to drastically reduce the training memory footprint of\nmodern deep neural networks in a computationally efficient way. Our solution\nsubstitutes the conventionally used succession of BatchNorm + Activation layers\nwith a single plugin layer, hence avoiding invasive framework surgery while\nproviding straightforward applicability for existing deep learning frameworks.\nWe obtain memory savings of up to 50% by dropping intermediate results and by\nrecovering required information during the backward pass through the inversion\nof stored forward results, with only minor increase (0.8-2%) in computation\ntime. Also, we demonstrate how frequently used checkpointing approaches can be\nmade computationally as efficient as InPlace-ABN. In our experiments on image\nclassification, we demonstrate on-par results on ImageNet-1k with\nstate-of-the-art approaches. On the memory-demanding task of semantic\nsegmentation, we report results for COCO-Stuff, Cityscapes and Mapillary\nVistas, obtaining new state-of-the-art results on the latter without additional\ntraining data but in a single-scale and -model scenario. Code can be found at\nhttps://github.com/mapillary/inplace_abn .", "published": "2017-12-07T13:43:45Z", "version": 3}, {"aid": "1712.03333", "authors": ["Heejin Jeong", "Clark Zhang", "George J. Pappas", "Daniel D. Lee"], "title": "Assumed Density Filtering Q-learning", "url": "http://arxiv.org/pdf/1712.03333v4", "summary": "While off-policy temporal difference (TD) methods have widely been used in\nreinforcement learning due to their efficiency and simple implementation, their\nBayesian counterparts have not been utilized as frequently. One reason is that\nthe non-linear max operation in the Bellman optimality equation makes it\ndifficult to define conjugate distributions over the value functions. In this\npaper, we introduce a novel Bayesian approach to off-policy TD methods, called\nas ADFQ, which updates beliefs on state-action values, Q, through an online\nBayesian inference method known as Assumed Density Filtering. We formulate an\nefficient closed-form solution for the value update by approximately estimating\nanalytic parameters of the posterior of the Q-beliefs. Uncertainty measures in\nthe beliefs not only are used in exploration but also provide a natural\nregularization for the value update considering all next available actions.\nADFQ converges to Q-learning as the uncertainty measures of the Q-beliefs\ndecrease and improves common drawbacks of other Bayesian RL algorithms such as\ncomputational complexity. We extend ADFQ with a neural network. Our empirical\nresults demonstrate that ADFQ outperforms comparable algorithms on various\nAtari 2600 games, with drastic improvements in highly stochastic domains or\ndomains with a large action space.", "published": "2017-12-09T02:18:05Z", "version": 4}, {"aid": "1712.03747", "authors": ["Jose Bernal", "Kaisar Kushibar", "Daniel S. Asfaw", "Sergi Valverde", "Arnau Oliver", "Robert Mart\u00ed", "Xavier Llad\u00f3"], "title": "Deep convolutional neural networks for brain image analysis on magnetic resonance imaging: a review", "url": "http://arxiv.org/pdf/1712.03747v3", "summary": "In recent years, deep convolutional neural networks (CNNs) have shown\nrecord-shattering performance in a variety of computer vision problems, such as\nvisual object recognition, detection and segmentation. These methods have also\nbeen utilised in medical image analysis domain for lesion segmentation,\nanatomical segmentation and classification. We present an extensive literature\nreview of CNN techniques applied in brain magnetic resonance imaging (MRI)\nanalysis, focusing on the architectures, pre-processing, data-preparation and\npost-processing strategies available in these works. The aim of this study is\nthree-fold. Our primary goal is to report how different CNN architectures have\nevolved, discuss state-of-the-art strategies, condense their results obtained\nusing public datasets and examine their pros and cons. Second, this paper is\nintended to be a detailed reference of the research activity in deep CNN for\nbrain MRI analysis. Finally, we present a perspective on the future of CNNs in\nwhich we hint some of the research directions in subsequent years.", "published": "2017-12-11T12:25:30Z", "version": 3}, {"aid": "1712.04323", "authors": ["Claudio Gallicchio", "Alessio Micheli"], "title": "Deep Echo State Network (DeepESN): A Brief Survey", "url": "http://arxiv.org/pdf/1712.04323v4", "summary": "The study of deep recurrent neural networks (RNNs) and, in particular, of\ndeep Reservoir Computing (RC) is gaining an increasing research attention in\nthe neural networks community. The recently introduced Deep Echo State Network\n(DeepESN) model opened the way to an extremely efficient approach for designing\ndeep neural networks for temporal data. At the same time, the study of DeepESNs\nallowed to shed light on the intrinsic properties of state dynamics developed\nby hierarchical compositions of recurrent layers, i.e. on the bias of depth in\nRNNs architectural design. In this paper, we summarize the advancements in the\ndevelopment, analysis and applications of DeepESNs.", "published": "2017-12-12T14:50:51Z", "version": 4}, {"aid": "1712.05577", "authors": ["George Philipp", "Dawn Song", "Jaime G. Carbonell"], "title": "The exploding gradient problem demystified - definition, prevalence, impact, origin, tradeoffs, and solutions", "url": "http://arxiv.org/pdf/1712.05577v4", "summary": "Whereas it is believed that techniques such as Adam, batch normalization and,\nmore recently, SeLU nonlinearities \"solve\" the exploding gradient problem, we\nshow that this is not the case in general and that in a range of popular MLP\narchitectures, exploding gradients exist and that they limit the depth to which\nnetworks can be effectively trained, both in theory and in practice. We explain\nwhy exploding gradients occur and highlight the *collapsing domain problem*,\nwhich can arise in architectures that avoid exploding gradients.\n  ResNets have significantly lower gradients and thus can circumvent the\nexploding gradient problem, enabling the effective training of much deeper\nnetworks. We show this is a direct consequence of the Pythagorean equation. By\nnoticing that *any neural network is a residual network*, we devise the\n*residual trick*, which reveals that introducing skip connections simplifies\nthe network mathematically, and that this simplicity may be the major cause for\ntheir success.", "published": "2017-12-15T08:25:51Z", "version": 4}, {"aid": "1712.05812", "authors": ["Stuart Armstrong", "S\u00f6ren Mindermann"], "title": "Occam's razor is insufficient to infer the preferences of irrational agents", "url": "http://arxiv.org/pdf/1712.05812v6", "summary": "Inverse reinforcement learning (IRL) attempts to infer human rewards or\npreferences from observed behavior. Since human planning systematically\ndeviates from rationality, several approaches have been tried to account for\nspecific human shortcomings. However, the general problem of inferring the\nreward function of an agent of unknown rationality has received little\nattention. Unlike the well-known ambiguity problems in IRL, this one is\npractically relevant but cannot be resolved by observing the agent's policy in\nenough environments. This paper shows (1) that a No Free Lunch result implies\nit is impossible to uniquely decompose a policy into a planning algorithm and\nreward function, and (2) that even with a reasonable simplicity prior/Occam's\nrazor on the set of decompositions, we cannot distinguish between the true\ndecomposition and others that lead to high regret. To address this, we need\nsimple `normative' assumptions, which cannot be deduced exclusively from\nobservations.", "published": "2017-12-15T19:05:01Z", "version": 6}, {"aid": "1712.06145", "authors": ["Dong-Qing Zhang"], "title": "clcNet: Improving the Efficiency of Convolutional Neural Network using Channel Local Convolutions", "url": "http://arxiv.org/pdf/1712.06145v3", "summary": "Depthwise convolution and grouped convolution has been successfully applied\nto improve the efficiency of convolutional neural network (CNN). We suggest\nthat these models can be considered as special cases of a generalized\nconvolution operation, named channel local convolution(CLC), where an output\nchannel is computed using a subset of the input channels. This definition\nentails computation dependency relations between input and output channels,\nwhich can be represented by a channel dependency graph(CDG). By modifying the\nCDG of grouped convolution, a new CLC kernel named interlaced grouped\nconvolution (IGC) is created. Stacking IGC and GC kernels results in a\nconvolution block (named CLC Block) for approximating regular convolution. By\nresorting to the CDG as an analysis tool, we derive the rule for setting the\nmeta-parameters of IGC and GC and the framework for minimizing the\ncomputational cost. A new CNN model named clcNet is then constructed using CLC\nblocks, which shows significantly higher computational efficiency and fewer\nparameters compared to state-of-the-art networks, when being tested using the\nImageNet-1K dataset. Source code is available at\nhttps://github.com/dqzhang17/clcnet.torch .", "published": "2017-12-17T17:07:54Z", "version": 3}, {"aid": "1712.06391", "authors": ["Xudong Mao", "Qing Li", "Haoran Xie", "Raymond Y. K. Lau", "Zhen Wang", "Stephen Paul Smolley"], "title": "On the Effectiveness of Least Squares Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1712.06391v2", "summary": "Unsupervised learning with generative adversarial networks (GANs) has proven\nto be hugely successful. Regular GANs hypothesize the discriminator as a\nclassifier with the sigmoid cross entropy loss function. However, we found that\nthis loss function may lead to the vanishing gradients problem during the\nlearning process. To overcome such a problem, we propose in this paper the\nLeast Squares Generative Adversarial Networks (LSGANs) which adopt the least\nsquares loss for both the discriminator and the generator. We show that\nminimizing the objective function of LSGAN yields minimizing the Pearson\n$\\chi^2$ divergence. We also show that the derived objective function that\nyields minimizing the Pearson $\\chi^2$ divergence performs better than the\nclassical one of using least squares for classification. There are two benefits\nof LSGANs over regular GANs. First, LSGANs are able to generate higher quality\nimages than regular GANs. Second, LSGANs perform more stably during the\nlearning process. For evaluating the image quality, we conduct both qualitative\nand quantitative experiments, and the experimental results show that LSGANs can\ngenerate higher quality images than regular GANs. Furthermore, we evaluate the\nstability of LSGANs in two groups. One is to compare between LSGANs and regular\nGANs without gradient penalty. We conduct three experiments, including Gaussian\nmixture distribution, difficult architectures, and a newly proposed method ---\ndatasets with small variability, to illustrate the stability of LSGANs. The\nother one is to compare between LSGANs with gradient penalty (LSGANs-GP) and\nWGANs with gradient penalty (WGANs-GP). The experimental results show that\nLSGANs-GP succeed in training for all the difficult architectures used in\nWGANs-GP, including 101-layer ResNet.", "published": "2017-12-18T13:36:09Z", "version": 2}, {"aid": "1801.03454", "authors": ["Ruth Fong", "Andrea Vedaldi"], "title": "Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters in Deep Neural Networks", "url": "http://arxiv.org/pdf/1801.03454v2", "summary": "In an effort to understand the meaning of the intermediate representations\ncaptured by deep networks, recent papers have tried to associate specific\nsemantic concepts to individual neural network filter responses, where\ninteresting correlations are often found, largely by focusing on extremal\nfilter responses. In this paper, we show that this approach can favor\neasy-to-interpret cases that are not necessarily representative of the average\nbehavior of a representation.\n  A more realistic but harder-to-study hypothesis is that semantic\nrepresentations are distributed, and thus filters must be studied in\nconjunction. In order to investigate this idea while enabling systematic\nvisualization and quantification of multiple filter responses, we introduce the\nNet2Vec framework, in which semantic concepts are mapped to vectorial\nembeddings based on corresponding filter responses. By studying such\nembeddings, we are able to show that 1., in most cases, multiple filters are\nrequired to code for a concept, that 2., often filters are not concept specific\nand help encode multiple concepts, and that 3., compared to single filter\nactivations, filter embeddings are able to better characterize the meaning of a\nrepresentation and its relationship to other concepts.", "published": "2018-01-10T17:01:36Z", "version": 2}, {"aid": "1801.04406", "authors": ["Lars Mescheder", "Andreas Geiger", "Sebastian Nowozin"], "title": "Which Training Methods for GANs do actually Converge?", "url": "http://arxiv.org/pdf/1801.04406v4", "summary": "Recent work has shown local convergence of GAN training for absolutely\ncontinuous data and generator distributions. In this paper, we show that the\nrequirement of absolute continuity is necessary: we describe a simple yet\nprototypical counterexample showing that in the more realistic case of\ndistributions that are not absolutely continuous, unregularized GAN training is\nnot always convergent. Furthermore, we discuss regularization strategies that\nwere recently proposed to stabilize GAN training. Our analysis shows that GAN\ntraining with instance noise or zero-centered gradient penalties converges. On\nthe other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number\nof discriminator updates per generator update do not always converge to the\nequilibrium point. We discuss these results, leading us to a new explanation\nfor the stability problems of GAN training. Based on our analysis, we extend\nour convergence results to more general GANs and prove local convergence for\nsimplified gradient penalties even if the generator and data distribution lie\non lower dimensional manifolds. We find these penalties to work well in\npractice and use them to learn high-resolution generative image models for a\nvariety of datasets with little hyperparameter tuning.", "published": "2018-01-13T09:42:26Z", "version": 4}, {"aid": "1801.04520", "authors": ["Dipan K. Pal", "Marios Savvides"], "title": "Non-Parametric Transformation Networks", "url": "http://arxiv.org/pdf/1801.04520v6", "summary": "ConvNets, through their architecture, only enforce invariance to translation.\nIn this paper, we introduce a new class of deep convolutional architectures\ncalled Non-Parametric Transformation Networks (NPTNs) which can learn\n\\textit{general} invariances and symmetries directly from data. NPTNs are a\nnatural generalization of ConvNets and can be optimized directly using gradient\ndescent. Unlike almost all previous works in deep architectures, they make no\nassumption regarding the structure of the invariances present in the data and\nin that aspect are flexible and powerful. We also model ConvNets and NPTNs\nunder a unified framework called Transformation Networks (TN), which yields a\nbetter understanding of the connection between the two. We demonstrate the\nefficacy of NPTNs on data such as MNIST with extreme transformations and\nCIFAR10 where they outperform baselines, and further outperform several recent\nalgorithms on ETH-80. They do so while having the same number of parameters. We\nalso show that they are more effective than ConvNets in modelling symmetries\nand invariances from data, without the explicit knowledge of the added\narbitrary nuisance transformations. Finally, we replace ConvNets with NPTNs\nwithin Capsule Networks and show that this enables Capsule Nets to perform even\nbetter.", "published": "2018-01-14T06:48:45Z", "version": 6}, {"aid": "1801.06432", "authors": ["Mehdi Bahri", "Yannis Panagakis", "Stefanos Zafeiriou"], "title": "Robust Kronecker Component Analysis", "url": "http://arxiv.org/pdf/1801.06432v2", "summary": "Dictionary learning and component analysis models are fundamental for\nlearning compact representations that are relevant to a given task (feature\nextraction, dimensionality reduction, denoising, etc.). The model complexity is\nencoded by means of specific structure, such as sparsity, low-rankness, or\nnonnegativity. Unfortunately, approaches like K-SVD - that learn dictionaries\nfor sparse coding via Singular Value Decomposition (SVD) - are hard to scale to\nhigh-volume and high-dimensional visual data, and fragile in the presence of\noutliers. Conversely, robust component analysis methods such as the Robust\nPrincipal Component Analysis (RPCA) are able to recover low-complexity (e.g.,\nlow-rank) representations from data corrupted with noise of unknown magnitude\nand support, but do not provide a dictionary that respects the structure of the\ndata (e.g., images), and also involve expensive computations. In this paper, we\npropose a novel Kronecker-decomposable component analysis model, coined as\nRobust Kronecker Component Analysis (RKCA), that combines ideas from sparse\ndictionary learning and robust component analysis. RKCA has several appealing\nproperties, including robustness to gross corruption; it can be used for\nlow-rank modeling, and leverages separability to solve significantly smaller\nproblems. We design an efficient learning algorithm by drawing links with a\nrestricted form of tensor factorization, and analyze its optimality and\nlow-rankness properties. The effectiveness of the proposed approach is\ndemonstrated on real-world applications, namely background subtraction and\nimage denoising and completion, by performing a thorough comparison with the\ncurrent state of the art.", "published": "2018-01-18T18:01:50Z", "version": 2}, {"aid": "1801.06434", "authors": ["Ido Freeman", "Lutz Roese-Koerner", "Anton Kummert"], "title": "EffNet: An Efficient Structure for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1801.06434v6", "summary": "With the ever increasing application of Convolutional Neural Networks to\ncustomer products the need emerges for models to efficiently run on embedded,\nmobile hardware. Slimmer models have therefore become a hot research topic with\nvarious approaches which vary from binary networks to revised convolution\nlayers. We offer our contribution to the latter and propose a novel convolution\nblock which significantly reduces the computational burden while surpassing the\ncurrent state-of-the-art. Our model, dubbed EffNet, is optimised for models\nwhich are slim to begin with and is created to tackle issues in existing models\nsuch as MobileNet and ShuffleNet.", "published": "2018-01-19T14:57:23Z", "version": 6}, {"aid": "1801.06724", "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "title": "DeepISP: Towards Learning an End-to-End Image Processing Pipeline", "url": "http://arxiv.org/pdf/1801.06724v2", "summary": "We present DeepISP, a full end-to-end deep neural model of the camera image\nsignal processing (ISP) pipeline. Our model learns a mapping from the raw\nlow-light mosaiced image to the final visually compelling image and encompasses\nlow-level tasks such as demosaicing and denoising as well as higher-level tasks\nsuch as color correction and image adjustment. The training and evaluation of\nthe pipeline were performed on a dedicated dataset containing pairs of\nlow-light and well-lit images captured by a Samsung S7 smartphone camera in\nboth raw and processed JPEG formats. The proposed solution achieves\nstate-of-the-art performance in objective evaluation of PSNR on the subtask of\njoint denoising and demosaicing. For the full end-to-end pipeline, it achieves\nbetter visual quality compared to the manufacturer ISP, in both a subjective\nhuman assessment and when rated by a deep model trained for assessing image\nquality.", "published": "2018-01-20T20:41:05Z", "version": 2}, {"aid": "1801.07211", "authors": ["Ayan Kumar Bhunia", "Abir Bhowmick", "Ankan Kumar Bhunia", "Aishik Konwer", "Prithaj Banerjee", "Partha Pratim Roy", "Umapada Pal"], "title": "Handwriting Trajectory Recovery using End-to-End Deep Encoder-Decoder Network", "url": "http://arxiv.org/pdf/1801.07211v4", "summary": "In this paper, we introduce a novel technique to recover the pen trajectory\nof offline characters which is a crucial step for handwritten character\nrecognition. Generally, online acquisition approach has more advantage than its\noffline counterpart as the online technique keeps track of the pen movement.\nHence, pen tip trajectory retrieval from offline text can bridge the gap\nbetween online and offline methods. Our proposed framework employs sequence to\nsequence model which consists of an encoder-decoder LSTM module. Our encoder\nmodule consists of Convolutional LSTM network, which takes an offline character\nimage as the input and encodes the feature sequence to a hidden representation.\nThe output of the encoder is fed to a decoder LSTM and we get the successive\ncoordinate points from every time step of the decoder LSTM. Although the\nsequence to sequence model is a popular paradigm in various computer vision and\nlanguage translation tasks, the main contribution of our work lies in designing\nan end-to-end network for a decade old popular problem in Document Image\nAnalysis community. Tamil, Telugu and Devanagari characters of LIPI Toolkit\ndataset are used for our experiments. Our proposed method has achieved superior\nperformance compared to the other conventional approaches.", "published": "2018-01-22T17:25:05Z", "version": 4}, {"aid": "1801.07648", "authors": ["Elie Aljalbout", "Vladimir Golkov", "Yawar Siddiqui", "Maximilian Strobel", "Daniel Cremers"], "title": "Clustering with Deep Learning: Taxonomy and New Methods", "url": "http://arxiv.org/pdf/1801.07648v2", "summary": "Clustering methods based on deep neural networks have proven promising for\nclustering real-world data because of their high representational power. In\nthis paper, we propose a systematic taxonomy of clustering methods that utilize\ndeep neural networks. We base our taxonomy on a comprehensive review of recent\nwork and validate the taxonomy in a case study. In this case study, we show\nthat the taxonomy enables researchers and practitioners to systematically\ncreate new clustering methods by selectively recombining and replacing distinct\naspects of previous methods with the goal of overcoming their individual\nlimitations. The experimental evaluation confirms this and shows that the\nmethod created for the case study achieves state-of-the-art clustering quality\nand surpasses it in some cases.", "published": "2018-01-23T16:41:03Z", "version": 2}, {"aid": "1801.09858", "authors": ["Xiaoxiao Wang", "Xiao Liang", "Zhoufan Jiang", "Benedictor Alexander Nguchu", "Yawen Zhou", "Yanming Wang", "Huijuan Wang", "Yu Li", "Yuying Zhu", "Feng Wu", "Jia-Hong Gao", "Benching Qiu"], "title": "Decoding and mapping task states of the human brain via deep learning", "url": "http://arxiv.org/pdf/1801.09858v3", "summary": "Support vector machine (SVM) based multivariate pattern analysis (MVPA) has\ndelivered promising performance in decoding specific task states based on\nfunctional magnetic resonance imaging (fMRI) of the human brain.\nConventionally, the SVM-MVPA requires careful feature selection/extraction\naccording to expert knowledge. In this study, we propose a deep neural network\n(DNN) for directly decoding multiple brain task states from fMRI signals of the\nbrain without any burden for feature handcrafts. We trained and tested the DNN\nclassifier using task fMRI data from the Human Connectome Project's S1200\ndataset (N=1034). In tests to verify its performance, the proposed\nclassification method identified seven tasks with an average accuracy of 93.7%.\nWe also showed the general applicability of the DNN for transfer learning to\nsmall datasets (N=43), a situation encountered in typical neuroscience\nresearch. The proposed method achieved an average accuracy of 89.0% and 94.7%\non a working memory task and a motor classification task, respectively, higher\nthan the accuracy of 69.2% and 68.6% obtained by the SVM-MVPA. A network\nvisualization analysis showed that the DNN automatically detected features from\nareas of the brain related to each task. Without incurring the burden of\nhandcrafting the features, the proposed deep decoding method can classify brain\ntask states highly accurately, and is a powerful tool for fMRI researchers.", "published": "2018-01-30T05:58:18Z", "version": 3}, {"aid": "1802.02172", "authors": ["Alexander N. Gorban", "Bogdan Grechuk", "Ivan Y. Tyukin"], "title": "Augmented Artificial Intelligence: a Conceptual Framework", "url": "http://arxiv.org/pdf/1802.02172v3", "summary": "All artificial Intelligence (AI) systems make errors. These errors are\nunexpected, and differ often from the typical human mistakes (\"non-human\"\nerrors). The AI errors should be corrected without damage of existing skills\nand, hopefully, avoiding direct human expertise. This paper presents an initial\nsummary report of project taking new and systematic approach to improving the\nintellectual effectiveness of the individual AI by communities of AIs. We\ncombine some ideas of learning in heterogeneous multiagent systems with new and\noriginal mathematical approaches for non-iterative corrections of errors of\nlegacy AI systems. The mathematical foundations of AI non-destructive\ncorrection are presented and a series of new stochastic separation theorems is\nproven. These theorems provide a new instrument for the development, analysis,\nand assessment of machine learning methods and algorithms in high dimension.\nThey demonstrate that in high dimensions and even for exponentially large\nsamples, linear classifiers in their classical Fisher's form are powerful\nenough to separate errors from correct responses with high probability and to\nprovide efficient solution to the non-destructive corrector problem. In\nparticular, we prove some hypotheses formulated in our paper `Stochastic\nSeparation Theorems' (Neural Networks, 94, 255--259, 2017), and answer one\ngeneral problem published by Donoho and Tanner in 2009.", "published": "2018-02-06T19:05:27Z", "version": 3}, {"aid": "1802.02375", "authors": ["Yoshihiro Yamada", "Masakazu Iwamura", "Takuya Akiba", "Koichi Kise"], "title": "ShakeDrop Regularization for Deep Residual Learning", "url": "http://arxiv.org/pdf/1802.02375v3", "summary": "Overfitting is a crucial problem in deep neural networks, even in the latest\nnetwork architectures. In this paper, to relieve the overfitting effect of\nResNet and its improvements (i.e., Wide ResNet, PyramidNet, and ResNeXt), we\npropose a new regularization method called ShakeDrop regularization. ShakeDrop\nis inspired by Shake-Shake, which is an effective regularization method, but\ncan be applied to ResNeXt only. ShakeDrop is more effective than Shake-Shake\nand can be applied not only to ResNeXt but also ResNet, Wide ResNet, and\nPyramidNet. An important key is to achieve stability of training. Because\neffective regularization often causes unstable training, we introduce a\ntraining stabilizer, which is an unusual use of an existing regularizer.\nThrough experiments under various conditions, we demonstrate the conditions\nunder which ShakeDrop works well.", "published": "2018-02-07T10:23:54Z", "version": 3}, {"aid": "1802.02952", "authors": ["Shoaib Ahmed Siddiqui", "Dominik Mercier", "Mohsin Munir", "Andreas Dengel", "Sheraz Ahmed"], "title": "TSViz: Demystification of Deep Learning Models for Time-Series Analysis", "url": "http://arxiv.org/pdf/1802.02952v3", "summary": "This paper presents a novel framework for demystification of convolutional\ndeep learning models for time-series analysis. This is a step towards making\ninformed/explainable decisions in the domain of time-series, powered by deep\nlearning. There have been numerous efforts to increase the interpretability of\nimage-centric deep neural network models, where the learned features are more\nintuitive to visualize. Visualization in time-series domain is much more\ncomplicated as there is no direct interpretation of the filters and inputs as\ncompared to the image modality. In addition, little or no concentration has\nbeen devoted for the development of such tools in the domain of time-series in\nthe past. TSViz provides possibilities to explore and analyze a network from\ndifferent dimensions at different levels of abstraction which includes\nidentification of parts of the input that were responsible for a prediction\n(including per filter saliency), importance of different filters present in the\nnetwork for a particular prediction, notion of diversity present in the network\nthrough filter clustering, understanding of the main sources of variation\nlearnt by the network through inverse optimization, and analysis of the\nnetwork's robustness against adversarial noise. As a sanity check for the\ncomputed influence values, we demonstrate results regarding pruning of neural\nnetworks based on the computed influence information. These representations\nallow to understand the network features so that the acceptability of deep\nnetworks for time-series data can be enhanced. This is extremely important in\ndomains like finance, industry 4.0, self-driving cars, health-care,\ncounter-terrorism etc., where reasons for reaching a particular prediction are\nequally important as the prediction itself. We assess the proposed framework\nfor interpretability with a set of desirable properties essential for any\nmethod.", "published": "2018-02-08T16:29:49Z", "version": 3}, {"aid": "1802.05160", "authors": ["Xiaolin Wu", "Xi Zhang", "Xiao Shu"], "title": "Cognitive Deficit of Deep Learning in Numerosity", "url": "http://arxiv.org/pdf/1802.05160v4", "summary": "Subitizing, or the sense of small natural numbers, is an innate cognitive\nfunction of humans and primates; it responds to visual stimuli prior to the\ndevelopment of any symbolic skills, language or arithmetic. Given successes of\ndeep learning (DL) in tasks of visual intelligence and given the primitivity of\nnumber sense, a tantalizing question is whether DL can comprehend numbers and\nperform subitizing. But somewhat disappointingly, extensive experiments of the\ntype of cognitive psychology demonstrate that the examples-driven black box DL\ncannot see through superficial variations in visual representations and distill\nthe abstract notion of natural number, a task that children perform with high\naccuracy and confidence. The failure is apparently due to the learning method\nnot the CNN computational machinery itself. A recurrent neural network capable\nof subitizing does exist, which we construct by encoding a mechanism of\nmathematical morphology into the CNN convolutional kernels. Also, we\ninvestigate, using subitizing as a test bed, the ways to aid the black box DL\nby cognitive priors derived from human insight. Our findings are mixed and\ninteresting, pointing to both cognitive deficit of pure DL, and some measured\nsuccesses of boosting DL by predetermined cognitive implements. This case study\nof DL in cognitive computing is meaningful for visual numerosity represents a\nminimum level of human intelligence.", "published": "2018-02-09T15:01:52Z", "version": 4}, {"aid": "1802.03596", "authors": ["Fengwei Zhou", "Bin Wu", "Zhenguo Li"], "title": "Deep Meta-Learning: Learning to Learn in the Concept Space", "url": "http://arxiv.org/pdf/1802.03596v1", "summary": "Few-shot learning remains challenging for meta-learning that learns a\nlearning algorithm (meta-learner) from many related tasks. In this work, we\nargue that this is due to the lack of a good representation for meta-learning,\nand propose deep meta-learning to integrate the representation power of deep\nlearning into meta-learning. The framework is composed of three modules, a\nconcept generator, a meta-learner, and a concept discriminator, which are\nlearned jointly. The concept generator, e.g. a deep residual net, extracts a\nrepresentation for each instance that captures its high-level concept, on which\nthe meta-learner performs few-shot learning, and the concept discriminator\nrecognizes the concepts. By learning to learn in the concept space rather than\nin the complicated instance space, deep meta-learning can substantially improve\nvanilla meta-learning, which is demonstrated on various few-shot image\nrecognition problems. For example, on 5-way-1-shot image recognition on\nCIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to\n58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%,\nand improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%,\nrespectively.", "published": "2018-02-10T14:18:08Z", "version": 1}, {"aid": "1802.03654", "authors": ["Yonathan Efroni", "Gal Dalal", "Bruno Scherrer", "Shie Mannor"], "title": "Beyond the One Step Greedy Approach in Reinforcement Learning", "url": "http://arxiv.org/pdf/1802.03654v3", "summary": "The famous Policy Iteration algorithm alternates between policy improvement\nand policy evaluation. Implementations of this algorithm with several variants\nof the latter evaluation stage, e.g, $n$-step and trace-based returns, have\nbeen analyzed in previous works. However, the case of multiple-step lookahead\npolicy improvement, despite the recent increase in empirical evidence of its\nstrength, has to our knowledge not been carefully analyzed yet. In this work,\nwe introduce the first such analysis. Namely, we formulate variants of\nmultiple-step policy improvement, derive new algorithms using these definitions\nand prove their convergence. Moreover, we show that recent prominent\nReinforcement Learning algorithms are, in fact, instances of our framework. We\nthus shed light on their empirical success and give a recipe for deriving new\nalgorithms for future study.", "published": "2018-02-10T22:22:03Z", "version": 3}, {"aid": "1802.03996", "authors": ["Xiang Zhang", "Lina Yao", "Xianzhi Wang", "Wenjie Zhang", "Shuai Zhang", "Yunhao Liu"], "title": "Know Your Mind: Adaptive Brain Signal Classification with Reinforced Attentive Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1802.03996v5", "summary": "Electroencephalography (EEG) signals reflect activities on certain brain\nareas. Effective classification of time-varying EEG signals is still\nchallenging. First, EEG signal processing and feature engineering are\ntime-consuming and highly rely on expert knowledge. In addition, most existing\nstudies focus on domain-specific classification algorithms which may not be\napplicable to other domains. Moreover, the EEG signal usually has a low\nsignal-to-noise ratio and can be easily corrupted. In this regard, we propose a\ngeneric EEG signal classification framework that accommodates a wide range of\napplications to address the aforementioned issues. The proposed framework\ndevelops a reinforced selective attention model to automatically choose the\ndistinctive information among the raw EEG signals. A convolutional mapping\noperation is employed to dynamically transform the selected information to an\nover-complete feature space, wherein implicit spatial dependency of EEG samples\ndistribution is able to be uncovered. We demonstrate the effectiveness of the\nproposed framework using three representative scenarios: intention recognition\nwith motor imagery EEG, person identification, and neurological diagnosis.\nThree widely used public datasets and a local dataset are used for our\nevaluation. The experiments show that our framework outperforms the\nstate-of-the-art baselines and achieves the accuracy of more than 97% on all\nthe datasets with low latency and good resilience of handling complex EEG\nsignals across various domains. These results confirm the suitability of the\nproposed generic approach for a range of problems in the realm of\nBrain-Computer Interface applications.", "published": "2018-02-12T11:59:40Z", "version": 5}, {"aid": "1802.05098", "authors": ["Jakob Foerster", "Gregory Farquhar", "Maruan Al-Shedivat", "Tim Rockt\u00e4schel", "Eric P. Xing", "Shimon Whiteson"], "title": "DiCE: The Infinitely Differentiable Monte-Carlo Estimator", "url": "http://arxiv.org/pdf/1802.05098v3", "summary": "The score function estimator is widely used for estimating gradients of\nstochastic objectives in stochastic computation graphs (SCG), eg, in\nreinforcement learning and meta-learning. While deriving the first-order\ngradient estimators by differentiating a surrogate loss (SL) objective is\ncomputationally and conceptually simple, using the same approach for\nhigher-order derivatives is more challenging. Firstly, analytically deriving\nand implementing such estimators is laborious and not compliant with automatic\ndifferentiation. Secondly, repeatedly applying SL to construct new objectives\nfor each order derivative involves increasingly cumbersome graph manipulations.\nLastly, to match the first-order gradient under differentiation, SL treats part\nof the cost as a fixed sample, which we show leads to missing and wrong terms\nfor estimators of higher-order derivatives. To address all these shortcomings\nin a unified way, we introduce DiCE, which provides a single objective that can\nbe differentiated repeatedly, generating correct estimators of derivatives of\nany order in SCGs. Unlike SL, DiCE relies on automatic differentiation for\nperforming the requisite graph manipulations. We verify the correctness of DiCE\nboth through a proof and numerical evaluation of the DiCE derivative estimates.\nWe also use DiCE to propose and evaluate a novel approach for multi-agent\nlearning. Our code is available at https://www.github.com/alshedivat/lola.", "published": "2018-02-14T14:05:54Z", "version": 3}, {"aid": "1802.05384", "authors": ["Thibault Groueix", "Matthew Fisher", "Vladimir G. Kim", "Bryan C. Russell", "Mathieu Aubry"], "title": "AtlasNet: A Papier-M\u00e2ch\u00e9 Approach to Learning 3D Surface Generation", "url": "http://arxiv.org/pdf/1802.05384v3", "summary": "We introduce a method for learning to generate the surface of 3D shapes. Our\napproach represents a 3D shape as a collection of parametric surface elements\nand, in contrast to methods generating voxel grids or point clouds, naturally\ninfers a surface representation of the shape. Beyond its novelty, our new shape\ngeneration framework, AtlasNet, comes with significant advantages, such as\nimproved precision and generalization capabilities, and the possibility to\ngenerate a shape of arbitrary resolution without memory issues. We demonstrate\nthese benefits and compare to strong baselines on the ShapeNet benchmark for\ntwo applications: (i) auto-encoding shapes, and (ii) single-view reconstruction\nfrom a still image. We also provide results showing its potential for other\napplications, such as morphing, parametrization, super-resolution, matching,\nand co-segmentation.", "published": "2018-02-15T02:07:30Z", "version": 3}, {"aid": "1802.05584", "authors": ["Il Yong Chun", "Jeffrey A. Fessler"], "title": "Convolutional Analysis Operator Learning: Acceleration and Convergence", "url": "http://arxiv.org/pdf/1802.05584v7", "summary": "Convolutional operator learning is gaining attention in many signal\nprocessing and computer vision applications. Learning kernels has mostly relied\non so-called patch-domain approaches that extract and store many overlapping\npatches across training signals. Due to memory demands, patch-domain methods\nhave limitations when learning kernels from large datasets -- particularly with\nmulti-layered structures, e.g., convolutional neural networks -- or when\napplying the learned kernels to high-dimensional signal recovery problems. The\nso-called convolution approach does not store many overlapping patches, and\nthus overcomes the memory problems particularly with careful algorithmic\ndesigns; it has been studied within the \"synthesis\" signal model, e.g.,\nconvolutional dictionary learning. This paper proposes a new convolutional\nanalysis operator learning (CAOL) framework that learns an analysis sparsifying\nregularizer with the convolution perspective, and develops a new convergent\nBlock Proximal Extrapolated Gradient method using a Majorizer (BPEG-M) to solve\nthe corresponding block multi-nonconvex problems. To learn diverse filters\nwithin the CAOL framework, this paper introduces an orthogonality constraint\nthat enforces a tight-frame filter condition, and a regularizer that promotes\ndiversity between filters. Numerical experiments show that, with sharp\nmajorizers, BPEG-M significantly accelerates the CAOL convergence rate compared\nto the state-of-the-art block proximal gradient (BPG) method. Numerical\nexperiments for sparse-view computational tomography show that a convolutional\nsparsifying regularizer learned via CAOL significantly improves reconstruction\nquality compared to a conventional edge-preserving regularizer. Using more and\nwider kernels in a learned regularizer better preserves edges in reconstructed\nimages.", "published": "2018-02-15T14:51:38Z", "version": 7}, {"aid": "1802.09904", "authors": ["Hector Zenil", "Narsis A. Kiani", "Allan A. Zea", "Jesper Tegn\u00e9r"], "title": "Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism", "url": "http://arxiv.org/pdf/1802.09904v8", "summary": "Complex data usually results from the interaction of objects produced by\ndifferent generating mechanisms. Here we introduce a universal, unsupervised\nand parameter-free model-oriented approach, based upon the seminal concept of\nalgorithmic probability, that decomposes an observation into its most likely\nalgorithmic generative sources. Our approach uses a causal calculus to infer\nmodel representations. We demonstrate its ability to deconvolve interacting\nmechanisms regardless of whether the resultant objects are strings, space-time\nevolution diagrams, images or networks. While this is mostly a conceptual\ncontribution and a novel framework, we provide numerical evidence evaluating\nthe ability of our methods to separate data from observations produced by\ndiscrete dynamical systems such as cellular automata and complex networks. We\nthink that these separating techniques can contribute to tackling the challenge\nof causation, thus complementing other statistically oriented approaches.", "published": "2018-02-18T08:06:13Z", "version": 8}, {"aid": "1802.06891", "authors": ["Matthew Fellows", "Kamil Ciosek", "Shimon Whiteson"], "title": "Fourier Policy Gradients", "url": "http://arxiv.org/pdf/1802.06891v2", "summary": "We propose a new way of deriving policy gradient updates for reinforcement\nlearning. Our technique, based on Fourier analysis, recasts integrals that\narise with expected policy gradients as convolutions and turns them into\nmultiplications. The obtained analytical solutions allow us to capture the low\nvariance benefits of EPG in a broad range of settings. For the critic, we treat\ntrigonometric and radial basis functions, two function families with the\nuniversal approximation property. The choice of policy can be almost arbitrary,\nincluding mixtures or hybrid continuous-discrete probability distributions.\nMoreover, we derive a general family of sample-based estimators for stochastic\npolicy gradients, which unifies existing results on sample-based approximation.\nWe believe that this technique has the potential to shape the next generation\nof policy gradient approaches, powered by analytical results.", "published": "2018-02-19T22:28:56Z", "version": 2}, {"aid": "1802.06955", "authors": ["Md Zahangir Alom", "Mahmudul Hasan", "Chris Yakopcic", "Tarek M. Taha", "Vijayan K. Asari"], "title": "Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation", "url": "http://arxiv.org/pdf/1802.06955v5", "summary": "Deep learning (DL) based semantic segmentation methods have been providing\nstate-of-the-art performance in the last few years. More specifically, these\ntechniques have been successfully applied to medical image classification,\nsegmentation, and detection tasks. One deep learning technique, U-Net, has\nbecome one of the most popular for these applications. In this paper, we\npropose a Recurrent Convolutional Neural Network (RCNN) based on U-Net as well\nas a Recurrent Residual Convolutional Neural Network (RRCNN) based on U-Net\nmodels, which are named RU-Net and R2U-Net respectively. The proposed models\nutilize the power of U-Net, Residual Network, as well as RCNN. There are\nseveral advantages of these proposed architectures for segmentation tasks.\nFirst, a residual unit helps when training deep architecture. Second, feature\naccumulation with recurrent residual convolutional layers ensures better\nfeature representation for segmentation tasks. Third, it allows us to design\nbetter U-Net architecture with same number of network parameters with better\nperformance for medical image segmentation. The proposed models are tested on\nthree benchmark datasets such as blood vessel segmentation in retina images,\nskin cancer segmentation, and lung lesion segmentation. The experimental\nresults show superior performance on segmentation tasks compared to equivalent\nmodels including U-Net and residual U-Net (ResU-Net).", "published": "2018-02-20T03:59:39Z", "version": 5}, {"aid": "1802.07303", "authors": ["Mengran Gou", "Fei Xiong", "Octavia Camps", "Mario Sznaier"], "title": "MoNet: Moments Embedding Network", "url": "http://arxiv.org/pdf/1802.07303v2", "summary": "Bilinear pooling has been recently proposed as a feature encoding layer,\nwhich can be used after the convolutional layers of a deep network, to improve\nperformance in multiple vision tasks. Different from conventional global\naverage pooling or fully connected layer, bilinear pooling gathers 2nd order\ninformation in a translation invariant fashion. However, a serious drawback of\nthis family of pooling layers is their dimensionality explosion. Approximate\npooling methods with compact properties have been explored towards resolving\nthis weakness. Additionally, recent results have shown that significant\nperformance gains can be achieved by adding 1st order information and applying\nmatrix normalization to regularize unstable higher order information. However,\ncombining compact pooling with matrix normalization and other order information\nhas not been explored until now. In this paper, we unify bilinear pooling and\nthe global Gaussian embedding layers through the empirical moment matrix. In\naddition, we propose a novel sub-matrix square-root layer, which can be used to\nnormalize the output of the convolution layer directly and mitigate the\ndimensionality problem with off-the-shelf compact pooling methods. Our\nexperiments on three widely used fine-grained classification datasets\nillustrate that our proposed architecture, MoNet, can achieve similar or better\nperformance than with the state-of-art G2DeNet. Furthermore, when combined with\ncompact pooling technique, MoNet obtains comparable performance with encoded\nfeatures with 96% less dimensions.", "published": "2018-02-20T19:54:58Z", "version": 2}, {"aid": "1802.08797", "authors": ["Yulun Zhang", "Yapeng Tian", "Yu Kong", "Bineng Zhong", "Yun Fu"], "title": "Residual Dense Network for Image Super-Resolution", "url": "http://arxiv.org/pdf/1802.08797v2", "summary": "A very deep convolutional neural network (CNN) has recently achieved great\nsuccess for image super-resolution (SR) and offered hierarchical features as\nwell. However, most deep CNN based SR models do not make full use of the\nhierarchical features from the original low-resolution (LR) images, thereby\nachieving relatively-low performance. In this paper, we propose a novel\nresidual dense network (RDN) to address this problem in image SR. We fully\nexploit the hierarchical features from all the convolutional layers.\nSpecifically, we propose residual dense block (RDB) to extract abundant local\nfeatures via dense connected convolutional layers. RDB further allows direct\nconnections from the state of preceding RDB to all the layers of current RDB,\nleading to a contiguous memory (CM) mechanism. Local feature fusion in RDB is\nthen used to adaptively learn more effective features from preceding and\ncurrent local features and stabilizes the training of wider network. After\nfully obtaining dense local features, we use global feature fusion to jointly\nand adaptively learn global hierarchical features in a holistic way. Extensive\nexperiments on benchmark datasets with different degradation models show that\nour RDN achieves favorable performance against state-of-the-art methods.", "published": "2018-02-24T04:40:06Z", "version": 2}, {"aid": "1802.08831", "authors": ["Mai Zhu", "Bo Chang", "Chong Fu"], "title": "Convolutional Neural Networks combined with Runge-Kutta Methods", "url": "http://arxiv.org/pdf/1802.08831v7", "summary": "A convolutional neural network can be constructed using numerical methods for\nsolving dynamical systems, since the forward pass of the network can be\nregarded as a trajectory of a dynamical system. However, existing models based\non numerical solvers cannot avoid the iterations of implicit methods, which\nmakes the models inefficient at inference time. In this paper, we reinterpret\nthe pre-activation Residual Networks (ResNets) and their variants from the\ndynamical systems view. We consider that the iterations of implicit Runge-Kutta\nmethods are fused into the training of these models. Moreover, we propose a\nnovel approach to constructing network models based on high-order Runge-Kutta\nmethods in order to achieve higher efficiency. Our proposed models are referred\nto as the Runge-Kutta Convolutional Neural Networks (RKCNNs). The RKCNNs are\nevaluated on multiple benchmark datasets. The experimental results show that\nRKCNNs are vastly superior to other dynamical system network models: they\nachieve higher accuracy with much fewer resources. They also expand the family\nof network models based on numerical methods for dynamical systems.", "published": "2018-02-24T10:31:24Z", "version": 7}, {"aid": "1802.09030", "authors": ["Uri Patish", "Shimon Ullman"], "title": "Cakewalk Sampling", "url": "http://arxiv.org/pdf/1802.09030v2", "summary": "We study the task of finding good local optima in combinatorial optimization\nproblems. Although combinatorial optimization is NP-hard in general, locally\noptimal solutions are frequently used in practice. Local search methods however\ntypically converge to a limited set of optima that depend on their\ninitialization. Sampling methods on the other hand can access any valid\nsolution, and thus can be used either directly or alongside methods of the\nformer type as a way for finding good local optima. Since the effectiveness of\nthis strategy depends on the sampling distribution, we derive a robust learning\nalgorithm that adapts sampling distributions towards good local optima of\narbitrary objective functions. As a first use case, we empirically study the\nefficiency in which sampling methods can recover locally maximal cliques in\nundirected graphs. Not only do we show how our adaptive sampler outperforms\nrelated methods, we also show how it can even approach the performance of\nestablished clique algorithms. As a second use case, we consider how greedy\nalgorithms can be combined with our adaptive sampler, and we demonstrate how\nthis leads to superior performance in k-medoid clustering. Together, these\nfindings suggest that our adaptive sampler can provide an effective strategy to\ncombinatorial optimization problems that arise in practice.", "published": "2018-02-25T16:15:32Z", "version": 2}, {"aid": "1802.09766", "authors": ["Rana Ali Amjad", "Bernhard C. Geiger"], "title": "Learning Representations for Neural Network-Based Classification Using the Information Bottleneck Principle", "url": "http://arxiv.org/pdf/1802.09766v6", "summary": "In this theory paper, we investigate training deep neural networks (DNNs) for\nclassification via minimizing the information bottleneck (IB) functional. We\nshow that the resulting optimization problem suffers from two severe issues:\nFirst, for deterministic DNNs, either the IB functional is infinite for almost\nall values of network parameters, making the optimization problem ill-posed, or\nit is piecewise constant, hence not admitting gradient-based optimization\nmethods. Second, the invariance of the IB functional under bijections prevents\nit from capturing properties of the learned representation that are desirable\nfor classification, such as robustness and simplicity. We argue that these\nissues are partly resolved for stochastic DNNs, DNNs that include a (hard or\nsoft) decision rule, or by replacing the IB functional with related, but more\nwell-behaved cost functions. We conclude that recent successes reported about\ntraining DNNs using the IB framework must be attributed to such solutions. As a\nside effect, our results indicate limitations of the IB framework for the\nanalysis of DNNs. We also note that rather than trying to repair the inherent\nproblems in the IB functional, a better approach may be to design regularizers\non latent representation enforcing the desired properties directly.", "published": "2018-02-27T08:24:19Z", "version": 6}, {"aid": "1802.10055", "authors": ["Jaejun Yoo", "Abdul Wahab", "Jong Chul Ye"], "title": "A Mathematical Framework for Deep Learning in Elastic Source Imaging", "url": "http://arxiv.org/pdf/1802.10055v3", "summary": "An inverse elastic source problem with sparse measurements is of concern. A\ngeneric mathematical framework is proposed which incorporates a low-\ndimensional manifold regularization in the conventional source reconstruction\nalgorithms thereby enhancing their performance with sparse datasets. It is\nrigorously established that the proposed framework is equivalent to the\nso-called \\emph{deep convolutional framelet expansion} in machine learning\nliterature for inverse problems. Apposite numerical examples are furnished to\nsubstantiate the efficacy of the proposed framework.", "published": "2018-02-27T18:14:00Z", "version": 3}, {"aid": "1802.10204", "authors": ["Atefeh Shahroudnejad", "Arash Mohammadi", "Konstantinos N. Plataniotis"], "title": "Improved Explainability of Capsule Networks: Relevance Path by Agreement", "url": "http://arxiv.org/pdf/1802.10204v1", "summary": "Recent advancements in signal processing and machine learning domains have\nresulted in an extensive surge of interest in deep learning models due to their\nunprecedented performance and high accuracy for different and challenging\nproblems of significant engineering importance. However, when such deep\nlearning architectures are utilized for making critical decisions such as the\nones that involve human lives (e.g., in medical applications), it is of\nparamount importance to understand, trust, and in one word \"explain\" the\nrational behind deep models' decisions. Currently, deep learning models are\ntypically considered as black-box systems, which do not provide any clue on\ntheir internal processing actions. Although some recent efforts have been\ninitiated to explain behavior and decisions of deep networks, explainable\nartificial intelligence (XAI) domain is still in its infancy. In this regard,\nwe consider capsule networks (referred to as CapsNets), which are novel deep\nstructures; recently proposed as an alternative counterpart to convolutional\nneural networks (CNNs), and posed to change the future of machine intelligence.\nIn this paper, we investigate and analyze structures and behaviors of the\nCapsNets and illustrate potential explainability properties of such networks.\nFurthermore, we show possibility of transforming deep learning architectures in\nto transparent networks via incorporation of capsules in different layers\ninstead of convolution layers of the CNNs.", "published": "2018-02-27T23:08:17Z", "version": 1}, {"aid": "1803.00094", "authors": ["Quynh Nguyen", "Mahesh Chandra Mukkamala", "Matthias Hein"], "title": "Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions", "url": "http://arxiv.org/pdf/1803.00094v3", "summary": "In the recent literature the important role of depth in deep learning has\nbeen emphasized. In this paper we argue that sufficient width of a feedforward\nnetwork is equally important by answering the simple question under which\nconditions the decision regions of a neural network are connected. It turns out\nthat for a class of activation functions including leaky ReLU, neural networks\nhaving a pyramidal structure, that is no layer has more hidden units than the\ninput dimension, produce necessarily connected decision regions. This implies\nthat a sufficiently wide hidden layer is necessary to guarantee that the\nnetwork can produce disconnected decision regions. We discuss the implications\nof this result for the construction of neural networks, in particular the\nrelation to the problem of adversarial manipulation of classifiers.", "published": "2018-02-28T21:28:28Z", "version": 3}, {"aid": "1803.00197", "authors": ["Xingyu Chen", "Junzhi Yu", "Zhengxing Wu"], "title": "Temporally Identity-Aware SSD with Attentional LSTM", "url": "http://arxiv.org/pdf/1803.00197v4", "summary": "Temporal object detection has attracted significant attention, but most\npopular detection methods cannot leverage rich temporal information in videos.\nVery recently, many algorithms have been developed for video detection task,\nyet very few approaches can achieve \\emph{real-time online} object detection in\nvideos. In this paper, based on attention mechanism and convolutional long\nshort-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD)\nfor real-world detection. Distinct from previous methods, we take aim at\ntemporally integrating pyramidal feature hierarchy using ConvLSTM, and design a\nnovel structure including a low-level temporal unit as well as a high-level one\n(LH-TU) for multi-scale feature maps. Moreover, we develop a creative temporal\nanalysis unit, namely, attentional ConvLSTM (AC-LSTM), in which a temporal\nattention mechanism is specially tailored for background suppression and scale\nsuppression while a ConvLSTM integrates attention-aware features across time.\nAn association loss and a multi-step training are designed for temporal\ncoherence. Besides, an online tubelet analysis (OTA) is exploited for\nidentification. Our framework is evaluated on ImageNet VID dataset and 2DMOT15\ndataset. Extensive comparisons on the detection and tracking capability\nvalidate the superiority of the proposed approach. Consequently, the developed\nTSSD-OTA achieves a fast speed and an overall competitive performance in terms\nof detection and tracking. Finally, a real-world maneuver is conducted for\nunderwater object grasping. The source code is publicly available at\nhttps://github.com/SeanChenxy/TSSD-OTA.", "published": "2018-03-01T03:48:07Z", "version": 4}, {"aid": "1803.00702", "authors": ["Emad M. Grais", "Dominic Ward", "Mark D. Plumbley"], "title": "Raw Multi-Channel Audio Source Separation using Multi-Resolution Convolutional Auto-Encoders", "url": "http://arxiv.org/pdf/1803.00702v1", "summary": "Supervised multi-channel audio source separation requires extracting useful\nspectral, temporal, and spatial features from the mixed signals. The success of\nmany existing systems is therefore largely dependent on the choice of features\nused for training. In this work, we introduce a novel multi-channel,\nmulti-resolution convolutional auto-encoder neural network that works on raw\ntime-domain signals to determine appropriate multi-resolution features for\nseparating the singing-voice from stereo music. Our experimental results show\nthat the proposed method can achieve multi-channel audio source separation\nwithout the need for hand-crafted features or any pre- or post-processing.", "published": "2018-03-02T03:47:47Z", "version": 1}, {"aid": "1803.00830", "authors": ["Ruijia Xu", "Ziliang Chen", "Wangmeng Zuo", "Junjie Yan", "Liang Lin"], "title": "Deep Cocktail Network: Multi-source Unsupervised Domain Adaptation with Category Shift", "url": "http://arxiv.org/pdf/1803.00830v1", "summary": "Unsupervised domain adaptation (UDA) conventionally assumes labeled source\nsamples coming from a single underlying source distribution. Whereas in\npractical scenario, labeled data are typically collected from diverse sources.\nThe multiple sources are different not only from the target but also from each\nother, thus, domain adaptater should not be modeled in the same way. Moreover,\nthose sources may not completely share their categories, which further brings a\nnew transfer challenge called category shift. In this paper, we propose a deep\ncocktail network (DCTN) to battle the domain and category shifts among multiple\nsources. Motivated by the theoretical results in \\cite{mansour2009domain}, the\ntarget distribution can be represented as the weighted combination of source\ndistributions, and, the multi-source unsupervised domain adaptation via DCTN is\nthen performed as two alternating steps: i) It deploys multi-way adversarial\nlearning to minimize the discrepancy between the target and each of the\nmultiple source domains, which also obtains the source-specific perplexity\nscores to denote the possibilities that a target sample belongs to different\nsource domains. ii) The multi-source category classifiers are integrated with\nthe perplexity scores to classify target sample, and the pseudo-labeled target\nsamples together with source samples are utilized to update the multi-source\ncategory classifier and the feature extractor. We evaluate DCTN in three domain\nadaptation benchmarks, which clearly demonstrate the superiority of our\nframework.", "published": "2018-03-02T12:58:51Z", "version": 1}, {"aid": "1803.01164", "authors": ["Md Zahangir Alom", "Tarek M. Taha", "Christopher Yakopcic", "Stefan Westberg", "Paheding Sidike", "Mst Shamima Nasrin", "Brian C Van Esesn", "Abdul A S. Awwal", "Vijayan K. Asari"], "title": "The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches", "url": "http://arxiv.org/pdf/1803.01164v2", "summary": "Deep learning has demonstrated tremendous success in variety of application\ndomains in the past few years. This new field of machine learning has been\ngrowing rapidly and applied in most of the application domains with some new\nmodalities of applications, which helps to open new opportunity. There are\ndifferent methods have been proposed on different category of learning\napproaches, which includes supervised, semi-supervised and un-supervised\nlearning. The experimental results show state-of-the-art performance of deep\nlearning over traditional machine learning approaches in the field of Image\nProcessing, Computer Vision, Speech Recognition, Machine Translation, Art,\nMedical imaging, Medical information processing, Robotics and control,\nBio-informatics, Natural Language Processing (NLP), Cyber security, and many\nmore. This report presents a brief survey on development of DL approaches,\nincluding Deep Neural Network (DNN), Convolutional Neural Network (CNN),\nRecurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and\nGated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN),\nGenerative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In\naddition, we have included recent development of proposed advanced variant DL\ntechniques based on the mentioned DL approaches. Furthermore, DL approaches\nhave explored and evaluated in different application domains are also included\nin this survey. We have also comprised recently developed frameworks, SDKs, and\nbenchmark datasets that are used for implementing and evaluating deep learning\napproaches. There are some surveys have published on Deep Learning in Neural\nNetworks [1, 38] and a survey on RL [234]. However, those papers have not\ndiscussed the individual advanced techniques for training large scale deep\nlearning models and the recently developed method of generative models [1].", "published": "2018-03-03T13:46:40Z", "version": 2}, {"aid": "1803.01216", "authors": ["Matthias Rottmann", "Karsten Kahl", "Hanno Gottschalk"], "title": "Deep Bayesian Active Semi-Supervised Learning", "url": "http://arxiv.org/pdf/1803.01216v1", "summary": "In many applications the process of generating label information is expensive\nand time consuming. We present a new method that combines active and\nsemi-supervised deep learning to achieve high generalization performance from a\ndeep convolutional neural network with as few known labels as possible. In a\nsetting where a small amount of labeled data as well as a large amount of\nunlabeled data is available, our method first learns the labeled data set. This\ninitialization is followed by an expectation maximization algorithm, where\nfurther training reduces classification entropy on the unlabeled data by\ntargeting a low entropy fit which is consistent with the labeled data. In\naddition the algorithm asks at a specified frequency an oracle for labels of\ndata with entropy above a certain entropy quantile. Using this active learning\ncomponent we obtain an agile labeling process that achieves high accuracy, but\nrequires only a small amount of known labels. For the MNIST dataset we report\nan error rate of 2.06% using only 300 labels and 1.06% for 1000 labels. These\nresults are obtained without employing any special network architecture or data\naugmentation.", "published": "2018-03-03T19:13:40Z", "version": 1}, {"aid": "1803.01364", "authors": ["Arief Koesdwiady", "Fakhri Karray"], "title": "SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary Time Series Prediction", "url": "http://arxiv.org/pdf/1803.01364v2", "summary": "This paper presents a practical approach for detecting non-stationarity in\ntime series prediction. This method is called SAFE and works by monitoring the\nevolution of the spectral contents of time series through a distance function.\nThis method is designed to work in combination with state-of-the-art machine\nlearning methods in real time by informing the online predictors to perform\nnecessary adaptation when a non-stationarity presents. We also propose an\nalgorithm to proportionally include some past data in the adaption process to\novercome the Catastrophic Forgetting problem. To validate our hypothesis and\ntest the effectiveness of our approach, we present comprehensive experiments in\ndifferent elements of the approach involving artificial and real-world\ndatasets. The experiments show that the proposed method is able to\nsignificantly save computational resources in term of processor or GPU cycles\nwhile maintaining high prediction performances.", "published": "2018-03-04T14:55:33Z", "version": 2}, {"aid": "1803.01417", "authors": ["Yuhua Chen", "Feng Shi", "Anthony G. Christodoulou", "Zhengwei Zhou", "Yibin Xie", "Debiao Li"], "title": "Efficient and Accurate MRI Super-Resolution using a Generative Adversarial Network and 3D Multi-Level Densely Connected Network", "url": "http://arxiv.org/pdf/1803.01417v3", "summary": "High-resolution (HR) magnetic resonance images (MRI) provide detailed\nanatomical information important for clinical application and quantitative\nimage analysis. However, HR MRI conventionally comes at the cost of longer scan\ntime, smaller spatial coverage, and lower signal-to-noise ratio (SNR). Recent\nstudies have shown that single image super-resolution (SISR), a technique to\nrecover HR details from one single low-resolution (LR) input image, could\nprovide high-quality image details with the help of advanced deep convolutional\nneural networks (CNN). However, deep neural networks consume memory heavily and\nrun slowly, especially in 3D settings. In this paper, we propose a novel 3D\nneural network design, namely a multi-level densely connected super-resolution\nnetwork (mDCSRN) with generative adversarial network (GAN)-guided training. The\nmDCSRN quickly trains and inferences and the GAN promotes realistic output\nhardly distinguishable from original HR images. Our results from experiments on\na dataset with 1,113 subjects show that our new architecture beats other\npopular deep learning methods in recovering 4x resolution-downgraded im-ages\nand runs 6x faster.", "published": "2018-03-04T20:45:06Z", "version": 3}, {"aid": "1803.01449", "authors": ["Sohil Atul Shah", "Vladlen Koltun"], "title": "Deep Continuous Clustering", "url": "http://arxiv.org/pdf/1803.01449v1", "summary": "Clustering high-dimensional datasets is hard because interpoint distances\nbecome less informative in high-dimensional spaces. We present a clustering\nalgorithm that performs nonlinear dimensionality reduction and clustering\njointly. The data is embedded into a lower-dimensional space by a deep\nautoencoder. The autoencoder is optimized as part of the clustering process.\nThe resulting network produces clustered data. The presented approach does not\nrely on prior knowledge of the number of ground-truth clusters. Joint nonlinear\ndimensionality reduction and clustering are formulated as optimization of a\nglobal continuous objective. We thus avoid discrete reconfigurations of the\nobjective that characterize prior clustering algorithms. Experiments on\ndatasets from multiple domains demonstrate that the presented algorithm\noutperforms state-of-the-art clustering schemes, including recent methods that\nuse deep networks.", "published": "2018-03-05T01:15:38Z", "version": 1}, {"aid": "1803.01489", "authors": ["Ahmed Hefny", "Zita Marinho", "Wen Sun", "Siddhartha Srinivasa", "Geoffrey Gordon"], "title": "Recurrent Predictive State Policy Networks", "url": "http://arxiv.org/pdf/1803.01489v1", "summary": "We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent\narchitecture that brings insights from predictive state representations to\nreinforcement learning in partially observable environments. Predictive state\npolicy networks consist of a recursive filter, which keeps track of a belief\nabout the state of the environment, and a reactive policy that directly maps\nbeliefs to actions, to maximize the cumulative reward. The recursive filter\nleverages predictive state representations (PSRs) (Rosencrantz and Gordon,\n2004; Sun et al., 2016) by modeling predictive state-- a prediction of the\ndistribution of future observations conditioned on history and future actions.\nThis representation gives rise to a rich class of statistically consistent\nalgorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive\nstate serves as an equivalent representation of a belief state. Therefore, the\npolicy component of the RPSP-network can be purely reactive, simplifying\ntraining while still allowing optimal behaviour. Moreover, we use the PSR\ninterpretation during training as well, by incorporating prediction error in\nthe loss function. The entire network (recursive filter and reactive policy) is\nstill differentiable and can be trained using gradient based methods. We\noptimize our policy using a combination of policy gradient based on rewards\n(Williams, 1992) and gradient descent based on prediction error. We show the\nefficacy of RPSP-networks under partial observability on a set of robotic\ncontrol tasks from OpenAI Gym. We empirically show that RPSP-networks perform\nwell compared with memory-preserving networks such as GRUs, as well as finite\nmemory models, being the overall best performing method.", "published": "2018-03-05T03:59:48Z", "version": 1}, {"aid": "1803.01719", "authors": ["Boris Hanin", "David Rolnick"], "title": "How to Start Training: The Effect of Initialization and Architecture", "url": "http://arxiv.org/pdf/1803.01719v3", "summary": "We identify and study two common failure modes for early training in deep\nReLU nets. For each we give a rigorous proof of when it occurs and how to avoid\nit, for fully connected and residual architectures. The first failure mode,\nexploding/vanishing mean activation length, can be avoided by initializing\nweights from a symmetric distribution with variance 2/fan-in and, for ResNets,\nby correctly weighting the residual modules. We prove that the second failure\nmode, exponentially large variance of activation length, never occurs in\nresidual nets once the first failure mode is avoided. In contrast, for fully\nconnected nets, we prove that this failure mode can happen and is avoided by\nkeeping constant the sum of the reciprocals of layer widths. We demonstrate\nempirically the effectiveness of our theoretical results in predicting when\nnetworks are able to start training. In particular, we note that many popular\ninitializations fail our criteria, whereas correct initialization and\narchitecture allows much deeper networks to be trained.", "published": "2018-03-05T15:17:50Z", "version": 3}, {"aid": "1803.01837", "authors": ["Chen-Hsuan Lin", "Ersin Yumer", "Oliver Wang", "Eli Shechtman", "Simon Lucey"], "title": "ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing", "url": "http://arxiv.org/pdf/1803.01837v1", "summary": "We address the problem of finding realistic geometric corrections to a\nforeground object such that it appears natural when composited into a\nbackground image. To achieve this, we propose a novel Generative Adversarial\nNetwork (GAN) architecture that utilizes Spatial Transformer Networks (STNs) as\nthe generator, which we call Spatial Transformer GANs (ST-GANs). ST-GANs seek\nimage realism by operating in the geometric warp parameter space. In\nparticular, we exploit an iterative STN warping scheme and propose a sequential\ntraining strategy that achieves better results compared to naive training of a\nsingle generator. One of the key advantages of ST-GAN is its applicability to\nhigh-resolution images indirectly since the predicted warp parameters are\ntransferable between reference frames. We demonstrate our approach in two\napplications: (1) visualizing how indoor furniture (e.g. from product images)\nmight be perceived in a room, (2) hallucinating how accessories like glasses\nwould look when matched with real portraits.", "published": "2018-03-05T18:59:01Z", "version": 1}, {"aid": "1803.02129", "authors": ["Felix Altenberger", "Claus Lenz"], "title": "A Non-Technical Survey on Deep Convolutional Neural Network Architectures", "url": "http://arxiv.org/pdf/1803.02129v1", "summary": "Artificial neural networks have recently shown great results in many\ndisciplines and a variety of applications, including natural language\nunderstanding, speech processing, games and image data generation. One\nparticular application in which the strong performance of artificial neural\nnetworks was demonstrated is the recognition of objects in images, where deep\nconvolutional neural networks are commonly applied. In this survey, we give a\ncomprehensive introduction to this topic (object recognition with deep\nconvolutional neural networks), with a strong focus on the evolution of network\narchitectures. Therefore, we aim to compress the most important concepts in\nthis field in a simple and non-technical manner to allow for future researchers\nto have a quick general understanding.\n  This work is structured as follows:\n  1. We will explain the basic ideas of (convolutional) neural networks and\ndeep learning and examine their usage for three object recognition tasks: image\nclassification, object localization and object detection.\n  2. We give a review on the evolution of deep convolutional neural networks by\nproviding an extensive overview of the most important network architectures\npresented in chronological order of their appearances.", "published": "2018-03-06T11:40:46Z", "version": 1}, {"aid": "1803.02579", "authors": ["Abhijit Guha Roy", "Nassir Navab", "Christian Wachinger"], "title": "Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks", "url": "http://arxiv.org/pdf/1803.02579v2", "summary": "Fully convolutional neural networks (F-CNNs) have set the state-of-the-art in\nimage segmentation for a plethora of applications. Architectural innovations\nwithin F-CNNs have mainly focused on improving spatial encoding or network\nconnectivity to aid gradient flow. In this paper, we explore an alternate\ndirection of recalibrating the feature maps adaptively, to boost meaningful\nfeatures, while suppressing weak ones. We draw inspiration from the recently\nproposed squeeze & excitation (SE) module for channel recalibration of feature\nmaps for image classification. Towards this end, we introduce three variants of\nSE modules for image segmentation, (i) squeezing spatially and exciting\nchannel-wise (cSE), (ii) squeezing channel-wise and exciting spatially (sSE)\nand (iii) concurrent spatial and channel squeeze & excitation (scSE). We\neffectively incorporate these SE modules within three different\nstate-of-the-art F-CNNs (DenseNet, SD-Net, U-Net) and observe consistent\nimprovement of performance across all architectures, while minimally effecting\nmodel complexity. Evaluations are performed on two challenging applications:\nwhole brain segmentation on MRI scans (Multi-Atlas Labelling Challenge Dataset)\nand organ segmentation on whole body contrast enhanced CT scans (Visceral\nDataset).", "published": "2018-03-07T10:22:06Z", "version": 2}, {"aid": "1803.02735", "authors": ["Muhammad Haris", "Greg Shakhnarovich", "Norimichi Ukita"], "title": "Deep Back-Projection Networks For Super-Resolution", "url": "http://arxiv.org/pdf/1803.02735v1", "summary": "The feed-forward architectures of recently proposed deep super-resolution\nnetworks learn representations of low-resolution inputs, and the non-linear\nmapping from those to high-resolution output. However, this approach does not\nfully address the mutual dependencies of low- and high-resolution images. We\npropose Deep Back-Projection Networks (DBPN), that exploit iterative up- and\ndown-sampling layers, providing an error feedback mechanism for projection\nerrors at each stage. We construct mutually-connected up- and down-sampling\nstages each of which represents different types of image degradation and\nhigh-resolution components. We show that extending this idea to allow\nconcatenation of features across up- and down-sampling stages (Dense DBPN)\nallows us to reconstruct further improve super-resolution, yielding superior\nresults and in particular establishing new state of the art results for large\nscaling factors such as 8x across multiple data sets.", "published": "2018-03-07T16:05:35Z", "version": 1}, {"aid": "1803.02742", "authors": ["Qiuyu Zhu", "Ruixin Zhang"], "title": "HENet:A Highly Efficient Convolutional Neural Networks Optimized for Accuracy, Speed and Storage", "url": "http://arxiv.org/pdf/1803.02742v2", "summary": "In order to enhance the real-time performance of convolutional neural\nnetworks(CNNs), more and more researchers are focusing on improving the\nefficiency of CNN. Based on the analysis of some CNN architectures, such as\nResNet, DenseNet, ShuffleNet and so on, we combined their advantages and\nproposed a very efficient model called Highly Efficient Networks(HENet). The\nnew architecture uses an unusual way to combine group convolution and channel\nshuffle which was mentioned in ShuffleNet. Inspired by ResNet and DenseNet, we\nalso proposed a new way to use element-wise addition and concatenation\nconnection with each block. In order to make greater use of feature maps,\npooling operations are removed from HENet. The experiments show that our\nmodel's efficiency is more than 1 times higher than ShuffleNet on many open\nsource datasets, such as CIFAR-10/100 and SVHN.", "published": "2018-03-07T16:18:51Z", "version": 2}, {"aid": "1803.02811", "authors": ["Adam Stooke", "Pieter Abbeel"], "title": "Accelerated Methods for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1803.02811v2", "summary": "Deep reinforcement learning (RL) has achieved many recent successes, yet\nexperiment turn-around time remains a key bottleneck in research and in\npractice. We investigate how to optimize existing deep RL algorithms for modern\ncomputers, specifically for a combination of CPUs and GPUs. We confirm that\nboth policy gradient and Q-value learning algorithms can be adapted to learn\nusing many parallel simulator instances. We further find it possible to train\nusing batch sizes considerably larger than are standard, without negatively\naffecting sample complexity or final performance. We leverage these facts to\nbuild a unified framework for parallelization that dramatically hastens\nexperiments in both classes of algorithm. All neural network computations use\nGPUs, accelerating both data collection and training. Our results include using\nan entire DGX-1 to learn successful strategies in Atari games in mere minutes,\nusing both synchronous and asynchronous algorithms.", "published": "2018-03-07T18:39:12Z", "version": 2}, {"aid": "1803.02865", "authors": ["Xiaoxia Wu", "Rachel Ward", "L\u00e9on Bottou"], "title": "WNGrad: Learn the Learning Rate in Gradient Descent", "url": "http://arxiv.org/pdf/1803.02865v2", "summary": "Adjusting the learning rate schedule in stochastic gradient methods is an\nimportant unresolved problem which requires tuning in practice. If certain\nparameters of the loss function such as smoothness or strong convexity\nconstants are known, theoretical learning rate schedules can be applied.\nHowever, in practice, such parameters are not known, and the loss function of\ninterest is not convex in any case. The recently proposed batch normalization\nreparametrization is widely adopted in most neural network architectures today\nbecause, among other advantages, it is robust to the choice of Lipschitz\nconstant of the gradient in loss function, allowing one to set a large learning\nrate without worry. Inspired by batch normalization, we propose a general\nnonlinear update rule for the learning rate in batch and stochastic gradient\ndescent so that the learning rate can be initialized at a high value, and is\nsubsequently decreased according to gradient observations along the way. The\nproposed method is shown to achieve robustness to the relationship between the\nlearning rate and the Lipschitz constant, and near-optimal convergence rates in\nboth the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch\nsetting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We\nalso show through numerical evidence that such robustness of the proposed\nmethod extends to highly nonconvex and possibly non-smooth loss function in\ndeep learning problems.Our analysis establishes some first theoretical\nunderstanding into the observed robustness for batch normalization and weight\nnormalization.", "published": "2018-03-07T20:30:35Z", "version": 2}, {"aid": "1803.03816", "authors": ["Mostafa Gamal", "Mennatullah Siam", "Moemen Abdel-Razek"], "title": "ShuffleSeg: Real-time Semantic Segmentation Network", "url": "http://arxiv.org/pdf/1803.03816v2", "summary": "Real-time semantic segmentation is of significant importance for mobile and\nrobotics related applications. We propose a computationally efficient\nsegmentation network which we term as ShuffleSeg. The proposed architecture is\nbased on grouped convolution and channel shuffling in its encoder for improving\nthe performance. An ablation study of different decoding methods is compared\nincluding Skip architecture, UNet, and Dilation Frontend. Interesting insights\non the speed and accuracy tradeoff is discussed. It is shown that skip\narchitecture in the decoding method provides the best compromise for the goal\nof real-time performance, while it provides adequate accuracy by utilizing\nhigher resolution feature maps for a more accurate segmentation. ShuffleSeg is\nevaluated on CityScapes and compared against the state of the art real-time\nsegmentation networks. It achieves 2x GFLOPs reduction, while it provides on\npar mean intersection over union of 58.3% on CityScapes test set. ShuffleSeg\nruns at 15.7 frames per second on NVIDIA Jetson TX2, which makes it of great\npotential for real-time applications.", "published": "2018-03-10T14:28:45Z", "version": 2}, {"aid": "1803.04792", "authors": ["Youcheng Sun", "Xiaowei Huang", "Daniel Kroening", "James Sharp", "Matthew Hill", "Rob Ashmore"], "title": "Testing Deep Neural Networks", "url": "http://arxiv.org/pdf/1803.04792v4", "summary": "Deep neural networks (DNNs) have a wide range of applications, and software\nemploying them must be thoroughly tested, especially in safety-critical\ndomains. However, traditional software test coverage metrics cannot be applied\ndirectly to DNNs. In this paper, inspired by the MC/DC coverage criterion, we\npropose a family of four novel test criteria that are tailored to structural\nfeatures of DNNs and their semantics. We validate the criteria by demonstrating\nthat the generated test inputs guided via our proposed coverage criteria are\nable to capture undesired behaviours in a DNN. Test cases are generated using a\nsymbolic approach and a gradient-based heuristic search. By comparing them with\nexisting methods, we show that our criteria achieve a balance between their\nability to find bugs (proxied using adversarial examples) and the computational\ncost of test case generation. Our experiments are conducted on state-of-the-art\nDNNs obtained using popular open source datasets, including MNIST, CIFAR-10 and\nImageNet.", "published": "2018-03-10T23:19:13Z", "version": 4}, {"aid": "1803.04848", "authors": ["Esther Derman", "Daniel J. Mankowitz", "Timothy A. Mann", "Shie Mannor"], "title": "Soft-Robust Actor-Critic Policy-Gradient", "url": "http://arxiv.org/pdf/1803.04848v2", "summary": "Robust Reinforcement Learning aims to derive optimal behavior that accounts\nfor model uncertainty in dynamical systems. However, previous studies have\nshown that by considering the worst case scenario, robust policies can be\noverly conservative. Our soft-robust framework is an attempt to overcome this\nissue. In this paper, we present a novel Soft-Robust Actor-Critic algorithm\n(SR-AC). It learns an optimal policy with respect to a distribution over an\nuncertainty set and stays robust to model uncertainty but avoids the\nconservativeness of robust strategies. We show the convergence of SR-AC and\ntest the efficiency of our approach on different domains by comparing it\nagainst regular learning methods and their robust formulations.", "published": "2018-03-11T09:43:20Z", "version": 2}, {"aid": "1803.04249", "authors": ["Jiaxin Li", "Ben M. Chen", "Gim Hee Lee"], "title": "SO-Net: Self-Organizing Network for Point Cloud Analysis", "url": "http://arxiv.org/pdf/1803.04249v4", "summary": "This paper presents SO-Net, a permutation invariant architecture for deep\nlearning with orderless point clouds. The SO-Net models the spatial\ndistribution of point cloud by building a Self-Organizing Map (SOM). Based on\nthe SOM, SO-Net performs hierarchical feature extraction on individual points\nand SOM nodes, and ultimately represents the input point cloud by a single\nfeature vector. The receptive field of the network can be systematically\nadjusted by conducting point-to-node k nearest neighbor search. In recognition\ntasks such as point cloud reconstruction, classification, object part\nsegmentation and shape retrieval, our proposed network demonstrates performance\nthat is similar with or better than state-of-the-art approaches. In addition,\nthe training speed is significantly faster than existing point cloud\nrecognition networks because of the parallelizability and simplicity of the\nproposed architecture. Our code is available at the project website.\nhttps://github.com/lijx10/SO-Net", "published": "2018-03-12T13:49:14Z", "version": 4}, {"aid": "1803.04469", "authors": ["He Huang", "Philip S. Yu", "Changhu Wang"], "title": "An Introduction to Image Synthesis with Generative Adversarial Nets", "url": "http://arxiv.org/pdf/1803.04469v2", "summary": "There has been a drastic growth of research in Generative Adversarial Nets\n(GANs) in the past few years. Proposed in 2014, GAN has been applied to various\napplications such as computer vision and natural language processing, and\nachieves impressive performance. Among the many applications of GAN, image\nsynthesis is the most well-studied one, and research in this area has already\ndemonstrated the great potential of using GAN in image synthesis. In this\npaper, we provide a taxonomy of methods used in image synthesis, review\ndifferent models for text-to-image synthesis and image-to-image translation,\nand discuss some evaluation metrics as well as possible future research\ndirections in image synthesis with GAN.", "published": "2018-03-12T19:14:35Z", "version": 2}, {"aid": "1803.04488", "authors": ["Faisal Alshargi", "Saeedeh Shekarpour", "Tommaso Soru", "Amit Sheth"], "title": "Concept2vec: Metrics for Evaluating Quality of Embeddings for Ontological Concepts", "url": "http://arxiv.org/pdf/1803.04488v3", "summary": "Although there is an emerging trend towards generating embeddings for\nprimarily unstructured data and, recently, for structured data, no systematic\nsuite for measuring the quality of embeddings has been proposed yet. This\ndeficiency is further sensed with respect to embeddings generated for\nstructured data because there are no concrete evaluation metrics measuring the\nquality of the encoded structure as well as semantic patterns in the embedding\nspace. In this paper, we introduce a framework containing three distinct tasks\nconcerned with the individual aspects of ontological concepts: (i) the\ncategorization aspect, (ii) the hierarchical aspect, and (iii) the relational\naspect. Then, in the scope of each task, a number of intrinsic metrics are\nproposed for evaluating the quality of the embeddings. Furthermore, w.r.t. this\nframework, multiple experimental studies were run to compare the quality of the\navailable embedding models. Employing this framework in future research can\nreduce misjudgment and provide greater insight about quality comparisons of\nembeddings for ontological concepts. We positioned our sampled data and code at\nhttps://github.com/alshargi/Concept2vec under GNU General Public License v3.0.", "published": "2018-03-12T19:46:10Z", "version": 3}, {"aid": "1803.04585", "authors": ["David Manheim", "Scott Garrabrant"], "title": "Categorizing Variants of Goodhart's Law", "url": "http://arxiv.org/pdf/1803.04585v4", "summary": "There are several distinct failure modes for overoptimization of systems on\nthe basis of metrics. This occurs when a metric which can be used to improve a\nsystem is used to an extent that further optimization is ineffective or\nharmful, and is sometimes termed Goodhart's Law. This class of failure is often\npoorly understood, partly because terminology for discussing them is ambiguous,\nand partly because discussion using this ambiguous terminology ignores\ndistinctions between different failure modes of this general type. This paper\nexpands on an earlier discussion by Garrabrant, which notes there are \"(at\nleast) four different mechanisms\" that relate to Goodhart's Law. This paper is\nintended to explore these mechanisms further, and specify more clearly how they\noccur. This discussion should be helpful in better understanding these types of\nfailures in economic regulation, in public policy, in machine learning, and in\nArtificial Intelligence alignment. The importance of Goodhart effects depends\non the amount of power directed towards optimizing the proxy, and so the\nincreased optimization power offered by artificial intelligence makes it\nespecially critical for that field.", "published": "2018-03-13T01:15:39Z", "version": 4}, {"aid": "1803.04626", "authors": ["Roey Mechrez", "Itamar Talmi", "Firas Shama", "Lihi Zelnik-Manor"], "title": "Maintaining Natural Image Statistics with the Contextual Loss", "url": "http://arxiv.org/pdf/1803.04626v3", "summary": "Maintaining natural image statistics is a crucial factor in restoration and\ngeneration of realistic looking images. When training CNNs, photorealism is\nusually attempted by adversarial training (GAN), that pushes the output images\nto lie on the manifold of natural images. GANs are very powerful, but not\nperfect. They are hard to train and the results still often suffer from\nartifacts. In this paper we propose a complementary approach, that could be\napplied with or without GAN, whose goal is to train a feed-forward CNN to\nmaintain natural internal statistics. We look explicitly at the distribution of\nfeatures in an image and train the network to generate images with natural\nfeature distributions. Our approach reduces by orders of magnitude the number\nof images required for training and achieves state-of-the-art results on both\nsingle-image super-resolution, and high-resolution surface normal estimation.", "published": "2018-03-13T05:19:26Z", "version": 3}, {"aid": "1803.04831", "authors": ["Shuai Li", "Wanqing Li", "Chris Cook", "Ce Zhu", "Yanbo Gao"], "title": "Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN", "url": "http://arxiv.org/pdf/1803.04831v3", "summary": "Recurrent neural networks (RNNs) have been widely used for processing\nsequential data. However, RNNs are commonly difficult to train due to the\nwell-known gradient vanishing and exploding problems and hard to learn\nlong-term patterns. Long short-term memory (LSTM) and gated recurrent unit\n(GRU) were developed to address these problems, but the use of hyperbolic\ntangent and the sigmoid action functions results in gradient decay over layers.\nConsequently, construction of an efficiently trainable deep network is\nchallenging. In addition, all the neurons in an RNN layer are entangled\ntogether and their behaviour is hard to interpret. To address these problems, a\nnew type of RNN, referred to as independently recurrent neural network\n(IndRNN), is proposed in this paper, where neurons in the same layer are\nindependent of each other and they are connected across layers. We have shown\nthat an IndRNN can be easily regulated to prevent the gradient exploding and\nvanishing problems while allowing the network to learn long-term dependencies.\nMoreover, an IndRNN can work with non-saturated activation functions such as\nrelu (rectified linear unit) and be still trained robustly. Multiple IndRNNs\ncan be stacked to construct a network that is deeper than the existing RNNs.\nExperimental results have shown that the proposed IndRNN is able to process\nvery long sequences (over 5000 time steps), can be used to construct very deep\nnetworks (21 layers used in the experiment) and still be trained robustly.\nBetter performances have been achieved on various tasks by using IndRNNs\ncompared with the traditional RNN and LSTM. The code is available at\nhttps://github.com/Sunnydreamrain/IndRNN_Theano_Lasagne.", "published": "2018-03-13T14:27:42Z", "version": 3}, {"aid": "1803.04988", "authors": ["Kai Xu", "Dawei Li", "Nick Cassimatis", "Xiaolong Wang"], "title": "LCANet: End-to-End Lipreading with Cascaded Attention-CTC", "url": "http://arxiv.org/pdf/1803.04988v1", "summary": "Machine lipreading is a special type of automatic speech recognition (ASR)\nwhich transcribes human speech by visually interpreting the movement of related\nface regions including lips, face, and tongue. Recently, deep neural network\nbased lipreading methods show great potential and have exceeded the accuracy of\nexperienced human lipreaders in some benchmark datasets. However, lipreading is\nstill far from being solved, and existing methods tend to have high error rates\non the wild data. In this paper, we propose LCANet, an end-to-end deep neural\nnetwork based lipreading system. LCANet encodes input video frames using a\nstacked 3D convolutional neural network (CNN), highway network and\nbidirectional GRU network. The encoder effectively captures both short-term and\nlong-term spatio-temporal information. More importantly, LCANet incorporates a\ncascaded attention-CTC decoder to generate output texts. By cascading CTC with\nattention, it partially eliminates the defect of the conditional independence\nassumption of CTC within the hidden neural layers, and this yields notably\nperformance improvement as well as faster convergence. The experimental results\nshow the proposed system achieves a 1.3% CER and 3.0% WER on the GRID corpus\ndatabase, leading to a 12.3% improvement compared to the state-of-the-art\nmethods.", "published": "2018-03-13T18:04:10Z", "version": 1}, {"aid": "1803.05026", "authors": ["Wenqi Wang", "Vaneet Aggarwal", "Shuchin Aeron"], "title": "Principal Component Analysis with Tensor Train Subspace", "url": "http://arxiv.org/pdf/1803.05026v1", "summary": "Tensor train is a hierarchical tensor network structure that helps alleviate\nthe curse of dimensionality by parameterizing large-scale multidimensional data\nvia a set of network of low-rank tensors. Associated with such a construction\nis a notion of Tensor Train subspace and in this paper we propose a TT-PCA\nalgorithm for estimating this structured subspace from the given data. By\nmaintaining low rank tensor structure, TT-PCA is more robust to noise comparing\nwith PCA or Tucker-PCA. This is borne out numerically by testing the proposed\napproach on the Extended YaleFace Dataset B.", "published": "2018-03-13T19:58:46Z", "version": 1}, {"aid": "1803.05049", "authors": ["Sergio Hernandez Cerezo", "Guillem Duran Ballester"], "title": "Fractal AI: A fragile theory of intelligence", "url": "http://arxiv.org/pdf/1803.05049v5", "summary": "Fractal AI is a theory for general artificial intelligence. It allows\nderiving new mathematical tools that constitute the foundations for a new kind\nof stochastic calculus, by modelling information using cellular automaton-like\nstructures instead of smooth functions. In the repository included we are\npresenting a new Agent, derived from the first principles of the theory, which\nis capable of solving Atari games several orders of magnitude more efficiently\nthan other similar techniques, like Monte Carlo Tree Search. The code provided\nshows how it is now possible to beat some of the current State of The Art\nbenchmarks on Atari games, without previous learning and using less than 1000\nsamples to calculate each one of the actions when standard MCTS uses 3 Million\nsamples. Among other things, Fractal AI makes it possible to generate a huge\ndatabase of top performing examples with a very little amount of computation\nrequired, transforming Reinforcement Learning into a supervised problem. The\nalgorithm presented is capable of solving the exploration vs exploitation\ndilemma on both the discrete and continuous cases, while maintaining control\nover any aspect of the behaviour of the Agent. From a general approach, new\ntechniques presented here have direct applications to other areas such as\nNon-equilibrium thermodynamics, chemistry, quantum physics, economics,\ninformation theory, and non-linear control theory.", "published": "2018-03-13T21:17:26Z", "version": 5}, {"aid": "1803.05788", "authors": ["Zihao Liu", "Tao Liu", "Wujie Wen", "Lei Jiang", "Jie Xu", "Yanzhi Wang", "Gang Quan"], "title": "DeepN-JPEG: A Deep Neural Network Favorable JPEG-based Image Compression Framework", "url": "http://arxiv.org/pdf/1803.05788v1", "summary": "As one of most fascinating machine learning techniques, deep neural network\n(DNN) has demonstrated excellent performance in various intelligent tasks such\nas image classification. DNN achieves such performance, to a large extent, by\nperforming expensive training over huge volumes of training data. To reduce the\ndata storage and transfer overhead in smart resource-limited Internet-of-Thing\n(IoT) systems, effective data compression is a \"must-have\" feature before\ntransferring real-time produced dataset for training or classification. While\nthere have been many well-known image compression approaches (such as JPEG), we\nfor the first time find that a human-visual based image compression approach\nsuch as JPEG compression is not an optimized solution for DNN systems,\nespecially with high compression ratios. To this end, we develop an image\ncompression framework tailored for DNN applications, named \"DeepN-JPEG\", to\nembrace the nature of deep cascaded information process mechanism of DNN\narchitecture. Extensive experiments, based on \"ImageNet\" dataset with various\nstate-of-the-art DNNs, show that \"DeepN-JPEG\" can achieve ~3.5x higher\ncompression rate over the popular JPEG solution while maintaining the same\naccuracy level for image recognition, demonstrating its great potential of\nstorage and power efficiency in DNN-based smart IoT system design.", "published": "2018-03-14T02:18:55Z", "version": 1}, {"aid": "1803.05215", "authors": ["Filippos Kokkinos", "Stamatios Lefkimmiatis"], "title": "Deep Image Demosaicking using a Cascade of Convolutional Residual Denoising Networks", "url": "http://arxiv.org/pdf/1803.05215v4", "summary": "Demosaicking and denoising are among the most crucial steps of modern digital\ncamera pipelines and their joint treatment is a highly ill-posed inverse\nproblem where at-least two-thirds of the information are missing and the rest\nare corrupted by noise. This poses a great challenge in obtaining meaningful\nreconstructions and a special care for the efficient treatment of the problem\nis required. While there are several machine learning approaches that have been\nrecently introduced to deal with joint image demosaicking-denoising, in this\nwork we propose a novel deep learning architecture which is inspired by\npowerful classical image regularization methods and large-scale convex\noptimization techniques. Consequently, our derived network is more transparent\nand has a clear interpretation compared to alternative competitive deep\nlearning approaches. Our extensive experiments demonstrate that our network\noutperforms any previous approaches on both noisy and noise-free data. This\nimprovement in reconstruction quality is attributed to the principled way we\ndesign our network architecture, which also requires fewer trainable parameters\nthan the current state-of-the-art deep network solution. Finally, we show that\nour network has the ability to generalize well even when it is trained on small\ndatasets, while keeping the overall number of trainable parameters low.", "published": "2018-03-14T11:44:08Z", "version": 4}, {"aid": "1803.05407", "authors": ["Pavel Izmailov", "Dmitrii Podoprikhin", "Timur Garipov", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": "Averaging Weights Leads to Wider Optima and Better Generalization", "url": "http://arxiv.org/pdf/1803.05407v3", "summary": "Deep neural networks are typically trained by optimizing a loss function with\nan SGD variant, in conjunction with a decaying learning rate, until\nconvergence. We show that simple averaging of multiple points along the\ntrajectory of SGD, with a cyclical or constant learning rate, leads to better\ngeneralization than conventional training. We also show that this Stochastic\nWeight Averaging (SWA) procedure finds much flatter solutions than SGD, and\napproximates the recent Fast Geometric Ensembling (FGE) approach with a single\nmodel. Using SWA we achieve notable improvement in test accuracy over\nconventional SGD training on a range of state-of-the-art residual networks,\nPyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and\nImageNet. In short, SWA is extremely easy to implement, improves\ngeneralization, and has almost no computational overhead.", "published": "2018-03-14T17:09:27Z", "version": 3}, {"aid": "1803.05536", "authors": ["Zhen-Hua Feng", "Patrik Huber", "Josef Kittler", "Peter JB Hancock", "Xiao-Jun Wu", "Qijun Zhao", "Paul Koppen", "Matthias R\u00e4tsch"], "title": "Evaluation of Dense 3D Reconstruction from 2D Face Images in the Wild", "url": "http://arxiv.org/pdf/1803.05536v2", "summary": "This paper investigates the evaluation of dense 3D face reconstruction from a\nsingle 2D image in the wild. To this end, we organise a competition that\nprovides a new benchmark dataset that contains 2000 2D facial images of 135\nsubjects as well as their 3D ground truth face scans. In contrast to previous\ncompetitions or challenges, the aim of this new benchmark dataset is to\nevaluate the accuracy of a 3D dense face reconstruction algorithm using real,\naccurate and high-resolution 3D ground truth face scans. In addition to the\ndataset, we provide a standard protocol as well as a Python script for the\nevaluation. Last, we report the results obtained by three state-of-the-art 3D\nface reconstruction systems on the new benchmark dataset. The competition is\norganised along with the 2018 13th IEEE Conference on Automatic Face & Gesture\nRecognition.", "published": "2018-03-14T23:12:12Z", "version": 2}, {"aid": "1803.05619", "authors": ["Huikai Wu", "Shuai Zheng", "Junge Zhang", "Kaiqi Huang"], "title": "Fast End-to-End Trainable Guided Filter", "url": "http://arxiv.org/pdf/1803.05619v2", "summary": "Dense pixel-wise image prediction has been advanced by harnessing the\ncapabilities of Fully Convolutional Networks (FCNs). One central issue of FCNs\nis the limited capacity to handle joint upsampling. To address the problem, we\npresent a novel building block for FCNs, namely guided filtering layer, which\nis designed for efficiently generating a high-resolution output given the\ncorresponding low-resolution one and a high-resolution guidance map. Such a\nlayer contains learnable parameters, which can be integrated with FCNs and\njointly optimized through end-to-end training. To further take advantage of\nend-to-end training, we plug in a trainable transformation function for\ngenerating the task-specific guidance map. Based on the proposed layer, we\npresent a general framework for pixel-wise image prediction, named deep guided\nfiltering network (DGF). The proposed network is evaluated on five image\nprocessing tasks. Experiments on MIT-Adobe FiveK Dataset demonstrate that DGF\nruns 10-100 times faster and achieves the state-of-the-art performance. We also\nshow that DGF helps to improve the performance of multiple computer vision\ntasks.", "published": "2018-03-15T07:31:24Z", "version": 2}, {"aid": "1803.05863", "authors": ["Alexander G. Ororbia", "Ankur Mali", "Jian Wu", "Scott O'Connell", "David Miller", "C. Lee Giles"], "title": "Learned Neural Iterative Decoding for Lossy Image Compression Systems", "url": "http://arxiv.org/pdf/1803.05863v3", "summary": "For lossy image compression systems, we develop an algorithm, iterative\nrefinement, to improve the decoder's reconstruction compared to standard\ndecoding techniques. Specifically, we propose a recurrent neural network\napproach for nonlinear, iterative decoding. Our decoder, which works with any\nencoder, employs self-connected memory units that make use of causal and\nnon-causal spatial context information to progressively reduce reconstruction\nerror over a fixed number of steps. We experiment with variants of our\nestimator and find that iterative refinement consistently creates lower\ndistortion images of higher perceptual quality compared to other approaches.\nSpecifically, on the Kodak Lossless True Color Image Suite, we observe as much\nas a 0.871 decibel (dB) gain over JPEG, a 1.095 dB gain over JPEG 2000, and a\n0.971 dB gain over a competitive neural model.", "published": "2018-03-15T16:58:45Z", "version": 3}, {"aid": "1803.06189", "authors": ["Xinwei He", "Yang Zhou", "Zhichao Zhou", "Song Bai", "Xiang Bai"], "title": "Triplet-Center Loss for Multi-View 3D Object Retrieval", "url": "http://arxiv.org/pdf/1803.06189v1", "summary": "Most existing 3D object recognition algorithms focus on leveraging the strong\ndiscriminative power of deep learning models with softmax loss for the\nclassification of 3D data, while learning discriminative features with deep\nmetric learning for 3D object retrieval is more or less neglected. In the\npaper, we study variants of deep metric learning losses for 3D object\nretrieval, which did not receive enough attention from this area. First , two\nkinds of representative losses, triplet loss and center loss, are introduced\nwhich could learn more discriminative features than traditional classification\nloss. Then, we propose a novel loss named triplet-center loss, which can\nfurther enhance the discriminative power of the features. The proposed\ntriplet-center loss learns a center for each class and requires that the\ndistances between samples and centers from the same class are closer than those\nfrom different classes. Extensive experimental results on two popular 3D object\nretrieval benchmarks and two widely-adopted sketch-based 3D shape retrieval\nbenchmarks consistently demonstrate the effectiveness of our proposed loss, and\nsignificant improvements have been achieved compared with the\nstate-of-the-arts.", "published": "2018-03-16T12:31:24Z", "version": 1}, {"aid": "1803.06199", "authors": ["Martin Simon", "Stefan Milz", "Karl Amende", "Horst-Michael Gross"], "title": "Complex-YOLO: Real-time 3D Object Detection on Point Clouds", "url": "http://arxiv.org/pdf/1803.06199v2", "summary": "Lidar based 3D object detection is inevitable for autonomous driving, because\nit directly links to environmental understanding and therefore builds the base\nfor prediction and motion planning. The capacity of inferencing highly sparse\n3D data in real-time is an ill-posed problem for lots of other application\nareas besides automated vehicles, e.g. augmented reality, personal robotics or\nindustrial automation. We introduce Complex-YOLO, a state of the art real-time\n3D object detection network on point clouds only. In this work, we describe a\nnetwork that expands YOLOv2, a fast 2D standard object detector for RGB images,\nby a specific complex regression strategy to estimate multi-class 3D boxes in\nCartesian space. Thus, we propose a specific Euler-Region-Proposal Network\n(E-RPN) to estimate the pose of the object by adding an imaginary and a real\nfraction to the regression network. This ends up in a closed complex space and\navoids singularities, which occur by single angle estimations. The E-RPN\nsupports to generalize well during training. Our experiments on the KITTI\nbenchmark suite show that we outperform current leading methods for 3D object\ndetection specifically in terms of efficiency. We achieve state of the art\nresults for cars, pedestrians and cyclists by being more than five times faster\nthan the fastest competitor. Further, our model is capable of estimating all\neight KITTI-classes, including Vans, Trucks or sitting pedestrians\nsimultaneously with high accuracy.", "published": "2018-03-16T12:54:40Z", "version": 2}, {"aid": "1803.06288", "authors": ["David J. Heeger", "Wayne E. Mackey"], "title": "ORGaNICs: A Theory of Working Memory in Brains and Machines", "url": "http://arxiv.org/pdf/1803.06288v4", "summary": "Working memory is a cognitive process that is responsible for temporarily\nholding and manipulating information. Most of the empirical neuroscience\nresearch on working memory has focused on measuring sustained activity in\nprefrontal cortex (PFC) and/or parietal cortex during simple delayed-response\ntasks, and most of the models of working memory have been based on neural\nintegrators. But working memory means much more than just holding a piece of\ninformation online. We describe a new theory of working memory, based on a\nrecurrent neural circuit that we call ORGaNICs (Oscillatory Recurrent GAted\nNeural Integrator Circuits). ORGaNICs are a variety of Long Short Term Memory\nunits (LSTMs), imported from machine learning and artificial intelligence.\nORGaNICs can be used to explain the complex dynamics of delay-period activity\nin prefrontal cortex (PFC) during a working memory task. The theory is\nanalytically tractable so that we can characterize the dynamics, and the theory\nprovides a means for reading out information from the dynamically varying\nresponses at any point in time, in spite of the complex dynamics. ORGaNICs can\nbe implemented with a biophysical (electrical circuit) model of pyramidal\ncells, combined with shunting inhibition via a thalamocortical loop. Although\nintroduced as a computational theory of working memory, ORGaNICs are also\napplicable to models of sensory processing, motor preparation and motor\ncontrol. ORGaNICs offer computational advantages compared to other varieties of\nLSTMs that are commonly used in AI applications. Consequently, ORGaNICs are a\nframework for canonical computation in brains and machines.", "published": "2018-03-16T16:04:09Z", "version": 4}, {"aid": "1803.06329", "authors": ["Diego Marcos", "Devis Tuia", "Benjamin Kellenberger", "Lisa Zhang", "Min Bai", "Renjie Liao", "Raquel Urtasun"], "title": "Learning deep structured active contours end-to-end", "url": "http://arxiv.org/pdf/1803.06329v1", "summary": "The world is covered with millions of buildings, and precisely knowing each\ninstance's position and extents is vital to a multitude of applications.\nRecently, automated building footprint segmentation models have shown superior\ndetection accuracy thanks to the usage of Convolutional Neural Networks (CNN).\nHowever, even the latest evolutions struggle to precisely delineating borders,\nwhich often leads to geometric distortions and inadvertent fusion of adjacent\nbuilding instances. We propose to overcome this issue by exploiting the\ndistinct geometric properties of buildings. To this end, we present Deep\nStructured Active Contours (DSAC), a novel framework that integrates priors and\nconstraints into the segmentation process, such as continuous boundaries,\nsmooth edges, and sharp corners. To do so, DSAC employs Active Contour Models\n(ACM), a family of constraint- and prior-based polygonal models. We learn ACM\nparameterizations per instance using a CNN, and show how to incorporate all\ncomponents in a structured output model, making DSAC trainable end-to-end. We\nevaluate DSAC on three challenging building instance segmentation datasets,\nwhere it compares favorably against state-of-the-art. Code will be made\navailable.", "published": "2018-03-16T17:30:37Z", "version": 1}, {"aid": "1803.06407", "authors": ["Calvin Murdock", "Ming-Fang Chang", "Simon Lucey"], "title": "Deep Component Analysis via Alternating Direction Neural Networks", "url": "http://arxiv.org/pdf/1803.06407v1", "summary": "Despite a lack of theoretical understanding, deep neural networks have\nachieved unparalleled performance in a wide range of applications. On the other\nhand, shallow representation learning with component analysis is associated\nwith rich intuition and theory, but smaller capacity often limits its\nusefulness. To bridge this gap, we introduce Deep Component Analysis (DeepCA),\nan expressive multilayer model formulation that enforces hierarchical structure\nthrough constraints on latent variables in each layer. For inference, we\npropose a differentiable optimization algorithm implemented using recurrent\nAlternating Direction Neural Networks (ADNNs) that enable parameter learning\nusing standard backpropagation. By interpreting feed-forward networks as\nsingle-iteration approximations of inference in our model, we provide both a\nnovel theoretical perspective for understanding them and a practical technique\nfor constraining predictions with prior knowledge. Experimentally, we\ndemonstrate performance improvements on a variety of tasks, including\nsingle-image depth prediction with sparse output constraints.", "published": "2018-03-16T21:40:02Z", "version": 1}, {"aid": "1803.06500", "authors": ["Joseph Corneli", "Ursula Martin", "Dave Murray-Rust", "Gabriela Rino Nesin", "Alison Pease"], "title": "Argumentation theory for mathematical argument", "url": "http://arxiv.org/pdf/1803.06500v2", "summary": "To adequately model mathematical arguments the analyst must be able to\nrepresent the mathematical objects under discussion and the relationships\nbetween them, as well as inferences drawn about these objects and relationships\nas the discourse unfolds. We introduce a framework with these properties, which\nhas been used to analyse mathematical dialogues and expository texts. The\nframework can recover salient elements of discourse at, and within, the\nsentence level, as well as the way mathematical content connects to form larger\nargumentative structures. We show how the framework might be used to support\ncomputational reasoning, and argue that it provides a more natural way to\nexamine the process of proving theorems than do Lamport's structured proofs.", "published": "2018-03-17T13:20:37Z", "version": 2}, {"aid": "1803.06744", "authors": ["Purushotham Kamath", "Abhishek Singh", "Debo Dutta"], "title": "Fast Neural Architecture Construction using EnvelopeNets", "url": "http://arxiv.org/pdf/1803.06744v3", "summary": "Fast Neural Architecture Construction (NAC) is a method to construct deep\nnetwork architectures by pruning and expansion of a base network. In recent\nyears, several automated search methods for neural network architectures have\nbeen proposed using methods such as evolutionary algorithms and reinforcement\nlearning. These methods use a single scalar objective function (usually\naccuracy) that is evaluated after a full training and evaluation cycle. In\ncontrast NAC directly compares the utility of different filters using\nstatistics derived from filter featuremaps reach a state where the utility of\ndifferent filters within a network can be compared and hence can be used to\nconstruct networks. The training epochs needed for filters within a network to\nreach this state is much less than the training epochs needed for the accuracy\nof a network to stabilize. NAC exploits this finding to construct convolutional\nneural nets (CNNs) with close to state of the art accuracy, in < 1 GPU day,\nfaster than most of the current neural architecture search methods. The\nconstructed networks show close to state of the art performance on the image\nclassification problem on well known datasets (CIFAR-10, ImageNet) and\nconsistently show better performance than hand constructed and randomly\ngenerated networks of the same depth, operators and approximately the same\nnumber of parameters.", "published": "2018-03-18T21:28:03Z", "version": 3}, {"aid": "1803.06802", "authors": ["Qianyi Wu", "Juyong Zhang", "Yu-Kun Lai", "Jianmin Zheng", "Jianfei Cai"], "title": "Alive Caricature from 2D to 3D", "url": "http://arxiv.org/pdf/1803.06802v3", "summary": "Caricature is an art form that expresses subjects in abstract, simple and\nexaggerated view. While many caricatures are 2D images, this paper presents an\nalgorithm for creating expressive 3D caricatures from 2D caricature images with\na minimum of user interaction. The key idea of our approach is to introduce an\nintrinsic deformation representation that has a capacity of extrapolation\nenabling us to create a deformation space from standard face dataset, which\nmaintains face constraints and meanwhile is sufficiently large for producing\nexaggerated face models. Built upon the proposed deformation representation, an\noptimization model is formulated to find the 3D caricature that captures the\nstyle of the 2D caricature image automatically. The experiments show that our\napproach has better capability in expressing caricatures than those fitting\napproaches directly using classical parametric face models such as 3DMM and\nFaceWareHouse. Moreover, our approach is based on standard face datasets and\navoids constructing complicated 3D caricature training set, which provides\ngreat flexibility in real applications.", "published": "2018-03-19T04:47:16Z", "version": 3}, {"aid": "1803.06815", "authors": ["Sachin Mehta", "Mohammad Rastegari", "Anat Caspi", "Linda Shapiro", "Hannaneh Hajishirzi"], "title": "ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation", "url": "http://arxiv.org/pdf/1803.06815v3", "summary": "We introduce a fast and efficient convolutional neural network, ESPNet, for\nsemantic segmentation of high resolution images under resource constraints.\nESPNet is based on a new convolutional module, efficient spatial pyramid (ESP),\nwhich is efficient in terms of computation, memory, and power. ESPNet is 22\ntimes faster (on a standard GPU) and 180 times smaller than the\nstate-of-the-art semantic segmentation network PSPNet, while its category-wise\naccuracy is only 8% less. We evaluated ESPNet on a variety of semantic\nsegmentation datasets including Cityscapes, PASCAL VOC, and a breast biopsy\nwhole slide image dataset. Under the same constraints on memory and\ncomputation, ESPNet outperforms all the current efficient CNN networks such as\nMobileNet, ShuffleNet, and ENet on both standard metrics and our newly\nintroduced performance metrics that measure efficiency on edge devices. Our\nnetwork can process high resolution images at a rate of 112 and 9 frames per\nsecond on a standard GPU and edge device, respectively.", "published": "2018-03-19T06:42:47Z", "version": 3}, {"aid": "1803.06904", "authors": ["Seyed Majid Azimi", "Peter Fischer", "Marco K\u00f6rner", "Peter Reinartz"], "title": "Aerial LaneNet: Lane Marking Semantic Segmentation in Aerial Imagery using Wavelet-Enhanced Cost-sensitive Symmetric Fully Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1803.06904v2", "summary": "The knowledge about the placement and appearance of lane markings is a\nprerequisite for the creation of maps with high precision, necessary for\nautonomous driving, infrastructure monitoring, lane-wise traffic management,\nand urban planning. Lane markings are one of the important components of such\nmaps. Lane markings convey the rules of roads to drivers. While these rules are\nlearned by humans, an autonomous driving vehicle should be taught to learn them\nto localize itself. Therefore, accurate and reliable lane marking semantic\nsegmentation in the imagery of roads and highways is needed to achieve such\ngoals. We use airborne imagery which can capture a large area in a short period\nof time by introducing an aerial lane marking dataset. In this work, we propose\na Symmetric Fully Convolutional Neural Network enhanced by Wavelet Transform in\norder to automatically carry out lane marking segmentation in aerial imagery.\nDue to a heavily unbalanced problem in terms of number of lane marking pixels\ncompared with background pixels, we use a customized loss function as well as a\nnew type of data augmentation step. We achieve a very high accuracy in\npixel-wise localization of lane markings without using 3rd-party information.\nIn this work, we introduce the first high-quality dataset used within our\nexperiments which contains a broad range of situations and classes of lane\nmarkings representative of current transportation systems. This dataset will be\npublicly available and hence, it can be used as the benchmark dataset for\nfuture algorithms within this domain.", "published": "2018-03-19T13:32:27Z", "version": 2}, {"aid": "1803.06959", "authors": ["Ari S. Morcos", "David G. T. Barrett", "Neil C. Rabinowitz", "Matthew Botvinick"], "title": "On the importance of single directions for generalization", "url": "http://arxiv.org/pdf/1803.06959v4", "summary": "Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.", "published": "2018-03-19T14:42:19Z", "version": 4}, {"aid": "1803.07055", "authors": ["Horia Mania", "Aurelia Guy", "Benjamin Recht"], "title": "Simple random search provides a competitive approach to reinforcement learning", "url": "http://arxiv.org/pdf/1803.07055v1", "summary": "A common belief in model-free reinforcement learning is that methods based on\nrandom search in the parameter space of policies exhibit significantly worse\nsample complexity than those that explore the space of actions. We dispel such\nbeliefs by introducing a random search method for training static, linear\npolicies for continuous control problems, matching state-of-the-art sample\nefficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a\nnearly optimal controller for a challenging instance of the Linear Quadratic\nRegulator, a classical problem in control theory, when the dynamics are not\nknown. Computationally, our random search algorithm is at least 15 times more\nefficient than the fastest competing model-free methods on these benchmarks. We\ntake advantage of this computational efficiency to evaluate the performance of\nour method over hundreds of random seeds and many different hyperparameter\nconfigurations for each benchmark task. Our simulations highlight a high\nvariability in performance in these benchmark tasks, suggesting that commonly\nused estimations of sample efficiency do not adequately evaluate the\nperformance of RL algorithms.", "published": "2018-03-19T17:35:14Z", "version": 1}, {"aid": "1803.07066", "authors": ["Jiayuan Gu", "Han Hu", "Liwei Wang", "Yichen Wei", "Jifeng Dai"], "title": "Learning Region Features for Object Detection", "url": "http://arxiv.org/pdf/1803.07066v1", "summary": "While most steps in the modern object detection methods are learnable, the\nregion feature extraction step remains largely hand-crafted, featured by RoI\npooling methods. This work proposes a general viewpoint that unifies existing\nregion feature extraction methods and a novel method that is end-to-end\nlearnable. The proposed method removes most heuristic choices and outperforms\nits RoI pooling counterparts. It moves further towards fully learnable object\ndetection.", "published": "2018-03-19T17:58:50Z", "version": 1}, {"aid": "1803.07469", "authors": ["Daniel Barath", "Jana Noskova", "Jiri Matas"], "title": "MAGSAC: marginalizing sample consensus", "url": "http://arxiv.org/pdf/1803.07469v2", "summary": "A method called, sigma-consensus, is proposed to eliminate the need for a\nuser-defined inlier-outlier threshold in RANSAC. Instead of estimating the\nnoise sigma, it is marginalized over a range of noise scales. The optimized\nmodel is obtained by weighted least-squares fitting where the weights come from\nthe marginalization over sigma of the point likelihoods of being inliers. A new\nquality function is proposed not requiring sigma and, thus, a set of inliers to\ndetermine the model quality. Also, a new termination criterion for RANSAC is\nbuilt on the proposed marginalization approach. Applying sigma-consensus,\nMAGSAC is proposed with no need for a user-defined sigma and improving the\naccuracy of robust estimation significantly. It is superior to the\nstate-of-the-art in terms of geometric accuracy on publicly available\nreal-world datasets for epipolar geometry (F and E) and homography estimation.\nIn addition, applying sigma-consensus only once as a post-processing step to\nthe RANSAC output always improved the model quality on a wide range of vision\nproblems without noticeable deterioration in processing time, adding a few\nmilliseconds. The source code is at https://github.com/danini/magsac.", "published": "2018-03-20T15:01:11Z", "version": 2}, {"aid": "1803.07482", "authors": ["Ethan Knight", "Osher Lerner"], "title": "Natural Gradient Deep Q-learning", "url": "http://arxiv.org/pdf/1803.07482v2", "summary": "We present a novel algorithm to train a deep Q-learning agent using\nnatural-gradient techniques. We compare the original deep Q-network (DQN)\nalgorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a\ncollection of classic control domains. Without employing target networks, NGDQN\nsignificantly outperforms DQN without target networks, and performs no worse\nthan DQN with target networks, suggesting that NGDQN stabilizes training and\ncan help reduce the need for additional hyperparameter tuning. We also find\nthat NGDQN is less sensitive to hyperparameter optimization relative to DQN.\nTogether these results suggest that natural-gradient techniques can improve\nvalue-function optimization in deep reinforcement learning.", "published": "2018-03-20T15:22:52Z", "version": 2}, {"aid": "1803.07517", "authors": ["Gabrielle Ras", "Marcel van Gerven", "Pim Haselager"], "title": "Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges", "url": "http://arxiv.org/pdf/1803.07517v2", "summary": "Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes.", "published": "2018-03-20T16:44:47Z", "version": 2}, {"aid": "1803.07624", "authors": ["Jialin Wu", "Dai Li", "Yu Yang", "Chandrajit Bajaj", "Xiangyang Ji"], "title": "Dynamic Filtering with Large Sampling Field for ConvNets", "url": "http://arxiv.org/pdf/1803.07624v3", "summary": "We propose a dynamic filtering strategy with large sampling field for\nConvNets (LS-DFN), where the position-specific kernels learn from not only the\nidentical position but also multiple sampled neighbor regions. During sampling,\nresidual learning is introduced to ease training and an attention mechanism is\napplied to fuse features from different samples. Such multiple samples enlarge\nthe kernels' receptive fields significantly without requiring more parameters.\nWhile LS-DFN inherits the advantages of DFN, namely avoiding feature map\nblurring by position-wise kernels while keeping translation invariance, it also\nefficiently alleviates the overfitting issue caused by much more parameters\nthan normal CNNs. Our model is efficient and can be trained end-to-end via\nstandard back-propagation. We demonstrate the merits of our LS-DFN on both\nsparse and dense prediction tasks involving object detection, semantic\nsegmentation, and flow estimation. Our results show LS-DFN enjoys stronger\nrecognition abilities in object detection and semantic segmentation tasks on\nVOC benchmark and sharper responses in flow estimation on FlyingChairs dataset\ncompared to strong baselines.", "published": "2018-03-20T19:52:16Z", "version": 3}, {"aid": "1803.07712", "authors": ["Furui Liu", "Laiwan Chan"], "title": "Causal Inference on Discrete Data via Estimating Distance Correlations", "url": "http://arxiv.org/pdf/1803.07712v3", "summary": "In this paper, we deal with the problem of inferring causal directions when\nthe data is on discrete domain. By considering the distribution of the cause\n$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as\nindependent random variables, we propose to infer the causal direction via\ncomparing the distance correlation between $P(X)$ and $P(Y|X)$ with the\ndistance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if\nthe dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments\nare performed to show the performance of the proposed method.", "published": "2018-03-21T01:39:08Z", "version": 3}, {"aid": "1803.07980", "authors": ["Tianchen Zhao"], "title": "Information Theoretic Interpretation of Deep learning", "url": "http://arxiv.org/pdf/1803.07980v2", "summary": "We interpret part of the experimental results of Shwartz-Ziv and Tishby\n[2017]. Inspired by these results, we established a conjecture of the dynamics\nof the machinary of deep neural network. This conjecture can be used to explain\nthe counterpart result by Saxe et al. [2018].", "published": "2018-03-21T16:03:29Z", "version": 2}, {"aid": "1803.08337", "authors": ["Sebastian Palacio", "Joachim Folz", "J\u00f6rn Hees", "Federico Raue", "Damian Borth", "Andreas Dengel"], "title": "What do Deep Networks Like to See?", "url": "http://arxiv.org/pdf/1803.08337v1", "summary": "We propose a novel way to measure and understand convolutional neural\nnetworks by quantifying the amount of input signal they let in. To do this, an\nautoencoder (AE) was fine-tuned on gradients from a pre-trained classifier with\nfixed parameters. We compared the reconstructed samples from AEs that were\nfine-tuned on a set of image classifiers (AlexNet, VGG16, ResNet-50, and\nInception~v3) and found substantial differences. The AE learns which aspects of\nthe input space to preserve and which ones to ignore, based on the information\nencoded in the backpropagated gradients. Measuring the changes in accuracy when\nthe signal of one classifier is used by a second one, a relation of total order\nemerges. This order depends directly on each classifier's input signal but it\ndoes not correlate with classification accuracy or network size. Further\nevidence of this phenomenon is provided by measuring the normalized mutual\ninformation between original images and auto-encoded reconstructions from\ndifferent fine-tuned AEs. These findings break new ground in the area of neural\nnetwork understanding, opening a new way to reason, debug, and interpret their\nresults. We present four concrete examples in the literature where observations\ncan now be explained in terms of the input signal that a model uses.", "published": "2018-03-22T13:10:47Z", "version": 1}, {"aid": "1803.08375", "authors": ["Abien Fred Agarap"], "title": "Deep Learning using Rectified Linear Units (ReLU)", "url": "http://arxiv.org/pdf/1803.08375v2", "summary": "We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.", "published": "2018-03-22T14:30:17Z", "version": 2}, {"aid": "1803.08450", "authors": ["St\u00e9phane Lathuili\u00e8re", "Pablo Mesejo", "Xavier Alameda-Pineda", "Radu Horaud"], "title": "A Comprehensive Analysis of Deep Regression", "url": "http://arxiv.org/pdf/1803.08450v3", "summary": "Deep learning revolutionized data science, and recently its popularity has\ngrown exponentially, as did the amount of papers employing deep networks.\nVision tasks, such as human pose estimation, did not escape from this trend.\nThere is a large number of deep models, where small changes in the network\narchitecture, or in the data pre-processing, together with the stochastic\nnature of the optimization procedures, produce notably different results,\nmaking extremely difficult to sift methods that significantly outperform\nothers. This situation motivates the current study, in which we perform a\nsystematic evaluation and statistical analysis of vanilla deep regression, i.e.\nconvolutional neural networks with a linear regression top layer. This is the\nfirst comprehensive analysis of deep regression techniques. We perform\nexperiments on four vision problems, and report confidence intervals for the\nmedian performance as well as the statistical significance of the results, if\nany. Surprisingly, the variability due to different data pre-processing\nprocedures generally eclipses the variability due to modifications in the\nnetwork architecture. Our results reinforce the hypothesis according to which,\nin general, a general-purpose network (e.g. VGG-16 or ResNet-50) adequately\ntuned can yield results close to the state-of-the-art without having to resort\nto more complex and ad-hoc regression models.", "published": "2018-03-22T16:46:39Z", "version": 3}, {"aid": "1803.08494", "authors": ["Yuxin Wu", "Kaiming He"], "title": "Group Normalization", "url": "http://arxiv.org/pdf/1803.08494v3", "summary": "Batch Normalization (BN) is a milestone technique in the development of deep\nlearning, enabling various networks to train. However, normalizing along the\nbatch dimension introduces problems --- BN's error increases rapidly when the\nbatch size becomes smaller, caused by inaccurate batch statistics estimation.\nThis limits BN's usage for training larger models and transferring features to\ncomputer vision tasks including detection, segmentation, and video, which\nrequire small batches constrained by memory consumption. In this paper, we\npresent Group Normalization (GN) as a simple alternative to BN. GN divides the\nchannels into groups and computes within each group the mean and variance for\nnormalization. GN's computation is independent of batch sizes, and its accuracy\nis stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN\nhas 10.6% lower error than its BN counterpart when using a batch size of 2;\nwhen using typical batch sizes, GN is comparably good with BN and outperforms\nother normalization variants. Moreover, GN can be naturally transferred from\npre-training to fine-tuning. GN can outperform its BN-based counterparts for\nobject detection and segmentation in COCO, and for video classification in\nKinetics, showing that GN can effectively replace the powerful BN in a variety\nof tasks. GN can be easily implemented by a few lines of code in modern\nlibraries.", "published": "2018-03-22T17:57:16Z", "version": 3}, {"aid": "1803.08607", "authors": ["Tao Sheng", "Chen Feng", "Shaojie Zhuo", "Xiaopeng Zhang", "Liang Shen", "Mickey Aleksic"], "title": "A Quantization-Friendly Separable Convolution for MobileNets", "url": "http://arxiv.org/pdf/1803.08607v3", "summary": "As deep learning (DL) is being rapidly pushed to edge computing, researchers\ninvented various ways to make inference computation more efficient on\nmobile/IoT devices, such as network pruning, parameter compression, and etc.\nQuantization, as one of the key approaches, can effectively offload GPU, and\nmake it possible to deploy DL on fixed-point pipeline. Unfortunately, not all\nexisting networks design are friendly to quantization. For example, the popular\nlightweight MobileNetV1, while it successfully reduces parameter size and\ncomputation latency with separable convolution, our experiment shows its\nquantized models have large accuracy gap against its float point models. To\nresolve this, we analyzed the root cause of quantization loss and proposed a\nquantization-friendly separable convolution architecture. By evaluating the\nimage classification task on ImageNet2012 dataset, our modified MobileNetV1\nmodel can archive 8-bit inference top-1 accuracy in 68.03%, almost closed the\ngap to the float pipeline.", "published": "2018-03-22T23:06:38Z", "version": 3}, {"aid": "1803.08664", "authors": ["Namhyuk Ahn", "Byungkon Kang", "Kyung-Ah Sohn"], "title": "Fast, Accurate, and Lightweight Super-Resolution with Cascading Residual Network", "url": "http://arxiv.org/pdf/1803.08664v5", "summary": "In recent years, deep learning methods have been successfully applied to\nsingle-image super-resolution tasks. Despite their great performances, deep\nlearning methods cannot be easily applied to real-world applications due to the\nrequirement of heavy computation. In this paper, we address this issue by\nproposing an accurate and lightweight deep network for image super-resolution.\nIn detail, we design an architecture that implements a cascading mechanism upon\na residual network. We also present variant models of the proposed cascading\nresidual network to further improve efficiency. Our extensive experiments show\nthat even with much fewer parameters and operations, our models achieve\nperformance comparable to that of state-of-the-art methods.", "published": "2018-03-23T06:07:20Z", "version": 5}, {"aid": "1803.08834", "authors": ["Isma Hadji", "Richard P. Wildes"], "title": "What Do We Understand About Convolutional Networks?", "url": "http://arxiv.org/pdf/1803.08834v1", "summary": "This document will review the most prominent proposals using multilayer\nconvolutional architectures. Importantly, the various components of a typical\nconvolutional network will be discussed through a review of different\napproaches that base their design decisions on biological findings and/or sound\ntheoretical bases. In addition, the different attempts at understanding\nConvNets via visualizations and empirical studies will be reviewed. The\nultimate goal is to shed light on the role of each layer of processing involved\nin a ConvNet architecture, distill what we currently understand about ConvNets\nand highlight critical open problems.", "published": "2018-03-23T15:22:01Z", "version": 1}, {"aid": "1803.08887", "authors": ["Ngoc-Trung Tran", "Tuan-Anh Bui", "Ngai-Man Cheung"], "title": "Dist-GAN: An Improved GAN using Distance Constraints", "url": "http://arxiv.org/pdf/1803.08887v3", "summary": "We introduce effective training algorithms for Generative Adversarial\nNetworks (GAN) to alleviate mode collapse and gradient vanishing. In our\nsystem, we constrain the generator by an Autoencoder (AE). We propose a\nformulation to consider the reconstructed samples from AE as \"real\" samples for\nthe discriminator. This couples the convergence of the AE with that of the\ndiscriminator, effectively slowing down the convergence of discriminator and\nreducing gradient vanishing. Importantly, we propose two novel distance\nconstraints to improve the generator. First, we propose a latent-data distance\nconstraint to enforce compatibility between the latent sample distances and the\ncorresponding data sample distances. We use this constraint to explicitly\nprevent the generator from mode collapse. Second, we propose a\ndiscriminator-score distance constraint to align the distribution of the\ngenerated samples with that of the real samples through the discriminator\nscore. We use this constraint to guide the generator to synthesize samples that\nresemble the real ones. Our proposed GAN using these distance constraints,\nnamely Dist-GAN, can achieve better results than state-of-the-art methods\nacross benchmark datasets: synthetic, MNIST, MNIST-1K, CelebA, CIFAR-10 and\nSTL-10 datasets. Our code is published here (https://github.com/tntrung/gan)\nfor research.", "published": "2018-03-23T17:06:26Z", "version": 3}, {"aid": "1803.09010", "authors": ["Timnit Gebru", "Jamie Morgenstern", "Briana Vecchione", "Jennifer Wortman Vaughan", "Hanna Wallach", "Hal Daum\u00e9 III", "Kate Crawford"], "title": "Datasheets for Datasets", "url": "http://arxiv.org/pdf/1803.09010v8", "summary": "The machine learning community currently has no standardized process for\ndocumenting datasets, which can lead to severe consequences in high-stakes\ndomains. To address this gap, we propose datasheets for datasets. In the\nelectronics industry, every component, no matter how simple or complex, is\naccompanied with a datasheet that describes its operating characteristics, test\nresults, recommended uses, and other information. By analogy, we propose that\nevery dataset be accompanied with a datasheet that documents its motivation,\ncomposition, collection process, recommended uses, and so on. Datasheets for\ndatasets will facilitate better communication between dataset creators and\ndataset consumers, and encourage the machine learning community to prioritize\ntransparency and accountability.", "published": "2018-03-23T23:22:18Z", "version": 8}, {"aid": "1803.09165", "authors": ["Renata Khasanova", "Jan Wassenberg", "Jyrki Alakuijala"], "title": "Noise generation for compression algorithms", "url": "http://arxiv.org/pdf/1803.09165v1", "summary": "In various Computer Vision and Signal Processing applications, noise is\ntypically perceived as a drawback of the image capturing system that ought to\nbe removed. We, on the other hand, claim that image noise, just as texture, is\nimportant for visual perception and, therefore, critical for lossy compression\nalgorithms that tend to make decompressed images look less realistic by\nremoving small image details. In this paper we propose a physically and\nbiologically inspired technique that learns a noise model at the encoding step\nof the compression algorithm and then generates the appropriate amount of\nadditive noise at the decoding step. Our method can significantly increase the\nrealism of the decompressed image at the cost of few bytes of additional memory\nspace regardless of the original image size. The implementation of our method\nis open-sourced and available at https://github.com/google/pik.", "published": "2018-03-24T21:19:29Z", "version": 1}, {"aid": "1803.09218", "authors": ["Dong-Qing Zhang"], "title": "Image Recognition Using Scale Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1803.09218v1", "summary": "Convolutional Neural Network(CNN) has been widely used for image recognition\nwith great success. However, there are a number of limitations of the current\nCNN based image recognition paradigm. First, the receptive field of CNN is\ngenerally fixed, which limits its recognition capacity when the input image is\nvery large. Second, it lacks the computational scalability for dealing with\nimages with different sizes. Third, it is quite different from human visual\nsystem for image recognition, which involves both feadforward and recurrent\nproprocessing. This paper proposes a different paradigm of image recognition,\nwhich can take advantages of variable scales of the input images, has more\ncomputational scalabilities, and is more similar to image recognition by human\nvisual system. It is based on recurrent neural network (RNN) defined on image\nscale with an embeded base CNN, which is named Scale Recurrent Neural\nNetwork(SRNN). This RNN based approach makes it easier to deal with images with\nvariable sizes, and allows us to borrow existing RNN techniques, such as LSTM\nand GRU, to further enhance the recognition accuracy. Our experiments show that\nthe recognition accuracy of a base CNN can be significantly boosted using the\nproposed SRNN models. It also significantly outperforms the scale ensemble\nmethod, which integrate the results of performing CNN to the input image at\ndifferent scales, although the computational overhead of using SRNN is\nnegligible.", "published": "2018-03-25T09:16:55Z", "version": 1}, {"aid": "1803.09263", "authors": ["Kangxue Yin", "Hui Huang", "Daniel Cohen-Or", "Hao Zhang"], "title": "P2P-NET: Bidirectional Point Displacement Net for Shape Transform", "url": "http://arxiv.org/pdf/1803.09263v4", "summary": "We introduce P2P-NET, a general-purpose deep neural network which learns\ngeometric transformations between point-based shape representations from two\ndomains, e.g., meso-skeletons and surfaces, partial and complete scans, etc.\nThe architecture of the P2P-NET is that of a bi-directional point displacement\nnetwork, which transforms a source point set to a target point set with the\nsame cardinality, and vice versa, by applying point-wise displacement vectors\nlearned from data. P2P-NET is trained on paired shapes from the source and\ntarget domains, but without relying on point-to-point correspondences between\nthe source and target point sets. The training loss combines two\nuni-directional geometric losses, each enforcing a shape-wise similarity\nbetween the predicted and the target point sets, and a cross-regularization\nterm to encourage consistency between displacement vectors going in opposite\ndirections. We develop and present several different applications enabled by\nour general-purpose bidirectional P2P-NET to highlight the effectiveness,\nversatility, and potential of our network in solving a variety of point-based\nshape transformation problems.", "published": "2018-03-25T14:30:51Z", "version": 4}, {"aid": "1803.09760", "authors": ["Andrew Jaegle", "Oleh Rybkin", "Konstantinos G. Derpanis", "Kostas Daniilidis"], "title": "Predicting the Future with Transformational States", "url": "http://arxiv.org/pdf/1803.09760v1", "summary": "An intelligent observer looks at the world and sees not only what is, but\nwhat is moving and what can be moved. In other words, the observer sees how the\npresent state of the world can transform in the future. We propose a model that\npredicts future images by learning to represent the present state and its\ntransformation given only a sequence of images. To do so, we introduce an\narchitecture with a latent state composed of two components designed to capture\n(i) the present image state and (ii) the transformation between present and\nfuture states, respectively. We couple this latent state with a recurrent\nneural network (RNN) core that predicts future frames by transforming past\nstates into future states by applying the accumulated state transformation with\na learned operator. We describe how this model can be integrated into an\nencoder-decoder convolutional neural network (CNN) architecture that uses\nweighted residual connections to integrate representations of the past with\nrepresentations of the future. Qualitatively, our approach generates image\nsequences that are stable and capture realistic motion over multiple predicted\nframes, without requiring adversarial training. Quantitatively, our method\nachieves prediction results comparable to state-of-the-art results on standard\nimage prediction benchmarks (Moving MNIST, KTH, and UCF101).", "published": "2018-03-26T18:00:07Z", "version": 1}, {"aid": "1803.09820", "authors": ["Leslie N. Smith"], "title": "A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay", "url": "http://arxiv.org/pdf/1803.09820v2", "summary": "Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums. Files to help replicate the results reported here\nare available.", "published": "2018-03-26T20:05:59Z", "version": 2}, {"aid": "1803.09845", "authors": ["Jiasen Lu", "Jianwei Yang", "Dhruv Batra", "Devi Parikh"], "title": "Neural Baby Talk", "url": "http://arxiv.org/pdf/1803.09845v1", "summary": "We introduce a novel framework for image captioning that can produce natural\nlanguage explicitly grounded in entities that object detectors find in the\nimage. Our approach reconciles classical slot filling approaches (that are\ngenerally better grounded in images) with modern neural captioning approaches\n(that are generally more natural sounding and accurate). Our approach first\ngenerates a sentence `template' with slot locations explicitly tied to specific\nimage regions. These slots are then filled in by visual concepts identified in\nthe regions by object detectors. The entire architecture (sentence template\ngeneration and slot filling with object detectors) is end-to-end\ndifferentiable. We verify the effectiveness of our proposed model on different\nimage captioning tasks. On standard image captioning and novel object\ncaptioning, our model reaches state-of-the-art on both COCO and Flickr30k\ndatasets. We also demonstrate that our model has unique advantages when the\ntrain and test distributions of scene compositions -- and hence language priors\nof associated captions -- are different. Code has been made available at:\nhttps://github.com/jiasenlu/NeuralBabyTalk", "published": "2018-03-27T01:59:56Z", "version": 1}, {"aid": "1803.10227", "authors": ["Ashley D. Edwards", "Laura Downs", "James C. Davidson"], "title": "Forward-Backward Reinforcement Learning", "url": "http://arxiv.org/pdf/1803.10227v1", "summary": "Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.", "published": "2018-03-27T04:33:08Z", "version": 1}, {"aid": "1803.09926", "authors": ["Zheng Qin", "Zhaoning Zhang", "Dongsheng Li", "Yiming Zhang", "Yuxing Peng"], "title": "Diagonalwise Refactorization: An Efficient Training Method for Depthwise Convolutions", "url": "http://arxiv.org/pdf/1803.09926v1", "summary": "Depthwise convolutions provide significant performance benefits owing to the\nreduction in both parameters and mult-adds. However, training depthwise\nconvolution layers with GPUs is slow in current deep learning frameworks\nbecause their implementations cannot fully utilize the GPU capacity. To address\nthis problem, in this paper we present an efficient method (called diagonalwise\nrefactorization) for accelerating the training of depthwise convolution layers.\nOur key idea is to rearrange the weight vectors of a depthwise convolution into\na large diagonal weight matrix so as to convert the depthwise convolution into\none single standard convolution, which is well supported by the cuDNN library\nthat is highly-optimized for GPU computations. We have implemented our training\nmethod in five popular deep learning frameworks. Evaluation results show that\nour proposed method gains $15.4\\times$ training speedup on Darknet, $8.4\\times$\non Caffe, $5.4\\times$ on PyTorch, $3.5\\times$ on MXNet, and $1.4\\times$ on\nTensorFlow, compared to their original implementations of depthwise\nconvolutions.", "published": "2018-03-27T07:06:54Z", "version": 1}, {"aid": "1803.10071", "authors": ["Tong Zhang", "Wenming Zheng", "Zhen Cui", "Yang Li"], "title": "Tensor graph convolutional neural network", "url": "http://arxiv.org/pdf/1803.10071v1", "summary": "In this paper, we propose a novel tensor graph convolutional neural network\n(TGCNN) to conduct convolution on factorizable graphs, for which here two types\nof problems are focused, one is sequential dynamic graphs and the other is\ncross-attribute graphs. Especially, we propose a graph preserving layer to\nmemorize salient nodes of those factorized subgraphs, i.e. cross graph\nconvolution and graph pooling. For cross graph convolution, a parameterized\nKronecker sum operation is proposed to generate a conjunctive adjacency matrix\ncharacterizing the relationship between every pair of nodes across two\nsubgraphs. Taking this operation, then general graph convolution may be\nefficiently performed followed by the composition of small matrices, which thus\nreduces high memory and computational burden. Encapsuling sequence graphs into\na recursive learning, the dynamics of graphs can be efficiently encoded as well\nas the spatial layout of graphs. To validate the proposed TGCNN, experiments\nare conducted on skeleton action datasets as well as matrix completion dataset.\nThe experiment results demonstrate that our method can achieve more competitive\nperformance with the state-of-the-art methods.", "published": "2018-03-27T13:34:05Z", "version": 1}, {"aid": "1803.10470", "authors": ["Jaan Aru", "Raul Vicente"], "title": "What deep learning can tell us about higher cognitive functions like mindreading?", "url": "http://arxiv.org/pdf/1803.10470v2", "summary": "Can deep learning (DL) guide our understanding of computations happening in\nbiological brain? We will first briefly consider how DL has contributed to the\nresearch on visual object recognition. In the main part we will assess whether\nDL could also help us to clarify the computations underlying higher cognitive\nfunctions such as Theory of Mind. In addition, we will compare the objectives\nand learning signals of brains and machines, leading us to conclude that simply\nscaling up the current DL algorithms will most likely not lead to human level\nTheory of Mind.", "published": "2018-03-28T08:58:49Z", "version": 2}, {"aid": "1803.10743", "authors": ["Taco S. Cohen", "Mario Geiger", "Maurice Weiler"], "title": "Intertwiners between Induced Representations (with Applications to the Theory of Equivariant Neural Networks)", "url": "http://arxiv.org/pdf/1803.10743v2", "summary": "Group equivariant and steerable convolutional neural networks (regular and\nsteerable G-CNNs) have recently emerged as a very effective model class for\nlearning from signal data such as 2D and 3D images, video, and other data where\nsymmetries are present. In geometrical terms, regular G-CNNs represent data in\nterms of scalar fields (\"feature channels\"), whereas the steerable G-CNN can\nalso use vector or tensor fields (\"capsules\") to represent data. In algebraic\nterms, the feature spaces in regular G-CNNs transform according to a regular\nrepresentation of the group G, whereas the feature spaces in Steerable G-CNNs\ntransform according to the more general induced representations of G. In order\nto make the network equivariant, each layer in a G-CNN is required to\nintertwine between the induced representations associated with its input and\noutput space.\n  In this paper we present a general mathematical framework for G-CNNs on\nhomogeneous spaces like Euclidean space or the sphere. We show, using\nelementary methods, that the layers of an equivariant network are convolutional\nif and only if the input and output feature spaces transform according to an\ninduced representation. This result, which follows from G.W. Mackey's abstract\ntheory on induced representations, establishes G-CNNs as a universal class of\nequivariant network architectures, and generalizes the important recent work of\nKondor & Trivedi on the intertwiners between regular representations.", "published": "2018-03-28T17:30:26Z", "version": 2}, {"aid": "1803.10794", "authors": ["Matthias M\u00fcller", "Adel Bibi", "Silvio Giancola", "Salman Al-Subaihi", "Bernard Ghanem"], "title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild", "url": "http://arxiv.org/pdf/1803.10794v1", "summary": "Despite the numerous developments in object tracking, further development of\ncurrent tracking algorithms is limited by small and mostly saturated datasets.\nAs a matter of fact, data-hungry trackers based on deep-learning currently rely\non object detection datasets due to the scarcity of dedicated large-scale\ntracking datasets. In this work, we present TrackingNet, the first large-scale\ndataset and benchmark for object tracking in the wild. We provide more than 30K\nvideos with more than 14 million dense bounding box annotations. Our dataset\ncovers a wide selection of object classes in broad and diverse context. By\nreleasing such a large-scale dataset, we expect deep trackers to further\nimprove and generalize. In addition, we introduce a new benchmark composed of\n500 novel videos, modeled with a distribution similar to our training dataset.\nBy sequestering the annotation of the test set and providing an online\nevaluation server, we provide a fair benchmark for future development of object\ntrackers. Deep trackers fine-tuned on a fraction of our dataset improve their\nperformance by up to 1.6% on OTB100 and up to 1.7% on TrackingNet Test. We\nprovide an extensive benchmark on TrackingNet by evaluating more than 20\ntrackers. Our results suggest that object tracking in the wild is far from\nbeing solved.", "published": "2018-03-28T18:30:17Z", "version": 1}, {"aid": "1803.10827", "authors": ["Kiana Ehsani", "Hessam Bagherinezhad", "Joseph Redmon", "Roozbeh Mottaghi", "Ali Farhadi"], "title": "Who Let The Dogs Out? Modeling Dog Behavior From Visual Data", "url": "http://arxiv.org/pdf/1803.10827v2", "summary": "We introduce the task of directly modeling a visually intelligent agent.\nComputer vision typically focuses on solving various subtasks related to visual\nintelligence. We depart from this standard approach to computer vision; instead\nwe directly model a visually intelligent agent. Our model takes visual\ninformation as input and directly predicts the actions of the agent. Toward\nthis end we introduce DECADE, a large-scale dataset of ego-centric videos from\na dog's perspective as well as her corresponding movements. Using this data we\nmodel how the dog acts and how the dog plans her movements. We show under a\nvariety of metrics that given just visual input we can successfully model this\nintelligent agent in many situations. Moreover, the representation learned by\nour model encodes distinct information compared to representations trained on\nimage classification, and our learned representation can generalize to other\ndomains. In particular, we show strong results on the task of walkable surface\nestimation by using this dog modeling task as representation learning.", "published": "2018-03-28T19:43:33Z", "version": 2}, {"aid": "1803.10981", "authors": ["Ian P. Gent", "Ciaran McCreesh", "Ian Miguel", "Neil C. A. Moore", "Peter Nightingale", "Patrick Prosser", "Chris Unsworth"], "title": "A Review of Literature on Parallel Constraint Solving", "url": "http://arxiv.org/pdf/1803.10981v1", "summary": "As multicore computing is now standard, it seems irresponsible for\nconstraints researchers to ignore the implications of it. Researchers need to\naddress a number of issues to exploit parallelism, such as: investigating which\nconstraint algorithms are amenable to parallelisation; whether to use shared\nmemory or distributed computation; whether to use static or dynamic\ndecomposition; and how to best exploit portfolios and cooperating search. We\nreview the literature, and see that we can sometimes do quite well, some of the\ntime, on some instances, but we are far from a general solution. Yet there\nseems to be little overall guidance that can be given on how best to exploit\nmulticore computers to speed up constraint solving. We hope at least that this\nsurvey will provide useful pointers to future researchers wishing to correct\nthis situation.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).", "published": "2018-03-29T09:34:09Z", "version": 1}, {"aid": "1803.11261", "authors": ["Kush R. Varshney"], "title": "How an Electrical Engineer Became an Artificial Intelligence Researcher, a Multiphase Active Contours Analysis", "url": "http://arxiv.org/pdf/1803.11261v1", "summary": "This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels.", "published": "2018-03-29T21:11:32Z", "version": 1}, {"aid": "1803.11370", "authors": ["Akito Takeki", "Daiki Ikami", "Go Irie", "Kiyoharu Aizawa"], "title": "Parallel Grid Pooling for Data Augmentation", "url": "http://arxiv.org/pdf/1803.11370v1", "summary": "Convolutional neural network (CNN) architectures utilize downsampling layers,\nwhich restrict the subsequent layers to learn spatially invariant features\nwhile reducing computational costs. However, such a downsampling operation\nmakes it impossible to use the full spectrum of input features. Motivated by\nthis observation, we propose a novel layer called parallel grid pooling (PGP)\nwhich is applicable to various CNN models. PGP performs downsampling without\ndiscarding any intermediate feature. It works as data augmentation and is\ncomplementary to commonly used data augmentation techniques. Furthermore, we\ndemonstrate that a dilated convolution can naturally be represented using PGP\noperations, which suggests that the dilated convolution can also be regarded as\na type of data augmentation technique. Experimental results based on popular\nimage classification benchmarks demonstrate the effectiveness of the proposed\nmethod. Code is available at: https://github.com/akitotakeki", "published": "2018-03-30T07:25:00Z", "version": 1}, {"aid": "1803.11405", "authors": ["Rohit Keshari", "Mayank Vatsa", "Richa Singh", "Afzel Noore"], "title": "Learning Structure and Strength of CNN Filters for Small Sample Size Training", "url": "http://arxiv.org/pdf/1803.11405v1", "summary": "Convolutional Neural Networks have provided state-of-the-art results in\nseveral computer vision problems. However, due to a large number of parameters\nin CNNs, they require a large number of training samples which is a limiting\nfactor for small sample size problems. To address this limitation, we propose\nSSF-CNN which focuses on learning the structure and strength of filters. The\nstructure of the filter is initialized using a dictionary-based filter learning\nalgorithm and the strength of the filter is learned using the small sample\ntraining data. The architecture provides the flexibility of training with both\nsmall and large training databases and yields good accuracies even with small\nsize training data. The effectiveness of the algorithm is first demonstrated on\nMNIST, CIFAR10, and NORB databases, with a varying number of training samples.\nThe results show that SSF-CNN significantly reduces the number of parameters\nrequired for training while providing high accuracies the test databases. On\nsmall sample size problems such as newborn face recognition and Omniglot, it\nyields state-of-the-art results. Specifically, on the IIITD Newborn Face\nDatabase, the results demonstrate improvement in rank-1 identification accuracy\nby at least 10%.", "published": "2018-03-30T10:34:33Z", "version": 1}, {"aid": "1804.00326", "authors": ["Arsha Nagrani", "Samuel Albanie", "Andrew Zisserman"], "title": "Seeing Voices and Hearing Faces: Cross-modal biometric matching", "url": "http://arxiv.org/pdf/1804.00326v2", "summary": "We introduce a seemingly impossible task: given only an audio clip of someone\nspeaking, decide which of two face images is the speaker. In this paper we\nstudy this, and a number of related cross-modal tasks, aimed at answering the\nquestion: how much can we infer from the voice about the face and vice versa?\nWe study this task \"in the wild\", employing the datasets that are now publicly\navailable for face recognition from static images (VGGFace) and speaker\nidentification from audio (VoxCeleb). These provide training and testing\nscenarios for both static and dynamic testing of cross-modal matching. We make\nthe following contributions: (i) we introduce CNN architectures for both binary\nand multi-way cross-modal face and audio matching, (ii) we compare dynamic\ntesting (where video information is available, but the audio is not from the\nsame video) with static testing (where only a single still image is available),\nand (iii) we use human testing as a baseline to calibrate the difficulty of the\ntask. We show that a CNN can indeed be trained to solve this task in both the\nstatic and dynamic scenarios, and is even well above chance on 10-way\nclassification of the face given the voice. The CNN matches human performance\non easy examples (e.g. different gender across faces) but exceeds human\nperformance on more challenging examples (e.g. faces with the same gender, age\nand nationality).", "published": "2018-04-01T18:02:41Z", "version": 2}, {"aid": "1804.00586", "authors": ["Jianwen Xie", "Zilong Zheng", "Ruiqi Gao", "Wenguan Wang", "Song-Chun Zhu", "Ying Nian Wu"], "title": "Learning Descriptor Networks for 3D Shape Synthesis and Analysis", "url": "http://arxiv.org/pdf/1804.00586v1", "summary": "This paper proposes a 3D shape descriptor network, which is a deep\nconvolutional energy-based model, for modeling volumetric shape patterns. The\nmaximum likelihood training of the model follows an \"analysis by synthesis\"\nscheme and can be interpreted as a mode seeking and mode shifting process. The\nmodel can synthesize 3D shape patterns by sampling from the probability\ndistribution via MCMC such as Langevin dynamics. The model can be used to train\na 3D generator network via MCMC teaching. The conditional version of the 3D\nshape descriptor net can be used for 3D object recovery and 3D object\nsuper-resolution. Experiments demonstrate that the proposed model can generate\nrealistic 3D shape patterns and can be useful for 3D shape analysis.", "published": "2018-04-02T15:15:34Z", "version": 1}, {"aid": "1804.00863", "authors": ["Maxim Maximov", "Laura Leal-Taix\u00e9", "Mario Fritz", "Tobias Ritschel"], "title": "Deep Appearance Maps", "url": "http://arxiv.org/pdf/1804.00863v3", "summary": "We propose a deep representation of appearance, i. e., the relation of color,\nsurface orientation, viewer position, material and illumination. Previous\napproaches have useddeep learning to extract classic appearance\nrepresentationsrelating to reflectance model parameters (e. g., Phong)\norillumination (e. g., HDR environment maps). We suggest todirectly represent\nappearance itself as a network we call aDeep Appearance Map (DAM). This is a 4D\ngeneralizationover 2D reflectance maps, which held the view direction fixed.\nFirst, we show how a DAM can be learned from images or video frames and later\nbe used to synthesize appearance, given new surface orientations and viewer\npositions. Second, we demonstrate how another network can be used to map from\nan image or video frames to a DAM network to reproduce this appearance, without\nusing a lengthy optimization such as stochastic gradient descent\n(learning-to-learn). Finally, we show the example of an appearance\nestimation-and-segmentation task, mapping from an image showingmultiple\nmaterials to multiple deep appearance maps.", "published": "2018-04-03T08:17:38Z", "version": 3}, {"aid": "1804.00946", "authors": ["Wenjie Pei", "David M. J. Tax"], "title": "Unsupervised Learning of Sequence Representations by Autoencoders", "url": "http://arxiv.org/pdf/1804.00946v2", "summary": "Sequence data is challenging for machine learning approaches, because the\nlengths of the sequences may vary between samples. In this paper, we present an\nunsupervised learning model for sequence data, called the Integrated Sequence\nAutoencoder (ISA), to learn a fixed-length vectorial representation by\nminimizing the reconstruction error. Specifically, we propose to integrate two\nclassical mechanisms for sequence reconstruction which takes into account both\nthe global silhouette information and the local temporal dependencies.\nFurthermore, we propose a stop feature that serves as a temporal stamp to guide\nthe reconstruction process, which results in a higher-quality representation.\nThe learned representation is able to effectively summarize not only the\napparent features, but also the underlying and high-level style information.\nTake for example a speech sequence sample: our ISA model can not only recognize\nthe spoken text (apparent feature), but can also discriminate the speaker who\nutters the audio (more high-level style). One promising application of the ISA\nmodel is that it can be readily used in the semi-supervised learning scenario,\nin which a large amount of unlabeled data is leveraged to extract high-quality\nsequence representations and thus to improve the performance of the subsequent\nsupervised learning tasks on limited labeled data.", "published": "2018-04-03T13:12:45Z", "version": 2}, {"aid": "1804.01050", "authors": ["Garoe Dorta", "Sara Vicente", "Lourdes Agapito", "Neill D. F. Campbell", "Ivor Simpson"], "title": "Training VAEs Under Structured Residuals", "url": "http://arxiv.org/pdf/1804.01050v3", "summary": "Variational auto-encoders (VAEs) are a popular and powerful deep generative\nmodel. Previous works on VAEs have assumed a factorized likelihood model,\nwhereby the output uncertainty of each pixel is assumed to be independent. This\napproximation is clearly limited as demonstrated by observing a residual image\nfrom a VAE reconstruction, which often possess a high level of structure. This\npaper demonstrates a novel scheme to incorporate a structured Gaussian\nlikelihood prediction network within the VAE that allows the residual\ncorrelations to be modeled. Our novel architecture, with minimal increase in\ncomplexity, incorporates the covariance matrix prediction within the VAE. We\nalso propose a new mechanism for allowing structured uncertainty on color\nimages. Furthermore, we provide a scheme for effectively training this model,\nand include some suggestions for improving performance in terms of efficiency\nor modeling longer range correlations.", "published": "2018-04-03T16:04:22Z", "version": 3}, {"aid": "1804.01128", "authors": ["Luis Piloto", "Ari Weinstein", "Dhruva TB", "Arun Ahuja", "Mehdi Mirza", "Greg Wayne", "David Amos", "Chia-chun Hung", "Matt Botvinick"], "title": "Probing Physics Knowledge Using Tools from Developmental Psychology", "url": "http://arxiv.org/pdf/1804.01128v1", "summary": "In order to build agents with a rich understanding of their environment, one\nkey objective is to endow them with a grasp of intuitive physics; an ability to\nreason about three-dimensional objects, their dynamic interactions, and\nresponses to forces. While some work on this problem has taken the approach of\nbuilding in components such as ready-made physics engines, other research aims\nto extract general physical concepts directly from sensory data. In the latter\ncase, one challenge that arises is evaluating the learning system. Research on\nintuitive physics knowledge in children has long employed a violation of\nexpectations (VOE) method to assess children's mastery of specific physical\nconcepts. We take the novel step of applying this method to artificial learning\nsystems. In addition to introducing the VOE technique, we describe a set of\nprobe datasets inspired by classic test stimuli from developmental psychology.\nWe test a baseline deep learning system on this battery, as well as on a\nphysics learning dataset (\"IntPhys\") recently posed by another research group.\nOur results show how the VOE technique may provide a useful tool for tracking\nphysics knowledge in future research.", "published": "2018-04-03T18:47:46Z", "version": 1}, {"aid": "1804.01144", "authors": ["Carlos Gershenson", "Vito Trianni", "Justin Werfel", "Hiroki Sayama"], "title": "Self-Organization and Artificial Life: A Review", "url": "http://arxiv.org/pdf/1804.01144v1", "summary": "Self-organization has been an important concept within a number of\ndisciplines, which Artificial Life (ALife) also has heavily utilized since its\ninception. The term and its implications, however, are often confusing or\nmisinterpreted. In this work, we provide a mini-review of self-organization and\nits relationship with ALife, aiming at initiating discussions on this important\ntopic with the interested audience. We first articulate some fundamental\naspects of self-organization, outline its usage, and review its applications to\nALife within its soft, hard, and wet domains. We also provide perspectives for\nfurther research.", "published": "2018-04-03T19:44:09Z", "version": 1}, {"aid": "1804.01159", "authors": ["Rajeev Ranjan", "Ankan Bansal", "Hongyu Xu", "Swami Sankaranarayanan", "Jun-Cheng Chen", "Carlos D. Castillo", "Rama Chellappa"], "title": "Crystal Loss and Quality Pooling for Unconstrained Face Verification and Recognition", "url": "http://arxiv.org/pdf/1804.01159v2", "summary": "In recent years, the performance of face verification and recognition systems\nbased on deep convolutional neural networks (DCNNs) has significantly improved.\nA typical pipeline for face verification includes training a deep network for\nsubject classification with softmax loss, using the penultimate layer output as\nthe feature descriptor, and generating a cosine similarity score given a pair\nof face images or videos. The softmax loss function does not optimize the\nfeatures to have higher similarity score for positive pairs and lower\nsimilarity score for negative pairs, which leads to a performance gap. In this\npaper, we propose a new loss function, called Crystal Loss, that restricts the\nfeatures to lie on a hypersphere of a fixed radius. The loss can be easily\nimplemented using existing deep learning frameworks. We show that integrating\nthis simple step in the training pipeline significantly improves the\nperformance of face verification and recognition systems. We achieve\nstate-of-the-art performance for face verification and recognition on\nchallenging LFW, IJB-A, IJB-B and IJB-C datasets over a large range of false\nalarm rates (10-1 to 10-7).", "published": "2018-04-03T20:30:25Z", "version": 2}, {"aid": "1804.01193", "authors": ["Bart Jacobs", "Fabio Zanasi"], "title": "The Logical Essentials of Bayesian Reasoning", "url": "http://arxiv.org/pdf/1804.01193v2", "summary": "This chapter offers an accessible introduction to the channel-based approach\nto Bayesian probability theory. This framework rests on algebraic and logical\nfoundations, inspired by the methodologies of programming language semantics.\nIt offers a uniform, structured and expressive language for describing Bayesian\nphenomena in terms of familiar programming concepts, like channel, predicate\ntransformation and state transformation. The introduction also covers inference\nin Bayesian networks, which will be modelled by a suitable calculus of string\ndiagrams.", "published": "2018-04-03T23:55:41Z", "version": 2}, {"aid": "1804.01508", "authors": ["Ole-Christoffer Granmo"], "title": "The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic", "url": "http://arxiv.org/pdf/1804.01508v15", "summary": "Although simple individually, artificial neurons provide state-of-the-art\nperformance when interconnected in deep networks. Arguably, the Tsetlin\nAutomaton is an even simpler and more versatile learning mechanism, capable of\nsolving the multi-armed bandit problem. Merely by means of a single integer as\nmemory, it learns the optimal action in stochastic environments through\nincrement and decrement operations. In this paper, we introduce the Tsetlin\nMachine, which solves complex pattern recognition problems with propositional\nformulas, composed by a collective of Tsetlin Automata. To eliminate the\nlongstanding problem of vanishing signal-to-noise ratio, the Tsetlin Machine\norchestrates the automata using a novel game. Further, both inputs, patterns,\nand outputs are expressed as bits, while recognition and learning rely on bit\nmanipulation, simplifying computation. Our theoretical analysis establishes\nthat the Nash equilibria of the game align with the propositional formulas that\nprovide optimal pattern recognition accuracy. This translates to learning\nwithout local optima, only global ones. In five benchmarks, the Tsetlin Machine\nprovides competitive accuracy compared with SVMs, Decision Trees, Random\nForests, Naive Bayes Classifier, Logistic Regression, and Neural Networks. We\nfurther demonstrate how the propositional formulas facilitate interpretation.\nIn conclusion, we believe the combination of high accuracy, interpretability,\nand computational simplicity makes the Tsetlin Machine a promising tool for a\nwide range of domains.", "published": "2018-04-04T16:52:34Z", "version": 15}, {"aid": "1804.02307", "authors": ["Ganesh Sundaramoorthi", "Anthony Yezzi"], "title": "Accelerated Optimization in the PDE Framework: Formulations for the Manifold of Diffeomorphisms", "url": "http://arxiv.org/pdf/1804.02307v2", "summary": "We consider the problem of optimization of cost functionals on the\ninfinite-dimensional manifold of diffeomorphisms. We present a new class of\noptimization methods, valid for any optimization problem setup on the space of\ndiffeomorphisms by generalizing Nesterov accelerated optimization to the\nmanifold of diffeomorphisms. While our framework is general for infinite\ndimensional manifolds, we specifically treat the case of diffeomorphisms,\nmotivated by optical flow problems in computer vision. This is accomplished by\nbuilding on a recent variational approach to a general class of accelerated\noptimization methods by Wibisono, Wilson and Jordan, which applies in finite\ndimensions. We generalize that approach to infinite dimensional manifolds. We\nderive the surprisingly simple continuum evolution equations, which are partial\ndifferential equations, for accelerated gradient descent, and relate it to\nsimple mechanical principles from fluid mechanics. Our approach has natural\nconnections to the optimal mass transport problem. This is because one can\nthink of our approach as an evolution of an infinite number of particles\nendowed with mass (represented with a mass density) that moves in an energy\nlandscape. The mass evolves with the optimization variable, and endows the\nparticles with dynamics. This is different than the finite dimensional case\nwhere only a single particle moves and hence the dynamics does not depend on\nthe mass. We derive the theory, compute the PDEs for accelerated optimization,\nand illustrate the behavior of these new accelerated optimization schemes.", "published": "2018-04-04T19:58:03Z", "version": 2}, {"aid": "1804.01654", "authors": ["Nanyang Wang", "Yinda Zhang", "Zhuwen Li", "Yanwei Fu", "Wei Liu", "Yu-Gang Jiang"], "title": "Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images", "url": "http://arxiv.org/pdf/1804.01654v2", "summary": "We propose an end-to-end deep learning architecture that produces a 3D shape\nin triangular mesh from a single color image. Limited by the nature of deep\nneural network, previous methods usually represent a 3D shape in volume or\npoint cloud, and it is non-trivial to convert them to the more ready-to-use\nmesh model. Unlike the existing methods, our network represents 3D mesh in a\ngraph-based convolutional neural network and produces correct geometry by\nprogressively deforming an ellipsoid, leveraging perceptual features extracted\nfrom the input image. We adopt a coarse-to-fine strategy to make the whole\ndeformation procedure stable, and define various of mesh related losses to\ncapture properties of different levels to guarantee visually appealing and\nphysically accurate 3D geometry. Extensive experiments show that our method not\nonly qualitatively produces mesh model with better details, but also achieves\nhigher 3D shape estimation accuracy compared to the state-of-the-art.", "published": "2018-04-05T02:24:03Z", "version": 2}, {"aid": "1804.01661", "authors": ["Xin Yu", "Zhiding Yu", "Srikumar Ramalingam"], "title": "Learning Strict Identity Mappings in Deep Residual Networks", "url": "http://arxiv.org/pdf/1804.01661v5", "summary": "A family of super deep networks, referred to as residual networks or ResNet,\nachieved record-beating performance in various visual tasks such as image\nrecognition, object detection, and semantic segmentation. The ability to train\nvery deep networks naturally pushed the researchers to use enormous resources\nto achieve the best performance. Consequently, in many applications super deep\nresidual networks were employed for just a marginal improvement in performance.\nIn this paper, we propose epsilon-ResNet that allows us to automatically\ndiscard redundant layers, which produces responses that are smaller than a\nthreshold epsilon, with a marginal or no loss in performance. The\nepsilon-ResNet architecture can be achieved using a few additional rectified\nlinear units in the original ResNet. Our method does not use any additional\nvariables nor numerous trials like other hyper-parameter optimization\ntechniques. The layer selection is achieved using a single training process and\nthe evaluation is performed on CIFAR-10, CIFAR-100, SVHN, and ImageNet\ndatasets. In some instances, we achieve about 80% reduction in the number of\nparameters.", "published": "2018-04-05T03:19:53Z", "version": 5}, {"aid": "1804.02276", "authors": ["Fay\u00e7al Ait Aoudia", "Jakob Hoydis"], "title": "End-to-End Learning of Communications Systems Without a Channel Model", "url": "http://arxiv.org/pdf/1804.02276v3", "summary": "The idea of end-to-end learning of communications systems through neural\nnetwork -based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm iterates between\nsupervised training of the receiver and reinforcement learning -based training\nof the transmitter. We demonstrate that this approach works as well as fully\nsupervised methods on additive white Gaussian noise (AWGN) and Rayleigh\nblock-fading (RBF) channels. Surprisingly, while our method converges slower on\nAWGN channels than supervised training, it converges faster on RBF channels.\nOur results are a first step towards learning of communications systems over\nany type of channel without prior assumptions.", "published": "2018-04-06T14:01:00Z", "version": 3}, {"aid": "1804.02477", "authors": ["Abhinav Verma", "Vijayaraghavan Murali", "Rishabh Singh", "Pushmeet Kohli", "Swarat Chaudhuri"], "title": "Programmatically Interpretable Reinforcement Learning", "url": "http://arxiv.org/pdf/1804.02477v3", "summary": "We present a reinforcement learning framework, called Programmatically\nInterpretable Reinforcement Learning (PIRL), that is designed to generate\ninterpretable and verifiable agent policies. Unlike the popular Deep\nReinforcement Learning (DRL) paradigm, which represents policies by neural\nnetworks, PIRL represents policies using a high-level, domain-specific\nprogramming language. Such programmatic policies have the benefits of being\nmore easily interpreted than neural networks, and being amenable to\nverification by symbolic methods. We propose a new method, called Neurally\nDirected Program Search (NDPS), for solving the challenging nonsmooth\noptimization problem of finding a programmatic policy with maximal reward. NDPS\nworks by first learning a neural policy network using DRL, and then performing\na local search over programmatic policies that seeks to minimize a distance\nfrom this neural \"oracle\". We evaluate NDPS on the task of learning to drive a\nsimulated car in the TORCS car-racing environment. We demonstrate that NDPS is\nable to discover human-readable policies that pass some significant performance\nbars. We also show that PIRL policies can have smoother trajectories, and can\nbe more easily transferred to environments not encountered during training,\nthan corresponding policies discovered by DRL.", "published": "2018-04-06T22:17:18Z", "version": 3}, {"aid": "1804.02698", "authors": ["Takumi Ichimura", "Daisuke Igaue"], "title": "Hierarchical Modular Reinforcement Learning Method and Knowledge Acquisition of State-Action Rule for Multi-target Problem", "url": "http://arxiv.org/pdf/1804.02698v1", "summary": "Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.", "published": "2018-04-08T14:39:13Z", "version": 1}, {"aid": "1804.02767", "authors": ["Joseph Redmon", "Ali Farhadi"], "title": "YOLOv3: An Incremental Improvement", "url": "http://arxiv.org/pdf/1804.02767v1", "summary": "We present some updates to YOLO! We made a bunch of little design changes to\nmake it better. We also trained this new network that's pretty swell. It's a\nlittle bigger than last time but more accurate. It's still fast though, don't\nworry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but\nthree times faster. When we look at the old .5 IOU mAP detection metric YOLOv3\nis quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5\nmAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always,\nall the code is online at https://pjreddie.com/yolo/", "published": "2018-04-08T22:27:57Z", "version": 1}, {"aid": "1804.02913", "authors": ["Kuldeep Purohit", "Anshul Shah", "A. N. Rajagopalan"], "title": "Bringing Alive Blurred Moments", "url": "http://arxiv.org/pdf/1804.02913v2", "summary": "We present a solution for the goal of extracting a video from a single motion\nblurred image to sequentially reconstruct the clear views of a scene as beheld\nby the camera during the time of exposure. We first learn motion representation\nfrom sharp videos in an unsupervised manner through training of a convolutional\nrecurrent video autoencoder network that performs a surrogate task of video\nreconstruction. Once trained, it is employed for guided training of a motion\nencoder for blurred images. This network extracts embedded motion information\nfrom the blurred image to generate a sharp video in conjunction with the\ntrained recurrent video decoder. As an intermediate step, we also design an\nefficient architecture that enables real-time single image deblurring and\noutperforms competing methods across all factors: accuracy, speed, and\ncompactness. Experiments on real scenes and standard datasets demonstrate the\nsuperiority of our framework over the state-of-the-art and its ability to\ngenerate a plausible sequence of temporally consistent sharp frames.", "published": "2018-04-09T11:14:32Z", "version": 2}, {"aid": "1804.02952", "authors": ["J. H. van Hateren"], "title": "A theory of consciousness: computation, algorithm, and neurobiological realization", "url": "http://arxiv.org/pdf/1804.02952v4", "summary": "The most enigmatic aspect of consciousness is the fact that it is felt, as a\nsubjective sensation. The theory proposed here aims to explain this particular\naspect. The theory encompasses both the computation that is presumably involved\nand the way in which that computation may be realized in the brain's\nneurobiology. It is assumed that the brain makes an internal estimate of an\nindividual's own evolutionary fitness, which can be shown to produce a special,\ndistinct form of causation. Communicating components of the fitness estimate\n(either for external or internal use) requires inverting them. Such inversion\ncan be performed by the thalamocortical feedback loop in the mammalian brain,\nif that loop is operating in a switched, dual-stage mode. A first\n(nonconscious) stage produces forward estimates, whereas the second (conscious)\nstage inverts those estimates. It is argued that inversion produces another\nspecial, distinct form of causation, which is spatially localized and is\nplausibly sensed as the feeling of consciousness.", "published": "2018-04-09T13:02:35Z", "version": 4}, {"aid": "1804.02967", "authors": ["Jose Dolz", "Karthik Gopinath", "Jing Yuan", "Herve Lombaert", "Christian Desrosiers", "Ismail Ben Ayed"], "title": "HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation", "url": "http://arxiv.org/pdf/1804.02967v2", "summary": "Recently, dense connections have attracted substantial attention in computer\nvision because they facilitate gradient flow and implicit deep supervision\nduring training. Particularly, DenseNet, which connects each layer to every\nother layer in a feed-forward fashion, has shown impressive performances in\nnatural image classification tasks. We propose HyperDenseNet, a 3D fully\nconvolutional neural network that extends the definition of dense connectivity\nto multi-modal segmentation problems. Each imaging modality has a path, and\ndense connections occur not only between the pairs of layers within the same\npath, but also between those across different paths. This contrasts with the\nexisting multi-modal CNN approaches, in which modeling several modalities\nrelies entirely on a single joint layer (or level of abstraction) for fusion,\ntypically either at the input or at the output of the network. Therefore, the\nproposed network has total freedom to learn more complex combinations between\nthe modalities, within and in-between all the levels of abstraction, which\nincreases significantly the learning representation. We report extensive\nevaluations over two different and highly competitive multi-modal brain tissue\nsegmentation challenges, iSEG 2017 and MRBrainS 2013, with the former focusing\non 6-month infant data and the latter on adult images. HyperDenseNet yielded\nsignificant improvements over many state-of-the-art segmentation networks,\nranking at the top on both benchmarks. We further provide a comprehensive\nexperimental analysis of features re-use, which confirms the importance of\nhyper-dense connections in multi-modal representation learning. Our code is\npublicly available at https://www.github.com/josedolz/HyperDenseNet.", "published": "2018-04-09T13:26:13Z", "version": 2}, {"aid": "1804.02969", "authors": ["Tom\u00e1\u0161 Kliegr", "\u0160t\u011bp\u00e1n Bahn\u00edk", "Johannes F\u00fcrnkranz"], "title": "A review of possible effects of cognitive biases on the interpretation of rule-based machine learning models", "url": "http://arxiv.org/pdf/1804.02969v7", "summary": "While the interpretability of machine learning models is often equated with\ntheir mere syntactic comprehensibility, we think that interpretability goes\nbeyond that, and that human interpretability should also be investigated from\nthe point of view of cognitive science. The goal of this paper is to discuss to\nwhat extent cognitive biases may affect human understanding of interpretable\nmachine learning models, in particular of logical rules discovered from data.\nTwenty cognitive biases are covered, as are possible debiasing techniques that\ncan be adopted by designers of machine learning algorithms and software. Our\nreview transfers results obtained in cognitive psychology to the domain of\nmachine learning, aiming to bridge the current gap between these two areas. It\nneeds to be followed by empirical studies specifically focused on the machine\nlearning domain.", "published": "2018-04-09T13:28:56Z", "version": 7}, {"aid": "1804.03313", "authors": ["Liyao Gao"], "title": "Cortex Neural Network: learning with Neural Network groups", "url": "http://arxiv.org/pdf/1804.03313v1", "summary": "Neural Network has been successfully applied to many real-world problems,\nsuch as image recognition and machine translation. However, for the current\narchitecture of neural networks, it is hard to perform complex cognitive tasks,\nfor example, to process the image and audio inputs together. Cortex, as an\nimportant architecture in the brain, is important for animals to perform the\ncomplex cognitive task. We view the architecture of Cortex in the brain as a\nmissing part in the design of the current artificial neural network. In this\npaper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is\nan upper architecture of neural networks which motivated from cerebral cortex\nin the brain to handle different tasks in the same learning system. It is able\nto identify different tasks and solve them with different methods. In our\nimplementation, the Cortex Neural Network is able to process different\ncognitive tasks and perform reflection to get a higher accuracy. We provide a\nseries of experiments to examine the capability of the cortex architecture on\ntraditional neural networks. Our experiments proved its ability on the Cortex\nNeural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the\nsame time, which can promisingly reduce the loss by 40%.", "published": "2018-04-10T02:33:47Z", "version": 1}, {"aid": "1804.03368", "authors": ["Dong Gong", "Zhen Zhang", "Qinfeng Shi", "Anton van den Hengel", "Chunhua Shen", "Yanning Zhang"], "title": "Learning Deep Gradient Descent Optimization for Image Deconvolution", "url": "http://arxiv.org/pdf/1804.03368v2", "summary": "As an integral component of blind image deblurring, non-blind deconvolution\nremoves image blur with a given blur kernel, which is essential but difficult\ndue to the ill-posed nature of the inverse problem. The predominant approach is\nbased on optimization subject to regularization functions that are either\nmanually designed, or learned from examples. Existing learning based methods\nhave shown superior restoration quality but are not practical enough due to\ntheir restricted and static model design. They solely focus on learning a prior\nand require to know the noise level for deconvolution. We address the gap\nbetween the optimization-based and learning-based approaches by learning a\nuniversal gradient descent optimizer. We propose a Recurrent Gradient Descent\nNetwork (RGDN) by systematically incorporating deep neural networks into a\nfully parameterized gradient descent scheme. A hyper-parameter-free update unit\nshared across steps is used to generate updates from the current estimates,\nbased on a convolutional neural network. By training on diverse examples, the\nRecurrent Gradient Descent Network learns an implicit image prior and a\nuniversal update rule through recursive supervision. The learned optimizer can\nbe repeatedly used to improve the quality of diverse degenerated observations.\nThe proposed method possesses strong interpretability and high generalization.\nExtensive experiments on synthetic benchmarks and challenging real-world images\ndemonstrate that the proposed deep optimization method is effective and robust\nto produce favorable results as well as practical for real-world image\ndeblurring applications.", "published": "2018-04-10T06:58:12Z", "version": 2}, {"aid": "1804.03439", "authors": ["Wojciech Skaba"], "title": "Evaluating Actuators in a Purely Information-Theory Based Reward Model", "url": "http://arxiv.org/pdf/1804.03439v1", "summary": "AGINAO builds its cognitive engine by applying self-programming techniques to\ncreate a hierarchy of interconnected codelets - the tiny pieces of code\nexecuted on a virtual machine. These basic processing units are evaluated for\ntheir applicability and fitness with a notion of reward calculated from\nself-information gain of binary partitioning of the codelet's input\nstate-space. This approach, however, is useless for the evaluation of\nactuators. Instead, a model is proposed in which actuators are evaluated by\nmeasuring the impact that an activation of an effector, and consequently the\nfeedback from the robot sensors, has on average reward received by the\nprocessing units.", "published": "2018-04-10T10:34:36Z", "version": 1}, {"aid": "1804.04512", "authors": ["Baptiste Wicht", "Jean Hennebert", "Andreas Fischer"], "title": "DLL: A Blazing Fast Deep Neural Network Library", "url": "http://arxiv.org/pdf/1804.04512v1", "summary": "Deep Learning Library (DLL) is a new library for machine learning with deep\nneural networks that focuses on speed. It supports feed-forward neural networks\nsuch as fully-connected Artificial Neural Networks (ANNs) and Convolutional\nNeural Networks (CNNs). It also has very comprehensive support for Restricted\nBoltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this\nwork was to propose and evaluate novel software engineering strategies with\npotential to accelerate runtime for training and inference. Such strategies are\nmostly independent of the underlying deep learning algorithms. On three\ndifferent datasets and for four different neural network models, we compared\nDLL to five popular deep learning frameworks. Experimentally, it is shown that\nthe proposed framework is systematically and significantly faster on CPU and\nGPU. In terms of classification performance, similar accuracies as the other\nframeworks are reported.", "published": "2018-04-11T13:56:07Z", "version": 1}, {"aid": "1804.03999", "authors": ["Ozan Oktay", "Jo Schlemper", "Loic Le Folgoc", "Matthew Lee", "Mattias Heinrich", "Kazunari Misawa", "Kensaku Mori", "Steven McDonagh", "Nils Y Hammerla", "Bernhard Kainz", "Ben Glocker", "Daniel Rueckert"], "title": "Attention U-Net: Learning Where to Look for the Pancreas", "url": "http://arxiv.org/pdf/1804.03999v3", "summary": "We propose a novel attention gate (AG) model for medical imaging that\nautomatically learns to focus on target structures of varying shapes and sizes.\nModels trained with AGs implicitly learn to suppress irrelevant regions in an\ninput image while highlighting salient features useful for a specific task.\nThis enables us to eliminate the necessity of using explicit external\ntissue/organ localisation modules of cascaded convolutional neural networks\n(CNNs). AGs can be easily integrated into standard CNN architectures such as\nthe U-Net model with minimal computational overhead while increasing the model\nsensitivity and prediction accuracy. The proposed Attention U-Net architecture\nis evaluated on two large CT abdominal datasets for multi-class image\nsegmentation. Experimental results show that AGs consistently improve the\nprediction performance of U-Net across different datasets and training sizes\nwhile preserving computational efficiency. The code for the proposed\narchitecture is publicly available.", "published": "2018-04-11T14:13:03Z", "version": 3}, {"aid": "1804.04020", "authors": ["Keiller Nogueira", "Mauro Dalla Mura", "Jocelyn Chanussot", "William R. Schwartz", "Jefersson A. dos Santos"], "title": "Dynamic Multi-Context Segmentation of Remote Sensing Images based on Convolutional Networks", "url": "http://arxiv.org/pdf/1804.04020v3", "summary": "Semantic segmentation requires methods capable of learning high-level\nfeatures while dealing with large volume of data. Towards such goal,\nConvolutional Networks can learn specific and adaptable features based on the\ndata. However, these networks are not capable of processing a whole remote\nsensing image, given its huge size. To overcome such limitation, the image is\nprocessed using fixed size patches. The definition of the input patch size is\nusually performed empirically (evaluating several sizes) or imposed (by network\nconstraint). Both strategies suffer from drawbacks and could not lead to the\nbest patch size. To alleviate this problem, several works exploited\nmulti-context information by combining networks or layers. This process\nincreases the number of parameters resulting in a more difficult model to\ntrain. In this work, we propose a novel technique to perform semantic\nsegmentation of remote sensing images that exploits a multi-context paradigm\nwithout increasing the number of parameters while defining, in training time,\nthe best patch size. The main idea is to train a dilated network with distinct\npatch sizes, allowing it to capture multi-context characteristics from\nheterogeneous contexts. While processing these varying patches, the network\nprovides a score for each patch size, helping in the definition of the best\nsize for the current scenario. A systematic evaluation of the proposed\nalgorithm is conducted using four high-resolution remote sensing datasets with\nvery distinct properties. Our results show that the proposed algorithm provides\nimprovements in pixelwise classification accuracy when compared to\nstate-of-the-art methods.", "published": "2018-04-11T14:32:15Z", "version": 3}, {"aid": "1804.04192", "authors": ["Naifan Zhuang", "The Duc Kieu", "Guo-Jun Qi", "Kien A. Hua"], "title": "Deep Differential Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1804.04192v1", "summary": "Due to the special gating schemes of Long Short-Term Memory (LSTM), LSTMs\nhave shown greater potential to process complex sequential information than the\ntraditional Recurrent Neural Network (RNN). The conventional LSTM, however,\nfails to take into consideration the impact of salient spatio-temporal dynamics\npresent in the sequential input data. This problem was first addressed by the\ndifferential Recurrent Neural Network (dRNN), which uses a differential gating\nscheme known as Derivative of States (DoS). DoS uses higher orders of internal\nstate derivatives to analyze the change in information gain caused by the\nsalient motions between the successive frames. The weighted combination of\nseveral orders of DoS is then used to modulate the gates in dRNN. While each\nindividual order of DoS is good at modeling a certain level of salient\nspatio-temporal sequences, the sum of all the orders of DoS could distort the\ndetected motion patterns. To address this problem, we propose to control the\nLSTM gates via individual orders of DoS and stack multiple levels of LSTM cells\nin an increasing order of state derivatives. The proposed model progressively\nbuilds up the ability of the LSTM gates to detect salient dynamical patterns in\ndeeper stacked layers modeling higher orders of DoS, and thus the proposed LSTM\nmodel is termed deep differential Recurrent Neural Network (d2RNN). The\neffectiveness of the proposed model is demonstrated on two publicly available\nhuman activity datasets: NUS-HGA and Violent-Flows. The proposed model\noutperforms both LSTM and non-LSTM based state-of-the-art algorithms.", "published": "2018-04-11T20:02:25Z", "version": 1}, {"aid": "1804.04235", "authors": ["Noam Shazeer", "Mitchell Stern"], "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost", "url": "http://arxiv.org/pdf/1804.04235v1", "summary": "In several recently proposed stochastic optimization methods (e.g. RMSProp,\nAdam, Adadelta), parameter updates are scaled by the inverse square roots of\nexponential moving averages of squared past gradients. Maintaining these\nper-parameter second-moment estimators requires memory equal to the number of\nparameters. For the case of neural network weight matrices, we propose\nmaintaining only the per-row and per-column sums of these moving averages, and\nestimating the per-parameter second moments based on these sums. We demonstrate\nempirically that this method produces similar results to the baseline.\nSecondly, we show that adaptive methods can produce larger-than-desired updates\nwhen the decay rate of the second moment accumulator is too slow. We propose\nupdate clipping and a gradually increasing decay rate scheme as remedies.\nCombining these methods and dropping momentum, we achieve comparable results to\nthe published Adam regime in training the Transformer model on the WMT 2014\nEnglish-German machine translation task, while using very little auxiliary\nstorage in the optimizer. Finally, we propose scaling the parameter updates\nbased on the scale of the parameters themselves.", "published": "2018-04-11T21:42:32Z", "version": 1}, {"aid": "1804.04438", "authors": ["Avraham Ruderman", "Neil C. Rabinowitz", "Ari S. Morcos", "Daniel Zoran"], "title": "Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs", "url": "http://arxiv.org/pdf/1804.04438v2", "summary": "Many of our core assumptions about how neural networks operate remain\nempirically untested. One common assumption is that convolutional neural\nnetworks need to be stable to small translations and deformations to solve\nimage recognition tasks. For many years, this stability was baked into CNN\narchitectures by incorporating interleaved pooling layers. Recently, however,\ninterleaved pooling has largely been abandoned. This raises a number of\nquestions: Are our intuitions about deformation stability right at all? Is it\nimportant? Is pooling necessary for deformation invariance? If not, how is\ndeformation invariance achieved in its absence? In this work, we rigorously\ntest these questions, and find that deformation stability in convolutional\nnetworks is more nuanced than it first appears: (1) Deformation invariance is\nnot a binary property, but rather that different tasks require different\ndegrees of deformation stability at different layers. (2) Deformation stability\nis not a fixed property of a network and is heavily adjusted over the course of\ntraining, largely through the smoothness of the convolutional filters. (3)\nInterleaved pooling layers are neither necessary nor sufficient for achieving\nthe optimal form of deformation stability for natural image classification. (4)\nPooling confers too much deformation stability for image classification at\ninitialization, and during training, networks have to learn to counteract this\ninductive bias. Together, these findings provide new insights into the role of\ninterleaved pooling and deformation invariance in CNNs, and demonstrate the\nimportance of rigorous empirical testing of even our most basic assumptions\nabout the working of neural networks.", "published": "2018-04-12T11:44:05Z", "version": 2}, {"aid": "1804.04694", "authors": ["Patrick Esser", "Ekaterina Sutter", "Bj\u00f6rn Ommer"], "title": "A Variational U-Net for Conditional Appearance and Shape Generation", "url": "http://arxiv.org/pdf/1804.04694v1", "summary": "Deep generative models have demonstrated great performance in image\nsynthesis. However, results deteriorate in case of spatial deformations, since\nthey generate images of objects directly, rather than modeling the intricate\ninterplay of their inherent shape and appearance. We present a conditional\nU-Net for shape-guided image generation, conditioned on the output of a\nvariational autoencoder for appearance. The approach is trained end-to-end on\nimages, without requiring samples of the same object with varying pose or\nappearance. Experiments show that the model enables conditional image\ngeneration and transfer. Therefore, either shape or appearance can be retained\nfrom a query image, while freely altering the other. Moreover, appearance can\nbe sampled due to its stochastic latent representation, while preserving shape.\nIn quantitative and qualitative experiments on COCO, DeepFashion, shoes,\nMarket-1501 and handbags, the approach demonstrates significant improvements\nover the state-of-the-art.", "published": "2018-04-12T19:05:57Z", "version": 1}, {"aid": "1804.05012", "authors": ["Peter L. Bartlett", "Steven N. Evans", "Philip M. Long"], "title": "Representing smooth functions as compositions of near-identity functions with implications for deep network optimization", "url": "http://arxiv.org/pdf/1804.05012v2", "summary": "We show that any smooth bi-Lipschitz $h$ can be represented exactly as a\ncomposition $h_m \\circ ... \\circ h_1$ of functions $h_1,...,h_m$ that are close\nto the identity in the sense that each $\\left(h_i-\\mathrm{Id}\\right)$ is\nLipschitz, and the Lipschitz constant decreases inversely with the number $m$\nof functions composed. This implies that $h$ can be represented to any accuracy\nby a deep residual network whose nonlinear layers compute functions with a\nsmall Lipschitz constant. Next, we consider nonlinear regression with a\ncomposition of near-identity nonlinear maps. We show that, regarding Fr\\'echet\nderivatives with respect to the $h_1,...,h_m$, any critical point of a\nquadratic criterion in this near-identity region must be a global minimizer. In\ncontrast, if we consider derivatives with respect to parameters of a fixed-size\nresidual network with sigmoid activation functions, we show that there are\nnear-identity critical points that are suboptimal, even in the realizable case.\nInformally, this means that functional gradient methods for residual networks\ncannot get stuck at suboptimal critical points corresponding to near-identity\nlayers, whereas parametric gradient methods for sigmoidal residual networks\nsuffer from suboptimal critical points in the near-identity region.", "published": "2018-04-13T16:24:17Z", "version": 2}, {"aid": "1804.05181", "authors": ["Saeid Asgari Taghanaki", "Aicha Bentaieb", "Anmol Sharma", "S. Kevin Zhou", "Yefeng Zheng", "Bogdan Georgescu", "Puneet Sharma", "Sasa Grbic", "Zhoubing Xu", "Dorin Comaniciu", "Ghassan Hamarneh"], "title": "Select, Attend, and Transfer: Light, Learnable Skip Connections", "url": "http://arxiv.org/pdf/1804.05181v3", "summary": "Skip connections in deep networks have improved both segmentation and\nclassification performance by facilitating the training of deeper network\narchitectures, and reducing the risks for vanishing gradients. They equip\nencoder-decoder-like networks with richer feature representations, but at the\ncost of higher memory usage, computation, and possibly resulting in\ntransferring non-discriminative feature maps. In this paper, we focus on\nimproving skip connections used in segmentation networks (e.g., U-Net, V-Net,\nand The One Hundred Layers Tiramisu (DensNet) architectures). We propose light,\nlearnable skip connections which learn to first select the most discriminative\nchannels and then attend to the most discriminative regions of the selected\nfeature maps. The output of the proposed skip connections is a unique feature\nmap which not only reduces the memory usage and network parameters to a high\nextent, but also improves segmentation accuracy. We evaluate the proposed\nmethod on three different 2D and volumetric datasets and demonstrate that the\nproposed light, learnable skip connections can outperform the traditional heavy\nskip connections in terms of segmentation accuracy, memory usage, and number of\nnetwork parameters.", "published": "2018-04-14T07:30:15Z", "version": 3}, {"aid": "1804.05340", "authors": ["Wenqi Liu", "Kun Zeng"], "title": "SparseNet: A Sparse DenseNet for Image Classification", "url": "http://arxiv.org/pdf/1804.05340v1", "summary": "Deep neural networks have made remarkable progresses on various computer\nvision tasks. Recent works have shown that depth, width and shortcut\nconnections of networks are all vital to their performances. In this paper, we\nintroduce a method to sparsify DenseNet which can reduce connections of a\nL-layer DenseNet from O(L^2) to O(L), and thus we can simultaneously increase\ndepth, width and connections of neural networks in a more parameter-efficient\nand computation-efficient way. Moreover, an attention module is introduced to\nfurther boost our network's performance. We denote our network as SparseNet. We\nevaluate SparseNet on datasets of CIFAR(including CIFAR10 and CIFAR100) and\nSVHN. Experiments show that SparseNet can obtain improvements over the\nstate-of-the-art on CIFAR10 and SVHN. Furthermore, while achieving comparable\nperformances as DenseNet on these datasets, SparseNet is x2.6 smaller and x3.7\nfaster than the original DenseNet.", "published": "2018-04-15T11:29:30Z", "version": 1}, {"aid": "1804.05839", "authors": ["Jason Dai", "Yiheng Wang", "Xin Qiu", "Ding Ding", "Yao Zhang", "Yanzhang Wang", "Xianyan Jia", "Cherry Zhang", "Yan Wan", "Zhichao Li", "Jiao Wang", "Shengsheng Huang", "Zhongyuan Wu", "Yang Wang", "Yuhao Yang", "Bowen She", "Dongjie Shi", "Qi Lu", "Kai Huang", "Guoqiong Song"], "title": "BigDL: A Distributed Deep Learning Framework for Big Data", "url": "http://arxiv.org/pdf/1804.05839v4", "summary": "This paper presents BigDL (a distributed deep learning framework for Apache\nSpark), which has been used by a variety of users in the industry for building\ndeep learning applications on production big data platforms. It allows deep\nlearning applications to run on the Apache Hadoop/Spark cluster so as to\ndirectly process the production data, and as a part of the end-to-end data\nanalysis pipeline for deployment and management. Unlike existing deep learning\nframeworks, BigDL implements distributed, data parallel training directly on\ntop of the functional compute model (with copy-on-write and coarse-grained\noperations) of Spark. We also share real-world experience and \"war stories\" of\nusers that have adopted BigDL to address their challenges(i.e., how to easily\nbuild end-to-end data analysis and deep learning pipelines for their production\ndata).", "published": "2018-04-16T12:04:03Z", "version": 4}, {"aid": "1804.06114", "authors": ["Cong Chen", "Kim Batselier", "Ching-Yun Ko", "Ngai Wong"], "title": "A Support Tensor Train Machine", "url": "http://arxiv.org/pdf/1804.06114v1", "summary": "There has been growing interest in extending traditional vector-based machine\nlearning techniques to their tensor forms. An example is the support tensor\nmachine (STM) that utilizes a rank-one tensor to capture the data structure,\nthereby alleviating the overfitting and curse of dimensionality problems in the\nconventional support vector machine (SVM). However, the expressive power of a\nrank-one tensor is restrictive for many real-world data. To overcome this\nlimitation, we introduce a support tensor train machine (STTM) by replacing the\nrank-one tensor in an STM with a tensor train. Experiments validate and confirm\nthe superiority of an STTM over the SVM and STM.", "published": "2018-04-17T08:59:13Z", "version": 1}, {"aid": "1804.06458", "authors": ["Guillaume Baudart", "Martin Hirzel", "Louis Mandel"], "title": "Deep Probabilistic Programming Languages: A Qualitative Study", "url": "http://arxiv.org/pdf/1804.06458v1", "summary": "Deep probabilistic programming languages try to combine the advantages of\ndeep learning with those of probabilistic programming languages. If successful,\nthis would be a big step forward in machine learning and programming languages.\nUnfortunately, as of now, this new crop of languages is hard to use and\nunderstand. This paper addresses this problem directly by explaining deep\nprobabilistic programming languages and indirectly by characterizing their\ncurrent strengths and weaknesses.", "published": "2018-04-17T20:03:25Z", "version": 1}, {"aid": "1804.06655", "authors": ["Mei Wang", "Weihong Deng"], "title": "Deep Face Recognition: A Survey", "url": "http://arxiv.org/pdf/1804.06655v9", "summary": "Deep learning applies multiple processing layers to learn representations of\ndata with multiple levels of feature extraction. This emerging technique has\nreshaped the research landscape of face recognition (FR) since 2014, launched\nby the breakthroughs of DeepFace and DeepID. Since then, deep learning\ntechnique, characterized by the hierarchical architecture to stitch together\npixels into invariant face representation, has dramatically improved the\nstate-of-the-art performance and fostered successful real-world applications.\nIn this survey, we provide a comprehensive review of the recent developments on\ndeep FR, covering broad topics on algorithm designs, databases, protocols, and\napplication scenes. First, we summarize different network architectures and\nloss functions proposed in the rapid evolution of the deep FR methods. Second,\nthe related face processing methods are categorized into two classes:\n\"one-to-many augmentation\" and \"many-to-one normalization\". Then, we summarize\nand compare the commonly used databases for both model training and evaluation.\nThird, we review miscellaneous scenes in deep FR, such as cross-factor,\nheterogenous, multiple-media and industrial scenes. Finally, the technical\nchallenges and several promising directions are highlighted.", "published": "2018-04-18T11:20:32Z", "version": 9}, {"aid": "1804.07090", "authors": ["Amartya Sanyal", "Varun Kanade", "Philip H. S. Torr", "Puneet K. Dokania"], "title": "Robustness via Deep Low-Rank Representations", "url": "http://arxiv.org/pdf/1804.07090v5", "summary": "We investigate the effect of the dimensionality of the representations\nlearned in Deep Neural Networks (DNNs) on their robustness to input\nperturbations, both adversarial and random. To achieve low dimensionality of\nlearned representations, we propose an easy-to-use, end-to-end trainable,\nlow-rank regularizer (LR) that can be applied to any intermediate layer\nrepresentation of a DNN. This regularizer forces the feature representations to\n(mostly) lie in a low-dimensional linear subspace. We perform a wide range of\nexperiments that demonstrate that the LR indeed induces low rank on the\nrepresentations, while providing modest improvements to accuracy as an added\nbenefit. Furthermore, the learned features make the trained model significantly\nmore robust to input perturbations such as Gaussian and adversarial noise (even\nwithout adversarial training). Lastly, the low-dimensionality means that the\nlearned features are highly compressible; thus discriminative features of the\ndata can be stored using very little memory. Our experiments indicate that\nmodels trained using the LR learn robust classifiers by discovering subspaces\nthat avoid non-robust features. Algorithmically, the LR is scalable, generic,\nand straightforward to implement into existing deep learning frameworks.", "published": "2018-04-19T11:17:41Z", "version": 5}, {"aid": "1804.07345", "authors": ["Sanjeel Parekh", "Slim Essid", "Alexey Ozerov", "Ngoc Q. K. Duong", "Patrick P\u00e9rez", "Ga\u00ebl Richard"], "title": "Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events", "url": "http://arxiv.org/pdf/1804.07345v2", "summary": "Audio-visual representation learning is an important task from the\nperspective of designing machines with the ability to understand complex\nevents. To this end, we propose a novel multimodal framework that instantiates\nmultiple instance learning. We show that the learnt representations are useful\nfor classifying events and localizing their characteristic audio-visual\nelements. The system is trained using only video-level event labels without any\ntiming information. An important feature of our method is its capacity to learn\nfrom unsynchronized audio-visual events. We achieve state-of-the-art results on\na large-scale dataset of weakly-labeled audio event videos. Visualizations of\nlocalized visual regions and audio segments substantiate our system's efficacy,\nespecially when dealing with noisy situations where modality-specific cues\nappear asynchronously.", "published": "2018-04-19T19:33:11Z", "version": 2}, {"aid": "1804.07612", "authors": ["Dominic Masters", "Carlo Luschi"], "title": "Revisiting Small Batch Training for Deep Neural Networks", "url": "http://arxiv.org/pdf/1804.07612v1", "summary": "Modern deep neural network training is typically based on mini-batch\nstochastic gradient optimization. While the use of large mini-batches increases\nthe available computational parallelism, small batch training has been shown to\nprovide improved generalization performance and allows a significantly smaller\nmemory footprint, which might also be exploited to improve machine throughput.\n  In this paper, we review common assumptions on learning rate scaling and\ntraining duration, as a basis for an experimental comparison of test\nperformance for different mini-batch sizes. We adopt a learning rate that\ncorresponds to a constant average weight update per gradient calculation (i.e.,\nper unit cost of computation), and point out that this results in a variance of\nthe weight updates that increases linearly with the mini-batch size $m$.\n  The collected experimental results for the CIFAR-10, CIFAR-100 and ImageNet\ndatasets show that increasing the mini-batch size progressively reduces the\nrange of learning rates that provide stable convergence and acceptable test\nperformance. On the other hand, small mini-batch sizes provide more up-to-date\ngradient calculations, which yields more stable and reliable training. The best\nperformance has been consistently obtained for mini-batch sizes between $m = 2$\nand $m = 32$, which contrasts with recent work advocating the use of mini-batch\nsizes in the thousands.", "published": "2018-04-20T13:44:12Z", "version": 1}, {"aid": "1804.07851", "authors": ["Ida H\u00e4ggstr\u00f6m", "C. Ross Schmidtlein", "Gabriele Campanella", "Thomas J. Fuchs"], "title": "DeepPET: A deep encoder-decoder network for directly solving the PET reconstruction inverse problem", "url": "http://arxiv.org/pdf/1804.07851v2", "summary": "Positron emission tomography (PET) is a cornerstone of modern radiology. The\nability to detect cancer and metastases in whole body scans fundamentally\nchanged cancer diagnosis and treatment. One of the main bottlenecks in the\nclinical application is the time it takes to reconstruct the anatomical image\nfrom the deluge of data in PET imaging. State-of-the art methods based on\nexpectation maximization can take hours for a single patient and depend on\nmanual fine-tuning. This results not only in financial burden for hospitals but\nmore importantly leads to less efficient patient handling, evaluation, and\nultimately diagnosis and treatment for patients. To overcome this problem we\npresent a novel PET image reconstruction technique based on a deep\nconvolutional encoder-decoder network, that takes PET sinogram data as input\nand directly outputs full PET images. Using realistic simulated data, we\ndemonstrate that our network is able to reconstruct images >100 times faster,\nand with comparable image quality (in terms of root mean squared error)\nrelative to conventional iterative reconstruction techniques.", "published": "2018-04-20T22:44:00Z", "version": 2}, {"aid": "1804.08010", "authors": ["Qibin Zheng", "Xingchun Diao", "Jianjun Cao", "Xiaolei Zhou", "Yi Liu", "Hongmei Li"], "title": "Multi-Modal Coreference Resolution with the Correlation between Space Structures", "url": "http://arxiv.org/pdf/1804.08010v2", "summary": "Multi-modal data is becoming more common in big data background. Finding the\nsemantically similar objects from different modality is one of the heart\nproblems of multi-modal learning. Most of the current methods try to learn the\ninter-modal correlation with extrinsic supervised information, while intrinsic\nstructural information of each modality is neglected. The performance of these\nmethods heavily depends on the richness of training samples. However, obtaining\nthe multi-modal training samples is still a labor and cost intensive work. In\nthis paper, we bring a extrinsic correlation between the space structures of\neach modalities in coreference resolution. With this correlation, a\nsemi-supervised learning model for multi-modal coreference resolution is\nproposed. We firstly extract high-level features of images and text, then\ncompute the distances of each object from some reference points to build the\nspace structure of each modality. With a shared reference point set, the space\nstructures of each modality are correlated. We employ the correlation to build\na commonly shared space that the semantic distance between multi-modal objects\ncan be computed directly. The experiments on two multi-modal datasets show that\nour model performs better than the existing methods with insufficient training\ndata.", "published": "2018-04-21T19:15:19Z", "version": 2}, {"aid": "1804.08039", "authors": ["Wen Wei", "Emilie Poirion", "Benedetta Bodini", "Stanley Durrleman", "Nicholas Ayache", "Bruno Stankoff", "Olivier Colliot"], "title": "Learning Myelin Content in Multiple Sclerosis from Multimodal MRI through Adversarial Training", "url": "http://arxiv.org/pdf/1804.08039v2", "summary": "Multiple sclerosis (MS) is a demyelinating disease of the central nervous\nsystem (CNS). A reliable measure of the tissue myelin content is therefore\nessential for the understanding of the physiopathology of MS, tracking\nprogression and assessing treatment efficacy. Positron emission tomography\n(PET) with $[^{11} \\mbox{C}] \\mbox{PIB}$ has been proposed as a promising\nbiomarker for measuring myelin content changes in-vivo in MS. However, PET\nimaging is expensive and invasive due to the injection of a radioactive tracer.\nOn the contrary, magnetic resonance imaging (MRI) is a non-invasive, widely\navailable technique, but existing MRI sequences do not provide, to date, a\nreliable, specific, or direct marker of either demyelination or remyelination.\nIn this work, we therefore propose Sketcher-Refiner Generative Adversarial\nNetworks (GANs) with specifically designed adversarial loss functions to\npredict the PET-derived myelin content map from a combination of MRI\nmodalities. The prediction problem is solved by a sketch-refinement process in\nwhich the sketcher generates the preliminary anatomical and physiological\ninformation and the refiner refines and generates images reflecting the tissue\nmyelin content in the human brain. We evaluated the ability of our method to\npredict myelin content at both global and voxel-wise levels. The evaluation\nresults show that the demyelination in lesion regions and myelin content in\nnormal-appearing white matter (NAWM) can be well predicted by our method. The\nmethod has the potential to become a useful tool for clinical management of\npatients with MS.", "published": "2018-04-21T22:23:51Z", "version": 2}, {"aid": "1804.08042", "authors": ["Najeeb Khan", "Jawad Shah", "Ian Stavness"], "title": "Bridgeout: stochastic bridge regularization for deep neural networks", "url": "http://arxiv.org/pdf/1804.08042v1", "summary": "A major challenge in training deep neural networks is overfitting, i.e.\ninferior performance on unseen test examples compared to performance on\ntraining examples. To reduce overfitting, stochastic regularization methods\nhave shown superior performance compared to deterministic weight penalties on a\nnumber of image recognition tasks. Stochastic methods such as Dropout and\nShakeout, in expectation, are equivalent to imposing a ridge and elastic-net\npenalty on the model parameters, respectively. However, the choice of the norm\nof weight penalty is problem dependent and is not restricted to $\\{L_1,L_2\\}$.\nTherefore, in this paper we propose the Bridgeout stochastic regularization\ntechnique and prove that it is equivalent to an $L_q$ penalty on the weights,\nwhere the norm $q$ can be learned as a hyperparameter from data. Experimental\nresults show that Bridgeout results in sparse model weights, improved gradients\nand superior classification performance compared to Dropout and Shakeout on\nsynthetic and real datasets.", "published": "2018-04-21T23:27:24Z", "version": 1}, {"aid": "1804.08071", "authors": ["Weiyang Liu", "Zhen Liu", "Zhiding Yu", "Bo Dai", "Rongmei Lin", "Yisen Wang", "James M. Rehg", "Le Song"], "title": "Decoupled Networks", "url": "http://arxiv.org/pdf/1804.08071v1", "summary": "Inner product-based convolution has been a central component of convolutional\nneural networks (CNNs) and the key to learning visual representations. Inspired\nby the observation that CNN-learned features are naturally decoupled with the\nnorm of features corresponding to the intra-class variation and the angle\ncorresponding to the semantic difference, we propose a generic decoupled\nlearning framework which models the intra-class variation and semantic\ndifference independently. Specifically, we first reparametrize the inner\nproduct to a decoupled form and then generalize it to the decoupled convolution\noperator which serves as the building block of our decoupled networks. We\npresent several effective instances of the decoupled convolution operator. Each\ndecoupled operator is well motivated and has an intuitive geometric\ninterpretation. Based on these decoupled operators, we further propose to\ndirectly learn the operator from data. Extensive experiments show that such\ndecoupled reparameterization renders significant performance gain with easier\nconvergence and stronger robustness.", "published": "2018-04-22T05:26:08Z", "version": 1}, {"aid": "1804.08139", "authors": ["Renjie Zheng", "Junkun Chen", "Xipeng Qiu"], "title": "Same Representation, Different Attentions: Shareable Sentence Representation Learning from Multiple Tasks", "url": "http://arxiv.org/pdf/1804.08139v1", "summary": "Distributed representation plays an important role in deep learning based\nnatural language processing. However, the representation of a sentence often\nvaries in different tasks, which is usually learned from scratch and suffers\nfrom the limited amounts of training data. In this paper, we claim that a good\nsentence representation should be invariant and can benefit the various\nsubsequent tasks. To achieve this purpose, we propose a new scheme of\ninformation sharing for multi-task learning. More specifically, all tasks share\nthe same sentence representation and each task can select the task-specific\ninformation from the shared sentence representation with attention mechanism.\nThe query vector of each task's attention could be either static parameters or\ngenerated dynamically. We conduct extensive experiments on 16 different text\nclassification tasks, which demonstrate the benefits of our architecture.", "published": "2018-04-22T17:13:06Z", "version": 1}, {"aid": "1804.08150", "authors": ["Amirhossein Tavanaei", "Masoud Ghodrati", "Saeed Reza Kheradpisheh", "Timothee Masquelier", "Anthony S. Maida"], "title": "Deep Learning in Spiking Neural Networks", "url": "http://arxiv.org/pdf/1804.08150v4", "summary": "In recent years, deep learning has been a revolution in the field of machine\nlearning, for computer vision in particular. In this approach, a deep\n(multilayer) artificial neural network (ANN) is trained in a supervised manner\nusing backpropagation. Huge amounts of labeled examples are required, but the\nresulting classification accuracy is truly impressive, sometimes outperforming\nhumans. Neurons in an ANN are characterized by a single, static,\ncontinuous-valued activation. Yet biological neurons use discrete spikes to\ncompute and transmit information, and the spike times, in addition to the spike\nrates, matter. Spiking neural networks (SNNs) are thus more biologically\nrealistic than ANNs, and arguably the only viable option if one wants to\nunderstand how the brain computes. SNNs are also more hardware friendly and\nenergy-efficient than ANNs, and are thus appealing for technology, especially\nfor portable devices. However, training deep SNNs remains a challenge. Spiking\nneurons' transfer function is usually non-differentiable, which prevents using\nbackpropagation. Here we review recent supervised and unsupervised methods to\ntrain deep SNNs, and compare them in terms of accuracy, but also computational\ncost and hardware friendliness. The emerging picture is that SNNs still lag\nbehind ANNs in terms of accuracy, but the gap is decreasing, and can even\nvanish on some tasks, while the SNNs typically require much fewer operations.", "published": "2018-04-22T18:27:34Z", "version": 4}, {"aid": "1804.08378", "authors": ["Nicolas Weber", "Florian Schmidt", "Mathias Niepert", "Felipe Huici"], "title": "BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First Parallelism", "url": "http://arxiv.org/pdf/1804.08378v1", "summary": "Neural network frameworks such as PyTorch and TensorFlow are the workhorses\nof numerous machine learning applications ranging from object recognition to\nmachine translation. While these frameworks are versatile and straightforward\nto use, the training of and inference in deep neural networks is resource\n(energy, compute, and memory) intensive. In contrast to recent works focusing\non algorithmic enhancements, we introduce BrainSlug, a framework that\ntransparently accelerates neural network workloads by changing the default\nlayer-by-layer processing to a depth-first approach, reducing the amount of\ndata required by the computations and thus improving the performance of the\navailable hardware caches. BrainSlug achieves performance improvements of up to\n41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the\nuser as they do not require hardware changes and only need tiny adjustments to\nthe software.", "published": "2018-04-23T12:49:04Z", "version": 1}, {"aid": "1804.09949", "authors": ["Adam Bielski", "Tomasz Trzcinski"], "title": "Pay Attention to Virality: understanding popularity of social media videos with the attention mechanism", "url": "http://arxiv.org/pdf/1804.09949v1", "summary": "Predicting popularity of social media videos before they are published is a\nchallenging task, mainly due to the complexity of content distribution network\nas well as the number of factors that play part in this process. As solving\nthis task provides tremendous help for media content creators, many successful\nmethods were proposed to solve this problem with machine learning. In this\nwork, we change the viewpoint and postulate that it is not only the predicted\npopularity that matters, but also, maybe even more importantly, understanding\nof how individual parts influence the final popularity score. To that end, we\npropose to combine the Grad-CAM visualization method with a soft attention\nmechanism. Our preliminary results show that this approach allows for more\nintuitive interpretation of the content impact on video popularity, while\nachieving competitive results in terms of prediction accuracy.", "published": "2018-04-26T09:06:06Z", "version": 1}, {"aid": "1804.10167", "authors": ["Maxim Sharaev", "Alexander Andreev", "Alexey Artemov", "Alexander Bernstein", "Evgeny Burnaev", "Ekaterina Kondratyeva", "Svetlana Sushchinskaya", "Renat Akzhigitov"], "title": "fMRI: preprocessing, classification and pattern recognition", "url": "http://arxiv.org/pdf/1804.10167v1", "summary": "As machine learning continues to gain momentum in the neuroscience community,\nwe witness the emergence of novel applications such as diagnostics,\ncharacterization, and treatment outcome prediction for psychiatric and\nneurological disorders, for instance, epilepsy and depression. Systematic\nresearch into these mental disorders increasingly involves drawing clinical\nconclusions on the basis of data-driven approaches; to this end, structural and\nfunctional neuroimaging serve as key source modalities. Identification of\ninformative neuroimaging markers requires establishing a comprehensive\npreparation pipeline for data which may be severely corrupted by artifactual\nsignal fluctuations. In this work, we review a large body of literature to\nprovide ample evidence for the advantages of pattern recognition approaches in\nclinical applications, overview advanced graph-based pattern recognition\napproaches, and propose a noise-aware neuroimaging data processing pipeline. To\ndemonstrate the effectiveness of our approach, we provide results from a pilot\nstudy, which show a significant improvement in classification accuracy,\nindicating a promising research direction.", "published": "2018-04-26T16:48:52Z", "version": 1}, {"aid": "1804.10172", "authors": ["Andrew Gritsevskiy", "Maksym Korablyov"], "title": "Capsule networks for low-data transfer learning", "url": "http://arxiv.org/pdf/1804.10172v1", "summary": "We propose a capsule network-based architecture for generalizing learning to\nnew data with few examples. Using both generative and non-generative capsule\nnetworks with intermediate routing, we are able to generalize to new\ninformation over 25 times faster than a similar convolutional neural network.\nWe train the networks on the multiMNIST dataset lacking one digit. After the\nnetworks reach their maximum accuracy, we inject 1-100 examples of the missing\ndigit into the training set, and measure the number of batches needed to return\nto a comparable level of accuracy. We then discuss the improvement in low-data\ntransfer learning that capsule networks bring, and propose future directions\nfor capsule research.", "published": "2018-04-26T17:01:12Z", "version": 1}, {"aid": "1804.11214", "authors": ["Yiming Xu", "Diego Klabjan"], "title": "k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks", "url": "http://arxiv.org/pdf/1804.11214v4", "summary": "k-Nearest Neighbors is one of the most fundamental but effective\nclassification models. In this paper, we propose two families of models built\non a sequence to sequence model and a memory network model to mimic the\nk-Nearest Neighbors model, which generate a sequence of labels, a sequence of\nout-of-sample feature vectors and a final label for classification, and thus\nthey could also function as oversamplers. We also propose 'out-of-core'\nversions of our models which assume that only a small portion of data can be\nloaded into memory. Computational experiments show that our models on\nstructured datasets outperform k-Nearest Neighbors, a feed-forward neural\nnetwork, XGBoost, lightGBM, random forest and a memory network, due to the fact\nthat our models must produce additional output and not just the label. On image\nand text datasets, the performance of our model is close to many\nstate-of-the-art deep models. As an oversampler on imbalanced datasets, the\nsequence to sequence kNN model often outperforms Synthetic Minority\nOver-sampling Technique and Adaptive Synthetic Sampling.", "published": "2018-04-27T15:13:29Z", "version": 4}, {"aid": "1805.01352", "authors": ["Yangfan Hu", "Huajin Tang", "Gang Pan"], "title": "Spiking Deep Residual Network", "url": "http://arxiv.org/pdf/1805.01352v2", "summary": "Spiking neural networks (SNNs) have received significant attention for their\nbiological plausibility. SNNs theoretically have at least the same\ncomputational power as traditional artificial neural networks (ANNs). They\npossess potential of achieving energy-efficiency while keeping comparable\nperformance to deep neural networks (DNNs). However, it is still a big\nchallenge to train a very deep SNN. In this paper, we propose an efficient\napproach to build a spiking version of deep residual network (ResNet). ResNet\nis considered as a kind of the state-of-the-art convolutional neural networks\n(CNNs). We employ the idea of converting a trained ResNet to a network of\nspiking neurons, named Spiking ResNet (S-ResNet). We propose a shortcut\nconversion model to appropriately scale continuous-valued activations to match\nfiring rates in SNN, and a compensation mechanism to reduce the error caused by\ndiscretisation. Experimental results demonstrate that, compared with the\nstate-of-the-art SNN approaches, the proposed Spiking ResNet achieves the best\nperformance on CIFAR-10, CIFAR-100, and ImageNet 2012. Our work is the first\ntime to build a SNN deeper than 40, with comparable performance to ANNs on a\nlarge-scale dataset.", "published": "2018-04-28T06:44:13Z", "version": 2}, {"aid": "1804.11191", "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "title": "How convolutional neural network see the world - A survey of convolutional neural network visualization methods", "url": "http://arxiv.org/pdf/1804.11191v2", "summary": "Nowadays, the Convolutional Neural Networks (CNNs) have achieved impressive\nperformance on many computer vision related tasks, such as object detection,\nimage recognition, image retrieval, etc. These achievements benefit from the\nCNNs outstanding capability to learn the input features with deep layers of\nneuron structures and iterative training process. However, these learned\nfeatures are hard to identify and interpret from a human vision perspective,\ncausing a lack of understanding of the CNNs internal working mechanism. To\nimprove the CNN interpretability, the CNN visualization is well utilized as a\nqualitative analysis method, which translates the internal features into\nvisually perceptible patterns. And many CNN visualization works have been\nproposed in the literature to interpret the CNN in perspectives of network\nstructure, operation, and semantic concept. In this paper, we expect to provide\na comprehensive survey of several representative CNN visualization methods,\nincluding Activation Maximization, Network Inversion, Deconvolutional Neural\nNetworks (DeconvNet), and Network Dissection based visualization. These methods\nare presented in terms of motivations, algorithms, and experiment results.\nBased on these visualization methods, we also discuss their practical\napplications to demonstrate the significance of the CNN interpretability in\nareas of network design, optimization, security enhancement, etc.", "published": "2018-04-30T13:47:11Z", "version": 2}, {"aid": "1805.00907", "authors": ["Nadav Rotem", "Jordan Fix", "Saleem Abdulrasool", "Garret Catron", "Summer Deng", "Roman Dzhabarov", "Nick Gibson", "James Hegeman", "Meghan Lele", "Roman Levenstein", "Jack Montgomery", "Bert Maher", "Satish Nadathur", "Jakob Olesen", "Jongsoo Park", "Artem Rakhov", "Misha Smelyanskiy", "Man Wang"], "title": "Glow: Graph Lowering Compiler Techniques for Neural Networks", "url": "http://arxiv.org/pdf/1805.00907v3", "summary": "This paper presents the design of Glow, a machine learning compiler for\nheterogeneous hardware. It is a pragmatic approach to compilation that enables\nthe generation of highly optimized code for multiple targets. Glow lowers the\ntraditional neural network dataflow graph into a two-phase strongly-typed\nintermediate representation. The high-level intermediate representation allows\nthe optimizer to perform domain-specific optimizations. The lower-level\ninstruction-based address-only intermediate representation allows the compiler\nto perform memory-related optimizations, such as instruction scheduling, static\nmemory allocation and copy elimination. At the lowest level, the optimizer\nperforms machine-specific code generation to take advantage of specialized\nhardware features. Glow features a lowering phase which enables the compiler to\nsupport a high number of input operators as well as a large number of hardware\ntargets by eliminating the need to implement all operators on all targets. The\nlowering phase is designed to reduce the input space and allow new hardware\nbackends to focus on a small number of linear algebra primitives.", "published": "2018-05-02T17:04:53Z", "version": 3}, {"aid": "1805.01385", "authors": ["Yang Liu"], "title": "Research on the Brain-inspired Cross-modal Neural Cognitive Computing Framework", "url": "http://arxiv.org/pdf/1805.01385v2", "summary": "To address modeling problems of brain-inspired intelligence, this thesis is\nfocused on researching in the semantic-oriented framework design for multimedia\nand multimodal information. The Multimedia Neural Cognitive Computing (MNCC)\nmodel was designed based on the nervous mechanism and cognitive architecture.\nFurthermore, the semantic-oriented hierarchical Cross-modal Neural Cognitive\nComputing (CNCC) framework was proposed based on MNCC model, and formal\ndescription and analysis for CNCC framework was given. It would effectively\nimprove the performance of semantic processing for multimedia and cross-modal\ninformation, and has far-reaching significance for exploration and realization\nbrain-inspired computing.", "published": "2018-05-03T15:51:51Z", "version": 2}, {"aid": "1805.01452", "authors": ["Dimitrios Kollias", "Stefanos Zafeiriou"], "title": "A Multi-component CNN-RNN Approach for Dimensional Emotion Recognition in-the-wild", "url": "http://arxiv.org/pdf/1805.01452v5", "summary": "This paper presents our approach to the One-Minute Gradual-Emotion\nRecognition (OMG-Emotion) Challenge, focusing on dimensional emotion\nrecognition through visual analysis of the provided emotion videos. The\napproach is based on a Convolutional and Recurrent (CNN-RNN) deep neural\narchitecture we have developed for the relevant large AffWild Emotion Database.\nWe extended and adapted this architecture, by letting a combination of multiple\nfeatures generated in the CNN component be explored by RNN subnets. Our target\nhas been to obtain best performance on the OMG-Emotion visual validation data\nset, while learning the respective visual training data set. Extended\nexperimentation has led to best architectures for the estimation of the values\nof the valence and arousal emotion dimensions over these data sets.", "published": "2018-05-03T17:54:44Z", "version": 5}, {"aid": "1805.01890", "authors": ["Kamran Kowsari", "Mojtaba Heidarysafa", "Donald E. Brown", "Kiana Jafari Meimandi", "Laura E. Barnes"], "title": "RMDL: Random Multimodel Deep Learning for Classification", "url": "http://arxiv.org/pdf/1805.01890v2", "summary": "The continually increasing number of complex datasets each year necessitates\never improving machine learning methods for robust and accurate categorization\nof these data. This paper introduces Random Multimodel Deep Learning (RMDL): a\nnew ensemble, deep learning approach for classification. Deep learning models\nhave achieved state-of-the-art results across many domains. RMDL solves the\nproblem of finding the best deep learning structure and architecture while\nsimultaneously improving robustness and accuracy through ensembles of deep\nlearning architectures. RDML can accept as input a variety data to include\ntext, video, images, and symbolic. This paper describes RMDL and shows test\nresults for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,\nand 20newsgroup. These test results show that RDML produces consistently better\nperformance than standard methods over a broad range of data types and\nclassification problems.", "published": "2018-05-03T19:36:43Z", "version": 2}, {"aid": "1805.01978", "authors": ["Zhirong Wu", "Yuanjun Xiong", "Stella Yu", "Dahua Lin"], "title": "Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination", "url": "http://arxiv.org/pdf/1805.01978v1", "summary": "Neural net classifiers trained on data with annotated class labels can also\ncapture apparent visual similarity among categories without being directed to\ndo so. We study whether this observation can be extended beyond the\nconventional domain of supervised learning: Can we learn a good feature\nrepresentation that captures apparent similarity among instances, instead of\nclasses, by merely asking the feature to be discriminative of individual\ninstances? We formulate this intuition as a non-parametric classification\nproblem at the instance-level, and use noise-contrastive estimation to tackle\nthe computational challenges imposed by the large number of instance classes.\nOur experimental results demonstrate that, under unsupervised learning\nsettings, our method surpasses the state-of-the-art on ImageNet classification\nby a large margin. Our method is also remarkable for consistently improving\ntest performance with more training data and better network architectures. By\nfine-tuning the learned feature, we further obtain competitive results for\nsemi-supervised learning and object detection tasks. Our non-parametric model\nis highly compact: With 128 features per image, our method requires only 600MB\nstorage for a million images, enabling fast nearest neighbour retrieval at the\nrun time.", "published": "2018-05-05T00:47:01Z", "version": 1}, {"aid": "1805.03225", "authors": ["Siddharth Mahendran", "Haider Ali", "Rene Vidal"], "title": "A Mixed Classification-Regression Framework for 3D Pose Estimation from 2D Images", "url": "http://arxiv.org/pdf/1805.03225v1", "summary": "3D pose estimation from a single 2D image is an important and challenging\ntask in computer vision with applications in autonomous driving, robot\nmanipulation and augmented reality. Since 3D pose is a continuous quantity, a\nnatural formulation for this task is to solve a pose regression problem.\nHowever, since pose regression methods return a single estimate of the pose,\nthey have difficulties handling multimodal pose distributions (e.g. in the case\nof symmetric objects). An alternative formulation, which can capture multimodal\npose distributions, is to discretize the pose space into bins and solve a pose\nclassification problem. However, pose classification methods can give large\npose estimation errors depending on the coarseness of the discretization. In\nthis paper, we propose a mixed classification-regression framework that uses a\nclassification network to produce a discrete multimodal pose estimate and a\nregression network to produce a continuous refinement of the discrete estimate.\nThe proposed framework can accommodate different architectures and loss\nfunctions, leading to multiple classification-regression models, some of which\nachieve state-of-the-art performance on the challenging Pascal3D+ dataset.", "published": "2018-05-08T18:32:04Z", "version": 1}, {"aid": "1805.03300", "authors": ["Joseph Y. Cheng", "Feiyu Chen", "Marcus T. Alley", "John M. Pauly", "Shreyas S. Vasanawala"], "title": "Highly Scalable Image Reconstruction using Deep Neural Networks with Bandpass Filtering", "url": "http://arxiv.org/pdf/1805.03300v2", "summary": "To increase the flexibility and scalability of deep neural networks for image\nreconstruction, a framework is proposed based on bandpass filtering. For many\napplications, sensing measurements are performed indirectly. For example, in\nmagnetic resonance imaging, data are sampled in the frequency domain. The\nintroduction of bandpass filtering enables leveraging known imaging physics\nwhile ensuring that the final reconstruction is consistent with actual\nmeasurements to maintain reconstruction accuracy. We demonstrate this flexible\narchitecture for reconstructing subsampled datasets of MRI scans. The resulting\nhigh subsampling rates increase the speed of MRI acquisitions and enable the\nvisualization rapid hemodynamics.", "published": "2018-05-08T21:42:53Z", "version": 2}, {"aid": "1806.01775", "authors": ["F. Liu", "C. Liu", "F. Bi"], "title": "A Memristor based Unsupervised Neuromorphic System Towards Fast and Energy-Efficient GAN", "url": "http://arxiv.org/pdf/1806.01775v4", "summary": "Deep Learning has gained immense success in pushing today's artificial\nintelligence forward. To solve the challenge of limited labeled data in the\nsupervised learning world, unsupervised learning has been proposed years ago\nwhile low accuracy hinters its realistic applications. Generative adversarial\nnetwork (GAN) emerges as an unsupervised learning approach with promising\naccuracy and are under extensively study. However, the execution of GAN is\nextremely memory and computation intensive and results in ultra-low speed and\nhigh-power consumption. In this work, we proposed a holistic solution for fast\nand energy-efficient GAN computation through a memristor-based neuromorphic\nsystem. First, we exploited a hardware and software co-design approach to map\nthe computation blocks in GAN efficiently. We also proposed an efficient data\nflow for optimal parallelism training and testing, depending on the computation\ncorrelations between different computing blocks. To compute the unique and\ncomplex loss of GAN, we developed a diff-block with optimized accuracy and\nperformance. The experiment results on big data show that our design achieves\n2.8x speedup and 6.1x energy-saving compared with the traditional GPU\naccelerator, as well as 5.5x speedup and 1.4x energy-saving compared with the\nprevious FPGA-based accelerator.", "published": "2018-05-09T02:45:38Z", "version": 4}, {"aid": "1805.03714", "authors": ["Vitaly Kuznetsov", "Zelda Mariet"], "title": "Foundations of Sequence-to-Sequence Modeling for Time Series", "url": "http://arxiv.org/pdf/1805.03714v2", "summary": "The availability of large amounts of time series data, paired with the\nperformance of deep-learning algorithms on a broad class of problems, has\nrecently led to significant interest in the use of sequence-to-sequence models\nfor time series forecasting. We provide the first theoretical analysis of this\ntime series forecasting framework. We include a comparison of\nsequence-to-sequence modeling to classical time series models, and as such our\ntheory can serve as a quantitative guide for practitioners choosing between\ndifferent modeling methodologies.", "published": "2018-05-09T20:03:37Z", "version": 2}, {"aid": "1805.04514", "authors": ["Kenny Young", "Baoxiang Wang", "Matthew E. Taylor"], "title": "Metatrace Actor-Critic: Online Step-size Tuning by Meta-gradient Descent for Reinforcement Learning Control", "url": "http://arxiv.org/pdf/1805.04514v2", "summary": "Reinforcement learning (RL) has had many successes in both \"deep\" and\n\"shallow\" settings. In both cases, significant hyperparameter tuning is often\nrequired to achieve good performance. Furthermore, when nonlinear function\napproximation is used, non-stationarity in the state representation can lead to\nlearning instability. A variety of techniques exist to combat this --- most\nnotably large experience replay buffers or the use of multiple parallel actors.\nThese techniques come at the cost of moving away from the online RL problem as\nit is traditionally formulated (i.e., a single agent learning online without\nmaintaining a large database of training examples). Meta-learning can\npotentially help with both these issues by tuning hyperparameters online and\nallowing the algorithm to more robustly adjust to non-stationarity in a\nproblem. This paper applies meta-gradient descent to derive a set of step-size\ntuning algorithms specifically for online RL control with eligibility traces.\nOur novel technique, Metatrace, makes use of an eligibility trace analogous to\nmethods like $TD(\\lambda)$. We explore tuning both a single scalar step-size\nand a separate step-size for each learned parameter. We evaluate Metatrace\nfirst for control with linear function approximation in the classic mountain\ncar problem and then in a noisy, non-stationary version. Finally, we apply\nMetatrace for control with nonlinear function approximation in 5 games in the\nArcade Learning Environment where we explore how it impacts learning speed and\nrobustness to initial step-size choice. Results show that the meta-step-size\nparameter of Metatrace is easy to set, Metatrace can speed learning, and\nMetatrace can allow an RL algorithm to deal with non-stationarity in the\nlearning task.", "published": "2018-05-10T20:00:50Z", "version": 2}, {"aid": "1805.04419", "authors": ["Le Pham Tuyen", "Ngo Anh Vien", "Abu Layek", "TaeChoong Chung"], "title": "Deep Hierarchical Reinforcement Learning Algorithm in Partially Observable Markov Decision Processes", "url": "http://arxiv.org/pdf/1805.04419v1", "summary": "In recent years, reinforcement learning has achieved many remarkable\nsuccesses due to the growing adoption of deep learning techniques and the rapid\ngrowth in computing power. Nevertheless, it is well-known that flat\nreinforcement learning algorithms are often not able to learn well and\ndata-efficient in tasks having hierarchical structures, e.g. consisting of\nmultiple subtasks. Hierarchical reinforcement learning is a principled approach\nthat is able to tackle these challenging tasks. On the other hand, many\nreal-world tasks usually have only partial observability in which state\nmeasurements are often imperfect and partially observable. The problems of RL\nin such settings can be formulated as a partially observable Markov decision\nprocess (POMDP). In this paper, we study hierarchical RL in POMDP in which the\ntasks have only partial observability and possess hierarchical properties. We\npropose a hierarchical deep reinforcement learning approach for learning in\nhierarchical POMDP. The deep hierarchical RL algorithm is proposed to apply to\nboth MDP and POMDP learning. We evaluate the proposed algorithm on various\nchallenging hierarchical POMDP.", "published": "2018-05-11T14:30:21Z", "version": 1}, {"aid": "1805.04590", "authors": ["Akash Bapat", "Jan-Michael Frahm"], "title": "The Domain Transform Solver", "url": "http://arxiv.org/pdf/1805.04590v1", "summary": "We present a framework for edge-aware optimization that is an order of\nmagnitude faster than the state of the art while having comparable performance.\nOur key insight is that the optimization can be formulated by leveraging\nproperties of the domain transform, a method for edge-aware filtering that\ndefines a distance-preserving 1D mapping of the input space. This enables our\nmethod to improve performance for a variety of problems including stereo, depth\nsuper-resolution, and render from defocus, while keeping the computational\ncomplexity linear in the number of pixels. Our method is highly parallelizable\nand adaptable, and it has demonstrable scalability with respect to image\nresolution.", "published": "2018-05-11T20:57:46Z", "version": 1}, {"aid": "1805.04770", "authors": ["Tommaso Furlanello", "Zachary C. Lipton", "Michael Tschannen", "Laurent Itti", "Anima Anandkumar"], "title": "Born Again Neural Networks", "url": "http://arxiv.org/pdf/1805.04770v2", "summary": "Knowledge Distillation (KD) consists of transferring \u201cknowledge\u201d from one\nmachine learning model (the teacher) to another (the student). Commonly, the\nteacher is a high-capacity model with formidable performance, while the student\nis more compact. By transferring knowledge, one hopes to benefit from the\nstudent\u2019s compactness, without sacrificing too much performance. We study KD\nfrom a new perspective: rather than compressing models, we train students\nparameterized identically to their teachers. Surprisingly, these Born-Again\nNetworks (BANs), outperform their teachers significantly, both on computer\nvision and language modeling tasks. Our experiments with BANs based on\nDenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and\nCIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore\ntwo distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and\n(ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate\nthe essential components of KD, demonstrating the effect of the teacher outputs\non both predicted and non-predicted classes.", "published": "2018-05-12T19:48:50Z", "version": 2}, {"aid": "1805.04955", "authors": ["Thomas Stepleton", "Razvan Pascanu", "Will Dabney", "Siddhant M. Jayakumar", "Hubert Soyer", "Remi Munos"], "title": "Low-pass Recurrent Neural Networks - A memory architecture for longer-term correlation discovery", "url": "http://arxiv.org/pdf/1805.04955v1", "summary": "Reinforcement learning (RL) agents performing complex tasks must be able to\nremember observations and actions across sizable time intervals. This is\nespecially true during the initial learning stages, when exploratory behaviour\ncan increase the delay between specific actions and their effects. Many new or\npopular approaches for learning these distant correlations employ\nbackpropagation through time (BPTT), but this technique requires storing\nobservation traces long enough to span the interval between cause and effect.\nBesides memory demands, learning dynamics like vanishing gradients and slow\nconvergence due to infrequent weight updates can reduce BPTT's practicality;\nmeanwhile, although online recurrent network learning is a developing topic,\nmost approaches are not efficient enough to use as replacements. We propose a\nsimple, effective memory strategy that can extend the window over which BPTT\ncan learn without requiring longer traces. We explore this approach empirically\non a few tasks and discuss its implications.", "published": "2018-05-13T21:35:08Z", "version": 1}, {"aid": "1805.06020", "authors": ["Tambet Matiisen", "Aqeel Labash", "Daniel Majoral", "Jaan Aru", "Raul Vicente"], "title": "Do deep reinforcement learning agents model intentions?", "url": "http://arxiv.org/pdf/1805.06020v2", "summary": "Inferring other agents' mental states such as their knowledge, beliefs and\nintentions is thought to be essential for effective interactions with other\nagents. Recently, multiagent systems trained via deep reinforcement learning\nhave been shown to succeed in solving different tasks, but it remains unclear\nhow each agent modeled or represented other agents in their environment. In\nthis work we test whether deep reinforcement learning agents explicitly\nrepresent other agents' intentions (their specific aims or goals) during a task\nin which the agents had to coordinate the covering of different spots in a 2D\nenvironment. In particular, we tracked over time the performance of a linear\ndecoder trained to predict the final goal of all agents from the hidden state\nof each agent's neural network controller. We observed that the hidden layers\nof agents represented explicit information about other agents' goals, i.e. the\ntarget landmark they ended up covering. We also performed a series of\nexperiments, in which some agents were replaced by others with fixed goals, to\ntest the level of generalization of the trained agents. We noticed that during\nthe training phase the agents developed a differential preference for each\ngoal, which hindered generalization. To alleviate the above problem, we propose\nsimple changes to the MADDPG training algorithm which leads to better\ngeneralization against unseen agents. We believe that training protocols\npromoting more active intention reading mechanisms, e.g. by preventing simple\nsymmetry-breaking solutions, is a promising direction towards achieving a more\nrobust generalization in different cooperative and competitive tasks.", "published": "2018-05-15T20:15:05Z", "version": 2}, {"aid": "1805.12069", "authors": ["Eray \u00d6zkural"], "title": "Omega: An Architecture for AI Unification", "url": "http://arxiv.org/pdf/1805.12069v1", "summary": "We introduce the open-ended, modular, self-improving Omega AI unification\narchitecture which is a refinement of Solomonoff's Alpha architecture, as\nconsidered from first principles. The architecture embodies several crucial\nprinciples of general intelligence including diversity of representations,\ndiversity of data types, integrated memory, modularity, and higher-order\ncognition. We retain the basic design of a fundamental algorithmic substrate\ncalled an \"AI kernel\" for problem solving and basic cognitive functions like\nmemory, and a larger, modular architecture that re-uses the kernel in many\nways. Omega includes eight representation languages and six classes of neural\nnetworks, which are briefly introduced. The architecture is intended to\ninitially address data science automation, hence it includes many problem\nsolving methods for statistical tasks. We review the broad software\narchitecture, higher-order cognition, self-improvement, modular neural\narchitectures, intelligent agents, the process and memory hierarchy, hardware\nabstraction, peer-to-peer computing, and data abstraction facility.", "published": "2018-05-16T22:08:28Z", "version": 1}, {"aid": "1805.06621", "authors": ["Tom\u00e1s Angles", "St\u00e9phane Mallat"], "title": "Generative networks as inverse problems with Scattering transforms", "url": "http://arxiv.org/pdf/1805.06621v1", "summary": "Generative Adversarial Nets (GANs) and Variational Auto-Encoders (VAEs)\nprovide impressive image generations from Gaussian white noise, but the\nunderlying mathematics are not well understood. We compute deep convolutional\nnetwork generators by inverting a fixed embedding operator. Therefore, they do\nnot require to be optimized with a discriminator or an encoder. The embedding\nis Lipschitz continuous to deformations so that generators transform linear\ninterpolations between input white noise vectors into deformations between\noutput images. This embedding is computed with a wavelet Scattering transform.\nNumerical experiments demonstrate that the resulting Scattering generators have\nsimilar properties as GANs or VAEs, without learning a discriminative network\nor an encoder.", "published": "2018-05-17T07:12:18Z", "version": 1}, {"aid": "1805.06753", "authors": ["Guangzeng Xie", "Yitan Wang", "Shuchang Zhou", "Zhihua Zhang"], "title": "Interpolatron: Interpolation or Extrapolation Schemes to Accelerate Optimization for Deep Neural Networks", "url": "http://arxiv.org/pdf/1805.06753v1", "summary": "In this paper we explore acceleration techniques for large scale nonconvex\noptimization problems with special focuses on deep neural networks. The\nextrapolation scheme is a classical approach for accelerating stochastic\ngradient descent for convex optimization, but it does not work well for\nnonconvex optimization typically. Alternatively, we propose an interpolation\nscheme to accelerate nonconvex optimization and call the method Interpolatron.\nWe explain motivation behind Interpolatron and conduct a thorough empirical\nanalysis. Empirical results on DNNs of great depths (e.g., 98-layer ResNet and\n200-layer ResNet) on CIFAR-10 and ImageNet show that Interpolatron can converge\nmuch faster than the state-of-the-art methods such as the SGD with momentum and\nAdam. Furthermore, Anderson's acceleration, in which mixing coefficients are\ncomputed by least-squares estimation, can also be used to improve the\nperformance. Both Interpolatron and Anderson's acceleration are easy to\nimplement and tune. We also show that Interpolatron has linear convergence rate\nunder certain regularity assumptions.", "published": "2018-05-17T13:29:33Z", "version": 1}, {"aid": "1805.07071", "authors": ["Pengju Liu", "Hongzhi Zhang", "Kai Zhang", "Liang Lin", "Wangmeng Zuo"], "title": "Multi-level Wavelet-CNN for Image Restoration", "url": "http://arxiv.org/pdf/1805.07071v2", "summary": "The tradeoff between receptive field size and efficiency is a crucial issue\nin low level vision. Plain convolutional networks (CNNs) generally enlarge the\nreceptive field at the expense of computational cost. Recently, dilated\nfiltering has been adopted to address this issue. But it suffers from gridding\neffect, and the resulting receptive field is only a sparse sampling of input\nimage with checkerboard patterns. In this paper, we present a novel multi-level\nwavelet CNN (MWCNN) model for better tradeoff between receptive field size and\ncomputational efficiency. With the modified U-Net architecture, wavelet\ntransform is introduced to reduce the size of feature maps in the contracting\nsubnetwork. Furthermore, another convolutional layer is further used to\ndecrease the channels of feature maps. In the expanding subnetwork, inverse\nwavelet transform is then deployed to reconstruct the high resolution feature\nmaps. Our MWCNN can also be explained as the generalization of dilated\nfiltering and subsampling, and can be applied to many image restoration tasks.\nThe experimental results clearly show the effectiveness of MWCNN for image\ndenoising, single image super-resolution, and JPEG image artifacts removal.", "published": "2018-05-18T06:59:00Z", "version": 2}, {"aid": "1805.07249", "authors": ["Shrihari Vasudevan"], "title": "Dynamic learning rate using Mutual Information", "url": "http://arxiv.org/pdf/1805.07249v2", "summary": "This paper demonstrates dynamic hyper-parameter setting, for deep neural\nnetwork training, using Mutual Information (MI). The specific hyper-parameter\nstudied in this paper is the learning rate. MI between the output layer and\ntrue outcomes is used to dynamically set the learning rate of the network\nthrough the training cycle; the idea is also extended to layer-wise setting of\nlearning rate. Two approaches are demonstrated - tracking relative change in\nmutual information and, additionally tracking its value relative to a reference\nmeasure. The paper does not attempt to recommend a specific learning rate\npolicy. Experiments demonstrate that mutual information may be effectively used\nto dynamically set learning rate and achieve competitive to better outcomes in\ncompetitive to better time.", "published": "2018-05-18T14:46:20Z", "version": 2}, {"aid": "1805.07281", "authors": ["Rushil Anirudh", "Jayaraman J. Thiagarajan", "Bhavya Kailkhura", "Timo Bremer"], "title": "An Unsupervised Approach to Solving Inverse Problems using Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1805.07281v2", "summary": "Solving inverse problems continues to be a challenge in a wide array of\napplications ranging from deblurring, image inpainting, source separation etc.\nMost existing techniques solve such inverse problems by either explicitly or\nimplicitly finding the inverse of the model. The former class of techniques\nrequire explicit knowledge of the measurement process which can be unrealistic,\nand rely on strong analytical regularizers to constrain the solution space,\nwhich often do not generalize well. The latter approaches have had remarkable\nsuccess in part due to deep learning, but require a large collection of\nsource-observation pairs, which can be prohibitively expensive. In this paper,\nwe propose an unsupervised technique to solve inverse problems with generative\nadversarial networks (GANs). Using a pre-trained GAN in the space of source\nsignals, we show that one can reliably recover solutions to under determined\nproblems in a `blind' fashion, i.e., without knowledge of the measurement\nprocess. We solve this by making successive estimates on the model and the\nsolution in an iterative fashion. We show promising results in three\nchallenging applications -- blind source separation, image deblurring, and\nrecovering an image from its edge map, and perform better than several\nbaselines.", "published": "2018-05-18T15:23:01Z", "version": 2}, {"aid": "1805.07477", "authors": ["Alireza Zaeemzadeh", "Nazanin Rahnavard", "Mubarak Shah"], "title": "Norm-Preservation: Why Residual Networks Can Become Extremely Deep?", "url": "http://arxiv.org/pdf/1805.07477v5", "summary": "Augmenting neural networks with skip connections, as introduced in the\nso-called ResNet architecture, surprised the community by enabling the training\nof networks of more than 1,000 layers with significant performance gains. This\npaper deciphers ResNet by analyzing the effect of skip connections, and puts\nforward new theoretical results on the advantages of identity skip connections\nin neural networks. We prove that the skip connections in the residual blocks\nfacilitate preserving the norm of the gradient, and lead to stable\nback-propagation, which is desirable from optimization perspective. We also\nshow that, perhaps surprisingly, as more residual blocks are stacked, the\nnorm-preservation of the network is enhanced. Our theoretical arguments are\nsupported by extensive empirical evidence. Can we push for extra\nnorm-preservation? We answer this question by proposing an efficient method to\nregularize the singular values of the convolution operator and making the\nResNet's transition layers extra norm-preserving. Our numerical investigations\ndemonstrate that the learning dynamics and the classification performance of\nResNet can be improved by making it even more norm preserving. Our results and\nthe introduced modification for ResNet, referred to as Procrustes ResNets, can\nbe used as a guide for training deeper networks and can also inspire new deeper\narchitectures.", "published": "2018-05-18T23:37:17Z", "version": 5}, {"aid": "1805.07732", "authors": ["Chao Qu", "Shie Mannor", "Huan Xu"], "title": "Nonlinear Distributional Gradient Temporal-Difference Learning", "url": "http://arxiv.org/pdf/1805.07732v3", "summary": "We devise a distributional variant of gradient temporal-difference (TD)\nlearning. Distributional reinforcement learning has been demonstrated to\noutperform the regular one in the recent study\n\\citep{bellemare2017distributional}. In the policy evaluation setting, we\ndesign two new algorithms called distributional GTD2 and distributional TDC\nusing the Cram{\\'e}r distance on the distributional version of the Bellman\nerror objective function, which inherits advantages of both the nonlinear\ngradient TD algorithms and the distributional RL approach. In the control\nsetting, we propose the distributional Greedy-GQ using the similar derivation.\nWe prove the asymptotic almost-sure convergence of distributional GTD2 and TDC\nto a local optimal solution for general smooth function approximators, which\nincludes neural networks that have been widely used in recent study to solve\nthe real-life RL problems. In each step, the computational complexities of\nabove three algorithms are linear w.r.t.\\ the number of the parameters of the\nfunction approximator, thus can be implemented efficiently for neural networks.", "published": "2018-05-20T08:43:05Z", "version": 3}, {"aid": "1805.08239", "authors": ["Joshua I. Glaser", "Ari S. Benjamin", "Roozbeh Farhoodi", "Konrad P. Kording"], "title": "The Roles of Supervised Machine Learning in Systems Neuroscience", "url": "http://arxiv.org/pdf/1805.08239v2", "summary": "Over the last several years, the use of machine learning (ML) in neuroscience\nhas been rapidly increasing. Here, we review ML's contributions, both realized\nand potential, across several areas of systems neuroscience. We describe four\nprimary roles of ML within neuroscience: 1) creating solutions to engineering\nproblems, 2) identifying predictive variables, 3) setting benchmarks for simple\nmodels of the brain, and 4) serving itself as a model for the brain. The\nbreadth and ease of its applicability suggests that machine learning should be\nin the toolbox of most systems neuroscientists.", "published": "2018-05-21T18:11:26Z", "version": 2}, {"aid": "1805.08522", "authors": ["Guillermo Valle-P\u00e9rez", "Chico Q. Camargo", "Ard A. Louis"], "title": "Deep learning generalizes because the parameter-function map is biased towards simple functions", "url": "http://arxiv.org/pdf/1805.08522v5", "summary": "Deep neural networks (DNNs) generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime where classical\nlearning theory would instead predict that they would severely overfit. While\nmany proposals for some kind of implicit regularization have been made to\nrationalise this success, there is no consensus for the fundamental reason why\nDNNs do not strongly overfit. In this paper, we provide a new explanation. By\napplying a very general probability-complexity bound recently derived from\nalgorithmic information theory (AIT), we argue that the parameter-function map\nof many DNNs should be exponentially biased towards simple functions. We then\nprovide clear evidence for this strong simplicity bias in a model DNN for\nBoolean functions, as well as in much larger fully connected and convolutional\nnetworks applied to CIFAR10 and MNIST. As the target functions in many real\nproblems are expected to be highly structured, this intrinsic simplicity bias\nhelps explain why deep networks generalize well on real world problems. This\npicture also facilitates a novel PAC-Bayes approach where the prior is taken\nover the DNN input-output function space, rather than the more conventional\nprior over parameter space. If we assume that the training algorithm samples\nparameters close to uniformly within the zero-error region then the PAC-Bayes\ntheorem can be used to guarantee good expected generalization for target\nfunctions producing high-likelihood training sets. By exploiting recently\ndiscovered connections between DNNs and Gaussian processes to estimate the\nmarginal likelihood, we produce relatively tight generalization PAC-Bayes error\nbounds which correlate well with the true error on realistic datasets such as\nMNIST and CIFAR10 and for architectures including convolutional and fully\nconnected networks.", "published": "2018-05-22T11:51:36Z", "version": 5}, {"aid": "1805.08651", "authors": ["Aapo Hyvarinen", "Hiroaki Sasaki", "Richard E. Turner"], "title": "Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning", "url": "http://arxiv.org/pdf/1805.08651v3", "summary": "Nonlinear ICA is a fundamental problem for unsupervised representation\nlearning, emphasizing the capacity to recover the underlying latent variables\ngenerating the data (i.e., identifiability). Recently, the very first\nidentifiability proofs for nonlinear ICA have been proposed, leveraging the\ntemporal structure of the independent components. Here, we propose a general\nframework for nonlinear ICA, which, as a special case, can make use of temporal\nstructure. It is based on augmenting the data by an auxiliary variable, such as\nthe time index, the history of the time series, or any other available\ninformation. We propose to learn nonlinear ICA by discriminating between true\naugmented data, or data in which the auxiliary variable has been randomized.\nThis enables the framework to be implemented algorithmically through logistic\nregression, possibly in a neural network. We provide a comprehensive proof of\nthe identifiability of the model as well as the consistency of our estimation\nmethod. The approach not only provides a general theoretical framework\ncombining and generalizing previously proposed nonlinear ICA models and\nalgorithms, but also brings practical advantages.", "published": "2018-05-22T15:01:22Z", "version": 3}, {"aid": "1805.08819", "authors": ["Drew Linsley", "Dan Shiebler", "Sven Eberhardt", "Thomas Serre"], "title": "Learning what and where to attend", "url": "http://arxiv.org/pdf/1805.08819v4", "summary": "Most recent gains in visual recognition have originated from the inclusion of\nattention mechanisms in deep convolutional networks (DCNs). Because these\nnetworks are optimized for object recognition, they learn where to attend using\nonly a weak form of supervision derived from image class labels. Here, we\ndemonstrate the benefit of using stronger supervisory signals by teaching DCNs\nto attend to image regions that humans deem important for object recognition.\nWe first describe a large-scale online experiment (ClickMe) used to supplement\nImageNet with nearly half a million human-derived \"top-down\" attention maps.\nUsing human psychophysics, we confirm that the identified top-down features\nfrom ClickMe are more diagnostic than \"bottom-up\" saliency features for rapid\nimage categorization. As a proof of concept, we extend a state-of-the-art\nattention network and demonstrate that adding ClickMe supervision significantly\nimproves its accuracy and yields visual features that are more interpretable\nand more similar to those used by human observers.", "published": "2018-05-22T19:12:47Z", "version": 4}, {"aid": "1805.08899", "authors": ["Bojian Zheng", "Abhishek Tiwari", "Nandita Vijaykumar", "Gennady Pekhimenko"], "title": "Echo: Compiler-based GPU Memory Footprint Reduction for LSTM RNN Training", "url": "http://arxiv.org/pdf/1805.08899v5", "summary": "The Long-Short-Term-Memory Recurrent Neural Networks (LSTM RNNs) are a\npopular class of machine learning models for analyzing sequential data. Their\ntraining on modern GPUs, however, is limited by the GPU memory capacity. Our\nprofiling results of the LSTM RNN-based Neural Machine Translation (NMT) model\nreveal that feature maps of the attention and RNN layers form the memory\nbottleneck and runtime is unevenly distributed across different layers when\ntraining on GPUs. Based on these two observations, we propose to recompute the\nfeature maps rather than stashing them persistently in the GPU memory.\n  While the idea of feature map recomputation has been considered before,\nexisting solutions fail to deliver satisfactory footprint reduction, as they do\nnot address two key challenges. For each feature map recomputation to be\neffective and efficient, its effect on (1) the total memory footprint, and (2)\nthe total execution time has to be carefully estimated. To this end, we propose\n*Echo*, a new compiler-based optimization scheme that addresses the first\nchallenge with a practical mechanism that estimates the memory benefits of\nrecomputation over the entire computation graph, and the second challenge by\nnon-conservatively estimating the recomputation overhead leveraging layer\nspecifics. *Echo* reduces the GPU memory footprint automatically and\ntransparently without any changes required to the training source code, and is\neffective for models beyond LSTM RNNs.\n  We evaluate *Echo* on numerous state-of-the-art machine learning workloads on\nreal systems with modern GPUs and observe footprint reduction ratios of 1.89X\non average and 3.13X maximum. Such reduction can be converted into faster\ntraining with a larger batch size, savings in GPU energy consumption (e.g.,\ntraining with one GPU as fast as with four), and/or an increase in the maximum\nnumber of layers under the same GPU memory budget.", "published": "2018-05-22T23:01:25Z", "version": 5}, {"aid": "1805.09975", "authors": ["Daniel McDuff", "Ashish Kapoor"], "title": "Visceral Machines: Risk-Aversion in Reinforcement Learning with Intrinsic Physiological Rewards", "url": "http://arxiv.org/pdf/1805.09975v2", "summary": "As people learn to navigate the world, autonomic nervous system (e.g., \"fight\nor flight\") responses provide intrinsic feedback about the potential\nconsequence of action choices (e.g., becoming nervous when close to a cliff\nedge or driving fast around a bend.) Physiological changes are correlated with\nthese biological preparations to protect one-self from danger. We present a\nnovel approach to reinforcement learning that leverages a task-independent\nintrinsic reward function trained on peripheral pulse measurements that are\ncorrelated with human autonomic nervous system responses. Our hypothesis is\nthat such reward functions can circumvent the challenges associated with sparse\nand skewed rewards in reinforcement learning settings and can help improve\nsample efficiency. We test this in a simulated driving environment and show\nthat it can increase the speed of learning and reduce the number of collisions\nduring the learning stage.", "published": "2018-05-25T04:22:31Z", "version": 2}, {"aid": "1805.10863", "authors": ["Patrick McClure", "Charles Y. Zheng", "Jakub R. Kaczmarzyk", "John A. Lee", "Satrajit S. Ghosh", "Dylan Nielson", "Peter Bandettini", "Francisco Pereira"], "title": "Distributed Weight Consolidation: A Brain Segmentation Case Study", "url": "http://arxiv.org/pdf/1805.10863v9", "summary": "Collecting the large datasets needed to train deep neural networks can be\nvery difficult, particularly for the many applications for which sharing and\npooling data is complicated by practical, ethical, or legal concerns. However,\nit may be the case that derivative datasets or predictive models developed\nwithin individual sites can be shared and combined with fewer restrictions.\nTraining on distributed data and combining the resulting networks is often\nviewed as continual learning, but these methods require networks to be trained\nsequentially. In this paper, we introduce distributed weight consolidation\n(DWC), a continual learning method to consolidate the weights of separate\nneural networks, each trained on an independent dataset. We evaluated DWC with\na brain segmentation case study, where we consolidated dilated convolutional\nneural networks trained on independent structural magnetic resonance imaging\n(sMRI) datasets from different sites. We found that DWC led to increased\nperformance on test sets from the different sites, while maintaining\ngeneralization performance for a very large and completely independent\nmulti-site dataset, compared to an ensemble baseline.", "published": "2018-05-28T10:50:11Z", "version": 9}, {"aid": "1806.07370", "authors": ["Yunho Jeon", "Junmo Kim"], "title": "Constructing Fast Network through Deconstruction of Convolution", "url": "http://arxiv.org/pdf/1806.07370v5", "summary": "Convolutional neural networks have achieved great success in various vision\ntasks; however, they incur heavy resource costs. By using deeper and wider\nnetworks, network accuracy can be improved rapidly. However, in an environment\nwith limited resources (e.g., mobile applications), heavy networks may not be\nusable. This study shows that naive convolution can be deconstructed into a\nshift operation and pointwise convolution. To cope with various convolutions,\nwe propose a new shift operation called active shift layer (ASL) that\nformulates the amount of shift as a learnable function with shift parameters.\nThis new layer can be optimized end-to-end through backpropagation and it can\nprovide optimal shift values. Finally, we apply this layer to a light and fast\nnetwork that surpasses existing state-of-the-art networks.", "published": "2018-05-28T10:54:27Z", "version": 5}, {"aid": "1805.11144", "authors": ["Daniel Rasmussen"], "title": "NengoDL: Combining deep learning and neuromorphic modelling methods", "url": "http://arxiv.org/pdf/1805.11144v3", "summary": "NengoDL is a software framework designed to combine the strengths of\nneuromorphic modelling and deep learning. NengoDL allows users to construct\nbiologically detailed neural models, intermix those models with deep learning\nelements (such as convolutional networks), and then efficiently simulate those\nmodels in an easy-to-use, unified framework. In addition, NengoDL allows users\nto apply deep learning training methods to optimize the parameters of\nbiological neural models. In this paper we present basic usage examples,\nbenchmarking, and details on the key implementation elements of NengoDL. More\ndetails can be found at https://www.nengo.ai/nengo-dl .", "published": "2018-05-28T19:36:45Z", "version": 3}, {"aid": "1805.11704", "authors": ["Arna Ghosh", "Fabien dal Maso", "Marc Roig", "Georgios D Mitsis", "Marie-H\u00e9l\u00e8ne Boudrias"], "title": "Deep Semantic Architecture with discriminative feature visualization for neuroimage analysis", "url": "http://arxiv.org/pdf/1805.11704v2", "summary": "Neuroimaging data analysis often involves \\emph{a-priori} selection of data\nfeatures to study the underlying neural activity. Since this could lead to\nsub-optimal feature selection and thereby prevent the detection of subtle\npatterns in neural activity, data-driven methods have recently gained\npopularity for optimizing neuroimaging data analysis pipelines and thereby,\nimproving our understanding of neural mechanisms. In this context, we developed\na deep convolutional architecture that can identify discriminating patterns in\nneuroimaging data and applied it to electroencephalography (EEG) recordings\ncollected from 25 subjects performing a hand motor task before and after a rest\nperiod or a bout of exercise. The deep network was trained to classify subjects\ninto exercise and control groups based on differences in their EEG signals.\nSubsequently, we developed a novel method termed the cue-combination for Class\nActivation Map (ccCAM), which enabled us to identify discriminating\nspatio-temporal features within definite frequency bands (23--33 Hz) and assess\nthe effects of exercise on the brain. Additionally, the proposed architecture\nallowed the visualization of the differences in the propagation of underlying\nneural activity across the cortex between the two groups, for the first time in\nour knowledge. Our results demonstrate the feasibility of using deep network\narchitectures for neuroimaging analysis in different contexts such as, for the\nidentification of robust brain biomarkers to better characterize and\npotentially treat neurological disorders.", "published": "2018-05-29T20:55:09Z", "version": 2}, {"aid": "1805.11706", "authors": ["Quan Vuong", "Yiming Zhang", "Keith W. Ross"], "title": "Supervised Policy Update for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1805.11706v4", "summary": "We propose a new sample-efficient methodology, called Supervised Policy\nUpdate (SPU), for deep reinforcement learning. Starting with data generated by\nthe current policy, SPU formulates and solves a constrained optimization\nproblem in the non-parameterized proximal policy space. Using supervised\nregression, it then converts the optimal non-parameterized policy to a\nparameterized policy, from which it draws new samples. The methodology is\ngeneral in that it applies to both discrete and continuous action spaces, and\ncan handle a wide variety of proximity constraints for the non-parameterized\noptimization problem. We show how the Natural Policy Gradient and Trust Region\nPolicy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization\n(PPO) problem can be addressed by this methodology. The SPU implementation is\nmuch simpler than TRPO. In terms of sample efficiency, our extensive\nexperiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and\noutperforms PPO in Atari video game tasks.", "published": "2018-05-29T20:57:19Z", "version": 4}, {"aid": "1805.11718", "authors": ["Sidharth Gupta", "Konik Kothari", "Maarten V. de Hoop", "Ivan Dokmani\u0107"], "title": "Random mesh projectors for inverse problems", "url": "http://arxiv.org/pdf/1805.11718v3", "summary": "We propose a new learning-based approach to solve ill-posed inverse problems\nin imaging. We address the case where ground truth training samples are rare\nand the problem is severely ill-posed - both because of the underlying physics\nand because we can only get few measurements. This setting is common in\ngeophysical imaging and remote sensing. We show that in this case the common\napproach to directly learn the mapping from the measured data to the\nreconstruction becomes unstable. Instead, we propose to first learn an ensemble\nof simpler mappings from the data to projections of the unknown image into\nrandom piecewise-constant subspaces. We then combine the projections to form a\nfinal reconstruction by solving a deconvolution-like problem. We show\nexperimentally that the proposed method is more robust to measurement noise and\ncorruptions not seen during training than a directly learned inverse.", "published": "2018-05-29T21:36:05Z", "version": 3}, {"aid": "1805.12177", "authors": ["Aharon Azulay", "Yair Weiss"], "title": "Why do deep convolutional networks generalize so poorly to small image transformations?", "url": "http://arxiv.org/pdf/1805.12177v4", "summary": "Convolutional Neural Networks (CNNs) are commonly assumed to be invariant to\nsmall image transformations: either because of the convolutional architecture\nor because they were trained using data augmentation. Recently, several authors\nhave shown that this is not the case: small translations or rescalings of the\ninput image can drastically change the network's prediction. In this paper, we\nquantify this phenomena and ask why neither the convolutional architecture nor\ndata augmentation are sufficient to achieve the desired invariance.\nSpecifically, we show that the convolutional architecture does not give\ninvariance since architectures ignore the classical sampling theorem, and data\naugmentation does not give invariance because the CNNs learn to be invariant to\ntransformations only for images that are very similar to typical images from\nthe training set. We discuss two possible solutions to this problem: (1)\nantialiasing the intermediate representations and (2) increasing data\naugmentation and show that they provide only a partial solution at best. Taken\ntogether, our results indicate that the problem of insuring invariance to small\nimage transformations in neural networks while preserving high accuracy remains\nunsolved.", "published": "2018-05-30T18:56:33Z", "version": 4}, {"aid": "1806.00153", "authors": ["Juyoung Lee", "Yoseob Han", "Jae-Kyun Ryu", "Jang-Yeon Park", "Jong Chul Ye"], "title": "k-Space Deep Learning for Reference-free EPI Ghost Correction", "url": "http://arxiv.org/pdf/1806.00153v3", "summary": "Nyquist ghost artifacts in EPI are originated from phase mismatch between the\neven and odd echoes. However, conventional correction methods using reference\nscans often produce erroneous results especially in high-field MRI due to the\nnon-linear and time-varying local magnetic field changes. Recently, it was\nshown that the problem of ghost correction can be reformulated as k-space\ninterpolation problem that can be solved using structured low-rank Hankel\nmatrix approaches. Another recent work showed that data driven Hankel matrix\ndecomposition can be reformulated to exhibit similar structures as deep\nconvolutional neural network. By synergistically combining these findings, we\npropose a k-space deep learning approach that immediately corrects the phase\nmismatch without a reference scan in both accelerated and non-accelerated EPI\nacquisitions. To take advantage of the even and odd-phase directional\nredundancy, the k-space data is divided into two channels configured with even\nand odd phase encodings. The redundancies between coils are also exploited by\nstacking the multi-coil k-space data into additional input channels. Then, our\nk-space ghost correction network is trained to learn the interpolation kernel\nto estimate the missing virtual k-space data. For the accelerated EPI data, the\nsame neural network is trained to directly estimate the interpolation kernels\nfor missing k-space data from both ghost and subsampling. Reconstruction\nresults using 3T and 7T in-vivo data showed that the proposed method\noutperformed the image quality compared to the existing methods, and the\ncomputing time is much faster.The proposed k-space deep learning for EPI ghost\ncorrection is highly robust and fast, and can be combined with acceleration, so\nthat it can be used as a promising correction tool for high-field MRI without\nchanging the current acquisition protocol.", "published": "2018-06-01T01:01:27Z", "version": 3}, {"aid": "1806.02375", "authors": ["Johan Bjorck", "Carla Gomes", "Bart Selman", "Kilian Q. Weinberger"], "title": "Understanding Batch Normalization", "url": "http://arxiv.org/pdf/1806.02375v4", "summary": "Batch normalization (BN) is a technique to normalize activations in\nintermediate layers of deep neural networks. Its tendency to improve accuracy\nand speed up training have established BN as a favorite technique in deep\nlearning. Yet, despite its enormous success, there remains little consensus on\nthe exact reason and mechanism behind these improvements. In this paper we take\na step towards a better understanding of BN, following an empirical approach.\nWe conduct several experiments, and show that BN primarily enables training\nwith larger learning rates, which is the cause for faster convergence and\nbetter generalization. For networks without BN we demonstrate how large\ngradient updates can result in diverging loss and activations growing\nuncontrollably with network depth, which limits possible learning rates. BN\navoids this problem by constantly correcting activations to be zero-mean and of\nunit standard deviation, which enables larger gradient steps, yields faster\nconvergence and may help bypass sharp local minima. We further show various\nways in which gradients and activations of deep unnormalized networks are\nill-behaved. We contrast our results against recent findings in random matrix\ntheory, shedding new light on classical initialization schemes and their\nconsequences.", "published": "2018-06-01T03:57:56Z", "version": 4}, {"aid": "1806.00523", "authors": ["Kashyap Chitta"], "title": "Targeted Kernel Networks: Faster Convolutions with Attentive Regularization", "url": "http://arxiv.org/pdf/1806.00523v2", "summary": "We propose Attentive Regularization (AR), a method to constrain the\nactivation maps of kernels in Convolutional Neural Networks (CNNs) to specific\nregions of interest (ROIs). Each kernel learns a location of specialization\nalong with its weights through standard backpropagation. A differentiable\nattention mechanism requiring no additional supervision is used to optimize the\nROIs. Traditional CNNs of different types and structures can be modified with\nthis idea into equivalent Targeted Kernel Networks (TKNs), while keeping the\nnetwork size nearly identical. By restricting kernel ROIs, we reduce the number\nof sliding convolutional operations performed throughout the network in its\nforward pass, speeding up both training and inference. We evaluate our proposed\narchitecture on both synthetic and natural tasks across multiple domains. TKNs\nobtain significant improvements over baselines, requiring less computation\n(around an order of magnitude) while achieving superior performance.", "published": "2018-06-01T19:46:16Z", "version": 2}, {"aid": "1806.00952", "authors": ["Navid Azizan", "Babak Hassibi"], "title": "Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization", "url": "http://arxiv.org/pdf/1806.00952v4", "summary": "Stochastic descent methods (of the gradient and mirror varieties) have become\nincreasingly popular in optimization. In fact, it is now widely recognized that\nthe success of deep learning is not only due to the special deep architecture\nof the models, but also due to the behavior of the stochastic descent methods\nused, which play a key role in reaching \"good\" solutions that generalize well\nto unseen data. In an attempt to shed some light on why this is the case, we\nrevisit some minimax properties of stochastic gradient descent (SGD) for the\nsquare loss of linear models---originally developed in the 1990's---and extend\nthem to general stochastic mirror descent (SMD) algorithms for general loss\nfunctions and nonlinear models. In particular, we show that there is a\nfundamental identity which holds for SMD (and SGD) under very general\nconditions, and which implies the minimax optimality of SMD (and SGD) for\nsufficiently small step size, and for a general class of loss functions and\ngeneral nonlinear models. We further show that this identity can be used to\nnaturally establish other properties of SMD (and SGD), namely convergence and\nimplicit regularization for over-parameterized linear models (in what is now\nbeing called the \"interpolating regime\"), some of which have been shown in\ncertain cases in prior literature. We also argue how this identity can be used\nin the so-called \"highly over-parameterized\" nonlinear setting (where the\nnumber of parameters far exceeds the number of data points) to provide insights\ninto why SMD (and SGD) may have similar convergence and implicit regularization\nproperties for deep learning.", "published": "2018-06-04T04:53:00Z", "version": 4}, {"aid": "1806.01363", "authors": ["Giuseppe Cuccu", "Julian Togelius", "Philippe Cudre-Mauroux"], "title": "Playing Atari with Six Neurons", "url": "http://arxiv.org/pdf/1806.01363v2", "summary": "Deep reinforcement learning, applied to vision-based problems like Atari\ngames, maps pixels directly to actions; internally, the deep neural network\nbears the responsibility of both extracting useful information and making\ndecisions based on it. By separating the image processing from decision-making,\none could better understand the complexity of each task, as well as potentially\nfind smaller policy representations that are easier for humans to understand\nand may generalize better. To this end, we propose a new method for learning\npolicies and compact state representations separately but simultaneously for\npolicy approximation in reinforcement learning. State representations are\ngenerated by an encoder based on two novel algorithms: Increasing Dictionary\nVector Quantization makes the encoder capable of growing its dictionary size\nover time, to address new observations as they appear in an open-ended\nonline-learning context; Direct Residuals Sparse Coding encodes observations by\ndisregarding reconstruction error minimization, and aiming instead for highest\ninformation inclusion. The encoder autonomously selects observations online to\ntrain on, in order to maximize code sparsity. As the dictionary size increases,\nthe encoder produces increasingly larger inputs for the neural network: this is\naddressed by a variation of the Exponential Natural Evolution Strategies\nalgorithm which adapts its probability distribution dimensionality along the\nrun. We test our system on a selection of Atari games using tiny neural\nnetworks of only 6 to 18 neurons (depending on the game's controls). These are\nstill capable of achieving results comparable---and occasionally superior---to\nstate-of-the-art techniques which use two orders of magnitude more neurons.", "published": "2018-06-04T20:09:43Z", "version": 2}, {"aid": "1806.01376", "authors": ["Jian Ren", "Jianchao Yang", "Ning Xu", "David J. Foran"], "title": "Factorized Adversarial Networks for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/1806.01376v1", "summary": "In this paper, we propose Factorized Adversarial Networks (FAN) to solve\nunsupervised domain adaptation problems for image classification tasks. Our\nnetworks map the data distribution into a latent feature space, which is\nfactorized into a domain-specific subspace that contains domain-specific\ncharacteristics and a task-specific subspace that retains category information,\nfor both source and target domains, respectively. Unsupervised domain\nadaptation is achieved by adversarial training to minimize the discrepancy\nbetween the distributions of two task-specific subspaces from source and target\ndomains. We demonstrate that the proposed approach outperforms state-of-the-art\nmethods on multiple benchmark datasets used in the literature for unsupervised\ndomain adaptation. Furthermore, we collect two real-world tagging datasets that\nare much larger than existing benchmark datasets, and get significant\nimprovement upon baselines, proving the practical value of our approach.", "published": "2018-06-04T20:39:13Z", "version": 1}, {"aid": "1806.01387", "authors": ["Christian Guckelsberger", "Christoph Salge", "Julian Togelius"], "title": "New And Surprising Ways to Be Mean. Adversarial NPCs with Coupled Empowerment Minimisation", "url": "http://arxiv.org/pdf/1806.01387v1", "summary": "Creating Non-Player Characters (NPCs) that can react robustly to unforeseen\nplayer behaviour or novel game content is difficult and time-consuming. This\nhinders the design of believable characters, and the inclusion of NPCs in games\nthat rely heavily on procedural content generation. We have previously\naddressed this challenge by means of empowerment, a model of intrinsic\nmotivation, and demonstrated how a coupled empowerment maximisation (CEM)\npolicy can yield generic, companion-like behaviour. In this paper, we extend\nthe CEM framework with a minimisation policy to give rise to adversarial\nbehaviour. We conduct a qualitative, exploratory study in a dungeon-crawler\ngame, demonstrating that CEM can exploit the affordances of different content\nfacets in adaptive adversarial behaviour without modifications to the policy.\nChanges to the level design, underlying mechanics and our character's actions\ndo not threaten our NPC's robustness, but yield new and surprising ways to be\nmean.", "published": "2018-06-04T21:02:49Z", "version": 1}, {"aid": "1806.01423", "authors": ["Hananel Hazan", "Daniel J. Saunders", "Hassaan Khan", "Darpan T. Sanghavi", "Hava T. Siegelmann", "Robert Kozma"], "title": "BindsNET: A machine learning-oriented spiking neural networks library in Python", "url": "http://arxiv.org/pdf/1806.01423v2", "summary": "The development of spiking neural network simulation software is a critical\ncomponent enabling the modeling of neural systems and the development of\nbiologically inspired algorithms. Existing software frameworks support a wide\nrange of neural functionality, software abstraction levels, and hardware\ndevices, yet are typically not suitable for rapid prototyping or application to\nproblems in the domain of machine learning. In this paper, we describe a new\nPython package for the simulation of spiking neural networks, specifically\ngeared towards machine learning and reinforcement learning. Our software,\ncalled BindsNET, enables rapid building and simulation of spiking networks and\nfeatures user-friendly, concise syntax. BindsNET is built on top of the PyTorch\ndeep neural networks library, enabling fast CPU and GPU computation for large\nspiking networks. The BindsNET framework can be adjusted to meet the needs of\nother existing computing and hardware environments, e.g., TensorFlow. We also\nprovide an interface into the OpenAI gym library, allowing for training and\nevaluation of spiking networks on reinforcement learning problems. We argue\nthat this package facilitates the use of spiking networks for large-scale\nmachine learning experimentation, and show some simple examples of how we\nenvision BindsNET can be used in practice. BindsNET code is available at\nhttps://github.com/Hananel-Hazan/bindsnet", "published": "2018-06-04T23:09:52Z", "version": 2}, {"aid": "1806.01502", "authors": ["Yen Yu", "Acer Y. C. Chang", "Ryota Kanai"], "title": "Boredom-driven curious learning by Homeo-Heterostatic Value Gradients", "url": "http://arxiv.org/pdf/1806.01502v1", "summary": "This paper presents the Homeo-Heterostatic Value Gradients (HHVG) algorithm\nas a formal account on the constructive interplay between boredom and curiosity\nwhich gives rise to effective exploration and superior forward model learning.\nWe envisaged actions as instrumental in agent's own epistemic disclosure. This\nmotivated two central algorithmic ingredients: devaluation and devaluation\nprogress, both underpin agent's cognition concerning intrinsically generated\nrewards. The two serve as an instantiation of homeostatic and heterostatic\nintrinsic motivation. A key insight from our algorithm is that the two\nseemingly opposite motivations can be reconciled---without which exploration\nand information-gathering cannot be effectively carried out. We supported this\nclaim with empirical evidence, showing that boredom-enabled agents consistently\noutperformed other curious or explorative agent variants in model building\nbenchmarks based on self-assisted experience accumulation.", "published": "2018-06-05T05:34:46Z", "version": 1}, {"aid": "1806.01547", "authors": ["Ankita Shukla", "Gullal Singh Cheema", "Saket Anand"], "title": "Semi-Supervised Clustering with Neural Networks", "url": "http://arxiv.org/pdf/1806.01547v2", "summary": "Clustering using neural networks has recently demonstrated promising\nperformance in machine learning and computer vision applications. However, the\nperformance of current approaches is limited either by unsupervised learning or\ntheir dependence on large set of labeled data samples. In this paper, we\npropose ClusterNet that uses pairwise semantic constraints from very few\nlabeled data samples (<5% of total data) and exploits the abundant unlabeled\ndata to drive the clustering approach. We define a new loss function that uses\npairwise semantic similarity between objects combined with constrained k-means\nclustering to efficiently utilize both labeled and unlabeled data in the same\nframework. The proposed network uses convolution autoencoder to learn a latent\nrepresentation that groups data into k specified clusters, while also learning\nthe cluster centers simultaneously. We evaluate and compare the performance of\nClusterNet on several datasets and state of the art deep clustering approaches.", "published": "2018-06-05T08:23:42Z", "version": 2}, {"aid": "1806.01655", "authors": ["Vinayak Kumar", "Vaibhav Singh", "P. K. Srijith", "Andreas Damianou"], "title": "Deep Gaussian Processes with Convolutional Kernels", "url": "http://arxiv.org/pdf/1806.01655v1", "summary": "Deep Gaussian processes (DGPs) provide a Bayesian non-parametric alternative\nto standard parametric deep learning models. A DGP is formed by stacking\nmultiple GPs resulting in a well-regularized composition of functions. The\nBayesian framework that equips the model with attractive properties, such as\nimplicit capacity control and predictive uncertainty, makes it at the same time\nchallenging to combine with a convolutional structure. This has hindered the\napplication of DGPs in computer vision tasks, an area where deep parametric\nmodels (i.e. CNNs) have made breakthroughs. Standard kernels used in DGPs such\nas radial basis functions (RBFs) are insufficient for handling pixel\nvariability in raw images. In this paper, we build on the recent convolutional\nGP to develop Convolutional DGP (CDGP) models which effectively capture image\nlevel features through the use of convolution kernels, therefore opening up the\nway for applying DGPs to computer vision tasks. Our model learns local spatial\ninfluence and outperforms strong GP based baselines on multi-class image\nclassification. We also consider various constructions of convolution kernel\nover the image patches, analyze the computational trade-offs and provide an\nefficient framework for convolutional DGP models. The experimental results on\nimage data such as MNIST, rectangles-image, CIFAR10 and Caltech101 demonstrate\nthe effectiveness of the proposed approaches.", "published": "2018-06-05T12:41:14Z", "version": 1}, {"aid": "1806.01709", "authors": ["Leonidas A. A. Doumas", "Guillermo Puebla", "Andrea E. Martin"], "title": "Human-like generalization in a machine through predicate learning", "url": "http://arxiv.org/pdf/1806.01709v3", "summary": "Humans readily generalize, applying prior knowledge to novel situations and\nstimuli. Advances in machine learning and artificial intelligence have begun to\napproximate and even surpass human performance, but machine systems reliably\nstruggle to generalize information to untrained situations. We describe a\nneural network model that is trained to play one video game (Breakout) and\ndemonstrates one-shot generalization to a new game (Pong). The model\ngeneralizes by learning representations that are functionally and formally\nsymbolic from training data, without feedback, and without requiring that\nstructured representations be specified a priori. The model uses unsupervised\ncomparison to discover which characteristics of the input are invariant, and to\nlearn relational predicates; it then applies these predicates to arguments in a\nsymbolic fashion, using oscillatory regularities in network firing to\ndynamically bind predicates to arguments. We argue that models of human\ncognition must account for far-reaching and flexible generalization, and that\nin order to do so, models must be able to discover symbolic representations\nfrom unstructured data, a process we call predicate learning. Only then can\nmodels begin to adequately explain where human-like representations come from,\nwhy human cognition is the way it is, and why it continues to differ from\nmachine intelligence in crucial ways.", "published": "2018-06-05T14:21:20Z", "version": 3}, {"aid": "1806.01756", "authors": ["Daniel T Chang"], "title": "Concept-Oriented Deep Learning", "url": "http://arxiv.org/pdf/1806.01756v1", "summary": "Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.", "published": "2018-06-05T15:50:30Z", "version": 1}, {"aid": "1806.01910", "authors": ["Robert Peharz", "Antonio Vergari", "Karl Stelzner", "Alejandro Molina", "Martin Trapp", "Kristian Kersting", "Zoubin Ghahramani"], "title": "Probabilistic Deep Learning using Random Sum-Product Networks", "url": "http://arxiv.org/pdf/1806.01910v2", "summary": "The need for consistent treatment of uncertainty has recently triggered\nincreased interest in probabilistic deep learning methods. However, most\ncurrent approaches have severe limitations when it comes to inference, since\nmany of these models do not even permit to evaluate exact data likelihoods.\nSum-product networks (SPNs), on the other hand, are an excellent architecture\nin that regard, as they allow to efficiently evaluate likelihoods, as well as\narbitrary marginalization and conditioning tasks. Nevertheless, SPNs have not\nbeen fully explored as serious deep learning models, likely due to their\nspecial structural requirements, which complicate learning. In this paper, we\nmake a drastic simplification and use random SPN structures which are trained\nin a \"classical deep learning manner\", i.e. employing automatic\ndifferentiation, SGD, and GPU support. The resulting models, called RAT-SPNs,\nyield prediction results comparable to deep neural networks, while still being\ninterpretable as generative model and maintaining well-calibrated\nuncertainties. This property makes them highly robust under missing input\nfeatures and enables them to naturally detect outliers and peculiar samples.", "published": "2018-06-05T19:44:44Z", "version": 2}, {"aid": "1806.02003", "authors": ["Abhejit Rajagopal", "Shivkumar Chandrasekaran", "Hrushikesh N. Mhaskar"], "title": "Deep Algorithms: designs for networks", "url": "http://arxiv.org/pdf/1806.02003v1", "summary": "A new design methodology for neural networks that is guided by traditional\nalgorithm design is presented. To prove our point, we present two heuristics\nand demonstrate an algorithmic technique for incorporating additional weights\nin their signal-flow graphs. We show that with training the performance of\nthese networks can not only exceed the performance of the initial network, but\ncan match the performance of more-traditional neural network architectures. A\nkey feature of our approach is that these networks are initialized with\nparameters that provide a known performance threshold for the architecture on a\ngiven task.", "published": "2018-06-06T04:39:37Z", "version": 1}, {"aid": "1806.02336", "authors": ["Naoyuki Ichimura"], "title": "Spatial Frequency Loss for Learning Convolutional Autoencoders", "url": "http://arxiv.org/pdf/1806.02336v1", "summary": "This paper presents a learning method for convolutional autoencoders (CAEs)\nfor extracting features from images. CAEs can be obtained by utilizing\nconvolutional neural networks to learn an approximation to the identity\nfunction in an unsupervised manner. The loss function based on the pixel loss\n(PL) that is the mean squared error between the pixel values of original and\nreconstructed images is the common choice for learning. However, using the loss\nfunction leads to blurred reconstructed images. A method for learning CAEs\nusing a loss function computed from features reflecting spatial frequencies is\nproposed to mitigate the problem. The blurs in reconstructed images show lack\nof high spatial frequency components mainly constituting edges and detailed\ntextures that are important features for tasks such as object detection and\nspatial matching. In order to evaluate the lack of components, a convolutional\nlayer with a Laplacian filter bank as weights is added to CAEs and the mean\nsquared error of features in a subband, called the spatial frequency loss\n(SFL), is computed from the outputs of each filter. The learning is performed\nusing a loss function based on the SFL. Empirical evaluation demonstrates that\nusing the SFL reduces the blurs in reconstructed images.", "published": "2018-06-06T08:34:12Z", "version": 1}, {"aid": "1806.02091", "authors": ["Andreas Makoto Hein", "H\u00e9l\u00e8ne Condat"], "title": "Can Machines Design? An Artificial General Intelligence Approach", "url": "http://arxiv.org/pdf/1806.02091v4", "summary": "Can machines design? Can they come up with creative solutions to problems and\nbuild tools and artifacts across a wide range of domains? Recent advances in\nthe field of computational creativity and formal Artificial General\nIntelligence (AGI) provide frameworks for machines with the general ability to\ndesign. In this paper we propose to integrate a formal computational creativity\nframework into the G\\\"odel machine framework. We call the resulting framework\ndesign G\\\"odel machine. Such a machine could solve a variety of design problems\nby generating novel concepts. In addition, it could change the way these\nconcepts are generated by modifying itself. The design G\\\"odel machine is able\nto improve its initial design program, once it has proven that a modification\nwould increase its return on the utility function. Finally, we sketch out a\nspecific version of the design G\\\"odel machine which specifically addresses the\ndesign of complex software and hardware systems. Future work aims at the\ndevelopment of a more formal version of the design G\\\"odel machine and a proof\nof concept implementation.", "published": "2018-06-06T09:41:58Z", "version": 4}, {"aid": "1806.03961", "authors": ["Liangbo He", "Hao Sun"], "title": "Attention Incorporate Network: A network can adapt various data size", "url": "http://arxiv.org/pdf/1806.03961v1", "summary": "In traditional neural networks for image processing, the inputs of the neural\nnetworks should be the same size such as 224*224*3. But how can we train the\nneural net model with different input size? A common way to do is image\ndeformation which accompany a problem of information loss (e.g. image crop or\nwrap). Sequence model(RNN, LSTM, etc.) can accept different size of input like\ntext and audio. But one disadvantage for sequence model is that the previous\ninformation will become more fragmentary during the transfer in time step, it\nwill make the network hard to train especially for long sequential data. In\nthis paper we propose a new network structure called Attention Incorporate\nNetwork(AIN). It solve the problem of different size of inputs including:\nimages, text, audio, and extract the key features of the inputs by attention\nmechanism, pay different attention depends on the importance of the features\nnot rely on the data size. Experimentally, AIN achieve a higher accuracy,\nbetter convergence comparing to the same size of other network structure", "published": "2018-06-06T11:09:35Z", "version": 1}, {"aid": "1806.02137", "authors": ["Abel Torres Montoya"], "title": "A New Framework for Machine Intelligence: Concepts and Prototype", "url": "http://arxiv.org/pdf/1806.02137v1", "summary": "Machine learning (ML) and artificial intelligence (AI) have become hot topics\nin many information processing areas, from chatbots to scientific data\nanalysis. At the same time, there is uncertainty about the possibility of\nextending predominant ML technologies to become general solutions with\ncontinuous learning capabilities. Here, a simple, yet comprehensive,\ntheoretical framework for intelligent systems is presented. A combination of\nMirror Compositional Representations (MCR) and a Solution-Critic Loop (SCL) is\nproposed as a generic approach for different types of problems. A prototype\nimplementation is presented for document comparison using English Wikipedia\ncorpus.", "published": "2018-06-06T12:06:33Z", "version": 1}, {"aid": "1806.02296", "authors": ["Edward T. Reehorst", "Philip Schniter"], "title": "Regularization by Denoising: Clarifications and New Interpretations", "url": "http://arxiv.org/pdf/1806.02296v4", "summary": "Regularization by Denoising (RED), as recently proposed by Romano, Elad, and\nMilanfar, is powerful image-recovery framework that aims to minimize an\nexplicit regularization objective constructed from a plug-in image-denoising\nfunction. Experimental evidence suggests that the RED algorithms are\nstate-of-the-art. We claim, however, that explicit regularization does not\nexplain the RED algorithms. In particular, we show that many of the expressions\nin the paper by Romano et al. hold only when the denoiser has a symmetric\nJacobian, and we demonstrate that such symmetry does not occur with practical\ndenoisers such as non-local means, BM3D, TNRD, and DnCNN. To explain the RED\nalgorithms, we propose a new framework called Score-Matching by Denoising\n(SMD), which aims to match a \"score\" (i.e., the gradient of a log-prior). We\nthen show tight connections between SMD, kernel density estimation, and\nconstrained minimum mean-squared error denoising. Furthermore, we interpret the\nRED algorithms from Romano et al. and propose new algorithms with acceleration\nand convergence guarantees. Finally, we show that the RED algorithms seek a\nconsensus equilibrium solution, which facilitates a comparison to plug-and-play\nADMM.", "published": "2018-06-06T16:49:59Z", "version": 4}, {"aid": "1806.02508", "authors": ["Chen Chen", "Qizhen Weng", "Wei Wang", "Baochun Li", "Bo Li"], "title": "Semi-Dynamic Load Balancing: Efficient Distributed Learning in Non-Dedicated Environments", "url": "http://arxiv.org/pdf/1806.02508v2", "summary": "Machine learning (ML) models are increasingly trained in clusters with\nnon-dedicated workers possessing heterogeneous resources. In such scenarios,\nmodel training efficiency can be negatively affected by stragglers -- workers\nthat run much slower than others. Efficient model training requires eliminating\nsuch stragglers, yet for modern ML workloads, existing load balancing\nstrategies are inefficient and even infeasible. In this paper, we propose a\nnovel strategy called semi-dynamic load balancing to eliminate stragglers of\ndistributed ML workloads. The key insight is that ML workers shall be\nload-balanced at iteration boundaries, being non-intrusive to intra-iteration\nexecution. We develop LB-BSP based on such an insight, which is an integrated\nworker coordination mechanism that adapts workers' load to their instantaneous\nprocessing capabilities by right-sizing the sample batches at the\nsynchronization barriers. We have custom-designed the batch sizing algorithm\nrespectively for CPU and GPU clusters based on their own characteristics.\nLB-BSP has been implemented as a Python module for ML frameworks like\nTensorFlow and PyTorch. Our EC2 deployment confirms that LB-BSP is practical,\neffective and light-weight, and is able to accelerating distributed training by\nup to $54\\%$.", "published": "2018-06-07T04:15:58Z", "version": 2}, {"aid": "1806.02623", "authors": ["Jie Zhang", "Yan Wang", "Jie Tang", "Ming Ding"], "title": "Spectral Network Embedding: A Fast and Scalable Method via Sparsity", "url": "http://arxiv.org/pdf/1806.02623v2", "summary": "Network embedding aims to learn low-dimensional representations of nodes in a\nnetwork, while the network structure and inherent properties are preserved. It\nhas attracted tremendous attention recently due to significant progress in\ndownstream network learning tasks, such as node classification, link\nprediction, and visualization. However, most existing network embedding methods\nsuffer from the expensive computations due to the large volume of networks. In\nthis paper, we propose a $10\\times \\sim 100\\times$ faster network embedding\nmethod, called Progle, by elegantly utilizing the sparsity property of online\nnetworks and spectral analysis. In Progle, we first construct a \\textit{sparse}\nproximity matrix and train the network embedding efficiently via sparse matrix\ndecomposition. Then we introduce a network propagation pattern via spectral\nanalysis to incorporate local and global structure information into the\nembedding. Besides, this model can be generalized to integrate network\ninformation into other insufficiently trained embeddings at speed. Benefiting\nfrom sparse spectral network embedding, our experiment on four different\ndatasets shows that Progle outperforms or is comparable to state-of-the-art\nunsupervised comparison approaches---DeepWalk, LINE, node2vec, GraRep, and\nHOPE, regarding accuracy, while is $10\\times$ faster than the fastest\nword2vec-based method. Finally, we validate the scalability of Progle both in\nreal large-scale networks and multiple scales of synthetic networks.", "published": "2018-06-07T11:38:34Z", "version": 2}, {"aid": "1806.02942", "authors": ["Yu Li", "Zhongxiao Li", "Lizhong Ding", "Yijie Pan", "Chao Huang", "Yuhui Hu", "Wei Chen", "Xin Gao"], "title": "SupportNet: solving catastrophic forgetting in class incremental learning with support data", "url": "http://arxiv.org/pdf/1806.02942v3", "summary": "A plain well-trained deep learning model often does not have the ability to\nlearn new knowledge without forgetting the previously learned knowledge, which\nis known as catastrophic forgetting. Here we propose a novel method,\nSupportNet, to efficiently and effectively solve the catastrophic forgetting\nproblem in the class incremental learning scenario. SupportNet combines the\nstrength of deep learning and support vector machine (SVM), where SVM is used\nto identify the support data from the old data, which are fed to the deep\nlearning model together with the new data for further training so that the\nmodel can review the essential information of the old data when learning the\nnew information. Two powerful consolidation regularizers are applied to\nstabilize the learned representation and ensure the robustness of the learned\nmodel. We validate our method with comprehensive experiments on various tasks,\nwhich show that SupportNet drastically outperforms the state-of-the-art\nincremental learning methods and even reaches similar performance as the deep\nlearning model trained from scratch on both old and new data. Our program is\naccessible at: https://github.com/lykaust15/SupportNet", "published": "2018-06-08T01:58:51Z", "version": 3}, {"aid": "1806.03751", "authors": ["Michael Hauser", "Sean Gunn", "Samer Saab Jr", "Asok Ray"], "title": "State Space Representations of Deep Neural Networks", "url": "http://arxiv.org/pdf/1806.03751v3", "summary": "This paper deals with neural networks as dynamical systems governed by\ndifferential or difference equations. It shows that the introduction of skip\nconnections into network architectures, such as residual networks and dense\nnetworks, turns a system of static equations into a system of dynamical\nequations with varying levels of smoothness on the layer-wise transformations.\nClosed form solutions for the state space representations of general dense\nnetworks, as well as $k^{th}$ order smooth networks, are found in general\nsettings. Furthermore, it is shown that imposing $k^{th}$ order smoothness on a\nnetwork architecture with $d$-many nodes per layer increases the state space\ndimension by a multiple of $k$, and so the effective embedding dimension of the\ndata manifold is $k \\cdot d$-many dimensions. It follows that network\narchitectures of these types reduce the number of parameters needed to maintain\nthe same embedding dimension by a factor of $k^2$ when compared to an\nequivalent first-order, residual network, significantly motivating the\ndevelopment of network architectures of these types. Numerical simulations were\nrun to validate parts of the developed theory.", "published": "2018-06-11T00:26:13Z", "version": 3}, {"aid": "1806.06927", "authors": ["Jaehong Kim", "Sangyeul Lee", "Sungwan Kim", "Moonsu Cha", "Jung Kwon Lee", "Youngduck Choi", "Yongseok Choi", "Dong-Yeon Cho", "Jiwon Kim"], "title": "Auto-Meta: Automated Gradient Based Meta Learner Search", "url": "http://arxiv.org/pdf/1806.06927v2", "summary": "Fully automating machine learning pipelines is one of the key challenges of\ncurrent artificial intelligence research, since practical machine learning\noften requires costly and time-consuming human-powered processes such as model\ndesign, algorithm development, and hyperparameter tuning. In this paper, we\nverify that automated architecture search synergizes with the effect of\ngradient-based meta learning. We adopt the progressive neural architecture\nsearch \\cite{liu:pnas_google:DBLP:journals/corr/abs-1712-00559} to find optimal\narchitectures for meta-learners. The gradient based meta-learner whose\narchitecture was automatically found achieved state-of-the-art results on the\n5-shot 5-way Mini-ImageNet classification problem with $74.65\\%$ accuracy,\nwhich is $11.54\\%$ improvement over the result obtained by the first\ngradient-based meta-learner called MAML\n\\cite{finn:maml:DBLP:conf/icml/FinnAL17}. To our best knowledge, this work is\nthe first successful neural architecture search implementation in the context\nof meta learning.", "published": "2018-06-11T04:28:02Z", "version": 2}, {"aid": "1806.06928", "authors": ["Risto Vuorio", "Dong-Yeon Cho", "Daejoong Kim", "Jiwon Kim"], "title": "Meta Continual Learning", "url": "http://arxiv.org/pdf/1806.06928v1", "summary": "Using neural networks in practical settings would benefit from the ability of\nthe networks to learn new tasks throughout their lifetimes without forgetting\nthe previous tasks. This ability is limited in the current deep neural networks\nby a problem called catastrophic forgetting, where training on new tasks tends\nto severely degrade performance on previous tasks. One way to lessen the impact\nof the forgetting problem is to constrain parameters that are important to\nprevious tasks to stay close to the optimal parameters. Recently, multiple\ncompetitive approaches for computing the importance of the parameters with\nrespect to the previous tasks have been presented. In this paper, we propose a\nlearning to optimize algorithm for mitigating catastrophic forgetting. Instead\nof trying to formulate a new constraint function ourselves, we propose to train\nanother neural network to predict parameter update steps that respect the\nimportance of parameters to the previous tasks. In the proposed meta-training\nscheme, the update predictor is trained to minimize loss on a combination of\ncurrent and past tasks. We show experimentally that the proposed approach works\nin the continual learning setting.", "published": "2018-06-11T06:49:54Z", "version": 1}, {"aid": "1806.03891", "authors": ["Juil Sock", "Kwang In Kim", "Caner Sahin", "Tae-Kyun Kim"], "title": "Multi-Task Deep Networks for Depth-Based 6D Object Pose and Joint Registration in Crowd Scenarios", "url": "http://arxiv.org/pdf/1806.03891v1", "summary": "In bin-picking scenarios, multiple instances of an object of interest are\nstacked in a pile randomly, and hence, the instances are inherently subjected\nto the challenges: severe occlusion, clutter, and similar-looking distractors.\nMost existing methods are, however, for single isolated object instances, while\nsome recent methods tackle crowd scenarios as post-refinement which accounts\nmultiple object relations. In this paper, we address recovering 6D poses of\nmultiple instances in bin-picking scenarios in depth modality by multi-task\nlearning in deep neural networks. Our architecture jointly learns multiple\nsub-tasks: 2D detection, depth, and 3D pose estimation of individual objects;\nand joint registration of multiple objects. For training data generation, depth\nimages of physically plausible object pose configurations are generated by a 3D\nobject model in a physics simulation, which yields diverse occlusion patterns\nto learn. We adopt a state-of-the-art object detector, and 2D offsets are\nfurther estimated via a network to refine misaligned 2D detections. The depth\nand 3D pose estimator is designed to generate multiple hypotheses per\ndetection. This allows the joint registration network to learn occlusion\npatterns and remove physically implausible pose hypotheses. We apply our\narchitecture on both synthetic (our own and Sileane dataset) and real (a public\nBin-Picking dataset) data, showing that it significantly outperforms\nstate-of-the-art methods by 15-31% in average precision.", "published": "2018-06-11T10:05:42Z", "version": 1}, {"aid": "1806.04734", "authors": ["Eli Schwartz", "Leonid Karlinsky", "Joseph Shtok", "Sivan Harary", "Mattias Marder", "Rogerio Feris", "Abhishek Kumar", "Raja Giryes", "Alex M. Bronstein"], "title": "Delta-encoder: an effective sample synthesis method for few-shot object recognition", "url": "http://arxiv.org/pdf/1806.04734v3", "summary": "Learning to classify new categories based on just one or a few examples is a\nlong-standing challenge in modern computer vision. In this work, we proposes a\nsimple yet effective method for few-shot (and one-shot) object recognition. Our\napproach is based on a modified auto-encoder, denoted Delta-encoder, that\nlearns to synthesize new samples for an unseen category just by seeing few\nexamples from it. The synthesized samples are then used to train a classifier.\nThe proposed approach learns to both extract transferable intra-class\ndeformations, or \"deltas\", between same-class pairs of training examples, and\nto apply those deltas to the few provided examples of a novel class (unseen\nduring training) in order to efficiently synthesize samples from that new\nclass. The proposed method improves over the state-of-the-art in one-shot\nobject-recognition and compares favorably in the few-shot case. Upon acceptance\ncode will be made available.", "published": "2018-06-12T19:31:11Z", "version": 3}, {"aid": "1806.04808", "authors": ["Guansong Pang", "Longbing Cao", "Ling Chen", "Huan Liu"], "title": "Learning Representations of Ultrahigh-dimensional Data for Random Distance-based Outlier Detection", "url": "http://arxiv.org/pdf/1806.04808v1", "summary": "Learning expressive low-dimensional representations of ultrahigh-dimensional\ndata, e.g., data with thousands/millions of features, has been a major way to\nenable learning methods to address the curse of dimensionality. However,\nexisting unsupervised representation learning methods mainly focus on\npreserving the data regularity information and learning the representations\nindependently of subsequent outlier detection methods, which can result in\nsuboptimal and unstable performance of detecting irregularities (i.e.,\noutliers).\n  This paper introduces a ranking model-based framework, called RAMODO, to\naddress this issue. RAMODO unifies representation learning and outlier\ndetection to learn low-dimensional representations that are tailored for a\nstate-of-the-art outlier detection approach - the random distance-based\napproach. This customized learning yields more optimal and stable\nrepresentations for the targeted outlier detectors. Additionally, RAMODO can\nleverage little labeled data as prior knowledge to learn more expressive and\napplication-relevant representations. We instantiate RAMODO to an efficient\nmethod called REPEN to demonstrate the performance of RAMODO.\n  Extensive empirical results on eight real-world ultrahigh dimensional data\nsets show that REPEN (i) enables a random distance-based detector to obtain\nsignificantly better AUC performance and two orders of magnitude speedup; (ii)\nperforms substantially better and more stably than four state-of-the-art\nrepresentation learning methods; and (iii) leverages less than 1% labeled data\nto achieve up to 32% AUC improvement.", "published": "2018-06-13T00:53:56Z", "version": 1}, {"aid": "1806.04854", "authors": ["Mohammad Emtiyaz Khan", "Didrik Nielsen", "Voot Tangkaratt", "Wu Lin", "Yarin Gal", "Akash Srivastava"], "title": "Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam", "url": "http://arxiv.org/pdf/1806.04854v3", "summary": "Uncertainty computation in deep learning is essential to design robust and\nreliable systems. Variational inference (VI) is a promising approach for such\ncomputation, but requires more effort to implement and execute compared to\nmaximum-likelihood methods. In this paper, we propose new natural-gradient\nalgorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms\ncan be implemented within the Adam optimizer by perturbing the network weights\nduring gradient evaluations, and uncertainty estimates can be cheaply obtained\nby using the vector that adapts the learning rate. This requires lower memory,\ncomputation, and implementation effort than existing VI methods, while\nobtaining uncertainty estimates of comparable quality. Our empirical results\nconfirm this and further suggest that the weight-perturbation in our algorithm\ncould be useful for exploration in reinforcement learning and stochastic\noptimization.", "published": "2018-06-13T05:45:22Z", "version": 3}, {"aid": "1806.05034", "authors": ["Simon A. A. Kohl", "Bernardino Romera-Paredes", "Clemens Meyer", "Jeffrey De Fauw", "Joseph R. Ledsam", "Klaus H. Maier-Hein", "S. M. Ali Eslami", "Danilo Jimenez Rezende", "Olaf Ronneberger"], "title": "A Probabilistic U-Net for Segmentation of Ambiguous Images", "url": "http://arxiv.org/pdf/1806.05034v4", "summary": "Many real-world vision problems suffer from inherent ambiguities. In clinical\napplications for example, it might not be clear from a CT scan alone which\nparticular region is cancer tissue. Therefore a group of graders typically\nproduces a set of diverse but plausible segmentations. We consider the task of\nlearning a distribution over segmentations given an input. To this end we\npropose a generative segmentation model based on a combination of a U-Net with\na conditional variational autoencoder that is capable of efficiently producing\nan unlimited number of plausible hypotheses. We show on a lung abnormalities\nsegmentation task and on a Cityscapes segmentation task that our model\nreproduces the possible segmentation variants as well as the frequencies with\nwhich they occur, doing so significantly better than published approaches.\nThese models could have a high impact in real-world applications, such as being\nused as clinical decision-making algorithms accounting for multiple plausible\nsemantic segmentation hypotheses to provide possible diagnoses and recommend\nfurther actions to resolve the present ambiguities.", "published": "2018-06-13T13:47:04Z", "version": 4}, {"aid": "1806.05226", "authors": ["Artur Jordao", "Antonio C. Nazare Jr.", "Jessica Sena", "William Robson Schwartz"], "title": "Human Activity Recognition Based on Wearable Sensor Data: A Standardization of the State-of-the-Art", "url": "http://arxiv.org/pdf/1806.05226v3", "summary": "Human activity recognition based on wearable sensor data has been an\nattractive research topic due to its application in areas such as healthcare\nand smart environments. In this context, many works have presented remarkable\nresults using accelerometer, gyroscope and magnetometer data to represent the\nactivities categories. However, current studies do not consider important\nissues that lead to skewed results, making it hard to assess the quality of\nsensor-based human activity recognition and preventing a direct comparison of\nprevious works. These issues include the samples generation processes and the\nvalidation protocols used. We emphasize that in other research areas, such as\nimage classification and object detection, these issues are already\nwell-defined, which brings more efforts towards the application. Inspired by\nthis, we conduct an extensive set of experiments that analyze different sample\ngeneration processes and validation protocols to indicate the vulnerable points\nin human activity recognition based on wearable sensor data. For this purpose,\nwe implement and evaluate several top-performance methods, ranging from\nhandcrafted-based approaches to convolutional neural networks. According to our\nstudy, most of the experimental evaluations that are currently employed are not\nadequate to perform the activity recognition in the context of wearable sensor\ndata, in which the recognition accuracy drops considerably when compared to an\nappropriate evaluation approach. To the best of our knowledge, this is the\nfirst study that tackles essential issues that compromise the understanding of\nthe performance in human activity recognition based on wearable sensor data.", "published": "2018-06-13T19:07:29Z", "version": 3}, {"aid": "1806.05234", "authors": ["Daniele Funaro"], "title": "Understanding the Meaning of Understanding", "url": "http://arxiv.org/pdf/1806.05234v2", "summary": "Can we train a machine to detect if another machine has understood a concept?\nIn principle, this is possible by conducting tests on the subject of that\nconcept. However we want this procedure to be done by avoiding direct\nquestions. In other words, we would like to isolate the absolute meaning of an\nabstract idea by putting it into a class of equivalence, hence without adopting\nstraight definitions or showing how this idea \"works\" in practice. We discuss\nthe metaphysical implications hidden in the above question, with the aim of\nproviding a plausible reference framework.", "published": "2018-06-13T19:26:55Z", "version": 2}, {"aid": "1806.05759", "authors": ["Ari S. Morcos", "Maithra Raghu", "Samy Bengio"], "title": "Insights on representational similarity in neural networks with canonical correlation", "url": "http://arxiv.org/pdf/1806.05759v3", "summary": "Comparing different neural network representations and determining how\nrepresentations evolve over time remain challenging open questions in our\nunderstanding of the function of neural networks. Comparing representations in\nneural networks is fundamentally difficult as the structure of representations\nvaries greatly, even across groups of networks trained on identical tasks, and\nover the course of training. Here, we develop projection weighted CCA\n(Canonical Correlation Analysis) as a tool for understanding neural networks,\nbuilding off of SVCCA, a recently proposed method (Raghu et al., 2017). We\nfirst improve the core method, showing how to differentiate between signal and\nnoise, and then apply this technique to compare across a group of CNNs,\ndemonstrating that networks which generalize converge to more similar\nrepresentations than networks which memorize, that wider networks converge to\nmore similar solutions than narrow networks, and that trained networks with\nidentical topology but different learning rates converge to distinct clusters\nwith diverse representations. We also investigate the representational dynamics\nof RNNs, across both training and sequential timesteps, finding that RNNs\nconverge in a bottom-up pattern over the course of training and that the hidden\nstate is highly variable over the course of a sequence, even when accounting\nfor linear transforms. Together, these results provide new insights into the\nfunction of CNNs and RNNs, and demonstrate the utility of using CCA to\nunderstand representations.", "published": "2018-06-14T22:34:11Z", "version": 3}, {"aid": "1806.05978", "authors": ["Kumar Shridhar", "Felix Laumann", "Marcus Liwicki"], "title": "Uncertainty Estimations by Softplus normalization in Bayesian Convolutional Neural Networks with Variational Inference", "url": "http://arxiv.org/pdf/1806.05978v6", "summary": "We introduce a novel uncertainty estimation for classification tasks for\nBayesian convolutional neural networks with variational inference. By\nnormalizing the output of a Softplus function in the final layer, we estimate\naleatoric and epistemic uncertainty in a coherent manner. The intractable\nposterior probability distributions over weights are inferred by Bayes by\nBackprop. Firstly, we demonstrate how this reliable variational inference\nmethod can serve as a fundamental construct for various network architectures.\nOn multiple datasets in supervised learning settings (MNIST, CIFAR-10,\nCIFAR-100), this variational inference method achieves performances equivalent\nto frequentist inference in identical architectures, while the two desiderata,\na measure for uncertainty and regularization are incorporated naturally.\nSecondly, we examine how our proposed measure for aleatoric and epistemic\nuncertainties is derived and validate it on the aforementioned datasets.", "published": "2018-06-15T13:55:18Z", "version": 6}, {"aid": "1806.06575", "authors": ["Thu Nguyen-Phuoc", "Chuan Li", "Stephen Balaban", "Yong-Liang Yang"], "title": "RenderNet: A deep convolutional network for differentiable rendering from 3D shapes", "url": "http://arxiv.org/pdf/1806.06575v3", "summary": "Traditional computer graphics rendering pipeline is designed for procedurally\ngenerating 2D quality images from 3D shapes with high performance. The\nnon-differentiability due to discrete operations such as visibility computation\nmakes it hard to explicitly correlate rendering parameters and the resulting\nimage, posing a significant challenge for inverse rendering tasks. Recent work\non differentiable rendering achieves differentiability either by designing\nsurrogate gradients for non-differentiable operations or via an approximate but\ndifferentiable renderer. These methods, however, are still limited when it\ncomes to handling occlusion, and restricted to particular rendering effects. We\npresent RenderNet, a differentiable rendering convolutional network with a\nnovel projection unit that can render 2D images from 3D shapes. Spatial\nocclusion and shading calculation are automatically encoded in the network. Our\nexperiments show that RenderNet can successfully learn to implement different\nshaders, and can be used in inverse rendering tasks to estimate shape, pose,\nlighting and texture from a single image.", "published": "2018-06-18T09:45:33Z", "version": 3}, {"aid": "1806.06986", "authors": ["Zhe Wu", "Navaneeth Bodla", "Bharat Singh", "Mahyar Najibi", "Rama Chellappa", "Larry S. Davis"], "title": "Soft Sampling for Robust Object Detection", "url": "http://arxiv.org/pdf/1806.06986v2", "summary": "We study the robustness of object detection under the presence of missing\nannotations. In this setting, the unlabeled object instances will be treated as\nbackground, which will generate an incorrect training signal for the detector.\nInterestingly, we observe that after dropping 30% of the annotations (and\nlabeling them as background), the performance of CNN-based object detectors\nlike Faster-RCNN only drops by 5% on the PASCAL VOC dataset. We provide a\ndetailed explanation for this result. To further bridge the performance gap, we\npropose a simple yet effective solution, called Soft Sampling. Soft Sampling\nre-weights the gradients of RoIs as a function of overlap with positive\ninstances. This ensures that the uncertain background regions are given a\nsmaller weight compared to the hardnegatives. Extensive experiments on curated\nPASCAL VOC datasets demonstrate the effectiveness of the proposed Soft Sampling\nmethod at different annotation drop rates. Finally, we show that on\nOpenImagesV3, which is a real-world dataset with missing annotations, Soft\nSampling outperforms standard detection baselines by over 3%.", "published": "2018-06-18T23:40:14Z", "version": 2}, {"aid": "1806.07108", "authors": ["Qiqi Zhang", "Ying Liu"], "title": "Improving brain computer interface performance by data augmentation with conditional Deep Convolutional Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1806.07108v2", "summary": "One of the big restrictions in brain computer interface field is the very\nlimited training samples, it is difficult to build a reliable and usable system\nwith such limited data. Inspired by generative adversarial networks, we propose\na conditional Deep Convolutional Generative Adversarial (cDCGAN) Networks\nmethod to generate more artificial EEG signal automatically for data\naugmentation to improve the performance of convolutional neural networks in\nbrain computer interface field and overcome the small training dataset\nproblems. We evaluate the proposed cDCGAN method on BCI competition dataset of\nmotor imagery. The results show that the generated artificial EEG data from\nGaussian noise can learn the features from raw EEG data and has no less than\nthe classification accuracy of raw EEG data in the testing dataset. Also by\nusing generated artificial data can effectively improve classification accuracy\nat the same model with limited training data.", "published": "2018-06-19T08:49:50Z", "version": 2}, {"aid": "1806.07366", "authors": ["Ricky T. Q. Chen", "Yulia Rubanova", "Jesse Bettencourt", "David Duvenaud"], "title": "Neural Ordinary Differential Equations", "url": "http://arxiv.org/pdf/1806.07366v5", "summary": "We introduce a new family of deep neural network models. Instead of\nspecifying a discrete sequence of hidden layers, we parameterize the derivative\nof the hidden state using a neural network. The output of the network is\ncomputed using a black-box differential equation solver. These continuous-depth\nmodels have constant memory cost, adapt their evaluation strategy to each\ninput, and can explicitly trade numerical precision for speed. We demonstrate\nthese properties in continuous-depth residual networks and continuous-time\nlatent variable models. We also construct continuous normalizing flows, a\ngenerative model that can train by maximum likelihood, without partitioning or\nordering the data dimensions. For training, we show how to scalably\nbackpropagate through any ODE solver, without access to its internal\noperations. This allows end-to-end training of ODEs within larger models.", "published": "2018-06-19T17:50:12Z", "version": 5}, {"aid": "1806.07685", "authors": ["Ivo D\u00fcntsch", "G\u00fcnther Gediga", "Hui Wang"], "title": "Approximation by filter functions", "url": "http://arxiv.org/pdf/1806.07685v1", "summary": "In this exploratory article, we draw attention to the common formal ground\namong various estimators such as the belief functions of evidence theory and\ntheir relatives, approximation quality of rough set theory, and contextual\nprobability. The unifying concept will be a general filter function composed of\na basic probability and a weighting which varies according to the problem at\nhand. To compare the various filter functions we conclude with a simulation\nstudy with an example from the area of item response theory.", "published": "2018-06-20T12:09:52Z", "version": 1}, {"aid": "1806.07908", "authors": ["Moacir Antonelli Ponti", "Gabriel B. Paranhos da Costa"], "title": "Como funciona o Deep Learning", "url": "http://arxiv.org/pdf/1806.07908v1", "summary": "Deep Learning methods are currently the state-of-the-art in many problems\nwhich can be tackled via machine learning, in particular classification\nproblems. However there is still lack of understanding on how those methods\nwork, why they work and what are the limitations involved in using them. In\nthis chapter we will describe in detail the transition from shallow to deep\nnetworks, include examples of code on how to implement them, as well as the\nmain issues one faces when training a deep network. Afterwards, we introduce\nsome theoretical background behind the use of deep models, and discuss their\nlimitations.", "published": "2018-06-20T18:04:09Z", "version": 1}, {"aid": "1806.07996", "authors": ["Dominique Beaini", "Sofiane Achiche", "Yann-Seing Law-Kam Cio", "Maxime Raison"], "title": "Novel Convolution Kernels for Computer Vision and Shape Analysis based on Electromagnetism", "url": "http://arxiv.org/pdf/1806.07996v1", "summary": "Computer vision is a growing field with a lot of new applications in\nautomation and robotics, since it allows the analysis of images and shapes for\nthe generation of numerical or analytical information. One of the most used\nmethod of information extraction is image filtering through convolution\nkernels, with each kernel specialized for specific applications. The objective\nof this paper is to present a novel convolution kernels, based on principles of\nelectromagnetic potentials and fields, for a general use in computer vision and\nto demonstrate its usage for shape and stroke analysis. Such filtering\npossesses unique geometrical properties that can be interpreted using well\nunderstood physics theorems. Therefore, this paper focuses on the development\nof the electromagnetic kernels and on their application on images for shape and\nstroke analysis. It also presents several interesting features of\nelectromagnetic kernels, such as resolution, size and orientation independence,\nrobustness to noise and deformation, long distance stroke interaction and\nability to work with 3D images", "published": "2018-06-20T21:31:00Z", "version": 1}, {"aid": "1806.07998", "authors": ["Christian Kerskens", "David Lopez Perez"], "title": "Experimental evidence of non-classical brain functions", "url": "http://arxiv.org/pdf/1806.07998v6", "summary": "Recent proposals in quantum gravity have suggested that unknown systems can\nmediate entanglement between two known quantum systems, if and only if the\nmediator itself is non-classical. This approach may be applicable to the brain,\nwhere speculations about quantum operations in consciousness and cognition have\na long history. Proton spins of bulk water, which most likely interfere with\nany brain function, can act as the known quantum systems. If an unknown\nmediator exists, then NMR methods based on multiple quantum coherence (MQC) can\nact as entanglement witness. However, there are doubts that today's NMR signals\ncan contain quantum correlations in general, and specifically in the brain\nenvironment. Here, we used a witness protocol based on zero quantum coherence\n(ZQC) whereby we minimised the classical signals to circumvent the NMR\ndetection limits for quantum correlation. For short repetitive periods, we\nfound evoked signals in most parts of the brain, whereby the temporal\nappearance resembled heartbeat-evoked potentials (HEPs). We found that those\nsignals had no correlates with any classical NMR contrast. Similar to HEPs, the\nevoked signal depended on conscious awareness. Consciousness-related or\nelectrophysiological signals are unknown in NMR. Remarkably, these signals only\nappeared if the local properties of the magnetisation were reduced. Our\nfindings suggest that we may have witnessed entanglement mediated by\nconsciousness-related brain functions. Those brain functions must then operate\nnon-classically, which would mean that consciousness is non-classical.", "published": "2018-06-20T21:43:44Z", "version": 6}, {"aid": "1806.08065", "authors": ["Devendra Singh Chaplot", "Christopher MacLellan", "Ruslan Salakhutdinov", "Kenneth Koedinger"], "title": "Learning Cognitive Models using Neural Networks", "url": "http://arxiv.org/pdf/1806.08065v1", "summary": "A cognitive model of human learning provides information about skills a\nlearner must acquire to perform accurately in a task domain. Cognitive models\nof learning are not only of scientific interest, but are also valuable in\nadaptive online tutoring systems. A more accurate model yields more effective\ntutoring through better instructional decisions. Prior methods of automated\ncognitive model discovery have typically focused on well-structured domains,\nrelied on student performance data or involved substantial human knowledge\nengineering. In this paper, we propose Cognitive Representation Learner\n(CogRL), a novel framework to learn accurate cognitive models in ill-structured\ndomains with no data and little to no human knowledge engineering. Our\ncontribution is two-fold: firstly, we show that representations learnt using\nCogRL can be used for accurate automatic cognitive model discovery without\nusing any student performance data in several ill-structured domains: Rumble\nBlocks, Chinese Character, and Article Selection. This is especially effective\nand useful in domains where an accurate human-authored cognitive model is\nunavailable or authoring a cognitive model is difficult. Secondly, for domains\nwhere a cognitive model is available, we show that representations learned\nthrough CogRL can be used to get accurate estimates of skill difficulty and\nlearning rate parameters without using any student performance data. These\nestimates are shown to highly correlate with estimates using student\nperformance data on an Article Selection dataset.", "published": "2018-06-21T04:43:35Z", "version": 1}, {"aid": "1806.08523", "authors": ["Phongtharin Vinayavekhin", "Subhajit Chaudhury", "Asim Munawar", "Don Joven Agravante", "Giovanni De Magistris", "Daiki Kimura", "Ryuki Tachibana"], "title": "Focusing on What is Relevant: Time-Series Learning and Understanding using Attention", "url": "http://arxiv.org/pdf/1806.08523v1", "summary": "This paper is a contribution towards interpretability of the deep learning\nmodels in different applications of time-series. We propose a temporal\nattention layer that is capable of selecting the relevant information to\nperform various tasks, including data completion, key-frame detection and\nclassification. The method uses the whole input sequence to calculate an\nattention value for each time step. This results in more focused attention\nvalues and more plausible visualisation than previous methods. We apply the\nproposed method to three different tasks. Experimental results show that the\nproposed network produces comparable results to a state of the art. In\naddition, the network provides better interpretability of the decision, that\nis, it generates more significant attention weight to related frames compared\nto similar techniques attempted in the past.", "published": "2018-06-22T07:16:08Z", "version": 1}, {"aid": "1806.08672", "authors": ["Rita Kuznetsova", "Oleg Bakhteev", "Alexandr Ogaltsov"], "title": "Variational learning across domains with triplet information", "url": "http://arxiv.org/pdf/1806.08672v2", "summary": "The work investigates deep generative models, which allow us to use training\ndata from one domain to build a model for another domain. We propose the\nVariational Bi-domain Triplet Autoencoder (VBTA) that learns a joint\ndistribution of objects from different domains. We extend the VBTAs objective\nfunction by the relative constraints or triplets that sampled from the shared\nlatent space across domains. In other words, we combine the deep generative\nmodels with a metric learning ideas in order to improve the final objective\nwith the triplets information. The performance of the VBTA model is\ndemonstrated on different tasks: image-to-image translation, bi-directional\nimage generation and cross-lingual document classification.", "published": "2018-06-22T13:58:42Z", "version": 2}, {"aid": "1806.08894", "authors": ["Seyed Sajad Mousavi", "Michael Schukat", "Enda Howley"], "title": "Deep Reinforcement Learning: An Overview", "url": "http://arxiv.org/pdf/1806.08894v1", "summary": "In recent years, a specific machine learning method called deep learning has\ngained huge attraction, as it has obtained astonishing results in broad\napplications such as pattern recognition, speech recognition, computer vision,\nand natural language processing. Recent research has also been shown that deep\nlearning techniques can be combined with reinforcement learning methods to\nlearn useful representations for the problems with high dimensional raw data\ninput. This chapter reviews the recent advances in deep reinforcement learning\nwith a focus on the most used deep architectures such as autoencoders,\nconvolutional neural networks and recurrent neural networks which have\nsuccessfully been come together with the reinforcement learning framework.", "published": "2018-06-23T02:18:26Z", "version": 1}, {"aid": "1806.09055", "authors": ["Hanxiao Liu", "Karen Simonyan", "Yiming Yang"], "title": "DARTS: Differentiable Architecture Search", "url": "http://arxiv.org/pdf/1806.09055v2", "summary": "This paper addresses the scalability challenge of architecture search by\nformulating the task in a differentiable manner. Unlike conventional approaches\nof applying evolution or reinforcement learning over a discrete and\nnon-differentiable search space, our method is based on the continuous\nrelaxation of the architecture representation, allowing efficient search of the\narchitecture using gradient descent. Extensive experiments on CIFAR-10,\nImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in\ndiscovering high-performance convolutional architectures for image\nclassification and recurrent architectures for language modeling, while being\norders of magnitude faster than state-of-the-art non-differentiable techniques.\nOur implementation has been made publicly available to facilitate further\nresearch on efficient architecture search algorithms.", "published": "2018-06-24T00:06:13Z", "version": 2}, {"aid": "1806.09141", "authors": ["Raanan Y. Rohekar", "Shami Nisimov", "Yaniv Gurwicz", "Guy Koren", "Gal Novik"], "title": "Constructing Deep Neural Networks by Bayesian Network Structure Learning", "url": "http://arxiv.org/pdf/1806.09141v3", "summary": "We introduce a principled approach for unsupervised structure learning of\ndeep neural networks. We propose a new interpretation for depth and inter-layer\nconnectivity where conditional independencies in the input distribution are\nencoded hierarchically in the network structure. Thus, the depth of the network\nis determined inherently. The proposed method casts the problem of neural\nnetwork structure learning as a problem of Bayesian network structure learning.\nThen, instead of directly learning the discriminative structure, it learns a\ngenerative graph, constructs its stochastic inverse, and then constructs a\ndiscriminative graph. We prove that conditional-dependency relations among the\nlatent variables in the generative graph are preserved in the class-conditional\ndiscriminative graph. We demonstrate on image classification benchmarks that\nthe deepest layers (convolutional and dense) of common networks can be replaced\nby significantly smaller learned structures, while maintaining classification\naccuracy---state-of-the-art on tested benchmarks. Our structure learning\nalgorithm requires a small computational cost and runs efficiently on a\nstandard desktop CPU.", "published": "2018-06-24T13:05:06Z", "version": 3}, {"aid": "1806.10282", "authors": ["Haifeng Jin", "Qingquan Song", "Xia Hu"], "title": "Auto-Keras: An Efficient Neural Architecture Search System", "url": "http://arxiv.org/pdf/1806.10282v3", "summary": "Neural architecture search (NAS) has been proposed to automatically tune deep\nneural networks, but existing search algorithms, e.g., NASNet, PNAS, usually\nsuffer from expensive computational cost. Network morphism, which keeps the\nfunctionality of a neural network while changing its neural architecture, could\nbe helpful for NAS by enabling more efficient training during the search. In\nthis paper, we propose a novel framework enabling Bayesian optimization to\nguide the network morphism for efficient neural architecture search. The\nframework develops a neural network kernel and a tree-structured acquisition\nfunction optimization algorithm to efficiently explores the search space.\nIntensive experiments on real-world benchmark datasets have been done to\ndemonstrate the superior performance of the developed framework over the\nstate-of-the-art methods. Moreover, we build an open-source AutoML system based\non our method, namely Auto-Keras. The system runs in parallel on CPU and GPU,\nwith an adaptive search strategy for different GPU memory limits.", "published": "2018-06-27T03:18:35Z", "version": 3}, {"aid": "1806.10342", "authors": ["Yi-Jie Huang", "Qi Dou", "Zi-Xian Wang", "Li-Zhi Liu", "Ying Jin", "Chao-Feng Li", "Lisheng Wang", "Hao Chen", "Rui-Hua Xu"], "title": "3D RoI-aware U-Net for Accurate and Efficient Colorectal Tumor Segmentation", "url": "http://arxiv.org/pdf/1806.10342v5", "summary": "Segmentation of colorectal cancerous regions from 3D Magnetic Resonance (MR)\nimages is a crucial procedure for radiotherapy which conventionally requires\naccurate delineation of tumour boundaries at an expense of labor, time and\nreproducibility. While deep learning based methods serve good baselines in 3D\nimage segmentation tasks, small applicable patch size limits effective\nreceptive field and degrades segmentation performance. In addition, Regions of\ninterest (RoIs) localization from large whole volume 3D images serves as a\npreceding operation that brings about multiple benefits in terms of speed,\ntarget completeness, reduction of false positives. Distinct from sliding window\nor non-joint localization-segmentation based models, we propose a novel\nmultitask framework referred to as 3D RoI-aware U-Net (3D RU-Net), for RoI\nlocalization and in-region segmentation where the two tasks share one backbone\nencoder network. With the region proposals from the encoder, we crop\nmulti-level RoI in-region features from the encoder to form a GPU\nmemory-efficient decoder for detailpreserving segmentation and therefore\nenlarged applicable volume size and effective receptive field. To effectively\ntrain the model, we designed a Dice formulated loss function for the\nglobal-to-local multi-task learning procedure. Based on the efficiency gains,\nwe went on to ensemble models with different receptive fields to achieve even\nhigher performance costing minor extra computational expensiveness. Extensive\nexperiments were conducted on 64 cancerous cases with a four-fold\ncross-validation, and the results showed significant superiority in terms of\naccuracy and efficiency over conventional frameworks. In conclusion, the\nproposed method has a huge potential for extension to other 3D object\nsegmentation tasks from medical images due to its inherent generalizability.\nThe code for the proposed method is publicly available.", "published": "2018-06-27T08:42:58Z", "version": 5}, {"aid": "1806.10779", "authors": ["Ping Luo", "Jiamin Ren", "Zhanglin Peng", "Ruimao Zhang", "Jingyu Li"], "title": "Differentiable Learning-to-Normalize via Switchable Normalization", "url": "http://arxiv.org/pdf/1806.10779v5", "summary": "We address a learning-to-normalize problem by proposing Switchable\nNormalization (SN), which learns to select different normalizers for different\nnormalization layers of a deep neural network. SN employs three distinct scopes\nto compute statistics (means and variances) including a channel, a layer, and a\nminibatch. SN switches between them by learning their importance weights in an\nend-to-end manner. It has several good properties. First, it adapts to various\nnetwork architectures and tasks (see Fig.1). Second, it is robust to a wide\nrange of batch sizes, maintaining high performance even when small minibatch is\npresented (e.g. 2 images/GPU). Third, SN does not have sensitive\nhyper-parameter, unlike group normalization that searches the number of groups\nas a hyper-parameter. Without bells and whistles, SN outperforms its\ncounterparts on various challenging benchmarks, such as ImageNet, COCO,\nCityScapes, ADE20K, and Kinetics. Analyses of SN are also presented. We hope SN\nwill help ease the usage and understand the normalization techniques in deep\nlearning. The code of SN has been made available in\nhttps://github.com/switchablenorms/.", "published": "2018-06-28T05:55:57Z", "version": 5}, {"aid": "1806.11169", "authors": ["J. Tilak Ratnanather", "Sylvain Arguill\u00e8re", "Kwame S. Kutten", "Peter Hubka", "Andrej Kral", "Laurent Younes"], "title": "3D Normal Coordinate Systems for Cortical Areas", "url": "http://arxiv.org/pdf/1806.11169v3", "summary": "A surface-based diffeomorphic algorithm to generate 3D coordinate grids in\nthe cortical ribbon is described. In the grid, normal coordinate lines are\ngenerated by the diffeomorphic evolution from the grey/white (inner) surface to\nthe grey/csf (outer) surface. Specifically, the cortical ribbon is described by\ntwo triangulated surfaces with open boundaries. Conceptually, the inner surface\nsits on top of the white matter structure and the outer on top of the gray\nmatter. It is assumed that the cortical ribbon consists of cortical columns\nwhich are orthogonal to the white matter surface. This might be viewed as a\nconsequence of the development of the columns in the embryo. It is also assumed\nthat the columns are orthogonal to the outer surface so that the resultant\nvector field is orthogonal to the evolving surface. Then the distance of the\nnormal lines from the vector field such that the inner surface evolves\ndiffeomorphically towards the outer one can be construed as a measure of\nthickness. Applications are described for the auditory cortices in human adults\nand cats with normal hearing or hearing loss. The approach offers great\npotential for cortical morphometry.", "published": "2018-06-28T20:16:57Z", "version": 3}, {"aid": "1806.11379", "authors": ["Tomaso Poggio", "Qianli Liao", "Brando Miranda", "Andrzej Banburski", "Xavier Boix", "Jack Hidary"], "title": "Theory IIIb: Generalization in Deep Networks", "url": "http://arxiv.org/pdf/1806.11379v1", "summary": "A main puzzle of deep neural networks (DNNs) revolves around the apparent\nabsence of \"overfitting\", defined in this paper as follows: the expected error\ndoes not get worse when increasing the number of neurons or of iterations of\ngradient descent. This is surprising because of the large capacity demonstrated\nby DNNs to fit randomly labeled data and the absence of explicit\nregularization. Recent results by Srebro et al. provide a satisfying solution\nof the puzzle for linear networks used in binary classification. They prove\nthat minimization of loss functions such as the logistic, the cross-entropy and\nthe exp-loss yields asymptotic, \"slow\" convergence to the maximum margin\nsolution for linearly separable datasets, independently of the initial\nconditions. Here we prove a similar result for nonlinear multilayer DNNs near\nzero minima of the empirical loss. The result holds for exponential-type losses\nbut not for the square loss. In particular, we prove that the weight matrix at\neach layer of a deep network converges to a minimum norm solution up to a scale\nfactor (in the separable case). Our analysis of the dynamical system\ncorresponding to gradient descent of a multilayer network suggests a simple\ncriterion for ranking the generalization performance of different zero\nminimizers of the empirical loss.", "published": "2018-06-29T12:39:08Z", "version": 1}, {"aid": "1807.00082", "authors": ["Thomas Dean", "Maurice Chiang", "Marcus Gomez", "Nate Gruver", "Yousef Hindy", "Michelle Lam", "Peter Lu", "Sophia Sanchez", "Rohun Saxena", "Michael Smith", "Lucy Wang", "Catherine Wong"], "title": "Amanuensis: The Programmer's Apprentice", "url": "http://arxiv.org/pdf/1807.00082v2", "summary": "This document provides an overview of the material covered in a course taught\nat Stanford in the spring quarter of 2018. The course draws upon insight from\ncognitive and systems neuroscience to implement hybrid connectionist and\nsymbolic reasoning systems that leverage and extend the state of the art in\nmachine learning by integrating human and machine intelligence. As a concrete\nexample we focus on digital assistants that learn from continuous dialog with\nan expert software engineer while providing initial value as powerful\nanalytical, computational and mathematical savants. Over time these savants\nlearn cognitive strategies (domain-relevant problem solving skills) and develop\nintuitions (heuristics and the experience necessary for applying them) by\nlearning from their expert associates. By doing so these savants elevate their\ninnate analytical skills allowing them to partner on an equal footing as\nversatile collaborators - effectively serving as cognitive extensions and\ndigital prostheses, thereby amplifying and emulating their human partner's\nconceptually-flexible thinking patterns and enabling improved access to and\ncontrol over powerful computing resources.", "published": "2018-06-29T22:59:08Z", "version": 2}, {"aid": "1807.00196", "authors": ["Pedro A. Ortega", "Shane Legg"], "title": "Modeling Friends and Foes", "url": "http://arxiv.org/pdf/1807.00196v1", "summary": "How can one detect friendly and adversarial behavior from raw data? Detecting\nwhether an environment is a friend, a foe, or anything in between, remains a\npoorly understood yet desirable ability for safe and robust agents. This paper\nproposes a definition of these environmental \"attitudes\" based on an\ncharacterization of the environment's ability to react to the agent's private\nstrategy. We define an objective function for a one-shot game that allows\nderiving the environment's probability distribution under friendly and\nadversarial assumptions alongside the agent's optimal strategy. Furthermore, we\npresent an algorithm to compute these equilibrium strategies, and show\nexperimentally that both friendly and adversarial environments possess\nnon-trivial optimal strategies.", "published": "2018-06-30T16:07:43Z", "version": 1}, {"aid": "1807.00962", "authors": ["Olga Krestinskaya", "Alex Pappachen James", "Leon O. Chua"], "title": "Neuro-memristive Circuits for Edge Computing: A review", "url": "http://arxiv.org/pdf/1807.00962v2", "summary": "The volume, veracity, variability, and velocity of data produced from the\never-increasing network of sensors connected to Internet pose challenges for\npower management, scalability, and sustainability of cloud computing\ninfrastructure. Increasing the data processing capability of edge computing\ndevices at lower power requirements can reduce several overheads for cloud\ncomputing solutions. This paper provides the review of neuromorphic\nCMOS-memristive architectures that can be integrated into edge computing\ndevices. We discuss why the neuromorphic architectures are useful for edge\ndevices and show the advantages, drawbacks and open problems in the field of\nneuro-memristive circuits for edge computing.", "published": "2018-07-01T04:07:23Z", "version": 2}, {"aid": "1807.00284", "authors": ["Benteng Ma", "Yong Xia"], "title": "Autonomous Deep Learning: A Genetic DCNN Designer for Image Classification", "url": "http://arxiv.org/pdf/1807.00284v1", "summary": "Recent years have witnessed the breakthrough success of deep convolutional\nneural networks (DCNNs) in image classification and other vision applications.\nAlthough freeing users from the troublesome handcrafted feature extraction by\nproviding a uniform feature extraction-classification framework, DCNNs still\nrequire a handcrafted design of their architectures. In this paper, we propose\nthe genetic DCNN designer, an autonomous learning algorithm can generate a DCNN\narchitecture automatically based on the data available for a specific image\nclassification problem. We first partition a DCNN into multiple stacked meta\nconvolutional blocks and fully connected blocks, each containing the operations\nof convolution, pooling, fully connection, batch normalization, activation and\ndrop out, and thus convert the architecture into an integer vector. Then, we\nuse refined evolutionary operations, including selection, mutation and\ncrossover to evolve a population of DCNN architectures. Our results on the\nMNIST, Fashion-MNIST, EMNISTDigit, EMNIST-Letter, CIFAR10 and CIFAR100 datasets\nsuggest that the proposed genetic DCNN designer is able to produce\nautomatically DCNN architectures, whose performance is comparable to, if not\nbetter than, that of stateof- the-art DCNN models", "published": "2018-07-01T07:11:54Z", "version": 1}, {"aid": "1807.00401", "authors": ["James Max Kanter", "Benjamin Schreck", "Kalyan Veeramachaneni"], "title": "Machine learning 2.0 : Engineering Data Driven AI Products", "url": "http://arxiv.org/pdf/1807.00401v1", "summary": "ML 2.0: In this paper, we propose a paradigm shift from the current practice\nof creating machine learning models - which requires months-long discovery,\nexploration and \"feasibility report\" generation, followed by re-engineering for\ndeployment - in favor of a rapid, 8-week process of development, understanding,\nvalidation and deployment that can executed by developers or subject matter\nexperts (non-ML experts) using reusable APIs. This accomplishes what we call a\n\"minimum viable data-driven model,\" delivering a ready-to-use machine learning\nmodel for problems that haven't been solved before using machine learning. We\nprovide provisions for the refinement and adaptation of the \"model,\" with\nstrict enforcement and adherence to both the scaffolding/abstractions and the\nprocess. We imagine that this will bring forth the second phase in machine\nlearning, in which discovery is subsumed by more targeted goals of delivery and\nimpact.", "published": "2018-07-01T21:50:58Z", "version": 1}, {"aid": "1807.00412", "authors": ["Alex Kendall", "Jeffrey Hawke", "David Janz", "Przemyslaw Mazur", "Daniele Reda", "John-Mark Allen", "Vinh-Dieu Lam", "Alex Bewley", "Amar Shah"], "title": "Learning to Drive in a Day", "url": "http://arxiv.org/pdf/1807.00412v2", "summary": "We demonstrate the first application of deep reinforcement learning to\nautonomous driving. From randomly initialised parameters, our model is able to\nlearn a policy for lane following in a handful of training episodes using a\nsingle monocular image as input. We provide a general and easy to obtain\nreward: the distance travelled by the vehicle without the safety driver taking\ncontrol. We use a continuous, model-free deep reinforcement learning algorithm,\nwith all exploration and optimisation performed on-vehicle. This demonstrates a\nnew framework for autonomous driving which moves away from reliance on defined\nlogical rules, mapping, and direct supervision. We discuss the challenges and\nopportunities to scale this approach to a broader range of autonomous driving\ntasks.", "published": "2018-07-01T22:47:08Z", "version": 2}, {"aid": "1807.00456", "authors": ["Chengxi Ye", "Chinmaya Devaraj", "Michael Maynord", "Cornelia Ferm\u00fcller", "Yiannis Aloimonos"], "title": "Evenly Cascaded Convolutional Networks", "url": "http://arxiv.org/pdf/1807.00456v2", "summary": "We introduce Evenly Cascaded convolutional Network (ECN), a neural network\ntaking inspiration from the cascade algorithm of wavelet analysis. ECN employs\ntwo feature streams - a low-level and high-level steam. At each layer these\nstreams interact, such that low-level features are modulated using advanced\nperspectives from the high-level stream. ECN is evenly structured through\nresizing feature map dimensions by a consistent ratio, which removes the burden\nof ad-hoc specification of feature map dimensions. ECN produces easily\ninterpretable features maps, a result whose intuition can be understood in the\ncontext of scale-space theory. We demonstrate that ECN's design facilitates the\ntraining process through providing easily trainable shortcuts. We report new\nstate-of-the-art results for small networks, without the need for additional\ntreatment such as pruning or compression - a consequence of ECN's simple\nstructure and direct training. A 6-layered ECN design with under 500k\nparameters achieves 95.24% and 78.99% accuracy on CIFAR-10 and CIFAR-100\ndatasets, respectively, outperforming the current state-of-the-art on small\nparameter networks, and a 3 million parameter ECN produces results competitive\nto the state-of-the-art.", "published": "2018-07-02T04:12:16Z", "version": 2}, {"aid": "1807.00737", "authors": ["Rui Zhao", "Volker Tresp"], "title": "Learning Goal-Oriented Visual Dialog via Tempered Policy Gradient", "url": "http://arxiv.org/pdf/1807.00737v5", "summary": "Learning goal-oriented dialogues by means of deep reinforcement learning has\nrecently become a popular research topic. However, commonly used policy-based\ndialogue agents often end up focusing on simple utterances and suboptimal\npolicies. To mitigate this problem, we propose a class of novel\ntemperature-based extensions for policy gradient methods, which are referred to\nas Tempered Policy Gradients (TPGs). On a recent AI-testbed, i.e., the\nGuessWhat?! game, we achieve significant improvements with two innovations. The\nfirst one is an extension of the state-of-the-art solutions with Seq2Seq and\nMemory Network structures that leads to an improvement of 7%. The second one is\nthe application of our newly developed TPG methods, which improves the\nperformance additionally by around 5% and, even more importantly, helps produce\nmore convincing utterances.", "published": "2018-07-02T15:14:43Z", "version": 5}, {"aid": "1807.03215", "authors": ["Fenglei Fan", "Ge Wang"], "title": "Fuzzy Logic Interpretation of Quadratic Networks", "url": "http://arxiv.org/pdf/1807.03215v3", "summary": "Over past several years, deep learning has achieved huge successes in various\napplications. However, such a data-driven approach is often criticized for lack\nof interpretability. Recently, we proposed artificial quadratic neural networks\nconsisting of second-order neurons in potentially many layers. In each\nsecond-order neuron, a quadratic function is used in the place of the inner\nproduct in a traditional neuron, and then undergoes a nonlinear activation.\nWith a single second-order neuron, any fuzzy logic operation, such as XOR, can\nbe implemented. In this sense, any deep network constructed with quadratic\nneurons can be interpreted as a deep fuzzy logic system. Since traditional\nneural networks and second-order counterparts can represent each other and\nfuzzy logic operations are naturally implemented in second-order neural\nnetworks, it is plausible to explain how a deep neural network works with a\nsecond-order network as the system model. In this paper, we generalize and\ncategorize fuzzy logic operations implementable with individual second-order\nneurons, and then perform statistical/information theoretic analyses of\nexemplary quadratic neural networks.", "published": "2018-07-04T12:45:25Z", "version": 3}, {"aid": "1807.01898", "authors": ["Jen-Yu Liu", "Yi-Hsuan Yang"], "title": "Denoising Auto-encoder with Recurrent Skip Connections and Residual Regression for Music Source Separation", "url": "http://arxiv.org/pdf/1807.01898v1", "summary": "Convolutional neural networks with skip connections have shown good\nperformance in music source separation. In this work, we propose a denoising\nAuto-encoder with Recurrent skip Connections (ARC). We use 1D convolution along\nthe temporal axis of the time-frequency feature map in all layers of the\nfully-convolutional network. The use of 1D convolution makes it possible to\napply recurrent layers to the intermediate outputs of the convolution layers.\nIn addition, we also propose an enhancement network and a residual regression\nmethod to further improve the separation result. The recurrent skip\nconnections, the enhancement module, and the residual regression all improve\nthe separation quality. The ARC model with residual regression achieves 5.74\nsiganl-to-distoration ratio (SDR) in vocals with MUSDB in SiSEC 2018. We also\nevaluate the ARC model alone on the older dataset DSD100 (used in SiSEC 2016)\nand it achieves 5.91 SDR in vocals.", "published": "2018-07-05T08:54:32Z", "version": 1}, {"aid": "1807.02155", "authors": ["Guangzhi Tang", "Konstantinos P. Michmizos"], "title": "Gridbot: An autonomous robot controlled by a Spiking Neural Network mimicking the brain's navigational system", "url": "http://arxiv.org/pdf/1807.02155v1", "summary": "It is true that the \"best\" neural network is not necessarily the one with the\nmost \"brain-like\" behavior. Understanding biological intelligence, however, is\na fundamental goal for several distinct disciplines. Translating our\nunderstanding of intelligence to machines is a fundamental problem in robotics.\nPropelled by new advancements in Neuroscience, we developed a spiking neural\nnetwork (SNN) that draws from mounting experimental evidence that a number of\nindividual neurons is associated with spatial navigation. By following the\nbrain's structure, our model assumes no initial all-to-all connectivity, which\ncould inhibit its translation to a neuromorphic hardware, and learns an\nuncharted territory by mapping its identified components into a limited number\nof neural representations, through spike-timing dependent plasticity (STDP). In\nour ongoing effort to employ a bioinspired SNN-controlled robot to real-world\nspatial mapping applications, we demonstrate here how an SNN may robustly\ncontrol an autonomous robot in mapping and exploring an unknown environment,\nwhile compensating for its own intrinsic hardware imperfections, such as\npartial or total loss of visual input.", "published": "2018-07-05T19:09:45Z", "version": 1}, {"aid": "1807.03858", "authors": ["Yuping Luo", "Huazhe Xu", "Yuanzhi Li", "Yuandong Tian", "Trevor Darrell", "Tengyu Ma"], "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees", "url": "http://arxiv.org/pdf/1807.03858v5", "summary": "Model-based reinforcement learning (RL) is considered to be a promising\napproach to reduce the sample complexity that hinders model-free RL. However,\nthe theoretical understanding of such methods has been rather limited. This\npaper introduces a novel algorithmic framework for designing and analyzing\nmodel-based RL algorithms with theoretical guarantees. We design a\nmeta-algorithm with a theoretical guarantee of monotone improvement to a local\nmaximum of the expected reward. The meta-algorithm iteratively builds a lower\nbound of the expected reward based on the estimated dynamical model and sample\ntrajectories, and then maximizes the lower bound jointly over the policy and\nthe model. The framework extends the optimism-in-face-of-uncertainty principle\nto non-linear dynamical models in a way that requires \\textit{no explicit}\nuncertainty quantification. Instantiating our framework with simplification\ngives a variant of model-based RL algorithms Stochastic Lower Bounds\nOptimization (SLBO). Experiments demonstrate that SLBO achieves\nstate-of-the-art performance when only one million or fewer samples are\npermitted on a range of continuous control benchmark tasks.", "published": "2018-07-10T20:53:04Z", "version": 5}, {"aid": "1807.04001", "authors": ["Benjamin Bruno Meier", "Ismail Elezi", "Mohammadreza Amirian", "Oliver Durr", "Thilo Stadelmann"], "title": "Learning Neural Models for End-to-End Clustering", "url": "http://arxiv.org/pdf/1807.04001v1", "summary": "We propose a novel end-to-end neural network architecture that, once trained,\ndirectly outputs a probabilistic clustering of a batch of input examples in one\npass. It estimates a distribution over the number of clusters $k$, and for each\n$1 \\leq k \\leq k_\\mathrm{max}$, a distribution over the individual cluster\nassignment for each data point. The network is trained in advance in a\nsupervised fashion on separate data to learn grouping by any perceptual\nsimilarity criterion based on pairwise labels (same/different group). It can\nthen be applied to different data containing different groups. We demonstrate\npromising performance on high-dimensional data like images (COIL-100) and\nspeech (TIMIT). We call this ``learning to cluster'' and show its conceptual\ndifference to deep metric learning, semi-supervise clustering and other related\napproaches while having the advantage of performing learnable clustering fully\nend-to-end.", "published": "2018-07-11T08:45:45Z", "version": 1}, {"aid": "1807.04050", "authors": ["Roberto Annunziata", "Christos Sagonas", "Jacques Cal\u00ec"], "title": "DeSTNet: Densely Fused Spatial Transformer Networks", "url": "http://arxiv.org/pdf/1807.04050v2", "summary": "Modern Convolutional Neural Networks (CNN) are extremely powerful on a range\nof computer vision tasks. However, their performance may degrade when the data\nis characterised by large intra-class variability caused by spatial\ntransformations. The Spatial Transformer Network (STN) is currently the method\nof choice for providing CNNs the ability to remove those transformations and\nimprove performance in an end-to-end learning framework. In this paper, we\npropose Densely Fused Spatial Transformer Network (DeSTNet), which, to our best\nknowledge, is the first dense fusion pattern for combining multiple STNs.\nSpecifically, we show how changing the connectivity pattern of multiple STNs\nfrom sequential to dense leads to more powerful alignment modules. Extensive\nexperiments on three benchmarks namely, MNIST, GTSRB, and IDocDB show that the\nproposed technique outperforms related state-of-the-art methods (i.e., STNs and\nCSTNs) both in terms of accuracy and robustness.", "published": "2018-07-11T10:06:32Z", "version": 2}, {"aid": "1807.04445", "authors": ["Pengfei Zhang", "Jianru Xue", "Cuiling Lan", "Wenjun Zeng", "Zhanning Gao", "Nanning Zheng"], "title": "Adding Attentiveness to the Neurons in Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1807.04445v1", "summary": "Recurrent neural networks (RNNs) are capable of modeling the temporal\ndynamics of complex sequential information. However, the structures of existing\nRNN neurons mainly focus on controlling the contributions of current and\nhistorical information but do not explore the different importance levels of\ndifferent elements in an input vector of a time slot. We propose adding a\nsimple yet effective Element-wiseAttention Gate (EleAttG) to an RNN block\n(e.g., all RNN neurons in a network layer) that empowers the RNN neurons to\nhave the attentiveness capability. For an RNN block, an EleAttG is added to\nadaptively modulate the input by assigning different levels of importance,\ni.e., attention, to each element/dimension of the input. We refer to an RNN\nblock equipped with an EleAttG as an EleAtt-RNN block. Specifically, the\nmodulation of the input is content adaptive and is performed at fine\ngranularity, being element-wise rather than input-wise. The proposed EleAttG,\nas an additional fundamental unit, is general and can be applied to any RNN\nstructures, e.g., standard RNN, Long Short-Term Memory (LSTM), or Gated\nRecurrent Unit (GRU). We demonstrate the effectiveness of the proposed\nEleAtt-RNN by applying it to the action recognition tasks on both 3D human\nskeleton data and RGB videos. Experiments show that adding attentiveness\nthrough EleAttGs to RNN blocks significantly boosts the power of RNNs.", "published": "2018-07-12T06:59:36Z", "version": 1}, {"aid": "1807.05076", "authors": ["Tsendsuren Munkhdalai", "Adam Trischler"], "title": "Metalearning with Hebbian Fast Weights", "url": "http://arxiv.org/pdf/1807.05076v1", "summary": "We unify recent neural approaches to one-shot learning with older ideas of\nassociative memory in a model for metalearning. Our model learns jointly to\nrepresent data and to bind class labels to representations in a single shot. It\nbuilds representations via slow weights, learned across tasks through SGD,\nwhile fast weights constructed by a Hebbian learning rule implement one-shot\nbinding for each new task. On the Omniglot, Mini-ImageNet, and Penn Treebank\none-shot learning benchmarks, our model achieves state-of-the-art results.", "published": "2018-07-12T14:40:06Z", "version": 1}, {"aid": "1807.04798", "authors": ["Florian Dubost", "Gerda Bortsova", "Hieab Adams", "M. Arfan Ikram", "Wiro Niessen", "Meike Vernooij", "Marleen de Bruijne"], "title": "Hydranet: Data Augmentation for Regression Neural Networks", "url": "http://arxiv.org/pdf/1807.04798v3", "summary": "Deep learning techniques are often criticized to heavily depend on a large\nquantity of labeled data. This problem is even more challenging in medical\nimage analysis where the annotator expertise is often scarce. We propose a\nnovel data-augmentation method to regularize neural network regressors that\nlearn from a single global label per image. The principle of the method is to\ncreate new samples by recombining existing ones. We demonstrate the performance\nof our algorithm on two tasks: estimation of the number of enlarged\nperivascular spaces in the basal ganglia, and estimation of white matter\nhyperintensities volume. We show that the proposed method improves the\nperformance over more basic data augmentation. The proposed method reached an\nintraclass correlation coefficient between ground truth and network predictions\nof 0.73 on the first task and 0.84 on the second task, only using between 25\nand 30 scans with a single global label per scan for training. With the same\nnumber of training scans, more conventional data augmentation methods could\nonly reach intraclass correlation coefficients of 0.68 on the first task, and\n0.79 on the second task.", "published": "2018-07-12T19:30:21Z", "version": 3}, {"aid": "1807.05214", "authors": ["Zhixin Lu", "Danielle S. Bassett"], "title": "Invertible generalized synchronization: A putative mechanism for implicit learning in biological and artificial neural systems", "url": "http://arxiv.org/pdf/1807.05214v2", "summary": "Regardless of the marked differences between biological and artificial neural\nsystems, one fundamental similarity is that they are essentially dynamical\nsystems that can learn to imitate other dynamical systems, without knowing\ntheir governing equations. The brain is able to learn the dynamic nature of the\nphysical world via experience; analogously, artificial neural systems can learn\nthe long-term behavior of complex dynamical systems from data. Yet, precisely\nhow this implicit learning occurs remains unknown. Here, we draw inspiration\nfrom human neuroscience and from reservoir computing to propose a\nfirst-principles framework explicating putative mechanisms of implicit\nlearning. Specifically, we show that an arbitrary dynamical system implicitly\nlearns other dynamical attractors by embedding them into its own phase space\nthrough invertible generalized synchronization. By sustaining the embedding\nthrough fine-tuned feedback loops, the arbitrary dynamical system can imitate\nthe attractor dynamics it has learned. To evaluate the mechanism's relevance,\nwe construct several distinct neural network models that adaptively learn and\nimitate multiple attractors. We observe and explain the emergence of 5 distinct\nphenomena reminiscent of cognitive functions: (i) imitating a dynamical system\npurely from learning the time series, (ii) learning multiple attractors by a\nsingle system, (iii) switching among the imitations of multiple attractors,\neither spontaneously or driven by external cues, (iv) filling-in missing\nvariables from incomplete observations of a learned dynamical system, and (v)\ndeciphering superimposed input from different dynamical systems. Collectively,\nour findings support the notion that artificial and biological neural networks\ncan learn the dynamic nature of their environment, and systems within their\nenvironment, through the mechanism of invertible generalized synchronization.", "published": "2018-07-13T00:50:52Z", "version": 2}, {"aid": "1807.05196", "authors": ["Lars Kunze", "Nick Hawes", "Tom Duckett", "Marc Hanheide", "Tom\u00e1\u0161 Krajn\u00edk"], "title": "Artificial Intelligence for Long-Term Robot Autonomy: A Survey", "url": "http://arxiv.org/pdf/1807.05196v1", "summary": "Autonomous systems will play an essential role in many applications across\ndiverse domains including space, marine, air, field, road, and service\nrobotics. They will assist us in our daily routines and perform dangerous,\ndirty and dull tasks. However, enabling robotic systems to perform autonomously\nin complex, real-world scenarios over extended time periods (i.e. weeks,\nmonths, or years) poses many challenges. Some of these have been investigated\nby sub-disciplines of Artificial Intelligence (AI) including navigation &\nmapping, perception, knowledge representation & reasoning, planning,\ninteraction, and learning. The different sub-disciplines have developed\ntechniques that, when re-integrated within an autonomous system, can enable\nrobots to operate effectively in complex, long-term scenarios. In this paper,\nwe survey and discuss AI techniques as 'enablers' for long-term robot autonomy,\ncurrent progress in integrating these techniques within long-running robotic\nsystems, and the future challenges and opportunities for AI in long-term\nautonomy.", "published": "2018-07-13T17:32:32Z", "version": 1}, {"aid": "1807.05511", "authors": ["Zhong-Qiu Zhao", "Peng Zheng", "Shou-tao Xu", "Xindong Wu"], "title": "Object Detection with Deep Learning: A Review", "url": "http://arxiv.org/pdf/1807.05511v2", "summary": "Due to object detection's close relationship with video analysis and image\nunderstanding, it has attracted much research attention in recent years.\nTraditional object detection methods are built on handcrafted features and\nshallow trainable architectures. Their performance easily stagnates by\nconstructing complex ensembles which combine multiple low-level image features\nwith high-level context from object detectors and scene classifiers. With the\nrapid development in deep learning, more powerful tools, which are able to\nlearn semantic, high-level, deeper features, are introduced to address the\nproblems existing in traditional architectures. These models behave differently\nin network architecture, training strategy and optimization function, etc. In\nthis paper, we provide a review on deep learning based object detection\nframeworks. Our review begins with a brief introduction on the history of deep\nlearning and its representative tool, namely Convolutional Neural Network\n(CNN). Then we focus on typical generic object detection architectures along\nwith some modifications and useful tricks to improve detection performance\nfurther. As distinct specific detection tasks exhibit different\ncharacteristics, we also briefly survey several specific tasks, including\nsalient object detection, face detection and pedestrian detection. Experimental\nanalyses are also provided to compare various methods and draw some meaningful\nconclusions. Finally, several promising directions and tasks are provided to\nserve as guidelines for future work in both object detection and relevant\nneural network based learning systems.", "published": "2018-07-15T08:16:03Z", "version": 2}, {"aid": "1807.05520", "authors": ["Mathilde Caron", "Piotr Bojanowski", "Armand Joulin", "Matthijs Douze"], "title": "Deep Clustering for Unsupervised Learning of Visual Features", "url": "http://arxiv.org/pdf/1807.05520v2", "summary": "Clustering is a class of unsupervised learning methods that has been\nextensively applied and studied in computer vision. Little work has been done\nto adapt it to the end-to-end training of visual features on large scale\ndatasets. In this work, we present DeepCluster, a clustering method that\njointly learns the parameters of a neural network and the cluster assignments\nof the resulting features. DeepCluster iteratively groups the features with a\nstandard clustering algorithm, k-means, and uses the subsequent assignments as\nsupervision to update the weights of the network. We apply DeepCluster to the\nunsupervised training of convolutional neural networks on large datasets like\nImageNet and YFCC100M. The resulting model outperforms the current state of the\nart by a significant margin on all the standard benchmarks.", "published": "2018-07-15T09:41:39Z", "version": 2}, {"aid": "1807.06521", "authors": ["Sanghyun Woo", "Jongchan Park", "Joon-Young Lee", "In So Kweon"], "title": "CBAM: Convolutional Block Attention Module", "url": "http://arxiv.org/pdf/1807.06521v2", "summary": "We propose Convolutional Block Attention Module (CBAM), a simple yet\neffective attention module for feed-forward convolutional neural networks.\nGiven an intermediate feature map, our module sequentially infers attention\nmaps along two separate dimensions, channel and spatial, then the attention\nmaps are multiplied to the input feature map for adaptive feature refinement.\nBecause CBAM is a lightweight and general module, it can be integrated into any\nCNN architectures seamlessly with negligible overheads and is end-to-end\ntrainable along with base CNNs. We validate our CBAM through extensive\nexperiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets.\nOur experiments show consistent improvements in classification and detection\nperformances with various models, demonstrating the wide applicability of CBAM.\nThe code and models will be publicly available.", "published": "2018-07-17T16:05:59Z", "version": 2}, {"aid": "1807.06613", "authors": ["Maximilian H\u00fcttenrauch", "Adrian \u0160o\u0161i\u0107", "Gerhard Neumann"], "title": "Deep Reinforcement Learning for Swarm Systems", "url": "http://arxiv.org/pdf/1807.06613v3", "summary": "Recently, deep reinforcement learning (RL) methods have been applied\nsuccessfully to multi-agent scenarios. Typically, these methods rely on a\nconcatenation of agent states to represent the information content required for\ndecentralized decision making. However, concatenation scales poorly to swarm\nsystems with a large number of homogeneous agents as it does not exploit the\nfundamental properties inherent to these systems: (i) the agents in the swarm\nare interchangeable and (ii) the exact number of agents in the swarm is\nirrelevant. Therefore, we propose a new state representation for deep\nmulti-agent RL based on mean embeddings of distributions. We treat the agents\nas samples of a distribution and use the empirical mean embedding as input for\na decentralized policy. We define different feature spaces of the mean\nembedding using histograms, radial basis functions and a neural network learned\nend-to-end. We evaluate the representation on two well known problems from the\nswarm literature (rendezvous and pursuit evasion), in a globally and locally\nobservable setup. For the local setup we furthermore introduce simple\ncommunication protocols. Of all approaches, the mean embedding representation\nusing neural network features enables the richest information exchange between\nneighboring agents facilitating the development of more complex collective\nstrategies.", "published": "2018-07-17T18:27:03Z", "version": 3}, {"aid": "1807.06699", "authors": ["Ryutaro Tanno", "Kai Arulkumaran", "Daniel C. Alexander", "Antonio Criminisi", "Aditya Nori"], "title": "Adaptive Neural Trees", "url": "http://arxiv.org/pdf/1807.06699v5", "summary": "Deep neural networks and decision trees operate on largely separate\nparadigms; typically, the former performs representation learning with\npre-specified architectures, while the latter is characterised by learning\nhierarchies over pre-specified features with data-driven architectures. We\nunite the two via adaptive neural trees (ANTs) that incorporates representation\nlearning into edges, routing functions and leaf nodes of a decision tree, along\nwith a backpropagation-based training algorithm that adaptively grows the\narchitecture from primitive modules (e.g., convolutional layers). We\ndemonstrate that, whilst achieving competitive performance on classification\nand regression datasets, ANTs benefit from (i) lightweight inference via\nconditional computation, (ii) hierarchical separation of features useful to the\ntask e.g. learning meaningful class associations, such as separating natural\nvs. man-made objects, and (iii) a mechanism to adapt the architecture to the\nsize and complexity of the training dataset.", "published": "2018-07-17T23:01:35Z", "version": 5}, {"aid": "1807.07281", "authors": ["Wei Ping", "Kainan Peng", "Jitong Chen"], "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "url": "http://arxiv.org/pdf/1807.07281v3", "summary": "In this work, we propose a new solution for parallel wave generation by\nWaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we\ndistill a Gaussian inverse autoregressive flow from the autoregressive WaveNet\nby minimizing a regularized KL divergence between their highly-peaked output\ndistributions. Our method computes the KL divergence in closed-form, which\nsimplifies the training algorithm and provides very efficient distillation. In\naddition, we introduce the first text-to-wave neural architecture for speech\nsynthesis, which is fully convolutional and enables fast end-to-end training\nfrom scratch. It significantly outperforms the previous pipeline that connects\na text-to-spectrogram model to a separately trained WaveNet (Ping et al.,\n2018). We also successfully distill a parallel waveform synthesizer conditioned\non the hidden representation in this end-to-end model.", "published": "2018-07-19T08:15:41Z", "version": 3}, {"aid": "1807.07320", "authors": ["Pau Rodr\u00edguez", "Josep M. Gonfaus", "Guillem Cucurull", "F. Xavier Roca", "Jordi Gonz\u00e0lez"], "title": "Attend and Rectify: a Gated Attention Mechanism for Fine-Grained Recovery", "url": "http://arxiv.org/pdf/1807.07320v2", "summary": "We propose a novel attention mechanism to enhance Convolutional Neural\nNetworks for fine-grained recognition. It learns to attend to lower-level\nfeature activations without requiring part annotations and uses these\nactivations to update and rectify the output likelihood distribution. In\ncontrast to other approaches, the proposed mechanism is modular,\narchitecture-independent and efficient both in terms of parameters and\ncomputation required. Experiments show that networks augmented with our\napproach systematically improve their classification accuracy and become more\nrobust to clutter. As a result, Wide Residual Networks augmented with our\nproposal surpasses the state of the art classification accuracies in CIFAR-10,\nthe Adience gender recognition task, Stanford dogs, and UEC Food-100.", "published": "2018-07-19T09:52:36Z", "version": 2}, {"aid": "1807.10583", "authors": ["Bishesh Khanal", "Alberto Gomez", "Nicolas Toussaint", "Steven McDonagh", "Veronika Zimmer", "Emily Skelton", "Jacqueline Matthew", "Daniel Grzech", "Robert Wright", "Chandni Gupta", "Benjamin Hou", "Daniel Rueckert", "Julia A. Schnabel", "Bernhard Kainz"], "title": "EchoFusion: Tracking and Reconstruction of Objects in 4D Freehand Ultrasound Imaging without External Trackers", "url": "http://arxiv.org/pdf/1807.10583v1", "summary": "Ultrasound (US) is the most widely used fetal imaging technique. However, US\nimages have limited capture range, and suffer from view dependent artefacts\nsuch as acoustic shadows. Compounding of overlapping 3D US acquisitions into a\nhigh-resolution volume can extend the field of view and remove image artefacts,\nwhich is useful for retrospective analysis including population based studies.\nHowever, such volume reconstructions require information about relative\ntransformations between probe positions from which the individual volumes were\nacquired. In prenatal US scans, the fetus can move independently from the\nmother, making external trackers such as electromagnetic or optical tracking\nunable to track the motion between probe position and the moving fetus. We\nprovide a novel methodology for image-based tracking and volume reconstruction\nby combining recent advances in deep learning and simultaneous localisation and\nmapping (SLAM). Tracking semantics are established through the use of a\nResidual 3D U-Net and the output is fed to the SLAM algorithm. As a proof of\nconcept, experiments are conducted on US volumes taken from a whole body fetal\nphantom, and from the heads of real fetuses. For the fetal head segmentation,\nwe also introduce a novel weak annotation approach to minimise the required\nmanual effort for ground truth annotation. We evaluate our method\nqualitatively, and quantitatively with respect to tissue discrimination\naccuracy and tracking robustness.", "published": "2018-07-19T12:07:50Z", "version": 1}, {"aid": "1807.07559", "authors": ["Amelia Jim\u00e9nez-S\u00e1nchez", "Shadi Albarqouni", "Diana Mateus"], "title": "Capsule Networks against Medical Imaging Data Challenges", "url": "http://arxiv.org/pdf/1807.07559v1", "summary": "A key component to the success of deep learning is the availability of\nmassive amounts of training data. Building and annotating large datasets for\nsolving medical image classification problems is today a bottleneck for many\napplications. Recently, capsule networks were proposed to deal with\nshortcomings of Convolutional Neural Networks (ConvNets). In this work, we\ncompare the behavior of capsule networks against ConvNets under typical\ndatasets constraints of medical image analysis, namely, small amounts of\nannotated data and class-imbalance. We evaluate our experiments on MNIST,\nFashion-MNIST and medical (histological and retina images) publicly available\ndatasets. Our results suggest that capsule networks can be trained with less\namount of data for the same or better performance and are more robust to an\nimbalanced class distribution, which makes our approach very promising for the\nmedical imaging community.", "published": "2018-07-19T17:56:37Z", "version": 1}, {"aid": "1807.07984", "authors": ["John Boaz Lee", "Ryan A. Rossi", "Sungchul Kim", "Nesreen K. Ahmed", "Eunyee Koh"], "title": "Attention Models in Graphs: A Survey", "url": "http://arxiv.org/pdf/1807.07984v1", "summary": "Graph-structured data arise naturally in many different application domains.\nBy representing data as graphs, we can capture entities (i.e., nodes) as well\nas their relationships (i.e., edges) with each other. Many useful insights can\nbe derived from graph-structured data as demonstrated by an ever-growing body\nof work focused on graph mining. However, in the real-world, graphs can be both\nlarge - with many complex patterns - and noisy which can pose a problem for\neffective graph mining. An effective way to deal with this issue is to\nincorporate \"attention\" into graph mining solutions. An attention mechanism\nallows a method to focus on task-relevant parts of the graph, helping it to\nmake better decisions. In this work, we conduct a comprehensive and focused\nsurvey of the literature on the emerging field of graph attention models. We\nintroduce three intuitive taxonomies to group existing work. These are based on\nproblem setting (type of input and output), the type of attention mechanism\nused, and the task (e.g., graph classification, link prediction, etc.). We\nmotivate our taxonomies through detailed examples and use each to survey\ncompeting approaches from a unique standpoint. Finally, we highlight several\nchallenges in the area and discuss promising directions for future work.", "published": "2018-07-20T18:11:07Z", "version": 1}, {"aid": "1807.08018", "authors": ["Houman Safaai", "Arno Onken", "Christopher D. Harvey", "Stefano Panzeri"], "title": "Information estimation using nonparametric copulas", "url": "http://arxiv.org/pdf/1807.08018v2", "summary": "Estimation of mutual information between random variables has become crucial\nin a range of fields, from physics to neuroscience to finance. Estimating\ninformation accurately over a wide range of conditions relies on the\ndevelopment of flexible methods to describe statistical dependencies among\nvariables, without imposing potentially invalid assumptions on the data. Such\nmethods are needed in cases that lack prior knowledge of their statistical\nproperties and that have limited sample numbers. Here we propose a powerful and\ngenerally applicable information estimator based on non-parametric copulas.\nThis estimator, called the non-parametric copula-based estimator (NPC), is\ntailored to take into account detailed stochastic relationships in the data\nindependently of the data's marginal distributions. The NPC estimator can be\nused both for continuous and discrete numerical variables and thus provides a\nsingle framework for the mutual information estimation of both continuous and\ndiscrete data. By extensive validation on artificial samples drawn from various\nstatistical distributions, we found that the NPC estimator compares well\nagainst commonly used alternatives. Unlike methods not based on copulas, it\nallows an estimation of information that is robust to changes of the details of\nthe marginal distributions. Unlike parametric copula methods, it remains\naccurate regardless of the precise form of the interactions between the\nvariables. In addition, the NPC estimator had accurate information estimates\neven at low sample numbers, in comparison to alternative estimators. The NPC\nestimator therefore provides a good balance between general applicability to\narbitrarily shaped statistical dependencies in the data and shows accurate and\nrobust performance when working with small sample sizes.", "published": "2018-07-20T20:17:59Z", "version": 2}, {"aid": "1807.08169", "authors": ["Matiur Rahman Minar", "Jibon Naher"], "title": "Recent Advances in Deep Learning: An Overview", "url": "http://arxiv.org/pdf/1807.08169v1", "summary": "Deep Learning is one of the newest trends in Machine Learning and Artificial\nIntelligence research. It is also one of the most popular scientific research\ntrends now-a-days. Deep learning methods have brought revolutionary advances in\ncomputer vision and machine learning. Every now and then, new and new deep\nlearning techniques are being born, outperforming state-of-the-art machine\nlearning and even existing deep learning techniques. In recent years, the world\nhas seen many major breakthroughs in this field. Since deep learning is\nevolving at a huge speed, its kind of hard to keep track of the regular\nadvances especially for new researchers. In this paper, we are going to briefly\ndiscuss about recent advances in Deep Learning for past few years.", "published": "2018-07-21T15:40:10Z", "version": 1}, {"aid": "1807.08291", "authors": ["Novanto Yudistira", "Takio Kurita"], "title": "Correlation Net: Spatiotemporal multimodal deep learning for action recognition", "url": "http://arxiv.org/pdf/1807.08291v6", "summary": "This paper describes a network that captures multimodal correlations over\narbitrary timestamps. The proposed scheme operates as a complementary, extended\nnetwork over a multimodal convolutional neural network (CNN). Spatial and\ntemporal streams are required for action recognition by a deep CNN, but\noverfitting reduction and fusing these two streams remain open problems. The\nexisting fusion approach averages the two streams. Here we propose a\ncorrelation network with a Shannon fusion for learning a pre-trained CNN. A\nLong-range video may consist of spatiotemporal correlations over arbitrary\ntimes, which can be captured by forming the correlation network from simple\nfully connected layers. This approach was found to complement the existing\nnetwork fusion methods. The importance of multimodal correlation is validated\nin comparison experiments on the UCF-101 and HMDB-51 datasets. The multimodal\ncorrelation enhanced the accuracy of the video recognition results.", "published": "2018-07-22T14:48:32Z", "version": 6}, {"aid": "1807.10641", "authors": ["Chuanqi Tan", "Fuchun Sun", "Wenchang Zhang", "Jianhua Chen", "Chunfang Liu"], "title": "Multimodal Classification with Deep Convolutional-Recurrent Neural Networks for Electroencephalography", "url": "http://arxiv.org/pdf/1807.10641v1", "summary": "Electroencephalography (EEG) has become the most significant input signal for\nbrain computer interface (BCI) based systems. However, it is very difficult to\nobtain satisfactory classification accuracy due to traditional methods can not\nfully exploit multimodal information. Herein, we propose a novel approach to\nmodeling cognitive events from EEG data by reducing it to a video\nclassification problem, which is designed to preserve the multimodal\ninformation of EEG. In addition, optical flow is introduced to represent the\nvariant information of EEG. We train a deep neural network (DNN) with\nconvolutional neural network (CNN) and recurrent neural network (RNN) for the\nEEG classification task by using EEG video and optical flow. The experiments\ndemonstrate that our approach has many advantages, such as more robustness and\nmore accuracy in EEG classification tasks. According to our approach, we\ndesigned a mixed BCI-based rehabilitation support system to help stroke\npatients perform some basic operations.", "published": "2018-07-24T03:33:43Z", "version": 1}, {"aid": "1807.09511", "authors": ["Xiaoran Xu", "Songpeng Zu", "Yuan Zhang", "Hanning Zhou", "Wei Feng"], "title": "Backprop-Q: Generalized Backpropagation for Stochastic Computation Graphs", "url": "http://arxiv.org/pdf/1807.09511v2", "summary": "In real-world scenarios, it is appealing to learn a model carrying out\nstochastic operations internally, known as stochastic computation graphs\n(SCGs), rather than learning a deterministic mapping. However, standard\nbackpropagation is not applicable to SCGs. We attempt to address this issue\nfrom the angle of cost propagation, with local surrogate costs, called\nQ-functions, constructed and learned for each stochastic node in an SCG. Then,\nthe SCG can be trained based on these surrogate costs using standard\nbackpropagation. We propose the entire framework as a solution to generalize\nbackpropagation for SCGs, which resembles an actor-critic architecture but\nbased on a graph. For broad applicability, we study a variety of SCG structures\nfrom one cost to multiple costs. We utilize recent advances in reinforcement\nlearning (RL) and variational Bayes (VB), such as off-policy critic learning\nand unbiased-and-low-variance gradient estimation, and review them in the\ncontext of SCGs. The generalized backpropagation extends transported learning\nsignals beyond gradients between stochastic nodes while preserving the benefit\nof backpropagating gradients through deterministic nodes. Experimental\nsuggestions and concerns are listed to help design and test any specific model\nusing this framework.", "published": "2018-07-25T10:06:24Z", "version": 2}, {"aid": "1807.09536", "authors": ["Francisco M. Castro", "Manuel J. Mar\u00edn-Jim\u00e9nez", "Nicol\u00e1s Guil", "Cordelia Schmid", "Karteek Alahari"], "title": "End-to-End Incremental Learning", "url": "http://arxiv.org/pdf/1807.09536v2", "summary": "Although deep learning approaches have stood out in recent years due to their\nstate-of-the-art results, they continue to suffer from catastrophic forgetting,\na dramatic decrease in overall performance when training with new classes added\nincrementally. This is due to current neural network architectures requiring\nthe entire dataset, consisting of all the samples from the old as well as the\nnew classes, to update the model -a requirement that becomes easily\nunsustainable as the number of classes grows. We address this issue with our\napproach to learn deep neural networks incrementally, using new data and only a\nsmall exemplar set corresponding to samples from the old classes. This is based\non a loss composed of a distillation measure to retain the knowledge acquired\nfrom the old classes, and a cross-entropy loss to learn the new classes. Our\nincremental training is achieved while keeping the entire framework end-to-end,\ni.e., learning the data representation and the classifier jointly, unlike\nrecent methods with no such guarantees. We evaluate our method extensively on\nthe CIFAR-100 and ImageNet (ILSVRC 2012) image classification datasets, and\nshow state-of-the-art performance.", "published": "2018-07-25T11:38:25Z", "version": 2}, {"aid": "1807.10117", "authors": ["G. Zhang", "H. Li"], "title": "Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)", "url": "http://arxiv.org/pdf/1807.10117v2", "summary": "Recently, self-normalizing neural networks (SNNs) have been proposed with the\nintention to avoid batch or weight normalization. The key step in SNNs is to\nproperly scale the exponential linear unit (referred to as SELU) to inherently\nincorporate normalization based on central limit theory. SELU is a\nmonotonically increasing function, where it has an approximately constant\nnegative output for large negative input. In this work, we propose a new\nactivation function to break the monotonicity property of SELU while still\npreserving the self-normalizing property. Differently from SELU, the new\nfunction introduces a bump-shaped function in the region of negative input by\nregularizing a linear function with a scaled exponential function, which is\nreferred to as a scaled exponentially-regularized linear unit (SERLU). The\nbump-shaped function has approximately zero response to large negative input\nwhile being able to push the output of SERLU towards zero mean statistically.\nTo effectively combat over-fitting, we develop a so-called shift-dropout for\nSERLU, which includes standard dropout as a special case. Experimental results\non MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provide\nconsistently promising results in comparison to other 5 activation functions\nincluding ELU, SELU, Swish, Leakly ReLU and ReLU.", "published": "2018-07-26T13:33:49Z", "version": 2}, {"aid": "1807.10119", "authors": ["Yuzhe Ma", "Ran Chen", "Wei Li", "Fanhua Shang", "Wenjian Yu", "Minsik Cho", "Bei Yu"], "title": "A Unified Approximation Framework for Compressing and Accelerating Deep Neural Networks", "url": "http://arxiv.org/pdf/1807.10119v3", "summary": "Deep neural networks (DNNs) have achieved significant success in a variety of\nreal world applications, i.e., image classification. However, tons of\nparameters in the networks restrict the efficiency of neural networks due to\nthe large model size and the intensive computation. To address this issue,\nvarious approximation techniques have been investigated, which seek for a light\nweighted network with little performance degradation in exchange of smaller\nmodel size or faster inference. Both low-rankness and sparsity are appealing\nproperties for the network approximation. In this paper we propose a unified\nframework to compress the convolutional neural networks (CNNs) by combining\nthese two properties, while taking the nonlinear activation into consideration.\nEach layer in the network is approximated by the sum of a structured sparse\ncomponent and a low-rank component, which is formulated as an optimization\nproblem. Then, an extended version of alternating direction method of\nmultipliers (ADMM) with guaranteed convergence is presented to solve the\nrelaxed optimization problem. Experiments are carried out on VGG-16, AlexNet\nand GoogLeNet with large image classification datasets. The results outperform\nprevious work in terms of accuracy degradation, compression rate and speedup\nratio. The proposed method is able to remarkably compress the model (with up to\n4.9x reduction of parameters) at a cost of little loss or without loss on\naccuracy.", "published": "2018-07-26T13:36:19Z", "version": 3}, {"aid": "1807.10267", "authors": ["Anurag Ranjan", "Timo Bolkart", "Soubhik Sanyal", "Michael J. Black"], "title": "Generating 3D faces using Convolutional Mesh Autoencoders", "url": "http://arxiv.org/pdf/1807.10267v3", "summary": "Learned 3D representations of human faces are useful for computer vision\nproblems such as 3D face tracking and reconstruction from images, as well as\ngraphics applications such as character generation and animation. Traditional\nmodels learn a latent representation of a face using linear subspaces or\nhigher-order tensor generalizations. Due to this linearity, they can not\ncapture extreme deformations and non-linear expressions. To address this, we\nintroduce a versatile model that learns a non-linear representation of a face\nusing spectral convolutions on a mesh surface. We introduce mesh sampling\noperations that enable a hierarchical mesh representation that captures\nnon-linear variations in shape and expression at multiple scales within the\nmodel. In a variational setting, our model samples diverse realistic 3D faces\nfrom a multivariate Gaussian distribution. Our training data consists of 20,466\nmeshes of extreme expressions captured over 12 different subjects. Despite\nlimited training data, our trained model outperforms state-of-the-art face\nmodels with 50% lower reconstruction error, while using 75% fewer parameters.\nWe also show that, replacing the expression space of an existing\nstate-of-the-art face model with our autoencoder, achieves a lower\nreconstruction error. Our data, model and code are available at\nhttp://github.com/anuragranj/coma", "published": "2018-07-26T17:53:50Z", "version": 3}, {"aid": "1807.10726", "authors": ["Bowen Zhang", "Xifan Zhang", "Fan Cheng", "Deli Zhao"], "title": "Few Shot Learning with Simplex", "url": "http://arxiv.org/pdf/1807.10726v2", "summary": "Deep learning has made remarkable achievement in many fields. However,\nlearning the parameters of neural networks usually demands a large amount of\nlabeled data. The algorithms of deep learning, therefore, encounter\ndifficulties when applied to supervised learning where only little data are\navailable. This specific task is called few-shot learning. To address it, we\npropose a novel algorithm for few-shot learning using discrete geometry, in the\nsense that the samples in a class are modeled as a reduced simplex. The volume\nof the simplex is used for the measurement of class scatter. During testing,\ncombined with the test sample and the points in the class, a new simplex is\nformed. Then the similarity between the test sample and the class can be\nquantized with the ratio of volumes of the new simplex to the original class\nsimplex. Moreover, we present an approach to constructing simplices using local\nregions of feature maps yielded by convolutional neural networks. Experiments\non Omniglot and miniImageNet verify the effectiveness of our simplex algorithm\non few-shot learning.", "published": "2018-07-27T16:52:57Z", "version": 2}, {"aid": "1808.00158", "authors": ["Mirco Ravanelli", "Yoshua Bengio"], "title": "Speaker Recognition from Raw Waveform with SincNet", "url": "http://arxiv.org/pdf/1808.00158v3", "summary": "Deep learning is progressively gaining popularity as a viable alternative to\ni-vectors for speaker recognition. Promising results have been recently\nobtained with Convolutional Neural Networks (CNNs) when fed by raw speech\nsamples directly. Rather than employing standard hand-crafted features, the\nlatter CNNs learn low-level speech representations from waveforms, potentially\nallowing the network to better capture important narrow-band speaker\ncharacteristics such as pitch and formants. Proper design of the neural network\nis crucial to achieve this goal. This paper proposes a novel CNN architecture,\ncalled SincNet, that encourages the first convolutional layer to discover more\nmeaningful filters. SincNet is based on parametrized sinc functions, which\nimplement band-pass filters. In contrast to standard CNNs, that learn all\nelements of each filter, only low and high cutoff frequencies are directly\nlearned from data with the proposed method. This offers a very compact and\nefficient way to derive a customized filter bank specifically tuned for the\ndesired application. Our experiments, conducted on both speaker identification\nand speaker verification tasks, show that the proposed architecture converges\nfaster and performs better than a standard CNN on raw waveforms.", "published": "2018-07-29T16:27:19Z", "version": 3}, {"aid": "1807.11091", "authors": ["Tianyun Zhang", "Shaokai Ye", "Kaiqi Zhang", "Xiaolong Ma", "Ning Liu", "Linfeng Zhang", "Jian Tang", "Kaisheng Ma", "Xue Lin", "Makan Fardad", "Yanzhi Wang"], "title": "StructADMM: A Systematic, High-Efficiency Framework of Structured Weight Pruning for DNNs", "url": "http://arxiv.org/pdf/1807.11091v3", "summary": "Weight pruning methods of DNNs have been demonstrated to achieve a good model\npruning rate without loss of accuracy, thereby alleviating the significant\ncomputation/storage requirements of large-scale DNNs. Structured weight pruning\nmethods have been proposed to overcome the limitation of irregular network\nstructure and demonstrated actual GPU acceleration. However, in prior work the\npruning rate (degree of sparsity) and GPU acceleration are limited (to less\nthan 50%) when accuracy needs to be maintained. In this work,we overcome these\nlimitations by proposing a unified, systematic framework of structured weight\npruning for DNNs. It is a framework that can be used to induce different types\nof structured sparsity, such as filter-wise, channel-wise, and shape-wise\nsparsity, as well non-structured sparsity. The proposed framework incorporates\nstochastic gradient descent with ADMM, and can be understood as a dynamic\nregularization method in which the regularization target is analytically\nupdated in each iteration. Without loss of accuracy on the AlexNet model, we\nachieve 2.58X and 3.65X average measured speedup on two GPUs, clearly\noutperforming the prior work. The average speedups reach 3.15X and 8.52X when\nallowing a moderate ac-curacy loss of 2%. In this case the model compression\nfor convolutional layers is 15.0X, corresponding to 11.93X measured CPU\nspeedup. Our experiments on ResNet model and on other data sets like UCF101 and\nCIFAR-10 demonstrate the consistently higher performance of our framework.", "published": "2018-07-29T18:07:04Z", "version": 3}, {"aid": "1807.11112", "authors": ["Huy Tu", "Vivek Nair"], "title": "Is One Hyperparameter Optimizer Enough?", "url": "http://arxiv.org/pdf/1807.11112v4", "summary": "Hyperparameter tuning is the black art of automatically finding a good\ncombination of control parameters for a data miner. While widely applied in\nempirical Software Engineering, there has not been much discussion on which\nhyperparameter tuner is best for software analytics. To address this gap in the\nliterature, this paper applied a range of hyperparameter optimizers (grid\nsearch, random search, differential evolution, and Bayesian optimization) to\ndefect prediction problem. Surprisingly, no hyperparameter optimizer was\nobserved to be `best' and, for one of the two evaluation measures studied here\n(F-measure), hyperparameter optimization, in 50\\% cases, was no better than\nusing default configurations.\n  We conclude that hyperparameter optimization is more nuanced than previously\nbelieved. While such optimization can certainly lead to large improvements in\nthe performance of classifiers used in software analytics, it remains to be\nseen which specific optimizers should be applied to a new dataset.", "published": "2018-07-29T21:26:12Z", "version": 4}, {"aid": "1807.11929", "authors": ["Mengmi Zhang", "Keng Teck Ma", "Shih-Cheng Yen", "Joo Hwee Lim", "Qi Zhao", "Jiashi Feng"], "title": "Egocentric Spatial Memory", "url": "http://arxiv.org/pdf/1807.11929v1", "summary": "Egocentric spatial memory (ESM) defines a memory system with encoding,\nstoring, recognizing and recalling the spatial information about the\nenvironment from an egocentric perspective. We introduce an integrated deep\nneural network architecture for modeling ESM. It learns to estimate the\noccupancy state of the world and progressively construct top-down 2D global\nmaps from egocentric views in a spatially extended environment. During the\nexploration, our proposed ESM model updates belief of the global map based on\nlocal observations using a recurrent neural network. It also augments the local\nmapping with a novel external memory to encode and store latent representations\nof the visited places over long-term exploration in large environments which\nenables agents to perform place recognition and hence, loop closure. Our\nproposed ESM network contributes in the following aspects: (1) without feature\nengineering, our model predicts free space based on egocentric views\nefficiently in an end-to-end manner; (2) different from other deep\nlearning-based mapping system, ESMN deals with continuous actions and states\nwhich is vitally important for robotic control in real applications. In the\nexperiments, we demonstrate its accurate and robust global mapping capacities\nin 3D virtual mazes and realistic indoor environments by comparing with several\ncompetitive baselines.", "published": "2018-07-31T17:27:19Z", "version": 1}, {"aid": "1808.00033", "authors": ["Mengnan Du", "Ninghao Liu", "Xia Hu"], "title": "Techniques for Interpretable Machine Learning", "url": "http://arxiv.org/pdf/1808.00033v3", "summary": "Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.", "published": "2018-07-31T19:14:39Z", "version": 3}, {"aid": "1808.00193", "authors": ["Yukang Chen", "Gaofeng Meng", "Qian Zhang", "Shiming Xiang", "Chang Huang", "Lisen Mu", "Xinggang Wang"], "title": "Reinforced Evolutionary Neural Architecture Search", "url": "http://arxiv.org/pdf/1808.00193v3", "summary": "Neural Architecture Search (NAS) is an important yet challenging task in\nnetwork design due to its high computational consumption. To address this\nissue, we propose the Reinforced Evolutionary Neural Architecture Search (RE-\nNAS), which is an evolutionary method with the reinforced mutation for NAS. Our\nmethod integrates reinforced mutation into an evolution algorithm for neural\narchitecture exploration, in which a mutation controller is introduced to learn\nthe effects of slight modifications and make mutation actions. The reinforced\nmutation controller guides the model population to evolve efficiently.\nFurthermore, as child models can inherit parameters from their parents during\nevolution, our method requires very limited computational resources. In\nexperiments, we conduct the proposed search method on CIFAR-10 and obtain a\npowerful network architecture, RENASNet. This architecture achieves a\ncompetitive result on CIFAR-10. The explored network architecture is\ntransferable to ImageNet and achieves a new state-of-the-art accuracy, i.e.,\n75.7% top-1 accuracy with 5.36M parameters on mobile ImageNet. We further test\nits performance on semantic segmentation with DeepLabv3 on the PASCAL VOC.\nRENASNet outperforms MobileNet-v1, MobileNet-v2 and NASNet. It achieves 75.83%\nmIOU without being pre-trained on COCO.", "published": "2018-08-01T06:53:53Z", "version": 3}, {"aid": "1808.00679", "authors": ["Irina Dolzhikova", "Khaled Salama", "Vipin Kizheppatt", "Alex Pappachen James"], "title": "Memristor-based Synaptic Sampling Machines", "url": "http://arxiv.org/pdf/1808.00679v1", "summary": "Synaptic Sampling Machine (SSM) is a type of neural network model that\nconsiders biological unreliability of the synapses. We propose the circuit\ndesign of the SSM neural network which is realized through the memristive-CMOS\ncrossbar structure with the synaptic sampling cell (SSC) being used as a basic\nstochastic unit. The increase in the edge computing devices in the Internet of\nthings era, drives the need for hardware acceleration for data processing and\ncomputing. The computational considerations of the processing speed and\npossibility for the real-time realization pushes the synaptic sampling\nalgorithm that demonstrated promising results on software for hardware\nimplementation.", "published": "2018-08-02T06:05:07Z", "version": 1}, {"aid": "1808.01174", "authors": ["Daniel Jakubovitz", "Raja Giryes", "Miguel R. D. Rodrigues"], "title": "Generalization Error in Deep Learning", "url": "http://arxiv.org/pdf/1808.01174v3", "summary": "Deep learning models have lately shown great performance in various fields\nsuch as computer vision, speech recognition, speech translation, and natural\nlanguage processing. However, alongside their state-of-the-art performance, it\nis still generally unclear what is the source of their generalization ability.\nThus, an important question is what makes deep neural networks able to\ngeneralize well from the training set to new data. In this article, we provide\nan overview of the existing theory and bounds for the characterization of the\ngeneralization error of deep neural networks, combining both classical and more\nrecent theoretical and empirical results.", "published": "2018-08-03T12:57:12Z", "version": 3}, {"aid": "1808.01462", "authors": ["Eman Ahmed", "Alexandre Saint", "Abd El Rahman Shabayek", "Kseniya Cherenkova", "Rig Das", "Gleb Gusev", "Djamila Aouada", "Bjorn Ottersten"], "title": "A survey on Deep Learning Advances on Different 3D Data Representations", "url": "http://arxiv.org/pdf/1808.01462v2", "summary": "3D data is a valuable asset the computer vision filed as it provides rich\ninformation about the full geometry of sensed objects and scenes. Recently,\nwith the availability of both large 3D datasets and computational power, it is\ntoday possible to consider applying deep learning to learn specific tasks on 3D\ndata such as segmentation, recognition and correspondence. Depending on the\nconsidered 3D data representation, different challenges may be foreseen in\nusing existent deep learning architectures. In this work, we provide a\ncomprehensive overview about various 3D data representations highlighting the\ndifference between Euclidean and non-Euclidean ones. We also discuss how Deep\nLearning methods are applied on each representation, analyzing the challenges\nto overcome.", "published": "2018-08-04T10:18:55Z", "version": 2}, {"aid": "1808.01556", "authors": ["Rongtian Ye", "Fangyu Liu", "Liqiang Zhang"], "title": "3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks", "url": "http://arxiv.org/pdf/1808.01556v1", "summary": "Standard 3D convolution operations require much larger amounts of memory and\ncomputation cost than 2D convolution operations. The fact has hindered the\ndevelopment of deep neural nets in many 3D vision tasks. In this paper, we\ninvestigate the possibility of applying depthwise separable convolutions in 3D\nscenario and introduce the use of 3D depthwise convolution. A 3D depthwise\nconvolution splits a single standard 3D convolution into two separate steps,\nwhich would drastically reduce the number of parameters in 3D convolutions with\nmore than one order of magnitude. We experiment with 3D depthwise convolution\non popular CNN architectures and also compare it with a similar structure\ncalled pseudo-3D convolution. The results demonstrate that, with 3D depthwise\nconvolutions, 3D vision tasks like classification and reconstruction can be\ncarried out with more light-weighted neural networks while still delivering\ncomparable performances.", "published": "2018-08-05T03:50:54Z", "version": 1}, {"aid": "1808.07004", "authors": ["J Gerard Wolff"], "title": "Mathematics as information compression via the matching and unification of patterns", "url": "http://arxiv.org/pdf/1808.07004v2", "summary": "This paper describes a novel perspective on the foundations of mathematics:\nhow mathematics may be seen to be largely about 'information compression via\nthe matching and unification of patterns' (ICMUP). ICMUP is itself a novel\napproach to information compression, couched in terms of non-mathematical\nprimitives, as is necessary in any investigation of the foundations of\nmathematics. This new perspective on the foundations of mathematics has grown\nout of an extensive programme of research developing the \"SP Theory of\nIntelligence\" and its realisation in the \"SP Computer Model\", a system in which\na generalised version of ICMUP -- the powerful concept of SP-multiple-alignment\n-- plays a central role. These ideas may be seen to be part of a \"Big Picture\"\ncomprising six areas of interest, with information compression as a unifying\ntheme. The paper describes the close relation between mathematics and\ninformation compression, and describes examples showing how variants of ICMUP\nmay be seen in widely-used structures and operations in mathematics. Examples\nare also given to show how the mathematics-related disciplines of logic and\ncomputing may be understood as ICMUP. There are many potential benefits and\napplications of these ideas.", "published": "2018-08-05T09:17:06Z", "version": 2}, {"aid": "1808.01721", "authors": ["Bin Chen", "Wei Guo", "Bin Li", "Rober K. F. Teng", "Mingjun Dai", "Jianping Luo", "Hui Wang"], "title": "A Study of Deep Feature Fusion based Methods for Classifying Multi-lead ECG", "url": "http://arxiv.org/pdf/1808.01721v1", "summary": "An automatic classification method has been studied to effectively detect and\nrecognize Electrocardiogram (ECG). Based on the synchronizing and orthogonal\nrelationships of multiple leads, we propose a Multi-branch Convolution and\nResidual Network (MBCRNet) with three kinds of feature fusion methods for\nautomatic detection of normal and abnormal ECG signals. Experiments are\nconducted on the Chinese Cardiovascular Disease Database (CCDD). Through\n10-fold cross-validation, we achieve an average accuracy of 87.04% and a\nsensitivity of 89.93%, which outperforms previous methods under the same\ndatabase. It is also shown that the multi-lead feature fusion network can\nimprove the classification accuracy over the network only with the single lead\nfeatures.", "published": "2018-08-06T03:23:53Z", "version": 1}, {"aid": "1808.01752", "authors": ["Chuanqi Tan", "Fuchun Sun", "Wenchang Zhang"], "title": "Deep Transfer Learning for EEG-based Brain Computer Interface", "url": "http://arxiv.org/pdf/1808.01752v1", "summary": "The electroencephalography classifier is the most important component of\nbrain-computer interface based systems. There are two major problems hindering\nthe improvement of it. First, traditional methods do not fully exploit\nmultimodal information. Second, large-scale annotated EEG datasets are almost\nimpossible to acquire because biological data acquisition is challenging and\nquality annotation is costly. Herein, we propose a novel deep transfer learning\napproach to solve these two problems. First, we model cognitive events based on\nEEG data by characterizing the data using EEG optical flow, which is designed\nto preserve multimodal EEG information in a uniform representation. Second, we\ndesign a deep transfer learning framework which is suitable for transferring\nknowledge by joint training, which contains a adversarial network and a special\nloss function. The experiments demonstrate that our approach, when applied to\nEEG classification tasks, has many advantages, such as robustness and accuracy.", "published": "2018-08-06T07:23:34Z", "version": 1}, {"aid": "1808.01834", "authors": ["Lingni Ma", "J\u00f6rg St\u00fcckler", "Tao Wu", "Daniel Cremers"], "title": "Detailed Dense Inference with Convolutional Neural Networks via Discrete Wavelet Transform", "url": "http://arxiv.org/pdf/1808.01834v1", "summary": "Dense pixelwise prediction such as semantic segmentation is an up-to-date\nchallenge for deep convolutional neural networks (CNNs). Many state-of-the-art\napproaches either tackle the loss of high-resolution information due to pooling\nin the encoder stage, or use dilated convolutions or high-resolution lanes to\nmaintain detailed feature maps and predictions. Motivated by the structural\nanalogy between multi-resolution wavelet analysis and the pooling/unpooling\nlayers of CNNs, we introduce discrete wavelet transform (DWT) into the CNN\nencoder-decoder architecture and propose WCNN. The high-frequency wavelet\ncoefficients are computed at encoder, which are later used at the decoder to\nunpooled jointly with coarse-resolution feature maps through the inverse DWT.\nThe DWT/iDWT is further used to develop two wavelet pyramids to capture the\nglobal context, where the multi-resolution DWT is applied to successively\nreduce the spatial resolution and increase the receptive field. Experiment with\nthe Cityscape dataset, the proposed WCNNs are computationally efficient and\nyield improvements the accuracy for high-resolution dense pixelwise prediction.", "published": "2018-08-06T11:57:15Z", "version": 1}, {"aid": "1808.02350", "authors": ["Waleed Ali", "Sherif Abdelkarim", "Mohamed Zahran", "Mahmoud Zidan", "Ahmad El Sallab"], "title": "YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection from LiDAR Point Cloud", "url": "http://arxiv.org/pdf/1808.02350v1", "summary": "Object detection and classification in 3D is a key task in Automated Driving\n(AD). LiDAR sensors are employed to provide the 3D point cloud reconstruction\nof the surrounding environment, while the task of 3D object bounding box\ndetection in real time remains a strong algorithmic challenge. In this paper,\nwe build on the success of the one-shot regression meta-architecture in the 2D\nperspective image space and extend it to generate oriented 3D object bounding\nboxes from LiDAR point cloud. Our main contribution is in extending the loss\nfunction of YOLO v2 to include the yaw angle, the 3D box center in Cartesian\ncoordinates and the height of the box as a direct regression problem. This\nformulation enables real-time performance, which is essential for automated\ndriving. Our results are showing promising figures on KITTI benchmark,\nachieving real-time performance (40 fps) on Titan X GPU.", "published": "2018-08-07T13:19:24Z", "version": 1}, {"aid": "1808.02455", "authors": ["Hassan Ismail Fawaz", "Germain Forestier", "Jonathan Weber", "Lhassane Idoumghar", "Pierre-Alain Muller"], "title": "Data augmentation using synthetic data for time series classification with deep residual networks", "url": "http://arxiv.org/pdf/1808.02455v1", "summary": "Data augmentation in deep neural networks is the process of generating\nartificial data in order to reduce the variance of the classifier with the goal\nto reduce the number of errors. This idea has been shown to improve deep neural\nnetwork's generalization capabilities in many computer vision tasks such as\nimage recognition and object localization. Apart from these applications, deep\nConvolutional Neural Networks (CNNs) have also recently gained popularity in\nthe Time Series Classification (TSC) community. However, unlike in image\nrecognition problems, data augmentation techniques have not yet been\ninvestigated thoroughly for the TSC task. This is surprising as the accuracy of\ndeep learning models for TSC could potentially be improved, especially for\nsmall datasets that exhibit overfitting, when a data augmentation method is\nadopted. In this paper, we fill this gap by investigating the application of a\nrecently proposed data augmentation technique based on the Dynamic Time Warping\ndistance, for a deep learning model for TSC. To evaluate the potential of\naugmenting the training set, we performed extensive experiments using the UCR\nTSC benchmark. Our preliminary experiments reveal that data augmentation can\ndrastically increase deep CNN's accuracy on some datasets and significantly\nimprove the deep model's accuracy when the method is used in an ensemble\napproach.", "published": "2018-08-07T16:48:21Z", "version": 1}, {"aid": "1808.05464", "authors": ["He He", "Dongrui Wu"], "title": "Transfer Learning for Brain-Computer Interfaces: A Euclidean Space Data Alignment Approach", "url": "http://arxiv.org/pdf/1808.05464v2", "summary": "Objective: This paper targets a major challenge in developing practical\nEEG-based brain-computer interfaces (BCIs): how to cope with individual\ndifferences so that better learning performance can be obtained for a new\nsubject, with minimum or even no subject-specific data? Methods: We propose a\nnovel approach to align EEG trials from different subjects in the Euclidean\nspace to make them more similar, and hence improve the learning performance for\na new subject. Our approach has three desirable properties: 1) it aligns the\nEEG trials directly in the Euclidean space, and any signal processing, feature\nextraction and machine learning algorithms can then be applied to the aligned\ntrials; 2) its computational cost is very low; and, 3) it is unsupervised and\ndoes not need any label information from the new subject. Results: Both offline\nand simulated online experiments on motor imagery classification and\nevent-related potential classification verified that our proposed approach\noutperformed a state-of-the-art Riemannian space data alignment approach, and\nseveral approaches without data alignment. Conclusion: The proposed Euclidean\nspace EEG data alignment approach can greatly facilitate transfer learning in\nBCIs. Significance: Our proposed approach is effective, efficient, and easy to\nimplement. It could be an essential pre-processing step for EEG-based BCIs.", "published": "2018-08-08T23:06:43Z", "version": 2}, {"aid": "1808.04247", "authors": ["Trang Pham", "Truyen Tran", "Svetha Venkatesh"], "title": "Relational dynamic memory networks", "url": "http://arxiv.org/pdf/1808.04247v3", "summary": "Neural networks excel in detecting regular patterns but are less successful\nin representing and manipulating complex data structures, possibly due to the\nlack of an external memory. This has led to the recent development of a new\nline of architectures known as Memory-Augmented Neural Networks (MANNs), each\nof which consists of a neural network that interacts with an external memory\nmatrix. However, this RAM-like memory matrix is unstructured and thus does not\nnaturally encode structured objects. Here we design a new MANN dubbed\nRelational Dynamic Memory Network (RMDN) to bridge the gap. Like existing\nMANNs, RMDN has a neural controller but its memory is structured as\nmulti-relational graphs. RMDN uses the memory to represent and manipulate\ngraph-structured data in response to query; and as a neural network, RMDN is\ntrainable from labeled data. Thus RMDN learns to answer queries about a set of\ngraph-structured objects without explicit programming. We evaluate the\ncapability of RMDN on several important prediction problems, including software\nvulnerability, molecular bioactivity and chemical-chemical interaction. Results\ndemonstrate the efficacy of the proposed model.", "published": "2018-08-10T00:01:34Z", "version": 3}, {"aid": "1808.03578", "authors": ["Noah Frazier-Logue", "Stephen Jos\u00e9 Hanson"], "title": "Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning", "url": "http://arxiv.org/pdf/1808.03578v2", "summary": "Multi-layer neural networks have lead to remarkable performance on many kinds\nof benchmark tasks in text, speech and image processing. Nonlinear parameter\nestimation in hierarchical models is known to be subject to overfitting and\nmisspecification. One approach to these estimation and related problems (local\nminima, colinearity, feature discovery etc.) is called Dropout (Hinton, et al\n2012, Baldi et al 2016). The Dropout algorithm removes hidden units according\nto a Bernoulli random variable with probability $p$ prior to each update,\ncreating random \"shocks\" to the network that are averaged over updates. In this\npaper we will show that Dropout is a special case of a more general model\npublished originally in 1990 called the Stochastic Delta Rule, or SDR (Hanson,\n1990). SDR redefines each weight in the network as a random variable with mean\n$\\mu_{w_{ij}}$ and standard deviation $\\sigma_{w_{ij}}$. Each weight random\nvariable is sampled on each forward activation, consequently creating an\nexponential number of potential networks with shared weights. Both parameters\nare updated according to prediction error, thus resulting in weight noise\ninjections that reflect a local history of prediction error and local model\naveraging. SDR therefore implements a more sensitive local gradient-dependent\nsimulated annealing per weight converging in the limit to a Bayes optimal\nnetwork. Tests on standard benchmarks (CIFAR) using a modified version of\nDenseNet shows the SDR outperforms standard Dropout in test error by approx.\n$17\\%$ with DenseNet-BC 250 on CIFAR-100 and approx. $12-14\\%$ in smaller\nnetworks. We also show that SDR reaches the same accuracy that Dropout attains\nin 100 epochs in as few as 35 epochs.", "published": "2018-08-10T15:06:05Z", "version": 2}, {"aid": "1808.04560", "authors": ["Chen Wei", "Wenjing Wang", "Wenhan Yang", "Jiaying Liu"], "title": "Deep Retinex Decomposition for Low-Light Enhancement", "url": "http://arxiv.org/pdf/1808.04560v1", "summary": "Retinex model is an effective tool for low-light image enhancement. It\nassumes that observed images can be decomposed into the reflectance and\nillumination. Most existing Retinex-based methods have carefully designed\nhand-crafted constraints and parameters for this highly ill-posed\ndecomposition, which may be limited by model capacity when applied in various\nscenes. In this paper, we collect a LOw-Light dataset (LOL) containing\nlow/normal-light image pairs and propose a deep Retinex-Net learned on this\ndataset, including a Decom-Net for decomposition and an Enhance-Net for\nillumination adjustment. In the training process for Decom-Net, there is no\nground truth of decomposed reflectance and illumination. The network is learned\nwith only key constraints including the consistent reflectance shared by paired\nlow/normal-light images, and the smoothness of illumination. Based on the\ndecomposition, subsequent lightness enhancement is conducted on illumination by\nan enhancement network called Enhance-Net, and for joint denoising there is a\ndenoising operation on reflectance. The Retinex-Net is end-to-end trainable, so\nthat the learned decomposition is by nature good for lightness adjustment.\nExtensive experiments demonstrate that our method not only achieves visually\npleasing quality for low-light enhancement but also provides a good\nrepresentation of image decomposition.", "published": "2018-08-14T07:20:55Z", "version": 1}, {"aid": "1808.04952", "authors": ["Yuqi Yang", "Shilin Liu", "Hao Pan", "Yang Liu", "Xin Tong"], "title": "PFCNN: Convolutional Neural Networks on 3D Surfaces Using Parallel Frames", "url": "http://arxiv.org/pdf/1808.04952v2", "summary": "Surface meshes are widely used shape representations and capture finer\ngeometry data than point clouds or volumetric grids, but are challenging to\napply CNNs directly due to their non-Euclidean structure. We use parallel\nframes on surface to define PFCNNs that enable effective feature learning on\nsurface meshes by mimicking standard convolutions faithfully. In particular,\nthe convolution of PFCNN not only maps local surface patches onto flat tangent\nplanes, but also aligns the tangent planes such that they locally form a flat\nEuclidean structure, thus enabling recovery of standard convolutions. The\nalignment is achieved by the tool of locally flat connections borrowed from\ndiscrete differential geometry, which can be efficiently encoded and computed\nby parallel frame fields. In addition, the lack of canonical axis on surface is\nhandled by sampling with the frame directions. Experiments show that for tasks\nincluding classification, segmentation and registration on deformable geometric\ndomains, as well as semantic scene segmentation on rigid domains, PFCNNs\nachieve robust and superior performances without using sophisticated input\nfeatures than state-of-the-art surface based CNNs.", "published": "2018-08-15T02:39:35Z", "version": 2}, {"aid": "1808.05779", "authors": ["Sangil Jung", "Changyong Son", "Seohyung Lee", "Jinwoo Son", "Youngjun Kwak", "Jae-Joon Han", "Sung Ju Hwang", "Changkyu Choi"], "title": "Learning to Quantize Deep Networks by Optimizing Quantization Intervals with Task Loss", "url": "http://arxiv.org/pdf/1808.05779v3", "summary": "Reducing bit-widths of activations and weights of deep networks makes it\nefficient to compute and store them in memory, which is crucial in their\ndeployments to resource-limited devices, such as mobile phones. However,\ndecreasing bit-widths with quantization generally yields drastically degraded\naccuracy. To tackle this problem, we propose to learn to quantize activations\nand weights via a trainable quantizer that transforms and discretizes them.\nSpecifically, we parameterize the quantization intervals and obtain their\noptimal values by directly minimizing the task loss of the network. This\nquantization-interval-learning (QIL) allows the quantized networks to maintain\nthe accuracy of the full-precision (32-bit) networks with bit-width as low as\n4-bit and minimize the accuracy degeneration with further bit-width reduction\n(i.e., 3 and 2-bit). Moreover, our quantizer can be trained on a heterogeneous\ndataset, and thus can be used to quantize pretrained networks without access to\ntheir training data. We demonstrate the effectiveness of our trainable\nquantizer on ImageNet dataset with various network architectures such as\nResNet-18, -34 and AlexNet, on which it outperforms existing methods to achieve\nthe state-of-the-art accuracy.", "published": "2018-08-17T07:28:17Z", "version": 3}, {"aid": "1808.05839", "authors": ["Abdullah M. Zyarah", "Dhireesha Kudithipudi"], "title": "Neuromorphic Architecture for the Hierarchical Temporal Memory", "url": "http://arxiv.org/pdf/1808.05839v1", "summary": "A biomimetic machine intelligence algorithm, that holds promise in creating\ninvariant representations of spatiotemporal input streams is the hierarchical\ntemporal memory (HTM). This unsupervised online algorithm has been demonstrated\non several machine-learning tasks, including anomaly detection. Significant\neffort has been made in formalizing and applying the HTM algorithm to different\nclasses of problems. There are few early explorations of the HTM hardware\narchitecture, especially for the earlier version of the spatial pooler of HTM\nalgorithm. In this article, we present a full-scale HTM architecture for both\nspatial pooler and temporal memory. Synthetic synapse design is proposed to\naddress the potential and dynamic interconnections occurring during learning.\nThe architecture is interweaved with parallel cells and columns that enable\nhigh processing speed for the HTM. The proposed architecture is verified for\ntwo different datasets: MNIST and the European number plate font (EUNF), with\nand without the presence of noise. The spatial pooler architecture is\nsynthesized on Xilinx ZYNQ-7, with 91.16% classification accuracy for MNIST and\n90\\% accuracy for EUNF, with noise. For the temporal memory sequence\nprediction, first and second order predictions are observed for a 5-number long\nsequence generated from EUNF dataset and 95% accuracy is obtained. Moreover,\nthe proposed hardware architecture offers 1364X speedup over the software\nrealization. These results indicate that the proposed architecture can serve as\na digital core to build the HTM in hardware and eventually as a standalone\nself-learning system.", "published": "2018-08-17T12:37:58Z", "version": 1}, {"aid": "1808.06414", "authors": ["Shuai Zhang", "Yi Tay", "Lina Yao", "Aixin Sun"], "title": "Next Item Recommendation with Self-Attention", "url": "http://arxiv.org/pdf/1808.06414v2", "summary": "In this paper, we propose a novel sequence-aware recommendation model. Our\nmodel utilizes self-attention mechanism to infer the item-item relationship\nfrom user's historical interactions. With self-attention, it is able to\nestimate the relative weights of each item in user interaction trajectories to\nlearn better representations for user's transient interests. The model is\nfinally trained in a metric learning framework, taking both short-term and\nlong-term intentions into consideration. Experiments on a wide range of\ndatasets on different domains demonstrate that our approach outperforms the\nstate-of-the-art by a wide margin.", "published": "2018-08-20T12:21:23Z", "version": 2}, {"aid": "1808.06934", "authors": ["Alessandro Betti", "Marco Gori", "Giuseppe Marra"], "title": "Backpropagation and Biological Plausibility", "url": "http://arxiv.org/pdf/1808.06934v1", "summary": "By and large, Backpropagation (BP) is regarded as one of the most important\nneural computation algorithms at the basis of the progress in machine learning,\nincluding the recent advances in deep learning. However, its computational\nstructure has been the source of many debates on its arguable biological\nplausibility. In this paper, it is shown that when framing supervised learning\nin the Lagrangian framework, while one can see a natural emergence of\nBackpropagation, biologically plausible local algorithms can also be devised\nthat are based on the search for saddle points in the learning adjoint space\ncomposed of weights, neural outputs, and Lagrangian multipliers. This might\nopen the doors to a truly novel class of learning algorithms where, because of\nthe introduction of the notion of support neurons, the optimization scheme also\nplays a fundamental role in the construction of the architecture.", "published": "2018-08-21T14:41:56Z", "version": 1}, {"aid": "1808.07804", "authors": ["S\u00f6ren R. K\u00fcnzel", "Bradly C. Stadie", "Nikita Vemuri", "Varsha Ramakrishnan", "Jasjeet S. Sekhon", "Pieter Abbeel"], "title": "Transfer Learning for Estimating Causal Effects using Neural Networks", "url": "http://arxiv.org/pdf/1808.07804v1", "summary": "We develop new algorithms for estimating heterogeneous treatment effects,\ncombining recent developments in transfer learning for neural networks with\ninsights from the causal inference literature. By taking advantage of transfer\nlearning, we are able to efficiently use different data sources that are\nrelated to the same underlying causal mechanisms. We compare our algorithms\nwith those in the extant literature using extensive simulation studies based on\nlarge-scale voter persuasion experiments and the MNIST database. Our methods\ncan perform an order of magnitude better than existing benchmarks while using a\nfraction of the data.", "published": "2018-08-23T15:27:14Z", "version": 1}, {"aid": "1809.00960", "authors": ["Yueyue Wang", "Liang Zhao", "Zhijian Song", "Manning Wang"], "title": "Organ at Risk Segmentation in Head and Neck CT Images by Using a Two-Stage Segmentation Framework Based on 3D U-Net", "url": "http://arxiv.org/pdf/1809.00960v2", "summary": "Accurate segmentation of organ at risk (OAR) play a critical role in the\ntreatment planning of image guided radiation treatment of head and neck cancer.\nThis segmentation task is challenging for both human and automatic algorithms\nbecause of the relatively large number of OARs to be segmented, the large\nvariability of the size and morphology across different OARs, and the low\ncontrast of between some OARs and the background. In this paper, we proposed a\ntwo-stage segmentation framework based on 3D U-Net. In this framework, the\nsegmentation of each OAR is decomposed into two sub-tasks: locating a bounding\nbox of the OAR and segment it from a small volume within the bounding box, and\neach sub-tasks is fulfilled by a dedicated 3D U-Net. The decomposition makes\neach of the two sub-tasks much easier, so that they can be better completed. We\nevaluated the proposed method and compared it to state-of-the-art methods by\nusing the MICCAI 2015 Challenge dataset. In terms of the boundary-based metric\n95HD, the proposed method ranked first in eight of all nine OARs and ranked\nsecond in the other OAR. In terms of the area-based metric DSC, the proposed\nmethod ranked first in six of the nine OARs and ranked second in the other\nthree OARs with small difference with the first one.", "published": "2018-08-25T14:09:28Z", "version": 2}, {"aid": "1809.00961", "authors": ["Ram Krishna Pandey", "Nabagata Saha", "Samarjit Karmakar", "A G Ramakrishnan"], "title": "MSCE: An edge preserving robust loss function for improving super-resolution algorithms", "url": "http://arxiv.org/pdf/1809.00961v1", "summary": "With the recent advancement in the deep learning technologies such as CNNs\nand GANs, there is significant improvement in the quality of the images\nreconstructed by deep learning based super-resolution (SR) techniques. In this\nwork, we propose a robust loss function based on the preservation of edges\nobtained by the Canny operator. This loss function, when combined with the\nexisting loss function such as mean square error (MSE), gives better SR\nreconstruction measured in terms of PSNR and SSIM. Our proposed loss function\nguarantees improved performance on any existing algorithm using MSE loss\nfunction, without any increase in the computational complexity during testing.", "published": "2018-08-25T22:00:10Z", "version": 1}, {"aid": "1808.09062", "authors": ["Huayu Li"], "title": "Cognitive Consistency Routing Algorithm of Capsule-network", "url": "http://arxiv.org/pdf/1808.09062v3", "summary": "Artificial Neural Networks (ANNs) are computational models inspired by the\ncentral nervous system (especially the brain) of animals and are used to\nestimate or generate unknown approximation functions relied on large amounts of\ninputs. Capsule Neural Network (Sabour S, et al.[2017]) is a novel structure of\nConvolutional Neural Networks which simulates the visual processing system of\nhuman brain. In this paper, we introduce psychological theories which called\nCognitive Consistency to optimize the routing algorithm of Capsnet to make it\nmore close to the work pattern of human brain. It has been shown in the\nexperiment that a progress had been made compared with the baseline.", "published": "2018-08-27T23:26:08Z", "version": 3}, {"aid": "1809.00982", "authors": ["D. D. N. De Silva", "S. Fernando", "I. T. S. Piyatilake", "A. V. S. Karunarathne"], "title": "Wavelet based edge feature enhancement for convolutional neural networks", "url": "http://arxiv.org/pdf/1809.00982v2", "summary": "Convolutional neural networks are able to perform a hierarchical learning\nprocess starting with local features. However, a limited attention is paid to\nenhancing such elementary level features like edges. We propose and evaluate\ntwo wavelet-based edge feature enhancement methods to preprocess the input\nimages to convolutional neural networks. The first method develops feature\nenhanced representations by decomposing the input images using wavelet\ntransform and limited reconstructing subsequently. The second method develops\nsuch feature enhanced inputs to the network using local modulus maxima of\nwavelet coefficients. For each method, we have developed a new preprocessing\nlayer by implementing each purposed method and have appended to the network\narchitecture. Our empirical evaluations demonstrate that the proposed methods\nare outperforming the baselines and previously published work with significant\naccuracy gains.", "published": "2018-08-29T06:13:01Z", "version": 2}, {"aid": "1808.10631", "authors": ["Olga Krestinskaya", "Khaled Nabil Salama", "Alex Pappachen James"], "title": "Learning in Memristive Neural Network Architectures using Analog Backpropagation Circuits", "url": "http://arxiv.org/pdf/1808.10631v1", "summary": "The on-chip implementation of learning algorithms would speed-up the training\nof neural networks in crossbar arrays. The circuit level design and\nimplementation of backpropagation algorithm using gradient descent operation\nfor neural network architectures is an open problem. In this paper, we proposed\nthe analog backpropagation learning circuits for various memristive learning\narchitectures, such as Deep Neural Network (DNN), Binary Neural Network (BNN),\nMultiple Neural Network (MNN), Hierarchical Temporal Memory (HTM) and\nLong-Short Term Memory (LSTM). The circuit design and verification is done\nusing TSMC 180nm CMOS process models, and TiO2 based memristor models. The\napplication level validations of the system are done using XOR problem, MNIST\ncharacter and Yale face image databases", "published": "2018-08-31T08:31:15Z", "version": 1}, {"aid": "1809.00193", "authors": ["Tianyang Wang", "Jun Huan", "Bo Li"], "title": "Data Dropout: Optimizing Training Data for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1809.00193v2", "summary": "Deep learning models learn to fit training data while they are highly\nexpected to generalize well to testing data. Most works aim at finding such\nmodels by creatively designing architectures and fine-tuning parameters. To\nadapt to particular tasks, hand-crafted information such as image prior has\nalso been incorporated into end-to-end learning. However, very little progress\nhas been made on investigating how an individual training sample will influence\nthe generalization ability of a model. In other words, to achieve high\ngeneralization accuracy, do we really need all the samples in a training\ndataset? In this paper, we demonstrate that deep learning models such as\nconvolutional neural networks may not favor all training samples, and\ngeneralization accuracy can be further improved by dropping those unfavorable\nsamples. Specifically, the influence of removing a training sample is\nquantifiable, and we propose a Two-Round Training approach, aiming to achieve\nhigher generalization accuracy. We locate unfavorable samples after the first\nround of training, and then retrain the model from scratch with the reduced\ntraining dataset in the second round. Since our approach is essentially\ndifferent from fine-tuning or further training, the computational cost should\nnot be a concern. Our extensive experimental results indicate that, with\nidentical settings, the proposed approach can boost performance of the\nwell-known networks on both high-level computer vision problems such as image\nclassification, and low-level vision problems such as image denoising.", "published": "2018-09-01T14:24:36Z", "version": 2}, {"aid": "1809.00219", "authors": ["Xintao Wang", "Ke Yu", "Shixiang Wu", "Jinjin Gu", "Yihao Liu", "Chao Dong", "Chen Change Loy", "Yu Qiao", "Xiaoou Tang"], "title": "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1809.00219v2", "summary": "The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work\nthat is capable of generating realistic textures during single image\nsuper-resolution. However, the hallucinated details are often accompanied with\nunpleasant artifacts. To further enhance the visual quality, we thoroughly\nstudy three key components of SRGAN - network architecture, adversarial loss\nand perceptual loss, and improve each of them to derive an Enhanced SRGAN\n(ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block\n(RRDB) without batch normalization as the basic network building unit.\nMoreover, we borrow the idea from relativistic GAN to let the discriminator\npredict relative realness instead of the absolute value. Finally, we improve\nthe perceptual loss by using the features before activation, which could\nprovide stronger supervision for brightness consistency and texture recovery.\nBenefiting from these improvements, the proposed ESRGAN achieves consistently\nbetter visual quality with more realistic and natural textures than SRGAN and\nwon the first place in the PIRM2018-SR Challenge. The code is available at\nhttps://github.com/xinntao/ESRGAN .", "published": "2018-09-01T16:21:03Z", "version": 2}, {"aid": "1809.00263", "authors": ["Qiangeng Xu", "Hanwang Zhang", "Weiyue Wang", "Peter N. Belhumeur", "Ulrich Neumann"], "title": "Stochastic Dynamics for Video Infilling", "url": "http://arxiv.org/pdf/1809.00263v5", "summary": "In this paper, we introduce a stochastic dynamics video infilling (SDVI)\nframework to generate frames between long intervals in a video. Our task\ndiffers from video interpolation which aims to produce transitional frames for\na short interval between every two frames and increase the temporal resolution.\nOur task, namely video infilling, however, aims to infill long intervals with\nplausible frame sequences. Our framework models the infilling as a constrained\nstochastic generation process and sequentially samples dynamics from the\ninferred distribution. SDVI consists of two parts: (1) a bi-directional\nconstraint propagation module to guarantee the spatial-temporal coherence among\nframes, (2) a stochastic sampling process to generate dynamics from the\ninferred distributions. Experimental results show that SDVI can generate clear\nframe sequences with varying contents. Moreover, motions in the generated\nsequence are realistic and able to transfer smoothly from the given start frame\nto the terminal frame. Our project site is\nhttps://xharlie.github.io/projects/project_sites/SDVI/video_results.html", "published": "2018-09-01T22:58:49Z", "version": 5}, {"aid": "1809.00564", "authors": ["Philippe Lemoisson", "Stefano A. Cerri"], "title": "ViewpointS: towards a Collective Brain", "url": "http://arxiv.org/pdf/1809.00564v1", "summary": "Tracing knowledge acquisition and linking learning events to interaction\nbetween peers is a major challenge of our times. We have conceived, designed\nand evaluated a new paradigm for constructing and using collective knowledge by\nWeb interactions that we called ViewpointS. By exploiting the similarity with\nEdelman's Theory of Neuronal Group Selection (TNGS), we conjecture that it may\nbe metaphorically considered a Collective Brain, especially effective in the\ncase of trans-disciplinary representations. Far from being without doubts, in\nthe paper we present the reasons (and the limits) of our proposal that aims to\nbecome a useful integrating tool for future quantitative explorations of\nindividual as well as collective learning at different degrees of granu-larity.\nWe are therefore challenging each of the current approaches: the logical one in\nthe semantic Web, the statistical one in mining and deep learning, the social\none in recommender systems based on authority and trust; not in each of their\nown preferred field of operation, rather in their integration weaknesses far\nfrom the holistic and dynamic behavior of the human brain.", "published": "2018-09-03T11:51:13Z", "version": 1}, {"aid": "1809.00832", "authors": ["Eunji Jeong", "Joo Seong Jeong", "Soojeong Kim", "Gyeong-In Yu", "Byung-Gon Chun"], "title": "Improving the Expressiveness of Deep Learning Frameworks with Recursion", "url": "http://arxiv.org/pdf/1809.00832v1", "summary": "Recursive neural networks have widely been used by researchers to handle\napplications with recursively or hierarchically structured data. However,\nembedded control flow deep learning frameworks such as TensorFlow, Theano,\nCaffe2, and MXNet fail to efficiently represent and execute such neural\nnetworks, due to lack of support for recursion. In this paper, we add recursion\nto the programming model of existing frameworks by complementing their design\nwith recursive execution of dataflow graphs as well as additional APIs for\nrecursive definitions. Unlike iterative implementations, which can only\nunderstand the topological index of each node in recursive data structures, our\nrecursive implementation is able to exploit the recursive relationships between\nnodes for efficient execution based on parallel computation. We present an\nimplementation on TensorFlow and evaluation results with various recursive\nneural network models, showing that our recursive implementation not only\nconveys the recursive nature of recursive neural networks better than other\nimplementations, but also uses given resources more effectively to reduce\ntraining and inference time.", "published": "2018-09-04T08:31:21Z", "version": 1}, {"aid": "1809.00837", "authors": ["Dan Dai", "Zhiwen Yu", "Yang Hu", "Wenming Cao", "Mingnan Luo"], "title": "Metabolize Neural Network", "url": "http://arxiv.org/pdf/1809.00837v1", "summary": "The metabolism of cells is the most basic and important part of human\nfunction. Neural networks in deep learning stem from neuronal activity. It is\nself-evident that the significance of metabolize neuronal network(MetaNet) in\nmodel construction. In this study, we explore neuronal metabolism for shallow\nnetwork from proliferation and autophagy two aspects. First, we propose\ndifferent neuron proliferate methods that constructive the selfgrowing network\nin metabolism cycle. Proliferate neurons alleviate resources wasting and\ninsufficient model learning problem when network initializes more or less\nparameters. Then combined with autophagy mechanism in the process of model self\nconstruction to ablate under-expressed neurons. The MetaNet can automatically\ndetermine the number of neurons during training, further, save more resource\nconsumption. We verify the performance of the proposed methods on datasets:\nMNIST, Fashion-MNIST and CIFAR-10.", "published": "2018-09-04T08:42:52Z", "version": 1}, {"aid": "1809.00846", "authors": ["Ping Luo", "Xinjiang Wang", "Wenqi Shao", "Zhanglin Peng"], "title": "Towards Understanding Regularization in Batch Normalization", "url": "http://arxiv.org/pdf/1809.00846v4", "summary": "Batch Normalization (BN) improves both convergence and generalization in\ntraining neural networks. This work understands these phenomena theoretically.\nWe analyze BN by using a basic block of neural networks, consisting of a kernel\nlayer, a BN layer, and a nonlinear activation function. This basic network\nhelps us understand the impacts of BN in three aspects. First, by viewing BN as\nan implicit regularizer, BN can be decomposed into population normalization\n(PN) and gamma decay as an explicit regularization. Second, learning dynamics\nof BN and the regularization show that training converged with large maximum\nand effective learning rate. Third, generalization of BN is explored by using\nstatistical mechanics. Experiments demonstrate that BN in convolutional neural\nnetworks share the same traits of regularization as the above analyses.", "published": "2018-09-04T09:01:10Z", "version": 4}, {"aid": "1809.00858", "authors": ["Anthony Hunter"], "title": "Non-monotonic Reasoning in Deductive Argumentation", "url": "http://arxiv.org/pdf/1809.00858v1", "summary": "Argumentation is a non-monotonic process. This reflects the fact that\nargumentation involves uncertain information, and so new information can cause\na change in the conclusions drawn. However, the base logic does not need to be\nnon-monotonic. Indeed, most proposals for structured argumentation use a\nmonotonic base logic (e.g. some form of modus ponens with a rule-based\nlanguage, or classical logic). Nonetheless, there are issues in capturing\ndefeasible reasoning in argumentation including choice of base logic and\nmodelling of defeasible knowledge. And there are insights and tools to be\nharnessed for research in non-monontonic logics. We consider some of these\nissues in this paper.", "published": "2018-09-04T09:29:37Z", "version": 1}, {"aid": "1809.00916", "authors": ["Yuhui Yuan", "Lang Huang", "Jianyuan Guo", "Chao Zhang", "Xilin Chen", "Jingdong Wang"], "title": "OCNet: Object Context Network for Scene Parsing", "url": "http://arxiv.org/pdf/1809.00916v4", "summary": "In this paper, we address the semantic segmentation task with a new context\naggregation scheme named \\emph{object context}, which focuses on enhancing the\nrole of object information. Motivated by the fact that the category of each\npixel is inherited from the object it belongs to, we define the object context\nfor each pixel as the set of pixels that belong to the same category as the\ngiven pixel in the image. We use a binary relation matrix to represent the\nrelationship between all pixels, where the value one indicates the two selected\npixels belong to the same category and zero otherwise.\n  We propose to use a dense relation matrix to serve as a surrogate for the\nbinary relation matrix. The dense relation matrix is capable to emphasize the\ncontribution of object information as the relation scores tend to be larger on\nthe object pixels than the other pixels. Considering that the dense relation\nmatrix estimation requires quadratic computation overhead and memory\nconsumption w.r.t. the input size, we propose an efficient interlaced sparse\nself-attention scheme to model the dense relations between any two of all\npixels via the combination of two sparse relation matrices.\n  To capture richer context information, we further combine our interlaced\nsparse self-attention scheme with the conventional multi-scale context schemes\nincluding pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid\npooling~\\citep{chen2018deeplab}. We empirically show the advantages of our\napproach with competitive performances on five challenging benchmarks\nincluding: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff", "published": "2018-09-04T12:22:10Z", "version": 4}, {"aid": "1809.01926", "authors": ["Alessio Burrello", "Kaspar Schindler", "Luca Benini", "Abbas Rahimi"], "title": "One-shot Learning for iEEG Seizure Detection Using End-to-end Binary Operations: Local Binary Patterns with Hyperdimensional Computing", "url": "http://arxiv.org/pdf/1809.01926v1", "summary": "This paper presents an efficient binarized algorithm for both learning and\nclassification of human epileptic seizures from intracranial\nelectroencephalography (iEEG). The algorithm combines local binary patterns\nwith brain-inspired hyperdimensional computing to enable end-to-end learning\nand inference with binary operations. The algorithm first transforms iEEG time\nseries from each electrode into local binary pattern codes. Then atomic\nhigh-dimensional binary vectors are used to construct composite representations\nof seizures across all electrodes. For the majority of our patients (10 out of\n16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot\nlearning) and perfectly generalizes on 27 further seizures. For other patients,\nthe algorithm requires three to six seizures for learning. Overall, our\nalgorithm surpasses the state-of-the-art methods for detecting 65 novel\nseizures with higher specificity and sensitivity, and lower memory footprint.", "published": "2018-09-06T11:39:12Z", "version": 1}, {"aid": "1809.02058", "authors": ["Chenshen Wu", "Luis Herranz", "Xialei Liu", "Yaxing Wang", "Joost van de Weijer", "Bogdan Raducanu"], "title": "Memory Replay GANs: learning to generate images from new categories without forgetting", "url": "http://arxiv.org/pdf/1809.02058v3", "summary": "Previous works on sequential learning address the problem of forgetting in\ndiscriminative models. In this paper we consider the case of generative models.\nIn particular, we investigate generative adversarial networks (GANs) in the\ntask of learning new categories in a sequential fashion. We first show that\nsequential fine tuning renders the network unable to properly generate images\nfrom previous categories (i.e. forgetting). Addressing this problem, we propose\nMemory Replay GANs (MeRGANs), a conditional GAN framework that integrates a\nmemory replay generator. We study two methods to prevent forgetting by\nleveraging these replays, namely joint training with replay and replay\nalignment. Qualitative and quantitative experimental results in MNIST, SVHN and\nLSUN datasets show that our memory replay approach can generate competitive\nimages while significantly mitigating the forgetting of previous categories.", "published": "2018-09-06T15:45:36Z", "version": 3}, {"aid": "1809.02145", "authors": ["Alexia Jolicoeur-Martineau"], "title": "GANs beyond divergence minimization", "url": "http://arxiv.org/pdf/1809.02145v1", "summary": "Generative adversarial networks (GANs) can be interpreted as an adversarial\ngame between two players, a discriminator D and a generator G, in which D\nlearns to classify real from fake data and G learns to generate realistic data\nby \"fooling\" D into thinking that fake data is actually real data. Currently, a\ndominating view is that G actually learns by minimizing a divergence given that\nthe general objective function is a divergence when D is optimal. However, this\nview has been challenged due to inconsistencies between theory and practice. In\nthis paper, we discuss of the properties associated with most loss functions\nfor G (e.g., saturating/non-saturating f-GAN, LSGAN, WGAN, etc.). We show that\nthese loss functions are not divergences and do not have the same equilibrium\nas expected of divergences. This suggests that G does not need to minimize the\nsame objective function as D maximize, nor maximize the objective of D after\nswapping real data with fake data (non-saturating GAN) but can instead use a\nwide range of possible loss functions to learn to generate realistic data. We\ndefine GANs through two separate and independent D maximization and G\nminimization steps. We generalize the generator step to four new classes of\nloss functions, most of which are actual divergences (while traditional G loss\nfunctions are not). We test a wide variety of loss functions from these four\nclasses on a synthetic dataset and on CIFAR-10. We observe that most loss\nfunctions converge well and provide comparable data generation quality to\nnon-saturating GAN, LSGAN, and WGAN-GP generator loss functions, whether we use\ndivergences or non-divergences. These results suggest that GANs do not conform\nwell to the divergence minimization theory and form a much broader range of\nmodels than previously assumed.", "published": "2018-09-06T18:00:26Z", "version": 1}, {"aid": "1809.02193", "authors": ["Andres Campero", "Aldo Pareja", "Tim Klinger", "Josh Tenenbaum", "Sebastian Riedel"], "title": "Logical Rule Induction and Theory Learning Using Neural Theorem Proving", "url": "http://arxiv.org/pdf/1809.02193v3", "summary": "A hallmark of human cognition is the ability to continually acquire and\ndistill observations of the world into meaningful, predictive theories. In this\npaper we present a new mechanism for logical theory acquisition which takes a\nset of observed facts and learns to extract from them a set of logical rules\nand a small set of core facts which together entail the observations. Our\napproach is neuro-symbolic in the sense that the rule pred- icates and core\nfacts are given dense vector representations. The rules are applied to the core\nfacts using a soft unification procedure to infer additional facts. After k\nsteps of forward inference, the consequences are compared to the initial\nobservations and the rules and core facts are then encouraged towards\nrepresentations that more faithfully generate the observations through\ninference. Our approach is based on a novel neural forward-chaining\ndifferentiable rule induction network. The rules are interpretable and learned\ncompositionally from their predicates, which may be invented. We demonstrate\nthe efficacy of our approach on a variety of ILP rule induction and domain\ntheory learning datasets.", "published": "2018-09-06T19:49:20Z", "version": 3}, {"aid": "1809.02260", "authors": ["Brian Shay", "Patrick Brazil"], "title": "The Force of Proof by Which Any Argument Prevails", "url": "http://arxiv.org/pdf/1809.02260v1", "summary": "Jakob Bernoulli, working in the late 17th century, identified a gap in\ncontemporary probability theory. He cautioned that it was inadequate to specify\nforce of proof (probability of provability) for some kinds of uncertain\narguments. After 300 years, this gap remains in present-day probability theory.\nWe present axioms analogous to Kolmogorov's axioms for probability, specifying\nuncertainty that lies in an argument's inference/implication itself rather than\nin its premise and conclusion. The axioms focus on arguments spanning two\nBoolean algebras, but generalize the obligatory: \"force of proof of A implies B\nis the probability of B or not A\" in the case that the Boolean algebras are\nidentical. We propose a categorical framework that relies on generalized\nprobabilities (objects) to express uncertainty in premises, to mix with\narguments (morphisms) to express uncertainty embedded directly in\ninference/implication. There is a direct application to Shafer's evidence\ntheory (Dempster-Shafer theory), greatly expanding its scope for applications.\nTherefore, we can offer this framework not only as an optimal solution to a\ndifficult historical puzzle, but also to advance the frontiers of contemporary\nartificial intelligence.\n  Keywords: force of proof, probability of provability, Ars Conjectandi, non\nadditive probabilities, evidence theory.", "published": "2018-09-07T00:24:29Z", "version": 1}, {"aid": "1809.02441", "authors": ["Jangho Kim", "Jeesoo Kim", "Nojun Kwak"], "title": "StackNet: Stacking Parameters for Continual learning", "url": "http://arxiv.org/pdf/1809.02441v3", "summary": "Training a neural network for a classification task typically assumes that\nthe data to train are given from the beginning. However, in the real world,\nadditional data accumulate gradually and the model requires additional training\nwithout accessing the old training data. This usually leads to the catastrophic\nforgetting problem which is inevitable for the traditional training methodology\nof neural networks. In this paper, we propose a continual learning method that\nis able to learn additional tasks while retaining the performance of previously\nlearned tasks by stacking parameters. Composed of two complementary components,\nthe index module and the StackNet, our method estimates the index of the\ncorresponding task for an input sample with the index module and utilizes a\nparticular portion of StackNet with this index. The StackNet guarantees no\ndegradation in the performance of the previously learned tasks and the index\nmodule shows high confidence in finding the origin of an input sample. Compared\nto the previous work of PackNet, our method is competitive and highly\nintuitive.", "published": "2018-09-07T12:39:13Z", "version": 3}, {"aid": "1809.02499", "authors": ["Hongyu Guo", "Yongyi Mao", "Richong Zhang"], "title": "MixUp as Locally Linear Out-Of-Manifold Regularization", "url": "http://arxiv.org/pdf/1809.02499v3", "summary": "MixUp is a recently proposed data-augmentation scheme, which linearly\ninterpolates a random pair of training examples and correspondingly the one-hot\nrepresentations of their labels. Training deep neural networks with such\nadditional data is shown capable of significantly improving the predictive\naccuracy of the current art. The power of MixUp, however, is primarily\nestablished empirically and its working and effectiveness have not been\nexplained in any depth. In this paper, we develop an understanding for MixUp as\na form of \"out-of-manifold regularization\", which imposes certain \"local\nlinearity\" constraints on the model's input space beyond the data manifold.\nThis analysis enables us to identify a limitation of MixUp, which we call\n\"manifold intrusion\". In a nutshell, manifold intrusion in MixUp is a form of\nunder-fitting resulting from conflicts between the synthetic labels of the\nmixed-up examples and the labels of original training data. Such a phenomenon\nusually happens when the parameters controlling the generation of mixing\npolicies are not sufficiently fine-tuned on the training data. To address this\nissue, we propose a novel adaptive version of MixUp, where the mixing policies\nare automatically learned from the data using an additional network and\nobjective function designed to avoid manifold intrusion. The proposed\nregularizer, AdaMixUp, is empirically evaluated on several benchmark datasets.\nExtensive experiments demonstrate that AdaMixUp improves upon MixUp when\napplied to the current art of deep classification models.", "published": "2018-09-07T14:26:17Z", "version": 3}, {"aid": "1809.02601", "authors": ["Junran Peng", "Lingxi Xie", "Zhaoxiang Zhang", "Tieniu Tan", "Jingdong Wang"], "title": "Accelerating Deep Neural Networks with Spatial Bottleneck Modules", "url": "http://arxiv.org/pdf/1809.02601v1", "summary": "This paper presents an efficient module named spatial bottleneck for\naccelerating the convolutional layers in deep neural networks. The core idea is\nto decompose convolution into two stages, which first reduce the spatial\nresolution of the feature map, and then restore it to the desired size. This\noperation decreases the sampling density in the spatial domain, which is\nindependent yet complementary to network acceleration approaches in the channel\ndomain. Using different sampling rates, we can tradeoff between recognition\naccuracy and model complexity.\n  As a basic building block, spatial bottleneck can be used to replace any\nsingle convolutional layer, or the combination of two convolutional layers. We\nempirically verify the effectiveness of spatial bottleneck by applying it to\nthe deep residual networks. Spatial bottleneck achieves 2x and 1.4x speedup on\nthe regular and channel-bottlenecked residual blocks, respectively, with the\naccuracies retained in recognizing low-resolution images, and even improved in\nrecognizing high-resolution images.", "published": "2018-09-07T17:54:54Z", "version": 1}, {"aid": "1809.03783", "authors": ["Xiao-Yun Zhou", "Guang-Zhong Yang"], "title": "Normalization in Training U-Net for 2D Biomedical Semantic Segmentation", "url": "http://arxiv.org/pdf/1809.03783v3", "summary": "2D biomedical semantic segmentation is important for robotic vision in\nsurgery. Segmentation methods based on Deep Convolutional Neural Network (DCNN)\ncan out-perform conventional methods in terms of both accuracy and levels of\nautomation. One common issue in training a DCNN for biomedical semantic\nsegmentation is the internal covariate shift where the training of\nconvolutional kernels is encumbered by the distribution change of input\nfeatures, hence both the training speed and performance are decreased. Batch\nNormalization (BN) is the first proposed method for addressing internal\ncovariate shift and is widely used. Instance Normalization (IN) and Layer\nNormalization (LN) have also been proposed. Group Normalization (GN) is\nproposed more recently and has not yet been applied to 2D biomedical semantic\nsegmentation, however, no specific validations on GN were given. Most DCNNs for\nbiomedical semantic segmentation adopt BN as the normalization method by\ndefault, without reviewing its performance. In this paper, four normalization\nmethods - BN, IN, LN and GN are compared in details, specifically for 2D\nbiomedical semantic segmentation. U-Net is adopted as the basic DCNN structure.\nThree datasets regarding the Right Ventricle (RV), aorta, and Left Ventricle\n(LV) are used for the validation. The results show that detailed subdivision of\nthe feature map, i.e. GN with a large group number or IN, achieves higher\naccuracy. This accuracy improvement mainly comes from better model\ngeneralization. Codes are uploaded and maintained at Xiao-Yun Zhou's Github.", "published": "2018-09-11T10:27:45Z", "version": 3}, {"aid": "1809.04356", "authors": ["Hassan Ismail Fawaz", "Germain Forestier", "Jonathan Weber", "Lhassane Idoumghar", "Pierre-Alain Muller"], "title": "Deep learning for time series classification: a review", "url": "http://arxiv.org/pdf/1809.04356v4", "summary": "Time Series Classification (TSC) is an important and challenging problem in\ndata mining. With the increase of time series data availability, hundreds of\nTSC algorithms have been proposed. Among these methods, only a few have\nconsidered Deep Neural Networks (DNNs) to perform this task. This is surprising\nas deep learning has seen very successful applications in the last years. DNNs\nhave indeed revolutionized the field of computer vision especially with the\nadvent of novel deeper architectures such as Residual and Convolutional Neural\nNetworks. Apart from images, sequential data such as text and audio can also be\nprocessed with DNNs to reach state-of-the-art performance for document\nclassification and speech recognition. In this article, we study the current\nstate-of-the-art performance of deep learning algorithms for TSC by presenting\nan empirical study of the most recent DNN architectures for TSC. We give an\noverview of the most successful deep learning applications in various time\nseries domains under a unified taxonomy of DNNs for TSC. We also provide an\nopen source deep learning framework to the TSC community where we implemented\neach of the compared approaches and evaluated them on a univariate TSC\nbenchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By\ntraining 8,730 deep learning models on 97 time series datasets, we propose the\nmost exhaustive study of DNNs for TSC to date.", "published": "2018-09-12T10:55:33Z", "version": 4}, {"aid": "1809.04508", "authors": ["Zhisheng Zhong", "Tiancheng Shen", "Yibo Yang", "Zhouchen Lin", "Chao Zhang"], "title": "Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution", "url": "http://arxiv.org/pdf/1809.04508v3", "summary": "Convolutional neural networks (CNNs) have recently achieved great success in\nsingle-image super-resolution (SISR). However, these methods tend to produce\nover-smoothed outputs and miss some textural details. To solve these problems,\nwe propose the Super-Resolution CliqueNet (SRCliqueNet) to reconstruct the high\nresolution (HR) image with better textural details in the wavelet domain. The\nproposed SRCliqueNet firstly extracts a set of feature maps from the low\nresolution (LR) image by the clique blocks group. Then we send the set of\nfeature maps to the clique up-sampling module to reconstruct the HR image. The\nclique up-sampling module consists of four sub-nets which predict the high\nresolution wavelet coefficients of four sub-bands. Since we consider the edge\nfeature properties of four sub-bands, the four sub-nets are connected to the\nothers so that they can learn the coefficients of four sub-bands jointly.\nFinally we apply inverse discrete wavelet transform (IDWT) to the output of\nfour sub-nets at the end of the clique up-sampling module to increase the\nresolution and reconstruct the HR image. Extensive quantitative and qualitative\nexperiments on benchmark datasets show that our method achieves superior\nperformance over the state-of-the-art methods.", "published": "2018-09-12T15:19:37Z", "version": 3}, {"aid": "1809.04673", "authors": ["Rishabh Iyer", "Nimit Acharya", "Tanuja Bompada", "Denis Charles", "Eren Manavoglu"], "title": "A Unified Batch Online Learning Framework for Click Prediction", "url": "http://arxiv.org/pdf/1809.04673v1", "summary": "We present a unified framework for Batch Online Learning (OL) for Click\nPrediction in Search Advertisement. Machine Learning models once deployed, show\nnon-trivial accuracy and calibration degradation over time due to model\nstaleness. It is therefore necessary to regularly update models, and do so\nautomatically. This paper presents two paradigms of Batch Online Learning, one\nwhich incrementally updates the model parameters via an early stopping\nmechanism, and another which does so through a proximal regularization. We\nargue how both these schemes naturally trade-off between old and new data. We\nthen theoretically and empirically show that these two seemingly different\nschemes are closely related. Through extensive experiments, we demonstrate the\nutility of of our OL framework; how the two OL schemes relate to each other and\nhow they trade-off between the new and historical data. We then compare batch\nOL to full model retrains, and show how online learning is more robust to data\nissues. We also demonstrate the long term impact of Online Learning, the role\nof the initial Models in OL, the impact of delays in the update, and finally\nconclude with some implementation details and challenges in deploying a real\nworld online learning system in production. While this paper mostly focuses on\napplication of click prediction for search advertisement, we hope that the\nlessons learned here can be carried over to other problem domains.", "published": "2018-09-12T21:01:55Z", "version": 1}, {"aid": "1809.04711", "authors": ["Galin Georgiev"], "title": "Linear Algebra and Duality of Neural Networks", "url": "http://arxiv.org/pdf/1809.04711v2", "summary": "Bases, mappings, projections and metrics, natural for Neural network\ntraining, are introduced. Graph-theoretical interpretation is offered.\nNon-Gaussianity naturally emerges, even in relatively simple datasets. Training\nstatistics, hierarchies and energies are analyzed, from physics point of view.\nDuality between observables (for example, pixels) and observations is\nestablished. Relationship between exact and numerical solutions is studied.\nPhysics and financial mathematics interpretations of a key problem are offered.\nExamples support all new concepts.", "published": "2018-09-12T23:39:18Z", "version": 2}, {"aid": "1809.04765", "authors": ["Shu Liang", "Xiufeng Huang", "Xianyu Meng", "Kunyao Chen", "Linda G. Shapiro", "Ira Kemelmacher-Shlizerman"], "title": "Video to Fully Automatic 3D Hair Model", "url": "http://arxiv.org/pdf/1809.04765v1", "summary": "Imagine taking a selfie video with your mobile phone and getting as output a\n3D model of your head (face and 3D hair strands) that can be later used in VR,\nAR, and any other domain. State of the art hair reconstruction methods allow\neither a single photo (thus compromising 3D quality) or multiple views, but\nthey require manual user interaction (manual hair segmentation and capture of\nfixed camera views that span full 360 degree). In this paper, we describe a\nsystem that can completely automatically create a reconstruction from any video\n(even a selfie video), and we don't require specific views, since taking your\n-90 degree, 90 degree, and full back views is not feasible in a selfie capture.\n  In the core of our system, in addition to the automatization components, hair\nstrands are estimated and deformed in 3D (rather than 2D as in state of the\nart) thus enabling superior results. We provide qualitative, quantitative, and\nMechanical Turk human studies that support the proposed system, and show\nresults on a diverse variety of videos (8 different celebrity videos, 9 selfie\nmobile videos, spanning age, gender, hair length, type, and styling).", "published": "2018-09-13T04:14:53Z", "version": 1}, {"aid": "1809.05127", "authors": ["Khushmeen Sakloth", "Wesley Beckner", "Jim Pfaendtner", "Garrett B. Goh"], "title": "IL-Net: Using Expert Knowledge to Guide the Design of Furcated Neural Networks", "url": "http://arxiv.org/pdf/1809.05127v1", "summary": "Deep neural networks (DNN) excel at extracting patterns. Through\nrepresentation learning and automated feature engineering on large datasets,\nsuch models have been highly successful in computer vision and natural language\napplications. Designing optimal network architectures from a principled or\nrational approach however has been less than successful, with the best\nsuccessful approaches utilizing an additional machine learning algorithm to\ntune the network hyperparameters. However, in many technical fields, there\nexist established domain knowledge and understanding about the subject matter.\nIn this work, we develop a novel furcated neural network architecture that\nutilizes domain knowledge as high-level design principles of the network. We\ndemonstrate proof-of-concept by developing IL-Net, a furcated network for\npredicting the properties of ionic liquids, which is a class of complex\nmulti-chemicals entities. Compared to existing state-of-the-art approaches, we\nshow that furcated networks can improve model accuracy by approximately 20-35%,\nwithout using additional labeled data. Lastly, we distill two key design\nprinciples for furcated networks that can be adapted to other domains.", "published": "2018-09-13T18:22:04Z", "version": 1}, {"aid": "1809.05676", "authors": ["Prabhat Nagarajan", "Garrett Warnell", "Peter Stone"], "title": "Deterministic Implementations for Reproducibility in Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1809.05676v5", "summary": "While deep reinforcement learning (DRL) has led to numerous successes in\nrecent years, reproducing these successes can be extremely challenging. One\nreproducibility challenge particularly relevant to DRL is nondeterminism in the\ntraining process, which can substantially affect the results. Motivated by this\nchallenge, we study the positive impacts of deterministic implementations in\neliminating nondeterminism in training. To do so, we consider the particular\ncase of the deep Q-learning algorithm, for which we produce a deterministic\nimplementation by identifying and controlling all sources of nondeterminism in\nthe training process. One by one, we then allow individual sources of\nnondeterminism to affect our otherwise deterministic implementation, and\nmeasure the impact of each source on the variance in performance. We find that\nindividual sources of nondeterminism can substantially impact the performance\nof agent, illustrating the benefits of deterministic implementations. In\naddition, we also discuss the important role of deterministic implementations\nin achieving exact replicability of results.", "published": "2018-09-15T08:53:28Z", "version": 5}, {"aid": "1809.05910", "authors": ["Rana Hanocka", "Amir Hertz", "Noa Fish", "Raja Giryes", "Shachar Fleishman", "Daniel Cohen-Or"], "title": "MeshCNN: A Network with an Edge", "url": "http://arxiv.org/pdf/1809.05910v2", "summary": "Polygonal meshes provide an efficient representation for 3D shapes. They\nexplicitly capture both shape surface and topology, and leverage non-uniformity\nto represent large flat regions as well as sharp, intricate features. This\nnon-uniformity and irregularity, however, inhibits mesh analysis efforts using\nneural networks that combine convolution and pooling operations. In this paper,\nwe utilize the unique properties of the mesh for a direct analysis of 3D shapes\nusing MeshCNN, a convolutional neural network designed specifically for\ntriangular meshes. Analogous to classic CNNs, MeshCNN combines specialized\nconvolution and pooling layers that operate on the mesh edges, by leveraging\ntheir intrinsic geodesic connections. Convolutions are applied on edges and the\nfour edges of their incident triangles, and pooling is applied via an edge\ncollapse operation that retains surface topology, thereby, generating new mesh\nconnectivity for the subsequent convolutions. MeshCNN learns which edges to\ncollapse, thus forming a task-driven process where the network exposes and\nexpands the important features while discarding the redundant ones. We\ndemonstrate the effectiveness of our task-driven pooling on various learning\ntasks applied to 3D meshes.", "published": "2018-09-16T16:32:29Z", "version": 2}, {"aid": "1809.06367", "authors": ["Edouard Oyallon", "Sergey Zagoruyko", "Gabriel Huang", "Nikos Komodakis", "Simon Lacoste-Julien", "Matthew Blaschko", "Eugene Belilovsky"], "title": "Scattering Networks for Hybrid Representation Learning", "url": "http://arxiv.org/pdf/1809.06367v1", "summary": "Scattering networks are a class of designed Convolutional Neural Networks\n(CNNs) with fixed weights. We argue they can serve as generic representations\nfor modelling images. In particular, by working in scattering space, we achieve\ncompetitive results both for supervised and unsupervised learning tasks, while\nmaking progress towards constructing more interpretable CNNs. For supervised\nlearning, we demonstrate that the early layers of CNNs do not necessarily need\nto be learned, and can be replaced with a scattering network instead. Indeed,\nusing hybrid architectures, we achieve the best results with predefined\nrepresentations to-date, while being competitive with end-to-end learned CNNs.\nSpecifically, even applying a shallow cascade of small-windowed scattering\ncoefficients followed by 1$\\times$1-convolutions results in AlexNet accuracy on\nthe ILSVRC2012 classification task. Moreover, by combining scattering networks\nwith deep residual networks, we achieve a single-crop top-5 error of 11.4% on\nILSVRC2012. Also, we show they can yield excellent performance in the small\nsample regime on CIFAR-10 and STL-10 datasets, exceeding their end-to-end\ncounterparts, through their ability to incorporate geometrical priors. For\nunsupervised learning, scattering coefficients can be a competitive\nrepresentation that permits image recovery. We use this fact to train hybrid\nGANs to generate images. Finally, we empirically analyze several properties\nrelated to stability and reconstruction of images from scattering coefficients.", "published": "2018-09-17T06:27:40Z", "version": 1}, {"aid": "1809.06205", "authors": ["Aristotelis Charalampous", "Sotirios Chatzis"], "title": "Quantum Statistics-Inspired Neural Attention", "url": "http://arxiv.org/pdf/1809.06205v2", "summary": "Sequence-to-sequence (encoder-decoder) models with attention constitute a\ncornerstone of deep learning research, as they have enabled unprecedented\nsequential data modeling capabilities. This effectiveness largely stems from\nthe capacity of these models to infer salient temporal dynamics over long\nhorizons; these are encoded into the obtained neural attention (NA)\ndistributions. However, existing NA formulations essentially constitute\npoint-wise selection mechanisms over the observed source sequences; that is,\nattention weights computation relies on the assumption that each source\nsequence element is independent of the rest. Unfortunately, although\nconvenient, this assumption fails to account for higher-order dependencies\nwhich might be prevalent in real-world data. This paper addresses these\nlimitations by leveraging Quantum-Statistical modeling arguments. Specifically,\nour work broadens the notion of NA, by attempting to account for the case that\nthe NA model becomes inherently incapable of discerning between individual\nsource elements; this is assumed to be the case due to higher-order temporal\ndynamics. On the contrary, we postulate that in some cases selection may be\nfeasible only at the level of pairs of source sequence elements. To this end,\nwe cast NA into inference of an attention density matrix (ADM) approximation.\nWe derive effective training and inference algorithms, and evaluate our\napproach in the context of a machine translation (MT) application. We perform\nexperiments with challenging benchmark datasets. As we show, our approach\nyields favorable outcomes in terms of several evaluation metrics.", "published": "2018-09-17T13:58:13Z", "version": 2}, {"aid": "1809.07009", "authors": ["Yuchi Huo", "Sung-Eui Yoon"], "title": "Light Field Neural Network", "url": "http://arxiv.org/pdf/1809.07009v2", "summary": "We introduce an optical neural network system made by off-the-shelf\ncomponents. In order to test the evaluate the physical property of the proposed\nsystem, we are making a prototype. After further discussions with our\ncooperators, we are agreed that the prototype implementation may take longer\ntime than we expected earlier. Therefore we reach a consensus on withdrawing\nthe paper until the physical data is available.", "published": "2018-09-19T04:19:28Z", "version": 2}, {"aid": "1809.07217", "authors": ["M\u00e1rton V\u00e9ges", "Viktor Varga", "Andr\u00e1s L\u0151rincz"], "title": "3D Human Pose Estimation with Siamese Equivariant Embedding", "url": "http://arxiv.org/pdf/1809.07217v2", "summary": "In monocular 3D human pose estimation a common setup is to first detect 2D\npositions and then lift the detection into 3D coordinates. Many algorithms\nsuffer from overfitting to camera positions in the training set. We propose a\nsiamese architecture that learns a rotation equivariant hidden representation\nto reduce the need for data augmentation. Our method is evaluated on multiple\ndatabases with different base networks and shows a consistent improvement of\nerror metrics. It achieves state-of-the-art cross-camera error rate among\nalgorithms that use estimated 2D joint coordinates only.", "published": "2018-09-19T14:26:14Z", "version": 2}, {"aid": "1809.07435", "authors": ["Kristopher De Asis", "Brendan Bennett", "Richard S. Sutton"], "title": "Predicting Periodicity with Temporal Difference Learning", "url": "http://arxiv.org/pdf/1809.07435v1", "summary": "Temporal difference (TD) learning is an important approach in reinforcement\nlearning, as it combines ideas from dynamic programming and Monte Carlo methods\nin a way that allows for online and incremental model-free learning. A key idea\nof TD learning is that it is learning predictive knowledge about the\nenvironment in the form of value functions, from which it can derive its\nbehavior to address long-term sequential decision making problems. The agent's\nhorizon of interest, that is, how immediate or long-term a TD learning agent\npredicts into the future, is adjusted through a discount rate parameter. In\nthis paper, we introduce an alternative view on the discount rate, with insight\nfrom digital signal processing, to include complex-valued discounting. Our\nresults show that setting the discount rate to appropriately chosen complex\nnumbers allows for online and incremental estimation of the Discrete Fourier\nTransform (DFT) of a signal of interest with TD learning. We thereby extend the\ntypes of knowledge representable by value functions, which we show are\nparticularly useful for identifying periodic effects in the reward sequence.", "published": "2018-09-20T00:07:27Z", "version": 1}, {"aid": "1809.07656", "authors": ["A. N. Gorban", "V. A. Makarov", "I. Y. Tyukin"], "title": "The unreasonable effectiveness of small neural ensembles in high-dimensional brain", "url": "http://arxiv.org/pdf/1809.07656v2", "summary": "Despite the widely-spread consensus on the brain complexity, sprouts of the\nsingle neuron revolution emerged in neuroscience in the 1970s. They brought\nmany unexpected discoveries, including grandmother or concept cells and sparse\ncoding of information in the brain.\n  In machine learning for a long time, the famous curse of dimensionality\nseemed to be an unsolvable problem. Nevertheless, the idea of the blessing of\ndimensionality becomes gradually more and more popular. Ensembles of\nnon-interacting or weakly interacting simple units prove to be an effective\ntool for solving essentially multidimensional problems. This approach is\nespecially useful for one-shot (non-iterative) correction of errors in large\nlegacy artificial intelligence systems.\n  These simplicity revolutions in the era of complexity have deep fundamental\nreasons grounded in geometry of multidimensional data spaces. To explore and\nunderstand these reasons we revisit the background ideas of statistical\nphysics. In the course of the 20th century they were developed into the\nconcentration of measure theory. New stochastic separation theorems reveal the\nfine structure of the data clouds.\n  We review and analyse biological, physical, and mathematical problems at the\ncore of the fundamental question: how can high-dimensional brain organise\nreliable and fast learning in high-dimensional world of data by simple tools?\n  Two critical applications are reviewed to exemplify the approach: one-shot\ncorrection of errors in intellectual systems and emergence of static and\nassociative memories in ensembles of single neurons.", "published": "2018-09-20T14:53:11Z", "version": 2}, {"aid": "1809.07803", "authors": ["Axel Abels", "Diederik M. Roijers", "Tom Lenaerts", "Ann Now\u00e9", "Denis Steckelmacher"], "title": "Dynamic Weights in Multi-Objective Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1809.07803v2", "summary": "Many real-world decision problems are characterized by multiple conflicting\nobjectives which must be balanced based on their relative importance. In the\ndynamic weights setting the relative importance changes over time and\nspecialized algorithms that deal with such change, such as a tabular\nReinforcement Learning (RL) algorithm by Natarajan and Tadepalli (2005), are\nrequired. However, this earlier work is not feasible for RL settings that\nnecessitate the use of function approximators. We generalize across weight\nchanges and high-dimensional inputs by proposing a multi-objective Q-network\nwhose outputs are conditioned on the relative importance of objectives and we\nintroduce Diverse Experience Replay (DER) to counter the inherent\nnon-stationarity of the Dynamic Weights setting. We perform an extensive\nexperimental evaluation and compare our methods to adapted algorithms from Deep\nMulti-Task/Multi-Objective Reinforcement Learning and show that our proposed\nnetwork in combination with DER dominates these adapted algorithms across\nweight change scenarios and problem domains.", "published": "2018-09-20T18:52:15Z", "version": 2}, {"aid": "1810.08648", "authors": ["George Kyriakides", "Konstantinos Margaritis"], "title": "Towards automated neural design: An open source, distributed neural architecture research framework", "url": "http://arxiv.org/pdf/1810.08648v1", "summary": "NORD (Neural Operations Research & Development) is an open source distributed\ndeep learning architectural research framework, based on PyTorch, MPI and\nHorovod. It aims to make research of deep architectures easier for experts of\ndifferent domains, in order to accelerate the process of finding better\narchitectures, as well as study the best architectures generated for different\ndatasets. Although currently under heavy development, the framework aims to\nallow the easy implementation of different design and optimization method\nfamilies (optimization algorithms, meta-heuristics, reinforcement learning\netc.) as well as the fair comparison between them. Furthermore, due to the\ncomputational resources required in order to optimize and evaluate network\narchitectures, it leverage the use of distributed computing, while aiming to\nminimize the researcher's overhead required to implement it. Moreover, it\nstrives to make the creation of architectures more intuitive, by implementing\nnetwork descriptors, allowing to separately define the architecture's nodes and\nconnections. In this paper, we present the framework's current state of\ndevelopment, while presenting its basic concepts, providing simple examples as\nwell as their experimental results.", "published": "2018-09-20T20:31:45Z", "version": 1}, {"aid": "1809.08229", "authors": ["Rohit Pardasani", "Utkarsh Shreemali"], "title": "Image Denoising and Super-Resolution using Residual Learning of Deep Convolutional Network", "url": "http://arxiv.org/pdf/1809.08229v1", "summary": "Image super-resolution and denoising are two important tasks in image\nprocessing that can lead to improvement in image quality. Image\nsuper-resolution is the task of mapping a low resolution image to a high\nresolution image whereas denoising is the task of learning a clean image from a\nnoisy input. We propose and train a single deep learning network that we term\nas SuRDCNN (super-resolution and denoising convolutional neural network), to\nperform these two tasks simultaneously . Our model nearly replicates the\narchitecture of existing state-of-the-art deep learning models for\nsuper-resolution and denoising. We use the proven strategy of residual\nlearning, as supported by state-of-the-art networks in this domain. Our trained\nSuRDCNN is capable of super-resolving image in the presence of Gaussian noise,\nPoisson noise or any random combination of both of these noises.", "published": "2018-09-21T17:58:22Z", "version": 1}, {"aid": "1809.08458", "authors": ["Huasong Zhong", "Xianggen Liu", "Yihui He", "Yuchun Ma"], "title": "Shift-based Primitives for Efficient Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1809.08458v2", "summary": "We propose a collection of three shift-based primitives for building\nefficient compact CNN-based networks. These three primitives (channel shift,\naddress shift, shortcut shift) can reduce the inference time on GPU while\nmaintains the prediction accuracy. These shift-based primitives only moves the\npointer but avoids memory copy, thus very fast. For example, the channel shift\noperation is 12.7x faster compared to channel shuffle in ShuffleNet but\nachieves the same accuracy. The address shift and channel shift can be merged\ninto the point-wise group convolution and invokes only a single kernel call,\ntaking little time to perform spatial convolution and channel shift. Shortcut\nshift requires no time to realize residual connection through allocating space\nin advance. We blend these shift-based primitives with point-wise group\nconvolution and built two inference-efficient CNN architectures named\nAddressNet and Enhanced AddressNet. Experiments on CIFAR100 and ImageNet\ndatasets show that our models are faster and achieve comparable or better\naccuracy.", "published": "2018-09-22T17:43:28Z", "version": 2}, {"aid": "1809.08590", "authors": ["Kaiyu Chen", "Yihan Dong", "Xipeng Qiu", "Zitian Chen"], "title": "Neural Arithmetic Expression Calculator", "url": "http://arxiv.org/pdf/1809.08590v1", "summary": "This paper presents a pure neural solver for arithmetic expression\ncalculation (AEC) problem. Previous work utilizes the powerful capabilities of\ndeep neural networks and attempts to build an end-to-end model to solve this\nproblem. However, most of these methods can only deal with the additive\noperations. It is still a challenging problem to solve the complex expression\ncalculation problem, which includes the adding, subtracting, multiplying,\ndividing and bracketing operations. In this work, we regard the arithmetic\nexpression calculation as a hierarchical reinforcement learning problem. An\narithmetic operation is decomposed into a series of sub-tasks, and each\nsub-task is dealt with by a skill module. The skill module could be a basic\nmodule performing elementary operations, or interactive module performing\ncomplex operations by invoking other skill models. With curriculum learning,\nour model can deal with a complex arithmetic expression calculation with the\ndeep hierarchical structure of skill models. Experiments show that our model\nsignificantly outperforms the previous models for arithmetic expression\ncalculation.", "published": "2018-09-23T13:05:28Z", "version": 1}, {"aid": "1809.09645", "authors": ["Kyongsik Yun", "Alexander Huyen", "Thomas Lu"], "title": "Deep Neural Networks for Pattern Recognition", "url": "http://arxiv.org/pdf/1809.09645v1", "summary": "In the field of pattern recognition research, the method of using deep neural\nnetworks based on improved computing hardware recently attracted attention\nbecause of their superior accuracy compared to conventional methods. Deep\nneural networks simulate the human visual system and achieve human equivalent\naccuracy in image classification, object detection, and segmentation. This\nchapter introduces the basic structure of deep neural networks that simulate\nhuman neural networks. Then we identify the operational processes and\napplications of conditional generative adversarial networks, which are being\nactively researched based on the bottom-up and top-down mechanisms, the most\nimportant functions of the human visual perception process. Finally, recent\ndevelopments in training strategies for effective learning of complex deep\nneural networks are addressed.", "published": "2018-09-25T18:23:49Z", "version": 1}, {"aid": "1809.10635", "authors": ["Gido M. van de Ven", "Andreas S. Tolias"], "title": "Generative replay with feedback connections as a general strategy for continual learning", "url": "http://arxiv.org/pdf/1809.10635v2", "summary": "A major obstacle to developing artificial intelligence applications capable\nof true lifelong learning is that artificial neural networks quickly or\ncatastrophically forget previously learned tasks when trained on a new one.\nNumerous methods for alleviating catastrophic forgetting are currently being\nproposed, but differences in evaluation protocols make it difficult to directly\ncompare their performance. To enable more meaningful comparisons, here we\nidentified three distinct scenarios for continual learning based on whether\ntask identity is known and, if it is not, whether it needs to be inferred.\nPerforming the split and permuted MNIST task protocols according to each of\nthese scenarios, we found that regularization-based approaches (e.g., elastic\nweight consolidation) failed when task identity needed to be inferred. In\ncontrast, generative replay combined with distillation (i.e., using class\nprobabilities as \"soft targets\") achieved superior performance in all three\nscenarios. Addressing the issue of efficiency, we reduced the computational\ncost of generative replay by integrating the generative model into the main\nmodel by equipping it with generative feedback or backward connections. This\nReplay-through-Feedback approach substantially shortened training time with no\nor negligible loss in performance. We believe this to be an important first\nstep towards making the powerful technique of generative replay scalable to\nreal-world continual learning applications.", "published": "2018-09-27T16:55:58Z", "version": 2}, {"aid": "1809.11130", "authors": ["Yanting Hu", "Jie Li", "Yuanfei Huang", "Xinbo Gao"], "title": "Channel-wise and Spatial Feature Modulation Network for Single Image Super-Resolution", "url": "http://arxiv.org/pdf/1809.11130v1", "summary": "The performance of single image super-resolution has achieved significant\nimprovement by utilizing deep convolutional neural networks (CNNs). The\nfeatures in deep CNN contain different types of information which make\ndifferent contributions to image reconstruction. However, most CNN-based models\nlack discriminative ability for different types of information and deal with\nthem equally, which results in the representational capacity of the models\nbeing limited. On the other hand, as the depth of neural networks grows, the\nlong-term information coming from preceding layers is easy to be weaken or lost\nin late layers, which is adverse to super-resolving image. To capture more\ninformative features and maintain long-term information for image\nsuper-resolution, we propose a channel-wise and spatial feature modulation\n(CSFM) network in which a sequence of feature-modulation memory (FMM) modules\nis cascaded with a densely connected structure to transform low-resolution\nfeatures to high informative features. In each FMM module, we construct a set\nof channel-wise and spatial attention residual (CSAR) blocks and stack them in\na chain structure to dynamically modulate multi-level features in a\nglobal-and-local manner. This feature modulation strategy enables the high\ncontribution information to be enhanced and the redundant information to be\nsuppressed. Meanwhile, for long-term information persistence, a gated fusion\n(GF) node is attached at the end of the FMM module to adaptively fuse\nhierarchical features and distill more effective information via the dense skip\nconnections and the gating mechanism. Extensive quantitative and qualitative\nevaluations on benchmark datasets illustrate the superiority of our proposed\nmethod over the state-of-the-art methods.", "published": "2018-09-28T16:29:31Z", "version": 1}, {"aid": "1810.00091", "authors": ["Kun Wan", "Boyuan Feng", "Lingwei Xie", "Yufei Ding"], "title": "Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout", "url": "http://arxiv.org/pdf/1810.00091v1", "summary": "Recently convolutional neural networks (CNNs) achieve great accuracy in\nvisual recognition tasks. DenseNet becomes one of the most popular CNN models\ndue to its effectiveness in feature-reuse. However, like other CNN models,\nDenseNets also face overfitting problem if not severer. Existing dropout method\ncan be applied but not as effective due to the introduced nonlinear\nconnections. In particular, the property of feature-reuse in DenseNet will be\nimpeded, and the dropout effect will be weakened by the spatial correlation\ninside feature maps. To address these problems, we craft the design of a\nspecialized dropout method from three aspects, dropout location, dropout\ngranularity, and dropout probability. The insights attained here could\npotentially be applied as a general approach for boosting the accuracy of other\nCNN models with similar nonlinear connections. Experimental results show that\nDenseNets with our specialized dropout method yield better accuracy compared to\nvanilla DenseNet and state-of-the-art CNN models, and such accuracy boost\nincreases with the model depth.", "published": "2018-09-28T21:42:38Z", "version": 1}, {"aid": "1810.00123", "authors": ["Jesse Farebrother", "Marlos C. Machado", "Michael Bowling"], "title": "Generalization and Regularization in DQN", "url": "http://arxiv.org/pdf/1810.00123v3", "summary": "Deep reinforcement learning algorithms have shown an impressive ability to\nlearn complex control policies in high-dimensional tasks. However, despite the\never-increasing performance on popular benchmarks, policies learned by deep\nreinforcement learning algorithms can struggle to generalize when evaluated in\nremarkably similar environments. In this paper we propose a protocol to\nevaluate generalization in reinforcement learning through different modes of\nAtari 2600 games. With that protocol we assess the generalization capabilities\nof DQN, one of the most traditional deep reinforcement learning algorithms, and\nwe provide evidence suggesting that DQN overspecializes to the training\nenvironment. We then comprehensively evaluate the impact of dropout and\n$\\ell_2$ regularization, as well as the impact of reusing learned\nrepresentations to improve the generalization capabilities of DQN. Despite\nregularization being largely underutilized in deep reinforcement learning, we\nshow that it can, in fact, help DQN learn more general features. These features\ncan be reused and fine-tuned on similar tasks, considerably improving DQN's\nsample efficiency.", "published": "2018-09-29T00:52:34Z", "version": 3}, {"aid": "1810.01256", "authors": ["Guanxiong Zeng", "Yang Chen", "Bo Cui", "Shan Yu"], "title": "Continual Learning of Context-dependent Processing in Neural Networks", "url": "http://arxiv.org/pdf/1810.01256v3", "summary": "Deep neural networks (DNNs) are powerful tools in learning sophisticated but\nfixed mapping rules between inputs and outputs, thereby limiting their\napplication in more complex and dynamic situations in which the mapping rules\nare not kept the same but changing according to different contexts. To lift\nsuch limits, we developed a novel approach involving a learning algorithm,\ncalled orthogonal weights modification (OWM), with the addition of a\ncontext-dependent processing (CDP) module. We demonstrated that with OWM to\novercome the problem of catastrophic forgetting, and the CDP module to learn\nhow to reuse a feature representation and a classifier for different contexts,\na single network can acquire numerous context-dependent mapping rules in an\nonline and continual manner, with as few as $\\sim$10 samples to learn each.\nThis should enable highly compact systems to gradually learn myriad\nregularities of the real world and eventually behave appropriately within it.", "published": "2018-09-29T09:45:08Z", "version": 3}, {"aid": "1810.04511", "authors": ["Lili Meng", "Bo Zhao", "Bo Chang", "Gao Huang", "Wei Sun", "Frederich Tung", "Leonid Sigal"], "title": "Interpretable Spatio-temporal Attention for Video Action Recognition", "url": "http://arxiv.org/pdf/1810.04511v2", "summary": "Inspired by the observation that humans are able to process videos\nefficiently by only paying attention where and when it is needed, we propose an\ninterpretable and easy plug-in spatial-temporal attention mechanism for video\naction recognition. For spatial attention, we learn a saliency mask to allow\nthe model to focus on the most salient parts of the feature maps. For temporal\nattention, we employ a convolutional LSTM based attention mechanism to identify\nthe most relevant frames from an input video. Further, we propose a set of\nregularizers to ensure that our attention mechanism attends to coherent regions\nin space and time. Our model not only improves video action recognition\naccuracy, but also localizes discriminative regions both spatially and\ntemporally, despite being trained in a weakly-supervised manner with only\nclassification labels (no bounding box labels or time frame temporal labels).\nWe evaluate our approach on several public video action recognition datasets\nwith ablation studies. Furthermore, we quantitatively and qualitatively\nevaluate our model's ability to localize discriminative regions spatially and\ncritical frames temporally. Experimental results demonstrate the efficacy of\nour approach, showing superior or comparable accuracy with the state-of-the-art\nmethods while increasing model interpretability.", "published": "2018-10-01T04:23:35Z", "version": 2}, {"aid": "1810.00826", "authors": ["Keyulu Xu", "Weihua Hu", "Jure Leskovec", "Stefanie Jegelka"], "title": "How Powerful are Graph Neural Networks?", "url": "http://arxiv.org/pdf/1810.00826v3", "summary": "Graph Neural Networks (GNNs) are an effective framework for representation\nlearning of graphs. GNNs follow a neighborhood aggregation scheme, where the\nrepresentation vector of a node is computed by recursively aggregating and\ntransforming representation vectors of its neighboring nodes. Many GNN variants\nhave been proposed and have achieved state-of-the-art results on both node and\ngraph classification tasks. However, despite GNNs revolutionizing graph\nrepresentation learning, there is limited understanding of their\nrepresentational properties and limitations. Here, we present a theoretical\nframework for analyzing the expressive power of GNNs to capture different graph\nstructures. Our results characterize the discriminative power of popular GNN\nvariants, such as Graph Convolutional Networks and GraphSAGE, and show that\nthey cannot learn to distinguish certain simple graph structures. We then\ndevelop a simple architecture that is provably the most expressive among the\nclass of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism\ntest. We empirically validate our theoretical findings on a number of graph\nclassification benchmarks, and demonstrate that our model achieves\nstate-of-the-art performance.", "published": "2018-10-01T17:11:31Z", "version": 3}, {"aid": "1810.05723", "authors": ["Ron Banner", "Yury Nahshan", "Elad Hoffer", "Daniel Soudry"], "title": "Post-training 4-bit quantization of convolution networks for rapid-deployment", "url": "http://arxiv.org/pdf/1810.05723v3", "summary": "Convolutional neural networks require significant memory bandwidth and\nstorage for intermediate computations, apart from substantial computing\nresources. Neural network quantization has significant benefits in reducing the\namount of intermediate results, but it often requires the full datasets and\ntime-consuming fine tuning to recover the accuracy lost after quantization.\nThis paper introduces the first practical 4-bit post training quantization\napproach: it does not involve training the quantized model (fine-tuning), nor\nit requires the availability of the full dataset. We target the quantization of\nboth activations and weights and suggest three complementary methods for\nminimizing quantization error at the tensor level, two of whom obtain a\nclosed-form analytical solution. Combining these methods, our approach achieves\naccuracy that is just a few percents less the state-of-the-art baseline across\na wide range of convolutional models. The source code to replicate all\nexperiments is available on GitHub:\n\\url{https://github.com/submission2019/cnn-quantization}.", "published": "2018-10-02T15:10:44Z", "version": 3}, {"aid": "1810.01620", "authors": ["Wendi Xu", "Ming Zhang"], "title": "Towards WARSHIP: Combining Components of Brain-Inspired Computing of RSH for Image Super Resolution", "url": "http://arxiv.org/pdf/1810.01620v1", "summary": "Evolution of deep learning shows that some algorithmic tricks are more\ndurable , while others are not. To the best of our knowledge, we firstly\nsummarize 5 more durable and complete deep learning components for vision, that\nis, WARSHIP. Moreover, we give a biological overview of WARSHIP, emphasizing\nbrain-inspired computing of WARSHIP. As a step towards WARSHIP, our case study\nof image super resolution combines 3 components of RSH to deploy a CNN model of\nWARSHIP-XZNet, which performs a happy medium between speed and performance.", "published": "2018-10-03T08:10:03Z", "version": 1}, {"aid": "1810.01622", "authors": ["Wendi Xu", "Ming Zhang"], "title": "Theory of Generative Deep Learning : Probe Landscape of Empirical Error via Norm Based Capacity Control", "url": "http://arxiv.org/pdf/1810.01622v1", "summary": "Despite its remarkable empirical success as a highly competitive branch of\nartificial intelligence, deep learning is often blamed for its widely known low\ninterpretation and lack of firm and rigorous mathematical foundation. However,\nmost theoretical endeavor is devoted in discriminative deep learning case,\nwhose complementary part is generative deep learning. To the best of our\nknowledge, we firstly highlight landscape of empirical error in generative case\nto complete the full picture through exquisite design of image super resolution\nunder norm based capacity control. Our theoretical advance in interpretation of\nthe training dynamic is achieved from both mathematical and biological sides.", "published": "2018-10-03T08:10:51Z", "version": 1}, {"aid": "1810.01638", "authors": ["Huan Li", "Yibo Yang", "Dongmin Chen", "Zhouchen Lin"], "title": "Optimization Algorithm Inspired Deep Neural Network Structure Design", "url": "http://arxiv.org/pdf/1810.01638v1", "summary": "Deep neural networks have been one of the dominant machine learning\napproaches in recent years. Several new network structures are proposed and\nhave better performance than the traditional feedforward neural network\nstructure. Representative ones include the skip connection structure in ResNet\nand the dense connection structure in DenseNet. However, it still lacks a\nunified guidance for the neural network structure design. In this paper, we\npropose the hypothesis that the neural network structure design can be inspired\nby optimization algorithms and a faster optimization algorithm may lead to a\nbetter neural network structure. Specifically, we prove that the propagation in\nthe feedforward neural network with the same linear transformation in different\nlayers is equivalent to minimizing some function using the gradient descent\nalgorithm. Based on this observation, we replace the gradient descent algorithm\nwith the heavy ball algorithm and Nesterov's accelerated gradient descent\nalgorithm, which are faster and inspire us to design new and better network\nstructures. ResNet and DenseNet can be considered as two special cases of our\nframework. Numerical experiments on CIFAR-10, CIFAR-100 and ImageNet verify the\nadvantage of our optimization algorithm inspired structures over ResNet and\nDenseNet.", "published": "2018-10-03T08:59:41Z", "version": 1}, {"aid": "1810.01868", "authors": ["\u0141ukasz Maziarka", "Marek \u015amieja", "Aleksandra Nowak", "Jacek Tabor", "\u0141ukasz Struski", "Przemys\u0142aw Spurek"], "title": "Set Aggregation Network as a Trainable Pooling Layer", "url": "http://arxiv.org/pdf/1810.01868v3", "summary": "Global pooling, such as max- or sum-pooling, is one of the key ingredients in\ndeep neural networks used for processing images, texts, graphs and other types\nof structured data. Based on the recent DeepSets architecture proposed by\nZaheer et al. (NIPS 2017), we introduce a Set Aggregation Network (SAN) as an\nalternative global pooling layer. In contrast to typical pooling operators, SAN\nallows to embed a given set of features to a vector representation of arbitrary\nsize. We show that by adjusting the size of embedding, SAN is capable of\npreserving the whole information from the input. In experiments, we demonstrate\nthat replacing global pooling layer by SAN leads to the improvement of\nclassification accuracy. Moreover, it is less prone to overfitting and can be\nused as a regularizer.", "published": "2018-10-03T13:20:13Z", "version": 3}, {"aid": "1810.01829", "authors": ["Masayuki Tanaka"], "title": "Weighted Sigmoid Gate Unit for an Activation Function of Deep Neural Network", "url": "http://arxiv.org/pdf/1810.01829v1", "summary": "An activation function has crucial role in a deep neural network.\n  A simple rectified linear unit (ReLU) are widely used for the activation\nfunction.\n  In this paper, a weighted sigmoid gate unit (WiG) is proposed as the\nactivation function.\n  The proposed WiG consists of a multiplication of inputs and the weighted\nsigmoid gate.\n  It is shown that the WiG includes the ReLU and same activation functions as a\nspecial case.\n  Many activation functions have been proposed to overcome the performance of\nthe ReLU.\n  In the literature, the performance is mainly evaluated with an object\nrecognition task.\n  The proposed WiG is evaluated with the object recognition task and the image\nrestoration task.\n  Then, the expeirmental comparisons demonstrate the proposed WiG overcomes the\nexisting activation functions including the ReLU.", "published": "2018-10-03T16:26:24Z", "version": 1}, {"aid": "1810.01989", "authors": ["Weiming Xiang", "Patrick Musau", "Ayana A. Wild", "Diego Manzanas Lopez", "Nathaniel Hamilton", "Xiaodong Yang", "Joel Rosenfeld", "Taylor T. Johnson"], "title": "Verification for Machine Learning, Autonomy, and Neural Networks Survey", "url": "http://arxiv.org/pdf/1810.01989v1", "summary": "This survey presents an overview of verification techniques for autonomous\nsystems, with a focus on safety-critical autonomous cyber-physical systems\n(CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances\nin artificial intelligence (AI) and machine learning (ML) through approaches\nsuch as deep neural networks (DNNs), embedded in so-called learning enabled\ncomponents (LECs) that accomplish tasks from classification to control.\nRecently, the formal methods and formal verification community has developed\nmethods to characterize behaviors in these LECs with eventual goals of formally\nverifying specifications for LECs, and this article presents a survey of many\nof these recent approaches.", "published": "2018-10-03T22:12:05Z", "version": 1}, {"aid": "1810.02328", "authors": ["Gerald Friedland", "Alfredo Metere", "Mario Krell"], "title": "A Practical Approach to Sizing Neural Networks", "url": "http://arxiv.org/pdf/1810.02328v1", "summary": "Memorization is worst-case generalization. Based on MacKay's information\ntheoretic model of supervised machine learning, this article discusses how to\npractically estimate the maximum size of a neural network given a training data\nset. First, we present four easily applicable rules to analytically determine\nthe capacity of neural network architectures. This allows the comparison of the\nefficiency of different network architectures independently of a task. Second,\nwe introduce and experimentally validate a heuristic method to estimate the\nneural network capacity requirement for a given dataset and labeling. This\nallows an estimate of the required size of a neural network for a given\nproblem. We conclude the article with a discussion on the consequences of\nsizing the network wrongly, which includes both increased computation effort\nfor training as well as reduced generalization capability.", "published": "2018-10-04T17:20:39Z", "version": 1}, {"aid": "1810.02334", "authors": ["Kyle Hsu", "Sergey Levine", "Chelsea Finn"], "title": "Unsupervised Learning via Meta-Learning", "url": "http://arxiv.org/pdf/1810.02334v6", "summary": "A central goal of unsupervised learning is to acquire representations from\nunlabeled data or experience that can be used for more effective learning of\ndownstream tasks from modest amounts of labeled data. Many prior unsupervised\nlearning works aim to do so by developing proxy objectives based on\nreconstruction, disentanglement, prediction, and other metrics. Instead, we\ndevelop an unsupervised meta-learning method that explicitly optimizes for the\nability to learn a variety of tasks from small amounts of data. To do so, we\nconstruct tasks from unlabeled data in an automatic way and run meta-learning\nover the constructed tasks. Surprisingly, we find that, when integrated with\nmeta-learning, relatively simple task construction mechanisms, such as\nclustering embeddings, lead to good performance on a variety of downstream,\nhuman-specified tasks. Our experiments across four image datasets indicate that\nour unsupervised meta-learning approach acquires a learning algorithm without\nany labeled data that is applicable to a wide range of downstream\nclassification tasks, improving upon the embedding learned by four prior\nunsupervised learning methods.", "published": "2018-10-04T17:29:17Z", "version": 6}, {"aid": "1810.02440", "authors": ["Alessandro Achille", "Glen Mbeng", "Stefano Soatto"], "title": "Dynamics and Reachability of Learning Tasks", "url": "http://arxiv.org/pdf/1810.02440v2", "summary": "We compute the transition probability between two learning tasks, and show\nthat it decomposes into two factors. The first depends on the geometry of the\nloss landscape of a model trained on each task, independent of any particular\nmodel used. This is related to an information theoretic distance function, but\nis insufficient to predict success in transfer learning, as nearby tasks can be\nunreachable via fine-tuning. The second factor depends on the ease of\ntraversing the path between two tasks. With this dynamic component, we derive\nstrict lower bounds on the complexity necessary to learn a task starting from\nthe solution to another, which is one of the most common forms of transfer\nlearning.", "published": "2018-10-04T22:14:40Z", "version": 2}, {"aid": "1810.02513", "authors": ["Nataniel Ruiz", "Samuel Schulter", "Manmohan Chandraker"], "title": "Learning To Simulate", "url": "http://arxiv.org/pdf/1810.02513v2", "summary": "Simulation is a useful tool in situations where training data for machine\nlearning models is costly to annotate or even hard to acquire. In this work, we\npropose a reinforcement learning-based method for automatically adjusting the\nparameters of any (non-differentiable) simulator, thereby controlling the\ndistribution of synthesized data in order to maximize the accuracy of a model\ntrained on that data. In contrast to prior art that hand-crafts these\nsimulation parameters or adjusts only parts of the available parameters, our\napproach fully controls the simulator with the actual underlying goal of\nmaximizing accuracy, rather than mimicking the real data distribution or\nrandomly generating a large volume of data. We find that our approach (i)\nquickly converges to the optimal simulation parameters in controlled\nexperiments and (ii) can indeed discover good sets of parameters for an image\nrendering simulator in actual computer vision applications.", "published": "2018-10-05T04:11:25Z", "version": 2}, {"aid": "1810.02525", "authors": ["Peter Henderson", "Joshua Romoff", "Joelle Pineau"], "title": "Where Did My Optimum Go?: An Empirical Analysis of Gradient Descent Optimization in Policy Gradient Methods", "url": "http://arxiv.org/pdf/1810.02525v1", "summary": "Recent analyses of certain gradient descent optimization methods have shown\nthat performance can degrade in some settings - such as with stochasticity or\nimplicit momentum. In deep reinforcement learning (Deep RL), such optimization\nmethods are often used for training neural networks via the temporal difference\nerror or policy gradient. As an agent improves over time, the optimization\ntarget changes and thus the loss landscape (and local optima) change. Due to\nthe failure modes of those methods, the ideal choice of optimizer for Deep RL\nremains unclear. As such, we provide an empirical analysis of the effects that\na wide range of gradient descent optimizers and their hyperparameters have on\npolicy gradient methods, a subset of Deep RL algorithms, for benchmark\ncontinuous control tasks. We find that adaptive optimizers have a narrow window\nof effective learning rates, diverging in other cases, and that the\neffectiveness of momentum varies depending on the properties of the\nenvironment. Our analysis suggests that there is significant interplay between\nthe dynamics of the environment and Deep RL algorithm properties which aren't\nnecessarily accounted for by traditional adaptive gradient methods. We provide\nsuggestions for optimal settings of current methods and further lines of\nresearch based on our findings.", "published": "2018-10-05T05:52:49Z", "version": 1}, {"aid": "1810.08669", "authors": ["G. Iacca", "F. Neri", "E. Mininno", "Y. S. Ong", "M. H. Lim"], "title": "Ockham's Razor in Memetic Computing: Three Stage Optimal Memetic Exploration", "url": "http://arxiv.org/pdf/1810.08669v1", "summary": "Memetic Computing is a subject in computer science which considers complex\nstructures as the combination of simple agents, memes, whose evolutionary\ninteractions lead to intelligent structures capable of problem-solving. This\npaper focuses on Memetic Computing optimization algorithms and proposes a\ncounter-tendency approach for algorithmic design. Research in the field tends\nto go in the direction of improving existing algorithms by combining different\nmethods or through the formulation of more complicated structures. Contrary to\nthis trend, we instead focus on simplicity, proposing a structurally simple\nalgorithm with emphasis on processing only one solution at a time. The proposed\nalgorithm, namely Three Stage Optimal Memetic Exploration, is composed of three\nmemes; the first stochastic and with a long search radius, the second\nstochastic and with a moderate search radius and the third deterministic and\nwith a short search radius. The bottom-up combination of the three operators by\nmeans of a natural trial and error logic, generates a robust and efficient\noptimizer, capable of competing with modern complex and computationally\nexpensive algorithms. This is suggestive of the fact that complexity in\nalgorithmic structures can be unnecessary, if not detrimental, and that simple\nbottom-up approaches are likely to be competitive is here invoked as an\nextension to Memetic Computing basing on the philosophical concept of Ockham's\nRazor. An extensive experimental setup on various test problems and one digital\nsignal processing application is presented. Numerical results show that the\nproposed approach, despite its simplicity and low computational cost displays a\nvery good performance on several problems, and is competitive with\nsophisticated algorithms representing the-state-of-the-art in computational\nintelligence optimization.", "published": "2018-10-05T14:14:34Z", "version": 1}, {"aid": "1810.02786", "authors": ["C. -C. Jay Kuo", "Min Zhang", "Siyang Li", "Jiali Duan", "Yueru Chen"], "title": "Interpretable Convolutional Neural Networks via Feedforward Design", "url": "http://arxiv.org/pdf/1810.02786v2", "summary": "The model parameters of convolutional neural networks (CNNs) are determined\nby backpropagation (BP). In this work, we propose an interpretable feedforward\n(FF) design without any BP as a reference. The FF design adopts a data-centric\napproach. It derives network parameters of the current layer based on data\nstatistics from the output of the previous layer in a one-pass manner. To\nconstruct convolutional layers, we develop a new signal transform, called the\nSaab (Subspace Approximation with Adjusted Bias) transform. It is a variant of\nthe principal component analysis (PCA) with an added bias vector to annihilate\nactivation's nonlinearity. Multiple Saab transforms in cascade yield multiple\nconvolutional layers. As to fully-connected (FC) layers, we construct them\nusing a cascade of multi-stage linear least squared regressors (LSRs). The\nclassification and robustness (against adversarial attacks) performances of BP-\nand FF-designed CNNs applied to the MNIST and the CIFAR-10 datasets are\ncompared. Finally, we comment on the relationship between BP and FF designs.", "published": "2018-10-05T16:44:49Z", "version": 2}, {"aid": "1810.04028", "authors": ["Hao Zhang", "Jianwei Ma"], "title": "Hartley Spectral Pooling for Deep Learning", "url": "http://arxiv.org/pdf/1810.04028v2", "summary": "In most convolution neural networks (CNNs), downsampling hidden layers is\nadopted for increasing computation efficiency and the receptive field size.\nSuch operation is commonly so-called pooling. Maximation and averaging over\nsliding windows (max/average pooling), and plain downsampling in the form of\nstrided convolution are popular pooling methods. Since the pooling is a lossy\nprocedure, a motivation of our work is to design a new pooling approach for\nless lossy in the dimensionality reduction. Inspired by the Fourier spectral\npooling(FSP) proposed by Rippel et. al. [1], we present the Hartley transform\nbased spectral pooling method in CNNs. Compared with FSP, the proposed spectral\npooling avoids the use of complex arithmetic for frequency representation and\nreduces the computation. Spectral pooling preserves more structure features for\nnetwork's discriminability than max and average pooling. We empirically show\nthat Hartley spectral pooling gives rise to the convergence of training CNNs on\nMNIST and CIFAR-10 datasets.", "published": "2018-10-07T06:57:01Z", "version": 2}, {"aid": "1810.03105", "authors": ["Fanhua Shang", "Licheng Jiao", "Kaiwen Zhou", "James Cheng", "Yan Ren", "Yufei Jin"], "title": "ASVRG: Accelerated Proximal SVRG", "url": "http://arxiv.org/pdf/1810.03105v2", "summary": "This paper proposes an accelerated proximal stochastic variance reduced\ngradient (ASVRG) method, in which we design a simple and effective momentum\nacceleration trick. Unlike most existing accelerated stochastic variance\nreduction methods such as Katyusha, ASVRG has only one additional variable and\none momentum parameter. Thus, ASVRG is much simpler than those methods, and has\nmuch lower per-iteration complexity. We prove that ASVRG achieves the best\nknown oracle complexities for both strongly convex and non-strongly convex\nobjectives. In addition, we extend ASVRG to mini-batch and non-smooth settings.\nWe also empirically verify our theoretical results and show that the\nperformance of ASVRG is comparable with, and sometimes even better than that of\nthe state-of-the-art stochastic methods.", "published": "2018-10-07T08:43:05Z", "version": 2}, {"aid": "1810.03422", "authors": ["Mikael Brudfors", "Yael Balbastre", "Parashkev Nachev", "John Ashburner"], "title": "MRI Super-Resolution using Multi-Channel Total Variation", "url": "http://arxiv.org/pdf/1810.03422v6", "summary": "This paper presents a generative model for super-resolution in routine\nclinical magnetic resonance images (MRI), of arbitrary orientation and\ncontrast. The model recasts the recovery of high resolution images as an\ninverse problem, in which a forward model simulates the slice-select profile of\nthe MR scanner. The paper introduces a prior based on multi-channel total\nvariation for MRI super-resolution. Bias-variance trade-off is handled by\nestimating hyper-parameters from the low resolution input scans. The model was\nvalidated on a large database of brain images. The validation showed that the\nmodel can improve brain segmentation, that it can recover anatomical\ninformation between images of different MR contrasts, and that it generalises\nwell to the large variability present in MR images of different subjects. The\nimplementation is freely available at https://github.com/brudfors/spm_superres", "published": "2018-10-08T13:14:28Z", "version": 6}, {"aid": "1810.03946", "authors": ["Xiaobo Huang"], "title": "Convolutional Neural Networks In Convolution", "url": "http://arxiv.org/pdf/1810.03946v1", "summary": "Currently, increasingly deeper neural networks have been applied to improve\ntheir accuracy. In contrast, We propose a novel wider Convolutional Neural\nNetworks (CNN) architecture, motivated by the Multi-column Deep Neural Networks\nand the Network In Network(NIN), aiming for higher accuracy without input data\ntransmutation. In our architecture, namely \"CNN In Convolution\"(CNNIC), a small\nCNN, instead of the original generalized liner model(GLM) based filters, is\nconvoluted as kernel on the original image, serving as feature extracting layer\nof this networks. And further classifications are then carried out by a global\naverage pooling layer and a softmax layer. Dropout and orthonormal\ninitialization are applied to overcome training difficulties including slow\nconvergence and over-fitting. Persuasive classification performance is\ndemonstrated on MNIST.", "published": "2018-10-09T12:59:12Z", "version": 1}, {"aid": "1810.04246", "authors": ["Mohammed Jabi", "Marco Pedersoli", "Amar Mitiche", "Ismail Ben Ayed"], "title": "Deep clustering: On the link between discriminative models and K-means", "url": "http://arxiv.org/pdf/1810.04246v2", "summary": "In the context of recent deep clustering studies, discriminative models\ndominate the literature and report the most competitive performances. These\nmodels learn a deep discriminative neural network classifier in which the\nlabels are latent. Typically, they use multinomial logistic regression\nposteriors and parameter regularization, as is very common in supervised\nlearning. It is generally acknowledged that discriminative objective functions\n(e.g., those based on the mutual information or the KL divergence) are more\nflexible than generative approaches (e.g., K-means) in the sense that they make\nfewer assumptions about the data distributions and, typically, yield much\nbetter unsupervised deep learning results. On the surface, several recent\ndiscriminative models may seem unrelated to K-means. This study shows that\nthese models are, in fact, equivalent to K-means under mild conditions and\ncommon posterior models and parameter regularization. We prove that, for the\ncommonly used logistic regression posteriors, maximizing the $L_2$ regularized\nmutual information via an approximate alternating direction method (ADM) is\nequivalent to a soft and regularized K-means loss. Our theoretical analysis not\nonly connects directly several recent state-of-the-art discriminative models to\nK-means, but also leads to a new soft and regularized deep K-means algorithm,\nwhich yields competitive performance on several image clustering benchmarks.", "published": "2018-10-09T21:17:09Z", "version": 2}, {"aid": "1810.05077", "authors": ["Abdullah Alchihabi", "Omer Ekmekci", "Baran B. Kivilcim", "Sharlene D. Newman", "Fatos T. Yarman Vural"], "title": "On the Brain Networks of Complex Problem Solving", "url": "http://arxiv.org/pdf/1810.05077v1", "summary": "Complex problem solving is a high level cognitive process which has been\nthoroughly studied over the last decade. The Tower of London (TOL) is a task\nthat has been widely used to study problem-solving. In this study, we aim to\nexplore the underlying cognitive network dynamics among anatomical regions of\ncomplex problem solving and its sub-phases, namely planning and execution. A\nnew brain network construction model establishing dynamic functional brain\nnetworks using fMRI is proposed. The first step of the model is a preprocessing\npipeline that manages to decrease the spatial redundancy while increasing the\ntemporal resolution of the fMRI recordings. Then, dynamic brain networks are\nestimated using artificial neural networks. The network properties of the\nestimated brain networks are studied in order to identify regions of interest,\nsuch as hubs and subgroups of densely connected brain regions. The major\nsimilarities and dissimilarities of the network structure of planning and\nexecution phases are highlighted. Our findings show the hubs and clusters of\ndensely interconnected regions during both subtasks. It is observed that there\nare more hubs during the planning phase compared to the execution phase, and\nthe clusters are more strongly connected during planning compared to execution.", "published": "2018-10-10T09:22:21Z", "version": 1}, {"aid": "1810.05534", "authors": ["Robert E. Kent"], "title": "Conceptual Knowledge Markup Language: An Introduction", "url": "http://arxiv.org/pdf/1810.05534v1", "summary": "Conceptual Knowledge Markup Language (CKML) is an application of XML. Earlier\nversions of CKML followed rather exclusively the philosophy of Conceptual\nKnowledge Processing (CKP), a principled approach to knowledge representation\nand data analysis that \"advocates methods and instruments of conceptual\nknowledge processing which support people in their rational thinking, judgment\nand acting and promote critical discussion.\" The new version of CKML continues\nto follow this approach, but also incorporates various principles, insights and\ntechniques from Information Flow (IF), the logical design of distributed\nsystems. Among other things, this allows diverse communities of discourse to\ncompare their own information structures, as coded in logical theories, with\nthat of other communities that share a common generic ontology. CKML\nincorporates the CKP ideas of concept lattice and formal context, along with\nthe IF ideas of classification (= formal context), infomorphism, theory,\ninterpretation and local logic. Ontology Markup Language (OML), a subset of\nCKML that is a self-sufficient markup language in its own right, follows the\nprinciples and ideas of Conceptual Graphs (CG). OML is used for structuring the\nspecifications and axiomatics of metadata into ontologies. OML incorporates the\nCG ideas of concept, conceptual relation, conceptual graph, conceptual context,\nparticipants and ontology. The link from OML to CKML is the process of\nconceptual scaling, which is the interpretive transformation of ontologically\nstructured knowledge to conceptual structured knowledge.", "published": "2018-10-10T23:41:42Z", "version": 1}, {"aid": "1810.04805", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "url": "http://arxiv.org/pdf/1810.04805v2", "summary": "We introduce a new language representation model called BERT, which stands\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\nlanguage representation models, BERT is designed to pre-train deep\nbidirectional representations from unlabeled text by jointly conditioning on\nboth left and right context in all layers. As a result, the pre-trained BERT\nmodel can be fine-tuned with just one additional output layer to create\nstate-of-the-art models for a wide range of tasks, such as question answering\nand language inference, without substantial task-specific architecture\nmodifications.\n  BERT is conceptually simple and empirically powerful. It obtains new\nstate-of-the-art results on eleven natural language processing tasks, including\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\n(5.1 point absolute improvement).", "published": "2018-10-11T00:50:01Z", "version": 2}, {"aid": "1810.05017", "authors": ["Tom Le Paine", "Sergio G\u00f3mez Colmenarejo", "Ziyu Wang", "Scott Reed", "Yusuf Aytar", "Tobias Pfaff", "Matt W. Hoffman", "Gabriel Barth-Maron", "Serkan Cabi", "David Budden", "Nando de Freitas"], "title": "One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL", "url": "http://arxiv.org/pdf/1810.05017v1", "summary": "Humans are experts at high-fidelity imitation -- closely mimicking a\ndemonstration, often in one attempt. Humans use this ability to quickly solve a\ntask instance, and to bootstrap learning of new tasks. Achieving these\nabilities in autonomous agents is an open problem. In this paper, we introduce\nan off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn\nboth (i) policies for high-fidelity one-shot imitation of diverse novel skills,\nand (ii) policies that enable the agent to solve tasks more efficiently than\nthe demonstrators. MetaMimic relies on the principle of storing all experiences\nin a memory and replaying these to learn massive deep neural network policies\nby off-policy RL. This paper introduces, to the best of our knowledge, the\nlargest existing neural networks for deep RL and shows that larger networks\nwith normalization are needed to achieve one-shot high-fidelity imitation on a\nchallenging manipulation task. The results also show that both types of policy\ncan be learned from vision, in spite of the task rewards being sparse, and\nwithout access to demonstrator actions.", "published": "2018-10-11T13:46:18Z", "version": 1}, {"aid": "1810.05148", "authors": ["Roman Novak", "Lechao Xiao", "Jaehoon Lee", "Yasaman Bahri", "Greg Yang", "Jiri Hron", "Daniel A. Abolafia", "Jeffrey Pennington", "Jascha Sohl-Dickstein"], "title": "Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes", "url": "http://arxiv.org/pdf/1810.05148v4", "summary": "There is a previously identified equivalence between wide fully connected\nneural networks (FCNs) and Gaussian processes (GPs). This equivalence enables,\nfor instance, test set predictions that would have resulted from a fully\nBayesian, infinitely wide trained FCN to be computed without ever instantiating\nthe FCN, but by instead evaluating the corresponding GP. In this work, we\nderive an analogous equivalence for multi-layer convolutional neural networks\n(CNNs) both with and without pooling layers, and achieve state of the art\nresults on CIFAR10 for GPs without trainable kernels. We also introduce a Monte\nCarlo method to estimate the GP corresponding to a given neural network\narchitecture, even in cases where the analytic form has too many terms to be\ncomputationally feasible.\n  Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs\nwith and without weight sharing are identical. As a consequence, translation\nequivariance, beneficial in finite channel CNNs trained with stochastic\ngradient descent (SGD), is guaranteed to play no role in the Bayesian treatment\nof the infinite channel limit - a qualitative difference between the two\nregimes that is not present in the FCN case. We confirm experimentally, that\nwhile in some scenarios the performance of SGD-trained finite CNNs approaches\nthat of the corresponding GPs as the channel count increases, with careful\ntuning SGD-trained CNNs can significantly outperform their corresponding GPs,\nsuggesting advantages from SGD training compared to fully Bayesian parameter\nestimation.", "published": "2018-10-11T17:49:41Z", "version": 4}, {"aid": "1810.05680", "authors": ["Ali Borji", "Hamed R. Tavakoli", "Zoya Bylinskii"], "title": "Bottom-up Attention, Models of", "url": "http://arxiv.org/pdf/1810.05680v3", "summary": "In this review, we examine the recent progress in saliency prediction and\nproposed several avenues for future research. In spite of tremendous efforts\nand huge progress, there is still room for improvement in terms finer-grained\nanalysis of deep saliency models, evaluation measures, datasets, annotation\nmethods, cognitive studies, and new applications. This chapter will appear in\nEncyclopedia of Computational Neuroscience.", "published": "2018-10-11T17:58:35Z", "version": 3}, {"aid": "1810.05220", "authors": ["Shreeraj Jadhav", "Saad Nadeem", "Arie Kaufman"], "title": "FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels", "url": "http://arxiv.org/pdf/1810.05220v2", "summary": "We present a volume exploration framework, FeatureLego, that uses a novel\nvoxel clustering approach for efficient selection of semantic features. We\npartition the input volume into a set of compact super-voxels that represent\nthe finest selection granularity. We then perform an exhaustive clustering of\nthese super-voxels using a graph-based clustering method. Unlike the prevalent\nbrute-force parameter sampling approaches, we propose an efficient algorithm to\nperform this exhaustive clustering. By computing an exhaustive set of clusters,\nwe aim to capture as many boundaries as possible and ensure that the user has\nsufficient options for efficiently selecting semantically relevant features.\nFurthermore, we merge all the computed clusters into a single tree of\nmeta-clusters that can be used for hierarchical exploration. We implement an\nintuitive user-interface to interactively explore volumes using our clustering\napproach. Finally, we show the effectiveness of our framework on multiple\nreal-world datasets of different modalities.", "published": "2018-10-11T19:40:25Z", "version": 2}, {"aid": "1810.05270", "authors": ["Zhuang Liu", "Mingjie Sun", "Tinghui Zhou", "Gao Huang", "Trevor Darrell"], "title": "Rethinking the Value of Network Pruning", "url": "http://arxiv.org/pdf/1810.05270v2", "summary": "Network pruning is widely used for reducing the heavy inference cost of deep\nmodels in low-resource settings. A typical pruning algorithm is a three-stage\npipeline, i.e., training (a large model), pruning and fine-tuning. During\npruning, according to a certain criterion, redundant weights are pruned and\nimportant weights are kept to best preserve the accuracy. In this work, we make\nseveral surprising observations which contradict common beliefs. For all\nstate-of-the-art structured pruning algorithms we examined, fine-tuning a\npruned model only gives comparable or worse performance than training that\nmodel with randomly initialized weights. For pruning algorithms which assume a\npredefined target network architecture, one can get rid of the full pipeline\nand directly train the target network from scratch. Our observations are\nconsistent for multiple network architectures, datasets, and tasks, which imply\nthat: 1) training a large, over-parameterized model is often not necessary to\nobtain an efficient final model, 2) learned \"important\" weights of the large\nmodel are typically not useful for the small pruned model, 3) the pruned\narchitecture itself, rather than a set of inherited \"important\" weights, is\nmore crucial to the efficiency in the final model, which suggests that in some\ncases pruning can be useful as an architecture search paradigm. Our results\nsuggest the need for more careful baseline evaluations in future research on\nstructured pruning methods. We also compare with the \"Lottery Ticket\nHypothesis\" (Frankle & Carbin 2019), and find that with optimal learning rate,\nthe \"winning ticket\" initialization as used in Frankle & Carbin (2019) does not\nbring improvement over random initialization.", "published": "2018-10-11T22:15:28Z", "version": 2}, {"aid": "1810.05291", "authors": ["Jeremy Bernstein", "Jiawei Zhao", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "signSGD with Majority Vote is Communication Efficient And Fault Tolerant", "url": "http://arxiv.org/pdf/1810.05291v3", "summary": "Training neural networks on large datasets can be accelerated by distributing\nthe workload over a network of machines. As datasets grow ever larger, networks\nof hundreds or thousands of machines become economically viable. The time cost\nof communicating gradients limits the effectiveness of using such large machine\ncounts, as may the increased chance of network faults. We explore a\nparticularly simple algorithm for robust, communication-efficient\nlearning---signSGD. Workers transmit only the sign of their gradient vector to\na server, and the overall update is decided by a majority vote. This algorithm\nuses $32\\times$ less communication per iteration than full-precision,\ndistributed SGD. Under natural conditions verified by experiment, we prove that\nsignSGD converges in the large and mini-batch settings, establishing\nconvergence for a parameter regime of Adam as a byproduct. Aggregating sign\ngradients by majority vote means that no individual worker has too much power.\nWe prove that unlike SGD, majority vote is robust when up to 50% of workers\nbehave adversarially. The class of adversaries we consider includes as special\ncases those that invert or randomise their gradient estimate. On the practical\nside, we built our distributed training system in Pytorch. Benchmarking against\nthe state of the art collective communications library (NCCL), our\nframework---with the parameter server housed entirely on one machine---led to a\n25% reduction in time for training resnet50 on Imagenet when using 15 AWS\np3.2xlarge machines.", "published": "2018-10-11T23:50:32Z", "version": 3}, {"aid": "1810.05331", "authors": ["Xitong Gao", "Yiren Zhao", "\u0141ukasz Dudziak", "Robert Mullins", "Cheng-zhong Xu"], "title": "Dynamic Channel Pruning: Feature Boosting and Suppression", "url": "http://arxiv.org/pdf/1810.05331v2", "summary": "Making deep convolutional neural networks more accurate typically comes at\nthe cost of increased computational and memory resources. In this paper, we\nreduce this cost by exploiting the fact that the importance of features\ncomputed by convolutional layers is highly input-dependent, and propose feature\nboosting and suppression (FBS), a new method to predictively amplify salient\nconvolutional channels and skip unimportant ones at run-time. FBS introduces\nsmall auxiliary connections to existing convolutional layers. In contrast to\nchannel pruning methods which permanently remove channels, it preserves the\nfull network structures and accelerates convolution by dynamically skipping\nunimportant input and output channels. FBS-augmented networks are trained with\nconventional stochastic gradient descent, making it readily available for many\nstate-of-the-art CNNs. We compare FBS to a range of existing channel pruning\nand dynamic execution schemes and demonstrate large improvements on ImageNet\nclassification. Experiments show that FBS can respectively provide $5\\times$\nand $2\\times$ savings in compute on VGG-16 and ResNet-18, both with less than\n$0.6\\%$ top-5 accuracy loss.", "published": "2018-10-12T03:00:59Z", "version": 2}, {"aid": "1810.06985", "authors": ["Yasha Savelyev"], "title": "Non-computability of human intelligence", "url": "http://arxiv.org/pdf/1810.06985v8", "summary": "We revisit the question (most famously) initiated by Turing: can human\nintelligence be completely modeled by a Turing machine? We show that the answer\nis \\emph{no}, assuming a certain weak soundness hypothesis. More specifically\nwe show that at least some meaningful thought processes of the brain cannot be\nTuring computable. In particular some physical processes are not Turing\ncomputable, which is not entirely expected. There are some similarities of our\nargument with the well known Lucas-Penrose argument, but we work purely on the\nlevel of Turing machines, and do not use G\\\"odel's incompleteness theorem or\nany direct analogue. Instead we construct directly and use a weak analogue of a\nG\\\"odel statement for a certain system which involves our human, this allows us\nto side-step some (possible) meta-logical issues with their argument.", "published": "2018-10-12T20:16:21Z", "version": 8}, {"aid": "1810.07632", "authors": ["Robert E. Kent"], "title": "Conceptual Collectives", "url": "http://arxiv.org/pdf/1810.07632v1", "summary": "The notions of formal contexts and concept lattices, although introduced by\nWille only ten years ago, already have proven to be of great utility in various\napplications such as data analysis and knowledge representation. In this paper\nwe give arguments that Wille's original notion of formal context, although\nquite appealing in its simplicity, now should be replaced by a more semantic\nnotion. This new notion of formal context entails a modified approach to\nconcept construction. We base our arguments for these new versions of formal\ncontext and concept construction upon Wille's philosophical attitude with\nreference to the intensional aspect of concepts. We give a brief development of\nthe relational theory of formal contexts and concept construction,\ndemonstrating the equivalence of \"concept-lattice construction\" of Wille with\nthe well-known \"completion by cuts\" of MacNeille. Generalization and\nabstraction of these formal contexts offers a powerful approach to knowledge\nrepresentation.", "published": "2018-10-14T19:11:19Z", "version": 1}, {"aid": "1810.06966", "authors": ["Victor Minden", "Cengiz Pehlevan", "Dmitri B. Chklovskii"], "title": "Biologically Plausible Online Principal Component Analysis Without Recurrent Neural Dynamics", "url": "http://arxiv.org/pdf/1810.06966v2", "summary": "Artificial neural networks that learn to perform Principal Component Analysis\n(PCA) and related tasks using strictly local learning rules have been\npreviously derived based on the principle of similarity matching: similar pairs\nof inputs should map to similar pairs of outputs. However, the operation of\nthese networks (and of similar networks) requires a fixed-point iteration to\ndetermine the output corresponding to a given input, which means that dynamics\nmust operate on a faster time scale than the variation of the input. Further,\nduring these fast dynamics such networks typically \"disable\" learning, updating\nsynaptic weights only once the fixed-point iteration has been resolved. Here,\nwe derive a network for PCA-based dimensionality reduction that avoids this\nfast fixed-point iteration. The key novelty of our approach is a modification\nof the similarity matching objective to encourage near-diagonality of a\nsynaptic weight matrix. We then approximately invert this matrix using a Taylor\nseries approximation, replacing the previous fast iterations. In the offline\nsetting, our algorithm corresponds to a dynamical system, the stability of\nwhich we rigorously analyze. In the online setting (i.e., with stochastic\ngradients), we map our algorithm to a familiar neural network architecture and\ngive numerical results showing that our method converges at a competitive rate.\nThe computational complexity per iteration of our online algorithm is linear in\nthe total degrees of freedom, which is in some sense optimal.", "published": "2018-10-16T13:06:38Z", "version": 2}, {"aid": "1810.10333", "authors": ["Adityanarayanan Radhakrishnan", "Karren Yang", "Mikhail Belkin", "Caroline Uhler"], "title": "Memorization in Overparameterized Autoencoders", "url": "http://arxiv.org/pdf/1810.10333v3", "summary": "The ability of deep neural networks to generalize well in the\noverparameterized regime has become a subject of significant research interest.\nWe show that overparameterized autoencoders exhibit memorization, a form of\ninductive bias that constrains the functions learned through the optimization\nprocess to concentrate around the training examples, although the network could\nin principle represent a much larger function class. In particular, we prove\nthat single-layer fully-connected autoencoders project data onto the\n(nonlinear) span of the training examples. In addition, we show that deep\nfully-connected autoencoders learn a map that is locally contractive at the\ntraining examples, and hence iterating the autoencoder results in convergence\nto the training examples. Finally, we prove that depth is necessary and provide\nempirical evidence that it is also sufficient for memorization in convolutional\nautoencoders. Understanding this inductive bias may shed light on the\ngeneralization properties of overparametrized deep neural networks that are\ncurrently unexplained by classical statistical theory.", "published": "2018-10-16T17:02:54Z", "version": 3}, {"aid": "1810.07307", "authors": ["Rafik Hadfi"], "title": "Solving Tree Problems with Category Theory", "url": "http://arxiv.org/pdf/1810.07307v1", "summary": "Artificial Intelligence (AI) has long pursued models, theories, and\ntechniques to imbue machines with human-like general intelligence. Yet even the\ncurrently predominant data-driven approaches in AI seem to be lacking humans'\nunique ability to solve wide ranges of problems. This situation begs the\nquestion of the existence of principles that underlie general problem-solving\ncapabilities. We approach this question through the mathematical formulation of\nanalogies across different problems and solutions. We focus in particular on\nproblems that could be represented as tree-like structures. Most importantly,\nwe adopt a category-theoretic approach in formalising tree problems as\ncategories, and in proving the existence of equivalences across apparently\nunrelated problem domains. We prove the existence of a functor between the\ncategory of tree problems and the category of solutions. We also provide a\nweaker version of the functor by quantifying equivalences of problem categories\nusing a metric on tree problems.", "published": "2018-10-16T23:06:48Z", "version": 1}, {"aid": "1810.07528", "authors": ["David Gunning"], "title": "Machine Common Sense Concept Paper", "url": "http://arxiv.org/pdf/1810.07528v1", "summary": "This paper summarizes some of the technical background, research ideas, and\npossible development strategies for achieving machine common sense. Machine\ncommon sense has long been a critical-but-missing component of Artificial\nIntelligence (AI). Recent advances in machine learning have resulted in new AI\ncapabilities, but in all of these applications, machine reasoning is narrow and\nhighly specialized. Developers must carefully train or program systems for\nevery situation. General commonsense reasoning remains elusive. The absence of\ncommon sense prevents intelligent systems from understanding their world,\nbehaving reasonably in unforeseen situations, communicating naturally with\npeople, and learning from new experiences. Its absence is perhaps the most\nsignificant barrier between the narrowly focused AI applications we have today\nand the more general, human-like AI systems we would like to build in the\nfuture. Machine common sense remains a broad, potentially unbounded problem in\nAI. There are a wide range of strategies that could be employed to make\nprogress on this difficult challenge. This paper discusses two diverse\nstrategies for focusing development on two different machine commonsense\nservices: (1) a service that learns from experience, like a child, to construct\ncomputational models that mimic the core domains of child cognition for objects\n(intuitive physics), agents (intentional actors), and places (spatial\nnavigation); and (2) service that learns from reading the Web, like a research\nlibrarian, to construct a commonsense knowledge repository capable of answering\nnatural language and image-based questions about commonsense phenomena.", "published": "2018-10-17T13:31:41Z", "version": 1}, {"aid": "1810.07746", "authors": ["Evan M. Yu", "Mert R. Sabuncu"], "title": "A Convolutional Autoencoder Approach to Learn Volumetric Shape Representations for Brain Structures", "url": "http://arxiv.org/pdf/1810.07746v1", "summary": "We propose a novel machine learning strategy for studying neuroanatomical\nshape variation. Our model works with volumetric binary segmentation images,\nand requires no pre-processing such as the extraction of surface points or a\nmesh. The learned shape descriptor is invariant to affine transformations,\nincluding shifts, rotations and scaling. Thanks to the adopted autoencoder\nframework, inter-subject differences are automatically enhanced in the learned\nrepresentation, while intra-subject variances are minimized. Our experimental\nresults on a shape retrieval task showed that the proposed representation\noutperforms a state-of-the-art benchmark for brain structures extracted from\nMRI scans.", "published": "2018-10-17T19:34:59Z", "version": 1}, {"aid": "1810.07842", "authors": ["Nabila Abraham", "Naimul Mefraz Khan"], "title": "A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation", "url": "http://arxiv.org/pdf/1810.07842v1", "summary": "We propose a generalized focal loss function based on the Tversky index to\naddress the issue of data imbalance in medical image segmentation. Compared to\nthe commonly used Dice loss, our loss function achieves a better trade off\nbetween precision and recall when training on small structures such as lesions.\nTo evaluate our loss function, we improve the attention U-Net model by\nincorporating an image pyramid to preserve contextual features. We experiment\non the BUS 2017 dataset and ISIC 2018 dataset where lesions occupy 4.84% and\n21.4% of the images area and improve segmentation accuracy when compared to the\nstandard U-Net by 25.7% and 3.6%, respectively.", "published": "2018-10-18T00:07:33Z", "version": 1}, {"aid": "1810.07960", "authors": ["Bolun Zheng", "Rui Sun", "Xiang Tian", "Yaowu Chen"], "title": "S-Net: A Scalable Convolutional Neural Network for JPEG Compression Artifact Reduction", "url": "http://arxiv.org/pdf/1810.07960v1", "summary": "Recent studies have used deep residual convolutional neural networks (CNNs)\nfor JPEG compression artifact reduction. This study proposes a scalable CNN\ncalled S-Net. Our approach effectively adjusts the network scale dynamically in\na multitask system for real-time operation with little performance loss. It\noffers a simple and direct technique to evaluate the performance gains obtained\nwith increasing network depth, and it is helpful for removing redundant network\nlayers to maximize the network efficiency. We implement our architecture using\nthe Keras framework with the TensorFlow backend on an NVIDIA K80 GPU server. We\ntrain our models on the DIV2K dataset and evaluate their performance on public\nbenchmark datasets. To validate the generality and universality of the proposed\nmethod, we created and utilized a new dataset, called WIN143, for\nover-processed images evaluation. Experimental results indicate that our\nproposed approach outperforms other CNN-based methods and achieves\nstate-of-the-art performance.", "published": "2018-10-18T09:21:44Z", "version": 1}, {"aid": "1810.08100", "authors": ["Lijun Wang", "Xiaohui Shen", "Jianming Zhang", "Oliver Wang", "Zhe Lin", "Chih-Yao Hsieh", "Sarah Kong", "Huchuan Lu"], "title": "DeepLens: Shallow Depth Of Field From A Single Image", "url": "http://arxiv.org/pdf/1810.08100v1", "summary": "We aim to generate high resolution shallow depth-of-field (DoF) images from a\nsingle all-in-focus image with controllable focal distance and aperture size.\nTo achieve this, we propose a novel neural network model comprised of a depth\nprediction module, a lens blur module, and a guided upsampling module. All\nmodules are differentiable and are learned from data. To train our depth\nprediction module, we collect a dataset of 2462 RGB-D images captured by mobile\nphones with a dual-lens camera, and use existing segmentation datasets to\nimprove border prediction. We further leverage a synthetic dataset with known\ndepth to supervise the lens blur and guided upsampling modules. The\neffectiveness of our system and training strategies are verified in the\nexperiments. Our method can generate high-quality shallow DoF images at high\nresolution, and produces significantly fewer artifacts than the baselines and\nexisting solutions for single image shallow DoF synthesis. Compared with the\niPhone portrait mode, which is a state-of-the-art shallow DoF solution based on\na dual-lens depth camera, our method generates comparable results, while\nallowing for greater flexibility to choose focal points and aperture size, and\nis not limited to one capture setup.", "published": "2018-10-18T15:14:41Z", "version": 1}, {"aid": "1810.08163", "authors": ["Steven Hansen", "Pablo Sprechmann", "Alexander Pritzel", "Andr\u00e9 Barreto", "Charles Blundell"], "title": "Fast deep reinforcement learning using online adjustments from the past", "url": "http://arxiv.org/pdf/1810.08163v1", "summary": "We propose Ephemeral Value Adjusments (EVA): a means of allowing deep\nreinforcement learning agents to rapidly adapt to experience in their replay\nbuffer. EVA shifts the value predicted by a neural network with an estimate of\nthe value function found by planning over experience tuples from the replay\nbuffer near the current state. EVA combines a number of recent ideas around\ncombining episodic memory-like structures into reinforcement learning agents:\nslot-based storage, content-based retrieval, and memory-based planning. We show\nthat EVAis performant on a demonstration task and Atari games.", "published": "2018-10-18T17:00:20Z", "version": 1}, {"aid": "1810.08170", "authors": ["Daniel Rodr\u00edguez-Chavarr\u00eda", "Miguel A. Guti\u00e9rrez-Naranjo", "Joaqu\u00edn Borrego-D\u00edaz"], "title": "Logic Negation with Spiking Neural P Systems", "url": "http://arxiv.org/pdf/1810.08170v2", "summary": "Nowadays, the success of neural networks as reasoning systems is doubtless.\nNonetheless, one of the drawbacks of such reasoning systems is that they work\nas black-boxes and the acquired knowledge is not human readable. In this paper,\nwe present a new step in order to close the gap between connectionist and logic\nbased reasoning systems. We show that two of the most used inference rules for\nobtaining negative information in rule based reasoning systems, the so-called\nClosed World Assumption and Negation as Finite Failure can be characterized by\nmeans of spiking neural P systems, a formal model of the third generation of\nneural networks born in the framework of membrane computing.", "published": "2018-10-18T17:22:30Z", "version": 2}, {"aid": "1810.08229", "authors": ["Qiaoying Huang", "Dong Yang", "Pengxiang Wu", "Hui Qu", "Jingru Yi", "Dimitris Metaxas"], "title": "MRI Reconstruction via Cascaded Channel-wise Attention Network", "url": "http://arxiv.org/pdf/1810.08229v2", "summary": "We consider an MRI reconstruction problem with input of k-space data at a\nvery low undersampled rate. This can practically benefit patient due to reduced\ntime of MRI scan, but it is also challenging since quality of reconstruction\nmay be compromised. Currently, deep learning based methods dominate MRI\nreconstruction over traditional approaches such as Compressed Sensing, but they\nrarely show satisfactory performance in the case of low undersampled k-space\ndata. One explanation is that these methods treat channel-wise features\nequally, which results in degraded representation ability of the neural\nnetwork. To solve this problem, we propose a new model called MRI Cascaded\nChannel-wise Attention Network (MICCAN), highlighted by three components: (i) a\nvariant of U-net with Channel-wise Attention (UCA) module, (ii) a long skip\nconnection and (iii) a combined loss. Our model is able to attend to salient\ninformation by filtering irrelevant features and also concentrate on\nhigh-frequency information by enforcing low-frequency information bypassed to\nthe final output. We conduct both quantitative evaluation and qualitative\nanalysis of our method on a cardiac dataset. The experiment shows that our\nmethod achieves very promising results in terms of three common metrics on the\nMRI reconstruction with low undersampled k-space data.", "published": "2018-10-18T18:37:37Z", "version": 2}, {"aid": "1810.08831", "authors": ["Robert E. Kent"], "title": "Enriched Interpretation", "url": "http://arxiv.org/pdf/1810.08831v1", "summary": "The theory introduced, presented and developed in this paper, is concerned\nwith an enriched extension of the theory of Rough Sets pioneered by Zdzislaw\nPawlak. The enrichment discussed here is in the sense of valuated categories as\ndeveloped by F.W. Lawvere. This paper relates Rough Sets to an abstraction of\nthe theory of Fuzzy Sets pioneered by Lotfi Zadeh, and provides a natural\nfoundation for \"soft computation\". To paraphrase Lotfi Zadeh, the impetus for\nthe transition from a hard theory to a soft theory derives from the fact that\nboth the generality of a theory and its applicability to real-world problems\nare substantially enhanced by replacing various hard concepts with their soft\ncounterparts. Here we discuss the corresponding enriched notions for\nindiscernibility, subsets, upper/lower approximations, and rough sets.\nThroughout, we indicate linkages with the theory of Formal Concept Analysis\npioneered by Rudolf Wille. We pay particular attention to the all-important\nnotion of a \"linguistic variable\" - developing its enriched extension,\ncomparing it with the notion of conceptual scale from Formal Concept Analysis,\nand discussing the pragmatic issues of its creation and use in the\ninterpretation of data. These pragmatic issues are exemplified by the\ndiscovery, conceptual analysis, interpretation, and categorization of networked\ninformation resources in WAVE, the Web Analysis and Visualization Environment\ncurrently being developed for the management and interpretation of the universe\nof resource information distributed over the World-Wide Web.", "published": "2018-10-20T17:41:16Z", "version": 1}, {"aid": "1810.09028", "authors": ["Michael Schaarschmidt", "Sven Mika", "Kai Fricke", "Eiko Yoneki"], "title": "RLgraph: Modular Computation Graphs for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1810.09028v2", "summary": "Reinforcement learning (RL) tasks are challenging to implement, execute and\ntest due to algorithmic instability, hyper-parameter sensitivity, and\nheterogeneous distributed communication patterns. We argue for the separation\nof logical component composition, backend graph definition, and distributed\nexecution. To this end, we introduce RLgraph, a library for designing and\nexecuting reinforcement learning tasks in both static graph and define-by-run\nparadigms. The resulting implementations are robust, incrementally testable,\nand yield high performance across different deep learning frameworks and\ndistributed backends.", "published": "2018-10-21T21:12:06Z", "version": 2}, {"aid": "1810.09038", "authors": ["Kenji Kawaguchi", "Yoshua Bengio"], "title": "Depth with Nonlinearity Creates No Bad Local Minima in ResNets", "url": "http://arxiv.org/pdf/1810.09038v3", "summary": "In this paper, we prove that depth with nonlinearity creates no bad local\nminima in a type of arbitrarily deep ResNets with arbitrary nonlinear\nactivation functions, in the sense that the values of all local minima are no\nworse than the global minimum value of corresponding classical machine-learning\nmodels, and are guaranteed to further improve via residual representations. As\na result, this paper provides an affirmative answer to an open question stated\nin a paper in the conference on Neural Information Processing Systems 2018.\nThis paper advances the optimization theory of deep learning only for ResNets\nand not for other network architectures.", "published": "2018-10-21T22:38:32Z", "version": 3}, {"aid": "1810.10353", "authors": ["Yang Li", "Mengying Lei", "Xianrui Zhang", "Weigang Cui", "Yuzhu Guo", "Ting-Wen Huang", "Hua-Liang Wei"], "title": "Boosted Convolutional Neural Networks for Motor Imagery EEG Decoding with Multiwavelet-based Time-Frequency Conditional Granger Causality Analysis", "url": "http://arxiv.org/pdf/1810.10353v1", "summary": "Decoding EEG signals of different mental states is a challenging task for\nbrain-computer interfaces (BCIs) due to nonstationarity of perceptual decision\nprocesses. This paper presents a novel boosted convolutional neural networks\n(ConvNets) decoding scheme for motor imagery (MI) EEG signals assisted by the\nmultiwavelet-based time-frequency (TF) causality analysis. Specifically,\nmultiwavelet basis functions are first combined with Geweke spectral measure to\nobtain high-resolution TF-conditional Granger causality (CGC) representations,\nwhere a regularized orthogonal forward regression (ROFR) algorithm is adopted\nto detect a parsimonious model with good generalization performance. The\ncausality images for network input preserving time, frequency and location\ninformation of connectivity are then designed based on the TF-CGC distributions\nof alpha band multichannel EEG signals. Further constructed boosted ConvNets by\nusing spatio-temporal convolutions as well as advances in deep learning\nincluding cropping and boosting methods, to extract discriminative causality\nfeatures and classify MI tasks. Our proposed approach outperforms the\ncompetition winner algorithm with 12.15% increase in average accuracy and\n74.02% decrease in associated inter subject standard deviation for the same\nbinary classification on BCI competition-IV dataset-IIa. Experiment results\nindicate that the boosted ConvNets with causality images works well in decoding\nMI-EEG signals and provides a promising framework for developing MI-BCI\nsystems.", "published": "2018-10-22T07:39:12Z", "version": 1}, {"aid": "1810.09136", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Dilan Gorur", "Balaji Lakshminarayanan"], "title": "Do Deep Generative Models Know What They Don't Know?", "url": "http://arxiv.org/pdf/1810.09136v3", "summary": "A neural network deployed in the wild may be asked to make predictions for\ninputs that were drawn from a different distribution than that of the training\ndata. A plethora of work has demonstrated that it is easy to find or synthesize\ninputs for which a neural network is highly confident yet wrong. Generative\nmodels are widely viewed to be robust to such mistaken confidence as modeling\nthe density of the input features can be used to detect novel,\nout-of-distribution inputs. In this paper we challenge this assumption. We find\nthat the density learned by flow-based models, VAEs, and PixelCNNs cannot\ndistinguish images of common objects such as dogs, trucks, and horses (i.e.\nCIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher\nlikelihood to the latter when the model is trained on the former. Moreover, we\nfind evidence of this phenomenon when pairing several popular image data sets:\nFashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN.\nTo investigate this curious behavior, we focus analysis on flow-based\ngenerative models in particular since they are trained and evaluated via the\nexact marginal likelihood. We find such behavior persists even when we restrict\nthe flows to constant-volume transformations. These transformations admit some\ntheoretical analysis, and we show that the difference in likelihoods can be\nexplained by the location and variances of the data and the model curvature.\nOur results caution against using the density estimates from deep generative\nmodels to identify inputs similar to the training distribution until their\nbehavior for out-of-distribution inputs is better understood.", "published": "2018-10-22T08:32:02Z", "version": 3}, {"aid": "1810.09391", "authors": ["Constantine Dovrolis"], "title": "A neuro-inspired architecture for unsupervised continual learning based on online clustering and hierarchical predictive coding", "url": "http://arxiv.org/pdf/1810.09391v1", "summary": "We propose that the Continual Learning desiderata can be achieved through a\nneuro-inspired architecture, grounded on Mountcastle's cortical column\nhypothesis. The proposed architecture involves a single module, called\nSelf-Taught Associative Memory (STAM), which models the function of a cortical\ncolumn. STAMs are repeated in multi-level hierarchies involving feedforward,\nlateral and feedback connections. STAM networks learn in an unsupervised\nmanner, based on a combination of online clustering and hierarchical predictive\ncoding. This short paper only presents the architecture and its connections\nwith neuroscience. A mathematical formulation and experimental results will be\npresented in an extended version of this paper.", "published": "2018-10-22T16:27:21Z", "version": 1}, {"aid": "1810.09821", "authors": ["Qibin Hou", "Peng-Tao Jiang", "Yunchao Wei", "Ming-Ming Cheng"], "title": "Self-Erasing Network for Integral Object Attention", "url": "http://arxiv.org/pdf/1810.09821v1", "summary": "Recently, adversarial erasing for weakly-supervised object attention has been\ndeeply studied due to its capability in localizing integral object regions.\nHowever, such a strategy raises one key problem that attention regions will\ngradually expand to non-object regions as training iterations continue, which\nsignificantly decreases the quality of the produced attention maps. To tackle\nsuch an issue as well as promote the quality of object attention, we introduce\na simple yet effective Self-Erasing Network (SeeNet) to prohibit attentions\nfrom spreading to unexpected background regions. In particular, SeeNet\nleverages two self-erasing strategies to encourage networks to use reliable\nobject and background cues for learning to attention. In this way, integral\nobject regions can be effectively highlighted without including much more\nbackground regions. To test the quality of the generated attention maps, we\nemploy the mined object regions as heuristic cues for learning semantic\nsegmentation models. Experiments on Pascal VOC well demonstrate the superiority\nof our SeeNet over other state-of-the-art methods.", "published": "2018-10-23T12:53:56Z", "version": 1}, {"aid": "1810.09849", "authors": ["Zhengsu Chen Jianwei Niu Qi Tian"], "title": "DropFilter: Dropout for Convolutions", "url": "http://arxiv.org/pdf/1810.09849v1", "summary": "Using a large number of parameters , deep neural networks have achieved\nremarkable performance on computer vison and natural language processing tasks.\nHowever the networks usually suffer from overfitting by using too much\nparameters. Dropout is a widely use method to deal with overfitting. Although\ndropout can significantly regularize densely connected layers in neural\nnetworks, it leads to suboptimal results when using for convolutional layers.\nTo track this problem, we propose DropFilter, a new dropout method for\nconvolutional layers. DropFilter randomly suppresses the outputs of some\nfilters. Because it is observed that co-adaptions are more likely to occurs\ninter filters rather than intra filters in convolutional layers. Using\nDropFilter, we remarkably improve the performance of convolutional networks on\nCIFAR and ImageNet.", "published": "2018-10-23T13:42:25Z", "version": 1}, {"aid": "1810.09945", "authors": ["Armin W. Thomas", "Hauke R. Heekeren", "Klaus-Robert M\u00fcller", "Wojciech Samek"], "title": "Analyzing Neuroimaging Data Through Recurrent Deep Learning Models", "url": "http://arxiv.org/pdf/1810.09945v2", "summary": "The application of deep learning (DL) models to neuroimaging data poses\nseveral challenges, due to the high dimensionality, low sample size and complex\ntemporo-spatial dependency structure of these datasets. Even further, DL models\nact as as black-box models, impeding insight into the association of cognitive\nstate and brain activity. To approach these challenges, we introduce the\nDeepLight framework, which utilizes long short-term memory (LSTM) based DL\nmodels to analyze whole-brain functional Magnetic Resonance Imaging (fMRI)\ndata. To decode a cognitive state (e.g., seeing the image of a house),\nDeepLight separates the fMRI volume into a sequence of axial brain slices,\nwhich is then sequentially processed by an LSTM. To maintain interpretability,\nDeepLight adapts the layer-wise relevance propagation (LRP) technique. Thereby,\ndecomposing its decoding decision into the contributions of the single input\nvoxels to this decision. Importantly, the decomposition is performed on the\nlevel of single fMRI volumes, enabling DeepLight to study the associations\nbetween cognitive state and brain activity on several levels of data\ngranularity, from the level of the group down to the level of single time\npoints. To demonstrate the versatility of DeepLight, we apply it to a large\nfMRI dataset of the Human Connectome Project. We show that DeepLight\noutperforms conventional approaches of uni- and multivariate fMRI analysis in\ndecoding the cognitive states and in identifying the physiologically\nappropriate brain regions associated with these states. We further demonstrate\nDeepLight's ability to study the fine-grained temporo-spatial variability of\nbrain activity over sequences of single fMRI samples.", "published": "2018-10-23T16:23:27Z", "version": 2}, {"aid": "1810.10531", "authors": ["Andrew M. Saxe", "James L. McClelland", "Surya Ganguli"], "title": "A mathematical theory of semantic development in deep neural networks", "url": "http://arxiv.org/pdf/1810.10531v1", "summary": "An extensive body of empirical research has revealed remarkable regularities\nin the acquisition, organization, deployment, and neural representation of\nhuman semantic knowledge, thereby raising a fundamental conceptual question:\nwhat are the theoretical principles governing the ability of neural networks to\nacquire, organize, and deploy abstract knowledge by integrating across many\nindividual experiences? We address this question by mathematically analyzing\nthe nonlinear dynamics of learning in deep linear networks. We find exact\nsolutions to this learning dynamics that yield a conceptual explanation for the\nprevalence of many disparate phenomena in semantic cognition, including the\nhierarchical differentiation of concepts through rapid developmental\ntransitions, the ubiquity of semantic illusions between such transitions, the\nemergence of item typicality and category coherence as factors controlling the\nspeed of semantic processing, changing patterns of inductive projection over\ndevelopment, and the conservation of semantic similarity in neural\nrepresentations across species. Thus, surprisingly, our simple neural model\nqualitatively recapitulates many diverse regularities underlying semantic\ndevelopment, while providing analytic insight into how the statistical\nstructure of an environment can interact with nonlinear deep learning dynamics\nto give rise to these regularities.", "published": "2018-10-23T22:20:27Z", "version": 1}, {"aid": "1810.10126", "authors": ["Yang Li", "Lukasz Kaiser", "Samy Bengio", "Si Si"], "title": "Area Attention", "url": "http://arxiv.org/pdf/1810.10126v7", "summary": "Existing attention mechanisms are trained to attend to individual items in a\ncollection (the memory) with a predefined, fixed granularity, e.g., a word\ntoken or an image grid. We propose area attention: a way to attend to areas in\nthe memory, where each area contains a group of items that are structurally\nadjacent, e.g., spatially for a 2D memory such as images, or temporally for a\n1D memory such as natural language sentences. Importantly, the shape and the\nsize of an area are dynamically determined via learning, which enables a model\nto attend to information with varying granularity. Area attention can easily\nwork with existing model architectures such as multi-head attention for\nsimultaneously attending to multiple areas in the memory. We evaluate area\nattention on two tasks: neural machine translation (both character and\ntoken-level) and image captioning, and improve upon strong (state-of-the-art)\nbaselines in all the cases. These improvements are obtainable with a basic form\nof area attention that is parameter free.", "published": "2018-10-23T23:14:27Z", "version": 7}, {"aid": "1811.02667", "authors": ["Pablo Ribalta Lorenzo", "Lukasz Tulczyjew", "Michal Marcinkiewicz", "Jakub Nalepa"], "title": "Band Selection from Hyperspectral Images Using Attention-based Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1811.02667v3", "summary": "This paper introduces new attention-based convolutional neural networks for\nselecting bands from hyperspectral images. The proposed approach re-uses\nconvolutional activations at different depths, identifying the most informative\nregions of the spectrum with the help of gating mechanisms. Our attention\ntechniques are modular and easy to implement, and they can be seamlessly\ntrained end-to-end using gradient descent. Our rigorous experiments showed that\ndeep models equipped with the attention mechanism deliver high-quality\nclassification, and repeatedly identify significant bands in the training data,\npermitting the creation of refined and extremely compact sets that retain the\nmost meaningful features.", "published": "2018-10-24T19:32:48Z", "version": 3}, {"aid": "1810.10853", "authors": ["Gabriele Valvano", "Nicola Martini", "Andrea Leo", "Gianmarco Santini", "Daniele Della Latta", "Emiliano Ricciardi", "Dante Chiappino"], "title": "Training of a Skull-Stripping Neural Network with efficient data augmentation", "url": "http://arxiv.org/pdf/1810.10853v1", "summary": "Skull-stripping methods aim to remove the non-brain tissue from acquisition\nof brain scans in magnetic resonance (MR) imaging. Although several methods\nsharing this common purpose have been presented in literature, they all suffer\nfrom the great variability of the MR images. In this work we propose a novel\napproach based on Convolutional Neural Networks to automatically perform the\nbrain extraction obtaining cutting-edge performance in the NFBS public\ndatabase. Additionally, we focus on the efficient training of the neural\nnetwork designing an effective data augmentation pipeline. Obtained results are\nevaluated through Dice metric, obtaining a value of 96.5%, and processing time,\nwith 4.5s per volume.", "published": "2018-10-25T13:01:27Z", "version": 1}, {"aid": "1810.10863", "authors": ["Christopher Bowles", "Liang Chen", "Ricardo Guerrero", "Paul Bentley", "Roger Gunn", "Alexander Hammers", "David Alexander Dickie", "Maria Vald\u00e9s Hern\u00e1ndez", "Joanna Wardlaw", "Daniel Rueckert"], "title": "GAN Augmentation: Augmenting Training Data using Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1810.10863v1", "summary": "One of the biggest issues facing the use of machine learning in medical\nimaging is the lack of availability of large, labelled datasets. The annotation\nof medical images is not only expensive and time consuming but also highly\ndependent on the availability of expert observers. The limited amount of\ntraining data can inhibit the performance of supervised machine learning\nalgorithms which often need very large quantities of data on which to train to\navoid overfitting. So far, much effort has been directed at extracting as much\ninformation as possible from what data is available. Generative Adversarial\nNetworks (GANs) offer a novel way to unlock additional information from a\ndataset by generating synthetic samples with the appearance of real images.\nThis paper demonstrates the feasibility of introducing GAN derived synthetic\ndata to the training datasets in two brain segmentation tasks, leading to\nimprovements in Dice Similarity Coefficient (DSC) of between 1 and 5 percentage\npoints under different conditions, with the strongest effects seen fewer than\nten training image stacks are available.", "published": "2018-10-25T13:17:33Z", "version": 1}, {"aid": "1810.11190", "authors": ["Ajay Patel", "Alexander Sands", "Chris Callison-Burch", "Marianna Apidianaki"], "title": "Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package", "url": "http://arxiv.org/pdf/1810.11190v1", "summary": "Vector space embedding models like word2vec, GloVe, fastText, and ELMo are\nextremely popular representations in natural language processing (NLP)\napplications. We present Magnitude, a fast, lightweight tool for utilizing and\nprocessing embeddings. Magnitude is an open source Python package with a\ncompact vector storage file format that allows for efficient manipulation of\nhuge numbers of embeddings. Magnitude performs common operations up to 60 to\n6,000 times faster than Gensim. Magnitude introduces several novel features for\nimproved robustness like out-of-vocabulary lookups.", "published": "2018-10-26T05:04:07Z", "version": 1}, {"aid": "1810.11335", "authors": ["Jirong Yi", "Anh Duc Le", "Tianming Wang", "Xiaodong Wu", "Weiyu Xu"], "title": "Outlier Detection using Generative Models with Theoretical Performance Guarantees", "url": "http://arxiv.org/pdf/1810.11335v1", "summary": "This paper considers the problem of recovering signals from compressed\nmeasurements contaminated with sparse outliers, which has arisen in many\napplications. In this paper, we propose a generative model neural network\napproach for reconstructing the ground truth signals under sparse outliers. We\npropose an iterative alternating direction method of multipliers (ADMM)\nalgorithm for solving the outlier detection problem via $\\ell_1$ norm\nminimization, and a gradient descent algorithm for solving the outlier\ndetection problem via squared $\\ell_1$ norm minimization. We establish the\nrecovery guarantees for reconstruction of signals using generative models in\nthe presence of outliers, and give an upper bound on the number of outliers\nallowed for recovery. Our results are applicable to both the linear generator\nneural network and the nonlinear generator neural network with an arbitrary\nnumber of layers. We conduct extensive experiments using variational\nauto-encoder and deep convolutional generative adversarial networks, and the\nexperimental results show that the signals can be successfully reconstructed\nunder outliers using our approach. Our approach outperforms the traditional\nLasso and $\\ell_2$ minimization approach.", "published": "2018-10-26T14:11:04Z", "version": 1}, {"aid": "1810.11393", "authors": ["Jo\u00e3o Sacramento", "Rui Ponte Costa", "Yoshua Bengio", "Walter Senn"], "title": "Dendritic cortical microcircuits approximate the backpropagation algorithm", "url": "http://arxiv.org/pdf/1810.11393v1", "summary": "Deep learning has seen remarkable developments over the last years, many of\nthem inspired by neuroscience. However, the main learning mechanism behind\nthese advances - error backpropagation - appears to be at odds with\nneurobiology. Here, we introduce a multilayer neuronal network model with\nsimplified dendritic compartments in which error-driven synaptic plasticity\nadapts the network towards a global desired output. In contrast to previous\nwork our model does not require separate phases and synaptic learning is driven\nby local dendritic prediction errors continuously in time. Such errors\noriginate at apical dendrites and occur due to a mismatch between predictive\ninput from lateral interneurons and activity from actual top-down feedback.\nThrough the use of simple dendritic compartments and different cell-types our\nmodel can represent both error and normal activity within a pyramidal neuron.\nWe demonstrate the learning capabilities of the model in regression and\nclassification tasks, and show analytically that it approximates the error\nbackpropagation algorithm. Moreover, our framework is consistent with recent\nobservations of learning between brain areas and the architecture of cortical\nmicrocircuits. Overall, we introduce a novel view of learning on dendritic\ncortical circuits and on how the brain may solve the long-standing synaptic\ncredit assignment problem.", "published": "2018-10-26T15:40:58Z", "version": 1}, {"aid": "1810.11579", "authors": ["Yunpeng Chen", "Yannis Kalantidis", "Jianshu Li", "Shuicheng Yan", "Jiashi Feng"], "title": "$A^2$-Nets: Double Attention Networks", "url": "http://arxiv.org/pdf/1810.11579v1", "summary": "Learning to capture long-range relations is fundamental to image/video\nrecognition. Existing CNN models generally rely on increasing depth to model\nsuch relations which is highly inefficient. In this work, we propose the\n\"double attention block\", a novel component that aggregates and propagates\ninformative global features from the entire spatio-temporal space of input\nimages/videos, enabling subsequent convolution layers to access features from\nthe entire space efficiently. The component is designed with a double attention\nmechanism in two steps, where the first step gathers features from the entire\nspace into a compact set through second-order attention pooling and the second\nstep adaptively selects and distributes features to each location via another\nattention. The proposed double attention block is easy to adopt and can be\nplugged into existing deep neural networks conveniently. We conduct extensive\nablation studies and experiments on both image and video recognition tasks for\nevaluating its performance. On the image recognition task, a ResNet-50 equipped\nwith our double attention blocks outperforms a much larger ResNet-152\narchitecture on ImageNet-1k dataset with over 40% less the number of parameters\nand less FLOPs. On the action recognition task, our proposed model achieves the\nstate-of-the-art results on the Kinetics and UCF-101 datasets with\nsignificantly higher efficiency than recent works.", "published": "2018-10-27T02:32:22Z", "version": 1}, {"aid": "1810.11594", "authors": ["Brian Hu", "Stefan Mihalas"], "title": "Convolutional neural networks with extra-classical receptive fields", "url": "http://arxiv.org/pdf/1810.11594v1", "summary": "Convolutional neural networks (CNNs) have had great success in many\nreal-world applications and have also been used to model visual processing in\nthe brain. However, these networks are quite brittle - small changes in the\ninput image can dramatically change a network's output prediction. In contrast\nto what is known from biology, these networks largely rely on feedforward\nconnections, ignoring the influence of recurrent connections. They also focus\non supervised rather than unsupervised learning. To address these issues, we\ncombine traditional supervised learning via backpropagation with a specialized\nunsupervised learning rule to learn lateral connections between neurons within\na convolutional neural network. These connections have been shown to optimally\nintegrate information from the surround, generating extra-classical receptive\nfields for the neurons in our new proposed model (CNNEx). Models with optimal\nlateral connections are more robust to noise and achieve better performance on\nnoisy versions of the MNIST and CIFAR-10 datasets. Resistance to noise can be\nfurther improved by combining our model with additional regularization\ntechniques such as dropout and weight decay. Although the image statistics of\nMNIST and CIFAR-10 differ greatly, the same unsupervised learning rule\ngeneralized to both datasets. Our results demonstrate the potential usefulness\nof combining supervised and unsupervised learning techniques and suggest that\nthe integration of lateral connections into convolutional neural networks is an\nimportant area of future research.", "published": "2018-10-27T04:15:50Z", "version": 1}, {"aid": "1810.11654", "authors": ["Andriy Myronenko"], "title": "3D MRI brain tumor segmentation using autoencoder regularization", "url": "http://arxiv.org/pdf/1810.11654v3", "summary": "Automated segmentation of brain tumors from 3D magnetic resonance images\n(MRIs) is necessary for the diagnosis, monitoring, and treatment planning of\nthe disease. Manual delineation practices require anatomical knowledge, are\nexpensive, time consuming and can be inaccurate due to human error. Here, we\ndescribe a semantic segmentation network for tumor subregion segmentation from\n3D MRIs based on encoder-decoder architecture. Due to a limited training\ndataset size, a variational auto-encoder branch is added to reconstruct the\ninput image itself in order to regularize the shared decoder and impose\nadditional constraints on its layers. The current approach won 1st place in the\nBraTS 2018 challenge.", "published": "2018-10-27T14:42:13Z", "version": 3}, {"aid": "1811.03009", "authors": ["Yana B. Feygin", "Kelly Morris", "Roman V. Yampolskiy"], "title": "Uploading Brain into Computer: Whom to Upload First?", "url": "http://arxiv.org/pdf/1811.03009v1", "summary": "The final goal of the intelligence augmentation process is a complete merger\nof biological brains and computers allowing for integration and mutual\nenhancement between computer's speed and memory and human's intelligence. This\nprocess, known as uploading, analyzes human brain in detail sufficient to\nunderstand its working patterns and makes it possible to simulate said brain on\na computer. As it is likely that such simulations would quickly evolve or be\nmodified to achieve superintelligence it is very important to make sure that\nthe first brain chosen for such a procedure is a suitable one. In this paper,\nwe attempt to answer the question: Whom to upload first?", "published": "2018-10-27T19:57:47Z", "version": 1}, {"aid": "1810.11787", "authors": ["Karanbir Chahal", "Manraj Singh Grover", "Kuntal Dey"], "title": "A Hitchhiker's Guide On Distributed Training of Deep Neural Networks", "url": "http://arxiv.org/pdf/1810.11787v1", "summary": "Deep learning has led to tremendous advancements in the field of Artificial\nIntelligence. One caveat however is the substantial amount of compute needed to\ntrain these deep learning models. Training a benchmark dataset like ImageNet on\na single machine with a modern GPU can take upto a week, distributing training\non multiple machines has been observed to drastically bring this time down.\nRecent work has brought down ImageNet training time to a time as low as 4\nminutes by using a cluster of 2048 GPUs. This paper surveys the various\nalgorithms and techniques used to distribute training and presents the current\nstate of the art for a modern distributed training framework. More\nspecifically, we explore the synchronous and asynchronous variants of\ndistributed Stochastic Gradient Descent, various All Reduce gradient\naggregation strategies and best practices for obtaining higher throughout and\nlower latency over a cluster such as mixed precision training, large batch\ntraining and gradient compression.", "published": "2018-10-28T09:37:47Z", "version": 1}, {"aid": "1810.11921", "authors": ["Weiping Song", "Chence Shi", "Zhiping Xiao", "Zhijian Duan", "Yewen Xu", "Ming Zhang", "Jian Tang"], "title": "AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks", "url": "http://arxiv.org/pdf/1810.11921v2", "summary": "Click-through rate (CTR) prediction, which aims to predict the probability of\na user clicking on an ad or an item, is critical to many online applications\nsuch as online advertising and recommender systems. The problem is very\nchallenging since (1) the input features (e.g., the user id, user age, item id,\nitem category) are usually sparse and high-dimensional, and (2) an effective\nprediction relies on high-order combinatorial features (\\textit{a.k.a.} cross\nfeatures), which are very time-consuming to hand-craft by domain experts and\nare impossible to be enumerated. Therefore, there have been efforts in finding\nlow-dimensional representations of the sparse and high-dimensional raw features\nand their meaningful combinations. In this paper, we propose an effective and\nefficient method called the \\emph{AutoInt} to automatically learn the\nhigh-order feature interactions of input features. Our proposed algorithm is\nvery general, which can be applied to both numerical and categorical input\nfeatures. Specifically, we map both the numerical and categorical features into\nthe same low-dimensional space. Afterwards, a multi-head self-attentive neural\nnetwork with residual connections is proposed to explicitly model the feature\ninteractions in the low-dimensional space. With different layers of the\nmulti-head self-attentive neural networks, different orders of feature\ncombinations of input features can be modeled. The whole model can be\nefficiently fit on large-scale raw data in an end-to-end fashion. Experimental\nresults on four real-world datasets show that our proposed approach not only\noutperforms existing state-of-the-art approaches for prediction but also offers\ngood explainability. Code is available at:\n\\url{https://github.com/DeepGraphLearning/RecommenderSystems}.", "published": "2018-10-29T01:56:25Z", "version": 2}, {"aid": "1810.12282", "authors": ["Charles Packer", "Katelyn Gao", "Jernej Kos", "Philipp Kr\u00e4henb\u00fchl", "Vladlen Koltun", "Dawn Song"], "title": "Assessing Generalization in Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1810.12282v2", "summary": "Deep reinforcement learning (RL) has achieved breakthrough results on many\ntasks, but agents often fail to generalize beyond the environment they were\ntrained in. As a result, deep RL algorithms that promote generalization are\nreceiving increasing attention. However, works in this area use a wide variety\nof tasks and experimental setups for evaluation. The literature lacks a\ncontrolled assessment of the merits of different generalization schemes. Our\naim is to catalyze community-wide progress on generalization in deep RL. To\nthis end, we present a benchmark and experimental protocol, and conduct a\nsystematic empirical study. Our framework contains a diverse set of\nenvironments, our methodology covers both in-distribution and\nout-of-distribution generalization, and our evaluation includes deep RL\nalgorithms that specifically tackle generalization. Our key finding is that\n`vanilla' deep RL algorithms generalize better than specialized schemes that\nwere proposed specifically to tackle generalization.", "published": "2018-10-29T17:51:46Z", "version": 2}, {"aid": "1810.12575", "authors": ["Tobias Pl\u00f6tz", "Stefan Roth"], "title": "Neural Nearest Neighbors Networks", "url": "http://arxiv.org/pdf/1810.12575v1", "summary": "Non-local methods exploiting the self-similarity of natural signals have been\nwell studied, for example in image analysis and restoration. Existing\napproaches, however, rely on k-nearest neighbors (KNN) matching in a fixed\nfeature space. The main hurdle in optimizing this feature space w.r.t.\napplication performance is the non-differentiability of the KNN selection rule.\nTo overcome this, we propose a continuous deterministic relaxation of KNN\nselection that maintains differentiability w.r.t. pairwise distances, but\nretains the original KNN as the limit of a temperature parameter approaching\nzero. To exploit our relaxation, we propose the neural nearest neighbors block\n(N3 block), a novel non-local processing layer that leverages the principle of\nself-similarity and can be used as building block in modern neural network\narchitectures. We show its effectiveness for the set reasoning task of\ncorrespondence classification as well as for image restoration, including image\ndenoising and single image super-resolution, where we outperform strong\nconvolutional neural network (CNN) baselines and recent non-local models that\nrely on KNN selection in hand-chosen features spaces.", "published": "2018-10-30T08:32:47Z", "version": 1}, {"aid": "1810.12640", "authors": ["Lyes Khacef", "Bernard Girau", "Nicolas Rougier", "Andres Upegui", "Benoit Miramond"], "title": "Neuromorphic hardware as a self-organizing computing system", "url": "http://arxiv.org/pdf/1810.12640v1", "summary": "This paper presents the self-organized neuromorphic architecture named SOMA.\nThe objective is to study neural-based self-organization in computing systems\nand to prove the feasibility of a self-organizing hardware structure.\nConsidering that these properties emerge from large scale and fully connected\nneural maps, we will focus on the definition of a self-organizing hardware\narchitecture based on digital spiking neurons that offer hardware efficiency.\nFrom a biological point of view, this corresponds to a combination of the\nso-called synaptic and structural plasticities. We intend to define\ncomputational models able to simultaneously self-organize at both computation\nand communication levels, and we want these models to be hardware-compliant,\nfault tolerant and scalable by means of a neuro-cellular structure.", "published": "2018-10-30T10:35:07Z", "version": 1}, {"aid": "1810.12850", "authors": ["Robson P. Bonidia", "Luiz A. L. Rodrigues", "Anderson P. Avila-Santos", "Danilo S. Sanches", "Jacques D. Brancher"], "title": "Computational Intelligence in Sports: A Systematic Literature Review", "url": "http://arxiv.org/pdf/1810.12850v1", "summary": "Recently, data mining studies are being successfully conducted to estimate\nseveral parameters in a variety of domains. Data mining techniques have\nattracted the attention of the information industry and society as a whole, due\nto a large amount of data and the imminent need to turn it into useful\nknowledge. However, the effective use of data in some areas is still under\ndevelopment, as is the case in sports, which in recent years, has presented a\nslight growth; consequently, many sports organizations have begun to see that\nthere is a wealth of unexplored knowledge in the data extracted by them.\nTherefore, this article presents a systematic review of sports data mining.\nRegarding years 2010 to 2018, 31 types of research were found in this topic.\nBased on these studies, we present the current panorama, themes, the database\nused, proposals, algorithms, and research opportunities. Our findings provide a\nbetter understanding of the sports data mining potentials, besides motivating\nthe scientific community to explore this timely and interesting topic.", "published": "2018-10-30T16:46:08Z", "version": 1}, {"aid": "1810.12890", "authors": ["Golnaz Ghiasi", "Tsung-Yi Lin", "Quoc V. Le"], "title": "DropBlock: A regularization method for convolutional networks", "url": "http://arxiv.org/pdf/1810.12890v1", "summary": "Deep neural networks often work well when they are over-parameterized and\ntrained with a massive amount of noise and regularization, such as weight decay\nand dropout. Although dropout is widely used as a regularization technique for\nfully connected layers, it is often less effective for convolutional layers.\nThis lack of success of dropout for convolutional layers is perhaps due to the\nfact that activation units in convolutional layers are spatially correlated so\ninformation can still flow through convolutional networks despite dropout. Thus\na structured form of dropout is needed to regularize convolutional networks. In\nthis paper, we introduce DropBlock, a form of structured dropout, where units\nin a contiguous region of a feature map are dropped together. We found that\napplying DropbBlock in skip connections in addition to the convolution layers\nincreases the accuracy. Also, gradually increasing number of dropped units\nduring training leads to better accuracy and more robust to hyperparameter\nchoices. Extensive experiments show that DropBlock works better than dropout in\nregularizing convolutional networks. On ImageNet classification, ResNet-50\narchitecture with DropBlock achieves $78.13\\%$ accuracy, which is more than\n$1.6\\%$ improvement on the baseline. On COCO detection, DropBlock improves\nAverage Precision of RetinaNet from $36.8\\%$ to $38.4\\%$.", "published": "2018-10-30T17:39:42Z", "version": 1}, {"aid": "1811.02636", "authors": ["Qiuwen Lou", "Chenyun Pan", "John McGuiness", "Andras Horvath", "Azad Naeemi", "Michael Niemier", "X. Sharon Hu"], "title": "A mixed signal architecture for convolutional neural networks", "url": "http://arxiv.org/pdf/1811.02636v4", "summary": "Deep neural network (DNN) accelerators with improved energy and delay are\ndesirable for meeting the requirements of hardware targeted for IoT and edge\ncomputing systems. Convolutional neural networks (CoNNs) belong to one of the\nmost popular types of DNN architectures. This paper presents the design and\nevaluation of an accelerator for CoNNs. The system-level architecture is based\non mixed-signal, cellular neural networks (CeNNs). Specifically, we present (i)\nthe implementation of different layers, including convolution, ReLU, and\npooling, in a CoNN using CeNN, (ii) modified CoNN structures with CeNN-friendly\nlayers to reduce computational overheads typically associated with a CoNN,\n(iii) a mixed-signal CeNN architecture that performs CoNN computations in the\nanalog and mixed signal domain, and (iv) design space exploration that\nidentifies what CeNN-based algorithm and architectural features fare best\ncompared to existing algorithms and architectures when evaluated over common\ndatasets -- MNIST and CIFAR-10. Notably, the proposed approach can lead to\n8.7$\\times$ improvements in energy-delay product (EDP) per digit classification\nfor the MNIST dataset at iso-accuracy when compared with the state-of-the-art\nDNN engine, while our approach could offer 4.3$\\times$ improvements in EDP when\ncompared to other network implementations for the CIFAR-10 dataset.", "published": "2018-10-30T18:51:57Z", "version": 4}, {"aid": "1810.13135", "authors": ["Naima Chouikhi", "Adel M. Alimi"], "title": "Adaptive Extreme Learning Machine for Recurrent Beta-basis Function Neural Network Training", "url": "http://arxiv.org/pdf/1810.13135v1", "summary": "Beta Basis Function Neural Network (BBFNN) is a special kind of kernel basis\nneural networks. It is a feedforward network typified by the use of beta\nfunction as a hidden activation function. Beta is a flexible transfer function\nrepresenting richer forms than the common existing functions. As in every\nnetwork, the architecture setting as well as the learning method are two main\ngauntlets faced by BBFNN. In this paper, new architecture and training\nalgorithm are proposed for the BBFNN. An Extreme Learning Machine (ELM) is used\nas a training approach of BBFNN with the aim of quickening the training\nprocess. The peculiarity of ELM is permitting a certain decrement of the\ncomputing time and complexity regarding the already used BBFNN learning\nalgorithms such as backpropagation, OLS, etc. For the architectural design, a\nrecurrent structure is added to the common BBFNN architecture in order to make\nit more able to deal with complex, non linear and time varying problems.\nThroughout this paper, the conceived recurrent ELM-trained BBFNN is tested on a\nnumber of tasks related to time series prediction, classification and\nregression. Experimental results show noticeable achievements of the proposed\nnetwork compared to common feedforward and recurrent networks trained by ELM\nand using hyperbolic tangent as activation function. These achievements are in\nterms of accuracy and robustness against data breakdowns such as noise signals.", "published": "2018-10-31T07:31:08Z", "version": 1}, {"aid": "1811.02656", "authors": ["Titouan Parcollet", "Mohamed Morchid", "Georges Linar\u00e8s"], "title": "Quaternion Convolutional Neural Networks for Heterogeneous Image Processing", "url": "http://arxiv.org/pdf/1811.02656v1", "summary": "Convolutional neural networks (CNN) have recently achieved state-of-the-art\nresults in various applications. In the case of image recognition, an ideal\nmodel has to learn independently of the training data, both local dependencies\nbetween the three components (R,G,B) of a pixel, and the global relations\ndescribing edges or shapes, making it efficient with small or heterogeneous\ndatasets. Quaternion-valued convolutional neural networks (QCNN) solved this\nproblematic by introducing multidimensional algebra to CNN. This paper proposes\nto explore the fundamental reason of the success of QCNN over CNN, by\ninvestigating the impact of the Hamilton product on a color image\nreconstruction task performed from a gray-scale only training. By learning\nindependently both internal and external relations and with less parameters\nthan real valued convolutional encoder-decoder (CAE), quaternion convolutional\nencoder-decoders (QCAE) perfectly reconstructed unseen color images while CAE\nproduced worst and gray-scale versions.", "published": "2018-10-31T11:22:54Z", "version": 1}, {"aid": "1810.13306", "authors": ["Zhenqian Shen", "Yongqi Zhang", "Lanning Wei", "Huan Zhao", "Quanming Yao"], "title": "Automated Machine Learning: From Principles to Practices", "url": "http://arxiv.org/pdf/1810.13306v5", "summary": "Machine learning (ML) methods have been developing rapidly, but configuring\nand selecting proper methods to achieve a desired performance is increasingly\ndifficult and tedious. To address this challenge, automated machine learning\n(AutoML) has emerged, which aims to generate satisfactory ML configurations for\ngiven tasks in a data-driven way. In this paper, we provide a comprehensive\nsurvey on this topic. We begin with the formal definition of AutoML and then\nintroduce its principles, including the bi-level learning objective, the\nlearning strategy, and the theoretical interpretation. Then, we summarize the\nAutoML practices by setting up the taxonomy of existing works based on three\nmain factors: the search space, the search algorithm, and the evaluation\nstrategy. Each category is also explained with the representative methods.\nThen, we illustrate the principles and practices with exemplary applications\nfrom configuring ML pipeline, one-shot neural architecture search, and\nintegration with foundation models. Finally, we highlight the emerging\ndirections of AutoML and conclude the survey.", "published": "2018-10-31T14:35:38Z", "version": 5}, {"aid": "1810.13373", "authors": ["David G. T. Barrett", "Ari S. Morcos", "Jakob H. Macke"], "title": "Analyzing biological and artificial neural networks: challenges with opportunities for synergy?", "url": "http://arxiv.org/pdf/1810.13373v1", "summary": "Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\n  We review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.", "published": "2018-10-31T16:09:44Z", "version": 1}, {"aid": "1811.00231", "authors": ["Benjamin James Lansdell", "Konrad Paul Kording"], "title": "Towards learning-to-learn", "url": "http://arxiv.org/pdf/1811.00231v3", "summary": "In good old-fashioned artificial intelligence (GOFAI), humans specified\nsystems that solved problems. Much of the recent progress in AI has come from\nreplacing human insights by learning. However, learning itself is still usually\nbuilt by humans -- specifically the choice that parameter updates should follow\nthe gradient of a cost function. Yet, in analogy with GOFAI, there is no reason\nto believe that humans are particularly good at defining such learning systems:\nwe may expect learning itself to be better if we learn it. Recent research in\nmachine learning has started to realize the benefits of that strategy. We\nshould thus expect this to be relevant for neuroscience: how could the correct\nlearning rules be acquired? Indeed, cognitive science has long shown that\nhumans learn-to-learn, which is potentially responsible for their impressive\nlearning abilities. Here we discuss ideas across machine learning,\nneuroscience, and cognitive science that matter for the principle of\nlearning-to-learn.", "published": "2018-11-01T05:07:49Z", "version": 3}, {"aid": "1811.00323", "authors": ["Emna Krichene", "Wael Ouarda", "Habib Chabchoub", "Adel M. Alimi"], "title": "Taylor-based Optimized Recursive Extended Exponential Smoothed Neural Networks Forecasting Method", "url": "http://arxiv.org/pdf/1811.00323v1", "summary": "A newly introduced method called Taylor-based Optimized Recursive Extended\nExponential Smoothed Neural Networks Forecasting method is applied and extended\nin this study to forecast numerical values. Unlike traditional forecasting\ntechniques which forecast only future values, our proposed method provides a\nnew extension to correct the predicted values which is done by forecasting the\nestimated error. Experimental results demonstrated that the proposed method has\na high accuracy both in training and testing data and outperform the\nstate-of-the-art RNN models on Mackey-Glass, NARMA, Lorenz and Henon map\ndatasets.", "published": "2018-11-01T11:39:49Z", "version": 1}, {"aid": "1811.00796", "authors": ["Mitsuru Kusumoto", "Keisuke Yahata", "Masahiro Sakai"], "title": "Automated Theorem Proving in Intuitionistic Propositional Logic by Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1811.00796v1", "summary": "The problem-solving in automated theorem proving (ATP) can be interpreted as\na search problem where the prover constructs a proof tree step by step. In this\npaper, we propose a deep reinforcement learning algorithm for proof search in\nintuitionistic propositional logic. The most significant challenge in the\napplication of deep learning to the ATP is the absence of large, public theorem\ndatabase. We, however, overcame this issue by applying a novel data\naugmentation procedure at each iteration of the reinforcement learning. We also\nimprove the efficiency of the algorithm by representing the syntactic structure\nof formulas by a novel compact graph representation. Using the large volume of\naugmented data, we train highly accurate graph neural networks that approximate\nthe value function for the set of the syntactic structures of formulas. Our\nmethod is also cost-efficient in terms of computational time. We will show that\nour prover outperforms Coq's $\\texttt{tauto}$ tactic, a prover based on\nhuman-engineered heuristics. Within the specified time limit, our prover solved\n84% of the theorems in a benchmark library, while $\\texttt{tauto}$ was able to\nsolve only 52%.", "published": "2018-11-02T09:49:18Z", "version": 1}, {"aid": "1811.00876", "authors": ["Deniz Lefkeli", "Baris Akgun", "Sahibzada Omar", "Aansa Malik", "Zeynep Gurhan Canli", "Terry Eskenazi"], "title": "Mind in the Machine: Perceived Minds Induce Decision Change", "url": "http://arxiv.org/pdf/1811.00876v1", "summary": "Recent research on human robot interaction explored whether people's tendency\nto conform to others extends to artificial agents (Hertz & Wiese, 2016).\nHowever, little is known about to what extent perception of a robot as having a\nmind affects people's decisions. Grounded on the theory of mind perception, the\ncurrent study proposes that artificial agents can induce decision change to the\nextent in which individuals perceive them as having minds. By varying the\ndegree to which robots expressed ability to act (agency) or feel (experience),\nwe specifically investigated the underlying mechanisms of mind attribution to\nrobots and social influence. Our results show an interactive effect of\nperceived experience and perceived agency on social influence induced by\nartificial agents. The findings provide preliminary insights regarding\nautonomous robots' influence on individuals' decisions and form a basis for\nunderstanding the underlying dynamics of decision making with robots.", "published": "2018-11-02T14:22:47Z", "version": 1}, {"aid": "1811.00941", "authors": ["Andrey Babichev", "Dmitriy Morozov", "Yuri Dabaghian"], "title": "Replays of spatial memories suppress topological fluctuations in cognitive map", "url": "http://arxiv.org/pdf/1811.00941v1", "summary": "The spiking activity of the hippocampal place cells plays a key role in\nproducing and sustaining an internalized representation of the ambient\nspace---a cognitive map. These cells do not only exhibit location-specific\nspiking during navigation, but also may rapidly replay the navigated routs\nthrough endogenous dynamics of the hippocampal network. Physiologically, such\nreactivations are viewed as manifestations of \"memory replays\" that help to\nlearn new information and to consolidate previously acquired memories by\nreinforcing synapses in the parahippocampal networks. Below we propose a\ncomputational model of these processes that allows assessing the effect of\nreplays on acquiring a robust topological map of the environment and\ndemonstrate that replays may play a key role in stabilizing the hippocampal\nrepresentation of space.", "published": "2018-11-02T15:43:40Z", "version": 1}, {"aid": "1811.00995", "authors": ["Jens Behrmann", "Will Grathwohl", "Ricky T. Q. Chen", "David Duvenaud", "J\u00f6rn-Henrik Jacobsen"], "title": "Invertible Residual Networks", "url": "http://arxiv.org/pdf/1811.00995v3", "summary": "We show that standard ResNet architectures can be made invertible, allowing\nthe same model to be used for classification, density estimation, and\ngeneration. Typically, enforcing invertibility requires partitioning dimensions\nor restricting network architectures. In contrast, our approach only requires\nadding a simple normalization step during training, already available in\nstandard frameworks. Invertible ResNets define a generative model which can be\ntrained by maximum likelihood on unlabeled data. To compute likelihoods, we\nintroduce a tractable approximation to the Jacobian log-determinant of a\nresidual block. Our empirical evaluation shows that invertible ResNets perform\ncompetitively with both state-of-the-art image classifiers and flow-based\ngenerative models, something that has not been previously achieved with a\nsingle architecture.", "published": "2018-11-02T17:17:55Z", "version": 3}, {"aid": "1811.01199", "authors": ["Christoph von der Malsburg"], "title": "Concerning the Neural Code", "url": "http://arxiv.org/pdf/1811.01199v1", "summary": "The central problem with understanding brain and mind is the neural code\nissue: understanding the matter of our brain as basis for the phenomena of our\nmind. The richness with which our mind represents our environment, the\nparsimony of genetic data, the tremendous efficiency with which the brain\nlearns from scant sensory input and the creativity with which our mind\nconstructs mental worlds all speak in favor of mind as an emergent phenomenon.\nThis raises the further issue of how the neural code supports these processes\nof organization. The central point of this communication is that the neural\ncode has the form of structured net fragments that are formed by network\nself-organization, activate and de-activate on the functional time scale, and\nspontaneously combine to form larger nets with the same basic structure.", "published": "2018-11-03T12:35:44Z", "version": 1}, {"aid": "1811.01545", "authors": ["P. Guo", "K. Wang", "X. L. Zhou"], "title": "PILAE: A Non-gradient Descent Learning Scheme for Deep Feedforward Neural Networks", "url": "http://arxiv.org/pdf/1811.01545v3", "summary": "In this work, a non-gradient descent learning (NGDL) scheme was proposed for\ndeep feedforward neural networks (DNN). It is known that an autoencoder can be\nused as the building blocks of the multi-layer perceptron (MLP) DNN, the MLP is\ntaken as an example to illustrate the proposed scheme of pseudoinverse learning\nalgorithm for autoencoder (PILAE) in this paper. The PILAE with low rank\napproximation is a NGDL algorithm, and the encoder weight matrix is set to be\nthe low rank approximation of the pseudoinverse of the input matrix, while the\ndecoder weight matrix is calculated by the pseudoinverse learning algorithm. It\nis worth to note that only very few network structure hyper-parameters need to\nbe tuned compared with classical gradient descent learning algorithm. Hence,\nthe proposed algorithm could be regarded as a quasi-automated training\nalgorithm which could be utilized in automated machine learning field. The\nexperimental results show that the proposed learning scheme for DNN could\nachieve better performance on considering the tradeoff between training\nefficiency and classification accuracy.", "published": "2018-11-05T08:14:11Z", "version": 3}, {"aid": "1811.02130", "authors": ["Prem Seetharaman", "Gordon Wichern", "Jonathan Le Roux", "Bryan Pardo"], "title": "Bootstrapping single-channel source separation via unsupervised spatial clustering on stereo mixtures", "url": "http://arxiv.org/pdf/1811.02130v1", "summary": "Separating an audio scene into isolated sources is a fundamental problem in\ncomputer audition, analogous to image segmentation in visual scene analysis.\nSource separation systems based on deep learning are currently the most\nsuccessful approaches for solving the underdetermined separation problem, where\nthere are more sources than channels. Traditionally, such systems are trained\non sound mixtures where the ground truth decomposition is already known. Since\nmost real-world recordings do not have such a decomposition available, this\nlimits the range of mixtures one can train on, and the range of mixtures the\nlearned models may successfully separate. In this work, we use a simple blind\nspatial source separation algorithm to generate estimated decompositions of\nstereo mixtures. These estimates, together with a weighting scheme in the\ntime-frequency domain, based on confidence in the separation quality, are used\nto train a deep learning model that can be used for single-channel separation,\nwhere no source direction information is available. This demonstrates how a\nsimple cue such as the direction of origin of source can be used to bootstrap a\nmodel for source separation that can be used in situations where that cue is\nnot available.", "published": "2018-11-06T02:20:40Z", "version": 1}, {"aid": "1811.02191", "authors": ["Ali Cheraghian", "Lars Petersson"], "title": "3DCapsule: Extending the Capsule Architecture to Classify 3D Point Clouds", "url": "http://arxiv.org/pdf/1811.02191v1", "summary": "This paper introduces the 3DCapsule, which is a 3D extension of the recently\nintroduced Capsule concept that makes it applicable to unordered point sets.\nThe original Capsule relies on the existence of a spatial relationship between\nthe elements in the feature map it is presented with, whereas in point\npermutation invariant formulations of 3D point set classification methods, such\nrelationships are typically lost. Here, a new layer called ComposeCaps is\nintroduced that, in lieu of a spatially relevant feature mapping, learns a new\nmapping that can be exploited by the 3DCapsule. Previous works in the 3D point\nset classification domain have focused on other parts of the architecture,\nwhereas instead, the 3DCapsule is a drop-in replacement of the commonly used\nfully connected classifier. It is demonstrated via an ablation study, that when\nthe 3DCapsule is applied to recent 3D point set classification architectures,\nit consistently shows an improvement, in particular when subjected to noisy\ndata. Similarly, the ComposeCaps layer is evaluated and demonstrates an\nimprovement over the baseline. In an apples-to-apples comparison against\nstate-of-the-art methods, again, better performance is demonstrated by the\n3DCapsule.", "published": "2018-11-06T06:57:49Z", "version": 1}, {"aid": "1811.02290", "authors": ["Qi Yan", "Yajing Zheng", "Shanshan Jia", "Yichen Zhang", "Zhaofei Yu", "Feng Chen", "Yonghong Tian", "Tiejun Huang", "Jian K. Liu"], "title": "Revealing Fine Structures of the Retinal Receptive Field by Deep Learning Networks", "url": "http://arxiv.org/pdf/1811.02290v2", "summary": "Deep convolutional neural networks (CNNs) have demonstrated impressive\nperformance on many visual tasks. Recently, they became useful models for the\nvisual system in neuroscience. However, it is still not clear what are learned\nby CNNs in terms of neuronal circuits. When a deep CNN with many layers is used\nfor the visual system, it is not easy to compare the structure components of\nCNNs with possible neuroscience underpinnings due to highly complex circuits\nfrom the retina to higher visual cortex. Here we address this issue by focusing\non single retinal ganglion cells with biophysical models and recording data\nfrom animals. By training CNNs with white noise images to predict neuronal\nresponses, we found that fine structures of the retinal receptive field can be\nrevealed. Specifically, convolutional filters learned are resembling biological\ncomponents of the retinal circuit. This suggests that a CNN learning from one\nsingle retinal cell reveals a minimal neural network carried out in this cell.\nFurthermore, when CNNs learned from different cells are transferred between\ncells, there is a diversity of transfer learning performance, which indicates\nthat CNNs are cell-specific. Moreover, when CNNs are transferred between\ndifferent types of input images, here white noise v.s. natural images, transfer\nlearning shows a good performance, which implies that CNNs indeed capture the\nfull computational ability of a single retinal cell for different inputs. Taken\ntogether, these results suggest that CNNs could be used to reveal structure\ncomponents of neuronal circuits, and provide a powerful model for neural system\nidentification.", "published": "2018-11-06T11:20:46Z", "version": 2}, {"aid": "1811.02353", "authors": ["Xian-Rui Zhang", "Meng-Ying Lei", "Yang Li"], "title": "An amplitudes-perturbation data augmentation method in convolutional neural networks for EEG decoding", "url": "http://arxiv.org/pdf/1811.02353v1", "summary": "Brain-Computer Interface (BCI) system provides a pathway between humans and\nthe outside world by analyzing brain signals which contain potential neural\ninformation. Electroencephalography (EEG) is one of most commonly used brain\nsignals and EEG recognition is an important part of BCI system. Recently,\nconvolutional neural networks (ConvNet) in deep learning are becoming the new\ncutting edge tools to tackle the problem of EEG recognition. However, training\nan effective deep learning model requires a big number of data, which limits\nthe application of EEG datasets with a small number of samples. In order to\nsolve the issue of data insufficiency in deep learning for EEG decoding, we\npropose a novel data augmentation method that add perturbations to amplitudes\nof EEG signals after transform them to frequency domain. In experiments, we\nexplore the performance of signal recognition with the state-of-the-art models\nbefore and after data augmentation on BCI Competition IV dataset 2a and our\nlocal dataset. The results show that our data augmentation technique can\nimprove the accuracy of EEG recognition effectively.", "published": "2018-11-06T14:00:05Z", "version": 1}, {"aid": "1811.04760", "authors": ["Steven Gratton"], "title": "Quantum Reasoning using Lie Algebra for Everyday Life (and AI perhaps...)", "url": "http://arxiv.org/pdf/1811.04760v1", "summary": "We investigate the applicability of the formalism of quantum mechanics to\neveryday life. It seems to be directly relevant for situations in which the\nvery act of coming to a conclusion or decision on one issue affects one's\nconfidence about conclusions or decisions on another issue. Lie algebra theory\nis argued to be a very useful tool in guiding the construction of quantum\ndescriptions of such situations. Tests, extensions and speculative applications\nand implications, including for the encoding of thoughts in neural networks,\nare discussed. It is suggested that the recognition and incorporation of such\nmathematical structure into machine learning and artificial intelligence might\nlead to significant efficiency and generality gains in addition to ensuring\nprobabilistic reasoning at a fundamental level.", "published": "2018-11-06T15:08:08Z", "version": 1}, {"aid": "1811.02454", "authors": ["Chen Lin", "Zhao Zhong", "Wei Wu", "Junjie Yan"], "title": "Synaptic Strength For Convolutional Neural Network", "url": "http://arxiv.org/pdf/1811.02454v1", "summary": "Convolutional Neural Networks(CNNs) are both computation and memory intensive\nwhich hindered their deployment in mobile devices. Inspired by the relevant\nconcept in neural science literature, we propose Synaptic Pruning: a\ndata-driven method to prune connections between input and output feature maps\nwith a newly proposed class of parameters called Synaptic Strength. Synaptic\nStrength is designed to capture the importance of a connection based on the\namount of information it transports. Experiment results show the effectiveness\nof our approach. On CIFAR-10, we prune connections for various CNN models with\nup to 96% , which results in significant size reduction and computation saving.\nFurther evaluation on ImageNet demonstrates that synaptic pruning is able to\ndiscover efficient models which is competitive to state-of-the-art compact CNNs\nsuch as MobileNet-V2 and NasNet-Mobile. Our contribution is summarized as\nfollowing: (1) We introduce Synaptic Strength, a new class of parameters for\nCNNs to indicate the importance of each connections. (2) Our approach can prune\nvarious CNNs with high compression without compromising accuracy. (3) Further\ninvestigation shows, the proposed Synaptic Strength is a better indicator for\nkernel pruning compared with the previous approach in both empirical result and\ntheoretical analysis.", "published": "2018-11-06T16:06:49Z", "version": 1}, {"aid": "1811.06825", "authors": ["Jerome Feldman"], "title": "Towards a Science of Mind", "url": "http://arxiv.org/pdf/1811.06825v3", "summary": "The ancient mind/body problem continues to be one of deepest mysteries of\nscience and of the human spirit. Despite major advances in many fields, there\nis still no plausible link between subjective experience (qualia) and its\nrealization in the body. This paper outlines some of the elements of a rigorous\nscience of mind (SoM) - key ideas include scientific realism of mind, agnostic\nmysterianism, careful attention to language, and a focus on concrete\n(touchstone) questions and results. A core suggestion is to focus effort on the\n(still mysterious) mapping from neural activity to subjective experience.", "published": "2018-11-06T18:02:40Z", "version": 3}, {"aid": "1811.02546", "authors": ["Paul Yaworsky"], "title": "A Model for General Intelligence", "url": "http://arxiv.org/pdf/1811.02546v2", "summary": "The overarching problem in artificial intelligence (AI) is that we do not\nunderstand the intelligence process well enough to enable the development of\nadequate computational models. Much work has been done in AI over the years at\nlower levels, but a big part of what has been missing involves the high level,\nabstract, general nature of intelligence. We address this gap by developing a\nmodel for general intelligence. To accomplish this, we focus on three basic\naspects of intelligence. First, we must realize the general order and nature of\nintelligence at a high level. Second, we must come to know what these\nrealizations mean with respect to the overall intelligence process. Third, we\nmust describe these realizations as clearly as possible. We propose a\nhierarchical model to help capture and exploit the order within intelligence.\nThe underlying order involves patterns of signals that become organized, stored\nand activated in space and time. These patterns can be described using a\nsimple, general hierarchy, with physical signals at the lowest level,\ninformation in the middle, and abstract signal representations at the top. This\nhigh level perspective provides a big picture that literally helps us see the\nintelligence process, thereby enabling fundamental realizations, a better\nunderstanding and clear descriptions of the intelligence process. The resulting\nmodel can be used to support all kinds of information processing across\nmultiple levels of abstraction. As computer technology improves, and as\ncooperation increases between humans and computers, people will become more\nefficient and more productive in performing their information processing tasks.", "published": "2018-11-06T18:37:04Z", "version": 2}, {"aid": "1811.02597", "authors": ["Sina Ghiassian", "Andrew Patterson", "Martha White", "Richard S. Sutton", "Adam White"], "title": "Online Off-policy Prediction", "url": "http://arxiv.org/pdf/1811.02597v1", "summary": "This paper investigates the problem of online prediction learning, where\nlearning proceeds continuously as the agent interacts with an environment. The\npredictions made by the agent are contingent on a particular way of behaving,\nrepresented as a value function. However, the behavior used to select actions\nand generate the behavior data might be different from the one used to define\nthe predictions, and thus the samples are generated off-policy. The ability to\nlearn behavior-contingent predictions online and off-policy has long been\nadvocated as a key capability of predictive-knowledge learning systems but\nremained an open algorithmic challenge for decades. The issue lies with the\ntemporal difference (TD) learning update at the heart of most prediction\nalgorithms: combining bootstrapping, off-policy sampling and function\napproximation may cause the value estimate to diverge. A breakthrough came with\nthe development of a new objective function that admitted stochastic gradient\ndescent variants of TD. Since then, many sound online off-policy prediction\nalgorithms have been developed, but there has been limited empirical work\ninvestigating the relative merits of all the variants. This paper aims to fill\nthese empirical gaps and provide clarity on the key ideas behind each method.\nWe summarize the large body of literature on off-policy learning, focusing on\n1- methods that use computation linear in the number of features and are\nconvergent under off-policy sampling, and 2- other methods which have proven\nuseful with non-fixed, nonlinear function approximation. We provide an\nempirical study of off-policy prediction methods in two challenging\nmicroworlds. We report each method's parameter sensitivity, empirical\nconvergence rate, and final performance, providing new insights that should\nenable practitioners to successfully extend these new methods to large-scale\napplications.[Abridged abstract]", "published": "2018-11-06T19:09:04Z", "version": 1}, {"aid": "1811.02617", "authors": ["Kieran Greer"], "title": "Category Trees", "url": "http://arxiv.org/pdf/1811.02617v6", "summary": "This paper presents a batch classifier that has been improved from the\nearlier version and fixed a mistake in the earlier paper. Two important changes\nhave been made. Each category is represented by a classifier, where each\nclassifier classifies its own subset of data rows, using batch input values to\nrepresent the centroid. The first change is to use the category centroid as the\ndesired category output. When the classifier represents more than one category,\nit creates a new layer and splits, to represent each category separately in the\nnew layer. The second change therefore, is to allow the classifier to branch to\nnew levels when there is a split in the data, or when some data rows are\nincorrectly classified. Each layer can therefore branch like a tree - not for\ndistinguishing features, but for distinguishing categories. The paper then\nsuggests further innovations, by adding fixed value ranges through bands, for\neach column or feature of the input dataset. When considering features, it is\nshown that some of the data can be classified directly through fixed value\nranges, while the rest can be classified using the classifier technique. Tests\nshow that the method can successfully classify a diverse set of benchmark\ndatasets to better than the state-of-the-art. The paper also discusses a\nbiological analogy with neurons and neuron links.", "published": "2018-11-06T20:21:26Z", "version": 6}, {"aid": "1811.02942", "authors": ["Shahab Aslani", "Michael Dayan", "Loredana Storelli", "Massimo Filippi", "Vittorio Murino", "Maria A Rocca", "Diego Sona"], "title": "Multi-branch Convolutional Neural Network for Multiple Sclerosis Lesion Segmentation", "url": "http://arxiv.org/pdf/1811.02942v4", "summary": "In this paper, we present an automated approach for segmenting multiple\nsclerosis (MS) lesions from multi-modal brain magnetic resonance images. Our\nmethod is based on a deep end-to-end 2D convolutional neural network (CNN) for\nslice-based segmentation of 3D volumetric data. The proposed CNN includes a\nmulti-branch downsampling path, which enables the network to encode information\nfrom multiple modalities separately. Multi-scale feature fusion blocks are\nproposed to combine feature maps from different modalities at different stages\nof the network. Then, multi-scale feature upsampling blocks are introduced to\nupsize combined feature maps to leverage information from lesion shape and\nlocation. We trained and tested the proposed model using orthogonal plane\norientations of each 3D modality to exploit the contextual information in all\ndirections. The proposed pipeline is evaluated on two different datasets: a\nprivate dataset including 37 MS patients and a publicly available dataset known\nas the ISBI 2015 longitudinal MS lesion segmentation challenge dataset,\nconsisting of 14 MS patients. Considering the ISBI challenge, at the time of\nsubmission, our method was amongst the top performing solutions. On the private\ndataset, using the same array of performance metrics as in the ISBI challenge,\nthe proposed approach shows high improvements in MS lesion segmentation\ncompared with other publicly available tools.", "published": "2018-11-07T15:42:57Z", "version": 4}, {"aid": "1811.03120", "authors": ["Vincent Billaut", "Matthieu de Rochemonteix", "Marc Thibault"], "title": "ColorUNet: A convolutional classification approach to colorization", "url": "http://arxiv.org/pdf/1811.03120v1", "summary": "This paper tackles the challenge of colorizing grayscale images. We take a\ndeep convolutional neural network approach, and choose to take the angle of\nclassification, working on a finite set of possible colors. Similarly to a\nrecent paper, we implement a loss and a prediction function that favor\nrealistic, colorful images rather than \"true\" ones.\n  We show that a rather lightweight architecture inspired by the U-Net, and\ntrained on a reasonable amount of pictures of landscapes, achieves satisfactory\nresults on this specific subset of pictures. We show that data augmentation\nsignificantly improves the performance and robustness of the model, and provide\nvisual analysis of the prediction confidence.\n  We show an application of our model, extending the task to video\ncolorization. We suggest a way to smooth color predictions across frames,\nwithout the need to train a recurrent network designed for sequential inputs.", "published": "2018-11-07T19:20:59Z", "version": 1}, {"aid": "1811.03151", "authors": ["K. Gretchen Greene"], "title": "DragonPaint: Rule based bootstrapping for small data with an application to cartoon coloring", "url": "http://arxiv.org/pdf/1811.03151v1", "summary": "In this paper, we confront the problem of deep learning's big labeled data\nrequirements, offer a rule based strategy for extreme augmentation of small\ndata sets and apply that strategy with the image to image translation model by\nIsola et al. (2016) to automate cel style cartoon coloring with very limited\ntraining data. While our experimental results using geometric rules and\ntransformations demonstrate the performance of our methods on an image\ntranslation task with industry applications in art, design and animation, we\nalso propose the use of rules on partial data sets as a generalizable small\ndata strategy, potentially applicable across data types and domains.", "published": "2018-11-07T21:23:31Z", "version": 1}, {"aid": "1811.03376", "authors": ["Xi Chen", "Ali Ghadirzadeh", "M\u00e5rten Bj\u00f6rkman", "Patric Jensfelt"], "title": "Meta-Learning for Multi-objective Reinforcement Learning", "url": "http://arxiv.org/pdf/1811.03376v2", "summary": "Multi-objective reinforcement learning (MORL) is the generalization of\nstandard reinforcement learning (RL) approaches to solve sequential decision\nmaking problems that consist of several, possibly conflicting, objectives.\nGenerally, in such formulations, there is no single optimal policy which\noptimizes all the objectives simultaneously, and instead, a number of policies\nhas to be found each optimizing a preference of the objectives. In other words,\nthe MORL is framed as a meta-learning problem, with the task distribution given\nby a distribution over the preferences. We demonstrate that such a formulation\nresults in a better approximation of the Pareto optimal solutions in terms of\nboth the optimality and the computational efficiency. We evaluated our method\non obtaining Pareto optimal policies using a number of continuous control\nproblems with high degrees of freedom.", "published": "2018-11-08T12:26:42Z", "version": 2}, {"aid": "1811.03378", "authors": ["Chigozie Nwankpa", "Winifred Ijomah", "Anthony Gachagan", "Stephen Marshall"], "title": "Activation Functions: Comparison of trends in Practice and Research for Deep Learning", "url": "http://arxiv.org/pdf/1811.03378v1", "summary": "Deep neural networks have been successfully used in diverse emerging domains\nto solve real world complex problems with may more deep learning(DL)\narchitectures, being developed to date. To achieve these state-of-the-art\nperformances, the DL architectures use activation functions (AFs), to perform\ndiverse computations between the hidden layers and the output layers of any\ngiven DL architecture. This paper presents a survey on the existing AFs used in\ndeep learning applications and highlights the recent trends in the use of the\nactivation functions for deep learning applications. The novelty of this paper\nis that it compiles majority of the AFs used in DL and outlines the current\ntrends in the applications and usage of these functions in practical deep\nlearning deployments against the state-of-the-art research results. This\ncompilation will aid in making effective decisions in the choice of the most\nsuitable and appropriate activation function for any given application, ready\nfor deployment. This paper is timely because most research papers on AF\nhighlights similar works and results while this paper will be the first, to\ncompile the trends in AF applications in practice against the research results\nfrom literature, found in deep learning research to date.", "published": "2018-11-08T12:28:43Z", "version": 1}, {"aid": "1811.03567", "authors": ["Will Xiao", "Honglin Chen", "Qianli Liao", "Tomaso Poggio"], "title": "Biologically-plausible learning algorithms can scale to large datasets", "url": "http://arxiv.org/pdf/1811.03567v3", "summary": "The backpropagation (BP) algorithm is often thought to be biologically\nimplausible in the brain. One of the main reasons is that BP requires symmetric\nweight matrices in the feedforward and feedback pathways. To address this\n\"weight transport problem\" (Grossberg, 1987), two more biologically plausible\nalgorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax\nBP's weight symmetry requirements and demonstrate comparable learning\ncapabilities to that of BP on small datasets. However, a recent study by\nBartunov et al. (2018) evaluate variants of target-propagation (TP) and\nfeedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that\nalthough many of the proposed algorithms perform well on MNIST and CIFAR, they\nperform significantly worse than BP on ImageNet. Here, we additionally evaluate\nthe sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and\nFA in that the feedback and feedforward weights share signs but not magnitudes.\nWe examine the performance of sign-symmetry and feedback alignment on ImageNet\nand MS COCO datasets using different network architectures (ResNet-18 and\nAlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained\nwith sign-symmetry can attain classification performance approaching that of\nBP-trained networks. These results complement the study by Bartunov et al.\n(2018), and establish a new benchmark for future biologically plausible\nlearning algorithms on more difficult datasets and more complex architectures.", "published": "2018-11-08T17:43:59Z", "version": 3}, {"aid": "1811.03804", "authors": ["Simon S. Du", "Jason D. Lee", "Haochuan Li", "Liwei Wang", "Xiyu Zhai"], "title": "Gradient Descent Finds Global Minima of Deep Neural Networks", "url": "http://arxiv.org/pdf/1811.03804v4", "summary": "Gradient descent finds a global minimum in training deep neural networks\ndespite the objective function being non-convex. The current paper proves\ngradient descent achieves zero training loss in polynomial time for a deep\nover-parameterized neural network with residual connections (ResNet). Our\nanalysis relies on the particular structure of the Gram matrix induced by the\nneural network architecture. This structure allows us to show the Gram matrix\nis stable throughout the training process and this stability implies the global\noptimality of the gradient descent algorithm. We further extend our analysis to\ndeep residual convolutional neural networks and obtain a similar convergence\nresult.", "published": "2018-11-09T07:39:59Z", "version": 4}, {"aid": "1811.03831", "authors": ["S. Bellavia", "G. Gurioli", "B. Morini", "Ph. L. Toint"], "title": "Adaptive Regularization Algorithms with Inexact Evaluations for Nonconvex Optimization", "url": "http://arxiv.org/pdf/1811.03831v3", "summary": "A regularization algorithm using inexact function values and inexact\nderivatives is proposed and its evaluation complexity analyzed. This algorithm\nis applicable to unconstrained problems and to problems with inexpensive\nconstraints (that is constraints whose evaluation and enforcement has\nnegligible cost) under the assumption that the derivative of highest degree is\n$\\beta$-H\\\"{o}lder continuous. It features a very flexible adaptive mechanism\nfor determining the inexactness which is allowed, at each iteration, when\ncomputing objective function values and derivatives. The complexity analysis\ncovers arbitrary optimality order and arbitrary degree of available approximate\nderivatives. It extends results of Cartis, Gould and Toint (2018) on the\nevaluation complexity to the inexact case: if a $q$th order minimizer is sought\nusing approximations to the first $p$ derivatives, it is proved that a suitable\napproximate minimizer within $\\epsilon$ is computed by the proposed algorithm\nin at most $O(\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ iterations and at most\n$O(|\\log(\\epsilon)|\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ approximate\nevaluations. An algorithmic variant, although more rigid in practice, can be\nproved to find such an approximate minimizer in\n$O(|\\log(\\epsilon)|+\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ evaluations.While\nthe proposed framework remains so far conceptual for high degrees and orders,\nit is shown to yield simple and computationally realistic inexact methods when\nspecialized to the unconstrained and bound-constrained first- and second-order\ncases. The deterministic complexity results are finally extended to the\nstochastic context, yielding adaptive sample-size rules for subsampling methods\ntypical of machine learning.", "published": "2018-11-09T09:39:53Z", "version": 3}, {"aid": "1811.03848", "authors": ["Sune Darkner", "Stefan Sommer", "Andreas Schuhmacher", "Henrik Ingerslev Anders O. Baandrup", "Carsten Thomsen", "S\u00f8ren J\u00f8nsson"], "title": "An Average of the Human Ear Canal: Recovering Acoustical Properties via Shape Analysis", "url": "http://arxiv.org/pdf/1811.03848v1", "summary": "Humans are highly dependent on the ability to process audio in order to\ninteract through conversation and navigate from sound. For this, the shape of\nthe ear acts as a mechanical audio filter. The anatomy of the outer human ear\ncanal to approximately 15-20 mm beyond the Tragus is well described because of\nits importance for customized hearing aid production. This is however not the\ncase for the part of the ear canal that is embedded in the skull, until the\ntypanic membrane. Due to the sensitivity of the outer ear, this part, referred\nto as the bony part, has only been described in a few population studies and\nonly ex-vivo. We present a study of the entire ear canal including the bony\npart and the tympanic membrane. We form an average ear canal from a number of\nMRI scans using standard image registration methods. We show that the obtained\nrepresentation is realistic in the sense that it has acoustical properties\nalmost identical to a real ear.", "published": "2018-11-09T10:19:25Z", "version": 1}, {"aid": "1811.04790", "authors": ["Mieczys\u0142aw K\u0142opotek"], "title": "Reasoning From Data in the Mathematical Theory of Evidence", "url": "http://arxiv.org/pdf/1811.04790v1", "summary": "Mathematical Theory of Evidence (MTE) is known as a foundation for reasoning\nwhen knowledge is expressed at various levels of detail. Though much research\neffort has been committed to this theory since its foundation, many questions\nremain open. One of the most important open questions seems to be the\nrelationship between frequencies and the Mathematical Theory of Evidence. The\ntheory is blamed to leave frequencies outside (or aside of) its framework. The\nseriousness of this accusation is obvious: no experiment may be run to compare\nthe performance of MTE-based models of real world processes against real world\ndata.\n  In this paper we develop a frequentist model of the MTE bringing to fall the\nabove argument against MTE. We describe, how to interpret data in terms of MTE\nbelief functions, how to reason from data about conditional belief functions,\nhow to generate a random sample out of a MTE model, how to derive MTE model\nfrom data and how to compare results of reasoning in MTE model and reasoning\nfrom data.\n  It is claimed in this paper that MTE is suitable to model some types of\ndestructive processes", "published": "2018-11-09T11:41:10Z", "version": 1}, {"aid": "1811.04047", "authors": ["Hongyang Jia", "Yinqi Tang", "Hossein Valavi", "Jintao Zhang", "Naveen Verma"], "title": "A Microprocessor implemented in 65nm CMOS with Configurable and Bit-scalable Accelerator for Programmable In-memory Computing", "url": "http://arxiv.org/pdf/1811.04047v1", "summary": "This paper presents a programmable in-memory-computing processor,\ndemonstrated in a 65nm CMOS technology. For data-centric workloads, such as\ndeep neural networks, data movement often dominates when implemented with\ntoday's computing architectures. This has motivated spatial architectures,\nwhere the arrangement of data-storage and compute hardware is distributed and\nexplicitly aligned to the computation dataflow, most notably for matrix-vector\nmultiplication. In-memory computing is a spatial architecture where processing\nelements correspond to dense bit cells, providing local storage and compute,\ntypically employing analog operation. Though this raises the potential for high\nenergy efficiency and throughput, analog operation has significantly limited\nrobustness, scale, and programmability. This paper describes a 590kb\nin-memory-computing accelerator integrated in a programmable processor\narchitecture, by exploiting recent approaches to charge-domain in-memory\ncomputing. The architecture takes the approach of tight coupling with an\nembedded CPU, through accelerator interfaces enabling integration in the\nstandard processor memory space. Additionally, a near-memory-computing datapath\nboth enables diverse computations locally, to address operations required\nacross applications, and enables bit-precision scalability for\nmatrix/input-vector elements, through a bit-parallel/bit-serial (BP/BS) scheme.\nChip measurements show an energy efficiency of 152/297 1b-TOPS/W and throughput\nof 4.7/1.9 1b-TOPS (scaling linearly with the matrix/input-vector element\nprecisions) at VDD of 1.2/0.85V. Neural network demonstrations with 1-b/4-b\nweights and activations for CIFAR-10 classification consume 5.3/105.2\n$\\mu$J/image at 176/23 fps, with accuracy at the level of digital/software\nimplementation (89.3/92.4 $\\%$ accuracy).", "published": "2018-11-09T18:03:14Z", "version": 1}, {"aid": "1811.04110", "authors": ["Akshay Raj Dhamija", "Manuel G\u00fcnther", "Terrance E. Boult"], "title": "Reducing Network Agnostophobia", "url": "http://arxiv.org/pdf/1811.04110v2", "summary": "Agnostophobia, the fear of the unknown, can be experienced by deep learning\nengineers while applying their networks to real-world applications.\nUnfortunately, network behavior is not well defined for inputs far from a\nnetworks training set. In an uncontrolled environment, networks face many\ninstances that are not of interest to them and have to be rejected in order to\navoid a false positive. This problem has previously been tackled by researchers\nby either a) thresholding softmax, which by construction cannot return \"none of\nthe known classes\", or b) using an additional background or garbage class. In\nthis paper, we show that both of these approaches help, but are generally\ninsufficient when previously unseen classes are encountered. We also introduce\na new evaluation metric that focuses on comparing the performance of multiple\napproaches in scenarios where such unseen classes or unknowns are encountered.\nOur major contributions are simple yet effective Entropic Open-Set and\nObjectosphere losses that train networks using negative samples from some\nclasses. These novel losses are designed to maximize entropy for unknown inputs\nwhile increasing separation in deep feature space by modifying magnitudes of\nknown and unknown samples. Experiments on networks trained to classify classes\nfrom MNIST and CIFAR-10 show that our novel loss functions are significantly\nbetter at dealing with unknown inputs from datasets such as Devanagari,\nNotMNIST, CIFAR-100, and SVHN.", "published": "2018-11-09T19:29:58Z", "version": 2}, {"aid": "1811.04239", "authors": ["Geesara Prathap", "Titus Nanda Kumara", "Roshan Ragel"], "title": "Near Real-Time Data Labeling Using a Depth Sensor for EMG Based Prosthetic Arms", "url": "http://arxiv.org/pdf/1811.04239v1", "summary": "Recognizing sEMG (Surface Electromyography) signals belonging to a particular\naction (e.g., lateral arm raise) automatically is a challenging task as EMG\nsignals themselves have a lot of variation even for the same action due to\nseveral factors. To overcome this issue, there should be a proper separation\nwhich indicates similar patterns repetitively for a particular action in raw\nsignals. A repetitive pattern is not always matched because the same action can\nbe carried out with different time duration. Thus, a depth sensor (Kinect) was\nused for pattern identification where three joint angles were recording\ncontinuously which is clearly separable for a particular action while recording\nsEMG signals. To Segment out a repetitive pattern in angle data, MDTW (Moving\nDynamic Time Warping) approach is introduced. This technique is allowed to\nretrieve suspected motion of interest from raw signals. MDTW based on DTW\nalgorithm, but it will be moving through the whole dataset in a pre-defined\nmanner which is capable of picking up almost all the suspected segments inside\na given dataset an optimal way. Elevated bicep curl and lateral arm raise\nmovements are taken as motions of interest to show how the proposed technique\ncan be employed to achieve auto identification and labelling. The full\nimplementation is available at https://github.com/GPrathap/OpenBCIPython", "published": "2018-11-10T11:59:56Z", "version": 1}, {"aid": "1811.04504", "authors": ["Aaron Mishkin", "Frederik Kunstner", "Didrik Nielsen", "Mark Schmidt", "Mohammad Emtiyaz Khan"], "title": "SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient", "url": "http://arxiv.org/pdf/1811.04504v2", "summary": "Uncertainty estimation in large deep-learning models is a computationally\nchallenging task, where it is difficult to form even a Gaussian approximation\nto the posterior distribution. In such situations, existing methods usually\nresort to a diagonal approximation of the covariance matrix despite, the fact\nthat these matrices are known to result in poor uncertainty estimates. To\naddress this issue, we propose a new stochastic, low-rank, approximate\nnatural-gradient (SLANG) method for variational inference in large, deep\nmodels. Our method estimates a \"diagonal plus low-rank\" structure based solely\non back-propagated gradients of the network log-likelihood. This requires\nstrictly less gradient computations than methods that compute the gradient of\nthe whole variational objective. Empirical evaluations on standard benchmarks\nconfirm that SLANG enables faster and more accurate estimation of uncertainty\nthan mean-field methods, and performs comparably to state-of-the-art methods.", "published": "2018-11-11T23:18:27Z", "version": 2}, {"aid": "1811.04581", "authors": ["Shigeko Takahashi"], "title": "Topographic maps in the brain are fundamental to processing of causality", "url": "http://arxiv.org/pdf/1811.04581v1", "summary": "The ubiquity of topographic maps in the brain has long been known, and\nmolecular mechanisms for the formation of topographic organization of neural\nsystems have been revealed. Less attention has been given to the question of\nwhy are the maps topographical and why so ubiquitous. In this study, I explore\nthe implications of the topographic maps for brain function, by employing the\nmathematical framework of the Zeeman topology. I propose the notion about the\nmeaning of topographic order as generic mechanisms for the representation and\nanalysis of causal structure, implemented by the neural systems. This leads to\na much improved understanding of the division of labour between chemical\nsystems and neural systems in the formation of maps to deal with causality.", "published": "2018-11-12T06:42:42Z", "version": 1}, {"aid": "1811.04768", "authors": ["Mingyang Geng", "Kele Xu", "Bo Ding", "Huaimin Wang", "Lei Zhang"], "title": "Learning data augmentation policies using augmented random search", "url": "http://arxiv.org/pdf/1811.04768v1", "summary": "Previous attempts for data augmentation are designed manually, and the\naugmentation policies are dataset-specific. Recently, an automatic data\naugmentation approach, named AutoAugment, is proposed using reinforcement\nlearning. AutoAugment searches for the augmentation polices in the discrete\nsearch space, which may lead to a sub-optimal solution. In this paper, we\nemploy the Augmented Random Search method (ARS) to improve the performance of\nAutoAugment. Our key contribution is to change the discrete search space to\ncontinuous space, which will improve the searching performance and maintain the\ndiversities between sub-policies. With the proposed method, state-of-the-art\naccuracies are achieved on CIFAR-10, CIFAR-100, and ImageNet (without\nadditional data). Our code is available at https://github.com/gmy2013/ARS-Aug.", "published": "2018-11-12T15:14:18Z", "version": 1}, {"aid": "1811.05029", "authors": ["Ricardo Martin-Brualla", "Rohit Pandey", "Shuoran Yang", "Pavel Pidlypenskyi", "Jonathan Taylor", "Julien Valentin", "Sameh Khamis", "Philip Davidson", "Anastasia Tkach", "Peter Lincoln", "Adarsh Kowdle", "Christoph Rhemann", "Dan B Goldman", "Cem Keskin", "Steve Seitz", "Shahram Izadi", "Sean Fanello"], "title": "LookinGood: Enhancing Performance Capture with Real-time Neural Re-Rendering", "url": "http://arxiv.org/pdf/1811.05029v1", "summary": "Motivated by augmented and virtual reality applications such as telepresence,\nthere has been a recent focus in real-time performance capture of humans under\nmotion. However, given the real-time constraint, these systems often suffer\nfrom artifacts in geometry and texture such as holes and noise in the final\nrendering, poor lighting, and low-resolution textures. We take the novel\napproach to augment such real-time performance capture systems with a deep\narchitecture that takes a rendering from an arbitrary viewpoint, and jointly\nperforms completion, super resolution, and denoising of the imagery in\nreal-time. We call this approach neural (re-)rendering, and our live system\n\"LookinGood\". Our deep architecture is trained to produce high resolution and\nhigh quality images from a coarse rendering in real-time. First, we propose a\nself-supervised training method that does not require manual ground-truth\nannotation. We contribute a specialized reconstruction error that uses semantic\ninformation to focus on relevant parts of the subject, e.g. the face. We also\nintroduce a salient reweighing scheme of the loss function that is able to\ndiscard outliers. We specifically design the system for virtual and augmented\nreality headsets where the consistency between the left and right eye plays a\ncrucial role in the final user experience. Finally, we generate temporally\nstable results by explicitly minimizing the difference between two consecutive\nframes. We tested the proposed system in two different scenarios: one involving\na single RGB-D sensor, and upper body reconstruction of an actor, the second\nconsisting of full body 360 degree capture. Through extensive experimentation,\nwe demonstrate how our system generalizes across unseen sequences and subjects.\nThe supplementary video is available at http://youtu.be/Md3tdAKoLGU.", "published": "2018-11-12T22:51:19Z", "version": 1}, {"aid": "1811.05067", "authors": ["John Benhardt", "Peter Hase", "Liuyi Zhu", "Cynthia Rudin"], "title": "Shall I Compare Thee to a Machine-Written Sonnet? An Approach to Algorithmic Sonnet Generation", "url": "http://arxiv.org/pdf/1811.05067v2", "summary": "We provide an approach for generating beautiful poetry. Our sonnet-generation\nalgorithm includes several novel elements that improve over the state of the\nart, leading to metrical, rhyming poetry with many human-like qualities. These\nnovel elements include in-line punctuation, part of speech restrictions, and\nmore appropriate training corpora. Our work is the winner of the 2018 PoetiX\nLiterary Turing Test Award for computer-generated poetry.", "published": "2018-11-13T02:04:42Z", "version": 2}, {"aid": "1811.05106", "authors": ["Sungmin Kang", "David Keetae Park", "Jaehyuk Chang", "Jaegul Choo"], "title": "Interpreting Models by Allowing to Ask", "url": "http://arxiv.org/pdf/1811.05106v1", "summary": "Questions convey information about the questioner, namely what one does not\nknow. In this paper, we propose a novel approach to allow a learning agent to\nask what it considers as tricky to predict, in the course of producing a final\noutput. By analyzing when and what it asks, we can make our model more\ntransparent and interpretable. We first develop this idea to propose a general\nframework of deep neural networks that can ask questions, which we call asking\nnetworks. A specific architecture and training process for an asking network is\nproposed for the task of colorization, which is an exemplar one-to-many task\nand thus a task where asking questions is helpful in performing the task\naccurately. Our results show that the model learns to generate meaningful\nquestions, asks difficult questions first, and utilizes the provided hint more\nefficiently than baseline models. We conclude that the proposed asking\nframework makes the learning agent reveal its weaknesses, which poses a\npromising new direction in developing interpretable and interactive models.", "published": "2018-11-13T04:57:48Z", "version": 1}, {"aid": "1811.05531", "authors": ["Dimitris Spathis", "Nikolaos Passalis", "Anastasios Tefas"], "title": "Interactive dimensionality reduction using similarity projections", "url": "http://arxiv.org/pdf/1811.05531v1", "summary": "Recent advances in machine learning allow us to analyze and describe the\ncontent of high-dimensional data like text, audio, images or other signals. In\norder to visualize that data in 2D or 3D, usually Dimensionality Reduction (DR)\ntechniques are employed. Most of these techniques, e.g., PCA or t-SNE, produce\nstatic projections without taking into account corrections from humans or other\ndata exploration scenarios. In this work, we propose the interactive Similarity\nProjection (iSP), a novel interactive DR framework based on similarity\nembeddings, where we form a differentiable objective based on the user\ninteractions and perform learning using gradient descent, with an end-to-end\ntrainable architecture. Two interaction scenarios are evaluated. First, a\ncommon methodology in multidimensional projection is to project a subset of\ndata, arrange them in classes or clusters, and project the rest unseen dataset\nbased on that manipulation, in a kind of semi-supervised interpolation. We\nreport results that outperform competitive baselines in a wide range of metrics\nand datasets. Second, we explore the scenario of manipulating some classes,\nwhile enriching the optimization with high-dimensional neighbor information.\nApart from improving classification precision and clustering on images and text\ndocuments, the new emerging structure of the projection unveils semantic\nmanifolds. For example, on the Head Pose dataset, by just dragging the faces\nlooking far left to the left and those looking far right to the right, all\nfaces are re-arranged on a continuum even on the vertical axis (face up and\ndown). This end-to-end framework can be used for fast, visual semi-supervised\nlearning, manifold exploration, interactive domain adaptation of neural\nembeddings and transfer learning.", "published": "2018-11-13T21:21:15Z", "version": 1}, {"aid": "1811.06115", "authors": ["Fergal Cotter", "Nick Kingsbury"], "title": "Deep Learning in the Wavelet Domain", "url": "http://arxiv.org/pdf/1811.06115v1", "summary": "This paper examines the possibility of, and the possible advantages to\nlearning the filters of convolutional neural networks (CNNs) for image analysis\nin the wavelet domain. We are stimulated by both Mallat's scattering transform\nand the idea of filtering in the Fourier domain. It is important to explore new\nspaces in which to learn, as these may provide inherent advantages that are not\navailable in the pixel space. However, the scattering transform is limited by\nits inability to learn in between scattering orders, and any Fourier domain\nfiltering is limited by the large number of filter parameters needed to get\nlocalized filters. Instead we consider filtering in the wavelet domain with\nlearnable filters. The wavelet space allows us to have local, smooth filters\nwith far fewer parameters, and learnability can give us flexibility. We present\na novel layer which takes CNN activations into the wavelet space, learns\nparameters and returns to the pixel space. This allows it to be easily dropped\nin to any neural network without affecting the structure. As part of this work,\nwe show how to pass gradients through a multirate system and give preliminary\nresults.", "published": "2018-11-14T23:33:09Z", "version": 1}, {"aid": "1811.06145", "authors": ["Jing Shi", "Jiaming Xu", "Yiqun Yao", "Bo Xu"], "title": "Concept Learning through Deep Reinforcement Learning with Memory-Augmented Neural Networks", "url": "http://arxiv.org/pdf/1811.06145v1", "summary": "Deep neural networks have shown superior performance in many regimes to\nremember familiar patterns with large amounts of data. However, the standard\nsupervised deep learning paradigm is still limited when facing the need to\nlearn new concepts efficiently from scarce data. In this paper, we present a\nmemory-augmented neural network which is motivated by the process of human\nconcept learning. The training procedure, imitating the concept formation\ncourse of human, learns how to distinguish samples from different classes and\naggregate samples of the same kind. In order to better utilize the advantages\noriginated from the human behavior, we propose a sequential process, during\nwhich the network should decide how to remember each sample at every step. In\nthis sequential process, a stable and interactive memory serves as an important\nmodule. We validate our model in some typical one-shot learning tasks and also\nan exploratory outlier detection problem. In all the experiments, our model\ngets highly competitive to reach or outperform those strong baselines.", "published": "2018-11-15T02:38:57Z", "version": 1}, {"aid": "1811.06624", "authors": ["Jason R. C. Nurse"], "title": "Cybercrime and You: How Criminals Attack and the Human Factors That They Seek to Exploit", "url": "http://arxiv.org/pdf/1811.06624v1", "summary": "Cybercrime is a significant challenge to society, but it can be particularly\nharmful to the individuals who become victims. This chapter engages in a\ncomprehensive and topical analysis of the cybercrimes that target individuals.\nIt also examines the motivation of criminals that perpetrate such attacks and\nthe key human factors and psychological aspects that help to make\ncybercriminals successful. Key areas assessed include social engineering (e.g.,\nphishing, romance scams, catfishing), online harassment (e.g., cyberbullying,\ntrolling, revenge porn, hate crimes), identity-related crimes (e.g., identity\ntheft, doxing), hacking (e.g., malware, cryptojacking, account hacking), and\ndenial-of-service crimes. As a part of its contribution, the chapter introduces\na summary taxonomy of cybercrimes against individuals and a case for why they\nwill continue to occur if concerted interdisciplinary efforts are not pursued.", "published": "2018-11-15T23:16:37Z", "version": 1}, {"aid": "1811.06783", "authors": ["Hengyue Pan", "Hui Jiang", "Xin Niu", "Yong Dou"], "title": "DropFilter: A Novel Regularization Method for Learning Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1811.06783v2", "summary": "The past few years have witnessed the fast development of different\nregularization methods for deep learning models such as fully-connected deep\nneural networks (DNNs) and Convolutional Neural Networks (CNNs). Most of\nprevious methods mainly consider to drop features from input data and hidden\nlayers, such as Dropout, Cutout and DropBlocks. DropConnect select to drop\nconnections between fully-connected layers. By randomly discard some features\nor connections, the above mentioned methods control the overfitting problem and\nimprove the performance of neural networks. In this paper, we proposed two\nnovel regularization methods, namely DropFilter and DropFilter-PLUS, for the\nlearning of CNNs. Different from the previous methods, DropFilter and\nDropFilter-PLUS selects to modify the convolution filters. For DropFilter-PLUS,\nwe find a suitable way to accelerate the learning process based on theoretical\nanalysis. Experimental results on MNIST show that using DropFilter and\nDropFilter-PLUS may improve performance on image classification tasks.", "published": "2018-11-16T12:40:39Z", "version": 2}, {"aid": "1811.06878", "authors": ["Jung HyoungHo", "Lee Ryong", "Lee Sanghwan", "Hwang Wonjun"], "title": "Residual Convolutional Neural Network Revisited with Active Weighted Mapping", "url": "http://arxiv.org/pdf/1811.06878v1", "summary": "In visual recognition, the key to the performance improvement of ResNet is\nthe success in establishing the stack of deep sequential convolutional layers\nusing identical mapping by a shortcut connection. It results in multiple paths\nof data flow under a network and the paths are merged with the equal weights.\nHowever, it is questionable whether it is correct to use the fixed and\npredefined weights at the mapping units of all paths. In this paper, we\nintroduce the active weighted mapping method which infers proper weight values\nbased on the characteristic of input data on the fly. The weight values of each\nmapping unit are not fixed but changed as the input image is changed, and the\nmost proper weight values for each mapping unit are derived according to the\ninput image. For this purpose, channel-wise information is embedded from both\nthe shortcut connection and convolutional block, and then the fully connected\nlayers are used to estimate the weight values for the mapping units. We train\nthe backbone network and the proposed module alternately for a more stable\nlearning of the proposed method. Results of the extensive experiments show that\nthe proposed method works successfully on the various backbone architectures\nfrom ResNet to DenseNet. We also verify the superiority and generality of the\nproposed method on various datasets in comparison with the baseline.", "published": "2018-11-16T15:51:20Z", "version": 1}, {"aid": "1811.06981", "authors": ["Oren Rippel", "Sanjay Nair", "Carissa Lew", "Steve Branson", "Alexander G. Anderson", "Lubomir Bourdev"], "title": "Learned Video Compression", "url": "http://arxiv.org/pdf/1811.06981v1", "summary": "We present a new algorithm for video coding, learned end-to-end for the\nlow-latency mode. In this setting, our approach outperforms all existing video\ncodecs across nearly the entire bitrate range. To our knowledge, this is the\nfirst ML-based method to do so.\n  We evaluate our approach on standard video compression test sets of varying\nresolutions, and benchmark against all mainstream commercial codecs, in the\nlow-latency mode. On standard-definition videos, relative to our algorithm,\nHEVC/H.265, AVC/H.264 and VP9 typically produce codes up to 60% larger. On\nhigh-definition 1080p videos, H.265 and VP9 typically produce codes up to 20%\nlarger, and H.264 up to 35% larger. Furthermore, our approach does not suffer\nfrom blocking artifacts and pixelation, and thus produces videos that are more\nvisually pleasing.\n  We propose two main contributions. The first is a novel architecture for\nvideo compression, which (1) generalizes motion estimation to perform any\nlearned compensation beyond simple translations, (2) rather than strictly\nrelying on previously transmitted reference frames, maintains a state of\narbitrary information learned by the model, and (3) enables jointly compressing\nall transmitted signals (such as optical flow and residual).\n  Secondly, we present a framework for ML-based spatial rate control: namely, a\nmechanism for assigning variable bitrates across space for each frame. This is\na critical component for video coding, which to our knowledge had not been\ndeveloped within a machine learning setting.", "published": "2018-11-16T17:29:51Z", "version": 1}, {"aid": "1811.07012", "authors": ["Benjamin P Cohen", "Carson C Chow", "Shashaank Vattikuti"], "title": "Multi-scale variability in neuronal competition", "url": "http://arxiv.org/pdf/1811.07012v1", "summary": "We examine whether a single biophysical cortical circuit model can explain\nboth spiking and perceptual variability. We consider perceptual rivalry, which\nprovides a window into intrinsic neural processing since neural activity in\nsome brain areas is correlated to the alternating perception rather than the\nconstant ambiguous stimulus. The prevalent theory for spiking variability is a\nchaotic attractor called the balanced state; whereas, the source of perceptual\nvariability is an open question. We present a dynamical model with a chaotic\nattractor that explains both spiking and perceptual variability and adheres to\na broad set of strict experimental constraints. The model makes quantitative\npredictions for how both spiking and perceptual variability will change as the\nstimulus changes.", "published": "2018-11-16T20:05:41Z", "version": 1}, {"aid": "1811.07017", "authors": ["Shagun Sodhani", "Sarath Chandar", "Yoshua Bengio"], "title": "Towards Training Recurrent Neural Networks for Lifelong Learning", "url": "http://arxiv.org/pdf/1811.07017v3", "summary": "Catastrophic forgetting and capacity saturation are the central challenges of\nany parametric lifelong learning system. In this work, we study these\nchallenges in the context of sequential supervised learning with an emphasis on\nrecurrent neural networks. To evaluate the models in the lifelong learning\nsetting, we propose a curriculum-based, simple, and intuitive benchmark where\nthe models are trained on tasks with increasing levels of difficulty. To\nmeasure the impact of catastrophic forgetting, the model is tested on all the\nprevious tasks as it completes any task. As a step towards developing true\nlifelong learning systems, we unify Gradient Episodic Memory (a catastrophic\nforgetting alleviation approach) and Net2Net(a capacity expansion approach).\nBoth these models are proposed in the context of feedforward networks and we\nevaluate the feasibility of using them for recurrent networks. Evaluation on\nthe proposed benchmark shows that the unified model is more suitable than the\nconstituent models for lifelong learning setting.", "published": "2018-11-16T20:13:23Z", "version": 3}, {"aid": "1812.03813", "authors": ["Marcel Nassar"], "title": "Hierarchical Bipartite Graph Convolution Networks", "url": "http://arxiv.org/pdf/1812.03813v2", "summary": "Recently, graph neural networks have been adopted in a wide variety of\napplications ranging from relational representations to modeling irregular data\ndomains such as point clouds and social graphs. However, the space of graph\nneural network architectures remains highly fragmented impeding the development\nof optimized implementations similar to what is available for convolutional\nneural networks. In this work, we present BiGraphNet, a graph neural network\narchitecture that generalizes many popular graph neural network models and\nenables new efficient operations similar to those supported by ConvNets. By\nexplicitly separating the input and output nodes, BiGraphNet: (i) generalizes\nthe graph convolution to support new efficient operations such as coarsened\ngraph convolutions (similar to strided convolution in convnets), multiple input\ngraphs convolution and graph expansions (unpooling) which can be used to\nimplement various graph architectures such as graph autoencoders, and graph\nresidual nets; and (ii) accelerates and scales the computations and memory\nrequirements in hierarchical networks by performing computations only at\nspecified output nodes.", "published": "2018-11-17T02:43:59Z", "version": 2}, {"aid": "1811.07246", "authors": ["Wenxuan Wu", "Zhongang Qi", "Li Fuxin"], "title": "PointConv: Deep Convolutional Networks on 3D Point Clouds", "url": "http://arxiv.org/pdf/1811.07246v3", "summary": "Unlike images which are represented in regular dense grids, 3D point clouds\nare irregular and unordered, hence applying convolution on them can be\ndifficult. In this paper, we extend the dynamic filter to a new convolution\noperation, named PointConv. PointConv can be applied on point clouds to build\ndeep convolutional networks. We treat convolution kernels as nonlinear\nfunctions of the local coordinates of 3D points comprised of weight and density\nfunctions. With respect to a given point, the weight functions are learned with\nmulti-layer perceptron networks and density functions through kernel density\nestimation. The most important contribution of this work is a novel\nreformulation proposed for efficiently computing the weight functions, which\nallowed us to dramatically scale up the network and significantly improve its\nperformance. The learned convolution kernel can be used to compute\ntranslation-invariant and permutation-invariant convolution on any point set in\nthe 3D space. Besides, PointConv can also be used as deconvolution operators to\npropagate features from a subsampled point cloud back to its original\nresolution. Experiments on ModelNet40, ShapeNet, and ScanNet show that deep\nconvolutional neural networks built on PointConv are able to achieve\nstate-of-the-art on challenging semantic segmentation benchmarks on 3D point\nclouds. Besides, our experiments converting CIFAR-10 into a point cloud showed\nthat networks built on PointConv can match the performance of convolutional\nnetworks in 2D images of a similar structure.", "published": "2018-11-17T23:42:13Z", "version": 3}, {"aid": "1811.07407", "authors": ["Faisal Mahmood", "Ziyun Yang", "Thomas Ashley", "Nicholas J. Durr"], "title": "Multimodal Densenet", "url": "http://arxiv.org/pdf/1811.07407v1", "summary": "Humans make accurate decisions by interpreting complex data from multiple\nsources. Medical diagnostics, in particular, often hinge on human\ninterpretation of multi-modal information. In order for artificial intelligence\nto make progress in automated, objective, and accurate diagnosis and prognosis,\nmethods to fuse information from multiple medical imaging modalities are\nrequired. However, combining information from multiple data sources has several\nchallenges, as current deep learning architectures lack the ability to extract\nuseful representations from multimodal information, and often simple\nconcatenation is used to fuse such information. In this work, we propose\nMultimodal DenseNet, a novel architecture for fusing multimodal data. Instead\nof focusing on concatenation or early and late fusion, our proposed\narchitectures fuses information over several layers and gives the model\nflexibility in how it combines information from multiple sources. We apply this\narchitecture to the challenge of polyp characterization and landmark\nidentification in endoscopy. Features from white light images are fused with\nfeatures from narrow band imaging or depth maps. This study demonstrates that\nMultimodal DenseNet outperforms monomodal classification as well as other\nmultimodal fusion techniques by a significant margin on two different datasets.", "published": "2018-11-18T21:31:22Z", "version": 1}, {"aid": "1811.07491", "authors": ["Yushan Feng", "Huitong Pan", "Craig Meyer", "Xue Feng"], "title": "A Self-Adaptive Network For Multiple Sclerosis Lesion Segmentation From Multi-Contrast MRI With Various Imaging Protocols", "url": "http://arxiv.org/pdf/1811.07491v1", "summary": "Deep neural networks (DNN) have shown promises in the lesion segmentation of\nmultiple sclerosis (MS) from multicontrast MRI including T1, T2, proton density\n(PD) and FLAIR sequences. However, one challenge in deploying such networks\ninto clinical practice is the variability of imaging protocols, which often\ndiffer from the training dataset as certain MRI sequences may be unavailable or\nunusable. Therefore, trained networks need to adapt to practical situations\nwhen imaging protocols are different in deployment. In this paper, we propose a\nDNN-based MS lesion segmentation framework with a novel technique called\nsequence dropout which can adapt to various combinations of input MRI sequences\nduring deployment and achieve the maximal possible performance from the given\ninput. In addition, with this framework, we studied the quantitative impact of\neach MRI sequence on the MS lesion segmentation task without training separate\nnetworks. Experiments were performed using the IEEE ISBI 2015 Longitudinal MS\nLesion Challenge dataset and our method is currently ranked 2nd with a Dice\nsimilarity coefficient of 0.684. Furthermore, we showed our network achieved\nthe maximal possible performance when one sequence is unavailable during\ndeployment by comparing with separate networks trained on the corresponding\ninput MRI sequences. In particular, we discovered T1 and PD have minor impact\non segmentation performance while FLAIR is the predominant sequence.\nExperiments with multiple missing sequences were also performed and showed the\nrobustness of our network.", "published": "2018-11-19T04:18:57Z", "version": 1}, {"aid": "1811.07542", "authors": ["Jean Stawiaski"], "title": "A Pretrained DenseNet Encoder for Brain Tumor Segmentation", "url": "http://arxiv.org/pdf/1811.07542v1", "summary": "This article presents a convolutional neural network for the automatic\nsegmentation of brain tumors in multimodal 3D MR images based on a U-net\narchitecture.We evaluate the use of a densely connected convolutional network\nencoder (DenseNet) which was pretrained on the ImageNet data set. We detail two\nnetwork architectures that can take into account multiple 3D images as inputs.\nThis work aims to identify if a generic pretrained network can be used for very\nspecific medical applications where the target data differ both in the number\nof spatial dimensions as well as in the number of inputs channels. Moreover in\norder to regularize this transfer learning task we only train the decoder part\nof the U-net architecture. We evaluate the effectiveness of the proposed\napproach on the BRATS 2018 segmentation challenge where we obtained dice scores\nof 0.79, 0.90, 0.85 and 95/% Hausdorff distance of 2.9mm, 3.95mm, and 6.48mm\nfor enhanced tumor core, whole tumor and tumor core respectively on the\nvalidation set. This scores degrades to 0.77, 0.88, 0.78 and 95 /% Hausdorff\ndistance of 3.6mm, 5.72mm, and 5.83mm on the testing set.", "published": "2018-11-19T08:00:22Z", "version": 1}, {"aid": "1811.07545", "authors": ["Yunxiao Qin", "Chenxu Zhao", "Zezheng Wang", "Junliang Xing", "Jun Wan", "Zhen Lei"], "title": "Representation based and Attention augmented Meta learning", "url": "http://arxiv.org/pdf/1811.07545v3", "summary": "Deep learning based computer vision fails to work when labeled images are\nscarce. Recently, Meta learning algorithm has been confirmed as a promising way\nto improve the ability of learning from few images for computer vision.\nHowever, previous Meta learning approaches expose problems:\n  1) they ignored the importance of attention mechanism for the Meta learner;\n  2) they didn't give the Meta learner the ability of well using the past\nknowledge which can help to express images into high representations, resulting\nin that the Meta learner has to solve few shot learning task directly from the\noriginal high dimensional RGB images.\n  In this paper, we argue that the attention mechanism and the past knowledge\nare crucial for the Meta learner, and the Meta learner should be trained on\nhigh representations of the RGB images instead of directly on the original\nones. Based on these arguments, we propose two methods: Attention augmented\nMeta Learning (AML) and Representation based and Attention augmented Meta\nLearning(RAML). The method AML aims to improve the Meta learner's attention\nability by explicitly embedding an attention model into its network. The method\nRAML aims to give the Meta learner the ability of leveraging the past learned\nknowledge to reduce the dimension of the original input data by expressing it\ninto high representations, and help the Meta learner to perform well. Extensive\nexperiments demonstrate the effectiveness of the proposed models, with\nstate-of-the-art few shot learning performances on several few shot learning\nbenchmarks. The source code of our proposed methods will be released soon to\nfacilitate further studies on those aforementioned problem.", "published": "2018-11-19T08:08:00Z", "version": 3}, {"aid": "1811.07583", "authors": ["Jaime Spencer", "Oscar Mendez", "Richard Bowden", "Simon Hadfield"], "title": "Localisation via Deep Imagination: learn the features not the map", "url": "http://arxiv.org/pdf/1811.07583v1", "summary": "How many times does a human have to drive through the same area to become\nfamiliar with it? To begin with, we might first build a mental model of our\nsurroundings. Upon revisiting this area, we can use this model to extrapolate\nto new unseen locations and imagine their appearance. Based on this, we propose\nan approach where an agent is capable of modelling new environments after a\nsingle visitation. To this end, we introduce \"Deep Imagination\", a combination\nof classical Visual-based Monte Carlo Localisation and deep learning. By making\nuse of a feature embedded 3D map, the system can \"imagine\" the view from any\nnovel location. These \"imagined\" views are contrasted with the current\nobservation in order to estimate the agent's current location. In order to\nbuild the embedded map, we train a deep Siamese Fully Convolutional U-Net to\nperform dense feature extraction. By training these features to be generic, no\nadditional training or fine tuning is required to adapt to new environments.\nOur results demonstrate the generality and transfer capability of our learnt\ndense features by training and evaluating on multiple datasets. Additionally,\nwe include several visualizations of the feature representations and resulting\n3D maps, as well as their application to localisation.", "published": "2018-11-19T09:52:34Z", "version": 1}, {"aid": "1811.07727", "authors": ["Ping Luo", "Zhanglin Peng", "Jiamin Ren", "Ruimao Zhang"], "title": "Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?", "url": "http://arxiv.org/pdf/1811.07727v1", "summary": "Yes, they do. This work investigates a perspective for deep learning: whether\ndifferent normalization layers in a ConvNet require different normalizers. This\nis the first step towards understanding this phenomenon. We allow each\nconvolutional layer to be stacked before a switchable normalization (SN) that\nlearns to choose a normalizer from a pool of normalization methods. Through\nsystematic experiments in ImageNet, COCO, Cityscapes, and ADE20K, we answer\nthree questions: (a) Is it useful to allow each normalization layer to select\nits own normalizer? (b) What impacts the choices of normalizers? (c) Do\ndifferent tasks and datasets prefer different normalizers? Our results suggest\nthat (1) using distinct normalizers improves both learning and generalization\nof a ConvNet; (2) the choices of normalizers are more related to depth and\nbatch size, but less relevant to parameter initialization, learning rate decay,\nand solver; (3) different tasks and datasets have different behaviors when\nlearning to select normalizers.", "published": "2018-11-19T14:36:25Z", "version": 1}, {"aid": "1812.07965", "authors": ["Yali Amit"], "title": "Deep learning with asymmetric connections and Hebbian updates", "url": "http://arxiv.org/pdf/1812.07965v2", "summary": "We show that deep networks can be trained using Hebbian updates yielding\nsimilar performance to ordinary back-propagation on challenging image datasets.\nTo overcome the unrealistic symmetry in connections between layers, implicit in\nback-propagation, the feedback weights are separate from the feedforward\nweights. The feedback weights are also updated with a local rule, the same as\nthe feedforward weights - a weight is updated solely based on the product of\nactivity of the units it connects. With fixed feedback weights as proposed in\nLillicrap et. al (2016) performance degrades quickly as the depth of the\nnetwork increases. If the feedforward and feedback weights are initialized with\nthe same values, as proposed in Zipser and Rumelhart (1990), they remain the\nsame throughout training thus precisely implementing back-propagation. We show\nthat even when the weights are initialized differently and at random, and the\nalgorithm is no longer performing back-propagation, performance is comparable\non challenging datasets. We also propose a cost function whose derivative can\nbe represented as a local Hebbian update on the last layer. Convolutional\nlayers are updated with tied weights across space, which is not biologically\nplausible. We show that similar performance is achieved with untied layers,\nalso known as locally connected layers, corresponding to the connectivity\nimplied by the convolutional layers, but where weights are untied and updated\nseparately. In the linear case we show theoretically that the convergence of\nthe error to zero is accelerated by the update of the feedback weights.", "published": "2018-11-19T20:40:29Z", "version": 2}, {"aid": "1811.08051", "authors": ["Prithviraj Dhar", "Rajat Vikram Singh", "Kuan-Chuan Peng", "Ziyan Wu", "Rama Chellappa"], "title": "Learning without Memorizing", "url": "http://arxiv.org/pdf/1811.08051v2", "summary": "Incremental learning (IL) is an important task aimed at increasing the\ncapability of a trained model, in terms of the number of classes recognizable\nby the model. The key problem in this task is the requirement of storing data\n(e.g. images) associated with existing classes, while teaching the classifier\nto learn new classes. However, this is impractical as it increases the memory\nrequirement at every incremental step, which makes it impossible to implement\nIL algorithms on edge devices with limited memory. Hence, we propose a novel\napproach, called `Learning without Memorizing (LwM)', to preserve the\ninformation about existing (base) classes, without storing any of their data,\nwhile making the classifier progressively learn the new classes. In LwM, we\npresent an information preserving penalty: Attention Distillation Loss\n($L_{AD}$), and demonstrate that penalizing the changes in classifiers'\nattention maps helps to retain information of the base classes, as new classes\nare added. We show that adding $L_{AD}$ to the distillation loss which is an\nexisting information preserving loss consistently outperforms the\nstate-of-the-art performance in the iILSVRC-small and iCIFAR-100 datasets in\nterms of the overall accuracy of base and incrementally learned classes.", "published": "2018-11-20T03:20:16Z", "version": 2}, {"aid": "1811.08056", "authors": ["Dae Hoon Park", "Chiu Man Ho", "Yi Chang", "Huaqing Zhang"], "title": "Gradient-Coherent Strong Regularization for Deep Neural Networks", "url": "http://arxiv.org/pdf/1811.08056v2", "summary": "Regularization plays an important role in generalization of deep neural\nnetworks, which are often prone to overfitting with their numerous parameters.\nL1 and L2 regularizers are common regularization tools in machine learning with\ntheir simplicity and effectiveness. However, we observe that imposing strong L1\nor L2 regularization with stochastic gradient descent on deep neural networks\neasily fails, which limits the generalization ability of the underlying neural\nnetworks. To understand this phenomenon, we first investigate how and why\nlearning fails when strong regularization is imposed on deep neural networks.\nWe then propose a novel method, gradient-coherent strong regularization, which\nimposes regularization only when the gradients are kept coherent in the\npresence of strong regularization. Experiments are performed with multiple deep\narchitectures on three benchmark data sets for image recognition. Experimental\nresults show that our proposed approach indeed endures strong regularization\nand significantly improves both accuracy and compression (up to 9.9x), which\ncould not be achieved otherwise.", "published": "2018-11-20T03:41:56Z", "version": 2}, {"aid": "1811.08081", "authors": ["Safwan Hossain", "Kiarash Jamali", "Yuchen Li", "Frank Rudzicz"], "title": "ChainGAN: A sequential approach to GANs", "url": "http://arxiv.org/pdf/1811.08081v2", "summary": "We propose a new architecture and training methodology for generative\nadversarial networks. Current approaches attempt to learn the transformation\nfrom a noise sample to a generated data sample in one shot. Our proposed\ngenerator architecture, called $\\textit{ChainGAN}$, uses a two-step process. It\nfirst attempts to transform a noise vector into a crude sample, similar to a\ntraditional generator. Next, a chain of networks, called $\\textit{editors}$,\nattempt to sequentially enhance this sample. We train each of these units\nindependently, instead of with end-to-end backpropagation on the entire chain.\nOur model is robust, efficient, and flexible as we can apply it to various\nnetwork architectures. We provide rationale for our choices and experimentally\nevaluate our model, achieving competitive results on several datasets.", "published": "2018-11-20T05:30:32Z", "version": 2}, {"aid": "1811.08126", "authors": ["Firas Shama", "Roey Mechrez", "Alon Shoshan", "Lihi Zelnik-Manor"], "title": "Adversarial Feedback Loop", "url": "http://arxiv.org/pdf/1811.08126v1", "summary": "Thanks to their remarkable generative capabilities, GANs have gained great\npopularity, and are used abundantly in state-of-the-art methods and\napplications. In a GAN based model, a discriminator is trained to learn the\nreal data distribution. To date, it has been used only for training purposes,\nwhere it's utilized to train the generator to provide real-looking outputs. In\nthis paper we propose a novel method that makes an explicit use of the\ndiscriminator in test-time, in a feedback manner in order to improve the\ngenerator results. To the best of our knowledge it is the first time a\ndiscriminator is involved in test-time. We claim that the discriminator holds\nsignificant information on the real data distribution, that could be useful for\ntest-time as well, a potential that has not been explored before.\n  The approach we propose does not alter the conventional training stage. At\ntest-time, however, it transfers the output from the generator into the\ndiscriminator, and uses feedback modules (convolutional blocks) to translate\nthe features of the discriminator layers into corrections to the features of\nthe generator layers, which are used eventually to get a better generator\nresult. Our method can contribute to both conditional and unconditional GANs.\nAs demonstrated by our experiments, it can improve the results of\nstate-of-the-art networks for super-resolution, and image generation.", "published": "2018-11-20T08:53:27Z", "version": 1}, {"aid": "1811.08210", "authors": ["Xing Hsu", "Zhifeng Zhao", "Rongpeng Li", "Honggang Zhang"], "title": "Brain-Inspired Stigmergy Learning", "url": "http://arxiv.org/pdf/1811.08210v1", "summary": "Stigmergy has proved its great superiority in terms of distributed control,\nrobustness and adaptability, thus being regarded as an ideal solution for\nlarge-scale swarm control problems. Based on new discoveries on astrocytes in\nregulating synaptic transmission in the brain, this paper has mapped stigmergy\nmechanism into the interaction between synapses and investigated its\ncharacteristics and advantages. Particularly, we have divided the interaction\nbetween synapses which are not directly connected into three phases and\nproposed a stigmergic learning model. In this model, the state change of a\nstigmergy agent will expand its influence to affect the states of others. The\nstrength of the interaction is determined by the level of neural activity as\nwell as the distance between stigmergy agents. Inspired by the morphological\nand functional changes in astrocytes during environmental enrichment, it is\nlikely that the regulation of distance between stigmergy agents plays a\ncritical role in the stigmergy learning process. Simulation results have\nverified its importance and indicated that the well-regulated distance between\nstigmergy agents can help to obtain stigmergy learning gain.", "published": "2018-11-20T12:36:25Z", "version": 1}, {"aid": "1811.08618", "authors": ["Jinhyeok Jang", "Jaehong Kim", "Jaeyeon Lee", "Seungjoon Yang"], "title": "Neural Networks with Activation Networks", "url": "http://arxiv.org/pdf/1811.08618v1", "summary": "This work presents an adaptive activation method for neural networks that\nexploits the interdependency of features. Each pixel, node, and layer is\nassigned with a polynomial activation function, whose coefficients are provided\nby an auxiliary activation network. The activation of a feature depends on the\nfeatures of neighboring pixels in a convolutional layer and other nodes in a\ndense layer. The dependency is learned from data by the activation networks. In\nour experiments, networks with activation networks provide significant\nperformance improvement compared to the baseline networks on which they are\nbuilt. The proposed method can be used to improve the network performance as an\nalternative to increasing the number of nodes and layers.", "published": "2018-11-21T07:54:41Z", "version": 1}, {"aid": "1811.08634", "authors": ["Yifan Yang", "Qijing Huang", "Bichen Wu", "Tianjun Zhang", "Liang Ma", "Giulio Gambardella", "Michaela Blott", "Luciano Lavagno", "Kees Vissers", "John Wawrzynek", "Kurt Keutzer"], "title": "Synetgy: Algorithm-hardware Co-design for ConvNet Accelerators on Embedded FPGAs", "url": "http://arxiv.org/pdf/1811.08634v4", "summary": "Using FPGAs to accelerate ConvNets has attracted significant attention in\nrecent years. However, FPGA accelerator design has not leveraged the latest\nprogress of ConvNets. As a result, the key application characteristics such as\nframes-per-second (FPS) are ignored in favor of simply counting GOPs, and\nresults on accuracy, which is critical to application success, are often not\neven reported. In this work, we adopt an algorithm-hardware co-design approach\nto develop a ConvNet accelerator called Synetgy and a novel ConvNet model\ncalled DiracDeltaNet$^{\\dagger}$. Both the accelerator and ConvNet are tailored\nto FPGA requirements. DiracDeltaNet, as the name suggests, is a ConvNet with\nonly $1\\times 1$ convolutions while spatial convolutions are replaced by more\nefficient shift operations. DiracDeltaNet achieves competitive accuracy on\nImageNet (88.7\\% top-5), but with 42$\\times$ fewer parameters and 48$\\times$\nfewer OPs than VGG16. We further quantize DiracDeltaNet's weights to 4-bit and\nactivations to 4-bits, with less than 1\\% accuracy loss. These quantizations\nexploit well the nature of FPGA hardware. In short, DiracDeltaNet's small model\nsize, low computational OP count, low precision and simplified operators allow\nus to co-design a highly customized computing unit for an FPGA. We implement\nthe computing units for DiracDeltaNet on an Ultra96 SoC system through\nhigh-level synthesis. Our accelerator's final top-5 accuracy of 88.1\\% on\nImageNet, is higher than all the previously reported embedded FPGA\naccelerators. In addition, the accelerator reaches an inference speed of 66.3\nFPS on the ImageNet classification task, surpassing prior works with similar\naccuracy by at least 11.6$\\times$.", "published": "2018-11-21T08:42:30Z", "version": 4}, {"aid": "1811.08728", "authors": ["Christian Wilms", "Simone Frintrop"], "title": "AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects", "url": "http://arxiv.org/pdf/1811.08728v1", "summary": "We propose a novel approach for class-agnostic object proposal generation,\nwhich is efficient and especially well-suited to detect small objects.\nEfficiency is achieved by scale-specific objectness attention maps which focus\nthe processing on promising parts of the image and reduce the amount of sampled\nwindows strongly. This leads to a system, which is $33\\%$ faster than the\nstate-of-the-art and clearly outperforming state-of-the-art in terms of average\nrecall. Secondly, we add a module for detecting small objects, which are often\nmissed by recent models. We show that this module improves the average recall\nfor small objects by about $53\\%$.", "published": "2018-11-21T13:43:43Z", "version": 1}, {"aid": "1811.09347", "authors": ["Bowen Cheng", "Yunchao Wei", "Jiahui Yu", "Shiyu Chang", "Jinjun Xiong", "Wen-Mei Hwu", "Thomas S. Huang", "Humphrey Shi"], "title": "A Simple Non-i.i.d. Sampling Approach for Efficient Training and Better Generalization", "url": "http://arxiv.org/pdf/1811.09347v2", "summary": "While training on samples drawn from independent and identical distribution\nhas been a de facto paradigm for optimizing image classification networks,\nhumans learn new concepts in an easy-to-hard manner and on the selected\nexamples progressively. Driven by this fact, we investigate the training\nparadigms where the samples are not drawn from independent and identical\ndistribution. We propose a data sampling strategy, named Drop-and-Refresh\n(DaR), motivated by the learning behaviors of humans that selectively drop easy\nsamples and refresh them only periodically. We show in our experiments that the\nproposed DaR strategy can maintain (and in many cases improve) the predictive\naccuracy even when the training cost is reduced by 15% on various datasets\n(CIFAR 10, CIFAR 100 and ImageNet) and with different backbone architectures\n(ResNets, DenseNets and MobileNets). Furthermore and perhaps more importantly,\nwe find the ImageNet pre-trained models using our DaR sampling strategy\nachieves better transferability for the downstream tasks including object\ndetection (+0.3 AP), instance segmentation (+0.3 AP), scene parsing (+0.5 mIoU)\nand human pose estimation (+0.6 AP). Our investigation encourages people to\nrethink the connections between the sampling strategy for training and the\ntransferability of its learned features for pre-training ImageNet models.", "published": "2018-11-23T02:49:47Z", "version": 2}, {"aid": "1811.09358", "authors": ["Fangyu Zou", "Li Shen", "Zequn Jie", "Weizhong Zhang", "Wei Liu"], "title": "A Sufficient Condition for Convergences of Adam and RMSProp", "url": "http://arxiv.org/pdf/1811.09358v3", "summary": "Adam and RMSProp are two of the most influential adaptive stochastic\nalgorithms for training deep neural networks, which have been pointed out to be\ndivergent even in the convex setting via a few simple counterexamples. Many\nattempts, such as decreasing an adaptive learning rate, adopting a big batch\nsize, incorporating a temporal decorrelation technique, seeking an analogous\nsurrogate, etc., have been tried to promote Adam/RMSProp-type algorithms to\nconverge. In contrast with existing approaches, we introduce an alternative\neasy-to-check sufficient condition, which merely depends on the parameters of\nthe base learning rate and combinations of historical second-order moments, to\nguarantee the global convergence of generic Adam/RMSProp for solving\nlarge-scale non-convex stochastic optimization. Moreover, we show that the\nconvergences of several variants of Adam, such as AdamNC, AdaEMA, etc., can be\ndirectly implied via the proposed sufficient condition in the non-convex\nsetting. In addition, we illustrate that Adam is essentially a specifically\nweighted AdaGrad with exponential moving average momentum, which provides a\nnovel perspective for understanding Adam and RMSProp. This observation coupled\nwith this sufficient condition gives much deeper interpretations on their\ndivergences. At last, we validate the sufficient condition by applying Adam and\nRMSProp to tackle a certain counterexample and train deep neural networks.\nNumerical results are exactly in accord with our theoretical analysis.", "published": "2018-11-23T04:26:47Z", "version": 3}, {"aid": "1811.09362", "authors": ["Yansen Wang", "Ying Shen", "Zhun Liu", "Paul Pu Liang", "Amir Zadeh", "Louis-Philippe Morency"], "title": "Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors", "url": "http://arxiv.org/pdf/1811.09362v2", "summary": "Humans convey their intentions through the usage of both verbal and nonverbal\nbehaviors during face-to-face communication. Speaker intentions often vary\ndynamically depending on different nonverbal contexts, such as vocal patterns\nand facial expressions. As a result, when modeling human language, it is\nessential to not only consider the literal meaning of the words but also the\nnonverbal contexts in which these words appear. To better model human language,\nwe first model expressive nonverbal representations by analyzing the\nfine-grained visual and acoustic patterns that occur during word segments. In\naddition, we seek to capture the dynamic nature of nonverbal intents by\nshifting word representations based on the accompanying nonverbal behaviors. To\nthis end, we propose the Recurrent Attended Variation Embedding Network (RAVEN)\nthat models the fine-grained structure of nonverbal subword sequences and\ndynamically shifts word representations based on nonverbal cues. Our proposed\nmodel achieves competitive performance on two publicly available datasets for\nmultimodal sentiment analysis and emotion recognition. We also visualize the\nshifted word representations in different nonverbal contexts and summarize\ncommon patterns regarding multimodal variations of word representations.", "published": "2018-11-23T05:13:38Z", "version": 2}, {"aid": "1811.09567", "authors": ["Yipeng Qin", "Niloy Mitra", "Peter Wonka"], "title": "How does Lipschitz Regularization Influence GAN Training?", "url": "http://arxiv.org/pdf/1811.09567v3", "summary": "Despite the success of Lipschitz regularization in stabilizing GAN training,\nthe exact reason of its effectiveness remains poorly understood. The direct\neffect of $K$-Lipschitz regularization is to restrict the $L2$-norm of the\nneural network gradient to be smaller than a threshold $K$ (e.g., $K=1$) such\nthat $\\|\\nabla f\\| \\leq K$. In this work, we uncover an even more important\neffect of Lipschitz regularization by examining its impact on the loss\nfunction: It degenerates GAN loss functions to almost linear ones by\nrestricting their domain and interval of attainable gradient values. Our\nanalysis shows that loss functions are only successful if they are degenerated\nto almost linear ones. We also show that loss functions perform poorly if they\nare not degenerated and that a wide range of functions can be used as loss\nfunction as long as they are sufficiently degenerated by regularization.\nBasically, Lipschitz regularization ensures that all loss functions effectively\nwork in the same way. Empirically, we verify our proposition on the MNIST,\nCIFAR10 and CelebA datasets.", "published": "2018-11-23T17:18:00Z", "version": 3}, {"aid": "1811.09699", "authors": ["Hossein Adeli", "Gregory Zelinsky"], "title": "Learning to attend in a brain-inspired deep neural network", "url": "http://arxiv.org/pdf/1811.09699v1", "summary": "Recent machine learning models have shown that including attention as a\ncomponent results in improved model accuracy and interpretability, despite the\nconcept of attention in these approaches only loosely approximating the brain's\nattention mechanism. Here we extend this work by building a more brain-inspired\ndeep network model of the primate ATTention Network (ATTNet) that learns to\nshift its attention so as to maximize the reward. Using deep reinforcement\nlearning, ATTNet learned to shift its attention to the visual features of a\ntarget category in the context of a search task. ATTNet's dorsal layers also\nlearned to prioritize these shifts of attention so as to maximize success of\nthe ventral pathway classification and receive greater reward. Model behavior\nwas tested against the fixations made by subjects searching images for the same\ncued category. Both subjects and ATTNet showed evidence for attention being\npreferentially directed to target goals, behaviorally measured as oculomotor\nguidance to targets. More fundamentally, ATTNet learned to shift its attention\nto target like objects and spatially route its visual inputs to accomplish the\ntask. This work makes a step toward a better understanding of the role of\nattention in the brain and other computational systems.", "published": "2018-11-23T21:23:56Z", "version": 1}, {"aid": "1811.09786", "authors": ["Yi Tay", "Luu Anh Tuan", "Siu Cheung Hui"], "title": "Recurrently Controlled Recurrent Networks", "url": "http://arxiv.org/pdf/1811.09786v1", "summary": "Recurrent neural networks (RNNs) such as long short-term memory and gated\nrecurrent units are pivotal building blocks across a broad spectrum of sequence\nmodeling problems. This paper proposes a recurrently controlled recurrent\nnetwork (RCRN) for expressive and powerful sequence encoding. More concretely,\nthe key idea behind our approach is to learn the recurrent gating functions\nusing recurrent networks. Our architecture is split into two components - a\ncontroller cell and a listener cell whereby the recurrent controller actively\ninfluences the compositionality of the listener cell. We conduct extensive\nexperiments on a myriad of tasks in the NLP domain such as sentiment analysis\n(SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment\nclassification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading\ncomprehension (NarrativeQA). Across all 26 datasets, our results demonstrate\nthat RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs,\nsuggesting that our controller architecture might be a suitable replacement for\nthe widely adopted stacked architecture.", "published": "2018-11-24T08:15:50Z", "version": 1}, {"aid": "1811.09800", "authors": ["Abhijit Guha Roy", "Sailesh Conjeti", "Nassir Navab", "Christian Wachinger"], "title": "Bayesian QuickNAT: Model Uncertainty in Deep Whole-Brain Segmentation for Structure-wise Quality Control", "url": "http://arxiv.org/pdf/1811.09800v1", "summary": "We introduce Bayesian QuickNAT for the automated quality control of\nwhole-brain segmentation on MRI T1 scans. Next to the Bayesian fully\nconvolutional neural network, we also present inherent measures of segmentation\nuncertainty that allow for quality control per brain structure. For estimating\nmodel uncertainty, we follow a Bayesian approach, wherein, Monte Carlo (MC)\nsamples from the posterior distribution are generated by keeping the dropout\nlayers active at test time. Entropy over the MC samples provides a voxel-wise\nmodel uncertainty map, whereas expectation over the MC predictions provides the\nfinal segmentation. Next to voxel-wise uncertainty, we introduce four metrics\nto quantify structure-wise uncertainty in segmentation for quality control. We\nreport experiments on four out-of-sample datasets comprising of diverse age\nrange, pathology and imaging artifacts. The proposed structure-wise uncertainty\nmetrics are highly correlated with the Dice score estimated with manual\nannotation and therefore present an inherent measure of segmentation quality.\nIn particular, the intersection over union over all the MC samples is a\nsuitable proxy for the Dice score. In addition to quality control at\nscan-level, we propose to incorporate the structure-wise uncertainty as a\nmeasure of confidence to do reliable group analysis on large data repositories.\nWe envisage that the introduced uncertainty metrics would help assess the\nfidelity of automated deep learning based segmentation methods for large-scale\npopulation studies, as they enable automated quality control and group analyses\nin processing large data repositories.", "published": "2018-11-24T09:41:28Z", "version": 1}, {"aid": "1811.10052", "authors": ["Alexander Selvikv\u00e5g Lundervold", "Arvid Lundervold"], "title": "An overview of deep learning in medical imaging focusing on MRI", "url": "http://arxiv.org/pdf/1811.10052v2", "summary": "What has happened in machine learning lately, and what does it mean for the\nfuture of medical image analysis? Machine learning has witnessed a tremendous\namount of attention over the last few years. The current boom started around\n2009 when so-called deep artificial neural networks began outperforming other\nestablished models on a number of important benchmarks. Deep neural networks\nare now the state-of-the-art machine learning models across a variety of areas,\nfrom image analysis to natural language processing, and widely deployed in\nacademia and industry. These developments have a huge potential for medical\nimaging technology, medical data analysis, medical diagnostics and healthcare\nin general, slowly being realized. We provide a short overview of recent\nadvances and some associated challenges in machine learning applied to medical\nimage processing and image analysis. As this has become a very broad and fast\nexpanding field we will not survey the entire landscape of applications, but\nput particular focus on deep learning in MRI.\n  Our aim is threefold: (i) give a brief introduction to deep learning with\npointers to core references; (ii) indicate how deep learning has been applied\nto the entire MRI processing chain, from acquisition to image retrieval, from\nsegmentation to disease prediction; (iii) provide a starting point for people\ninterested in experimenting and perhaps contributing to the field of machine\nlearning for medical imaging by pointing out good educational resources,\nstate-of-the-art open-source code, and interesting sources of data and problems\nrelated medical imaging.", "published": "2018-11-25T16:40:42Z", "version": 2}, {"aid": "1811.10111", "authors": ["Abhay Koushik", "Judith Amores", "Pattie Maes"], "title": "Real-Time Sleep Staging using Deep Learning on a Smartphone for a Wearable EEG", "url": "http://arxiv.org/pdf/1811.10111v2", "summary": "We present the first real-time sleep staging system that uses deep learning\nwithout the need for servers in a smartphone application for a wearable EEG. We\nemploy real-time adaptation of a single channel Electroencephalography (EEG) to\ninfer from a Time-Distributed 1-D Deep Convolutional Neural Network.\nPolysomnography (PSG)-the gold standard for sleep staging, requires a human\nscorer and is both complex and resource-intensive. Our work demonstrates an\nend-to-end on-smartphone pipeline that can infer sleep stages in just single\n30-second epochs, with an overall accuracy of 83.5% on 20-fold cross validation\nfor five-class classification of sleep stages using the open Sleep-EDF dataset.", "published": "2018-11-25T22:25:31Z", "version": 2}, {"aid": "1811.10146", "authors": ["Zhi-Qin John Xu"], "title": "Frequency Principle in Deep Learning with General Loss Functions and Its Potential Application", "url": "http://arxiv.org/pdf/1811.10146v1", "summary": "Previous studies have shown that deep neural networks (DNNs) with common\nsettings often capture target functions from low to high frequency, which is\ncalled Frequency Principle (F-Principle). It has also been shown that\nF-Principle can provide an understanding to the often observed good\ngeneralization ability of DNNs. However, previous studies focused on the loss\nfunction of mean square error, while various loss functions are used in\npractice. In this work, we show that the F-Principle holds for a general loss\nfunction (e.g., mean square error, cross entropy, etc.). In addition, DNN's\nF-Principle may be applied to develop numerical schemes for solving various\nproblems which would benefit from a fast converging of low frequency. As an\nexample of the potential usage of F-Principle, we apply DNN in solving\ndifferential equations, in which conventional methods (e.g., Jacobi method) is\nusually slow in solving problems due to the convergence from high to low\nfrequency.", "published": "2018-11-26T02:27:44Z", "version": 1}, {"aid": "1811.10355", "authors": ["Benjamin Graham"], "title": "Unsupervised learning with sparse space-and-time autoencoders", "url": "http://arxiv.org/pdf/1811.10355v1", "summary": "We use spatially-sparse two, three and four dimensional convolutional\nautoencoder networks to model sparse structures in 2D space, 3D space, and\n3+1=4 dimensional space-time. We evaluate the resulting latent spaces by\ntesting their usefulness for downstream tasks. Applications are to handwriting\nrecognition in 2D, segmentation for parts in 3D objects, segmentation for\nobjects in 3D scenes, and body-part segmentation for 4D wire-frame models\ngenerated from motion capture data.", "published": "2018-11-26T13:22:17Z", "version": 1}, {"aid": "1811.10798", "authors": ["Yiwen Huang", "Rihui Wu", "Pinglai Ou", "Ziyong Feng"], "title": "Sequentially Aggregated Convolutional Networks", "url": "http://arxiv.org/pdf/1811.10798v3", "summary": "Modern deep networks generally implement a certain form of shortcut\nconnections to alleviate optimization difficulties. However, we observe that\nsuch network topology alters the nature of deep networks. In many ways, these\nnetworks behave similarly to aggregated wide networks. We thus exploit the\naggregation nature of shortcut connections at a finer architectural level and\nplace them within wide convolutional layers. We end up with a sequentially\naggregated convolutional (SeqConv) layer that combines the benefits of both\nwide and deep representations by aggregating features of various depths in\nsequence. The proposed SeqConv serves as a drop-in replacement of regular wide\nconvolutional layers and thus could be handily integrated into any backbone\nnetwork. We apply SeqConv to widely adopted backbones including ResNet and\nResNeXt, and conduct experiments for image classification on public benchmark\ndatasets. Our ResNet based network with a model size of ResNet-50 easily\nsurpasses the performance of the 2.35$\\times$ larger ResNet-152, while our\nResNeXt based model sets a new state-of-the-art accuracy on ImageNet\nclassification for networks with similar model complexity. The code and\npre-trained models of our work are publicly available at\nhttps://github.com/GroupOfAlchemists/SeqConv.", "published": "2018-11-27T04:15:35Z", "version": 3}, {"aid": "1811.11051", "authors": ["Idan Kligvasser", "Tomer Michaeli"], "title": "Dense xUnit Networks", "url": "http://arxiv.org/pdf/1811.11051v1", "summary": "Deep net architectures have constantly evolved over the past few years,\nleading to significant advancements in a wide array of computer vision tasks.\nHowever, besides high accuracy, many applications also require a low\ncomputational load and limited memory footprint. To date, efficiency has\ntypically been achieved either by architectural choices at the macro level\n(e.g. using skip connections or pruning techniques) or modifications at the\nlevel of the individual layers (e.g. using depth-wise convolutions or channel\nshuffle operations). Interestingly, much less attention has been devoted to the\nrole of the activation functions in constructing efficient nets. Recently,\nKligvasser et al. showed that incorporating spatial connections within the\nactivation functions, enables a significant boost in performance in image\nrestoration tasks, at any given budget of parameters. However, the\neffectiveness of their xUnit module has only been tested on simple small\nmodels, which are not characteristic of those used in high-level vision tasks.\nIn this paper, we adopt and improve the xUnit activation, show how it can be\nincorporated into the DenseNet architecture, and illustrate its high\neffectiveness for classification and image restoration tasks alike. While the\nDenseNet architecture is extremely efficient to begin with, our dense xUnit net\n(DxNet) can typically achieve the same performance with far fewer parameters.\nFor example, on ImageNet, our DxNet outperforms a ReLU-based DenseNet having\n30% more parameters and achieves state-of-the-art results for this budget of\nparameters. Furthermore, in denoising and super-resolution, DxNet significantly\nimproves upon all existing lightweight solutions, including the xUnit-based\nnets of Kligvasser et al.", "published": "2018-11-27T15:21:50Z", "version": 1}, {"aid": "1811.11168", "authors": ["Xizhou Zhu", "Han Hu", "Stephen Lin", "Jifeng Dai"], "title": "Deformable ConvNets v2: More Deformable, Better Results", "url": "http://arxiv.org/pdf/1811.11168v2", "summary": "The superior performance of Deformable Convolutional Networks arises from its\nability to adapt to the geometric variations of objects. Through an examination\nof its adaptive behavior, we observe that while the spatial support for its\nneural features conforms more closely than regular ConvNets to object\nstructure, this support may nevertheless extend well beyond the region of\ninterest, causing features to be influenced by irrelevant image content. To\naddress this problem, we present a reformulation of Deformable ConvNets that\nimproves its ability to focus on pertinent image regions, through increased\nmodeling power and stronger training. The modeling power is enhanced through a\nmore comprehensive integration of deformable convolution within the network,\nand by introducing a modulation mechanism that expands the scope of deformation\nmodeling. To effectively harness this enriched modeling capability, we guide\nnetwork training via a proposed feature mimicking scheme that helps the network\nto learn features that reflect the object focus and classification power of\nR-CNN features. With the proposed contributions, this new version of Deformable\nConvNets yields significant performance gains over the original model and\nproduces leading results on the COCO benchmark for object detection and\ninstance segmentation.", "published": "2018-11-27T18:58:11Z", "version": 2}, {"aid": "1811.11205", "authors": ["Zhourong Chen", "Yang Li", "Samy Bengio", "Si Si"], "title": "You Look Twice: GaterNet for Dynamic Filter Selection in CNNs", "url": "http://arxiv.org/pdf/1811.11205v2", "summary": "The concept of conditional computation for deep nets has been proposed\npreviously to improve model performance by selectively using only parts of the\nmodel conditioned on the sample it is processing. In this paper, we investigate\ninput-dependent dynamic filter selection in deep convolutional neural networks\n(CNNs). The problem is interesting because the idea of forcing different parts\nof the model to learn from different types of samples may help us acquire\nbetter filters in CNNs, improve the model generalization performance and\npotentially increase the interpretability of model behavior. We propose a novel\nyet simple framework called GaterNet, which involves a backbone and a gater\nnetwork. The backbone network is a regular CNN that performs the major\ncomputation needed for making a prediction, while a global gater network is\nintroduced to generate binary gates for selectively activating filters in the\nbackbone network based on each input. Extensive experiments on CIFAR and\nImageNet datasets show that our models consistently outperform the original\nmodels with a large margin. On CIFAR-10, our model also improves upon\nstate-of-the-art results.", "published": "2018-11-27T19:14:49Z", "version": 2}, {"aid": "1811.11236", "authors": ["Liane Gabora"], "title": "The Making of a Creative Worldview", "url": "http://arxiv.org/pdf/1811.11236v1", "summary": "Research at the interface between cognitive psychology, neuroscience, and the\nscience of complex, dynamical systems, is piecing together an understanding of\nthe creative process, including how it works, how it can be fostered, and the\ndevelopmental antecedents and personality traits of particularly creative\npeople. This chapter examines the workings of creative minds, those with the\npotential to significantly impact the evolution of human culture.", "published": "2018-11-27T20:14:31Z", "version": 1}, {"aid": "1811.11876", "authors": ["Rajesh P. N. Rao"], "title": "Towards Neural Co-Processors for the Brain: Combining Decoding and Encoding in Brain-Computer Interfaces", "url": "http://arxiv.org/pdf/1811.11876v2", "summary": "The field of brain-computer interfaces is poised to advance from the\ntraditional goal of controlling prosthetic devices using brain signals to\ncombining neural decoding and encoding within a single neuroprosthetic device.\nSuch a device acts as a \"co-processor\" for the brain, with applications ranging\nfrom inducing Hebbian plasticity for rehabilitation after brain injury to\nreanimating paralyzed limbs and enhancing memory. We review recent progress in\nsimultaneous decoding and encoding for closed-loop control and plasticity\ninduction. To address the challenge of multi-channel decoding and encoding, we\nintroduce a unifying framework for developing brain co-processors based on\nartificial neural networks and deep learning. These \"neural co-processors\" can\nbe used to jointly optimize cost functions with the nervous system to achieve\ndesired behaviors ranging from targeted neuro-rehabilitation to augmentation of\nbrain function.", "published": "2018-11-28T23:13:24Z", "version": 2}, {"aid": "1811.11987", "authors": ["Laurent Bou\u00e9"], "title": "Deep learning for pedestrians: backpropagation in CNNs", "url": "http://arxiv.org/pdf/1811.11987v1", "summary": "The goal of this document is to provide a pedagogical introduction to the\nmain concepts underpinning the training of deep neural networks using gradient\ndescent; a process known as backpropagation. Although we focus on a very\ninfluential class of architectures called \"convolutional neural networks\"\n(CNNs) the approach is generic and useful to the machine learning community as\na whole. Motivated by the observation that derivations of backpropagation are\noften obscured by clumsy index-heavy narratives that appear somewhat\nmathemagical, we aim to offer a conceptually clear, vectorized description that\narticulates well the higher level logic. Following the principle of \"writing is\nnature's way of letting you know how sloppy your thinking is\", we try to make\nthe calculations meticulous, self-contained and yet as intuitive as possible.\nTaking nothing for granted, ample illustrations serve as visual guides and an\nextensive bibliography is provided for further explorations.\n  (For the sake of clarity, long mathematical derivations and visualizations\nhave been broken up into short \"summarized views\" and longer \"detailed views\"\nencoded into the PDF as optional content groups. Some figures contain\nanimations designed to illustrate important concepts in a more engaging style.\nFor these reasons, we advise to download the document locally and open it using\nAdobe Acrobat Reader. Other viewers were not tested and may not render the\ndetailed views, animations correctly.)", "published": "2018-11-29T07:00:09Z", "version": 1}, {"aid": "1811.12043", "authors": ["Jun-Hyuk Kim", "Jun-Ho Choi", "Manri Cheon", "Jong-Seok Lee"], "title": "MAMNet: Multi-path Adaptive Modulation Network for Image Super-Resolution", "url": "http://arxiv.org/pdf/1811.12043v2", "summary": "In recent years, single image super-resolution (SR) methods based on deep\nconvolutional neural networks (CNNs) have made significant progress. However,\ndue to the non-adaptive nature of the convolution operation, they cannot adapt\nto various characteristics of images, which limits their representational\ncapability and, consequently, results in unnecessarily large model sizes. To\naddress this issue, we propose a novel multi-path adaptive modulation network\n(MAMNet). Specifically, we propose a multi-path adaptive modulation block\n(MAMB), which is a lightweight yet effective residual block that adaptively\nmodulates residual feature responses by fully exploiting their information via\nthree paths. The three paths model three types of information suitable for SR:\n1) channel-specific information (CSI) using global variance pooling, 2)\ninter-channel dependencies (ICD) based on the CSI, 3) and channel-specific\nspatial dependencies (CSD) via depth-wise convolution. We demonstrate that the\nproposed MAMB is effective and parameter-efficient for image SR than other\nfeature modulation methods. In addition, experimental results show that our\nMAMNet outperforms most of the state-of-the-art methods with a relatively small\nnumber of parameters.", "published": "2018-11-29T09:59:31Z", "version": 2}, {"aid": "1811.12091", "authors": ["Patrick Krauss", "Karin Prebeck", "Achim Schilling", "Claus Metzner"], "title": "Stochastic resonance in three-neuron motifs", "url": "http://arxiv.org/pdf/1811.12091v1", "summary": "Stochastic resonance is a non-linear phenomenon, in which the sensitivity of\nsignal detectors can be enhanced by adding random noise to the detector input.\nHere, we demonstrate that noise can also improve the information flux in\nrecurrent neural networks. In particular, we show for the case of three-neuron\nmotifs that the mutual information between successive network states can be\nmaximized by adding a suitable amount of noise to the neuron inputs. This\nstriking result suggests that noise in the brain may not be a problem that\nneeds to be suppressed, but indeed a resource that is dynamically regulated in\norder to optimize information processing.", "published": "2018-11-29T12:12:47Z", "version": 1}, {"aid": "1811.12108", "authors": ["Kilho Son", "Jesse Hostetler", "Sek Chai"], "title": "Bootstrapping Deep Neural Networks from Approximate Image Processing Pipelines", "url": "http://arxiv.org/pdf/1811.12108v2", "summary": "Complex image processing and computer vision systems often consist of a\nprocessing pipeline of functional modules. We intend to replace parts or all of\na target pipeline with deep neural networks to achieve benefits such as\nincreased accuracy or reduced computational requirement. To acquire a large\namount of labeled data necessary to train the deep neural network, we propose a\nworkflow that leverages the target pipeline to create a significantly larger\nlabeled training set automatically, without prior domain knowledge of the\ntarget pipeline. We show experimentally that despite the noise introduced by\nautomated labeling and only using a very small initially labeled data set, the\ntrained deep neural networks can achieve similar or even better performance\nthan the components they replace, while in some cases also reducing\ncomputational requirements.", "published": "2018-11-29T12:54:51Z", "version": 2}, {"aid": "1811.12231", "authors": ["Robert Geirhos", "Patricia Rubisch", "Claudio Michaelis", "Matthias Bethge", "Felix A. Wichmann", "Wieland Brendel"], "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness", "url": "http://arxiv.org/pdf/1811.12231v3", "summary": "Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation.", "published": "2018-11-29T15:04:05Z", "version": 3}, {"aid": "1811.12248", "authors": ["Yuancheng Ye", "Xiaodong Yang", "Yingli Tian"], "title": "Discovering Spatio-Temporal Action Tubes", "url": "http://arxiv.org/pdf/1811.12248v1", "summary": "In this paper, we address the challenging problem of spatial and temporal\naction detection in videos. We first develop an effective approach to localize\nframe-level action regions through integrating static and kinematic information\nby the early- and late-fusion detection scheme. With the intention of exploring\nimportant temporal connections among the detected action regions, we propose a\ntracking-by-point-matching algorithm to stitch the discrete action regions into\na continuous spatio-temporal action tube. Recurrent 3D convolutional neural\nnetwork is used to predict action categories and determine temporal boundaries\nof the generated tubes. We then introduce an action footprint map to refine the\ncandidate tubes based on the action-specific spatial characteristics preserved\nin the convolutional layers of R3DCNN. In the extensive experiments, our method\nachieves superior detection results on the three public benchmark datasets:\nUCFSports, J-HMDB and UCF101.", "published": "2018-11-29T15:29:43Z", "version": 1}, {"aid": "1811.12560", "authors": ["Vincent Francois-Lavet", "Peter Henderson", "Riashat Islam", "Marc G. Bellemare", "Joelle Pineau"], "title": "An Introduction to Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1811.12560v2", "summary": "Deep reinforcement learning is the combination of reinforcement learning (RL)\nand deep learning. This field of research has been able to solve a wide range\nof complex decision-making tasks that were previously out of reach for a\nmachine. Thus, deep RL opens up many new applications in domains such as\nhealthcare, robotics, smart grids, finance, and many more. This manuscript\nprovides an introduction to deep reinforcement learning models, algorithms and\ntechniques. Particular focus is on the aspects related to generalization and\nhow deep RL can be used for practical applications. We assume the reader is\nfamiliar with basic machine learning concepts.", "published": "2018-11-30T00:57:30Z", "version": 2}, {"aid": "1811.12642", "authors": ["Tomasz M. Rutkowski", "Qibin Zhao", "Masao S. Abe", "Mihoko Otake"], "title": "AI Neurotechnology for Aging Societies -- Task-load and Dementia EEG Digital Biomarker Development Using Information Geometry Machine Learning Methods", "url": "http://arxiv.org/pdf/1811.12642v1", "summary": "Dementia and especially Alzheimer's disease (AD) are the most common causes\nof cognitive decline in elderly people. A spread of the above mentioned mental\nhealth problems in aging societies is causing a significant medical and\neconomic burden in many countries around the world. According to a recent World\nHealth Organization (WHO) report, it is approximated that currently, worldwide,\nabout 47 million people live with a dementia spectrum of neurocognitive\ndisorders. This number is expected to triple by 2050, which calls for possible\napplication of AI-based technologies to support an early screening for\npreventive interventions and a subsequent mental wellbeing monitoring as well\nas maintenance with so-called digital-pharma or beyond a pill therapeutical\napproaches. This paper discusses our attempt and preliminary results of\nbrainwave (EEG) techniques to develop digital biomarkers for dementia progress\ndetection and monitoring. We present an information geometry-based\nclassification approach for automatic EEG-derived event related responses\n(ERPs) discrimination of low versus high task-load auditory or tactile stimuli\nrecognition, of which amplitude and latency variabilities are similar to those\nin dementia. The discussed approach is a step forward to develop AI, and\nespecially machine learning (ML) approaches, for the subsequent application to\nmild-cognitive impairment (MCI) and AD diagnostics.", "published": "2018-11-30T06:58:16Z", "version": 1}, {"aid": "1812.00020", "authors": ["Jingwei Huang", "Haotian Zhang", "Li Yi", "Thomas Funkhouser", "Matthias Nie\u00dfner", "Leonidas Guibas"], "title": "TextureNet: Consistent Local Parametrizations for Learning from High-Resolution Signals on Meshes", "url": "http://arxiv.org/pdf/1812.00020v2", "summary": "We introduce, TextureNet, a neural network architecture designed to extract\nfeatures from high-resolution signals associated with 3D surface meshes (e.g.,\ncolor texture maps). The key idea is to utilize a 4-rotational symmetric\n(4-RoSy) field to define a domain for convolution on a surface. Though 4-RoSy\nfields have several properties favorable for convolution on surfaces (low\ndistortion, few singularities, consistent parameterization, etc.), orientations\nare ambiguous up to 4-fold rotation at any sample point. So, we introduce a new\nconvolutional operator invariant to the 4-RoSy ambiguity and use it in a\nnetwork to extract features from high-resolution signals on geodesic\nneighborhoods of a surface. In comparison to alternatives, such as PointNet\nbased methods which lack a notion of orientation, the coherent structure given\nby these neighborhoods results in significantly stronger features. As an\nexample application, we demonstrate the benefits of our architecture for 3D\nsemantic segmentation of textured 3D meshes. The results show that our method\noutperforms all existing methods on the basis of mean IoU by a significant\nmargin in both geometry-only (6.4%) and RGB+Geometry (6.9-8.2%) settings.", "published": "2018-11-30T19:01:09Z", "version": 2}, {"aid": "1812.00136", "authors": ["Yujian Li"], "title": "Theory of Cognitive Relativity: A Promising Paradigm for True AI", "url": "http://arxiv.org/pdf/1812.00136v3", "summary": "The rise of deep learning has brought artificial intelligence (AI) to the\nforefront. The ultimate goal of AI is to realize machines with human mind and\nconsciousness, but existing achievements mainly simulate intelligent behavior\non computer platforms. These achievements all belong to weak AI rather than\nstrong AI. How to achieve strong AI is not known yet in the field of\nintelligence science. Currently, this field is calling for a new paradigm,\nespecially Theory of Cognitive Relativity (TCR). The TCR aims to summarize a\nsimple and elegant set of first principles about the nature of intelligence, at\nleast including the Principle of World's Relativity and the Principle of\nSymbol's Relativity. The Principle of World's Relativity states that the\nsubjective world an intelligent agent can observe is strongly constrained by\nthe way it perceives the objective world. The Principle of Symbol's Relativity\nstates that an intelligent agent can use any physical symbol system to express\nwhat it observes in its subjective world. The two principles are derived from\nscientific facts and life experience. Thought experiments show that they are\nimportant to understand high-level intelligence and necessary to establish a\nscientific theory of mind and consciousness. Rather than brain-like\nintelligence, the TCR indeed advocates a promising change in direction to\nrealize true AI, i.e. artificial general intelligence or artificial\nconsciousness, particularly different from humans' and animals'. Furthermore, a\nTCR creed has been presented and extended to reveal the secrets of\nconsciousness and to guide realization of conscious machines. In the sense that\ntrue AI could be diversely implemented in a brain-different way, the TCR would\nprobably drive an intelligence revolution in combination with some additional\nfirst principles.", "published": "2018-12-01T04:01:03Z", "version": 3}, {"aid": "1812.00231", "authors": ["Assaf Shocher", "Shai Bagon", "Phillip Isola", "Michal Irani"], "title": "InGAN: Capturing and Remapping the \"DNA\" of a Natural Image", "url": "http://arxiv.org/pdf/1812.00231v2", "summary": "Generative Adversarial Networks (GANs) typically learn a distribution of\nimages in a large image dataset, and are then able to generate new images from\nthis distribution. However, each natural image has its own internal statistics,\ncaptured by its unique distribution of patches. In this paper we propose an\n\"Internal GAN\" (InGAN) - an image-specific GAN - which trains on a single input\nimage and learns its internal distribution of patches. It is then able to\nsynthesize a plethora of new natural images of significantly different sizes,\nshapes and aspect-ratios - all with the same internal patch-distribution (same\n\"DNA\") as the input image. In particular, despite large changes in global\nsize/shape of the image, all elements inside the image maintain their local\nsize/shape. InGAN is fully unsupervised, requiring no additional data other\nthan the input image itself. Once trained on the input image, it can remap the\ninput to any size or shape in a single feedforward pass, while preserving the\nsame internal patch distribution. InGAN provides a unified framework for a\nvariety of tasks, bridging the gap between textures and natural images.", "published": "2018-12-01T17:48:02Z", "version": 2}, {"aid": "1812.00278", "authors": ["Nikolaus Kriegeskorte", "Pamela K. Douglas"], "title": "Interpreting Encoding and Decoding Models", "url": "http://arxiv.org/pdf/1812.00278v2", "summary": "Encoding and decoding models are widely used in systems, cognitive, and\ncomputational neuroscience to make sense of brain-activity data. However, the\ninterpretation of their results requires care. Decoding models can help reveal\nwhether particular information is present in a brain region in a format the\ndecoder can exploit. Encoding models make comprehensive predictions about\nrepresentational spaces. In the context of sensory systems, encoding models\nenable us to test and compare brain-computational models, and thus directly\nconstrain computational theory. Encoding and decoding models typically include\nfitted linear-model components. Sometimes the weights of the fitted linear\ncombinations are interpreted as reflecting, in an encoding model, the\ncontribution of different sensory features to the representation or, in a\ndecoding model, the contribution of different measured brain responses to a\ndecoded feature. Such interpretations can be problematic when the predictor\nvariables or their noise components are correlated and when priors (or\npenalties) are used to regularize the fit. Encoding and decoding models are\nevaluated in terms of their generalization performance. The correct\ninterpretation depends on the level of generalization a model achieves (e.g. to\nnew response measurements for the same stimuli, to new stimuli from the same\npopulation, or to stimuli from a different population). Significant decoding or\nencoding performance of a single model (at whatever level of generality) does\nnot provide strong constraints for theory. Many models must be tested and\ninferentially compared for analyses to drive theoretical progress.", "published": "2018-12-01T22:58:55Z", "version": 2}, {"aid": "1812.01714", "authors": ["Yuji Yoshimura", "Bill Cai", "Zhoutong Wang", "Carlo Ratti"], "title": "Deep Learning Architect: Classification for Architectural Design through the Eye of Artificial Intelligence", "url": "http://arxiv.org/pdf/1812.01714v1", "summary": "This paper applies state-of-the-art techniques in deep learning and computer\nvision to measure visual similarities between architectural designs by\ndifferent architects. Using a dataset consisting of web scraped images and an\noriginal collection of images of architectural works, we first train a deep\nconvolutional neural network (DCNN) model capable of achieving 73% accuracy in\nclassifying works belonging to 34 different architects. Through examining the\nweights in the trained DCNN model, we are able to quantitatively measure the\nvisual similarities between architects that are implicitly learned by our\nmodel. Using this measure, we cluster architects that are identified to be\nsimilar and compare our findings to conventional classification made by\narchitectural historians and theorists. Our clustering of architectural designs\nremarkably corroborates conventional views in architectural history, and the\nlearned architectural features also coheres with the traditional understanding\nof architectural designs.", "published": "2018-12-03T00:30:59Z", "version": 1}, {"aid": "1812.00722", "authors": ["Petros Koutras", "Petros Maragos"], "title": "SUSiNet: See, Understand and Summarize it", "url": "http://arxiv.org/pdf/1812.00722v2", "summary": "In this work we propose a multi-task spatio-temporal network, called SUSiNet,\nthat can jointly tackle the spatio-temporal problems of saliency estimation,\naction recognition and video summarization. Our approach employs a single\nnetwork that is jointly end-to-end trained for all tasks with multiple and\ndiverse datasets related to the exploring tasks. The proposed network uses a\nunified architecture that includes global and task specific layer and produces\nmultiple output types, i.e., saliency maps or classification labels, by\nemploying the same video input. Moreover, one additional contribution is that\nthe proposed network can be deeply supervised through an attention module that\nis related to human attention as it is expressed by eye-tracking data. From the\nextensive evaluation, on seven different datasets, we have observed that the\nmulti-task network performs as well as the state-of-the-art single-task methods\n(or in some cases better), while it requires less computational budget than\nhaving one independent network per each task.", "published": "2018-12-03T13:21:51Z", "version": 2}, {"aid": "1812.01719", "authors": ["Patrick McClure", "Nao Rho", "John A. Lee", "Jakub R. Kaczmarzyk", "Charles Zheng", "Satrajit S. Ghosh", "Dylan Nielson", "Adam G. Thomas", "Peter Bandettini", "Francisco Pereira"], "title": "Knowing what you know in brain segmentation using Bayesian deep neural networks", "url": "http://arxiv.org/pdf/1812.01719v5", "summary": "In this paper, we describe a Bayesian deep neural network (DNN) for\npredicting FreeSurfer segmentations of structural MRI volumes, in minutes\nrather than hours. The network was trained and evaluated on a large dataset (n\n= 11,480), obtained by combining data from more than a hundred different sites,\nand also evaluated on another completely held-out dataset (n = 418). The\nnetwork was trained using a novel spike-and-slab dropout-based variational\ninference approach. We show that, on these datasets, the proposed Bayesian DNN\noutperforms previously proposed methods, in terms of the similarity between the\nsegmentation predictions and the FreeSurfer labels, and the usefulness of the\nestimate uncertainty of these predictions. In particular, we demonstrated that\nthe prediction uncertainty of this network at each voxel is a good indicator of\nwhether the network has made an error and that the uncertainty across the whole\nbrain can predict the manual quality control ratings of a scan. The proposed\nBayesian DNN method should be applicable to any new network architecture for\naddressing the segmentation problem.", "published": "2018-12-03T13:23:30Z", "version": 5}, {"aid": "1812.02578", "authors": ["Daniel Estrada"], "title": "Conscious enactive computation", "url": "http://arxiv.org/pdf/1812.02578v1", "summary": "This paper looks at recent debates in the enactivist literature on\ncomputation and consciousness in order to assess major obstacles to building\nartificial conscious agents. We consider a proposal from Villalobos and\nDewhurst (2018) for enactive computation on the basis of organizational\nclosure. We attempt to improve the argument by reflecting on the closed paths\nthrough state space taken by finite state automata. This motivates a defense\nagainst Clark's recent criticisms of \"extended consciousness\", and perhaps a\nnew perspective on living with machines.", "published": "2018-12-03T17:48:11Z", "version": 1}, {"aid": "1812.01024", "authors": ["Vincent Sitzmann", "Justus Thies", "Felix Heide", "Matthias Nie\u00dfner", "Gordon Wetzstein", "Michael Zollh\u00f6fer"], "title": "DeepVoxels: Learning Persistent 3D Feature Embeddings", "url": "http://arxiv.org/pdf/1812.01024v2", "summary": "In this work, we address the lack of 3D understanding of generative neural\nnetworks by introducing a persistent 3D feature embedding for view synthesis.\nTo this end, we propose DeepVoxels, a learned representation that encodes the\nview-dependent appearance of a 3D scene without having to explicitly model its\ngeometry. At its core, our approach is based on a Cartesian 3D grid of\npersistent embedded features that learn to make use of the underlying 3D scene\nstructure. Our approach combines insights from 3D geometric computer vision\nwith recent advances in learning image-to-image mappings based on adversarial\nloss functions. DeepVoxels is supervised, without requiring a 3D reconstruction\nof the scene, using a 2D re-rendering loss and enforces perspective and\nmulti-view geometry in a principled manner. We apply our persistent 3D scene\nrepresentation to the problem of novel view synthesis demonstrating\nhigh-quality results for a variety of challenging scenes.", "published": "2018-12-03T19:01:01Z", "version": 2}, {"aid": "1812.01243", "authors": ["Zhuoran Shen", "Mingyuan Zhang", "Haiyu Zhao", "Shuai Yi", "Hongsheng Li"], "title": "Efficient Attention: Attention with Linear Complexities", "url": "http://arxiv.org/pdf/1812.01243v10", "summary": "Dot-product attention has wide applications in computer vision and natural\nlanguage processing. However, its memory and computational costs grow\nquadratically with the input size. Such growth prohibits its application on\nhigh-resolution inputs. To remedy this drawback, this paper proposes a novel\nefficient attention mechanism equivalent to dot-product attention but with\nsubstantially less memory and computational costs. Its resource efficiency\nallows more widespread and flexible integration of attention modules into a\nnetwork, which leads to better accuracies. Empirical evaluations demonstrated\nthe effectiveness of its advantages. Efficient attention modules brought\nsignificant performance boosts to object detectors and instance segmenters on\nMS-COCO 2017. Further, the resource efficiency democratizes attention to\ncomplex models, where high costs prohibit the use of dot-product attention. As\nan exemplar, a model with efficient attention achieved state-of-the-art\naccuracies for stereo depth estimation on the Scene Flow dataset. Code is\navailable at https://github.com/cmsflash/efficient-attention.", "published": "2018-12-04T06:41:46Z", "version": 10}, {"aid": "1812.01569", "authors": ["Iris Rubi Seaman", "Jan-Willem van de Meent", "David Wingate"], "title": "Nested Reasoning About Autonomous Agents Using Probabilistic Programs", "url": "http://arxiv.org/pdf/1812.01569v2", "summary": "As autonomous agents become more ubiquitous, they will eventually have to\nreason about the plans of other agents, which is known as theory of mind\nreasoning. We develop a planning-as-inference framework in which agents perform\nnested simulation to reason about the behavior of other agents in an online\nmanner. As a concrete application of this framework, we use probabilistic\nprograms to model a high-uncertainty variant of pursuit-evasion games in which\nan agent must make inferences about the other agents' plans to craft\ncounter-plans. Our probabilistic programs incorporate a variety of complex\nprimitives such as field-of-view calculations and path planners, which enable\nus to model quasi-realistic scenarios in a computationally tractable manner. We\nperform extensive experimental evaluations which establish a variety of\nrational behaviors and quantify how allocating computation across levels of\nnesting affects the variance of our estimators.", "published": "2018-12-04T18:19:34Z", "version": 2}, {"aid": "1812.01600", "authors": ["Mahyar Najibi", "Bharat Singh", "Larry S. Davis"], "title": "AutoFocus: Efficient Multi-Scale Inference", "url": "http://arxiv.org/pdf/1812.01600v2", "summary": "This paper describes AutoFocus, an efficient multi-scale inference algorithm\nfor deep-learning based object detectors. Instead of processing an entire image\npyramid, AutoFocus adopts a coarse to fine approach and only processes regions\nwhich are likely to contain small objects at finer scales. This is achieved by\npredicting category agnostic segmentation maps for small objects at coarser\nscales, called FocusPixels. FocusPixels can be predicted with high recall, and\nin many cases, they only cover a small fraction of the entire image. To make\nefficient use of FocusPixels, an algorithm is proposed which generates compact\nrectangular FocusChips which enclose FocusPixels. The detector is only applied\ninside FocusChips, which reduces computation while processing finer scales.\nDifferent types of error can arise when detections from FocusChips of multiple\nscales are combined, hence techniques to correct them are proposed. AutoFocus\nobtains an mAP of 47.9% (68.3% at 50% overlap) on the COCO test-dev set while\nprocessing 6.4 images per second on a Titan X (Pascal) GPU. This is 2.5X faster\nthan our multi-scale baseline detector and matches its mAP. The number of\npixels processed in the pyramid can be reduced by 5X with a 1% drop in mAP.\nAutoFocus obtains more than 10% mAP gain compared to RetinaNet but runs at the\nsame speed with the same ResNet-101 backbone.", "published": "2018-12-04T18:57:08Z", "version": 2}, {"aid": "1812.01659", "authors": ["Oren Dovrat", "Itai Lang", "Shai Avidan"], "title": "Learning to Sample", "url": "http://arxiv.org/pdf/1812.01659v2", "summary": "Processing large point clouds is a challenging task. Therefore, the data is\noften sampled to a size that can be processed more easily. The question is how\nto sample the data? A popular sampling technique is Farthest Point Sampling\n(FPS). However, FPS is agnostic to a downstream application (classification,\nretrieval, etc.). The underlying assumption seems to be that minimizing the\nfarthest point distance, as done by FPS, is a good proxy to other objective\nfunctions.\n  We show that it is better to learn how to sample. To do that, we propose a\ndeep network to simplify 3D point clouds. The network, termed S-NET, takes a\npoint cloud and produces a smaller point cloud that is optimized for a\nparticular task. The simplified point cloud is not guaranteed to be a subset of\nthe original point cloud. Therefore, we match it to a subset of the original\npoints in a post-processing step. We contrast our approach with FPS by\nexperimenting on two standard data sets and show significantly better results\nfor a variety of applications. Our code is publicly available at:\nhttps://github.com/orendv/learning_to_sample", "published": "2018-12-04T19:58:44Z", "version": 2}, {"aid": "1812.01754", "authors": ["Xingchao Peng", "Qinxun Bai", "Xide Xia", "Zijun Huang", "Kate Saenko", "Bo Wang"], "title": "Moment Matching for Multi-Source Domain Adaptation", "url": "http://arxiv.org/pdf/1812.01754v4", "summary": "Conventional unsupervised domain adaptation (UDA) assumes that training data\nare sampled from a single domain. This neglects the more practical scenario\nwhere training data are collected from multiple sources, requiring multi-source\ndomain adaptation. We make three major contributions towards addressing this\nproblem. First, we collect and annotate by far the largest UDA dataset, called\nDomainNet, which contains six domains and about 0.6 million images distributed\namong 345 categories, addressing the gap in data availability for multi-source\nUDA research. Second, we propose a new deep learning approach, Moment Matching\nfor Multi-Source Domain Adaptation M3SDA, which aims to transfer knowledge\nlearned from multiple labeled source domains to an unlabeled target domain by\ndynamically aligning moments of their feature distributions. Third, we provide\nnew theoretical insights specifically for moment matching approaches in both\nsingle and multiple source domain adaptation. Extensive experiments are\nconducted to demonstrate the power of our new dataset in benchmarking\nstate-of-the-art multi-source domain adaptation methods, as well as the\nadvantage of our proposed model. Dataset and Code are available at\n\\url{http://ai.bu.edu/M3SDA/}.", "published": "2018-12-04T23:43:37Z", "version": 4}, {"aid": "1812.01894", "authors": ["Wei Shen", "Rujie Liu"], "title": "Learning to generate filters for convolutional neural networks", "url": "http://arxiv.org/pdf/1812.01894v1", "summary": "Conventionally, convolutional neural networks (CNNs) process different images\nwith the same set of filters. However, the variations in images pose a\nchallenge to this fashion. In this paper, we propose to generate\nsample-specific filters for convolutional layers in the forward pass. Since the\nfilters are generated on-the-fly, the model becomes more flexible and can\nbetter fit the training data compared to traditional CNNs. In order to obtain\nsample-specific features, we extract the intermediate feature maps from an\nautoencoder. As filters are usually high dimensional, we propose to learn a set\nof coefficients instead of a set of filters. These coefficients are used to\nlinearly combine the base filters from a filter repository to generate the\nfinal filters for a CNN. The proposed method is evaluated on MNIST, MTFL and\nCIFAR10 datasets. Experiment results demonstrate that the classification\naccuracy of the baseline model can be improved by using the proposed filter\ngeneration method.", "published": "2018-12-05T10:16:38Z", "version": 1}, {"aid": "1812.02068", "authors": ["Qiaoying Huang", "Xiao Chen", "Dimitris Metaxas", "Mariappan S. Nadar"], "title": "Brain Segmentation from k-space with End-to-end Recurrent Attention Network", "url": "http://arxiv.org/pdf/1812.02068v2", "summary": "The task of medical image segmentation commonly involves an image\nreconstruction step to convert acquired raw data to images before any analysis.\nHowever, noises, artifacts and loss of information due to the reconstruction\nprocess are almost inevitable, which compromises the final performance of\nsegmentation. We present a novel learning framework that performs magnetic\nresonance brain image segmentation directly from k-space data. The end-to-end\nframework consists of a unique task-driven attention module that recurrently\nutilizes intermediate segmentation estimation to facilitate image-domain\nfeature extraction from the raw data, thus closely bridging the reconstruction\nand the segmentation tasks. In addition, to address the challenge of manual\nlabeling, we introduce a novel workflow to generate labeled training data for\nsegmentation by exploiting imaging modality simulators and digital phantoms.\nExtensive experimental results show that the proposed method outperforms\nseveral state-of-the-art methods.", "published": "2018-12-05T16:01:28Z", "version": 2}, {"aid": "1812.02340", "authors": ["Daniel Philps", "Tillman Weyde", "Artur d'Avila Garcez", "Roy Batchelor"], "title": "Continual Learning Augmented Investment Decisions", "url": "http://arxiv.org/pdf/1812.02340v4", "summary": "Investment decisions can benefit from incorporating an accumulated knowledge\nof the past to drive future decision making. We introduce Continual Learning\nAugmentation (CLA) which is based on an explicit memory structure and a feed\nforward neural network (FFNN) base model and used to drive long term financial\ninvestment decisions. We demonstrate that our approach improves accuracy in\ninvestment decision making while memory is addressed in an explainable way. Our\napproach introduces novel remember cues, consisting of empirically learned\nchange points in the absolute error series of the FFNN. Memory recall is also\nnovel, with contextual similarity assessed over time by sampling distances\nusing dynamic time warping (DTW). We demonstrate the benefits of our approach\nby using it in an expected return forecasting task to drive investment\ndecisions. In an investment simulation in a broad international equity universe\nbetween 2003-2017, our approach significantly outperforms FFNN base models. We\nalso illustrate how CLA's memory addressing works in practice, using a worked\nexample to demonstrate the explainability of our approach.", "published": "2018-12-06T04:26:25Z", "version": 4}, {"aid": "1812.02375", "authors": ["Yuhui Xu", "Shuai Zhang", "Yingyong Qi", "Jiaxian Guo", "Weiyao Lin", "Hongkai Xiong"], "title": "DNQ: Dynamic Network Quantization", "url": "http://arxiv.org/pdf/1812.02375v1", "summary": "Network quantization is an effective method for the deployment of neural\nnetworks on memory and energy constrained mobile devices. In this paper, we\npropose a Dynamic Network Quantization (DNQ) framework which is composed of two\nmodules: a bit-width controller and a quantizer. Unlike most existing\nquantization methods that use a universal quantization bit-width for the whole\nnetwork, we utilize policy gradient to train an agent to learn the bit-width of\neach layer by the bit-width controller. This controller can make a trade-off\nbetween accuracy and compression ratio. Given the quantization bit-width\nsequence, the quantizer adopts the quantization distance as the criterion of\nthe weights importance during quantization. We extensively validate the\nproposed approach on various main-stream neural networks and obtain impressive\nresults.", "published": "2018-12-06T07:06:17Z", "version": 1}, {"aid": "1812.02415", "authors": ["Oshri Halimi", "Or Litany", "Emanuele Rodol\u00e0", "Alex Bronstein", "Ron Kimmel"], "title": "Self-supervised Learning of Dense Shape Correspondence", "url": "http://arxiv.org/pdf/1812.02415v1", "summary": "We introduce the first completely unsupervised correspondence learning\napproach for deformable 3D shapes. Key to our model is the understanding that\nnatural deformations (such as changes in pose) approximately preserve the\nmetric structure of the surface, yielding a natural criterion to drive the\nlearning process toward distortion-minimizing predictions. On this basis, we\novercome the need for annotated data and replace it by a purely geometric\ncriterion. The resulting learning model is class-agnostic, and is able to\nleverage any type of deformable geometric data for the training phase. In\ncontrast to existing supervised approaches which specialize on the class seen\nat training time, we demonstrate stronger generalization as well as\napplicability to a variety of challenging settings. We showcase our method on a\nwide selection of correspondence benchmarks, where we outperform other methods\nin terms of accuracy, generalization, and efficiency.", "published": "2018-12-06T09:26:03Z", "version": 1}, {"aid": "1812.02464", "authors": ["Craig Atkinson", "Brendan McCane", "Lech Szymanski", "Anthony Robins"], "title": "Pseudo-Rehearsal: Achieving Deep Reinforcement Learning without Catastrophic Forgetting", "url": "http://arxiv.org/pdf/1812.02464v6", "summary": "Neural networks can achieve excellent results in a wide variety of\napplications. However, when they attempt to sequentially learn, they tend to\nlearn the new task while catastrophically forgetting previous ones. We propose\na model that overcomes catastrophic forgetting in sequential reinforcement\nlearning by combining ideas from continual learning in both the image\nclassification domain and the reinforcement learning domain. This model\nfeatures a dual memory system which separates continual learning from\nreinforcement learning and a pseudo-rehearsal system that \"recalls\" items\nrepresentative of previous tasks via a deep generative network. Our model\nsequentially learns Atari 2600 games without demonstrating catastrophic\nforgetting and continues to perform above human level on all three games. This\nresult is achieved without: demanding additional storage requirements as the\nnumber of tasks increases, storing raw data or revisiting past tasks. In\ncomparison, previous state-of-the-art solutions are substantially more\nvulnerable to forgetting on these complex deep reinforcement learning tasks.", "published": "2018-12-06T11:20:18Z", "version": 6}, {"aid": "1812.02984", "authors": ["Ehsan Pajouheshgar", "Christoph H. Lampert"], "title": "Back to square one: probabilistic trajectory forecasting without bells and whistles", "url": "http://arxiv.org/pdf/1812.02984v1", "summary": "We introduce a spatio-temporal convolutional neural network model for\ntrajectory forecasting from visual sources. Applied in an auto-regressive way\nit provides an explicit probability distribution over continuations of a given\ninitial trajectory segment. We discuss it in relation to (more complicated)\nexisting work and report on experiments on two standard datasets for trajectory\nforecasting: MNISTseq and Stanford Drones, achieving results on-par with or\nbetter than previous methods.", "published": "2018-12-07T11:31:05Z", "version": 1}, {"aid": "1812.03115", "authors": ["Yu-Chuan Su", "Kristen Grauman"], "title": "Kernel Transformer Networks for Compact Spherical Convolution", "url": "http://arxiv.org/pdf/1812.03115v2", "summary": "Ideally, 360{\\deg} imagery could inherit the deep convolutional neural\nnetworks (CNNs) already trained with great success on perspective projection\nimages. However, existing methods to transfer CNNs from perspective to\nspherical images introduce significant computational costs and/or degradations\nin accuracy. In this work, we present the Kernel Transformer Network (KTN).\nKTNs efficiently transfer convolution kernels from perspective images to the\nequirectangular projection of 360{\\deg} images. Given a source CNN for\nperspective images as input, the KTN produces a function parameterized by a\npolar angle and kernel as output. Given a novel 360{\\deg} image, that function\nin turn can compute convolutions for arbitrary layers and kernels as would the\nsource CNN on the corresponding tangent plane projections. Distinct from all\nexisting methods, KTNs allow model transfer: the same model can be applied to\ndifferent source CNNs with the same base architecture. This enables application\nto multiple recognition tasks without re-training the KTN. Validating our\napproach with multiple source CNNs and datasets, we show that KTNs improve the\nstate of the art for spherical convolution. KTNs successfully preserve the\nsource CNN's accuracy, while offering transferability, scalability to typical\nimage resolutions, and, in many cases, a substantially lower memory footprint.", "published": "2018-12-07T17:26:28Z", "version": 2}, {"aid": "1812.03381", "authors": ["Tim Salimans", "Richard Chen"], "title": "Learning Montezuma's Revenge from a Single Demonstration", "url": "http://arxiv.org/pdf/1812.03381v1", "summary": "We propose a new method for learning from a single demonstration to solve\nhard exploration tasks like the Atari game Montezuma's Revenge. Instead of\nimitating human demonstrations, as proposed in other recent works, our approach\nis to maximize rewards directly. Our agent is trained using off-the-shelf\nreinforcement learning, but starts every episode by resetting to a state from a\ndemonstration. By starting from such demonstration states, the agent requires\nmuch less exploration to learn a game compared to when it starts from the\nbeginning of the game at every episode. We analyze reinforcement learning for\ntasks with sparse rewards in a simple toy environment, where we show that the\nrun-time of standard RL methods scales exponentially in the number of states\nbetween rewards. Our method reduces this to quadratic scaling, opening up many\ntasks that were previously infeasible. We then apply our method to Montezuma's\nRevenge, for which we present a trained agent achieving a high-score of 74,500,\nbetter than any previously published result.", "published": "2018-12-08T20:16:16Z", "version": 1}, {"aid": "1812.03385", "authors": ["Rahul Kumar Jaiswal", "Gaurav Saxena"], "title": "Biometric Recognition System (Algorithm)", "url": "http://arxiv.org/pdf/1812.03385v1", "summary": "Fingerprints are the most widely deployed form of biometric identification.\nNo two individuals share the same fingerprint because they have unique\nbiometric identifiers. This paper presents an efficient fingerprint\nverification algorithm which improves matching accuracy. Fingerprint images get\ndegraded and corrupted due to variations in skin and impression conditions.\nThus, image enhancement techniques are employed prior to singular point\ndetection and minutiae extraction. Singular point is the point of maximum\ncurvature. It is determined by the normal of each fingerprint ridge, and then\nfollowing them inward towards the centre. The local ridge features known as\nminutiae is extracted using cross-number method to find ridge endings and ridge\nbifurcations. The proposed algorithm chooses a radius and draws a circle with\ncore point as centre, making fingerprint images rotationally invariant and\nuniform. The radius can be varied according to the accuracy depending on the\nparticular application. Morphological techniques such as clean, spur and\nH-break is employed to remove noise, followed by removing spurious minutiae.\nTemplates are created based on feature vector extraction and databases are made\nfor verification and identification for the fingerprint images taken from\nFingerprint Verification Competition (FVC2002). Minimum Euclidean distance is\ncalculated between saved template and the test fingerprint image template and\ncompared with the set threshold for matching decision. For the performance\nevaluation of the proposed algorithm various measures, equal error rate (EER),\nDmin at EER, accuracy and threshold are evaluated and plotted. The measures\ndemonstrate that the proposed algorithm is more effective and robust.", "published": "2018-12-08T21:12:38Z", "version": 1}, {"aid": "1812.03451", "authors": ["Chloe Eunhyang Kim", "Mahdi Maktab Dar Oghaz", "Jiri Fajtl", "Vasileios Argyriou", "Paolo Remagnino"], "title": "A Comparison of Embedded Deep Learning Methods for Person Detection", "url": "http://arxiv.org/pdf/1812.03451v2", "summary": "Recent advancements in parallel computing, GPU technology and deep learning\nprovide a new platform for complex image processing tasks such as person\ndetection to flourish. Person detection is fundamental preliminary operation\nfor several high level computer vision tasks. One industry that can\nsignificantly benefit from person detection is retail. In recent years, various\nstudies attempt to find an optimal solution for person detection using neural\nnetworks and deep learning. This study conducts a comparison among the state of\nthe art deep learning base object detector with the focus on person detection\nperformance in indoor environments. Performance of various implementations of\nYOLO, SSD, RCNN, R-FCN and SqueezeDet have been assessed using our in-house\nproprietary dataset which consists of over 10 thousands indoor images captured\nform shopping malls, retails and stores. Experimental results indicate that,\nTiny YOLO-416 and SSD (VGG-300) are the fastest and Faster-RCNN (Inception\nResNet-v2) and R-FCN (ResNet-101) are the most accurate detectors investigated\nin this study. Further analysis shows that YOLO v3-416 delivers relatively\naccurate result in a reasonable amount of time, which makes it an ideal model\nfor person detection in embedded platforms.", "published": "2018-12-09T09:29:28Z", "version": 2}, {"aid": "1812.03945", "authors": ["Hao Zheng", "Yizhe Zhang", "Lin Yang", "Peixian Liang", "Zhuo Zhao", "Chaoli Wang", "Danny Z. Chen"], "title": "A New Ensemble Learning Framework for 3D Biomedical Image Segmentation", "url": "http://arxiv.org/pdf/1812.03945v1", "summary": "3D image segmentation plays an important role in biomedical image analysis.\nMany 2D and 3D deep learning models have achieved state-of-the-art segmentation\nperformance on 3D biomedical image datasets. Yet, 2D and 3D models have their\nown strengths and weaknesses, and by unifying them together, one may be able to\nachieve more accurate results. In this paper, we propose a new ensemble\nlearning framework for 3D biomedical image segmentation that combines the\nmerits of 2D and 3D models. First, we develop a fully convolutional network\nbased meta-learner to learn how to improve the results from 2D and 3D models\n(base-learners). Then, to minimize over-fitting for our sophisticated\nmeta-learner, we devise a new training method that uses the results of the\nbase-learners as multiple versions of \"ground truths\". Furthermore, since our\nnew meta-learner training scheme does not depend on manual annotation, it can\nutilize abundant unlabeled 3D image data to further improve the model.\nExtensive experiments on two public datasets (the HVSMR 2016 Challenge dataset\nand the mouse piriform cortex dataset) show that our approach is effective\nunder fully-supervised, semi-supervised, and transductive settings, and attains\nsuperior performance over state-of-the-art image segmentation methods.", "published": "2018-12-10T17:58:00Z", "version": 1}, {"aid": "1812.04056", "authors": ["Georgios Georgiadis"], "title": "Accelerating Convolutional Neural Networks via Activation Map Compression", "url": "http://arxiv.org/pdf/1812.04056v2", "summary": "The deep learning revolution brought us an extensive array of neural network\narchitectures that achieve state-of-the-art performance in a wide variety of\nComputer Vision tasks including among others, classification, detection and\nsegmentation. In parallel, we have also been observing an unprecedented demand\nin computational and memory requirements, rendering the efficient use of neural\nnetworks in low-powered devices virtually unattainable. Towards this end, we\npropose a three-stage compression and acceleration pipeline that sparsifies,\nquantizes and entropy encodes activation maps of Convolutional Neural Networks.\nSparsification increases the representational power of activation maps leading\nto both acceleration of inference and higher model accuracy. Inception-V3 and\nMobileNet-V1 can be accelerated by as much as $1.6\\times$ with an increase in\naccuracy of $0.38\\%$ and $0.54\\%$ on the ImageNet and CIFAR-10 datasets\nrespectively. Quantizing and entropy coding the sparser activation maps lead to\nhigher compression over the baseline, reducing the memory cost of the network\nexecution. Inception-V3 and MobileNet-V1 activation maps, quantized to $16$\nbits, are compressed by as much as $6\\times$ with an increase in accuracy of\n$0.36\\%$ and $0.55\\%$ respectively.", "published": "2018-12-10T19:50:44Z", "version": 2}, {"aid": "1812.04240", "authors": ["Tianyu Zhao", "Wenqi Ren", "Changqing Zhang", "Dongwei Ren", "Qinghua Hu"], "title": "Unsupervised Degradation Learning for Single Image Super-Resolution", "url": "http://arxiv.org/pdf/1812.04240v2", "summary": "Deep Convolution Neural Networks (CNN) have achieved significant performance\non single image super-resolution (SR) recently. However, existing CNN-based\nmethods use artificially synthetic low-resolution (LR) and high-resolution (HR)\nimage pairs to train networks, which cannot handle real-world cases since the\ndegradation from HR to LR is much more complex than manually designed. To solve\nthis problem, we propose a real-world LR images guided bi-cycle network for\nsingle image super-resolution, in which the bidirectional structural\nconsistency is exploited to train both the degradation and SR reconstruction\nnetworks in an unsupervised way. Specifically, we propose a degradation network\nto model the real-world degradation process from HR to LR via generative\nadversarial networks, and these generated realistic LR images paired with\nreal-world HR images are exploited for training the SR reconstruction network,\nforming the first cycle. Then in the second reverse cycle, consistency of\nreal-world LR images are exploited to further stabilize the training of SR\nreconstruction and degradation networks. Extensive experiments on both\nsynthetic and real-world images demonstrate that the proposed algorithm\nperforms favorably against state-of-the-art single image SR methods.", "published": "2018-12-11T07:07:58Z", "version": 2}, {"aid": "1812.04955", "authors": ["Yunxiao Qin", "Weiguo Zhang", "Chenxu Zhao", "Zezheng Wang", "Xiangyu Zhu", "Guojun Qi", "Jingping Shi", "Zhen Lei"], "title": "Prior-Knowledge and Attention-based Meta-Learning for Few-Shot Learning", "url": "http://arxiv.org/pdf/1812.04955v5", "summary": "Recently, meta-learning has been shown as a promising way to solve few-shot\nlearning. In this paper, inspired by the human cognition process which utilizes\nboth prior-knowledge and vision attention in learning new knowledge, we present\na novel paradigm of meta-learning approach with three developments to introduce\nattention mechanism and prior-knowledge for meta-learning. In our approach,\nprior-knowledge is responsible for helping meta-learner expressing the input\ndata into high-level representation space, and attention mechanism enables\nmeta-learner focusing on key features of the data in the representation space.\nCompared with existing meta-learning approaches that pay little attention to\nprior-knowledge and vision attention, our approach alleviates the\nmeta-learner's few-shot cognition burden. Furthermore, a Task-Over-Fitting\n(TOF) problem, which indicates that the meta-learner has poor generalization on\ndifferent K-shot learning tasks, is discovered and we propose a Cross-Entropy\nacross Tasks (CET) metric to model and solve the TOF problem. Extensive\nexperiments demonstrate that we improve the meta-learner with state-of-the-art\nperformance on several few-shot learning benchmarks, and at the same time the\nTOF problem can also be released greatly.", "published": "2018-12-11T08:56:47Z", "version": 5}, {"aid": "1812.04604", "authors": ["Biye Jiang", "David M. Chan", "Tianhao Zhang", "John F. Canny"], "title": "Diagnostic Visualization for Deep Neural Networks Using Stochastic Gradient Langevin Dynamics", "url": "http://arxiv.org/pdf/1812.04604v1", "summary": "The internal states of most deep neural networks are difficult to interpret,\nwhich makes diagnosis and debugging during training challenging. Activation\nmaximization methods are widely used, but lead to multiple optima and are hard\nto interpret (appear noise-like) for complex neurons. Image-based methods use\nmaximally-activating image regions which are easier to interpret, but do not\nprovide pixel-level insight into why the neuron responds to them. In this work\nwe introduce an MCMC method: Langevin Dynamics Activation Maximization (LDAM),\nwhich is designed for diagnostic visualization. LDAM provides two affordances\nin combination: the ability to explore the set of maximally activating\npre-images, and the ability to trade-off interpretability and pixel-level\naccuracy using a GAN-style discriminator as a regularizer. We present case\nstudies on MNIST, CIFAR and ImageNet datasets exploring these trade-offs.\nFinally we show that diagnostic visualization using LDAM leads to a novel\ninsight into the parameter averaging method for deep net training.", "published": "2018-12-11T18:43:52Z", "version": 1}, {"aid": "1812.04754", "authors": ["Guy Gur-Ari", "Daniel A. Roberts", "Ethan Dyer"], "title": "Gradient Descent Happens in a Tiny Subspace", "url": "http://arxiv.org/pdf/1812.04754v1", "summary": "We show that in a variety of large-scale deep learning scenarios the gradient\ndynamically converges to a very small subspace after a short period of\ntraining. The subspace is spanned by a few top eigenvectors of the Hessian\n(equal to the number of classes in the dataset), and is mostly preserved over\nlong periods of training. A simple argument then suggests that gradient descent\nmay happen mostly in this subspace. We give an example of this effect in a\nsolvable model of classification, and we comment on possible implications for\noptimization and learning.", "published": "2018-12-12T00:36:17Z", "version": 1}, {"aid": "1812.04769", "authors": ["Emanuel Diamant"], "title": "Designing Artificial Cognitive Architectures: Brain Inspired or Biologically Inspired?", "url": "http://arxiv.org/pdf/1812.04769v1", "summary": "Artificial Neural Networks (ANNs) were devised as a tool for Artificial\nIntelligence design implementations. However, it was soon became obvious that\nthey are unable to fulfill their duties. The fully autonomous way of ANNs\nworking, precluded from any human intervention or supervision, deprived of any\ntheoretical underpinning, leads to a strange state of affairs, when ANN\ndesigners cannot explain why and how they achieve their amazing and remarkable\nresults. Therefore, contemporary Artificial Intelligence R&D looks more like a\nModern Alchemy enterprise rather than a respected scientific or technological\nundertaking. On the other hand, modern biological science posits that\nintelligence can be distinguished not only in human brains. Intelligence today\nis considered as a fundamental property of each and every living being.\nTherefore, lower simplified forms of natural intelligence are more suitable for\ninvestigation and further replication in artificial cognitive architectures.", "published": "2018-12-12T01:40:51Z", "version": 1}, {"aid": "1812.05668", "authors": ["Hang Yu", "Ziyi Liu", "Jiansheng Wu"], "title": "Forgetting in order to Remember Better", "url": "http://arxiv.org/pdf/1812.05668v1", "summary": "In human memory, forgetting occur rapidly after the remembering and the rate\nof forgetting slowed down as time went. This is so-called the Ebbinghaus\nforgetting curve. There are many explanations of how this curve occur based on\nthe properties of the brains. In this article, we use a simple mathematical\nmodel to explain the mechanism of forgetting based on rearrangement inequality\nand get a general formalism for short-term and long-term memory and use it to\nfit the Ebbinghaus forgetting curve. We also find out that forgetting is not a\nflaw, instead it is help to improve the efficiency of remembering when human\nconfront different situations by reducing the interference of information and\nreducing the number of retrievals. Furthurmove, we find that the interference\nof informations limits the capacity of human memory, which is the \"magic number\nseven\".", "published": "2018-12-12T18:54:27Z", "version": 1}, {"aid": "1812.05212", "authors": ["Marcel Nassar", "Xin Wang", "Evren Tumer"], "title": "Conditional Graph Neural Processes: A Functional Autoencoder Approach", "url": "http://arxiv.org/pdf/1812.05212v1", "summary": "We introduce a novel encoder-decoder architecture to embed functional\nprocesses into latent vector spaces. This embedding can then be decoded to\nsample the encoded functions over any arbitrary domain. This autoencoder\ngeneralizes the recently introduced Conditional Neural Process (CNP) model of\nrandom processes. Our architecture employs the latest advances in graph neural\nnetworks to process irregularly sampled functions. Thus, we refer to our model\nas Conditional Graph Neural Process (CGNP). Graph neural networks can\neffectively exploit `local' structures of the metric spaces over which the\nfunctions/processes are defined. The contributions of this paper are twofold:\n(i) a novel graph-based encoder-decoder architecture for functional and process\nembeddings, and (ii) a demonstration of the importance of using the structure\nof metric spaces for this type of representations.", "published": "2018-12-13T00:52:56Z", "version": 1}, {"aid": "1812.05905", "authors": ["Tuomas Haarnoja", "Aurick Zhou", "Kristian Hartikainen", "George Tucker", "Sehoon Ha", "Jie Tan", "Vikash Kumar", "Henry Zhu", "Abhishek Gupta", "Pieter Abbeel", "Sergey Levine"], "title": "Soft Actor-Critic Algorithms and Applications", "url": "http://arxiv.org/pdf/1812.05905v2", "summary": "Model-free deep reinforcement learning (RL) algorithms have been successfully\napplied to a range of challenging sequential decision making and control tasks.\nHowever, these methods typically suffer from two major challenges: high sample\ncomplexity and brittleness to hyperparameters. Both of these challenges limit\nthe applicability of such methods to real-world domains. In this paper, we\ndescribe Soft Actor-Critic (SAC), our recently introduced off-policy\nactor-critic algorithm based on the maximum entropy RL framework. In this\nframework, the actor aims to simultaneously maximize expected return and\nentropy. That is, to succeed at the task while acting as randomly as possible.\nWe extend SAC to incorporate a number of modifications that accelerate training\nand improve stability with respect to the hyperparameters, including a\nconstrained formulation that automatically tunes the temperature\nhyperparameter. We systematically evaluate SAC on a range of benchmark tasks,\nas well as real-world challenging tasks such as locomotion for a quadrupedal\nrobot and robotic manipulation with a dexterous hand. With these improvements,\nSAC achieves state-of-the-art performance, outperforming prior on-policy and\noff-policy methods in sample-efficiency and asymptotic performance.\nFurthermore, we demonstrate that, in contrast to other off-policy algorithms,\nour approach is very stable, achieving similar performance across different\nrandom seeds. These results suggest that SAC is a promising candidate for\nlearning in real-world robotics tasks.", "published": "2018-12-13T04:44:29Z", "version": 2}, {"aid": "1812.05687", "authors": ["Peter E. Lillian", "Richard Meyes", "Tobias Meisen"], "title": "Ablation of a Robot's Brain: Neural Networks Under a Knife", "url": "http://arxiv.org/pdf/1812.05687v2", "summary": "It is still not fully understood exactly how neural networks are able to\nsolve the complex tasks that have recently pushed AI research forward. We\npresent a novel method for determining how information is structured inside a\nneural network. Using ablation (a neuroscience technique for cutting away parts\nof a brain to determine their function), we approach several neural network\narchitectures from a biological perspective. Through an analysis of this\nmethod's results, we examine important similarities between biological and\nartificial neural networks to search for the implicit knowledge locked away in\nthe network's weights.", "published": "2018-12-13T20:58:37Z", "version": 2}, {"aid": "1812.05806", "authors": ["Yifan Xing", "Rahul Tewari", "Paulo R. S. Mendonca"], "title": "A Self-Supervised Bootstrap Method for Single-Image 3D Face Reconstruction", "url": "http://arxiv.org/pdf/1812.05806v2", "summary": "State-of-the-art methods for 3D reconstruction of faces from a single image\nrequire 2D-3D pairs of ground-truth data for supervision. Such data is costly\nto acquire, and most datasets available in the literature are restricted to\npairs for which the input 2D images depict faces in a near fronto-parallel\npose. Therefore, many data-driven methods for single-image 3D facial\nreconstruction perform poorly on profile and near-profile faces. We propose a\nmethod to improve the performance of single-image 3D facial reconstruction\nnetworks by utilizing the network to synthesize its own training data for\nfine-tuning, comprising: (i) single-image 3D reconstruction of faces in\nnear-frontal images without ground-truth 3D shape; (ii) application of a\nrigid-body transformation to the reconstructed face model; (iii) rendering of\nthe face model from new viewpoints; and (iv) use of the rendered image and\ncorresponding 3D reconstruction as additional data for supervised fine-tuning.\nThe new 2D-3D pairs thus produced have the same high-quality observed for near\nfronto-parallel reconstructions, thereby nudging the network towards more\nuniform performance as a function of the viewing angle of input faces.\nApplication of the proposed technique to the fine-tuning of a state-of-the-art\nsingle-image 3D-reconstruction network for faces demonstrates the usefulness of\nthe method, with particularly significant gains for profile or near-profile\nviews.", "published": "2018-12-14T07:46:02Z", "version": 2}, {"aid": "1812.05945", "authors": ["Daniel Omeiza", "Kayode Sakariyah Adewole", "Daniel Nkemelu"], "title": "EEG-based Communication with a Predictive Text Algorithm", "url": "http://arxiv.org/pdf/1812.05945v4", "summary": "Several changes occur in the brain in response to voluntary and involuntary\nactivities performed by a person. The ability to retrieve data from the brain\nwithin a time space provides a basis for in-depth analyses that offer insight\non what changes occur in the brain during its decision-making processes. In\nthis work, we present the technical description and software implementation of\nan electroencephalographic (EEG) based communication system. We read EEG data\nin real-time with which we compute the likelihood that a voluntary eye blink\nhas been made by a person and use the decision to trigger buttons on a user\ninterface in order to produce text. Relevant texts are suggested using a\nmodification of the T9 algorithm. Our results indicate that EEG-based\ntechnology can be effectively applied in facilitating speech for people with\nsevere speech and muscular disabilities, providing a foundation for future work\nin the area.", "published": "2018-12-14T14:08:35Z", "version": 4}, {"aid": "1812.07032", "authors": ["Hoel Kervadec", "Jihene Bouchtiba", "Christian Desrosiers", "Eric Granger", "Jose Dolz", "Ismail Ben Ayed"], "title": "Boundary loss for highly unbalanced segmentation", "url": "http://arxiv.org/pdf/1812.07032v4", "summary": "Widely used loss functions for CNN segmentation, e.g., Dice or cross-entropy,\nare based on integrals over the segmentation regions. Unfortunately, for highly\nunbalanced segmentations, such regional summations have values that differ by\nseveral orders of magnitude across classes, which affects training performance\nand stability. We propose a boundary loss, which takes the form of a distance\nmetric on the space of contours, not regions. This can mitigate the\ndifficulties of highly unbalanced problems because it uses integrals over the\ninterface between regions instead of unbalanced integrals over the regions.\nFurthermore, a boundary loss complements regional information. Inspired by\ngraph-based optimization techniques for computing active-contour flows, we\nexpress a non-symmetric $L_2$ distance on the space of contours as a regional\nintegral, which avoids completely local differential computations involving\ncontour points. This yields a boundary loss expressed with the regional softmax\nprobability outputs of the network, which can be easily combined with standard\nregional losses and implemented with any existing deep network architecture for\nN-D segmentation. We report comprehensive evaluations and comparisons on\ndifferent unbalanced problems, showing that our boundary loss can yield\nsignificant increases in performances while improving training stability. Our\ncode is publicly available: https://github.com/LIVIAETS/surface-loss .", "published": "2018-12-17T20:06:50Z", "version": 4}, {"aid": "1812.07363", "authors": ["Jian Han", "Sezer Karaoglu", "Hoang-An Le", "Theo Gevers"], "title": "Improving Face Detection Performance with 3D-Rendered Synthetic Data", "url": "http://arxiv.org/pdf/1812.07363v3", "summary": "In this paper, we provide a synthetic data generator methodology with fully\ncontrolled, multifaceted variations based on a new 3D face dataset (3DU-Face).\nWe customized synthetic datasets to address specific types of variations\n(scale, pose, occlusion, blur, etc.), and systematically investigate the\ninfluence of different variations on face detection performances. We examine\nwhether and how these factors contribute to better face detection performances.\nWe validate our synthetic data augmentation for different face detectors\n(Faster RCNN, SSH and HR) on various face datasets (MAFA, UFDD and Wider Face).", "published": "2018-12-18T13:46:58Z", "version": 3}, {"aid": "1812.07544", "authors": ["Nikolay Nikolov", "Johannes Kirschner", "Felix Berkenkamp", "Andreas Krause"], "title": "Information-Directed Exploration for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1812.07544v2", "summary": "Efficient exploration remains a major challenge for reinforcement learning.\nOne reason is that the variability of the returns often depends on the current\nstate and action, and is therefore heteroscedastic. Classical exploration\nstrategies such as upper confidence bound algorithms and Thompson sampling fail\nto appropriately account for heteroscedasticity, even in the bandit setting.\nMotivated by recent findings that address this issue in bandits, we propose to\nuse Information-Directed Sampling (IDS) for exploration in reinforcement\nlearning. As our main contribution, we build on recent advances in\ndistributional reinforcement learning and propose a novel, tractable\napproximation of IDS for deep Q-learning. The resulting exploration strategy\nexplicitly accounts for both parametric uncertainty and heteroscedastic\nobservation noise. We evaluate our method on Atari games and demonstrate a\nsignificant improvement over alternative approaches.", "published": "2018-12-18T18:20:49Z", "version": 2}, {"aid": "1812.07697", "authors": ["Ren Li", "Jared S. Johansen", "Hamad Ahmed", "Thomas V. Ilyevsky", "Ronnie B Wilbur", "Hari M Bharadwaj", "Jeffrey Mark Siskind"], "title": "Training on the test set? An analysis of Spampinato et al. [31]", "url": "http://arxiv.org/pdf/1812.07697v1", "summary": "A recent paper [31] claims to classify brain processing evoked in subjects\nwatching ImageNet stimuli as measured with EEG and to use a representation\nderived from this processing to create a novel object classifier. That paper,\ntogether with a series of subsequent papers [8, 15, 17, 20, 21, 30, 35], claims\nto revolutionize the field by achieving extremely successful results on several\ncomputer-vision tasks, including object classification, transfer learning, and\ngeneration of images depicting human perception and thought using brain-derived\nrepresentations measured through EEG. Our novel experiments and analyses\ndemonstrate that their results crucially depend on the block design that they\nuse, where all stimuli of a given class are presented together, and fail with a\nrapid-event design, where stimuli of different classes are randomly intermixed.\nThe block design leads to classification of arbitrary brain states based on\nblock-level temporal correlations that tend to exist in all EEG data, rather\nthan stimulus-related activity. Because every trial in their test sets comes\nfrom the same block as many trials in the corresponding training sets, their\nblock design thus leads to surreptitiously training on the test set. This\ninvalidates all subsequent analyses performed on this data in multiple\npublished papers and calls into question all of the purported results. We\nfurther show that a novel object classifier constructed with a random codebook\nperforms as well as or better than a novel object classifier constructed with\nthe representation extracted from EEG data, suggesting that the performance of\ntheir classifier constructed with a representation extracted from EEG data does\nnot benefit at all from the brain-derived representation. Our results calibrate\nthe underlying difficulty of the tasks involved and caution against sensational\nand overly optimistic, but false, claims to the contrary.", "published": "2018-12-18T23:38:28Z", "version": 1}, {"aid": "1812.08989", "authors": ["Li Zhou", "Jianfeng Gao", "Di Li", "Heung-Yeung Shum"], "title": "The Design and Implementation of XiaoIce, an Empathetic Social Chatbot", "url": "http://arxiv.org/pdf/1812.08989v2", "summary": "This paper describes the development of Microsoft XiaoIce, the most popular\nsocial chatbot in the world. XiaoIce is uniquely designed as an AI companion\nwith an emotional connection to satisfy the human need for communication,\naffection, and social belonging. We take into account both intelligent quotient\n(IQ) and emotional quotient (EQ) in system design, cast human-machine social\nchat as decision-making over Markov Decision Processes (MDPs), and optimize\nXiaoIce for long-term user engagement, measured in expected Conversation-turns\nPer Session (CPS). We detail the system architecture and key components\nincluding dialogue manager, core chat, skills, and an empathetic computing\nmodule. We show how XiaoIce dynamically recognizes human feelings and states,\nunderstands user intent, and responds to user needs throughout long\nconversations. Since her launch in 2014, XiaoIce has communicated with over 660\nmillion active users and succeeded in establishing long-term relationships with\nmany of them. Analysis of large scale online logs shows that XiaoIce has\nachieved an average CPS of 23, which is significantly higher than that of other\nchatbots and even human conversations.", "published": "2018-12-21T08:01:31Z", "version": 2}, {"aid": "1812.10587", "authors": ["Jianwen Xie", "Ruiqi Gao", "Zilong Zheng", "Song-Chun Zhu", "Ying Nian Wu"], "title": "Learning Dynamic Generator Model by Alternating Back-Propagation Through Time", "url": "http://arxiv.org/pdf/1812.10587v1", "summary": "This paper studies the dynamic generator model for spatial-temporal processes\nsuch as dynamic textures and action sequences in video data. In this model,\neach time frame of the video sequence is generated by a generator model, which\nis a non-linear transformation of a latent state vector, where the non-linear\ntransformation is parametrized by a top-down neural network. The sequence of\nlatent state vectors follows a non-linear auto-regressive model, where the\nstate vector of the next frame is a non-linear transformation of the state\nvector of the current frame as well as an independent noise vector that\nprovides randomness in the transition. The non-linear transformation of this\ntransition model can be parametrized by a feedforward neural network. We show\nthat this model can be learned by an alternating back-propagation through time\nalgorithm that iteratively samples the noise vectors and updates the parameters\nin the transition model and the generator model. We show that our training\nmethod can learn realistic models for dynamic textures and action patterns.", "published": "2018-12-27T01:34:08Z", "version": 1}, {"aid": "1812.10775", "authors": ["Yongheng Zhao", "Tolga Birdal", "Haowen Deng", "Federico Tombari"], "title": "3D Point Capsule Networks", "url": "http://arxiv.org/pdf/1812.10775v2", "summary": "In this paper, we propose 3D point-capsule networks, an auto-encoder designed\nto process sparse 3D point clouds while preserving spatial arrangements of the\ninput data. 3D capsule networks arise as a direct consequence of our novel\nunified 3D auto-encoder formulation. Their dynamic routing scheme and the\npeculiar 2D latent space deployed by our approach bring in improvements for\nseveral common point cloud-related tasks, such as object classification, object\nreconstruction and part segmentation as substantiated by our extensive\nevaluations. Moreover, it enables new applications such as part interpolation\nand replacement.", "published": "2018-12-27T17:16:48Z", "version": 2}, {"aid": "1812.11214", "authors": ["Mathieu Andreux", "Tom\u00e1s Angles", "Georgios Exarchakis", "Roberto Leonarduzzi", "Gaspar Rochette", "Louis Thiry", "John Zarka", "St\u00e9phane Mallat", "Joakim and\u00e9n", "Eugene Belilovsky", "Joan Bruna", "Vincent Lostanlen", "Muawiz Chaudhary", "Matthew J. Hirn", "Edouard Oyallon", "Sixin Zhang", "Carmine Cella", "Michael Eickenberg"], "title": "Kymatio: Scattering Transforms in Python", "url": "http://arxiv.org/pdf/1812.11214v3", "summary": "The wavelet scattering transform is an invariant signal representation\nsuitable for many signal processing and machine learning applications. We\npresent the Kymatio software package, an easy-to-use, high-performance Python\nimplementation of the scattering transform in 1D, 2D, and 3D that is compatible\nwith modern deep learning frameworks. All transforms may be executed on a GPU\n(in addition to CPU), offering a considerable speed up over CPU\nimplementations. The package also has a small memory footprint, resulting\ninefficient memory usage. The source code, documentation, and examples are\navailable undera BSD license at https://www.kymat.io/", "published": "2018-12-28T20:53:29Z", "version": 3}, {"aid": "1812.11440", "authors": ["Irina Sanchez", "Veronica Vilaplana"], "title": "Brain MRI super-resolution using 3D generative adversarial networks", "url": "http://arxiv.org/pdf/1812.11440v1", "summary": "In this work we propose an adversarial learning approach to generate high\nresolution MRI scans from low resolution images. The architecture, based on the\nSRGAN model, adopts 3D convolutions to exploit volumetric information. For the\ndiscriminator, the adversarial loss uses least squares in order to stabilize\nthe training. For the generator, the loss function is a combination of a least\nsquares adversarial loss and a content term based on mean square error and\nimage gradients in order to improve the quality of the generated images. We\nexplore different solutions for the upsampling phase. We present promising\nresults that improve classical interpolation, showing the potential of the\napproach for 3D medical imaging super-resolution. Source code available at\nhttps://github.com/imatge-upc/3D-GAN-superresolution", "published": "2018-12-29T22:19:00Z", "version": 1}, {"aid": "1812.11677", "authors": ["Ao Ren", "Tianyun Zhang", "Shaokai Ye", "Jiayu Li", "Wenyao Xu", "Xuehai Qian", "Xue Lin", "Yanzhi Wang"], "title": "ADMM-NN: An Algorithm-Hardware Co-Design Framework of DNNs Using Alternating Direction Method of Multipliers", "url": "http://arxiv.org/pdf/1812.11677v1", "summary": "To facilitate efficient embedded and hardware implementations of deep neural\nnetworks (DNNs), two important categories of DNN model compression techniques:\nweight pruning and weight quantization are investigated. The former leverages\nthe redundancy in the number of weights, whereas the latter leverages the\nredundancy in bit representation of weights. However, there lacks a systematic\nframework of joint weight pruning and quantization of DNNs, thereby limiting\nthe available model compression ratio. Moreover, the computation reduction,\nenergy efficiency improvement, and hardware performance overhead need to be\naccounted for besides simply model size reduction.\n  To address these limitations, we present ADMM-NN, the first\nalgorithm-hardware co-optimization framework of DNNs using Alternating\nDirection Method of Multipliers (ADMM), a powerful technique to deal with\nnon-convex optimization problems with possibly combinatorial constraints. The\nfirst part of ADMM-NN is a systematic, joint framework of DNN weight pruning\nand quantization using ADMM. It can be understood as a smart regularization\ntechnique with regularization target dynamically updated in each ADMM\niteration, thereby resulting in higher performance in model compression than\nprior work. The second part is hardware-aware DNN optimizations to facilitate\nhardware-level implementations.\n  Without accuracy loss, we can achieve 85$\\times$ and 24$\\times$ pruning on\nLeNet-5 and AlexNet models, respectively, significantly higher than prior work.\nThe improvement becomes more significant when focusing on computation\nreductions. Combining weight pruning and quantization, we achieve 1,910$\\times$\nand 231$\\times$ reductions in overall model size on these two benchmarks, when\nfocusing on data storage. Highly promising results are also observed on other\nrepresentative DNNs such as VGGNet and ResNet-50.", "published": "2018-12-31T02:26:48Z", "version": 1}, {"aid": "1812.11780", "authors": ["F\u00e1bio Perez", "R\u00e9mi Lebret", "Karl Aberer"], "title": "Weakly Supervised Active Learning with Cluster Annotation", "url": "http://arxiv.org/pdf/1812.11780v2", "summary": "In this work, we introduce a novel framework that employs cluster annotation\nto boost active learning by reducing the number of human interactions required\nto train deep neural networks. Instead of annotating single samples\nindividually, humans can also label clusters, producing a higher number of\nannotated samples with the cost of a small label error. Our experiments show\nthat the proposed framework requires 82% and 87% less human interactions for\nCIFAR-10 and EuroSAT datasets respectively when compared with the\nfully-supervised training while maintaining similar performance on the test\nset.", "published": "2018-12-31T13:06:09Z", "version": 2}, {"aid": "1812.11806", "authors": ["Wouter M. Kouw", "Marco Loog"], "title": "An introduction to domain adaptation and transfer learning", "url": "http://arxiv.org/pdf/1812.11806v2", "summary": "In machine learning, if the training data is an unbiased sample of an\nunderlying distribution, then the learned classification function will make\naccurate predictions for new samples. However, if the training data is not an\nunbiased sample, then there will be differences between how the training data\nis distributed and how the test data is distributed. Standard classifiers\ncannot cope with changes in data distributions between training and test\nphases, and will not perform well. Domain adaptation and transfer learning are\nsub-fields within machine learning that are concerned with accounting for these\ntypes of changes. Here, we present an introduction to these fields, guided by\nthe question: when and how can a classifier generalize from a source to a\ntarget domain? We will start with a brief introduction into risk minimization,\nand how transfer learning and domain adaptation expand upon this framework.\nFollowing that, we discuss three special cases of data set shift, namely prior,\ncovariate and concept shift. For more complex domain shifts, there are a wide\nvariety of approaches. These are categorized into: importance-weighting,\nsubspace mapping, domain-invariant spaces, feature augmentation, minimax\nestimators and robust algorithms. A number of points will arise, which we will\ndiscuss in the last section. We conclude with the remark that many open\nquestions will have to be addressed before transfer learners and\ndomain-adaptive classifiers become practical.", "published": "2018-12-31T14:19:20Z", "version": 2}, {"aid": "1901.05903", "authors": ["Yash Srivastava", "Vaishnav Murali", "Shiv Ram Dubey"], "title": "A Performance Comparison of Loss Functions for Deep Face Recognition", "url": "http://arxiv.org/pdf/1901.05903v2", "summary": "Face recognition is one of the most widely publicized feature in the devices\ntoday and hence represents an important problem that should be studied with the\nutmost priority. As per the recent trends, the Convolutional Neural Network\n(CNN) based approaches are highly successful in many tasks of Computer Vision\nincluding face recognition. The loss function is used on the top of CNN to\njudge the goodness of any network. In this paper, we present a performance\ncomparison of different loss functions such as Cross-Entropy, Angular Softmax,\nAdditive-Margin Softmax, ArcFace and Marginal Loss for face recognition. The\nexperiments are conducted with two CNN architectures namely, ResNet and\nMobileNet. Two widely used face datasets namely, CASIA-Webface and MS-Celeb-1M\nare used for the training and benchmark Labeled Faces in the Wild (LFW) face\ndataset is used for the testing.", "published": "2019-01-01T03:00:10Z", "version": 2}, {"aid": "1901.00945", "authors": ["Jack Lindsey", "Samuel A. Ocko", "Surya Ganguli", "Stephane Deny"], "title": "A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs", "url": "http://arxiv.org/pdf/1901.00945v1", "summary": "The visual system is hierarchically organized to process visual information\nin successive stages. Neural representations vary drastically across the first\nstages of visual processing: at the output of the retina, ganglion cell\nreceptive fields (RFs) exhibit a clear antagonistic center-surround structure,\nwhereas in the primary visual cortex, typical RFs are sharply tuned to a\nprecise orientation. There is currently no unified theory explaining these\ndifferences in representations across layers. Here, using a deep convolutional\nneural network trained on image recognition as a model of the visual system, we\nshow that such differences in representation can emerge as a direct consequence\nof different neural resource constraints on the retinal and cortical networks,\nand we find a single model from which both geometries spontaneously emerge at\nthe appropriate stages of visual processing. The key constraint is a reduced\nnumber of neurons at the retinal output, consistent with the anatomy of the\noptic nerve as a stringent bottleneck. Second, we find that, for simple\ncortical networks, visual representations at the retinal output emerge as\nnonlinear and lossy feature detectors, whereas they emerge as linear and\nfaithful encoders of the visual scene for more complex cortices. This result\npredicts that the retinas of small vertebrates should perform sophisticated\nnonlinear computations, extracting features directly relevant to behavior,\nwhereas retinas of large animals such as primates should mostly encode the\nvisual scene linearly and respond to a much broader range of stimuli. These\npredictions could reconcile the two seemingly incompatible views of the retina\nas either performing feature extraction or efficient coding of natural scenes,\nby suggesting that all vertebrates lie on a spectrum between these two\nobjectives, depending on the degree of neural resources allocated to their\nvisual system.", "published": "2019-01-03T23:51:38Z", "version": 1}, {"aid": "1901.01021", "authors": ["Rongrong Ma", "Jianyu Miao", "Lingfeng Niu", "Peng Zhang"], "title": "Transformed $\\ell_1$ Regularization for Learning Sparse Deep Neural Networks", "url": "http://arxiv.org/pdf/1901.01021v1", "summary": "Deep neural networks (DNNs) have achieved extraordinary success in numerous\nareas. However, to attain this success, DNNs often carry a large number of\nweight parameters, leading to heavy costs of memory and computation resources.\nOverfitting is also likely to happen in such network when the training data are\ninsufficient. These shortcomings severely hinder the application of DNNs in\nresource-constrained platforms. In fact, many network weights are known to be\nredundant and can be removed from the network without much loss of performance.\nTo this end, we introduce a new non-convex integrated transformed $\\ell_1$\nregularizer to promote sparsity for DNNs, which removes both redundant\nconnections and unnecessary neurons simultaneously. To be specific, we apply\nthe transformed $\\ell_1$ to the matrix space of network weights and utilize it\nto remove redundant connections. Besides, group sparsity is also employed as an\nauxiliary to remove unnecessary neurons. An efficient stochastic proximal\ngradient algorithm is presented to solve the new model at the same time. To the\nbest of our knowledge, this is the first work to utilize a non-convex\nregularizer in sparse optimization based method to promote sparsity for DNNs.\nExperiments on several public datasets demonstrate the effectiveness of the\nproposed method.", "published": "2019-01-04T08:46:16Z", "version": 1}, {"aid": "1901.01091", "authors": ["Thomas Lucas", "Konstantin Shmelkov", "Karteek Alahari", "Cordelia Schmid", "Jakob Verbeek"], "title": "Adaptive Density Estimation for Generative Models", "url": "http://arxiv.org/pdf/1901.01091v3", "summary": "Unsupervised learning of generative models has seen tremendous progress over\nrecent years, in particular due to generative adversarial networks (GANs),\nvariational autoencoders, and flow-based models. GANs have dramatically\nimproved sample quality, but suffer from two drawbacks: (i) they mode-drop,\ni.e., do not cover the full support of the train data, and (ii) they do not\nallow for likelihood evaluations on held-out data. In contrast,\nlikelihood-based training encourages models to cover the full support of the\ntrain data, but yields poorer samples. These mutual shortcomings can in\nprinciple be addressed by training generative latent variable models in a\nhybrid adversarial-likelihood manner. However, we show that commonly made\nparametric assumptions create a conflict between them, making successful hybrid\nmodels non trivial. As a solution, we propose to use deep invertible\ntransformations in the latent variable decoder. This approach allows for\nlikelihood computations in image space, is more efficient than fully invertible\nmodels, and can take full advantage of adversarial training. We show that our\nmodel significantly improves over existing hybrid models: offering GAN-like\nsamples, IS and FID scores that are competitive with fully adversarial models,\nand improved likelihood scores.", "published": "2019-01-04T13:43:18Z", "version": 3}, {"aid": "1901.01672", "authors": ["Vaishnavh Nagarajan", "J. Zico Kolter"], "title": "Generalization in Deep Networks: The Role of Distance from Initialization", "url": "http://arxiv.org/pdf/1901.01672v2", "summary": "Why does training deep neural networks using stochastic gradient descent\n(SGD) result in a generalization error that does not worsen with the number of\nparameters in the network? To answer this question, we advocate a notion of\neffective model capacity that is dependent on {\\em a given random\ninitialization of the network} and not just the training algorithm and the data\ndistribution. We provide empirical evidences that demonstrate that the model\ncapacity of SGD-trained deep networks is in fact restricted through implicit\nregularization of {\\em the $\\ell_2$ distance from the initialization}. We also\nprovide theoretical arguments that further highlight the need for\ninitialization-dependent notions of model capacity. We leave as open questions\nhow and why distance from initialization is regularized, and whether it is\nsufficient to explain generalization.", "published": "2019-01-07T05:59:11Z", "version": 2}, {"aid": "1901.02358", "authors": ["Aditya Kusupati", "Manish Singh", "Kush Bhatia", "Ashish Kumar", "Prateek Jain", "Manik Varma"], "title": "FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network", "url": "http://arxiv.org/pdf/1901.02358v1", "summary": "This paper develops the FastRNN and FastGRNN algorithms to address the twin\nRNN limitations of inaccurate training and inefficient prediction. Previous\napproaches have improved accuracy at the expense of prediction costs making\nthem infeasible for resource-constrained and real-time applications. Unitary\nRNNs have increased accuracy somewhat by restricting the range of the state\ntransition matrix's singular values but have also increased the model size as\nthey require a larger number of hidden units to make up for the loss in\nexpressive power. Gated RNNs have obtained state-of-the-art accuracies by\nadding extra parameters thereby resulting in even larger models. FastRNN\naddresses these limitations by adding a residual connection that does not\nconstrain the range of the singular values explicitly and has only two extra\nscalar parameters. FastGRNN then extends the residual connection to a gate by\nreusing the RNN matrices to match state-of-the-art gated RNN accuracies but\nwith a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse\nand quantized resulted in accurate models that could be up to 35x smaller than\nleading gated and unitary RNNs. This allowed FastGRNN to accurately recognize\nthe \"Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely\nresource-constrained IoT microcontrollers too tiny to store other RNN models.\nFastGRNN's code is available at https://github.com/Microsoft/EdgeML/.", "published": "2019-01-08T15:19:13Z", "version": 1}, {"aid": "1901.02874", "authors": ["Sophie Schrader", "Andreas Westhoff", "Maria Carla Piastra", "Tuuli Miinalainen", "Sampsa Pursiainen", "Johannes Vorwerk", "Heinrich Brinck", "Carsten H. Wolters", "Christian Engwer"], "title": "DUNEuro -- A software toolbox for forward modeling in bioelectromagnetism", "url": "http://arxiv.org/pdf/1901.02874v4", "summary": "Accurate and efficient source analysis in electro- and magnetoencephalography\nusing sophisticated realistic head geometries requires advanced numerical\napproaches. This paper presents DUNEuro, a free and open source C++ software\ntoolbox for forward modeling in bioelectromagnetism. Building upon the DUNE\nframework, it provides implementations of modern fitted and unfitted finite\nelement methods to efficiently solve the forward problems in electro- and\nmagnetoencephalography. The user can choose between a variety of different\nsource models that are implemented. The software's aim is to provide interfaces\nthat are extendible and easy-to-use. In order to enable a closer integration\ninto existing analysis pipelines, interfaces to Python and Matlab are provided.\nThe practical use is demonstrated by a source analysis example of somatosensory\nevoked potentials using a realistic six compartment head model.", "published": "2019-01-09T18:52:01Z", "version": 4}, {"aid": "1901.05376", "authors": ["Tony Joseph", "Konstantinos G. Derpanis", "Faisal Z. Qureshi"], "title": "Joint Spatial and Layer Attention for Convolutional Networks", "url": "http://arxiv.org/pdf/1901.05376v2", "summary": "In this paper, we propose a novel approach that learns to sequentially attend\nto different Convolutional Neural Networks (CNN) layers (i.e., ``what'' feature\nabstraction to attend to) and different spatial locations of the selected\nfeature map (i.e., ``where'') to perform the task at hand. Specifically, at\neach Recurrent Neural Network (RNN) step, both a CNN layer and localized\nspatial region within it are selected for further processing. We demonstrate\nthe effectiveness of this approach on two computer vision tasks: (i)\nimage-based six degree of freedom camera pose regression and (ii) indoor scene\nclassification. Empirically, we show that combining the ``what'' and ``where''\naspects of attention improves network performance on both tasks. We evaluate\nour method on standard benchmarks for camera localization (Cambridge, 7-Scenes,\nand TUM-LSI) and for scene classification (MIT-67 Indoor Scenes). For camera\nlocalization our approach reduces the median error by 18.8\\% for position and\n8.2\\% for orientation (averaged over all scenes), and for scene classification\nit improves the mean accuracy by 3.4\\% over previous methods.", "published": "2019-01-16T16:32:31Z", "version": 2}, {"aid": "1901.05555", "authors": ["Yin Cui", "Menglin Jia", "Tsung-Yi Lin", "Yang Song", "Serge Belongie"], "title": "Class-Balanced Loss Based on Effective Number of Samples", "url": "http://arxiv.org/pdf/1901.05555v1", "summary": "With the rapid increase of large-scale, real-world datasets, it becomes\ncritical to address the problem of long-tailed data distribution (i.e., a few\nclasses account for most of the data, while most classes are\nunder-represented). Existing solutions typically adopt class re-balancing\nstrategies such as re-sampling and re-weighting based on the number of\nobservations for each class. In this work, we argue that as the number of\nsamples increases, the additional benefit of a newly added data point will\ndiminish. We introduce a novel theoretical framework to measure data overlap by\nassociating with each sample a small neighboring region rather than a single\npoint. The effective number of samples is defined as the volume of samples and\ncan be calculated by a simple formula $(1-\\beta^{n})/(1-\\beta)$, where $n$ is\nthe number of samples and $\\beta \\in [0,1)$ is a hyperparameter. We design a\nre-weighting scheme that uses the effective number of samples for each class to\nre-balance the loss, thereby yielding a class-balanced loss. Comprehensive\nexperiments are conducted on artificially induced long-tailed CIFAR datasets\nand large-scale datasets including ImageNet and iNaturalist. Our results show\nthat when trained with the proposed class-balanced loss, the network is able to\nachieve significant performance gains on long-tailed datasets.", "published": "2019-01-16T23:03:45Z", "version": 1}, {"aid": "1901.05567", "authors": ["Shichen Liu", "Weikai Chen", "Tianye Li", "Hao Li"], "title": "Soft Rasterizer: Differentiable Rendering for Unsupervised Single-View Mesh Reconstruction", "url": "http://arxiv.org/pdf/1901.05567v2", "summary": "Rendering is the process of generating 2D images from 3D assets, simulated in\na virtual environment, typically with a graphics pipeline. By inverting such\nrenderer, one can think of a learning approach to predict a 3D shape from an\ninput image. However, standard rendering pipelines involve a fundamental\ndiscretization step called rasterization, which prevents the rendering process\nto be differentiable, hence suitable for learning. We present the first\nnon-parametric and truly differentiable rasterizer based on silhouettes. Our\nmethod enables unsupervised learning for high-quality 3D mesh reconstruction\nfrom a single image. We call our framework `soft rasterizer' as it provides an\naccurate soft approximation of the standard rasterizer. The key idea is to fuse\nthe probabilistic contributions of all mesh triangles with respect to the\nrendered pixels. When combined with a mesh generator in a deep neural network,\nour soft rasterizer is able to generate an approximated silhouette of the\ngenerated polygon mesh in the forward pass. The rendering loss is\nback-propagated to supervise the mesh generation without the need of 3D\ntraining data. Experimental results demonstrate that our approach significantly\noutperforms the state-of-the-art unsupervised techniques, both quantitatively\nand qualitatively. We also show that our soft rasterizer can achieve comparable\nresults to the cutting-edge supervised learning method and in various cases\neven better ones, especially for real-world data.", "published": "2019-01-17T00:00:58Z", "version": 2}, {"aid": "1901.05733", "authors": ["Mostafa Salem", "Sergi Valverde", "Mariano Cabezas", "Deborah Pareto", "Arnau Oliver", "Joaquim Salvi", "\u00c0lex Rovira", "Xavier Llad\u00f3"], "title": "Multiple Sclerosis Lesion Synthesis in MRI using an encoder-decoder U-NET", "url": "http://arxiv.org/pdf/1901.05733v1", "summary": "In this paper, we propose generating synthetic multiple sclerosis (MS)\nlesions on MRI images with the final aim to improve the performance of\nsupervised machine learning algorithms, therefore avoiding the problem of the\nlack of available ground truth. We propose a two-input two-output fully\nconvolutional neural network model for MS lesion synthesis in MRI images. The\nlesion information is encoded as discrete binary intensity level masks passed\nto the model and stacked with the input images. The model is trained end-to-end\nwithout the need for manually annotating the lesions in the training set. We\nthen perform the generation of synthetic lesions on healthy images via\nregistration of patient images, which are subsequently used for data\naugmentation to increase the performance for supervised MS lesion detection\nalgorithms. Our pipeline is evaluated on MS patient data from an in-house\nclinical dataset and the public ISBI2015 challenge dataset. The evaluation is\nbased on measuring the similarities between the real and the synthetic images\nas well as in terms of lesion detection performance by segmenting both the\noriginal and synthetic images individually using a state-of-the-art\nsegmentation framework. We also demonstrate the usage of synthetic MS lesions\ngenerated on healthy images as data augmentation. We analyze a scenario of\nlimited training data (one-image training) to demonstrate the effect of the\ndata augmentation on both datasets. Our results significantly show the\neffectiveness of the usage of synthetic MS lesion images. For the ISBI2015\nchallenge, our one-image model trained using only a single image plus the\nsynthetic data augmentation strategy showed a performance similar to that of\nother CNN methods that were fully trained using the entire training set,\nyielding a comparable human expert rater performance", "published": "2019-01-17T11:25:50Z", "version": 1}, {"aid": "1901.06032", "authors": ["Asifullah Khan", "Anabia Sohail", "Umme Zahoora", "Aqsa Saeed Qureshi"], "title": "A Survey of the Recent Architectures of Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1901.06032v7", "summary": "Deep Convolutional Neural Network (CNN) is a special type of Neural Networks,\nwhich has shown exemplary performance on several competitions related to\nComputer Vision and Image Processing. Some of the exciting application areas of\nCNN include Image Classification and Segmentation, Object Detection, Video\nProcessing, Natural Language Processing, and Speech Recognition. The powerful\nlearning ability of deep CNN is primarily due to the use of multiple feature\nextraction stages that can automatically learn representations from the data.\nThe availability of a large amount of data and improvement in the hardware\ntechnology has accelerated the research in CNNs, and recently interesting deep\nCNN architectures have been reported. Several inspiring ideas to bring\nadvancements in CNNs have been explored, such as the use of different\nactivation and loss functions, parameter optimization, regularization, and\narchitectural innovations. However, the significant improvement in the\nrepresentational capacity of the deep CNN is achieved through architectural\ninnovations. Notably, the ideas of exploiting spatial and channel information,\ndepth and width of architecture, and multi-path information processing have\ngained substantial attention. Similarly, the idea of using a block of layers as\na structural unit is also gaining popularity. This survey thus focuses on the\nintrinsic taxonomy present in the recently reported deep CNN architectures and,\nconsequently, classifies the recent innovations in CNN architectures into seven\ndifferent categories. These seven categories are based on spatial exploitation,\ndepth, multi-path, width, feature-map exploitation, channel boosting, and\nattention. Additionally, the elementary understanding of CNN components,\ncurrent challenges, and applications of CNN are also provided.", "published": "2019-01-17T23:20:23Z", "version": 7}, {"aid": "1901.06110", "authors": ["Unni V. S.", "Sanjay Ghosh", "Kunal N. Chaudhury"], "title": "Linearized ADMM and Fast Nonlocal Denoising for Efficient Plug-and-Play Restoration", "url": "http://arxiv.org/pdf/1901.06110v1", "summary": "In plug-and-play image restoration, the regularization is performed using\npowerful denoisers such as nonlocal means (NLM) or BM3D. This is done within\nthe framework of alternating direction method of multipliers (ADMM), where the\nregularization step is formally replaced by an off-the-shelf denoiser. Each\nplug-and-play iteration involves the inversion of the forward model followed by\na denoising step. In this paper, we present a couple of ideas for improving the\nefficiency of the inversion and denoising steps. First, we propose to use\nlinearized ADMM, which generally allows us to perform the inversion at a lower\ncost than standard ADMM. Moreover, we can easily incorporate hard constraints\ninto the optimization framework as a result. Second, we develop a fast\nalgorithm for doubly stochastic NLM, originally proposed by Sreehari et al.\n(IEEE TCI, 2016), which is about 80x faster than brute-force computation. This\nparticular denoiser can be expressed as the proximal map of a convex\nregularizer and, as a consequence, we can guarantee convergence for linearized\nplug-and-play ADMM. We demonstrate the effectiveness of our proposals for\nsuper-resolution and single-photon imaging.", "published": "2019-01-18T07:20:32Z", "version": 1}, {"aid": "1901.06401", "authors": ["Atra Akandeh", "Fathi M. Salem"], "title": "Slim LSTM networks: LSTM_6 and LSTM_C6", "url": "http://arxiv.org/pdf/1901.06401v1", "summary": "We have shown previously that our parameter-reduced variants of Long\nShort-Term Memory (LSTM) Recurrent Neural Networks (RNN) are comparable in\nperformance to the standard LSTM RNN on the MNIST dataset. In this study, we\nshow that this is also the case for two diverse benchmark datasets, namely, the\nreview sentiment IMDB and the 20 Newsgroup datasets. Specifically, we focus on\ntwo of the simplest variants, namely LSTM_6 (i.e., standard LSTM with three\nconstant fixed gates) and LSTM_C6 (i.e., LSTM_6 with further reduced cell body\ninput block). We demonstrate that these two aggressively reduced-parameter\nvariants are competitive with the standard LSTM when hyper-parameters, e.g.,\nlearning parameter, number of hidden units and gate constants are set properly.\nThese architectures enable speeding up training computations and hence, these\nnetworks would be more suitable for online training and inference onto portable\ndevices with relatively limited computational resources.", "published": "2019-01-18T19:36:41Z", "version": 1}, {"aid": "1901.06773", "authors": ["Jinrong Guo", "Wantao Liu", "Wang Wang", "Qu Lu", "Songlin Hu", "Jizhong Han", "Ruixuan Li"], "title": "AccUDNN: A GPU Memory Efficient Accelerator for Training Ultra-deep Neural Networks", "url": "http://arxiv.org/pdf/1901.06773v2", "summary": "Typically, Ultra-deep neural network(UDNN) tends to yield high-quality model,\nbut its training process is usually resource intensive and time-consuming.\nModern GPU's scarce DRAM capacity is the primary bottleneck that hinders the\ntrainability and the training efficiency of UDNN. In this paper, we present\n\"AccUDNN\", an accelerator that aims to make the utmost use of finite GPU memory\nresources to speed up the training process of UDNN. AccUDNN mainly includes two\nmodules: memory optimizer and hyperparameter tuner. Memory optimizer develops a\nperformance-model guided dynamic swap out/in strategy, by offloading\nappropriate data to host memory, GPU memory footprint can be significantly\nslashed to overcome the restriction of trainability of UDNN. After applying the\nmemory optimization strategy, hyperparameter tuner is designed to explore the\nefficiency-optimal minibatch size and the matched learning rate. Evaluations\ndemonstrate that AccUDNN cuts down the GPU memory requirement of ResNet-152\nfrom more than 24GB to 8GB. In turn, given 12GB GPU memory budget, the\nefficiency-optimal minibatch size can reach 4.2x larger than original Caffe.\nBenefiting from better utilization of single GPU's computing resources and\nfewer parameter synchronization of large minibatch size, 7.7x speed-up is\nachieved by 8 GPUs' cluster without any communication optimization and no\naccuracy losses.", "published": "2019-01-21T02:52:09Z", "version": 2}, {"aid": "1902.02771", "authors": ["S. H. Shabbeer Basha", "Shiv Ram Dubey", "Viswanath Pulabaigari", "Snehasis Mukherjee"], "title": "Impact of Fully Connected Layers on Performance of Convolutional Neural Networks for Image Classification", "url": "http://arxiv.org/pdf/1902.02771v3", "summary": "The Convolutional Neural Networks (CNNs), in domains like computer vision,\nmostly reduced the need for handcrafted features due to its ability to learn\nthe problem-specific features from the raw input data. However, the selection\nof dataset-specific CNN architecture, which mostly performed by either\nexperience or expertise is a time-consuming and error-prone process. To\nautomate the process of learning a CNN architecture, this paper attempts at\nfinding the relationship between Fully Connected (FC) layers with some of the\ncharacteristics of the datasets. The CNN architectures, and recently datasets\nalso, are categorized as deep, shallow, wide, etc. This paper tries to\nformalize these terms along with answering the following questions. (i) What is\nthe impact of deeper/shallow architectures on the performance of the CNN w.r.t.\nFC layers?, (ii) How the deeper/wider datasets influence the performance of CNN\nw.r.t. FC layers?, and (iii) Which kind of architecture (deeper/ shallower) is\nbetter suitable for which kind of (deeper/ wider) datasets. To address these\nfindings, we have performed experiments with three CNN architectures having\ndifferent depths. The experiments are conducted by varying the number of FC\nlayers. We used four widely used datasets including CIFAR-10, CIFAR-100, Tiny\nImageNet, and CRCHistoPhenotypes to justify our findings in the context of the\nimage classification problem. The source code of this research is available at\nhttps://github.com/shabbeersh/Impact-of-FC-layers.", "published": "2019-01-21T07:42:26Z", "version": 3}, {"aid": "1901.11390", "authors": ["Christopher P. Burgess", "Loic Matthey", "Nicholas Watters", "Rishabh Kabra", "Irina Higgins", "Matt Botvinick", "Alexander Lerchner"], "title": "MONet: Unsupervised Scene Decomposition and Representation", "url": "http://arxiv.org/pdf/1901.11390v1", "summary": "The ability to decompose scenes in terms of abstract building blocks is\ncrucial for general intelligence. Where those basic building blocks share\nmeaningful properties, interactions and other regularities across scenes, such\ndecompositions can simplify reasoning and facilitate imagination of novel\nscenarios. In particular, representing perceptual observations in terms of\nentities should improve data efficiency and transfer performance on a wide\nrange of tasks. Thus we need models capable of discovering useful\ndecompositions of scenes by identifying units with such regularities and\nrepresenting them in a common format. To address this problem, we have\ndeveloped the Multi-Object Network (MONet). In this model, a VAE is trained\nend-to-end together with a recurrent attention network -- in a purely\nunsupervised manner -- to provide attention masks around, and reconstructions\nof, regions of images. We show that this model is capable of learning to\ndecompose and represent challenging 3D scenes into semantically meaningful\ncomponents, such as objects and background elements.", "published": "2019-01-22T18:55:34Z", "version": 1}, {"aid": "1901.07647", "authors": ["Jong Chul Ye", "Woon Kyoung Sung"], "title": "Understanding Geometry of Encoder-Decoder CNNs", "url": "http://arxiv.org/pdf/1901.07647v2", "summary": "Encoder-decoder networks using convolutional neural network (CNN)\narchitecture have been extensively used in deep learning literatures thanks to\nits excellent performance for various inverse problems. However, it is still\ndifficult to obtain coherent geometric view why such an architecture gives the\ndesired performance. Inspired by recent theoretical understanding on\ngeneralizability, expressivity and optimization landscape of neural networks,\nas well as the theory of convolutional framelets, here we provide a unified\ntheoretical framework that leads to a better understanding of geometry of\nencoder-decoder CNNs. Our unified mathematical framework shows that\nencoder-decoder CNN architecture is closely related to nonlinear basis\nrepresentation using combinatorial convolution frames, whose expressibility\nincreases exponentially with the network depth. We also demonstrate the\nimportance of skipped connection in terms of expressibility, and optimization\nlandscape.", "published": "2019-01-22T23:37:43Z", "version": 2}, {"aid": "1901.07680", "authors": ["Guanghan Ning", "Ping Liu", "Xiaochuan Fan", "Chi Zhang"], "title": "A Top-down Approach to Articulated Human Pose Estimation and Tracking", "url": "http://arxiv.org/pdf/1901.07680v1", "summary": "Both the tasks of multi-person human pose estimation and pose tracking in\nvideos are quite challenging. Existing methods can be categorized into two\ngroups: top-down and bottom-up approaches. In this paper, following the\ntop-down approach, we aim to build a strong baseline system with three modules:\nhuman candidate detector, single-person pose estimator and human pose tracker.\nFirstly, we choose a generic object detector among state-of-the-art methods to\ndetect human candidates. Then, the cascaded pyramid network is used to estimate\nthe corresponding human pose. Finally, we use a flow-based pose tracker to\nrender keypoint-association across frames, i.e., assigning each human candidate\na unique and temporally-consistent id, for the multi-target pose tracking\npurpose. We conduct extensive ablative experiments to validate various choices\nof models and configurations. We take part in two ECCV 18 PoseTrack challenges:\npose estimation and pose tracking.", "published": "2019-01-23T01:19:29Z", "version": 1}, {"aid": "1901.07929", "authors": ["Jos\u00e9 Ignacio Orlando", "Philipp Seeb\u00f6ck", "Hrvoje Bogunovi\u0107", "Sophie Klimscha", "Christoph Grechenig", "Sebastian Waldstein", "Bianca S. Gerendas", "Ursula Schmidt-Erfurth"], "title": "U2-Net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans", "url": "http://arxiv.org/pdf/1901.07929v2", "summary": "In this paper, we introduce a Bayesian deep learning based model for\nsegmenting the photoreceptor layer in pathological OCT scans. Our architecture\nprovides accurate segmentations of the photoreceptor layer and produces\npixel-wise epistemic uncertainty maps that highlight potential areas of\npathologies or segmentation errors. We empirically evaluated this approach in\ntwo sets of pathological OCT scans of patients with age-related macular\ndegeneration, retinal vein oclussion and diabetic macular edema, improving the\nperformance of the baseline U-Net both in terms of the Dice index and the area\nunder the precision/recall curve. We also observed that the uncertainty\nestimates were inversely correlated with the model performance, underlying its\nutility for highlighting areas where manual inspection/correction might be\nneeded.", "published": "2019-01-23T14:52:33Z", "version": 2}, {"aid": "1901.07945", "authors": ["Samuel J. Gershman"], "title": "What does the free energy principle tell us about the brain?", "url": "http://arxiv.org/pdf/1901.07945v5", "summary": "The free energy principle has been proposed as a unifying account of brain\nfunction. It is closely related, and in some cases subsumes, earlier unifying\nideas such as Bayesian inference, predictive coding, and active learning. This\narticle clarifies these connections, teasing apart distinctive and shared\npredictions.", "published": "2019-01-23T15:23:00Z", "version": 5}, {"aid": "1901.08373", "authors": ["Xuesong Li", "Jose Guivant", "Ngaiming Kwok", "Yongzhi Xu", "Ruowei Li", "Hongkun Wu"], "title": "Three-dimensional Backbone Network for 3D Object Detection in Traffic Scenes", "url": "http://arxiv.org/pdf/1901.08373v2", "summary": "The task of detecting 3D objects in traffic scenes has a pivotal role in many\nreal-world applications. However, the performance of 3D object detection is\nlower than that of 2D object detection due to the lack of powerful 3D feature\nextraction methods. To address this issue, this study proposes a 3D backbone\nnetwork to acquire comprehensive 3D feature maps for 3D object detection. It\nprimarily consists of sparse 3D convolutional neural network operations in the\npoint cloud. The 3D backbone network can inherently learn 3D features from the\nraw data without compressing the point cloud into multiple 2D images. The\nsparse 3D convolutional neural network takes full advantage of the sparsity in\nthe 3D point cloud to accelerate computation and save memory, which makes the\n3D backbone network feasible in a real-world application. Empirical experiments\nwere conducted on the KITTI benchmark and comparable results were obtained with\nrespect to the state-of-the-art performance for 3D object detection.", "published": "2019-01-24T12:11:05Z", "version": 2}, {"aid": "1901.08688", "authors": ["Poojan Oza", "Vishal M. Patel"], "title": "One-Class Convolutional Neural Network", "url": "http://arxiv.org/pdf/1901.08688v1", "summary": "We present a novel Convolutional Neural Network (CNN) based approach for one\nclass classification. The idea is to use a zero centered Gaussian noise in the\nlatent space as the pseudo-negative class and train the network using the\ncross-entropy loss to learn a good representation as well as the decision\nboundary for the given class. A key feature of the proposed approach is that\nany pre-trained CNN can be used as the base network for one class\nclassification. The proposed One Class CNN (OC-CNN) is evaluated on the\nUMDAA-02 Face, Abnormality-1001, FounderType-200 datasets. These datasets are\nrelated to a variety of one class application problems such as user\nauthentication, abnormality detection and novelty detection. Extensive\nexperiments demonstrate that the proposed method achieves significant\nimprovements over the recent state-of-the-art methods. The source code is\navailable at : github.com/otkupjnoz/oc-cnn.", "published": "2019-01-24T23:31:11Z", "version": 1}, {"aid": "1901.09822", "authors": ["Haifeng Shi", "Guanyu Cai", "Yuqin Wang", "Shaohua Shang", "Lianghua He"], "title": "Virtual Conditional Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1901.09822v1", "summary": "When trained on multimodal image datasets, normal Generative Adversarial\nNetworks (GANs) are usually outperformed by class-conditional GANs and ensemble\nGANs, but conditional GANs is restricted to labeled datasets and ensemble GANs\nlack efficiency. We propose a novel GAN variant called virtual conditional GAN\n(vcGAN) which is not only an ensemble GAN with multiple generative paths while\nadding almost zero network parameters, but also a conditional GAN that can be\ntrained on unlabeled datasets without explicit clustering steps or objectives\nother than the adversary loss. Inside the vcGAN's generator, a learnable\n``analog-to-digital converter (ADC)\" module maps a slice of the inputted\nmultivariate Gaussian noise to discrete/digital noise (virtual label),\naccording to which a selector selects the corresponding generative path to\nproduce the sample. All the generative paths share the same decoder network\nwhile in each path the decoder network is fed with a concatenation of a\ndifferent pre-computed amplified one-hot vector and the inputted Gaussian\nnoise. We conducted a lot of experiments on several balanced/imbalanced image\ndatasets to demonstrate that vcGAN converges faster and achieves improved\nFrech\\'et Inception Distance (FID). In addition, we show the training byproduct\nthat the ADC in vcGAN learned the categorical probability of each mode and that\neach generative path generates samples of specific mode, which enables\nclass-conditional sampling. Codes are available at\n\\url{https://github.com/annonnymmouss/vcgan}", "published": "2019-01-25T07:15:17Z", "version": 1}, {"aid": "1901.09054", "authors": ["Bj\u00f6rn Barz", "Joachim Denzler"], "title": "Deep Learning on Small Datasets without Pre-Training using Cosine Loss", "url": "http://arxiv.org/pdf/1901.09054v2", "summary": "Two things seem to be indisputable in the contemporary deep learning\ndiscourse: 1. The categorical cross-entropy loss after softmax activation is\nthe method of choice for classification. 2. Training a CNN classifier from\nscratch on small datasets does not work well. In contrast to this, we show that\nthe cosine loss function provides significantly better performance than\ncross-entropy on datasets with only a handful of samples per class. For\nexample, the accuracy achieved on the CUB-200-2011 dataset without pre-training\nis by 30% higher than with the cross-entropy loss. Further experiments on other\npopular datasets confirm our findings. Moreover, we demonstrate that\nintegrating prior knowledge in the form of class hierarchies is straightforward\nwith the cosine loss and improves classification performance further.", "published": "2019-01-25T19:13:03Z", "version": 2}, {"aid": "1901.09465", "authors": ["Banghua Zhu", "Jiantao Jiao", "David Tse"], "title": "Deconstructing Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1901.09465v7", "summary": "We deconstruct the performance of GANs into three components:\n  1. Formulation: we propose a perturbation view of the population target of\nGANs. Building on this interpretation, we show that GANs can be viewed as a\ngeneralization of the robust statistics framework, and propose a novel GAN\narchitecture, termed as Cascade GANs, to provably recover meaningful\nlow-dimensional generator approximations when the real distribution is\nhigh-dimensional and corrupted by outliers.\n  2. Generalization: given a population target of GANs, we design a systematic\nprinciple, projection under admissible distance, to design GANs to meet the\npopulation requirement using finite samples. We implement our principle in\nthree cases to achieve polynomial and sometimes near-optimal sample\ncomplexities: (1) learning an arbitrary generator under an arbitrary\npseudonorm; (2) learning a Gaussian location family under TV distance, where we\nutilize our principle provide a new proof for the optimality of Tukey median\nviewed as GANs; (3) learning a low-dimensional Gaussian approximation of a\nhigh-dimensional arbitrary distribution under Wasserstein distance. We\ndemonstrate a fundamental trade-off in the approximation error and statistical\nerror in GANs, and show how to apply our principle with empirical samples to\npredict how many samples are sufficient for GANs in order not to suffer from\nthe discriminator winning problem.\n  3. Optimization: we demonstrate alternating gradient descent is provably not\nlocally asymptotically stable in optimizing the GAN formulation of PCA. We\ndiagnose the problem as the minimax duality gap being non-zero, and propose a\nnew GAN architecture whose duality gap is zero, where the value of the game is\nequal to the previous minimax value (not the maximin value). We prove the new\nGAN architecture is globally asymptotically stable in optimization under\nalternating gradient descent.", "published": "2019-01-27T23:53:32Z", "version": 7}, {"aid": "1901.09615", "authors": ["Okan K\u00f6p\u00fckl\u00fc", "Maryam Babaee", "Stefan H\u00f6rmann", "Gerhard Rigoll"], "title": "Convolutional Neural Networks with Layer Reuse", "url": "http://arxiv.org/pdf/1901.09615v2", "summary": "A convolutional layer in a Convolutional Neural Network (CNN) consists of\nmany filters which apply convolution operation to the input, capture some\nspecial patterns and pass the result to the next layer. If the same patterns\nalso occur at the deeper layers of the network, why wouldn't the same\nconvolutional filters be used also in those layers? In this paper, we propose a\nCNN architecture, Layer Reuse Network (LruNet), where the convolutional layers\nare used repeatedly without the need of introducing new layers to get a better\nperformance. This approach introduces several advantages: (i) Considerable\namount of parameters are saved since we are reusing the layers instead of\nintroducing new layers, (ii) the Memory Access Cost (MAC) can be reduced since\nreused layer parameters can be fetched only once, (iii) the number of\nnonlinearities increases with layer reuse, and (iv) reused layers get gradient\nupdates from multiple parts of the network. The proposed approach is evaluated\non CIFAR-10, CIFAR-100 and Fashion-MNIST datasets for image classification\ntask, and layer reuse improves the performance by 5.14%, 5.85% and 2.29%,\nrespectively. The source code and pretrained models are publicly available.", "published": "2019-01-28T11:45:50Z", "version": 2}, {"aid": "1901.09886", "authors": ["Tapabrata Chakraborti", "Brendan McCane", "Steven Mills", "Umapada Pal"], "title": "CoCoNet: A Collaborative Convolutional Network", "url": "http://arxiv.org/pdf/1901.09886v4", "summary": "We present an end-to-end deep network for fine-grained visual categorization\ncalled Collaborative Convolutional Network (CoCoNet). The network uses a\ncollaborative layer after the convolutional layers to represent an image as an\noptimal weighted collaboration of features learned from training samples as a\nwhole rather than one at a time. This gives CoCoNet more power to encode the\nfine-grained nature of the data with limited samples. We perform a detailed\nstudy of the performance with 1-stage and 2-stage transfer learning. The\nablation study shows that the proposed method outperforms its constituent parts\nconsistently. CoCoNet also outperforms few state-of-the-art competing methods.\nExperiments have been performed on the fine-grained bird species classification\nproblem as a representative example, but the method may be applied to other\nsimilar tasks. We also introduce a new public dataset for fine-grained species\nrecognition, that of Indian endemic birds and have reported initial results on\nit.", "published": "2019-01-28T18:58:50Z", "version": 4}, {"aid": "1901.10177", "authors": ["Hong-Xing Yu", "Ancong Wu", "Wei-Shi Zheng"], "title": "Unsupervised Person Re-identification by Deep Asymmetric Metric Embedding", "url": "http://arxiv.org/pdf/1901.10177v1", "summary": "Person re-identification (Re-ID) aims to match identities across\nnon-overlapping camera views. Researchers have proposed many supervised Re-ID\nmodels which require quantities of cross-view pairwise labelled data. This\nlimits their scalabilities to many applications where a large amount of data\nfrom multiple disjoint camera views is available but unlabelled. Although some\nunsupervised Re-ID models have been proposed to address the scalability\nproblem, they often suffer from the view-specific bias problem which is caused\nby dramatic variances across different camera views, e.g., different\nillumination, viewpoints and occlusion. The dramatic variances induce specific\nfeature distortions in different camera views, which can be very disturbing in\nfinding cross-view discriminative information for Re-ID in the unsupervised\nscenarios, since no label information is available to help alleviate the bias.\nWe propose to explicitly address this problem by learning an unsupervised\nasymmetric distance metric based on cross-view clustering. The asymmetric\ndistance metric allows specific feature transformations for each camera view to\ntackle the specific feature distortions. We then design a novel unsupervised\nloss function to embed the asymmetric metric into a deep neural network, and\ntherefore develop a novel unsupervised deep framework named the DEep\nClustering-based Asymmetric MEtric Learning (DECAMEL). In such a way, DECAMEL\njointly learns the feature representation and the unsupervised asymmetric\nmetric. DECAMEL learns a compact cross-view cluster structure of Re-ID data,\nand thus help alleviate the view-specific bias and facilitate mining the\npotential cross-view discriminative information for unsupervised Re-ID.\nExtensive experiments on seven benchmark datasets whose sizes span several\norders show the effectiveness of our framework.", "published": "2019-01-29T08:49:26Z", "version": 1}, {"aid": "1901.10208", "authors": ["Nicola Strisciuglio", "Manuel Lopez-Antequera", "Nicolai Petkov"], "title": "A Push-Pull Layer Improves Robustness of Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1901.10208v1", "summary": "We propose a new layer in Convolutional Neural Networks (CNNs) to increase\ntheir robustness to several types of noise perturbations of the input images.\nWe call this a push-pull layer and compute its response as the combination of\ntwo half-wave rectified convolutions, with kernels of opposite polarity. It is\nbased on a biologically-motivated non-linear model of certain neurons in the\nvisual system that exhibit a response suppression phenomenon, known as\npush-pull inhibition. We validate our method by substituting the first\nconvolutional layer of the LeNet-5 and WideResNet architectures with our\npush-pull layer. We train the networks on nonperturbed training images from the\nMNIST, CIFAR-10 and CIFAR-100 data sets, and test on images perturbed by noise\nthat is unseen by the training process. We demonstrate that our push-pull\nlayers contribute to a considerable improvement in robustness of classification\nof images perturbed by noise, while maintaining state-of-the-art performance on\nthe original image classification task.", "published": "2019-01-29T10:42:04Z", "version": 1}, {"aid": "1901.10430", "authors": ["Felix Wu", "Angela Fan", "Alexei Baevski", "Yann N. Dauphin", "Michael Auli"], "title": "Pay Less Attention with Lightweight and Dynamic Convolutions", "url": "http://arxiv.org/pdf/1901.10430v2", "summary": "Self-attention is a useful mechanism to build generative models for language\nand images. It determines the importance of context elements by comparing each\nelement to the current time step. In this paper, we show that a very\nlightweight convolution can perform competitively to the best reported\nself-attention results. Next, we introduce dynamic convolutions which are\nsimpler and more efficient than self-attention. We predict separate convolution\nkernels based solely on the current time-step in order to determine the\nimportance of context elements. The number of operations required by this\napproach scales linearly in the input length, whereas self-attention is\nquadratic. Experiments on large-scale machine translation, language modeling\nand abstractive summarization show that dynamic convolutions improve over\nstrong self-attention models. On the WMT'14 English-German test set dynamic\nconvolutions achieve a new state of the art of 29.7 BLEU.", "published": "2019-01-29T18:01:35Z", "version": 2}, {"aid": "1901.11082", "authors": ["Chiyu \"Max\" Jiang", "Dana Lynn Ona Lansigan", "Philip Marcus", "Matthias Nie\u00dfner"], "title": "DDSL: Deep Differentiable Simplex Layer for Learning Geometric Signals", "url": "http://arxiv.org/pdf/1901.11082v3", "summary": "We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for\ngeometric deep learning. The DDSL is a differentiable layer compatible with\ndeep neural networks for bridging simplex mesh-based geometry representations\n(point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images\n(e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to\nperform differentiable, efficient, anti-aliased rasterization of simplex-based\nsignals. We present a complete theoretical framework for the process as well as\nan efficient backpropagation algorithm. Compared to previous differentiable\nrenderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees\nand dimensions. In particular, we explore its applications to 2D shapes and\nillustrate two applications of this method: (1) mesh editing and optimization\nguided by neural network outputs, and (2) using DDSL for a differentiable\nrasterization loss to facilitate end-to-end training of polygon generators. We\nare able to validate the effectiveness of gradient-based shape optimization\nwith the example of airfoil optimization, and using the differentiable\nrasterization loss to facilitate end-to-end training, we surpass state of the\nart for polygonal image segmentation given ground-truth bounding boxes.", "published": "2019-01-30T20:17:50Z", "version": 3}, {"aid": "1901.11137", "authors": ["Emiel Hoogeboom", "Rianne van den Berg", "Max Welling"], "title": "Emerging Convolutions for Generative Normalizing Flows", "url": "http://arxiv.org/pdf/1901.11137v3", "summary": "Generative flows are attractive because they admit exact likelihood\noptimization and efficient image synthesis. Recently, Kingma & Dhariwal (2018)\ndemonstrated with Glow that generative flows are capable of generating high\nquality images. We generalize the 1 x 1 convolutions proposed in Glow to\ninvertible d x d convolutions, which are more flexible since they operate on\nboth channel and spatial axes. We propose two methods to produce invertible\nconvolutions that have receptive fields identical to standard convolutions:\nEmerging convolutions are obtained by chaining specific autoregressive\nconvolutions, and periodic convolutions are decoupled in the frequency domain.\nOur experiments show that the flexibility of d x d convolutions significantly\nimproves the performance of generative flow models on galaxy images, CIFAR10\nand ImageNet.", "published": "2019-01-30T23:02:37Z", "version": 3}, {"aid": "1901.11153", "authors": ["Haozhe Xie", "Hongxun Yao", "Xiaoshuai Sun", "Shangchen Zhou", "Shengping Zhang"], "title": "Pix2Vox: Context-aware 3D Reconstruction from Single and Multi-view Images", "url": "http://arxiv.org/pdf/1901.11153v2", "summary": "Recovering the 3D representation of an object from single-view or multi-view\nRGB images by deep neural networks has attracted increasing attention in the\npast few years. Several mainstream works (e.g., 3D-R2N2) use recurrent neural\nnetworks (RNNs) to fuse multiple feature maps extracted from input images\nsequentially. However, when given the same set of input images with different\norders, RNN-based approaches are unable to produce consistent reconstruction\nresults. Moreover, due to long-term memory loss, RNNs cannot fully exploit\ninput images to refine reconstruction results. To solve these problems, we\npropose a novel framework for single-view and multi-view 3D reconstruction,\nnamed Pix2Vox. By using a well-designed encoder-decoder, it generates a coarse\n3D volume from each input image. Then, a context-aware fusion module is\nintroduced to adaptively select high-quality reconstructions for each part\n(e.g., table legs) from different coarse 3D volumes to obtain a fused 3D\nvolume. Finally, a refiner further refines the fused 3D volume to generate the\nfinal output. Experimental results on the ShapeNet and Pix3D benchmarks\nindicate that the proposed Pix2Vox outperforms state-of-the-arts by a large\nmargin. Furthermore, the proposed method is 24 times faster than 3D-R2N2 in\nterms of backward inference time. The experiments on ShapeNet unseen 3D\ncategories have shown the superior generalization abilities of our method.", "published": "2019-01-31T00:01:25Z", "version": 2}, {"aid": "1901.11228", "authors": ["Vineet Edupuganti", "Morteza Mardani", "Shreyas Vasanawala", "John Pauly"], "title": "Uncertainty Quantification in Deep MRI Reconstruction", "url": "http://arxiv.org/pdf/1901.11228v3", "summary": "Reliable MRI is crucial for accurate interpretation in therapeutic and\ndiagnostic tasks. However, undersampling during MRI acquisition as well as the\noverparameterized and non-transparent nature of deep learning (DL) leaves\nsubstantial uncertainty about the accuracy of DL reconstruction. With this in\nmind, this study aims to quantify the uncertainty in image recovery with DL\nmodels. To this end, we first leverage variational autoencoders (VAEs) to\ndevelop a probabilistic reconstruction scheme that maps out (low-quality) short\nscans with aliasing artifacts to the diagnostic-quality ones. The VAE encodes\nthe acquisition uncertainty in a latent code and naturally offers a posterior\nof the image from which one can generate pixel variance maps using Monte-Carlo\nsampling. Accurately predicting risk requires knowledge of the bias as well,\nfor which we leverage Stein's Unbiased Risk Estimator (SURE) as a proxy for\nmean-squared-error (MSE). Extensive empirical experiments are performed for\nKnee MRI reconstruction under different training losses (adversarial and\npixel-wise) and unrolled recurrent network architectures. Our key observations\nindicate that: 1) adversarial losses introduce more uncertainty; and 2)\nrecurrent unrolled nets reduce the prediction uncertainty and risk.", "published": "2019-01-31T06:33:48Z", "version": 3}, {"aid": "1902.10815", "authors": ["Cheng Ouyang", "Jo Schlemper", "Carlo Biffi", "Gavin Seegoolam", "Jose Caballero", "Anthony N. Price", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Generalizing Deep Learning MRI Reconstruction across Different Domains", "url": "http://arxiv.org/pdf/1902.10815v2", "summary": "We look into the robustness of deep learning based MRI reconstruction when\ntested on unseen contrasts and organs. We then propose to generalize the\nnetwork by training with large publicly-available natural image datasets with\nsynthesized phase information to achieve high cross-domain reconstruction\nperformance which is competitive with domain-specific training. To explain its\ngeneralization mechanism, we have also analyzed patch sets for different\ntraining datasets.", "published": "2019-01-31T12:08:33Z", "version": 2}, {"aid": "1901.11515", "authors": ["Willie Neiswanger", "Kirthevasan Kandasamy", "Barnabas Poczos", "Jeff Schneider", "Eric Xing"], "title": "ProBO: Versatile Bayesian Optimization Using Any Probabilistic Programming Language", "url": "http://arxiv.org/pdf/1901.11515v2", "summary": "Optimizing an expensive-to-query function is a common task in science and\nengineering, where it is beneficial to keep the number of queries to a minimum.\nA popular strategy is Bayesian optimization (BO), which leverages probabilistic\nmodels for this task. Most BO today uses Gaussian processes (GPs), or a few\nother surrogate models. However, there is a broad set of Bayesian modeling\ntechniques that could be used to capture complex systems and reduce the number\nof queries in BO. Probabilistic programming languages (PPLs) are modern tools\nthat allow for flexible model definition, prior specification, model\ncomposition, and automatic inference. In this paper, we develop ProBO, a BO\nprocedure that uses only standard operations common to most PPLs. This allows a\nuser to drop in a model built with an arbitrary PPL and use it directly in BO.\nWe describe acquisition functions for ProBO, and strategies for efficiently\noptimizing these functions given complex models or costly inference procedures.\nUsing existing PPLs, we implement new models to aid in a few challenging\noptimization settings, and demonstrate these on model hyperparameter and\narchitecture search tasks.", "published": "2019-01-31T18:35:56Z", "version": 2}, {"aid": "1902.00137", "authors": ["Kyungjae Lee", "Sungyub Kim", "Sungbin Lim", "Sungjoon Choi", "Songhwai Oh"], "title": "Tsallis Reinforcement Learning: A Unified Framework for Maximum Entropy Reinforcement Learning", "url": "http://arxiv.org/pdf/1902.00137v2", "summary": "In this paper, we present a new class of Markov decision processes (MDPs),\ncalled Tsallis MDPs, with Tsallis entropy maximization, which generalizes\nexisting maximum entropy reinforcement learning (RL). A Tsallis MDP provides a\nunified framework for the original RL problem and RL with various types of\nentropy, including the well-known standard Shannon-Gibbs (SG) entropy, using an\nadditional real-valued parameter, called an entropic index. By controlling the\nentropic index, we can generate various types of entropy, including the SG\nentropy, and a different entropy results in a different class of the optimal\npolicy in Tsallis MDPs. We also provide a full mathematical analysis of Tsallis\nMDPs, including the optimality condition, performance error bounds, and\nconvergence. Our theoretical result enables us to use any positive entropic\nindex in RL. To handle complex and large-scale problems, we propose a\nmodel-free actor-critic RL method using Tsallis entropy maximization. We\nevaluate the regularization effect of the Tsallis entropy with various values\nof entropic indices and show that the entropic index controls the exploration\ntendency of the proposed method. For a different type of RL problems, we find\nthat a different value of the entropic index is desirable. The proposed method\nis evaluated using the MuJoCo simulator and achieves the state-of-the-art\nperformance.", "published": "2019-01-31T23:59:34Z", "version": 2}, {"aid": "1902.00301", "authors": ["Oleksii Sidorov", "Jon Yngve Hardeberg"], "title": "Deep Hyperspectral Prior: Denoising, Inpainting, Super-Resolution", "url": "http://arxiv.org/pdf/1902.00301v2", "summary": "Deep learning algorithms have demonstrated state-of-the-art performance in\nvarious tasks of image restoration. This was made possible through the ability\nof CNNs to learn from large exemplar sets. However, the latter becomes an issue\nfor hyperspectral image processing where datasets commonly consist of just a\nfew images. In this work, we propose a new approach to denoising, inpainting,\nand super-resolution of hyperspectral image data using intrinsic properties of\na CNN without any training. The performance of the given algorithm is shown to\nbe comparable to the performance of trained networks, while its application is\nnot restricted by the availability of training data. This work is an extension\nof original \"deep prior\" algorithm to HSI domain and 3D-convolutional networks.", "published": "2019-02-01T12:20:38Z", "version": 2}, {"aid": "1902.00347", "authors": ["Christoph Angermann", "Markus Haltmeier", "Ruth Steiger", "Sergiy Pereverzyev Jr", "Elke Gizewski"], "title": "Projection-Based 2.5D U-net Architecture for Fast Volumetric Segmentation", "url": "http://arxiv.org/pdf/1902.00347v2", "summary": "Convolutional neural networks are state-of-the-art for various segmentation\ntasks. While for 2D images these networks are also computationally efficient,\n3D convolutions have huge storage requirements and require long training time.\nTo overcome this issue, we introduce a network structure for volumetric data\nwithout 3D convolutional layers. The main idea is to include maximum intensity\nprojections from different directions to transform the volumetric data to a\nsequence of images, where each image contains information of the full data. We\nthen apply 2D convolutions to these projection images and lift them again to\nvolumetric data using a trainable reconstruction algorithm.The proposed network\narchitecture has less storage requirements than network structures using 3D\nconvolutions. For a tested binary segmentation task, it even shows better\nperformance than the 3D U-net and can be trained much faster.", "published": "2019-02-01T14:19:00Z", "version": 2}, {"aid": "1902.00730", "authors": ["Fayez Lahoud", "Radhakrishna Achanta", "Pablo M\u00e1rquez-Neila", "Sabine S\u00fcsstrunk"], "title": "Self-Binarizing Networks", "url": "http://arxiv.org/pdf/1902.00730v1", "summary": "We present a method to train self-binarizing neural networks, that is,\nnetworks that evolve their weights and activations during training to become\nbinary. To obtain similar binary networks, existing methods rely on the sign\nactivation function. This function, however, has no gradients for non-zero\nvalues, which makes standard backpropagation impossible. To circumvent the\ndifficulty of training a network relying on the sign activation function, these\nmethods alternate between floating-point and binary representations of the\nnetwork during training, which is sub-optimal and inefficient. We approach the\nbinarization task by training on a unique representation involving a smooth\nactivation function, which is iteratively sharpened during training until it\nbecomes a binary representation equivalent to the sign activation function.\nAdditionally, we introduce a new technique to perform binary batch\nnormalization that simplifies the conventional batch normalization by\ntransforming it into a simple comparison operation. This is unlike existing\nmethods, which are forced to the retain the conventional floating-point-based\nbatch normalization. Our binary networks, apart from displaying advantages of\nlower memory and computation as compared to conventional floating-point and\nbinary networks, also show higher classification accuracy than existing\nstate-of-the-art methods on multiple benchmark datasets.", "published": "2019-02-02T14:48:16Z", "version": 1}, {"aid": "1902.01722", "authors": ["Paavo Parmas"], "title": "Total stochastic gradient algorithms and applications in reinforcement learning", "url": "http://arxiv.org/pdf/1902.01722v1", "summary": "Backpropagation and the chain rule of derivatives have been prominent;\nhowever, the total derivative rule has not enjoyed the same amount of\nattention. In this work we show how the total derivative rule leads to an\nintuitive visual framework for creating gradient estimators on graphical\nmodels. In particular, previous \"policy gradient theorems\" are easily derived.\nWe derive new gradient estimators based on density estimation, as well as a\nlikelihood ratio gradient, which \"jumps\" to an intermediate node, not directly\nto the objective function. We evaluate our methods on model-based policy\ngradient algorithms, achieve good performance, and present evidence towards\ndemystifying the success of the popular PILCO algorithm.", "published": "2019-02-05T14:54:05Z", "version": 1}, {"aid": "1902.01831", "authors": ["Roberto Valle", "Jos\u00e9 M. Buenaposada", "Antonio Vald\u00e9s", "Luis Baumela"], "title": "Face Alignment using a 3D Deeply-initialized Ensemble of Regression Trees", "url": "http://arxiv.org/pdf/1902.01831v2", "summary": "Face alignment algorithms locate a set of landmark points in images of faces\ntaken in unrestricted situations. State-of-the-art approaches typically fail or\nlose accuracy in the presence of occlusions, strong deformations, large pose\nvariations and ambiguous configurations. In this paper we present 3DDE, a\nrobust and efficient face alignment algorithm based on a coarse-to-fine cascade\nof ensembles of regression trees. It is initialized by robustly fitting a 3D\nface model to the probability maps produced by a convolutional neural network.\nWith this initialization we address self-occlusions and large face rotations.\nFurther, the regressor implicitly imposes a prior face shape on the solution,\naddressing occlusions and ambiguous face configurations. Its coarse-to-fine\nstructure tackles the combinatorial explosion of parts deformation. In the\nexperiments performed, 3DDE improves the state-of-the-art in 300W, COFW, AFLW\nand WFLW data sets. Finally, we perform cross-dataset experiments that reveal\nthe existence of a significant data set bias in these benchmarks.", "published": "2019-02-05T18:07:17Z", "version": 2}, {"aid": "1902.01996", "authors": ["Chiyuan Zhang", "Samy Bengio", "Yoram Singer"], "title": "Are All Layers Created Equal?", "url": "http://arxiv.org/pdf/1902.01996v4", "summary": "Understanding deep neural networks is a major research objective with notable\nexperimental and theoretical attention in recent years. The practical success\nof excessively large networks underscores the need for better theoretical\nanalyses and justifications. In this paper we focus on layer-wise functional\nstructure and behavior in overparameterized deep models. To do so, we study\nempirically the layers' robustness to post-training re-initialization and\nre-randomization of the parameters. We provide experimental results which give\nevidence for the heterogeneity of layers. Morally, layers of large deep neural\nnetworks can be categorized as either \"robust\" or \"critical\". Resetting the\nrobust layers to their initial values does not result in adverse decline in\nperformance. In many cases, robust layers hardly change throughout training. In\ncontrast, re-initializing critical layers vastly degrades the performance of\nthe network with test error essentially dropping to random guesses. Our study\nprovides further evidence that mere parameter counting or norm calculations are\ntoo coarse in studying generalization of deep models, and \"flatness\" and\nrobustness analysis of trained models need to be examined while taking into\naccount the respective network architectures.", "published": "2019-02-06T01:29:01Z", "version": 4}, {"aid": "1902.02354", "authors": ["Oded Ben-David", "Zohar Ringel"], "title": "The role of a layer in deep neural networks: a Gaussian Process perspective", "url": "http://arxiv.org/pdf/1902.02354v3", "summary": "A fundamental question in deep learning concerns the role played by\nindividual layers in a deep neural network (DNN) and the transferable\nproperties of the data representations which they learn. To the extent that\nlayers have clear roles, one should be able to optimize them separately using\nlayer-wise loss functions. Such loss functions would describe what is the set\nof good data representations at each depth of the network and provide a target\nfor layer-wise greedy optimization (LEGO). Here we derive a novel\ncorrespondence between Gaussian Processes and SGD trained deep neural networks.\nLeveraging this correspondence, we derive the Deep Gaussian Layer-wise loss\nfunctions (DGLs) which, we believe, are the first supervised layer-wise loss\nfunctions which are both explicit and competitive in terms of accuracy. Being\nhighly structured and symmetric, the DGLs provide a promising analytic route to\nunderstanding the internal representations generated by DNNs.", "published": "2019-02-06T19:00:03Z", "version": 3}, {"aid": "1902.02399", "authors": ["Payel Das", "Brian Quanz", "Pin-Yu Chen", "Jae-wook Ahn", "Dhruv Shah"], "title": "Toward A Neuro-inspired Creative Decoder", "url": "http://arxiv.org/pdf/1902.02399v4", "summary": "Creativity, a process that generates novel and meaningful ideas, involves\nincreased association between task-positive (control) and task-negative\n(default) networks in the human brain. Inspired by this seminal finding, in\nthis study we propose a creative decoder within a deep generative framework,\nwhich involves direct modulation of the neuronal activation pattern after\nsampling from the learned latent space. The proposed approach is fully\nunsupervised and can be used off-the-shelf. Several novelty metrics and human\nevaluation were used to evaluate the creative capacity of the deep decoder. Our\nexperiments on different image datasets (MNIST, FMNIST, MNIST+FMNIST, WikiArt\nand CelebA) reveal that atypical co-activation of highly activated and weakly\nactivated neurons in a deep decoder promotes generation of novel and meaningful\nartifacts.", "published": "2019-02-06T21:06:58Z", "version": 4}, {"aid": "1902.02449", "authors": ["Byung Hyun Lee", "Se Young Chun"], "title": "Empirically Accelerating Scaled Gradient Projection Using Deep Neural Network For Inverse Problems In Image Processing", "url": "http://arxiv.org/pdf/1902.02449v3", "summary": "Recently, deep neural networks (DNNs) have shown advantages in accelerating\noptimization algorithms. One approach is to unfold finite number of iterations\nof conventional optimization algorithms and to learn parameters in the\nalgorithms. However, these are forward methods and are indeed neither iterative\nnor convergent. Here, we present a novel DNN-based convergent iterative\nalgorithm that accelerates conventional optimization algorithms. We train a DNN\nto yield parameters in scaled gradient projection method. So far, these\nparameters have been chosen heuristically, but have shown to be crucial for\ngood empirical performance. In simulation results, the proposed method\nsignificantly improves the empirical convergence rate over conventional\noptimization methods for various large-scale inverse problems in image\nprocessing.", "published": "2019-02-07T02:19:53Z", "version": 3}, {"aid": "1902.02476", "authors": ["Wesley Maddox", "Timur Garipov", "Pavel Izmailov", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning", "url": "http://arxiv.org/pdf/1902.02476v2", "summary": "We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose\napproach for uncertainty representation and calibration in deep learning.\nStochastic Weight Averaging (SWA), which computes the first moment of\nstochastic gradient descent (SGD) iterates with a modified learning rate\nschedule, has recently been shown to improve generalization in deep learning.\nWith SWAG, we fit a Gaussian using the SWA solution as the first moment and a\nlow rank plus diagonal covariance also derived from the SGD iterates, forming\nan approximate posterior distribution over neural network weights; we then\nsample from this Gaussian distribution to perform Bayesian model averaging. We\nempirically find that SWAG approximates the shape of the true posterior, in\naccordance with results describing the stationary distribution of SGD iterates.\nMoreover, we demonstrate that SWAG performs well on a wide variety of tasks,\nincluding out of sample detection, calibration, and transfer learning, in\ncomparison to many popular alternatives including MC dropout, KFAC Laplace,\nSGLD, and temperature scaling.", "published": "2019-02-07T05:15:46Z", "version": 2}, {"aid": "1902.02693", "authors": ["Joost Visser", "Alessandro Corbetta", "Vlado Menkovski", "Federico Toschi"], "title": "StampNet: unsupervised multi-class object discovery", "url": "http://arxiv.org/pdf/1902.02693v1", "summary": "Unsupervised object discovery in images involves uncovering recurring\npatterns that define objects and discriminates them against the background.\nThis is more challenging than image clustering as the size and the location of\nthe objects are not known: this adds additional degrees of freedom and\nincreases the problem complexity. In this work, we propose StampNet, a novel\nautoencoding neural network that localizes shapes (objects) over a simple\nbackground in images and categorizes them simultaneously. StampNet consists of\na discrete latent space that is used to categorize objects and to determine the\nlocation of the objects. The object categories are formed during the training,\nresulting in the discovery of a fixed set of objects. We present a set of\nexperiments that demonstrate that StampNet is able to localize and cluster\nmultiple overlapping shapes with varying complexity including the digits from\nthe MNIST dataset. We also present an application of StampNet in the\nlocalization of pedestrians in overhead depth-maps.", "published": "2019-02-07T15:35:55Z", "version": 1}, {"aid": "1902.02875", "authors": ["Christian Klos", "Yaroslav Felipe Kalle Kossio", "Sven Goedeke", "Aditya Gilra", "Raoul-Martin Memmesheimer"], "title": "Dynamical learning of dynamics", "url": "http://arxiv.org/pdf/1902.02875v3", "summary": "The ability of humans and animals to quickly adapt to novel tasks is\ndifficult to reconcile with the standard paradigm of learning by slow synaptic\nweight modification. Here we show that fixed-weight neural networks can learn\nto generate required dynamics by imitation. After appropriate weight\npretraining, the networks quickly and dynamically adapt to learn new tasks and\nthereafter continue to achieve them without further teacher feedback. We\nexplain this ability and illustrate it with a variety of target dynamics,\nranging from oscillatory trajectories to driven and chaotic dynamical systems.", "published": "2019-02-07T23:00:54Z", "version": 3}, {"aid": "1902.02893", "authors": ["Silviu Pitis"], "title": "Rethinking the Discount Factor in Reinforcement Learning: A Decision Theoretic Approach", "url": "http://arxiv.org/pdf/1902.02893v1", "summary": "Reinforcement learning (RL) agents have traditionally been tasked with\nmaximizing the value function of a Markov decision process (MDP), either in\ncontinuous settings, with fixed discount factor $\\gamma < 1$, or in episodic\nsettings, with $\\gamma = 1$. While this has proven effective for specific tasks\nwith well-defined objectives (e.g., games), it has never been established that\nfixed discounting is suitable for general purpose use (e.g., as a model of\nhuman preferences). This paper characterizes rationality in sequential decision\nmaking using a set of seven axioms and arrives at a form of discounting that\ngeneralizes traditional fixed discounting. In particular, our framework admits\na state-action dependent \"discount\" factor that is not constrained to be less\nthan 1, so long as there is eventual long run discounting. Although this\nbroadens the range of possible preference structures in continuous settings, we\nshow that there exists a unique \"optimizing MDP\" with fixed $\\gamma < 1$ whose\noptimal value function matches the true utility of the optimal policy, and we\nquantify the difference between value and utility for suboptimal policies. Our\nwork can be seen as providing a normative justification for (a slight\ngeneralization of) Martha White's RL task formalism (2017) and other recent\ndepartures from the traditional RL, and is relevant to task specification in\nRL, inverse RL and preference-based RL.", "published": "2019-02-08T00:30:53Z", "version": 1}, {"aid": "1902.03043", "authors": ["Ross Harper", "Joshua Southern"], "title": "A Bayesian Deep Learning Framework for End-To-End Prediction of Emotion from Heartbeat", "url": "http://arxiv.org/pdf/1902.03043v2", "summary": "Automatic prediction of emotion promises to revolutionise human-computer\ninteraction. Recent trends involve fusion of multiple data modalities - audio,\nvisual, and physiological - to classify emotional state. However, in practice,\ncollection of physiological data `in the wild' is currently limited to\nheartbeat time series of the kind generated by affordable wearable heart\nmonitors. Furthermore, real-world applications of emotion prediction often\nrequire some measure of uncertainty over model output, in order to inform\ndownstream decision-making. We present here an end-to-end deep learning model\nfor classifying emotional valence from unimodal heartbeat time series. We\nfurther propose a Bayesian framework for modelling uncertainty over these\nvalence predictions, and describe a probabilistic procedure for choosing to\naccept or reject model output according to the intended application. We\nbenchmarked our framework against two established datasets and achieved peak\nclassification accuracy of 90%. These results lay the foundation for\napplications of affective computing in real-world domains such as healthcare,\nwhere a high premium is placed on non-invasive collection of data, and\npredictive certainty.", "published": "2019-02-08T12:10:45Z", "version": 2}, {"aid": "1902.03389", "authors": ["Hiroki Tamaru", "Yuki Saito", "Shinnosuke Takamichi", "Tomoki Koriyama", "Hiroshi Saruwatari"], "title": "Generative Moment Matching Network-based Random Modulation Post-filter for DNN-based Singing Voice Synthesis and Neural Double-tracking", "url": "http://arxiv.org/pdf/1902.03389v1", "summary": "This paper proposes a generative moment matching network (GMMN)-based\npost-filter that provides inter-utterance pitch variation for deep neural\nnetwork (DNN)-based singing voice synthesis. The natural pitch variation of a\nhuman singing voice leads to a richer musical experience and is used in\ndouble-tracking, a recording method in which two performances of the same\nphrase are recorded and mixed to create a richer, layered sound. However,\nsinging voices synthesized using conventional DNN-based methods never vary\nbecause the synthesis process is deterministic and only one waveform is\nsynthesized from one musical score. To address this problem, we use a GMMN to\nmodel the variation of the modulation spectrum of the pitch contour of natural\nsinging voices and add a randomized inter-utterance variation to the pitch\ncontour generated by conventional DNN-based singing voice synthesis.\nExperimental evaluations suggest that 1) our approach can provide perceptible\ninter-utterance pitch variation while preserving speech quality. We extend our\napproach to double-tracking, and the evaluation demonstrates that 2) GMMN-based\nneural double-tracking is perceptually closer to natural double-tracking than\nconventional signal processing-based artificial double-tracking is.", "published": "2019-02-09T07:49:42Z", "version": 1}, {"aid": "1902.03459", "authors": ["Marcin Kopaczka", "Justus Schock", "Dorit Merhof"], "title": "Super-realtime facial landmark detection and shape fitting by deep regression of shape model parameters", "url": "http://arxiv.org/pdf/1902.03459v1", "summary": "We present a method for highly efficient landmark detection that combines\ndeep convolutional neural networks with well established model-based fitting\nalgorithms. Motivated by established model-based fitting methods such as active\nshapes, we use a PCA of the landmark positions to allow generative modeling of\nfacial landmarks. Instead of computing the model parameters using iterative\noptimization, the PCA is included in a deep neural network using a novel layer\ntype. The network predicts model parameters in a single forward pass, thereby\nallowing facial landmark detection at several hundreds of frames per second.\nOur architecture allows direct end-to-end training of a model-based landmark\ndetection method and shows that deep neural networks can be used to reliably\npredict model parameters directly without the need for an iterative\noptimization. The method is evaluated on different datasets for facial landmark\ndetection and medical image segmentation. PyTorch code is freely available at\nhttps://github.com/justusschock/shapenet", "published": "2019-02-09T17:59:07Z", "version": 1}, {"aid": "1902.03524", "authors": ["Stephen Balaban"], "title": "Deep learning and face recognition: the state of the art", "url": "http://arxiv.org/pdf/1902.03524v1", "summary": "Deep Neural Networks (DNNs) have established themselves as a dominant\ntechnique in machine learning. DNNs have been top performers on a wide variety\nof tasks including image classification, speech recognition, and face\nrecognition. Convolutional neural networks (CNNs) have been used in nearly all\nof the top performing methods on the Labeled Faces in the Wild (LFW) dataset.\nIn this talk and accompanying paper, I attempt to provide a review and summary\nof the deep learning techniques used in the state-of-the-art. In addition, I\nhighlight the need for both larger and more challenging public datasets to\nbenchmark these systems. The high accuracy (99.63% for FaceNet at the time of\npublishing) and utilization of outside data (hundreds of millions of images in\nthe case of Google's FaceNet) suggest that current face verification benchmarks\nsuch as LFW may not be challenging enough, nor provide enough data, for current\ntechniques. There exist a variety of organizations with mobile photo sharing\napplications that would be capable of releasing a very large scale and highly\ndiverse dataset of facial images captured on mobile devices. Such an \"ImageNet\nfor Face Recognition\" would likely receive a warm welcome from researchers and\npractitioners alike.", "published": "2019-02-10T01:07:15Z", "version": 1}, {"aid": "1902.03565", "authors": ["Ran He", "Jie Cao", "Lingxiao Song", "Zhenan Sun", "Tieniu Tan"], "title": "Cross-spectral Face Completion for NIR-VIS Heterogeneous Face Recognition", "url": "http://arxiv.org/pdf/1902.03565v1", "summary": "Near infrared-visible (NIR-VIS) heterogeneous face recognition refers to the\nprocess of matching NIR to VIS face images. Current heterogeneous methods try\nto extend VIS face recognition methods to the NIR spectrum by synthesizing VIS\nimages from NIR images. However, due to self-occlusion and sensing gap, NIR\nface images lose some visible lighting contents so that they are always\nincomplete compared to VIS face images. This paper models high resolution\nheterogeneous face synthesis as a complementary combination of two components,\na texture inpainting component and pose correction component. The inpainting\ncomponent synthesizes and inpaints VIS image textures from NIR image textures.\nThe correction component maps any pose in NIR images to a frontal pose in VIS\nimages, resulting in paired NIR and VIS textures. A warping procedure is\ndeveloped to integrate the two components into an end-to-end deep network. A\nfine-grained discriminator and a wavelet-based discriminator are designed to\nsupervise intra-class variance and visual quality respectively. One UV loss,\ntwo adversarial losses and one pixel loss are imposed to ensure synthesis\nresults. We demonstrate that by attaching the correction component, we can\nsimplify heterogeneous face synthesis from one-to-many unpaired image\ntranslation to one-to-one paired image translation, and minimize spectral and\npose discrepancy during heterogeneous recognition. Extensive experimental\nresults show that our network not only generates high-resolution VIS face\nimages and but also facilitates the accuracy improvement of heterogeneous face\nrecognition.", "published": "2019-02-10T10:20:38Z", "version": 1}, {"aid": "1902.03619", "authors": ["Victoria Fernandez Abrevaya", "Adnane Boukhayma", "Stefanie Wuhrer", "Edmond Boyer"], "title": "A Decoupled 3D Facial Shape Model by Adversarial Training", "url": "http://arxiv.org/pdf/1902.03619v3", "summary": "Data-driven generative 3D face models are used to compactly encode facial\nshape data into meaningful parametric representations. A desirable property of\nthese models is their ability to effectively decouple natural sources of\nvariation, in particular identity and expression. While factorized\nrepresentations have been proposed for that purpose, they are still limited in\nthe variability they can capture and may present modeling artifacts when\napplied to tasks such as expression transfer. In this work, we explore a new\ndirection with Generative Adversarial Networks and show that they contribute to\nbetter face modeling performances, especially in decoupling natural factors,\nwhile also achieving more diverse samples. To train the model we introduce a\nnovel architecture that combines a 3D generator with a 2D discriminator that\nleverages conventional CNNs, where the two components are bridged by a geometry\nmapping layer. We further present a training scheme, based on auxiliary\nclassifiers, to explicitly disentangle identity and expression attributes.\nThrough quantitative and qualitative results on standard face datasets, we\nillustrate the benefits of our model and demonstrate that it outperforms\ncompeting state of the art methods in terms of decoupling and diversity.", "published": "2019-02-10T15:15:44Z", "version": 3}, {"aid": "1902.04394", "authors": ["Alex B\u00e4uerle", "Christian van Onzenoodt", "Timo Ropinski"], "title": "Net2Vis -- A Visual Grammar for Automatically Generating Publication-Tailored CNN Architecture Visualizations", "url": "http://arxiv.org/pdf/1902.04394v6", "summary": "To convey neural network architectures in publications, appropriate\nvisualizations are of great importance. While most current deep learning papers\ncontain such visualizations, these are usually handcrafted just before\npublication, which results in a lack of a common visual grammar, significant\ntime investment, errors, and ambiguities. Current automatic network\nvisualization tools focus on debugging the network itself and are not ideal for\ngenerating publication visualizations. Therefore, we present an approach to\nautomate this process by translating network architectures specified in Keras\ninto visualizations that can directly be embedded into any publication. To do\nso, we propose a visual grammar for convolutional neural networks (CNNs), which\nhas been derived from an analysis of such figures extracted from all ICCV and\nCVPR papers published between 2013 and 2019. The proposed grammar incorporates\nvisual encoding, network layout, layer aggregation, and legend generation. We\nhave further realized our approach in an online system available to the\ncommunity, which we have evaluated through expert feedback, and a quantitative\nstudy. It not only reduces the time needed to generate network visualizations\nfor publications, but also enables a unified and unambiguous visualization\ndesign.", "published": "2019-02-11T15:13:58Z", "version": 6}, {"aid": "1902.04049", "authors": ["Nabil Ibtehaz", "M. Sohel Rahman"], "title": "MultiResUNet : Rethinking the U-Net Architecture for Multimodal Biomedical Image Segmentation", "url": "http://arxiv.org/pdf/1902.04049v1", "summary": "In recent years Deep Learning has brought about a breakthrough in Medical\nImage Segmentation. U-Net is the most prominent deep network in this regard,\nwhich has been the most popular architecture in the medical imaging community.\nDespite outstanding overall performance in segmenting multimodal medical\nimages, from extensive experimentations on challenging datasets, we found out\nthat the classical U-Net architecture seems to be lacking in certain aspects.\nTherefore, we propose some modifications to improve upon the already\nstate-of-the-art U-Net model. Hence, following the modifications we develop a\nnovel architecture MultiResUNet as the potential successor to the successful\nU-Net architecture. We have compared our proposed architecture MultiResUNet\nwith the classical U-Net on a vast repertoire of multimodal medical images.\nAlbeit slight improvements in the cases of ideal images, a remarkable gain in\nperformance has been attained for challenging images. We have evaluated our\nmodel on five different datasets, each with their own unique challenges, and\nhave obtained a relative improvement in performance of 10.15%, 5.07%, 2.63%,\n1.41%, and 0.62% respectively.", "published": "2019-02-11T18:50:11Z", "version": 1}, {"aid": "1902.04161", "authors": ["Gopalakrishnan Srinivasan", "Kaushik Roy"], "title": "ReStoCNet: Residual Stochastic Binary Convolutional Spiking Neural Network for Memory-Efficient Neuromorphic Computing", "url": "http://arxiv.org/pdf/1902.04161v1", "summary": "In this work, we propose ReStoCNet, a residual stochastic multilayer\nconvolutional Spiking Neural Network (SNN) composed of binary kernels, to\nreduce the synaptic memory footprint and enhance the computational efficiency\nof SNNs for complex pattern recognition tasks. ReStoCNet consists of an input\nlayer followed by stacked convolutional layers for hierarchical input feature\nextraction, pooling layers for dimensionality reduction, and fully-connected\nlayer for inference. In addition, we introduce residual connections between the\nstacked convolutional layers to improve the hierarchical feature learning\ncapability of deep SNNs. We propose Spike Timing Dependent Plasticity (STDP)\nbased probabilistic learning algorithm, referred to as Hybrid-STDP (HB-STDP),\nincorporating Hebbian and anti-Hebbian learning mechanisms, to train the binary\nkernels forming ReStoCNet in a layer-wise unsupervised manner. We demonstrate\nthe efficacy of ReStoCNet and the presented HB-STDP based unsupervised training\nmethodology on the MNIST and CIFAR-10 datasets. We show that residual\nconnections enable the deeper convolutional layers to self-learn useful\nhigh-level input features and mitigate the accuracy loss observed in deep SNNs\ndevoid of residual connections. The proposed ReStoCNet offers >20x kernel\nmemory compression compared to full-precision (32-bit) SNN while yielding high\nenough classification accuracy on the chosen pattern recognition tasks.", "published": "2019-02-11T21:54:48Z", "version": 1}, {"aid": "1902.04294", "authors": ["Jaeyoung Yoo", "Hojun Lee", "Nojun Kwak"], "title": "Unpriortized Autoencoder For Image Generation", "url": "http://arxiv.org/pdf/1902.04294v2", "summary": "In this paper, we treat the image generation task using an autoencoder, a\nrepresentative latent model. Unlike many studies regularizing the latent\nvariable's distribution by assuming a manually specified prior, we approach the\nimage generation task using an autoencoder by directly estimating the latent\ndistribution. To this end, we introduce 'latent density estimator' which\ncaptures latent distribution explicitly and propose its structure. Through\nexperiments, we show that our generative model generates images with the\nimproved visual quality compared to previous autoencoder-based generative\nmodels.", "published": "2019-02-12T09:41:36Z", "version": 2}, {"aid": "1902.04698", "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Michael C. Mozer", "Yoram Singer"], "title": "Identity Crisis: Memorization and Generalization under Extreme Overparameterization", "url": "http://arxiv.org/pdf/1902.04698v4", "summary": "We study the interplay between memorization and generalization of\noverparameterized networks in the extreme case of a single training example and\nan identity-mapping task. We examine fully-connected and convolutional networks\n(FCN and CNN), both linear and nonlinear, initialized randomly and then trained\nto minimize the reconstruction error. The trained networks stereotypically take\none of two forms: the constant function (memorization) and the identity\nfunction (generalization). We formally characterize generalization in\nsingle-layer FCNs and CNNs. We show empirically that different architectures\nexhibit strikingly different inductive biases. For example, CNNs of up to 10\nlayers are able to generalize from a single example, whereas FCNs cannot learn\nthe identity function reliably from 60k examples. Deeper CNNs often fail, but\nnonetheless do astonishing work to memorize the training output: because CNN\nbiases are location invariant, the model must progressively grow an output\npattern from the image boundaries via the coordination of many layers. Our work\nhelps to quantify and visualize the sensitivity of inductive biases to\narchitectural choices such as depth, kernel width, and number of channels.", "published": "2019-02-13T01:45:30Z", "version": 4}, {"aid": "1902.04832", "authors": ["Tshilidzi Marwala"], "title": "Relative rationality: Is machine rationality subjective?", "url": "http://arxiv.org/pdf/1902.04832v1", "summary": "Rational decision making in its linguistic description means making logical\ndecisions. In essence, a rational agent optimally processes all relevant\ninformation to achieve its goal. Rationality has two elements and these are the\nuse of relevant information and the efficient processing of such information.\nIn reality, relevant information is incomplete, imperfect and the processing\nengine, which is a brain for humans, is suboptimal. Humans are risk averse\nrather than utility maximizers. In the real world, problems are predominantly\nnon-convex and this makes the idea of rational decision-making fundamentally\nunachievable and Herbert Simon called this bounded rationality. There is a\ntrade-off between the amount of information used for decision-making and the\ncomplexity of the decision model used. This explores whether machine\nrationality is subjective and concludes that indeed it is.", "published": "2019-02-13T10:08:12Z", "version": 1}, {"aid": "1902.05908", "authors": ["Naimul Mefraz Khan", "Nabila Abraham", "Ling Guan"], "title": "Machine Learning on Biomedical Images: Interactive Learning, Transfer Learning, Class Imbalance, and Beyond", "url": "http://arxiv.org/pdf/1902.05908v1", "summary": "In this paper, we highlight three issues that limit performance of machine\nlearning on biomedical images, and tackle them through 3 case studies: 1)\nInteractive Machine Learning (IML): we show how IML can drastically improve\nexploration time and quality of direct volume rendering. 2) transfer learning:\nwe show how transfer learning along with intelligent pre-processing can result\nin better Alzheimer's diagnosis using a much smaller training set 3) data\nimbalance: we show how our novel focal Tversky loss function can provide better\nsegmentation results taking into account the imbalanced nature of segmentation\ndatasets. The case studies are accompanied by in-depth analytical discussion of\nresults with possible future directions.", "published": "2019-02-13T21:23:07Z", "version": 1}, {"aid": "1902.05978", "authors": ["Baris Gecer", "Stylianos Ploumpis", "Irene Kotsia", "Stefanos Zafeiriou"], "title": "GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction", "url": "http://arxiv.org/pdf/1902.05978v2", "summary": "In the past few years, a lot of work has been done towards reconstructing the\n3D facial structure from single images by capitalizing on the power of Deep\nConvolutional Neural Networks (DCNNs). In the most recent works, differentiable\nrenderers were employed in order to learn the relationship between the facial\nidentity features and the parameters of a 3D morphable model for shape and\ntexture. The texture features either correspond to components of a linear\ntexture space or are learned by auto-encoders directly from in-the-wild images.\nIn all cases, the quality of the facial texture reconstruction of the\nstate-of-the-art methods is still not capable of modeling textures in high\nfidelity. In this paper, we take a radically different approach and harness the\npower of Generative Adversarial Networks (GANs) and DCNNs in order to\nreconstruct the facial texture and shape from single images. That is, we\nutilize GANs to train a very powerful generator of facial texture in UV space.\nThen, we revisit the original 3D Morphable Models (3DMMs) fitting approaches\nmaking use of non-linear optimization to find the optimal latent parameters\nthat best reconstruct the test image but under a new perspective. We optimize\nthe parameters with the supervision of pretrained deep identity features\nthrough our end-to-end differentiable framework. We demonstrate excellent\nresults in photorealistic and identity preserving 3D face reconstructions and\nachieve for the first time, to the best of our knowledge, facial texture\nreconstruction with high-frequency details.", "published": "2019-02-15T19:53:45Z", "version": 2}, {"aid": "1902.11106", "authors": ["Serkan Kiranyaz", "Turker Ince", "Alexandros Iosifidis", "Moncef Gabbouj"], "title": "Operational Neural Networks", "url": "http://arxiv.org/pdf/1902.11106v2", "summary": "Feed-forward, fully-connected Artificial Neural Networks (ANNs) or the\nso-called Multi-Layer Perceptrons (MLPs) are well-known universal\napproximators. However, their learning performance varies significantly\ndepending on the function or the solution space that they attempt to\napproximate. This is mainly because of their homogenous configuration based\nsolely on the linear neuron model. Therefore, while they learn very well those\nproblems with a monotonous, relatively simple and linearly separable solution\nspace, they may entirely fail to do so when the solution space is highly\nnonlinear and complex. Sharing the same linear neuron model with two additional\nconstraints (local connections and weight sharing), this is also true for the\nconventional Convolutional Neural Networks (CNNs) and, it is, therefore, not\nsurprising that in many challenging problems only the deep CNNs with a massive\ncomplexity and depth can achieve the required diversity and the learning\nperformance. In order to address this drawback and also to accomplish a more\ngeneralized model over the convolutional neurons, this study proposes a novel\nnetwork model, called Operational Neural Networks (ONNs), which can be\nheterogeneous and encapsulate neurons with any set of operators to boost\ndiversity and to learn highly complex and multi-modal functions or spaces with\nminimal network complexity and training data. Finally, a novel training method\nis formulated to back-propagate the error through the operational layers of\nONNs. Experimental results over highly challenging problems demonstrate the\nsuperior learning capabilities of ONNs even with few neurons and hidden layers.", "published": "2019-02-15T20:13:51Z", "version": 2}, {"aid": "1902.06066", "authors": ["Varshaneya V", "Balasubramanian S", "Darshan Gera"], "title": "RES-SE-NET: Boosting Performance of Resnets by Enhancing Bridge-connections", "url": "http://arxiv.org/pdf/1902.06066v1", "summary": "One of the ways to train deep neural networks effectively is to use residual\nconnections. Residual connections can be classified as being either identity\nconnections or bridge-connections with a reshaping convolution. Empirical\nobservations on CIFAR-10 and CIFAR-100 datasets using a baseline Resnet model,\nwith bridge-connections removed, have shown a significant reduction in\naccuracy. This reduction is due to lack of contribution, in the form of feature\nmaps, by the bridge-connections. Hence bridge-connections are vital for Resnet.\nHowever, all feature maps in the bridge-connections are considered to be\nequally important. In this work, an upgraded architecture \"Res-SE-Net\" is\nproposed to further strengthen the contribution from the bridge-connections by\nquantifying the importance of each feature map and weighting them accordingly\nusing Squeeze-and-Excitation (SE) block. It is demonstrated that Res-SE-Net\ngeneralizes much better than Resnet and SE-Resnet on the benchmark CIFAR-10 and\nCIFAR-100 datasets.", "published": "2019-02-16T08:25:16Z", "version": 1}, {"aid": "1902.06068", "authors": ["Zhihao Wang", "Jian Chen", "Steven C. H. Hoi"], "title": "Deep Learning for Image Super-resolution: A Survey", "url": "http://arxiv.org/pdf/1902.06068v2", "summary": "Image Super-Resolution (SR) is an important class of image processing\ntechniques to enhance the resolution of images and videos in computer vision.\nRecent years have witnessed remarkable progress of image super-resolution using\ndeep learning techniques. This article aims to provide a comprehensive survey\non recent advances of image super-resolution using deep learning approaches. In\ngeneral, we can roughly group the existing studies of SR techniques into three\nmajor categories: supervised SR, unsupervised SR, and domain-specific SR. In\naddition, we also cover some other important issues, such as publicly available\nbenchmark datasets and performance evaluation metrics. Finally, we conclude\nthis survey by highlighting several future directions and open issues which\nshould be further addressed by the community in the future.", "published": "2019-02-16T08:39:36Z", "version": 2}, {"aid": "1902.06292", "authors": ["Sercan O. Arik", "Tomas Pfister"], "title": "ProtoAttend: Attention-Based Prototypical Learning", "url": "http://arxiv.org/pdf/1902.06292v4", "summary": "We propose a novel inherently interpretable machine learning method that\nbases decisions on few relevant examples that we call prototypes. Our method,\nProtoAttend, can be integrated into a wide range of neural network\narchitectures including pre-trained models. It utilizes an attention mechanism\nthat relates the encoded representations to samples in order to determine\nprototypes. The resulting model outperforms state of the art in three high\nimpact problems without sacrificing accuracy of the original model: (1) it\nenables high-quality interpretability that outputs samples most relevant to the\ndecision-making (i.e. a sample-based interpretability method); (2) it achieves\nstate of the art confidence estimation by quantifying the mismatch across\nprototype labels; and (3) it obtains state of the art in distribution mismatch\ndetection. All this can be achieved with minimal additional test time and a\npractically viable training time computational cost.", "published": "2019-02-17T17:12:07Z", "version": 4}, {"aid": "1902.06853", "authors": ["Soufiane Hayou", "Arnaud Doucet", "Judith Rousseau"], "title": "On the Impact of the Activation Function on Deep Neural Networks Training", "url": "http://arxiv.org/pdf/1902.06853v2", "summary": "The weight initialization and the activation function of deep neural networks\nhave a crucial impact on the performance of the training procedure. An\ninappropriate selection can lead to the loss of information of the input during\nforward propagation and the exponential vanishing/exploding of gradients during\nback-propagation. Understanding the theoretical properties of untrained random\nnetworks is key to identifying which deep networks may be trained successfully\nas recently demonstrated by Samuel et al (2017) who showed that for deep\nfeedforward neural networks only a specific choice of hyperparameters known as\nthe `Edge of Chaos' can lead to good performance. While the work by Samuel et\nal (2017) discuss trainability issues, we focus here on training acceleration\nand overall performance. We give a comprehensive theoretical analysis of the\nEdge of Chaos and show that we can indeed tune the initialization parameters\nand the activation function in order to accelerate the training and improve the\nperformance.", "published": "2019-02-19T00:50:19Z", "version": 2}, {"aid": "1902.07153", "authors": ["Felix Wu", "Tianyi Zhang", "Amauri Holanda de Souza Jr.", "Christopher Fifty", "Tao Yu", "Kilian Q. Weinberger"], "title": "Simplifying Graph Convolutional Networks", "url": "http://arxiv.org/pdf/1902.07153v2", "summary": "Graph Convolutional Networks (GCNs) and their variants have experienced\nsignificant attention and have become the de facto methods for learning graph\nrepresentations. GCNs derive inspiration primarily from recent deep learning\napproaches, and as a result, may inherit unnecessary complexity and redundant\ncomputation. In this paper, we reduce this excess complexity through\nsuccessively removing nonlinearities and collapsing weight matrices between\nconsecutive layers. We theoretically analyze the resulting linear model and\nshow that it corresponds to a fixed low-pass filter followed by a linear\nclassifier. Notably, our experimental evaluation demonstrates that these\nsimplifications do not negatively impact accuracy in many downstream\napplications. Moreover, the resulting model scales to larger datasets, is\nnaturally interpretable, and yields up to two orders of magnitude speedup over\nFastGCN.", "published": "2019-02-19T17:21:15Z", "version": 2}, {"aid": "1902.07474", "authors": ["Domen Tabernik", "Matej Kristan", "Ale\u0161 Leonardis"], "title": "Spatially-Adaptive Filter Units for Compact and Efficient Deep Neural Networks", "url": "http://arxiv.org/pdf/1902.07474v2", "summary": "Convolutional neural networks excel in a number of computer vision tasks. One\nof their most crucial architectural elements is the effective receptive field\nsize, that has to be manually set to accommodate a specific task. Standard\nsolutions involve large kernels, down/up-sampling and dilated convolutions.\nThese require testing a variety of dilation and down/up-sampling factors and\nresult in non-compact representations and excessive number of parameters. We\naddress this issue by proposing a new convolution filter composed of displaced\naggregation units (DAU). DAUs learn spatial displacements and adapt the\nreceptive field sizes of individual convolution filters to a given problem,\nthus eliminating the need for hand-crafted modifications. DAUs provide a\nseamless substitution of convolutional filters in existing state-of-the-art\narchitectures, which we demonstrate on AlexNet, ResNet50, ResNet101, DeepLab\nand SRN-DeblurNet. The benefits of this design are demonstrated on a variety of\ncomputer vision tasks and datasets, such as image classification (ILSVRC 2012),\nsemantic segmentation (PASCAL VOC 2011, Cityscape) and blind image de-blurring\n(GOPRO). Results show that DAUs efficiently allocate parameters resulting in up\nto four times more compact networks at similar or better performance.", "published": "2019-02-20T09:49:55Z", "version": 2}, {"aid": "1902.07476", "authors": ["Sercan T\u00fcrkmen", "Janne Heikkil\u00e4"], "title": "An efficient solution for semantic segmentation: ShuffleNet V2 with atrous separable convolutions", "url": "http://arxiv.org/pdf/1902.07476v2", "summary": "Assigning a label to each pixel in an image, namely semantic segmentation,\nhas been an important task in computer vision, and has applications in\nautonomous driving, robotic navigation, localization, and scene understanding.\nFully convolutional neural networks have proved to be a successful solution for\nthe task over the years but most of the work being done focuses primarily on\naccuracy. In this paper, we present a computationally efficient approach to\nsemantic segmentation, while achieving a high mean intersection over union\n(mIOU), 70.33% on Cityscapes challenge. The network proposed is capable of\nrunning real-time on mobile devices. In addition, we make our code and model\nweights publicly available.", "published": "2019-02-20T09:50:47Z", "version": 2}, {"aid": "1902.07656", "authors": ["Bartosz W\u00f3jcik", "\u0141ukasz Maziarka", "Jacek Tabor"], "title": "LOSSGRAD: automatic learning rate in gradient descent", "url": "http://arxiv.org/pdf/1902.07656v1", "summary": "In this paper, we propose a simple, fast and easy to implement algorithm\nLOSSGRAD (locally optimal step-size in gradient descent), which automatically\nmodifies the step-size in gradient descent during neural networks training.\nGiven a function $f$, a point $x$, and the gradient $\\nabla_x f$ of $f$, we aim\nto find the step-size $h$ which is (locally) optimal, i.e. satisfies: $$\nh=arg\\,min_{t \\geq 0} f(x-t \\nabla_x f). $$ Making use of quadratic\napproximation, we show that the algorithm satisfies the above assumption. We\nexperimentally show that our method is insensitive to the choice of initial\nlearning rate while achieving results comparable to other methods.", "published": "2019-02-20T17:11:17Z", "version": 1}, {"aid": "1902.08153", "authors": ["Steven K. Esser", "Jeffrey L. McKinstry", "Deepika Bablani", "Rathinakumar Appuswamy", "Dharmendra S. Modha"], "title": "Learned Step Size Quantization", "url": "http://arxiv.org/pdf/1902.08153v3", "summary": "Deep networks run with low precision operations at inference time offer power\nand space advantages over high precision alternatives, but need to overcome the\nchallenge of maintaining high accuracy as precision decreases. Here, we present\na method for training such networks, Learned Step Size Quantization, that\nachieves the highest accuracy to date on the ImageNet dataset when using\nmodels, from a variety of architectures, with weights and activations quantized\nto 2-, 3- or 4-bits of precision, and that can train 3-bit models that reach\nfull precision baseline accuracy. Our approach builds upon existing methods for\nlearning weights in quantized networks by improving how the quantizer itself is\nconfigured. Specifically, we introduce a novel means to estimate and scale the\ntask loss gradient at each weight and activation layer's quantizer step size,\nsuch that it can be learned in conjunction with other network parameters. This\napproach works using different levels of precision as needed for a given system\nand requires only a simple modification of existing training code.", "published": "2019-02-21T17:31:32Z", "version": 3}, {"aid": "1902.08994", "authors": ["S. M. Kamrul Hasan", "Cristian A. Linte"], "title": "U-NetPlus: A Modified Encoder-Decoder U-Net Architecture for Semantic and Instance Segmentation of Surgical Instrument", "url": "http://arxiv.org/pdf/1902.08994v1", "summary": "Conventional therapy approaches limit surgeons' dexterity control due to\nlimited field-of-view. With the advent of robot-assisted surgery, there has\nbeen a paradigm shift in medical technology for minimally invasive surgery.\nHowever, it is very challenging to track the position of the surgical\ninstruments in a surgical scene, and accurate detection & identification of\nsurgical tools is paramount. Deep learning-based semantic segmentation in\nframes of surgery videos has the potential to facilitate this task. In this\nwork, we modify the U-Net architecture named U-NetPlus, by introducing a\npre-trained encoder and re-design the decoder part, by replacing the transposed\nconvolution operation with an upsampling operation based on nearest-neighbor\n(NN) interpolation. To further improve performance, we also employ a very fast\nand flexible data augmentation technique. We trained the framework on 8 x 225\nframe sequences of robotic surgical videos, available through the MICCAI 2017\nEndoVis Challenge dataset and tested it on 8 x 75 frame and 2 x 300 frame\nvideos. Using our U-NetPlus architecture, we report a 90.20% DICE for binary\nsegmentation, 76.26% DICE for instrument part segmentation, and 46.07% for\ninstrument type (i.e., all instruments) segmentation, outperforming the results\nof previous techniques implemented and tested on these data.", "published": "2019-02-24T18:57:19Z", "version": 1}, {"aid": "1902.09782", "authors": ["Qingyan Duan", "Lei Zhang"], "title": "BoostGAN for Occlusive Profile Face Frontalization and Recognition", "url": "http://arxiv.org/pdf/1902.09782v1", "summary": "There are many facts affecting human face recognition, such as pose,\nocclusion, illumination, age, etc. First and foremost are large pose and\nocclusion problems, which can even result in more than 10% performance\ndegradation. Pose-invariant feature representation and face frontalization with\ngenerative adversarial networks (GAN) have been widely used to solve the pose\nproblem. However, the synthesis and recognition of occlusive but profile faces\nis still an uninvestigated problem. To address this issue, in this paper, we\naim to contribute an effective solution on how to recognize occlusive but\nprofile faces, even with facial keypoint region (e.g. eyes, nose, etc.)\ncorrupted. Specifically, we propose a boosting Generative Adversarial Network\n(BoostGAN) for de-occlusion, frontalization, and recognition of faces. Upon the\nassumption that facial occlusion is partial and incomplete, multiple patch\noccluded images are fed as inputs for knowledge boosting, such as identity and\ntexture information. A new aggregation structure composed of a deep GAN for\ncoarse face synthesis and a shallow boosting net for fine face generation is\nfurther designed. Exhaustive experiments demonstrate that the proposed approach\nnot only presents clear perceptual photo-realistic results but also shows\nstate-of-the-art recognition performance for occlusive but profile faces.", "published": "2019-02-26T07:59:47Z", "version": 1}, {"aid": "1902.09992", "authors": ["Javier Garcia-Barcos", "Ruben Martinez-Cantin"], "title": "Fully Distributed Bayesian Optimization with Stochastic Policies", "url": "http://arxiv.org/pdf/1902.09992v2", "summary": "Bayesian optimization has become a popular method for high-throughput\ncomputing, like the design of computer experiments or hyperparameter tuning of\nexpensive models, where sample efficiency is mandatory. In these applications,\ndistributed and scalable architectures are a necessity. However, Bayesian\noptimization is mostly sequential. Even parallel variants require certain\ncomputations between samples, limiting the parallelization bandwidth. Thompson\nsampling has been previously applied for distributed Bayesian optimization.\nBut, when compared with other acquisition functions in the sequential setting,\nThompson sampling is known to perform suboptimally. In this paper, we present a\nnew method for fully distributed Bayesian optimization, which can be combined\nwith any acquisition function. Our approach considers Bayesian optimization as\na partially observable Markov decision process. In this context, stochastic\npolicies, such as the Boltzmann policy, have some interesting properties which\ncan also be studied for Bayesian optimization. Furthermore, the Boltzmann\npolicy trivially allows a distributed Bayesian optimization implementation with\nhigh level of parallelism and scalability. We present results in several\nbenchmarks and applications that shows the performance of our method.", "published": "2019-02-26T15:13:17Z", "version": 2}, {"aid": "1902.10658", "authors": ["Baihan Lin"], "title": "Regularity Normalization: Neuroscience-Inspired Unsupervised Attention across Neural Network Layers", "url": "http://arxiv.org/pdf/1902.10658v13", "summary": "Inspired by the adaptation phenomenon of neuronal firing, we propose the\nregularity normalization (RN) as an unsupervised attention mechanism (UAM)\nwhich computes the statistical regularity in the implicit space of neural\nnetworks under the Minimum Description Length (MDL) principle. Treating the\nneural network optimization process as a partially observable model selection\nproblem, the regularity normalization constrains the implicit space by a\nnormalization factor, the universal code length. We compute this universal code\nincrementally across neural network layers and demonstrate the flexibility to\ninclude data priors such as top-down attention and other oracle information.\nEmpirically, our approach outperforms existing normalization methods in\ntackling limited, imbalanced and non-stationary input distribution in image\nclassification, classic control, procedurally-generated reinforcement learning,\ngenerative modeling, handwriting generation and question answering tasks with\nvarious neural network architectures. Lastly, the unsupervised attention\nmechanisms is a useful probing tool for neural networks by tracking the\ndependency and critical learning stages across layers and recurrent time steps\nof deep networks.", "published": "2019-02-27T17:44:50Z", "version": 13}, {"aid": "1902.10747", "authors": ["Mikael Brudfors", "Ya\u00ebl Balbastre", "John Ashburner"], "title": "Nonlinear Markov Random Fields Learned via Backpropagation", "url": "http://arxiv.org/pdf/1902.10747v2", "summary": "Although convolutional neural networks (CNNs) currently dominate competitions\non image segmentation, for neuroimaging analysis tasks, more classical\ngenerative approaches based on mixture models are still used in practice to\nparcellate brains. To bridge the gap between the two, in this paper we propose\na marriage between a probabilistic generative model, which has been shown to be\nrobust to variability among magnetic resonance (MR) images acquired via\ndifferent imaging protocols, and a CNN. The link is in the prior distribution\nover the unknown tissue classes, which are classically modelled using a Markov\nrandom field. In this work we model the interactions among neighbouring pixels\nby a type of recurrent CNN, which can encode more complex spatial interactions.\nWe validate our proposed model on publicly available MR data, from different\ncentres, and show that it generalises across imaging protocols. This result\ndemonstrates a successful and principled inclusion of a CNN in a generative\nmodel, which in turn could be adapted by any probabilistic generative approach\nfor image segmentation.", "published": "2019-02-27T19:34:22Z", "version": 2}, {"aid": "1902.10949", "authors": ["Yingcheng Su", "Shunfeng Zhou", "Yichao Wu", "Tian Su", "Ding Liang", "Jiaheng Liu", "Dixin Zheng", "Yingxu Wang", "Junjie Yan", "Xiaolin Hu"], "title": "Dynamic Multi-path Neural Network", "url": "http://arxiv.org/pdf/1902.10949v3", "summary": "Although deeper and larger neural networks have achieved better performance,\nthe complex network structure and increasing computational cost cannot meet the\ndemands of many resource-constrained applications. Existing methods usually\nchoose to execute or skip an entire specific layer, which can only alter the\ndepth of the network. In this paper, we propose a novel method called Dynamic\nMulti-path Neural Network (DMNN), which provides more path selection choices in\nterms of network width and depth during inference. The inference path of the\nnetwork is determined by a controller, which takes into account both previous\nstate and object category information. The proposed method can be easily\nincorporated into most modern network architectures. Experimental results on\nImageNet and CIFAR-100 demonstrate the superiority of our method on both\nefficiency and overall classification accuracy. To be specific, DMNN-101\nsignificantly outperforms ResNet-101 with an encouraging 45.1% FLOPs reduction,\nand DMNN-50 performs comparably to ResNet-101 while saving 42.1% parameters.", "published": "2019-02-28T08:48:18Z", "version": 3}, {"aid": "1903.00840", "authors": ["Amir Zadeh", "Yao-Chong Lim", "Paul Pu Liang", "Louis-Philippe Morency"], "title": "Variational Auto-Decoder: A Method for Neural Generative Modeling from Incomplete Data", "url": "http://arxiv.org/pdf/1903.00840v6", "summary": "Learning a generative model from partial data (data with missingness) is a\nchallenging area of machine learning research. We study a specific\nimplementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named\nin this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework\nwhich uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to\nlearn a generative model from partial data. The main distinction between VAD\nand Variational Auto-Encoder (VAE) is the encoder component, as VAD does not\nhave one. Using a proposed efficient inference method from a multivariate\nGaussian approximate posterior, VAD models allow inference to be performed via\nsimple gradient ascent rather than MCMC sampling from a probabilistic decoder.\nThis technique reduces the inference computational cost, allows for using more\ncomplex optimization techniques during latent space inference (which are shown\nto be crucial due to a high degree of freedom in the VAD latent space), and\nkeeps the framework simple to implement. Through extensive experiments over\nseveral datasets and different missing ratios, we show that encoders cannot\nefficiently marginalize the input volatility caused by imputed missing values.\nWe study multimodal datasets in this paper, which is a particular area of\nimpact for VAD models.", "published": "2019-03-03T06:19:55Z", "version": 6}, {"aid": "1903.01003", "authors": ["Ismail Akrout", "Amal Feriani", "Mohamed Akrout"], "title": "Hacking Google reCAPTCHA v3 using Reinforcement Learning", "url": "http://arxiv.org/pdf/1903.01003v3", "summary": "We present a Reinforcement Learning (RL) methodology to bypass Google\nreCAPTCHA v3. We formulate the problem as a grid world where the agent learns\nhow to move the mouse and click on the reCAPTCHA button to receive a high\nscore. We study the performance of the agent when we vary the cell size of the\ngrid world and show that the performance drops when the agent takes big steps\ntoward the goal. Finally, we used a divide and conquer strategy to defeat the\nreCAPTCHA system for any grid resolution. Our proposed method achieves a\nsuccess rate of 97.4% on a 100x100 grid and 96.7% on a 1000x1000 screen\nresolution.", "published": "2019-03-03T22:10:47Z", "version": 3}, {"aid": "1903.01882", "authors": ["Reuben Feinman", "Brenden M. Lake"], "title": "Learning a smooth kernel regularizer for convolutional neural networks", "url": "http://arxiv.org/pdf/1903.01882v1", "summary": "Modern deep neural networks require a tremendous amount of data to train,\noften needing hundreds or thousands of labeled examples to learn an effective\nrepresentation. For these networks to work with less data, more structure must\nbe built into their architectures or learned from previous experience. The\nlearned weights of convolutional neural networks (CNNs) trained on large\ndatasets for object recognition contain a substantial amount of structure.\nThese representations have parallels to simple cells in the primary visual\ncortex, where receptive fields are smooth and contain many regularities.\nIncorporating smoothness constraints over the kernel weights of modern CNN\narchitectures is a promising way to improve their sample complexity. We propose\na smooth kernel regularizer that encourages spatial correlations in convolution\nkernel weights. The correlation parameters of this regularizer are learned from\nprevious experience, yielding a method with a hierarchical Bayesian\ninterpretation. We show that our correlated regularizer can help constrain\nmodels for visual recognition, improving over an L2 regularization baseline.", "published": "2019-03-05T15:07:29Z", "version": 1}, {"aid": "1903.01931", "authors": ["Jianlin Su"], "title": "O-GAN: Extremely Concise Approach for Auto-Encoding Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1903.01931v1", "summary": "In this paper, we propose Orthogonal Generative Adversarial Networks\n(O-GANs). We decompose the network of discriminator orthogonally and add an\nextra loss into the objective of common GANs, which can enforce discriminator\nbecome an effective encoder. The same extra loss can be embedded into any kind\nof GANs and there is almost no increase in computation. Furthermore, we discuss\nthe principle of our method, which is relative to the fully-exploiting of the\nremaining degrees of freedom of discriminator. As we know, our solution is the\nsimplest approach to train a generative adversarial network with auto-encoding\nability.", "published": "2019-03-05T17:01:49Z", "version": 1}, {"aid": "1903.04933", "authors": ["Jeffrey De Fauw", "Sander Dieleman", "Karen Simonyan"], "title": "Hierarchical Autoregressive Image Models with Auxiliary Decoders", "url": "http://arxiv.org/pdf/1903.04933v2", "summary": "Autoregressive generative models of images tend to be biased towards\ncapturing local structure, and as a result they often produce samples which are\nlacking in terms of large-scale coherence. To address this, we propose two\nmethods to learn discrete representations of images which abstract away local\ndetail. We show that autoregressive models conditioned on these representations\ncan produce high-fidelity reconstructions of images, and that we can train\nautoregressive priors on these representations that produce samples with\nlarge-scale coherence. We can recursively apply the learning procedure,\nyielding a hierarchy of progressively more abstract image representations. We\ntrain hierarchical class-conditional autoregressive models on the ImageNet\ndataset and demonstrate that they are able to generate realistic images at\nresolutions of 128$\\times$128 and 256$\\times$256 pixels. We also perform a\nhuman evaluation study comparing our models with both adversarial and\nlikelihood-based state-of-the-art generative models.", "published": "2019-03-06T22:13:52Z", "version": 2}, {"aid": "1903.04019", "authors": ["Xiaoguang Han", "Zhaoxuan Zhang", "Dong Du", "Mingdai Yang", "Jingming Yu", "Pan Pan", "Xin Yang", "Ligang Liu", "Zixiang Xiong", "Shuguang Cui"], "title": "Deep Reinforcement Learning of Volume-guided Progressive View Inpainting for 3D Point Scene Completion from a Single Depth Image", "url": "http://arxiv.org/pdf/1903.04019v2", "summary": "We present a deep reinforcement learning method of progressive view\ninpainting for 3D point scene completion under volume guidance, achieving\nhigh-quality scene reconstruction from only a single depth image with severe\nocclusion. Our approach is end-to-end, consisting of three modules: 3D scene\nvolume reconstruction, 2D depth map inpainting, and multi-view selection for\ncompletion. Given a single depth image, our method first goes through the 3D\nvolume branch to obtain a volumetric scene reconstruction as a guide to the\nnext view inpainting step, which attempts to make up the missing information;\nthe third step involves projecting the volume under the same view of the input,\nconcatenating them to complete the current view depth, and integrating all\ndepth into the point cloud. Since the occluded areas are unavailable, we resort\nto a deep Q-Network to glance around and pick the next best view for large hole\ncompletion progressively until a scene is adequately reconstructed while\nguaranteeing validity. All steps are learned jointly to achieve robust and\nconsistent results. We perform qualitative and quantitative evaluations with\nextensive experiments on the SUNCG data, obtaining better results than the\nstate of the art.", "published": "2019-03-10T16:25:03Z", "version": 2}, {"aid": "1903.04576", "authors": ["Javier A. Galad\u00ed", "Joaqu\u00edn J. Torres", "J. Marro"], "title": "Emergence of Brain Rhythms: Model Interpretation of EEG Data", "url": "http://arxiv.org/pdf/1903.04576v1", "summary": "Electroencephalography (EEG) monitors ---by either intrusive or noninvasive\nelectrodes--- time and frequency variations and spectral content of voltage\nfluctuations or waves, known as brain rhythms, which in some way uncover\nactivity during both rest periods and specific events in which the subject is\nunder stimulus. This is a useful tool to explore brain behavior, as it\ncomplements imaging techniques that have a poorer temporal resolution. We here\napproach the understanding of EEG data from first principles by studying a\nnetworked model of excitatory and inhibitory neurons which generates a variety\nof comparable waves. In fact, we thus reproduce $\\alpha$, $\\beta,$ $\\gamma$ and\nother rhythms as observed by EEG, and identify the details of the respectively\ninvolved complex phenomena, including a precise relationship between an input\nand the collective response to it. It ensues the potentiality of our model to\nbetter understand actual mind mechanisms and its possible disorders, and we\nalso describe kind of stochastic resonance phenomena which locate main\nqualitative changes of mental behavior in (e.g.) humans. We also discuss the\nplausible use of these findings to design deep learning algorithms to detect\nthe occurence of phase transitions in the brain and to analyse its\nconsequences.", "published": "2019-03-11T20:13:42Z", "version": 1}, {"aid": "1903.04687", "authors": ["Lei Zhang", "Xinbo Gao"], "title": "Transfer Adaptation Learning: A Decade Survey", "url": "http://arxiv.org/pdf/1903.04687v2", "summary": "The world we see is ever-changing and it always changes with people, things,\nand the environment. Domain is referred to as the state of the world at a\ncertain moment. A research problem is characterized as transfer adaptation\nlearning (TAL) when it needs knowledge correspondence between different\nmoments/domains. Conventional machine learning aims to find a model with the\nminimum expected risk on test data by minimizing the regularized empirical risk\non the training data, which, however, supposes that the training and test data\nshare similar joint probability distribution. TAL aims to build models that can\nperform tasks of target domain by learning knowledge from a semantic related\nbut distribution different source domain. It is an energetic research filed of\nincreasing influence and importance, which is presenting a blowout publication\ntrend. This paper surveys the advances of TAL methodologies in the past decade,\nand the technical challenges and essential problems of TAL have been observed\nand discussed with deep insights and new perspectives. Broader solutions of\ntransfer adaptation learning being created by researchers are identified, i.e.,\ninstance re-weighting adaptation, feature adaptation, classifier adaptation,\ndeep network adaptation and adversarial adaptation, which are beyond the early\nsemi-supervised and unsupervised split. The survey helps researchers rapidly\nbut comprehensively understand and identify the research foundation, research\nstatus, theoretical limitations, future challenges and under-studied issues\n(universality, interpretability, and credibility) to be broken in the field\ntoward universal representation and safe applications in open-world scenarios.", "published": "2019-03-12T01:32:59Z", "version": 2}, {"aid": "1903.04711", "authors": ["Wentao Zhu"], "title": "Deep Learning for Automated Medical Image Analysis", "url": "http://arxiv.org/pdf/1903.04711v1", "summary": "Medical imaging is an essential tool in many areas of medical applications,\nused for both diagnosis and treatment. However, reading medical images and\nmaking diagnosis or treatment recommendations require specially trained medical\nspecialists. The current practice of reading medical images is labor-intensive,\ntime-consuming, costly, and error-prone. It would be more desirable to have a\ncomputer-aided system that can automatically make diagnosis and treatment\nrecommendations. Recent advances in deep learning enable us to rethink the ways\nof clinician diagnosis based on medical images. In this thesis, we will\nintroduce 1) mammograms for detecting breast cancers, the most frequently\ndiagnosed solid cancer for U.S. women, 2) lung CT images for detecting lung\ncancers, the most frequently diagnosed malignant cancer, and 3) head and neck\nCT images for automated delineation of organs at risk in radiotherapy. First,\nwe will show how to employ the adversarial concept to generate the hard\nexamples improving mammogram mass segmentation. Second, we will demonstrate how\nto use the weakly labeled data for the mammogram breast cancer diagnosis by\nefficiently design deep learning for multi-instance learning. Third, the thesis\nwill walk through DeepLung system which combines deep 3D ConvNets and GBM for\nautomated lung nodule detection and classification. Fourth, we will show how to\nuse weakly labeled data to improve existing lung nodule detection system by\nintegrating deep learning with a probabilistic graphic model. Lastly, we will\ndemonstrate the AnatomyNet which is thousands of times faster and more accurate\nthan previous methods on automated anatomy segmentation.", "published": "2019-03-12T03:28:37Z", "version": 1}, {"aid": "1903.04772", "authors": ["Arash Akbarinia", "Karl R. Gegenfurtner"], "title": "Paradox in Deep Neural Networks: Similar yet Different while Different yet Similar", "url": "http://arxiv.org/pdf/1903.04772v1", "summary": "Machine learning is advancing towards a data-science approach, implying a\nnecessity to a line of investigation to divulge the knowledge learnt by deep\nneuronal networks. Limiting the comparison among networks merely to a\npredefined intelligent ability, according to ground truth, does not suffice, it\nshould be associated with innate similarity of these artificial entities. Here,\nwe analysed multiple instances of an identical architecture trained to classify\nobjects in static images (CIFAR and ImageNet data sets). We evaluated the\nperformance of the networks under various distortions and compared it to the\nintrinsic similarity between their constituent kernels. While we expected a\nclose correspondence between these two measures, we observed a puzzling\nphenomenon. Pairs of networks whose kernels' weights are over 99.9% correlated\ncan exhibit significantly different performances, yet other pairs with no\ncorrelation can reach quite compatible levels of performance. We show\nimplications of this for transfer learning, and argue its importance in our\ngeneral understanding of what intelligence is, whether natural or artificial.", "published": "2019-03-12T08:04:44Z", "version": 1}, {"aid": "1903.06530", "authors": ["Seijoon Kim", "Seongsik Park", "Byunggook Na", "Sungroh Yoon"], "title": "Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection", "url": "http://arxiv.org/pdf/1903.06530v2", "summary": "Over the past decade, deep neural networks (DNNs) have demonstrated\nremarkable performance in a variety of applications. As we try to solve more\nadvanced problems, increasing demands for computing and power resources has\nbecome inevitable. Spiking neural networks (SNNs) have attracted widespread\ninterest as the third-generation of neural networks due to their event-driven\nand low-powered nature. SNNs, however, are difficult to train, mainly owing to\ntheir complex dynamics of neurons and non-differentiable spike operations.\nFurthermore, their applications have been limited to relatively simple tasks\nsuch as image classification. In this study, we investigate the performance\ndegradation of SNNs in a more challenging regression problem (i.e., object\ndetection). Through our in-depth analysis, we introduce two novel methods:\nchannel-wise normalization and signed neuron with imbalanced threshold, both of\nwhich provide fast and accurate information transmission for deep SNNs.\nConsequently, we present a first spiked-based object detection model, called\nSpiking-YOLO. Our experiments show that Spiking-YOLO achieves remarkable\nresults that are comparable (up to 98%) to those of Tiny YOLO on non-trivial\ndatasets, PASCAL VOC and MS COCO. Furthermore, Spiking-YOLO on a neuromorphic\nchip consumes approximately 280 times less energy than Tiny YOLO and converges\n2.3 to 4 times faster than previous SNN conversion methods.", "published": "2019-03-12T08:34:47Z", "version": 2}, {"aid": "1903.05285", "authors": ["Weijie Chen", "Di Xie", "Yuan Zhang", "Shiliang Pu"], "title": "All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification", "url": "http://arxiv.org/pdf/1903.05285v1", "summary": "Shift operation is an efficient alternative over depthwise separable\nconvolution. However, it is still bottlenecked by its implementation manner,\nnamely memory movement. To put this direction forward, a new and novel basic\ncomponent named Sparse Shift Layer (SSL) is introduced in this paper to\nconstruct efficient convolutional neural networks. In this family of\narchitectures, the basic block is only composed by 1x1 convolutional layers\nwith only a few shift operations applied to the intermediate feature maps. To\nmake this idea feasible, we introduce shift operation penalty during\noptimization and further propose a quantization-aware shift learning method to\nimpose the learned displacement more friendly for inference. Extensive ablation\nstudies indicate that only a few shift operations are sufficient to provide\nspatial information communication. Furthermore, to maximize the role of SSL, we\nredesign an improved network architecture to Fully Exploit the limited capacity\nof neural Network (FE-Net). Equipped with SSL, this network can achieve 75.0%\ntop-1 accuracy on ImageNet with only 563M M-Adds. It surpasses other\ncounterparts constructed by depthwise separable convolution and the networks\nsearched by NAS in terms of accuracy and practical speed.", "published": "2019-03-13T01:44:39Z", "version": 1}, {"aid": "1903.05359", "authors": ["Jun Long", "WuQing Sun", "Zhan Yang", "Osolo Ian Raymond"], "title": "Asymmetric Residual Neural Network for Accurate Human Activity Recognition", "url": "http://arxiv.org/pdf/1903.05359v3", "summary": "Human Activity Recognition (HAR) using deep neural network has become a hot\ntopic in human-computer interaction. Machine can effectively identify human\nnaturalistic activities by learning from a large collection of sensor data.\nActivity recognition is not only an interesting research problem, but also has\nmany real-world practical applications. Based on the success of residual\nnetworks in achieving a high level of aesthetic representation of the automatic\nlearning, we propose a novel \\textbf{A}symmetric \\textbf{R}esidual\n\\textbf{N}etwork, named ARN. ARN is implemented using two identical path\nframeworks consisting of (1) a short time window, which is used to capture\nspatial features, and (2) a long time window, which is used to capture fine\ntemporal features. The long time window path can be made very lightweight by\nreducing its channel capacity, yet still being able to learn useful temporal\nrepresentations for activity recognition. In this paper, we mainly focus on\nproposing a new model to improve the accuracy of HAR. In order to demonstrate\nthe effectiveness of ARN model, we carried out extensive experiments on\nbenchmark datasets (i.e., OPPORTUNITY, UniMiB-SHAR) and compared with some\nconventional and state-of-the-art learning-based methods. Then, we discuss the\ninfluence of networks parameters on performance to provide insights about its\noptimization. Results from our experiments show that ARN is effective in\nrecognizing human activities via wearable datasets.", "published": "2019-03-13T08:44:01Z", "version": 3}, {"aid": "1903.05503", "authors": ["Wenzhao Zheng", "Zhaodong Chen", "Jiwen Lu", "Jie Zhou"], "title": "Hardness-Aware Deep Metric Learning", "url": "http://arxiv.org/pdf/1903.05503v2", "summary": "This paper presents a hardness-aware deep metric learning (HDML) framework.\nMost previous deep metric learning methods employ the hard negative mining\nstrategy to alleviate the lack of informative samples for training. However,\nthis mining strategy only utilizes a subset of training data, which may not be\nenough to characterize the global geometry of the embedding space\ncomprehensively. To address this problem, we perform linear interpolation on\nembeddings to adaptively manipulate their hard levels and generate\ncorresponding label-preserving synthetics for recycled training, so that\ninformation buried in all samples can be fully exploited and the metric is\nalways challenged with proper difficulty. Our method achieves very competitive\nperformance on the widely used CUB-200-2011, Cars196, and Stanford Online\nProducts datasets.", "published": "2019-03-13T14:14:54Z", "version": 2}, {"aid": "1903.05610", "authors": ["Paul Smolen", "Douglas A. Baxter", "John H. Byrne"], "title": "How Can Memories Last for Days, Years, or a Lifetime? Proposed Mechanisms for Maintaining Synaptic Potentiation and Memory", "url": "http://arxiv.org/pdf/1903.05610v3", "summary": "With memory encoding reliant on persistent changes in the properties of\nsynapses, a key question is how can memories be maintained from days to months\nor a lifetime given molecular turnover? It is likely that positive feedback\nloops are necessary to persistently maintain the strength of synapses that\nparticipate in encoding. Such feedback may occur within signal-transduction\ncascades and/or the regulation of translation, and it may occur within specific\nsubcellular compartments or within neuronal networks. Not surprisingly,\nnumerous positive feedback loops have been proposed. Some posited loops operate\nat the level of biochemical signal transduction cascades, such as persistent\nactivation of calcium/calmodulin kinase II or protein kinase M. Another level\nconsists of feedback loops involving transcriptional, epigenetic and\ntranslational pathways, and autocrine actions of growth factors such as BDNF.\nFinally, at the neuronal network level, recurrent reactivation of cell\nassemblies encoding memories is likely to be essential for late maintenance of\nmemory. These levels are not isolated, but linked by shared components of\nfeedback loops. Here, we review characteristics of some commonly discussed\nfeedback loops proposed to underlie the maintenance of memory and long-term\nsynaptic plasticity, assess evidence for and against their necessity, and\nsuggest experiments that could further delineate the dynamics of these feedback\nloops. We also discuss crosstalk between proposed loops, and ways in which such\ninteraction can facilitate the rapidity and robustness of memory formation and\nstorage.", "published": "2019-03-13T17:16:52Z", "version": 3}, {"aid": "1903.08066", "authors": ["Sambhav R. Jain", "Albert Gural", "Michael Wu", "Chris H. Dick"], "title": "Trained Quantization Thresholds for Accurate and Efficient Fixed-Point Inference of Deep Neural Networks", "url": "http://arxiv.org/pdf/1903.08066v3", "summary": "We propose a method of training quantization thresholds (TQT) for uniform\nsymmetric quantizers using standard backpropagation and gradient descent.\nContrary to prior work, we show that a careful analysis of the straight-through\nestimator for threshold gradients allows for a natural range-precision\ntrade-off leading to better optima. Our quantizers are constrained to use\npower-of-2 scale-factors and per-tensor scaling of weights and activations to\nmake it amenable for hardware implementations. We present analytical support\nfor the general robustness of our methods and empirically validate them on\nvarious CNNs for ImageNet classification. We are able to achieve\nnear-floating-point accuracy on traditionally difficult networks such as\nMobileNets with less than 5 epochs of quantized (8-bit) retraining. Finally, we\npresent Graffitist, a framework that enables automatic quantization of\nTensorFlow graphs for TQT (available at https://github.com/Xilinx/graffitist ).", "published": "2019-03-19T15:50:24Z", "version": 3}, {"aid": "1903.09630", "authors": ["Francesca Arese Lucini", "Gino Del Ferraro", "Mariano Sigman", "Hernan A. Makse"], "title": "How the Brain Transitions from Conscious to Subliminal Perception", "url": "http://arxiv.org/pdf/1903.09630v3", "summary": "We study the transition in the functional networks that characterize the\nhuman brains' conscious-state to an unconscious subliminal state of perception\nby using k-core percolation. We find that the most inner core (i.e., the most\nconnected kernel) of the conscious-state functional network corresponds to\nareas which remain functionally active when the brain transitions from the\nconscious-state to the subliminal-state. That is, the inner core of the\nconscious network coincides with the subliminal-state. Mathematical modeling\nallows to interpret the conscious to subliminal transition as driven by k-core\npercolation, through which the conscious state is lost by the inactivation of\nthe peripheral k-shells of the conscious functional network. Thus, the inner\ncore and most robust component of the conscious brain corresponds to the\nunconscious subliminal state. This finding imposes constraints to theoretical\nmodels of consciousness, in that the location of the core of the functional\nbrain network is in the unconscious part of the brain rather than in the\nconscious state as previously thought.", "published": "2019-03-21T01:09:05Z", "version": 3}, {"aid": "1903.11683", "authors": ["Vasileios Tzoumas", "Pasquale Antonante", "Luca Carlone"], "title": "Outlier-Robust Spatial Perception: Hardness, General-Purpose Algorithms, and Guarantees", "url": "http://arxiv.org/pdf/1903.11683v2", "summary": "Spatial perception is the backbone of many robotics applications, and spans a\nbroad range of research problems, including localization and mapping, point\ncloud alignment, and relative pose estimation from camera images. Robust\nspatial perception is jeopardized by the presence of incorrect data\nassociation, and in general, outliers. Although techniques to handle outliers\ndo exist, they can fail in unpredictable manners (e.g., RANSAC, robust\nestimators), or can have exponential runtime (e.g., branch-and-bound). In this\npaper, we advance the state of the art in outlier rejection by making three\ncontributions. First, we show that even a simple linear instance of outlier\nrejection is inapproximable: in the worst-case one cannot design a\nquasi-polynomial time algorithm that computes an approximate solution\nefficiently. Our second contribution is to provide the first per-instance\nsub-optimality bounds to assess the approximation quality of a given outlier\nrejection outcome. Our third contribution is to propose a simple\ngeneral-purpose algorithm, named adaptive trimming, to remove outliers. Our\nalgorithm leverages recently-proposed global solvers that are able to solve\noutlier-free problems, and iteratively removes measurements with large errors.\nWe demonstrate the proposed algorithm on three spatial perception problems: 3D\nregistration, two-view geometry, and SLAM. The results show that our algorithm\noutperforms several state-of-the-art methods across applications while being a\ngeneral-purpose method.", "published": "2019-03-27T20:12:37Z", "version": 2}, {"aid": "1903.11816", "authors": ["Huikai Wu", "Junge Zhang", "Kaiqi Huang", "Kongming Liang", "Yizhou Yu"], "title": "FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation", "url": "http://arxiv.org/pdf/1903.11816v1", "summary": "Modern approaches for semantic segmentation usually employ dilated\nconvolutions in the backbone to extract high-resolution feature maps, which\nbrings heavy computation complexity and memory footprint. To replace the time\nand memory consuming dilated convolutions, we propose a novel joint upsampling\nmodule named Joint Pyramid Upsampling (JPU) by formulating the task of\nextracting high-resolution feature maps into a joint upsampling problem. With\nthe proposed JPU, our method reduces the computation complexity by more than\nthree times without performance loss. Experiments show that JPU is superior to\nother upsampling modules, which can be plugged into many existing approaches to\nreduce computation complexity and improve performance. By replacing dilated\nconvolutions with the proposed JPU module, our method achieves the\nstate-of-the-art performance in Pascal Context dataset (mIoU of 53.13%) and\nADE20K dataset (final score of 0.5584) while running 3 times faster.", "published": "2019-03-28T07:49:36Z", "version": 1}, {"aid": "1903.12152", "authors": ["Yuankai Huo", "Zhoubing Xu", "Yunxi Xiong", "Katherine Aboud", "Prasanna Parvathaneni", "Shunxing Bao", "Camilo Bermudez", "Susan M. Resnick", "Laurie E. Cutting", "Bennett A. Landman"], "title": "3D Whole Brain Segmentation using Spatially Localized Atlas Network Tiles", "url": "http://arxiv.org/pdf/1903.12152v1", "summary": "Detailed whole brain segmentation is an essential quantitative technique,\nwhich provides a non-invasive way of measuring brain regions from a structural\nmagnetic resonance imaging (MRI). Recently, deep convolution neural network\n(CNN) has been applied to whole brain segmentation. However, restricted by\ncurrent GPU memory, 2D based methods, downsampling based 3D CNN methods, and\npatch-based high-resolution 3D CNN methods have been the de facto standard\nsolutions. 3D patch-based high resolution methods typically yield superior\nperformance among CNN approaches on detailed whole brain segmentation (>100\nlabels), however, whose performance are still commonly inferior compared with\nmulti-atlas segmentation methods (MAS) due to the following challenges: (1) a\nsingle network is typically used to learn both spatial and contextual\ninformation for the patches, (2) limited manually traced whole brain volumes\nare available (typically less than 50) for training a network. In this work, we\npropose the spatially localized atlas network tiles (SLANT) method to\ndistribute multiple independent 3D fully convolutional networks (FCN) for\nhigh-resolution whole brain segmentation. To address the first challenge,\nmultiple spatially distributed networks were used in the SLANT method, in which\neach network learned contextual information for a fixed spatial location. To\naddress the second challenge, auxiliary labels on 5111 initially unlabeled\nscans were created by multi-atlas segmentation for training. Since the method\nintegrated multiple traditional medical image processing methods with deep\nlearning, we developed a containerized pipeline to deploy the end-to-end\nsolution. From the results, the proposed method achieved superior performance\ncompared with multi-atlas segmentation methods, while reducing the\ncomputational time from >30 hours to 15 minutes\n(https://github.com/MASILab/SLANTbrainSeg).", "published": "2019-03-28T17:40:32Z", "version": 1}, {"aid": "1904.00277", "authors": ["Fei Wang", "Stanislav Panev", "Ziyi Dai", "Jinsong Han", "Dong Huang"], "title": "Can WiFi Estimate Person Pose?", "url": "http://arxiv.org/pdf/1904.00277v2", "summary": "WiFi human sensing has achieved great progress in indoor localization,\nactivity classification, etc. Retracing the development of these work, we have\na natural question: can WiFi devices work like cameras for vision applications?\nIn this paper We try to answer this question by exploring the ability of WiFi\non estimating single person pose. We use a 3-antenna WiFi sender and a\n3-antenna receiver to generate WiFi data. Meanwhile, we use a synchronized\ncamera to capture person videos for corresponding keypoint annotations. We\nfurther propose a fully convolutional network (FCN), termed WiSPPN, to estimate\nsingle person pose from the collected data and annotations. Evaluation on over\n80k images (16 sites and 8 persons) replies aforesaid question with a positive\nanswer. Codes have been made publicly available at\nhttps://github.com/geekfeiw/WiSPPN.", "published": "2019-03-30T19:50:52Z", "version": 2}, {"aid": "1904.00962", "authors": ["Yang You", "Jing Li", "Sashank Reddi", "Jonathan Hseu", "Sanjiv Kumar", "Srinadh Bhojanapalli", "Xiaodan Song", "James Demmel", "Kurt Keutzer", "Cho-Jui Hsieh"], "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes", "url": "http://arxiv.org/pdf/1904.00962v5", "summary": "Training large deep neural networks on massive datasets is computationally\nvery challenging. There has been recent surge in interest in using large batch\nstochastic optimization methods to tackle this issue. The most prominent\nalgorithm in this line of research is LARS, which by employing layerwise\nadaptive learning rates trains ResNet on ImageNet in a few minutes. However,\nLARS performs poorly for attention models like BERT, indicating that its\nperformance gains are not consistent across tasks. In this paper, we first\nstudy a principled layerwise adaptation strategy to accelerate training of deep\nneural networks using large mini-batches. Using this strategy, we develop a new\nlayerwise adaptive large batch optimization technique called LAMB; we then\nprovide convergence analysis of LAMB as well as LARS, showing convergence to a\nstationary point in general nonconvex settings. Our empirical results\ndemonstrate the superior performance of LAMB across various tasks such as BERT\nand ResNet-50 training with very little hyperparameter tuning. In particular,\nfor BERT training, our optimizer enables use of very large batch sizes of 32868\nwithout any degradation of performance. By increasing the batch size to the\nmemory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to\njust 76 minutes (Table 1). The LAMB implementation is available at\nhttps://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py", "published": "2019-04-01T16:53:35Z", "version": 5}, {"aid": "1904.01169", "authors": ["Shang-Hua Gao", "Ming-Ming Cheng", "Kai Zhao", "Xin-Yu Zhang", "Ming-Hsuan Yang", "Philip Torr"], "title": "Res2Net: A New Multi-scale Backbone Architecture", "url": "http://arxiv.org/pdf/1904.01169v3", "summary": "Representing features at multiple scales is of great importance for numerous\nvision tasks. Recent advances in backbone convolutional neural networks (CNNs)\ncontinually demonstrate stronger multi-scale representation ability, leading to\nconsistent performance gains on a wide range of applications. However, most\nexisting methods represent the multi-scale features in a layer-wise manner. In\nthis paper, we propose a novel building block for CNNs, namely Res2Net, by\nconstructing hierarchical residual-like connections within one single residual\nblock. The Res2Net represents multi-scale features at a granular level and\nincreases the range of receptive fields for each network layer. The proposed\nRes2Net block can be plugged into the state-of-the-art backbone CNN models,\ne.g., ResNet, ResNeXt, and DLA. We evaluate the Res2Net block on all these\nmodels and demonstrate consistent performance gains over baseline models on\nwidely-used datasets, e.g., CIFAR-100 and ImageNet. Further ablation studies\nand experimental results on representative computer vision tasks, i.e., object\ndetection, class activation mapping, and salient object detection, further\nverify the superiority of the Res2Net over the state-of-the-art baseline\nmethods. The source code and trained models are available on\nhttps://mmcheng.net/res2net/.", "published": "2019-04-02T01:56:34Z", "version": 3}, {"aid": "1904.01186", "authors": ["Hanting Chen", "Yunhe Wang", "Chang Xu", "Zhaohui Yang", "Chuanjian Liu", "Boxin Shi", "Chunjing Xu", "Chao Xu", "Qi Tian"], "title": "Data-Free Learning of Student Networks", "url": "http://arxiv.org/pdf/1904.01186v4", "summary": "Learning portable neural networks is very essential for computer vision for\nthe purpose that pre-trained heavy deep models can be well applied on edge\ndevices such as mobile phones and micro sensors. Most existing deep neural\nnetwork compression and speed-up methods are very effective for training\ncompact deep models, when we can directly access the training dataset. However,\ntraining data for the given deep network are often unavailable due to some\npractice problems (e.g. privacy, legal issue, and transmission), and the\narchitecture of the given network are also unknown except some interfaces. To\nthis end, we propose a novel framework for training efficient deep neural\nnetworks by exploiting generative adversarial networks (GANs). To be specific,\nthe pre-trained teacher networks are regarded as a fixed discriminator and the\ngenerator is utilized for derivating training samples which can obtain the\nmaximum response on the discriminator. Then, an efficient network with smaller\nmodel size and computational complexity is trained using the generated data and\nthe teacher network, simultaneously. Efficient student networks learned using\nthe proposed Data-Free Learning (DAFL) method achieve 92.22% and 74.47%\naccuracies using ResNet-18 without any training data on the CIFAR-10 and\nCIFAR-100 datasets, respectively. Meanwhile, our student network obtains an\n80.56% accuracy on the CelebA benchmark.", "published": "2019-04-02T03:00:06Z", "version": 4}, {"aid": "1904.01277", "authors": ["Sa\u00efd Ladjal", "Alasdair Newson", "Chi-Hieu Pham"], "title": "A PCA-like Autoencoder", "url": "http://arxiv.org/pdf/1904.01277v1", "summary": "An autoencoder is a neural network which data projects to and from a lower\ndimensional latent space, where this data is easier to understand and model.\nThe autoencoder consists of two sub-networks, the encoder and the decoder,\nwhich carry out these transformations. The neural network is trained such that\nthe output is as close to the input as possible, the data having gone through\nan information bottleneck : the latent space. This tool bears significant\nressemblance to Principal Component Analysis (PCA), with two main differences.\nFirstly, the autoencoder is a non-linear transformation, contrary to PCA, which\nmakes the autoencoder more flexible and powerful. Secondly, the axes found by a\nPCA are orthogonal, and are ordered in terms of the amount of variability which\nthe data presents along these axes. This makes the interpretability of the PCA\nmuch greater than that of the autoencoder, which does not have these\nattributes. Ideally, then, we would like an autoencoder whose latent space\nconsists of independent components, ordered by decreasing importance to the\ndata. In this paper, we propose an algorithm to create such a network. We\ncreate an iterative algorithm which progressively increases the size of the\nlatent space, learning a new dimension at each step. Secondly, we propose a\ncovariance loss term to add to the standard autoencoder loss function, as well\nas a normalisation layer just before the latent space, which encourages the\nlatent space components to be statistically independent. We demonstrate the\nresults of this autoencoder on simple geometric shapes, and find that the\nalgorithm indeed finds a meaningful representation in the latent space. This\nmeans that subsequent interpolation in the latent space has meaning with\nrespect to the geometric properties of the images.", "published": "2019-04-02T08:27:52Z", "version": 1}, {"aid": "1904.01318", "authors": ["Christian Rupprecht", "Cyril Ibrahim", "Christopher J. Pal"], "title": "Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents", "url": "http://arxiv.org/pdf/1904.01318v1", "summary": "As deep reinforcement learning driven by visual perception becomes more\nwidely used there is a growing need to better understand and probe the learned\nagents. Understanding the decision making process and its relationship to\nvisual inputs can be very valuable to identify problems in learned behavior.\nHowever, this topic has been relatively under-explored in the research\ncommunity. In this work we present a method for synthesizing visual inputs of\ninterest for a trained agent. Such inputs or states could be situations in\nwhich specific actions are necessary. Further, critical states in which a very\nhigh or a very low reward can be achieved are often interesting to understand\nthe situational awareness of the system as they can correspond to risky states.\nTo this end, we learn a generative model over the state space of the\nenvironment and use its latent space to optimize a target function for the\nstate of interest. In our experiments we show that this method can generate\ninsights for a variety of environments and reinforcement learning methods. We\nexplore results in the standard Atari benchmark games as well as in an\nautonomous driving simulator. Based on the efficiency with which we have been\nable to identify behavioural weaknesses with this technique, we believe this\ngeneral approach could serve as an important tool for AI safety applications.", "published": "2019-04-02T10:21:23Z", "version": 1}, {"aid": "1904.01326", "authors": ["Thu Nguyen-Phuoc", "Chuan Li", "Lucas Theis", "Christian Richardt", "Yong-Liang Yang"], "title": "HoloGAN: Unsupervised learning of 3D representations from natural images", "url": "http://arxiv.org/pdf/1904.01326v2", "summary": "We propose a novel generative adversarial network (GAN) for the task of\nunsupervised learning of 3D representations from natural images. Most\ngenerative models rely on 2D kernels to generate images and make few\nassumptions about the 3D world. These models therefore tend to create blurry\nimages or artefacts in tasks that require a strong 3D understanding, such as\nnovel-view synthesis. HoloGAN instead learns a 3D representation of the world,\nand to render this representation in a realistic manner. Unlike other GANs,\nHoloGAN provides explicit control over the pose of generated objects through\nrigid-body transformations of the learnt 3D features. Our experiments show that\nusing explicit 3D features enables HoloGAN to disentangle 3D pose and identity,\nwhich is further decomposed into shape and appearance, while still being able\nto generate images with similar or higher visual quality than other generative\nmodels. HoloGAN can be trained end-to-end from unlabelled 2D images only.\nParticularly, we do not require pose labels, 3D shapes, or multiple views of\nthe same objects. This shows that HoloGAN is the first generative model that\nlearns 3D representations from natural images in an entirely unsupervised\nmanner.", "published": "2019-04-02T10:36:01Z", "version": 2}, {"aid": "1904.01774", "authors": ["Atsuhiro Noguchi", "Tatsuya Harada"], "title": "Image Generation From Small Datasets via Batch Statistics Adaptation", "url": "http://arxiv.org/pdf/1904.01774v4", "summary": "Thanks to the recent development of deep generative models, it is becoming\npossible to generate high-quality images with both fidelity and diversity.\nHowever, the training of such generative models requires a large dataset. To\nreduce the amount of data required, we propose a new method for transferring\nprior knowledge of the pre-trained generator, which is trained with a large\ndataset, to a small dataset in a different domain. Using such prior knowledge,\nthe model can generate images leveraging some common sense that cannot be\nacquired from a small dataset. In this work, we propose a novel method focusing\non the parameters for batch statistics, scale and shift, of the hidden layers\nin the generator. By training only these parameters in a supervised manner, we\nachieved stable training of the generator, and our method can generate higher\nquality images compared to previous methods without collapsing, even when the\ndataset is small (~100). Our results show that the diversity of the filters\nacquired in the pre-trained generator is important for the performance on the\ntarget domain. Our method makes it possible to add a new class or domain to a\npre-trained generator without disturbing the performance on the original\ndomain.", "published": "2019-04-03T05:24:02Z", "version": 4}, {"aid": "1904.01777", "authors": ["Heng Wang", "Mingzhi Mao"], "title": "Defeats GAN: A Simpler Model Outperforms in Knowledge Representation Learning", "url": "http://arxiv.org/pdf/1904.01777v1", "summary": "The goal of knowledge representation learning is to embed entities and\nrelations into a low-dimensional, continuous vector space. How to push a model\nto its limit and obtain better results is of great significance in knowledge\ngraph's applications. We propose a simple and elegant method, Trans-DLR, whose\nmain idea is dynamic learning rate control during training. Our method achieves\nremarkable improvement, compared with recent GAN-based method. Moreover, we\nintroduce a new negative sampling trick which corrupts not only entities, but\nalso relations, in different probabilities. We also develop an efficient way,\nwhich fully utilizes multiprocessing and parallel computing, to speed up\nevaluation of the model in link prediction tasks. Experiments show that our\nmethod is effective.", "published": "2019-04-03T05:42:14Z", "version": 1}, {"aid": "1904.01786", "authors": ["Shichen Liu", "Tianye Li", "Weikai Chen", "Hao Li"], "title": "Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning", "url": "http://arxiv.org/pdf/1904.01786v1", "summary": "Rendering bridges the gap between 2D vision and 3D scenes by simulating the\nphysical process of image formation. By inverting such renderer, one can think\nof a learning approach to infer 3D information from 2D images. However,\nstandard graphics renderers involve a fundamental discretization step called\nrasterization, which prevents the rendering process to be differentiable, hence\nable to be learned. Unlike the state-of-the-art differentiable renderers, which\nonly approximate the rendering gradient in the back propagation, we propose a\ntruly differentiable rendering framework that is able to (1) directly render\ncolorized mesh using differentiable functions and (2) back-propagate efficient\nsupervision signals to mesh vertices and their attributes from various forms of\nimage representations, including silhouette, shading and color images. The key\nto our framework is a novel formulation that views rendering as an aggregation\nfunction that fuses the probabilistic contributions of all mesh triangles with\nrespect to the rendered pixels. Such formulation enables our framework to flow\ngradients to the occluded and far-range vertices, which cannot be achieved by\nthe previous state-of-the-arts. We show that by using the proposed renderer,\none can achieve significant improvement in 3D unsupervised single-view\nreconstruction both qualitatively and quantitatively. Experiments also\ndemonstrate that our approach is able to handle the challenging tasks in\nimage-based shape fitting, which remain nontrivial to existing differentiable\nrenderers.", "published": "2019-04-03T06:06:43Z", "version": 1}, {"aid": "1904.02021", "authors": ["James Smith", "Cameron Taylor", "Seth Baer", "Constantine Dovrolis"], "title": "Unsupervised Progressive Learning and the STAM Architecture", "url": "http://arxiv.org/pdf/1904.02021v6", "summary": "We first pose the Unsupervised Progressive Learning (UPL) problem: an online\nrepresentation learning problem in which the learner observes a non-stationary\nand unlabeled data stream, learning a growing number of features that persist\nover time even though the data is not stored or replayed. To solve the UPL\nproblem we propose the Self-Taught Associative Memory (STAM) architecture.\nLayered hierarchies of STAM modules learn based on a combination of online\nclustering, novelty detection, forgetting outliers, and storing only\nprototypical features rather than specific examples. We evaluate STAM\nrepresentations using clustering and classification tasks. While there are no\nexisting learning scenarios that are directly comparable to UPL, we compare the\nSTAM architecture with two recent continual learning models, Memory Aware\nSynapses (MAS) and Gradient Episodic Memories (GEM), after adapting them in the\nUPL setting.", "published": "2019-04-03T14:25:08Z", "version": 6}, {"aid": "1904.02063", "authors": ["Jeremias Knoblauch", "Jack Jewson", "Theodoros Damoulas"], "title": "Generalized Variational Inference: Three arguments for deriving new Posteriors", "url": "http://arxiv.org/pdf/1904.02063v4", "summary": "We advocate an optimization-centric view on and introduce a novel\ngeneralization of Bayesian inference. Our inspiration is the representation of\nBayes' rule as infinite-dimensional optimization problem (Csiszar, 1975;\nDonsker and Varadhan; 1975, Zellner; 1988). First, we use it to prove an\noptimality result of standard Variational Inference (VI): Under the proposed\nview, the standard Evidence Lower Bound (ELBO) maximizing VI posterior is\npreferable to alternative approximations of the Bayesian posterior. Next, we\nargue for generalizing standard Bayesian inference. The need for this arises in\nsituations of severe misalignment between reality and three assumptions\nunderlying standard Bayesian inference: (1) Well-specified priors, (2)\nwell-specified likelihoods, (3) the availability of infinite computing power.\nOur generalization addresses these shortcomings with three arguments and is\ncalled the Rule of Three (RoT). We derive it axiomatically and recover existing\nposteriors as special cases, including the Bayesian posterior and its\napproximation by standard VI. In contrast, approximations based on alternative\nELBO-like objectives violate the axioms. Finally, we study a special case of\nthe RoT that we call Generalized Variational Inference (GVI). GVI posteriors\nare a large and tractable family of belief distributions specified by three\narguments: A loss, a divergence and a variational family. GVI posteriors have\nappealing properties, including consistency and an interpretation as\napproximate ELBO. The last part of the paper explores some attractive\napplications of GVI in popular machine learning models, including robustness\nand more appropriate marginals. After deriving black box inference schemes for\nGVI posteriors, their predictive performance is investigated on Bayesian Neural\nNetworks and Deep Gaussian Processes, where GVI can comprehensively improve\nupon existing methods.", "published": "2019-04-03T15:31:46Z", "version": 4}, {"aid": "1904.02323", "authors": ["Fred Hohman", "Haekyu Park", "Caleb Robinson", "Duen Horng Chau"], "title": "Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations", "url": "http://arxiv.org/pdf/1904.02323v3", "summary": "Deep learning is increasingly used in decision-making tasks. However,\nunderstanding how neural networks produce final predictions remains a\nfundamental challenge. Existing work on interpreting neural network predictions\nfor images often focuses on explaining predictions for single images or\nneurons. As predictions are often computed from millions of weights that are\noptimized over millions of images, such explanations can easily miss a bigger\npicture. We present Summit, an interactive system that scalably and\nsystematically summarizes and visualizes what features a deep learning model\nhas learned and how those features interact to make predictions. Summit\nintroduces two new scalable summarization techniques: (1) activation\naggregation discovers important neurons, and (2) neuron-influence aggregation\nidentifies relationships among such neurons. Summit combines these techniques\nto create the novel attribution graph that reveals and summarizes crucial\nneuron associations and substructures that contribute to a model's outcomes.\nSummit scales to large data, such as the ImageNet dataset with 1.2M images, and\nleverages neural network feature visualization and dataset examples to help\nusers distill large, complex neural network models into compact, interactive\nvisualizations. We present neural network exploration scenarios where Summit\nhelps us discover multiple surprising insights into a prevalent, large-scale\nimage classifier's learned representations and informs future neural network\narchitecture design. The Summit visualization runs in modern web browsers and\nis open-sourced.", "published": "2019-04-04T03:00:40Z", "version": 3}, {"aid": "1904.05677", "authors": ["Muhammad Haris", "Greg Shakhnarovich", "Norimichi Ukita"], "title": "Deep Back-Projection Networks for Single Image Super-resolution", "url": "http://arxiv.org/pdf/1904.05677v2", "summary": "Previous feed-forward architectures of recently proposed deep\nsuper-resolution networks learn the features of low-resolution inputs and the\nnon-linear mapping from those to a high-resolution output. However, this\napproach does not fully address the mutual dependencies of low- and\nhigh-resolution images. We propose Deep Back-Projection Networks (DBPN), the\nwinner of two image super-resolution challenges (NTIRE2018 and PIRM2018), that\nexploit iterative up- and down-sampling layers. These layers are formed as a\nunit providing an error feedback mechanism for projection errors. We construct\nmutually-connected up- and down-sampling units each of which represents\ndifferent types of low- and high-resolution components. We also show that\nextending this idea to demonstrate a new insight towards more efficient network\ndesign substantially, such as parameter sharing on the projection module and\ntransition layer on projection step. The experimental results yield superior\nresults and in particular establishing new state-of-the-art results across\nmultiple data sets, especially for large scaling factors such as 8x.", "published": "2019-04-04T05:32:53Z", "version": 2}, {"aid": "1904.02358", "authors": ["Chaofeng Wang", "Zheng Li", "Jun Shi"], "title": "Lightweight Image Super-Resolution with Adaptive Weighted Learning Network", "url": "http://arxiv.org/pdf/1904.02358v1", "summary": "Deep learning has been successfully applied to the single-image\nsuper-resolution (SISR) task with great performance in recent years. However,\nmost convolutional neural network based SR models require heavy computation,\nwhich limit their real-world applications. In this work, a lightweight SR\nnetwork, named Adaptive Weighted Super-Resolution Network (AWSRN), is proposed\nfor SISR to address this issue. A novel local fusion block (LFB) is designed in\nAWSRN for efficient residual learning, which consists of stacked adaptive\nweighted residual units (AWRU) and a local residual fusion unit (LRFU).\nMoreover, an adaptive weighted multi-scale (AWMS) module is proposed to make\nfull use of features in reconstruction layer. AWMS consists of several\ndifferent scale convolutions, and the redundancy scale branch can be removed\naccording to the contribution of adaptive weights in AWMS for lightweight\nnetwork. The experimental results on the commonly used datasets show that the\nproposed lightweight AWSRN achieves superior performance on x2, x3, x4, and x8\nscale factors to state-of-the-art methods with similar parameters and\ncomputational overhead. Code is avaliable at:\nhttps://github.com/ChaofWang/AWSRN", "published": "2019-04-04T05:44:32Z", "version": 1}, {"aid": "1904.02375", "authors": ["Alexandre Boulch"], "title": "ConvPoint: Continuous Convolutions for Point Cloud Processing", "url": "http://arxiv.org/pdf/1904.02375v5", "summary": "Point clouds are unstructured and unordered data, as opposed to images. Thus,\nmost machine learning approach developed for image cannot be directly\ntransferred to point clouds. In this paper, we propose a generalization of\ndiscrete convolutional neural networks (CNNs) in order to deal with point\nclouds by replacing discrete kernels by continuous ones. This formulation is\nsimple, allows arbitrary point cloud sizes and can easily be used for designing\nneural networks similarly to 2D CNNs. We present experimental results with\nvarious architectures, highlighting the flexibility of the proposed approach.\nWe obtain competitive results compared to the state-of-the-art on shape\nclassification, part segmentation and semantic segmentation for large-scale\npoint clouds.", "published": "2019-04-04T06:51:56Z", "version": 5}, {"aid": "1904.02639", "authors": ["Dong Gong", "Lingqiao Liu", "Vuong Le", "Budhaditya Saha", "Moussa Reda Mansour", "Svetha Venkatesh", "Anton van den Hengel"], "title": "Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection", "url": "http://arxiv.org/pdf/1904.02639v2", "summary": "Deep autoencoder has been extensively used for anomaly detection. Training on\nthe normal data, the autoencoder is expected to produce higher reconstruction\nerror for the abnormal inputs than the normal ones, which is adopted as a\ncriterion for identifying anomalies. However, this assumption does not always\nhold in practice. It has been observed that sometimes the autoencoder\n\"generalizes\" so well that it can also reconstruct anomalies well, leading to\nthe miss detection of anomalies. To mitigate this drawback for autoencoder\nbased anomaly detector, we propose to augment the autoencoder with a memory\nmodule and develop an improved autoencoder called memory-augmented autoencoder,\ni.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder\nand then uses it as a query to retrieve the most relevant memory items for\nreconstruction. At the training stage, the memory contents are updated and are\nencouraged to represent the prototypical elements of the normal data. At the\ntest stage, the learned memory will be fixed, and the reconstruction is\nobtained from a few selected memory records of the normal data. The\nreconstruction will thus tend to be close to a normal sample. Thus the\nreconstructed errors on anomalies will be strengthened for anomaly detection.\nMemAE is free of assumptions on the data type and thus general to be applied to\ndifferent tasks. Experiments on various datasets prove the excellent\ngeneralization and high effectiveness of the proposed MemAE.", "published": "2019-04-04T16:16:50Z", "version": 2}, {"aid": "1904.02675", "authors": ["Wu Jionghao"], "title": "UU-Nets Connecting Discriminator and Generator for Image to Image Translation", "url": "http://arxiv.org/pdf/1904.02675v1", "summary": "Adversarial generative model have successfully manifest itself in image\nsynthesis. However, the performance deteriorate and unstable, because\ndiscriminator is far stable than generator, and it is hard to control the game\nbetween the two modules. Various methods have been introduced to tackle the\nproblem such as WGAN, Relativistic GAN and their successors by adding or\nrestricting the loss function, which certainly help balance the min-max game,\nbut they all focused on the loss function ignoring the intrinsic structure\nlimitation. We present a UU-Net architecture inspired by U-net bridging the\nencoder and the decoder, UU-Net composed by two U-Net liked modules\nrespectively served as generator and discriminator. Because the modules in\nU-net are symmetrical, therefore it shares weights easily between all four\ncomponents. Thanks to UU-net's modules identical and symmetric property, we\ncould not only carried the features from inner generator's encoder to its\ndecoder, but also to the discriminator's encoder and decoder. By this design,\nit give us more control and condition flexibility to intervene the process\nbetween the generator and the discriminator.", "published": "2019-04-04T17:25:21Z", "version": 1}, {"aid": "1904.02698", "authors": ["Jean Kossaifi", "Adrian Bulat", "Georgios Tzimiropoulos", "Maja Pantic"], "title": "T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order Tensor", "url": "http://arxiv.org/pdf/1904.02698v1", "summary": "Recent findings indicate that over-parametrization, while crucial for\nsuccessfully training deep neural networks, also introduces large amounts of\nredundancy. Tensor methods have the potential to efficiently parametrize\nover-complete representations by leveraging this redundancy. In this paper, we\npropose to fully parametrize Convolutional Neural Networks (CNNs) with a single\nhigh-order, low-rank tensor. Previous works on network tensorization have\nfocused on parametrizing individual layers (convolutional or fully connected)\nonly, and perform the tensorization layer-by-layer separately. In contrast, we\npropose to jointly capture the full structure of a neural network by\nparametrizing it with a single high-order tensor, the modes of which represent\neach of the architectural design parameters of the network (e.g. number of\nconvolutional blocks, depth, number of stacks, input features, etc). This\nparametrization allows to regularize the whole network and drastically reduce\nthe number of parameters. Our model is end-to-end trainable and the low-rank\nstructure imposed on the weight tensor acts as an implicit regularization. We\nstudy the case of networks with rich structure, namely Fully Convolutional\nNetworks (FCNs), which we propose to parametrize with a single 8th-order\ntensor. We show that our approach can achieve superior performance with small\ncompression rates, and attain high compression rates with negligible drop in\naccuracy for the challenging task of human pose estimation.", "published": "2019-04-04T17:55:37Z", "version": 1}, {"aid": "1904.02741", "authors": ["David Berga", "Xavier Otazu"], "title": "Modeling Bottom-Up and Top-Down Attention with a Neurodynamic Model of V1", "url": "http://arxiv.org/pdf/1904.02741v3", "summary": "Previous studies suggested that lateral interactions of V1 cells are\nresponsible, among other visual effects, of bottom-up visual attention\n(alternatively named visual salience or saliency). Our objective is to mimic\nthese connections with a neurodynamic network of firing-rate neurons in order\nto predict visual attention. Early visual subcortical processes (i.e. retinal\nand thalamic) are functionally simulated. An implementation of the cortical\nmagnification function is included to define the retinotopical projections\ntowards V1, processing neuronal activity for each distinct view during scene\nobservation. Novel computational definitions of top-down inhibition (in terms\nof inhibition of return and selection mechanisms), are also proposed to predict\nattention in Free-Viewing and Visual Search tasks. Results show that our model\noutpeforms other biologically-inpired models of saliency prediction while\npredicting visual saccade sequences with the same model. We also show how\ntemporal and spatial characteristics of inhibition of return can improve\nprediction of saccades, as well as how distinct search strategies (in terms of\nfeature-selective or category-specific inhibition) can predict attention at\ndistinct image contexts.", "published": "2019-04-04T18:33:15Z", "version": 3}, {"aid": "1904.03092", "authors": ["Jie Hao", "Xing Wang", "Baosong Yang", "Longyue Wang", "Jinfeng Zhang", "Zhaopeng Tu"], "title": "Modeling Recurrence for Transformer", "url": "http://arxiv.org/pdf/1904.03092v1", "summary": "Recently, the Transformer model that is based solely on attention mechanisms,\nhas advanced the state-of-the-art on various machine translation tasks.\nHowever, recent studies reveal that the lack of recurrence hinders its further\nimprovement of translation capacity. In response to this problem, we propose to\ndirectly model recurrence for Transformer with an additional recurrence\nencoder. In addition to the standard recurrent neural network, we introduce a\nnovel attentive recurrent network to leverage the strengths of both attention\nand recurrent networks. Experimental results on the widely-used WMT14\nEnglish-German and WMT17 Chinese-English translation tasks demonstrate the\neffectiveness of the proposed approach. Our studies also reveal that the\nproposed model benefits from a short-cut that bridges the source and target\nsequences with a single recurrent layer, which outperforms its deep\ncounterpart.", "published": "2019-04-05T14:40:22Z", "version": 1}, {"aid": "1904.03107", "authors": ["Baosong Yang", "Longyue Wang", "Derek Wong", "Lidia S. Chao", "Zhaopeng Tu"], "title": "Convolutional Self-Attention Networks", "url": "http://arxiv.org/pdf/1904.03107v1", "summary": "Self-attention networks (SANs) have drawn increasing interest due to their\nhigh parallelization in computation and flexibility in modeling dependencies.\nSANs can be further enhanced with multi-head attention by allowing the model to\nattend to information from different representation subspaces. In this work, we\npropose novel convolutional self-attention networks, which offer SANs the\nabilities to 1) strengthen dependencies among neighboring elements, and 2)\nmodel the interaction between features extracted by multiple attention heads.\nExperimental results of machine translation on different language pairs and\nmodel settings show that our approach outperforms both the strong Transformer\nbaseline and other existing models on enhancing the locality of SANs. Comparing\nwith prior studies, the proposed model is parameter free in terms of\nintroducing no more parameters.", "published": "2019-04-05T15:02:26Z", "version": 1}, {"aid": "1904.03392", "authors": ["Shaofeng Cai", "Yao Shu", "Gang Chen", "Beng Chin Ooi", "Wei Wang", "Meihui Zhang"], "title": "Effective and Efficient Dropout for Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1904.03392v5", "summary": "Convolutional Neural networks (CNNs) based applications have become\nubiquitous, where proper regularization is greatly needed. To prevent large\nneural network models from overfitting, dropout has been widely used as an\nefficient regularization technique in practice. However, many recent works show\nthat the standard dropout is ineffective or even detrimental to the training of\nCNNs. In this paper, we revisit this issue and examine various dropout variants\nin an attempt to improve existing dropout-based regularization techniques for\nCNNs. We attribute the failure of standard dropout to the conflict between the\nstochasticity of dropout and its following Batch Normalization (BN), and\npropose to reduce the conflict by placing dropout operations right before the\nconvolutional operation instead of BN, or totally address this issue by\nreplacing BN with Group Normalization (GN). We further introduce a structurally\nmore suited dropout variant Drop-Conv2d, which provides more efficient and\neffective regularization for deep CNNs. These dropout variants can be readily\nintegrated into the building blocks of CNNs and implemented in existing deep\nlearning platforms. Extensive experiments on benchmark datasets including\nCIFAR, SVHN and ImageNet are conducted to compare the existing building blocks\nand the proposed ones with dropout training. Results show that our building\nblocks improve over state-of-the-art CNNs significantly, which is mainly due to\nthe better regularization and implicit model ensemble effect.", "published": "2019-04-06T09:17:51Z", "version": 5}, {"aid": "1904.03441", "authors": ["Lei Huang", "Yi Zhou", "Fan Zhu", "Li Liu", "Ling Shao"], "title": "Iterative Normalization: Beyond Standardization towards Efficient Whitening", "url": "http://arxiv.org/pdf/1904.03441v1", "summary": "Batch Normalization (BN) is ubiquitously employed for accelerating neural\nnetwork training and improving the generalization capability by performing\nstandardization within mini-batches. Decorrelated Batch Normalization (DBN)\nfurther boosts the above effectiveness by whitening. However, DBN relies\nheavily on either a large batch size, or eigen-decomposition that suffers from\npoor efficiency on GPUs. We propose Iterative Normalization (IterNorm), which\nemploys Newton's iterations for much more efficient whitening, while\nsimultaneously avoiding the eigen-decomposition. Furthermore, we develop a\ncomprehensive study to show IterNorm has better trade-off between optimization\nand generalization, with theoretical and experimental support. To this end, we\nexclusively introduce Stochastic Normalization Disturbance (SND), which\nmeasures the inherent stochastic uncertainty of samples when applied to\nnormalization operations. With the support of SND, we provide natural\nexplanations to several phenomena from the perspective of optimization, e.g.,\nwhy group-wise whitening of DBN generally outperforms full-whitening and why\nthe accuracy of BN degenerates with reduced batch sizes. We demonstrate the\nconsistently improved performance of IterNorm with extensive experiments on\nCIFAR-10 and ImageNet over BN and DBN.", "published": "2019-04-06T13:10:20Z", "version": 1}, {"aid": "1904.03525", "authors": ["Yuxiang Zhou", "Jiankang Deng", "Irene Kotsia", "Stefanos Zafeiriou"], "title": "Dense 3D Face Decoding over 2500FPS: Joint Texture & Shape Convolutional Mesh Decoders", "url": "http://arxiv.org/pdf/1904.03525v1", "summary": "3D Morphable Models (3DMMs) are statistical models that represent facial\ntexture and shape variations using a set of linear bases and more particular\nPrincipal Component Analysis (PCA). 3DMMs were used as statistical priors for\nreconstructing 3D faces from images by solving non-linear least square\noptimization problems. Recently, 3DMMs were used as generative models for\ntraining non-linear mappings (\\ie, regressors) from image to the parameters of\nthe models via Deep Convolutional Neural Networks (DCNNs). Nevertheless, all of\nthe above methods use either fully connected layers or 2D convolutions on\nparametric unwrapped UV spaces leading to large networks with many parameters.\nIn this paper, we present the first, to the best of our knowledge, non-linear\n3DMMs by learning joint texture and shape auto-encoders using direct mesh\nconvolutions. We demonstrate how these auto-encoders can be used to train very\nlight-weight models that perform Coloured Mesh Decoding (CMD) in-the-wild at a\nspeed of over 2500 FPS.", "published": "2019-04-06T20:22:53Z", "version": 1}, {"aid": "1904.03751", "authors": ["Guohao Li", "Matthias M\u00fcller", "Ali Thabet", "Bernard Ghanem"], "title": "DeepGCNs: Can GCNs Go as Deep as CNNs?", "url": "http://arxiv.org/pdf/1904.03751v2", "summary": "Convolutional Neural Networks (CNNs) achieve impressive performance in a wide\nvariety of fields. Their success benefited from a massive boost when very deep\nCNN models were able to be reliably trained. Despite their merits, CNNs fail to\nproperly address problems with non-Euclidean data. To overcome this challenge,\nGraph Convolutional Networks (GCNs) build graphs to represent non-Euclidean\ndata, borrow concepts from CNNs, and apply them in training. GCNs show\npromising results, but they are usually limited to very shallow models due to\nthe vanishing gradient problem. As a result, most state-of-the-art GCN models\nare no deeper than 3 or 4 layers. In this work, we present new ways to\nsuccessfully train very deep GCNs. We do this by borrowing concepts from CNNs,\nspecifically residual/dense connections and dilated convolutions, and adapting\nthem to GCN architectures. Extensive experiments show the positive effect of\nthese deep GCN frameworks. Finally, we use these new concepts to build a very\ndeep 56-layer GCN, and show how it significantly boosts performance (+3.7% mIoU\nover state-of-the-art) in the task of point cloud semantic segmentation. We\nbelieve that the community can greatly benefit from this work, as it opens up\nmany opportunities for advancing GCN-based research.", "published": "2019-04-07T21:49:26Z", "version": 2}, {"aid": "1904.03955", "authors": ["Chen Wang", "Jianfei Yang", "Lihua Xie", "Junsong Yuan"], "title": "Kervolutional Neural Networks", "url": "http://arxiv.org/pdf/1904.03955v2", "summary": "Convolutional neural networks (CNNs) have enabled the state-of-the-art\nperformance in many computer vision tasks. However, little effort has been\ndevoted to establishing convolution in non-linear space. Existing works mainly\nleverage on the activation layers, which can only provide point-wise\nnon-linearity. To solve this problem, a new operation, kervolution (kernel\nconvolution), is introduced to approximate complex behaviors of human\nperception systems leveraging on the kernel trick. It generalizes convolution,\nenhances the model capacity, and captures higher order interactions of\nfeatures, via patch-wise kernel functions, but without introducing additional\nparameters. Extensive experiments show that kervolutional neural networks (KNN)\nachieve higher accuracy and faster convergence than baseline CNN.", "published": "2019-04-08T11:10:51Z", "version": 2}, {"aid": "1904.04015", "authors": ["Maxime Chabance", "Gr\u00e9goire Cattan", "Bastien Maureille"], "title": "Implementation of a Daemon for OpenBCI", "url": "http://arxiv.org/pdf/1904.04015v1", "summary": "This document describes a technical study of the electroencephalographic\n(EEG) headset OpenBCI (New York, US). In comparison to research grade EEG, the\nOpenBCI headset is affordable thus suitable for the general public use. In this\nstudy we designed a daemon, that is, a background and continuous task\ncommunicating with the headset, acquiring, filtering and analyzing the EEG\ndata. This study was promoted by the IHMTEK Company (Vienne, France) in 2016\nwithin a thesis on the integration of EEG-based brain-computer interfaces in\nvirtual reality for the general public.", "published": "2019-04-08T12:45:51Z", "version": 1}, {"aid": "1904.04579", "authors": ["Kieran Greer"], "title": "A Concept-Value Network as a Brain Model", "url": "http://arxiv.org/pdf/1904.04579v6", "summary": "This paper suggests a statistical framework for describing the relations\nbetween the physical and conceptual entities of a brain-like model. Features\nand concept instances are put into context, where the paper suggests that\nfeatures may be the electrical wiring, although chemical connections are also\npossible. With this idea, the actual length of the connection is important,\nbecause it is related to firing rates and neuron synchronization, but the\nsignal type is less important. The paper then suggests that concepts are neuron\ngroups that link feature sets and concept instances are determined by chemical\nsignals from those groups. Therefore, features become the static horizontal\nframework of the neural system and concepts are vertically interconnected\ncombinations of these. With regards to functionality, the neuron is then\nconsidered to be functional and the more horizontal memory structures can even\nbe glial. This would also suggest that features can be distributed entities and\nnot concentrated to a single area. Another aspect could be signal 'breaks' that\ncompartmentalise a pattern and may help with neural binding.", "published": "2019-04-09T10:30:23Z", "version": 6}, {"aid": "1904.04862", "authors": ["Mojan Javaheripi", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "title": "SWNet: Small-World Neural Networks and Rapid Convergence", "url": "http://arxiv.org/pdf/1904.04862v1", "summary": "Training large and highly accurate deep learning (DL) models is\ncomputationally costly. This cost is in great part due to the excessive number\nof trained parameters, which are well-known to be redundant and compressible\nfor the execution phase. This paper proposes a novel transformation which\nchanges the topology of the DL architecture such that it reaches an optimal\ncross-layer connectivity. This transformation leverages our important\nobservation that for a set level of accuracy, convergence is fastest when\nnetwork topology reaches the boundary of a Small-World Network. Small-world\ngraphs are known to possess a specific connectivity structure that enables\nenhanced signal propagation among nodes. Our small-world models, called SWNets,\nprovide several intriguing benefits: they facilitate data (gradient) flow\nwithin the network, enable feature-map reuse by adding long-range connections\nand accommodate various network architectures/datasets. Compared to densely\nconnected networks (e.g., DenseNets), SWNets require a substantially fewer\nnumber of training parameters while maintaining a similar level of\nclassification accuracy. We evaluate our networks on various DL model\narchitectures and image classification datasets, namely, CIFAR10, CIFAR100, and\nILSVRC (ImageNet). Our experiments demonstrate an average of ~2.1x improvement\nin convergence speed to the desired accuracy", "published": "2019-04-09T18:41:26Z", "version": 1}, {"aid": "1904.05019", "authors": ["Yurun Tian", "Xin Yu", "Bin Fan", "Fuchao Wu", "Huub Heijnen", "Vassileios Balntas"], "title": "SOSNet: Second Order Similarity Regularization for Local Descriptor Learning", "url": "http://arxiv.org/pdf/1904.05019v2", "summary": "Despite the fact that Second Order Similarity (SOS) has been used with\nsignificant success in tasks such as graph matching and clustering, it has not\nbeen exploited for learning local descriptors. In this work, we explore the\npotential of SOS in the field of descriptor learning by building upon the\nintuition that a positive pair of matching points should exhibit similar\ndistances with respect to other points in the embedding space. Thus, we propose\na novel regularization term, named Second Order Similarity Regularization\n(SOSR), that follows this principle. By incorporating SOSR into training, our\nlearned descriptor achieves state-of-the-art performance on several challenging\nbenchmarks containing distinct tasks ranging from local patch retrieval to\nstructure from motion. Furthermore, by designing a von Mises-Fischer\ndistribution based evaluation method, we link the utilization of the descriptor\nspace to the matching performance, thus demonstrating the effectiveness of our\nproposed SOSR. Extensive experimental results, empirical evidence, and in-depth\nanalysis are provided, indicating that SOSR can significantly boost the\nmatching performance of the learned descriptor.", "published": "2019-04-10T06:33:28Z", "version": 2}, {"aid": "1904.05046", "authors": ["Yaqing Wang", "Quanming Yao", "James Kwok", "Lionel M. Ni"], "title": "Generalizing from a Few Examples: A Survey on Few-Shot Learning", "url": "http://arxiv.org/pdf/1904.05046v3", "summary": "Machine learning has been highly successful in data-intensive applications\nbut is often hampered when the data set is small. Recently, Few-Shot Learning\n(FSL) is proposed to tackle this problem. Using prior knowledge, FSL can\nrapidly generalize to new tasks containing only a few samples with supervised\ninformation. In this paper, we conduct a thorough survey to fully understand\nFSL. Starting from a formal definition of FSL, we distinguish FSL from several\nrelevant machine learning problems. We then point out that the core issue in\nFSL is that the empirical risk minimized is unreliable. Based on how prior\nknowledge can be used to handle this core issue, we categorize FSL methods from\nthree perspectives: (i) data, which uses prior knowledge to augment the\nsupervised experience; (ii) model, which uses prior knowledge to reduce the\nsize of the hypothesis space; and (iii) algorithm, which uses prior knowledge\nto alter the search for the best hypothesis in the given hypothesis space. With\nthis taxonomy, we review and discuss the pros and cons of each category.\nPromising directions, in the aspects of the FSL problem setups, techniques,\napplications and theories, are also proposed to provide insights for future\nresearch.", "published": "2019-04-10T08:05:48Z", "version": 3}, {"aid": "1904.05049", "authors": ["Yunpeng Chen", "Haoqi Fan", "Bing Xu", "Zhicheng Yan", "Yannis Kalantidis", "Marcus Rohrbach", "Shuicheng Yan", "Jiashi Feng"], "title": "Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution", "url": "http://arxiv.org/pdf/1904.05049v3", "summary": "In natural images, information is conveyed at different frequencies where\nhigher frequencies are usually encoded with fine details and lower frequencies\nare usually encoded with global structures. Similarly, the output feature maps\nof a convolution layer can also be seen as a mixture of information at\ndifferent frequencies. In this work, we propose to factorize the mixed feature\nmaps by their frequencies, and design a novel Octave Convolution (OctConv)\noperation to store and process feature maps that vary spatially \"slower\" at a\nlower spatial resolution reducing both memory and computation cost. Unlike\nexisting multi-scale methods, OctConv is formulated as a single, generic,\nplug-and-play convolutional unit that can be used as a direct replacement of\n(vanilla) convolutions without any adjustments in the network architecture. It\nis also orthogonal and complementary to methods that suggest better topologies\nor reduce channel-wise redundancy like group or depth-wise convolutions. We\nexperimentally show that by simply replacing convolutions with OctConv, we can\nconsistently boost accuracy for both image and video recognition tasks, while\nreducing memory and computational cost. An OctConv-equipped ResNet-152 can\nachieve 82.9% top-1 classification accuracy on ImageNet with merely 22.2\nGFLOPs.", "published": "2019-04-10T08:15:00Z", "version": 3}, {"aid": "1904.05373", "authors": ["Hang Su", "Varun Jampani", "Deqing Sun", "Orazio Gallo", "Erik Learned-Miller", "Jan Kautz"], "title": "Pixel-Adaptive Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1904.05373v1", "summary": "Convolutions are the fundamental building block of CNNs. The fact that their\nweights are spatially shared is one of the main reasons for their widespread\nuse, but it also is a major limitation, as it makes convolutions content\nagnostic. We propose a pixel-adaptive convolution (PAC) operation, a simple yet\neffective modification of standard convolutions, in which the filter weights\nare multiplied with a spatially-varying kernel that depends on learnable, local\npixel features. PAC is a generalization of several popular filtering techniques\nand thus can be used for a wide range of use cases. Specifically, we\ndemonstrate state-of-the-art performance when PAC is used for deep joint image\nupsampling. PAC also offers an effective alternative to fully-connected CRF\n(Full-CRF), called PAC-CRF, which performs competitively, while being\nconsiderably faster. In addition, we also demonstrate that PAC can be used as a\ndrop-in replacement for convolution layers in pre-trained networks, resulting\nin consistent performance improvements.", "published": "2019-04-10T18:02:54Z", "version": 1}, {"aid": "1904.05387", "authors": ["Eunice Jun", "Maureen Daum", "Jared Roesch", "Sarah E. Chasins", "Emery D. Berger", "Rene Just", "Katharina Reinecke"], "title": "Tea: A High-level Language and Runtime System for Automating Statistical Analysis", "url": "http://arxiv.org/pdf/1904.05387v1", "summary": "Though statistical analyses are centered on research questions and\nhypotheses, current statistical analysis tools are not. Users must first\ntranslate their hypotheses into specific statistical tests and then perform API\ncalls with functions and parameters. To do so accurately requires that users\nhave statistical expertise. To lower this barrier to valid, replicable\nstatistical analysis, we introduce Tea, a high-level declarative language and\nruntime system. In Tea, users express their study design, any parametric\nassumptions, and their hypotheses. Tea compiles these high-level specifications\ninto a constraint satisfaction problem that determines the set of valid\nstatistical tests, and then executes them to test the hypothesis. We evaluate\nTea using a suite of statistical analyses drawn from popular tutorials. We show\nthat Tea generally matches the choices of experts while automatically switching\nto non-parametric tests when parametric assumptions are not met. We simulate\nthe effect of mistakes made by non-expert users and show that Tea automatically\navoids both false negatives and false positives that could be produced by the\napplication of incorrect statistical tests.", "published": "2019-04-10T18:44:55Z", "version": 1}, {"aid": "1904.05408", "authors": ["Jiqing Wu", "Zhiwu Huang", "Dinesh Acharya", "Wen Li", "Janine Thoma", "Danda Pani Paudel", "Luc Van Gool"], "title": "Sliced Wasserstein Generative Models", "url": "http://arxiv.org/pdf/1904.05408v2", "summary": "In generative modeling, the Wasserstein distance (WD) has emerged as a useful\nmetric to measure the discrepancy between generated and real data\ndistributions. Unfortunately, it is challenging to approximate the WD of\nhigh-dimensional distributions. In contrast, the sliced Wasserstein distance\n(SWD) factorizes high-dimensional distributions into their multiple\none-dimensional marginal distributions and is thus easier to approximate. In\nthis paper, we introduce novel approximations of the primal and dual SWD.\nInstead of using a large number of random projections, as it is done by\nconventional SWD approximation methods, we propose to approximate SWDs with a\nsmall number of parameterized orthogonal projections in an end-to-end deep\nlearning fashion. As concrete applications of our SWD approximations, we design\ntwo types of differentiable SWD blocks to equip modern generative\nframeworks---Auto-Encoders (AE) and Generative Adversarial Networks (GAN). In\nthe experiments, we not only show the superiority of the proposed generative\nmodels on standard image synthesis benchmarks, but also demonstrate the\nstate-of-the-art performance on challenging high resolution image and video\ngeneration in an unsupervised manner.", "published": "2019-04-10T19:49:43Z", "version": 2}, {"aid": "1904.10508", "authors": ["Yasunao Katayama"], "title": "Quantum-Inspired Computing: Can it be a Microscopic Computing Model of the Brain?", "url": "http://arxiv.org/pdf/1904.10508v2", "summary": "Quantum computing and the workings of the brain have many aspects in common\nand have been attracting increasing attention in academia and industry. The\ncomputation in both is parallel and non-discrete. Though the underlying\nphysical dynamics (e.g., equation of motion) may be deterministic, the observed\nor interpreted outcomes are often probabilistic. Consequently, various\ninvestigations have been undertaken to understand and reproduce the brain on\nthe basis of quantum physics and computing. However, there have been arguments\non whether the brain can and have to take advantage of quantum phenomena that\nneed to survive in the macroscopic space-time region at room temperature. This\npaper presents a unique microscopic computational model for the brain based on\nan ansatz that the brain computes in a manner similar to quantum computing, but\nwith classical waves. Log-scale encoding of information in the context of\ncomputing with waves is shown to play a critical role in bridging the computing\nmodels with classical and quantum waves. Our quantum-inspired computing model\nopens up a possibility of unifying the computing framework of artificial\nintelligence and quantum computing beyond quantum machine learning approaches.", "published": "2019-04-11T01:12:23Z", "version": 2}, {"aid": "1904.05493", "authors": ["Juan Liu", "Kevin M. Koch"], "title": "Non-locally Encoder-Decoder Convolutional Network for Whole Brain QSM Inversion", "url": "http://arxiv.org/pdf/1904.05493v1", "summary": "Quantitative Susceptibility Mapping (QSM) reconstruction is a challenging\ninverse problem driven by ill conditioning of its field-to -susceptibility\ntransformation. State-of-art QSM reconstruction methods either suffer from\nimage artifacts or long computation times, which limits QSM clinical\ntranslation efforts. To overcome these limitations, a non-locally\nencoder-decoder gated convolutional neural network is trained to infer whole\nbrain susceptibility map, using the local field and brain mask as the inputs.\nThe performance of the proposed method is evaluated relative to synthetic data,\na publicly available challenge dataset, and clinical datasets. The proposed\napproach can outperform existing methods on quantitative metrics and visual\nassessment of image sharpness and streaking artifacts. The estimated\nsusceptibility maps can preserve conspicuity of fine features and suppress\nstreaking artifacts. The demonstrated methods have potential value in advancing\nQSM clinical research and aiding in the translation of QSM to clinical\noperations.", "published": "2019-04-11T01:20:05Z", "version": 1}, {"aid": "1904.06194", "authors": ["Ze-Feng Gao", "Song Cheng", "Rong-Qiang He", "Z. Y. Xie", "Hui-Hai Zhao", "Zhong-Yi Lu", "Tao Xiang"], "title": "Compressing deep neural networks by matrix product operators", "url": "http://arxiv.org/pdf/1904.06194v2", "summary": "A deep neural network is a parametrization of a multilayer mapping of signals\nin terms of many alternatively arranged linear and nonlinear transformations.\nThe linear transformations, which are generally used in the fully connected as\nwell as convolutional layers, contain most of the variational parameters that\nare trained and stored. Compressing a deep neural network to reduce its number\nof variational parameters but not its prediction power is an important but\nchallenging problem toward the establishment of an optimized scheme in training\nefficiently these parameters and in lowering the risk of overfitting. Here we\nshow that this problem can be effectively solved by representing linear\ntransformations with matrix product operators (MPOs), which is a tensor network\noriginally proposed in physics to characterize the short-range entanglement in\none-dimensional quantum states. We have tested this approach in five typical\nneural networks, including FC2, LeNet-5, VGG, ResNet, and DenseNet on two\nwidely used data sets, namely, MNIST and CIFAR-10, and found that this MPO\nrepresentation indeed sets up a faithful and efficient mapping between input\nand output signals, which can keep or even improve the prediction accuracy with\na dramatically reduced number of parameters. Our method greatly simplifies the\nrepresentations in deep learning, and opens a possible route toward\nestablishing a framework of modern neural networks which might be simpler and\ncheaper, but more efficient.", "published": "2019-04-11T17:59:00Z", "version": 2}, {"aid": "1904.06008", "authors": ["Qiuyu Zhu", "Pengju Zhang", "Xin Ye"], "title": "A New Loss Function for CNN Classifier Based on Pre-defined Evenly-Distributed Class Centroids", "url": "http://arxiv.org/pdf/1904.06008v2", "summary": "With the development of convolutional neural networks (CNNs) in recent years,\nthe network structure has become more and more complex and varied, and has\nachieved very good results in pattern recognition, image classification, object\ndetection and tracking. For CNNs used for image classification, in addition to\nthe network structure, more and more research is now focusing on the\nimprovement of the loss function, so as to enlarge the inter-class feature\ndifferences, and reduce the intra-class feature variations as soon as possible.\nBesides the traditional Softmax, typical loss functions include L-Softmax,\nAM-Softmax, ArcFace, and Center loss, etc. Based on the concept of predefined\nevenly-distributed class centroids (PEDCC) in CSAE network, this paper proposes\na PEDCC-based loss function called PEDCC-Loss, which can make the inter-class\ndistance maximal and intra-class distance small enough in hidden feature space.\nMultiple experiments on image classification and face recognition have proved\nthat our method achieve the best recognition accuracy, and network training is\nstable and easy to converge. Code is available in\nhttps://github.com/ZLeopard/PEDCC-Loss", "published": "2019-04-12T02:19:45Z", "version": 2}, {"aid": "1904.06031", "authors": ["Saurabh Singh", "Abhinav Shrivastava"], "title": "EvalNorm: Estimating Batch Normalization Statistics for Evaluation", "url": "http://arxiv.org/pdf/1904.06031v2", "summary": "Batch normalization (BN) has been very effective for deep learning and is\nwidely used. However, when training with small minibatches, models using BN\nexhibit a significant degradation in performance. In this paper we study this\npeculiar behavior of BN to gain a better understanding of the problem, and\nidentify a cause. We propose 'EvalNorm' to address the issue by estimating\ncorrected normalization statistics to use for BN during evaluation. EvalNorm\nsupports online estimation of the corrected statistics while the model is being\ntrained, and does not affect the training scheme of the model. As a result,\nEvalNorm can also be used with existing pre-trained models allowing them to\nbenefit from our method. EvalNorm yields large gains for models trained with\nsmaller batches. Our experiments show that EvalNorm performs 6.18% (absolute)\nbetter than vanilla BN for a batchsize of 2 on ImageNet validation set and from\n1.5 to 7.0 points (absolute) gain on the COCO object detection benchmark across\na variety of setups.", "published": "2019-04-12T04:54:56Z", "version": 2}, {"aid": "1904.06252", "authors": ["Jingcai Guo", "Shiheng Ma", "Song Guo"], "title": "MAANet: Multi-view Aware Attention Networks for Image Super-Resolution", "url": "http://arxiv.org/pdf/1904.06252v1", "summary": "In most recent years, deep convolutional neural networks (DCNNs) based image\nsuper-resolution (SR) has gained increasing attention in multimedia and\ncomputer vision communities, focusing on restoring the high-resolution (HR)\nimage from a low-resolution (LR) image. However, one nonnegligible flaw of\nDCNNs based methods is that most of them are not able to restore\nhigh-resolution images containing sufficient high-frequency information from\nlow-resolution images with low-frequency information redundancy. Worse still,\nas the depth of DCNNs increases, the training easily encounters the problem of\nvanishing gradients, which makes the training more difficult. These problems\nhinder the effectiveness of DCNNs in image SR task. To solve these problems, we\npropose the Multi-view Aware Attention Networks (MAANet) for image SR task.\nSpecifically, we propose the local aware (LA) and global aware (GA) attention\nto deal with LR features in unequal manners, which can highlight the\nhigh-frequency components and discriminate each feature from LR images in the\nlocal and the global views, respectively. Furthermore, we propose the local\nattentive residual-dense (LARD) block, which combines the LA attention with\nmultiple residual and dense connections, to fit a deeper yet easy to train\narchitecture. The experimental results show that our proposed approach can\nachieve remarkable performance compared with other state-of-the-art methods.", "published": "2019-04-12T14:32:10Z", "version": 1}, {"aid": "1904.06260", "authors": ["Eric Benhamou"], "title": "Similarities between policy gradient methods (PGM) in Reinforcement learning (RL) and supervised learning (SL)", "url": "http://arxiv.org/pdf/1904.06260v3", "summary": "Reinforcement learning (RL) is about sequential decision making and is\ntraditionally opposed to supervised learning (SL) and unsupervised learning\n(USL). In RL, given the current state, the agent makes a decision that may\ninfluence the next state as opposed to SL (and USL) where, the next state\nremains the same, regardless of the decisions taken, either in batch or online\nlearning. Although this difference is fundamental between SL and RL, there are\nconnections that have been overlooked. In particular, we prove in this paper\nthat gradient policy method can be cast as a supervised learning problem where\ntrue label are replaced with discounted rewards. We provide a new proof of\npolicy gradient methods (PGM) that emphasizes the tight link with the cross\nentropy and supervised learning. We provide a simple experiment where we\ninterchange label and pseudo rewards. We conclude that other relationships with\nSL could be made if we modify the reward functions wisely.", "published": "2019-04-12T14:49:28Z", "version": 3}, {"aid": "1904.06458", "authors": ["Kyle Olszewski", "Sergey Tulyakov", "Oliver Woodford", "Hao Li", "Linjie Luo"], "title": "Transformable Bottleneck Networks", "url": "http://arxiv.org/pdf/1904.06458v5", "summary": "We propose a novel approach to performing fine-grained 3D manipulation of\nimage content via a convolutional neural network, which we call the\nTransformable Bottleneck Network (TBN). It applies given spatial\ntransformations directly to a volumetric bottleneck within our\nencoder-bottleneck-decoder architecture. Multi-view supervision encourages the\nnetwork to learn to spatially disentangle the feature space within the\nbottleneck. The resulting spatial structure can be manipulated with arbitrary\nspatial transformations. We demonstrate the efficacy of TBNs for novel view\nsynthesis, achieving state-of-the-art results on a challenging benchmark. We\ndemonstrate that the bottlenecks produced by networks trained for this task\ncontain meaningful spatial structure that allows us to intuitively perform a\nvariety of image manipulations in 3D, well beyond the rigid transformations\nseen during training. These manipulations include non-uniform scaling,\nnon-rigid warping, and combining content from different images. Finally, we\nextract explicit 3D structure from the bottleneck, performing impressive 3D\nreconstruction from a single input image.", "published": "2019-04-13T00:56:29Z", "version": 5}, {"aid": "1904.06813", "authors": ["Changhua Pei", "Yi Zhang", "Yongfeng Zhang", "Fei Sun", "Xiao Lin", "Hanxiao Sun", "Jian Wu", "Peng Jiang", "Wenwu Ou"], "title": "Personalized Re-ranking for Recommendation", "url": "http://arxiv.org/pdf/1904.06813v3", "summary": "Ranking is a core task in recommender systems, which aims at providing an\nordered list of items to users. Typically, a ranking function is learned from\nthe labeled dataset to optimize the global performance, which produces a\nranking score for each individual item. However, it may be sub-optimal because\nthe scoring function applies to each item individually and does not explicitly\nconsider the mutual influence between items, as well as the differences of\nusers' preferences or intents. Therefore, we propose a personalized re-ranking\nmodel for recommender systems. The proposed re-ranking model can be easily\ndeployed as a follow-up modular after any ranking algorithm, by directly using\nthe existing ranking feature vectors. It directly optimizes the whole\nrecommendation list by employing a transformer structure to efficiently encode\nthe information of all items in the list. Specifically, the Transformer applies\na self-attention mechanism that directly models the global relationships\nbetween any pair of items in the whole list. We confirm that the performance\ncan be further improved by introducing pre-trained embedding to learn\npersonalized encoding functions for different users. Experimental results on\nboth offline benchmarks and real-world online e-commerce systems demonstrate\nthe significant improvements of the proposed re-ranking model.", "published": "2019-04-15T02:47:40Z", "version": 3}, {"aid": "1904.06836", "authors": ["Qilong Wang", "Jiangtao Xie", "Wangmeng Zuo", "Lei Zhang", "Peihua Li"], "title": "Deep CNNs Meet Global Covariance Pooling: Better Representation and Generalization", "url": "http://arxiv.org/pdf/1904.06836v2", "summary": "Compared with global average pooling in existing deep convolutional neural\nnetworks (CNNs), global covariance pooling can capture richer statistics of\ndeep features, having potential for improving representation and generalization\nabilities of deep CNNs. However, integration of global covariance pooling into\ndeep CNNs brings two challenges: (1) robust covariance estimation given deep\nfeatures of high dimension and small sample size; (2) appropriate usage of\ngeometry of covariances. To address these challenges, we propose a global\nMatrix Power Normalized COVariance (MPN-COV) Pooling. Our MPN-COV conforms to a\nrobust covariance estimator, very suitable for scenario of high dimension and\nsmall sample size. It can also be regarded as Power-Euclidean metric between\ncovariances, effectively exploiting their geometry. Furthermore, a global\nGaussian embedding network is proposed to incorporate first-order statistics\ninto MPN-COV. For fast training of MPN-COV networks, we implement an iterative\nmatrix square root normalization, avoiding GPU unfriendly eigen-decomposition\ninherent in MPN-COV. Additionally, progressive 1x1 convolutions and group\nconvolution are introduced to compress covariance representations. The proposed\nmethods are highly modular, readily plugged into existing deep CNNs. Extensive\nexperiments are conducted on large-scale object classification, scene\ncategorization, fine-grained visual recognition and texture classification,\nshowing our methods outperform the counterparts and obtain state-of-the-art\nperformance.", "published": "2019-04-15T04:30:01Z", "version": 2}, {"aid": "1904.07523", "authors": ["Saeed Anwar", "Salman Khan", "Nick Barnes"], "title": "A Deep Journey into Super-resolution: A survey", "url": "http://arxiv.org/pdf/1904.07523v3", "summary": "Deep convolutional networks based super-resolution is a fast-growing field\nwith numerous practical applications. In this exposition, we extensively\ncompare 30+ state-of-the-art super-resolution Convolutional Neural Networks\n(CNNs) over three classical and three recently introduced challenging datasets\nto benchmark single image super-resolution. We introduce a taxonomy for\ndeep-learning based super-resolution networks that groups existing methods into\nnine categories including linear, residual, multi-branch, recursive,\nprogressive, attention-based and adversarial designs. We also provide\ncomparisons between the models in terms of network complexity, memory\nfootprint, model input and output, learning details, the type of network losses\nand important architectural differences (e.g., depth, skip-connections,\nfilters). The extensive evaluation performed, shows the consistent and rapid\ngrowth in the accuracy in the past few years along with a corresponding boost\nin model complexity and the availability of large-scale datasets. It is also\nobserved that the pioneering methods identified as the benchmark have been\nsignificantly outperformed by the current contenders. Despite the progress in\nrecent years, we identify several shortcomings of existing techniques and\nprovide future research directions towards the solution of these open problems.", "published": "2019-04-16T08:08:14Z", "version": 3}, {"aid": "1904.07952", "authors": ["Linda Wang"], "title": "Response of Selective Attention in Middle Temporal Area", "url": "http://arxiv.org/pdf/1904.07952v1", "summary": "The primary visual cortex processes a large amount of visual information,\nhowever, due to its large receptive fields, when multiple stimuli fall within\none receptive field, there are computational problems. To solve this problem,\nthe visual system uses selective attention, which allocates resources to a\nspecific spatial location, to attend to one of the stimuli in the receptive\nfield. During this process, the center and width of the attending receptive\nfield change. The model presented in the paper, which is extended and altered\nfrom Bobier et al., simulates the selective attention between the primary\nvisual cortex, V1, and middle temporal (MT) area. The responses of the MT\ncolumns, which encode the target stimulus, are compared to the results of an\nexperiment conducted by Womelsdorf et al. on the receptive field shift and\nshrinkage in macaque MT area from selective attention. Based on the results,\nthe responses in the MT area are similar to the Gaussian shaped receptive\nfields found in the experiment. As well, the responses of the MT columns are\nalso measured for accuracy of representing the target visual stimulus and is\nfound to represent the stimulus with a root mean squared error around 0.17 to\n0.18. The paper also explores varying model parameters, such as the membrane\ntime constant and maximum firing rates, and how those affect the measurement.\nThis model is a start to modeling the responses of selective attention, however\nthere are still improvements that can be made to better compare with the\nexperiment, produce more accurate responses and incorporate more biologically\nplausible features.", "published": "2019-04-16T20:04:32Z", "version": 1}, {"aid": "1904.08128", "authors": ["Fabian Isensee", "Paul F. J\u00e4ger", "Simon A. A. Kohl", "Jens Petersen", "Klaus H. Maier-Hein"], "title": "Automated Design of Deep Learning Methods for Biomedical Image Segmentation", "url": "http://arxiv.org/pdf/1904.08128v2", "summary": "Biomedical imaging is a driver of scientific discovery and core component of\nmedical care, currently stimulated by the field of deep learning. While\nsemantic segmentation algorithms enable 3D image analysis and quantification in\nmany applications, the design of respective specialised solutions is\nnon-trivial and highly dependent on dataset properties and hardware conditions.\nWe propose nnU-Net, a deep learning framework that condenses the current domain\nknowledge and autonomously takes the key decisions required to transfer a basic\narchitecture to different datasets and segmentation tasks. Without manual\ntuning, nnU-Net surpasses most specialised deep learning pipelines in 19 public\ninternational competitions and sets a new state of the art in the majority of\nthe 49 tasks. The results demonstrate a vast hidden potential in the systematic\nadaptation of deep learning methods to different datasets. We make nnU-Net\npublicly available as an open-source tool that can effectively be used\nout-of-the-box, rendering state of the art segmentation accessible to\nnon-experts and catalyzing scientific progress as a framework for automated\nmethod design.", "published": "2019-04-17T08:30:17Z", "version": 2}, {"aid": "1904.08935", "authors": ["Alan H. Gee", "Diego Garcia-Olano", "Joydeep Ghosh", "David Paydarfar"], "title": "Explaining Deep Classification of Time-Series Data with Learned Prototypes", "url": "http://arxiv.org/pdf/1904.08935v3", "summary": "The emergence of deep learning networks raises a need for explainable AI so\nthat users and domain experts can be confident applying them to high-risk\ndecisions. In this paper, we leverage data from the latent space induced by\ndeep learning models to learn stereotypical representations or \"prototypes\"\nduring training to elucidate the algorithmic decision-making process. We study\nhow leveraging prototypes effect classification decisions of two dimensional\ntime-series data in a few different settings: (1) electrocardiogram (ECG)\nwaveforms to detect clinical bradycardia, a slowing of heart rate, in preterm\ninfants, (2) respiration waveforms to detect apnea of prematurity, and (3)\naudio waveforms to classify spoken digits. We improve upon existing models by\noptimizing for increased prototype diversity and robustness, visualize how\nthese prototypes in the latent space are used by the model to distinguish\nclasses, and show that prototypes are capable of learning features on two\ndimensional time-series data to produce explainable insights during\nclassification tasks. We show that the prototypes are capable of learning\nreal-world features - bradycardia in ECG, apnea in respiration, and\narticulation in speech - as well as features within sub-classes. Our novel work\nleverages learned prototypical framework on two dimensional time-series data to\nproduce explainable insights during classification tasks.", "published": "2019-04-18T07:14:45Z", "version": 3}, {"aid": "1904.08939", "authors": ["Anh Nguyen", "Jason Yosinski", "Jeff Clune"], "title": "Understanding Neural Networks via Feature Visualization: A survey", "url": "http://arxiv.org/pdf/1904.08939v1", "summary": "A neuroscience method to understanding the brain is to find and study the\npreferred stimuli that highly activate an individual cell or groups of cells.\nRecent advances in machine learning enable a family of methods to synthesize\npreferred stimuli that cause a neuron in an artificial or biological brain to\nfire strongly. Those methods are known as Activation Maximization (AM) or\nFeature Visualization via Optimization. In this chapter, we (1) review existing\nAM techniques in the literature; (2) discuss a probabilistic interpretation for\nAM; and (3) review the applications of AM in debugging and explaining networks.", "published": "2019-04-18T15:46:26Z", "version": 1}, {"aid": "1904.09120", "authors": ["Yunze Man", "Yangsibo Huang", "Junyi Feng", "Xi Li", "Fei Wu"], "title": "Deep Q Learning Driven CT Pancreas Segmentation with Geometry-Aware U-Net", "url": "http://arxiv.org/pdf/1904.09120v1", "summary": "Segmentation of pancreas is important for medical image analysis, yet it\nfaces great challenges of class imbalance, background distractions and\nnon-rigid geometrical features. To address these difficulties, we introduce a\nDeep Q Network(DQN) driven approach with deformable U-Net to accurately segment\nthe pancreas by explicitly interacting with contextual information and extract\nanisotropic features from pancreas. The DQN based model learns a\ncontext-adaptive localization policy to produce a visually tightened and\nprecise localization bounding box of the pancreas. Furthermore, deformable\nU-Net captures geometry-aware information of pancreas by learning geometrically\ndeformable filters for feature extraction. Experiments on NIH dataset validate\nthe effectiveness of the proposed framework in pancreas segmentation.", "published": "2019-04-19T08:36:21Z", "version": 1}, {"aid": "1904.09658", "authors": ["Yichun Shi", "Anil K. Jain"], "title": "Probabilistic Face Embeddings", "url": "http://arxiv.org/pdf/1904.09658v4", "summary": "Embedding methods have achieved success in face recognition by comparing\nfacial features in a latent semantic space. However, in a fully unconstrained\nface setting, the facial features learned by the embedding model could be\nambiguous or may not even be present in the input face, leading to noisy\nrepresentations. We propose Probabilistic Face Embeddings (PFEs), which\nrepresent each face image as a Gaussian distribution in the latent space. The\nmean of the distribution estimates the most likely feature values while the\nvariance shows the uncertainty in the feature values. Probabilistic solutions\ncan then be naturally derived for matching and fusing PFEs using the\nuncertainty information. Empirical evaluation on different baseline models,\ntraining datasets and benchmarks show that the proposed method can improve the\nface recognition performance of deterministic embeddings by converting them\ninto PFEs. The uncertainties estimated by PFEs also serve as good indicators of\nthe potential matching accuracy, which are important for a risk-controlled\nrecognition system.", "published": "2019-04-21T21:08:00Z", "version": 4}, {"aid": "1904.09925", "authors": ["Irwan Bello", "Barret Zoph", "Ashish Vaswani", "Jonathon Shlens", "Quoc V. Le"], "title": "Attention Augmented Convolutional Networks", "url": "http://arxiv.org/pdf/1904.09925v5", "summary": "Convolutional networks have been the paradigm of choice in many computer\nvision applications. The convolution operation however has a significant\nweakness in that it only operates on a local neighborhood, thus missing global\ninformation. Self-attention, on the other hand, has emerged as a recent advance\nto capture long range interactions, but has mostly been applied to sequence\nmodeling and generative modeling tasks. In this paper, we consider the use of\nself-attention for discriminative visual tasks as an alternative to\nconvolutions. We introduce a novel two-dimensional relative self-attention\nmechanism that proves competitive in replacing convolutions as a stand-alone\ncomputational primitive for image classification. We find in control\nexperiments that the best results are obtained when combining both convolutions\nand self-attention. We therefore propose to augment convolutional operators\nwith this self-attention mechanism by concatenating convolutional feature maps\nwith a set of feature maps produced via self-attention. Extensive experiments\nshow that Attention Augmentation leads to consistent improvements in image\nclassification on ImageNet and object detection on COCO across many different\nmodels and scales, including ResNets and a state-of-the art mobile constrained\nnetwork, while keeping the number of parameters similar. In particular, our\nmethod achieves a $1.3\\%$ top-1 accuracy improvement on ImageNet classification\nover a ResNet50 baseline and outperforms other attention mechanisms for images\nsuch as Squeeze-and-Excitation. It also achieves an improvement of 1.4 mAP in\nCOCO Object Detection on top of a RetinaNet baseline.", "published": "2019-04-22T15:31:15Z", "version": 5}, {"aid": "1904.10255", "authors": ["Ahmed Imtiaz Humayun", "Asif Shahriyar Sushmit", "Taufiq Hasan", "Mohammed Imamul Hassan Bhuiyan"], "title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets", "url": "http://arxiv.org/pdf/1904.10255v1", "summary": "Humans approximately spend a third of their life sleeping, which makes\nmonitoring sleep an integral part of well-being. In this paper, a 34-layer deep\nresidual ConvNet architecture for end-to-end sleep staging is proposed. The\nnetwork takes raw single channel electroencephalogram (Fpz-Cz) signal as input\nand yields hypnogram annotations for each 30s segments as output. Experiments\nare carried out for two different scoring standards (5 and 6 stage\nclassification) on the expanded PhysioNet Sleep-EDF dataset, which contains\nmulti-source data from hospital and household polysomnography setups. The\nperformance of the proposed network is compared with that of the\nstate-of-the-art algorithms in patient independent validation tasks. The\nexperimental results demonstrate the superiority of the proposed network\ncompared to the best existing method, providing a relative improvement in\nepoch-wise average accuracy of 6.8% and 6.3% on the household data and\nmulti-source data, respectively. Codes are made publicly available on Github.", "published": "2019-04-23T11:32:46Z", "version": 1}, {"aid": "1904.10405", "authors": ["Jacques Carette", "William M. Farmer", "Michael Kohlhase", "Florian Rabe"], "title": "Big Math and the One-Brain Barrier A Position Paper and Architecture Proposal", "url": "http://arxiv.org/pdf/1904.10405v2", "summary": "Over the last decades, a class of important mathematical results have\nrequired an ever increasing amount of human effort to carry out. For some, the\nhelp of computers is now indispensable. We analyze the implications of this\ntrend towards \"big mathematics\", its relation to human cognition, and how\nmachine support for big math can be organized. The central contribution of this\nposition paper is an information model for \"doing mathematics\", which posits\nthat humans very efficiently integrate four aspects: inference, computation,\ntabulation, and narration around a well-organized core of mathematical\nknowledge. The challenge for mathematical software systems is that these four\naspects need to be integrated as well. We briefly survey the state of the art.", "published": "2019-04-23T16:15:52Z", "version": 2}, {"aid": "1904.10424", "authors": ["Shengcai Liao", "Ling Shao"], "title": "Interpretable and Generalizable Person Re-Identification with Query-Adaptive Convolution and Temporal Lifting", "url": "http://arxiv.org/pdf/1904.10424v4", "summary": "For person re-identification, existing deep networks often focus on\nrepresentation learning. However, without transfer learning, the learned model\nis fixed as is, which is not adaptable for handling various unseen scenarios.\nIn this paper, beyond representation learning, we consider how to formulate\nperson image matching directly in deep feature maps. We treat image matching as\nfinding local correspondences in feature maps, and construct query-adaptive\nconvolution kernels on the fly to achieve local matching. In this way, the\nmatching process and results are interpretable, and this explicit matching is\nmore generalizable than representation features to unseen scenarios, such as\nunknown misalignments, pose or viewpoint changes. To facilitate end-to-end\ntraining of this architecture, we further build a class memory module to cache\nfeature maps of the most recent samples of each class, so as to compute image\nmatching losses for metric learning. Through direct cross-dataset evaluation,\nthe proposed Query-Adaptive Convolution (QAConv) method gains large\nimprovements over popular learning methods (about 10%+ mAP), and achieves\ncomparable results to many transfer learning methods. Besides, a model-free\ntemporal cooccurrence based score weighting method called TLift is proposed,\nwhich improves the performance to a further extent, achieving state-of-the-art\nresults in cross-dataset person re-identification. Code is available at\nhttps://github.com/ShengcaiLiao/QAConv.", "published": "2019-04-23T17:03:13Z", "version": 4}, {"aid": "1904.10489", "authors": ["Jingpeng Wu", "William M. Silversmith", "Kisuk Lee", "H. Sebastian Seung"], "title": "Chunkflow: Distributed Hybrid Cloud Processing of Large 3D Images by Convolutional Nets", "url": "http://arxiv.org/pdf/1904.10489v3", "summary": "It is now common to process volumetric biomedical images using 3D\nConvolutional Networks (ConvNets). This can be challenging for the teravoxel\nand even petavoxel images that are being acquired today by light or electron\nmicroscopy. Here we introduce chunkflow, a software framework for distributing\nConvNet processing over local and cloud GPUs and CPUs. The image volume is\ndivided into overlapping chunks, each chunk is processed by a ConvNet, and the\nresults are blended together to yield the output image. The frontend submits\nConvNet tasks to a cloud queue. The tasks are executed by local and cloud GPUs\nand CPUs. Thanks to the fault-tolerant architecture of Chunkflow, cost can be\ngreatly reduced by utilizing cheap unstable cloud instances. Chunkflow\ncurrently supports PyTorch for GPUs and PZnet for CPUs. To illustrate its\nusage, a large 3D brain image from serial section electron microscopy was\nprocessed by a 3D ConvNet with a U-Net style architecture. Chunkflow provides\nsome chunk operations for general use, and the operations can be composed\nflexibly in a command line interface.", "published": "2019-04-23T18:47:57Z", "version": 3}, {"aid": "1904.10619", "authors": ["Hongzhu Li", "Weiqiang Wang"], "title": "Reinterpreting CTC training as iterative fitting", "url": "http://arxiv.org/pdf/1904.10619v2", "summary": "The connectionist temporal classification (CTC) enables end-to-end sequence\nlearning by maximizing the probability of correctly recognizing sequences\nduring training. The outputs of a CTC-trained model tend to form a series of\nspikes separated by strongly predicted blanks, know as the spiky problem. To\nfigure out the reason for it, we reinterpret the CTC training process as an\niterative fitting task that is based on frame-wise cross-entropy loss. It\noffers us an intuitive way to compare target probabilities with model outputs\nfor each iteration, and explain how the model outputs gradually turns spiky.\nInspired by it, we put forward two ways to modify the CTC training. The\nexperiments demonstrate that our method can well solve the spiky problem and\nmoreover, lead to faster convergence over various training settings. Beside\nthis, the reinterpretation of CTC, as a brand new perspective, may be\npotentially useful in other situations. The code is publicly available at\nhttps://github.com/hzli-ucas/caffe/tree/ctc.", "published": "2019-04-24T02:50:29Z", "version": 2}, {"aid": "1904.10633", "authors": ["Yonghao He", "Dezhong Xu", "Lifang Wu", "Meng Jian", "Shiming Xiang", "Chunhong Pan"], "title": "LFFD: A Light and Fast Face Detector for Edge Devices", "url": "http://arxiv.org/pdf/1904.10633v3", "summary": "Face detection, as a fundamental technology for various applications, is\nalways deployed on edge devices which have limited memory storage and low\ncomputing power. This paper introduces a Light and Fast Face Detector (LFFD)\nfor edge devices. The proposed method is anchor-free and belongs to the\none-stage category. Specifically, we rethink the importance of receptive field\n(RF) and effective receptive field (ERF) in the background of face detection.\nEssentially, the RFs of neurons in a certain layer are distributed regularly in\nthe input image and theses RFs are natural \"anchors\". Combining RF \"anchors\"\nand appropriate RF strides, the proposed method can detect a large range of\ncontinuous face scales with 100% coverage in theory. The insightful\nunderstanding of relations between ERF and face scales motivates an efficient\nbackbone for one-stage detection. The backbone is characterized by eight\ndetection branches and common layers, resulting in efficient computation.\nComprehensive and extensive experiments on popular benchmarks: WIDER FACE and\nFDDB are conducted. A new evaluation schema is proposed for\napplication-oriented scenarios. Under the new schema, the proposed method can\nachieve superior accuracy (WIDER FACE Val/Test -- Easy: 0.910/0.896, Medium:\n0.881/0.865, Hard: 0.780/0.770; FDDB -- discontinuous: 0.973, continuous:\n0.724). Multiple hardware platforms are introduced to evaluate the running\nefficiency. The proposed method can obtain fast inference speed (NVIDIA TITAN\nXp: 131.45 FPS at 640x480; NVIDIA TX2: 136.99 PFS at 160x120; Raspberry Pi 3\nModel B+: 8.44 FPS at 160x120) with model size of 9 MB.", "published": "2019-04-24T03:47:24Z", "version": 3}, {"aid": "1904.10644", "authors": ["Yu Chen", "Tom Diethe", "Neil Lawrence"], "title": "Facilitating Bayesian Continual Learning by Natural Gradients and Stein Gradients", "url": "http://arxiv.org/pdf/1904.10644v1", "summary": "Continual learning aims to enable machine learning models to learn a general\nsolution space for past and future tasks in a sequential manner. Conventional\nmodels tend to forget the knowledge of previous tasks while learning a new\ntask, a phenomenon known as catastrophic forgetting. When using Bayesian models\nin continual learning, knowledge from previous tasks can be retained in two\nways: 1). posterior distributions over the parameters, containing the knowledge\ngained from inference in previous tasks, which then serve as the priors for the\nfollowing task; 2). coresets, containing knowledge of data distributions of\nprevious tasks. Here, we show that Bayesian continual learning can be\nfacilitated in terms of these two means through the use of natural gradients\nand Stein gradients respectively.", "published": "2019-04-24T05:18:32Z", "version": 1}, {"aid": "1904.10653", "authors": ["Xu Zhu"], "title": "Stochastic Lipschitz Q-Learning", "url": "http://arxiv.org/pdf/1904.10653v2", "summary": "In an episodic Markov Decision Process (MDP) problem, an online algorithm\nchooses from a set of actions in a sequence of $H$ trials, where $H$ is the\nepisode length, in order to maximize the total payoff of the chosen actions.\nQ-learning, as the most popular model-free reinforcement learning (RL)\nalgorithm, directly parameterizes and updates value functions without\nexplicitly modeling the environment. Recently, [Jin et al. 2018] studies the\nsample complexity of Q-learning with finite states and actions. Their algorithm\nachieves nearly optimal regret, which shows that Q-learning can be made sample\nefficient. However, MDPs with large discrete states and actions [Silver et al.\n2016] or continuous spaces [Mnih et al. 2013] cannot learn efficiently in this\nway. Hence, it is critical to develop new algorithms to solve this dilemma with\nprovable guarantee on the sample complexity. With this motivation, we propose a\nnovel algorithm that works for MDPs with a more general setting, which has\ninfinitely many states and actions and assumes that the payoff function and\ntransition kernel are Lipschitz continuous. We also provide corresponding\ntheory justification for our algorithm. It achieves the regret\n$\\tilde{\\mathcal{O}}(K^{\\frac{d+1}{d+2}}\\sqrt{H^3}),$ where $K$ denotes the\nnumber of episodes and $d$ denotes the dimension of the joint space. To the\nbest of our knowledge, this is the first analysis in the model-free setting\nwhose established regret matches the lower bound up to a logarithmic factor.", "published": "2019-04-24T06:25:42Z", "version": 2}, {"aid": "1904.12456", "authors": ["Yousef Jamali", "Mohammad Jamali", "Mehdi Golshani"], "title": "A new method of brain stimulation at ultra-high frequency", "url": "http://arxiv.org/pdf/1904.12456v1", "summary": "Nerve stimulation via micro-electrode implants is one of the neurostimulation\napproaches which is used frequently in the medical treatment of some brain\ndisorders, neural prosthetics, brain-machine interfaces and also in the cyborg.\nIn this method, the electrical stimulation signal can be categorized by the\nfrequency band: low frequency, high frequency, and ultra-high frequency. The\nstimulation should be less destructive, more smooth, and controllable. In this\narticle, we present a brief description of the mechanism underlying the\nultra-high frequency stimulation. In the flowing, from an informatics\nperspective, we propose a state-of-the-art, low destructive, and highly\nefficient stimulation method at the low amplitude ultra-high frequency signal.\nIn this method, we have tried to reduce the adaptation of the nerve system by\nmodulating the stimulation signal via a low frequency rectangular random wave.\nBy this method, we could reach the \"almost zero discharge\" with minimum\ndestructive effect in the experimental test on the fish nervous system.", "published": "2019-04-29T05:52:43Z", "version": 1}, {"aid": "1904.12460", "authors": ["Mohammad Jamali", "Yousef Jamali", "Mehdi Golshani"], "title": "Theory of cyborg: a new approach to fish locomotion control", "url": "http://arxiv.org/pdf/1904.12460v2", "summary": "Cyborg in the brain-machine interface field has attracted more attention in\nrecent years. To control a creature via a machine called cyborg method, three\nstages are considerable: stimulation of neurons, neural response, and the\nbehavioral reaction of the subject. Our main concern was to know how electrical\nstimulation induces neural activity and leads to a behavioral response.\nAdditionally, we were interested to explore which type of electrical\nstimulation is optimal from different aspects such as maximum response with\nminimum induction stimulus field, minimum damage of the tissue and the\nelectrode, reduction of the noxiousness of stimuli or pain in the living\ncreature. In this article, we proposed a new model for the induction of neural\nactivity led to locomotion responses through electrical stimulation.\nFurthermore, based on this model, we developed a new approach of electrical\nneural stimulation to provide a better locomotion control of living beings.\nThis approach was verified through the empirical data of fish cyborg. We\nstimulated the fish brain by use of an ultra-high frequency signal which\ncareered by a random low frequency. According to our model, we could control\nthe locomotion of fish in a novel and innovative way. In this study, we\ncategorized the different cyborg methods based on the nervous system areas and\nthe stimulation signal properties to reach the better and optimal behavioral\ncontrol of creature. According to this, we proposed a new stimulation method\ntheoretically and confirmed it experimentally.", "published": "2019-04-29T06:03:38Z", "version": 2}, {"aid": "1904.12848", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "title": "Unsupervised Data Augmentation for Consistency Training", "url": "http://arxiv.org/pdf/1904.12848v6", "summary": "Semi-supervised learning lately has shown much promise in improving deep\nlearning models when labeled data is scarce. Common among recent approaches is\nthe use of consistency training on a large amount of unlabeled data to\nconstrain model predictions to be invariant to input noise. In this work, we\npresent a new perspective on how to effectively noise unlabeled examples and\nargue that the quality of noising, specifically those produced by advanced data\naugmentation methods, plays a crucial role in semi-supervised learning. By\nsubstituting simple noising operations with advanced data augmentation methods\nsuch as RandAugment and back-translation, our method brings substantial\nimprovements across six language and three vision tasks under the same\nconsistency training framework. On the IMDb text classification dataset, with\nonly 20 labeled examples, our method achieves an error rate of 4.20,\noutperforming the state-of-the-art model trained on 25,000 labeled examples. On\na standard semi-supervised learning benchmark, CIFAR-10, our method outperforms\nall previous approaches and achieves an error rate of 5.43 with only 250\nexamples. Our method also combines well with transfer learning, e.g., when\nfinetuning from BERT, and yields improvements in high-data regime, such as\nImageNet, whether when there is only 10% labeled data or when a full labeled\nset with 1.3M extra unlabeled examples is used. Code is available at\nhttps://github.com/google-research/uda.", "published": "2019-04-29T17:56:59Z", "version": 6}, {"aid": "1904.13132", "authors": ["Yuki M. Asano", "Christian Rupprecht", "Andrea Vedaldi"], "title": "A critical analysis of self-supervision, or what we can learn from a single image", "url": "http://arxiv.org/pdf/1904.13132v3", "summary": "We look critically at popular self-supervision techniques for learning deep\nconvolutional neural networks without manual labels. We show that three\ndifferent and representative methods, BiGAN, RotNet and DeepCluster, can learn\nthe first few layers of a convolutional network from a single image as well as\nusing millions of images and manual labels, provided that strong data\naugmentation is used. However, for deeper layers the gap with manual\nsupervision cannot be closed even if millions of unlabelled images are used for\ntraining. We conclude that: (1) the weights of the early layers of deep\nnetworks contain limited information about the statistics of natural images,\nthat (2) such low-level statistics can be learned through self-supervision just\nas well as through strong supervision, and that (3) the low-level statistics\ncan be captured via synthetic transformations instead of using a large image\ndataset.", "published": "2019-04-30T10:10:38Z", "version": 3}, {"aid": "1905.01988", "authors": ["Xianbin Hong", "Gautam Pal", "Sheng-Uei Guan", "Prudence Wong", "Dawei Liu", "Ka Lok Man", "Xin Huang"], "title": "Semi-Unsupervised Lifelong Learning for Sentiment Classification: Less Manual Data Annotation and More Self-Studying", "url": "http://arxiv.org/pdf/1905.01988v2", "summary": "Lifelong machine learning is a novel machine learning paradigm which can\ncontinually accumulate knowledge during learning. The knowledge extracting and\nreusing abilities enable the lifelong machine learning to solve the related\nproblems. The traditional approaches like Na\\\"ive Bayes and some neural network\nbased approaches only aim to achieve the best performance upon a single task.\nUnlike them, the lifelong machine learning in this paper focuses on how to\naccumulate knowledge during learning and leverage them for further tasks.\nMeanwhile, the demand for labelled data for training also is significantly\ndecreased with the knowledge reusing. This paper suggests that the aim of the\nlifelong learning is to use less labelled data and computational cost to\nachieve the performance as well as or even better than the supervised learning.", "published": "2019-04-30T23:56:54Z", "version": 2}, {"aid": "1905.00780", "authors": ["Suraj Srinivas", "Francois Fleuret"], "title": "Full-Gradient Representation for Neural Network Visualization", "url": "http://arxiv.org/pdf/1905.00780v4", "summary": "We introduce a new tool for interpreting neural net responses, namely\nfull-gradients, which decomposes the neural net response into input sensitivity\nand per-neuron sensitivity components. This is the first proposed\nrepresentation which satisfies two key properties: completeness and weak\ndependence, which provably cannot be satisfied by any saliency map-based\ninterpretability method. For convolutional nets, we also propose an approximate\nsaliency map representation, called FullGrad, obtained by aggregating the\nfull-gradient components.\n  We experimentally evaluate the usefulness of FullGrad in explaining model\nbehaviour with two quantitative tests: pixel perturbation and\nremove-and-retrain. Our experiments reveal that our method explains model\nbehaviour correctly, and more comprehensively than other methods in the\nliterature. Visual inspection also reveals that our saliency maps are sharper\nand more tightly confined to object regions than other methods.", "published": "2019-05-02T14:41:31Z", "version": 4}, {"aid": "1905.01164", "authors": ["Tamar Rott Shaham", "Tali Dekel", "Tomer Michaeli"], "title": "SinGAN: Learning a Generative Model from a Single Natural Image", "url": "http://arxiv.org/pdf/1905.01164v2", "summary": "We introduce SinGAN, an unconditional generative model that can be learned\nfrom a single natural image. Our model is trained to capture the internal\ndistribution of patches within the image, and is then able to generate high\nquality, diverse samples that carry the same visual content as the image.\nSinGAN contains a pyramid of fully convolutional GANs, each responsible for\nlearning the patch distribution at a different scale of the image. This allows\ngenerating new samples of arbitrary size and aspect ratio, that have\nsignificant variability, yet maintain both the global structure and the fine\ntextures of the training image. In contrast to previous single image GAN\nschemes, our approach is not limited to texture images, and is not conditional\n(i.e. it generates samples from noise). User studies confirm that the generated\nsamples are commonly confused to be real images. We illustrate the utility of\nSinGAN in a wide range of image manipulation tasks.", "published": "2019-05-02T16:15:38Z", "version": 2}, {"aid": "1905.11437", "authors": ["Leonardo Enzo Brito da Silva", "Islam Elnabarawy", "Donald C. Wunsch II"], "title": "A Survey of Adaptive Resonance Theory Neural Network Models for Engineering Applications", "url": "http://arxiv.org/pdf/1905.11437v1", "summary": "This survey samples from the ever-growing family of adaptive resonance theory\n(ART) neural network models used to perform the three primary machine learning\nmodalities, namely, unsupervised, supervised and reinforcement learning. It\ncomprises a representative list from classic to modern ART models, thereby\npainting a general picture of the architectures developed by researchers over\nthe past 30 years. The learning dynamics of these ART models are briefly\ndescribed, and their distinctive characteristics such as code representation,\nlong-term memory and corresponding geometric interpretation are discussed.\nUseful engineering properties of ART (speed, configurability, explainability,\nparallelization and hardware implementation) are examined along with current\nchallenges. Finally, a compilation of online software libraries is provided. It\nis expected that this overview will be helpful to new and seasoned ART\nresearchers.", "published": "2019-05-04T00:54:06Z", "version": 1}, {"aid": "1905.02244", "authors": ["Andrew Howard", "Mark Sandler", "Grace Chu", "Liang-Chieh Chen", "Bo Chen", "Mingxing Tan", "Weijun Wang", "Yukun Zhu", "Ruoming Pang", "Vijay Vasudevan", "Quoc V. Le", "Hartwig Adam"], "title": "Searching for MobileNetV3", "url": "http://arxiv.org/pdf/1905.02244v5", "summary": "We present the next generation of MobileNets based on a combination of\ncomplementary search techniques as well as a novel architecture design.\nMobileNetV3 is tuned to mobile phone CPUs through a combination of\nhardware-aware network architecture search (NAS) complemented by the NetAdapt\nalgorithm and then subsequently improved through novel architecture advances.\nThis paper starts the exploration of how automated search algorithms and\nnetwork design can work together to harness complementary approaches improving\nthe overall state of the art. Through this process we create two new MobileNet\nmodels for release: MobileNetV3-Large and MobileNetV3-Small which are targeted\nfor high and low resource use cases. These models are then adapted and applied\nto the tasks of object detection and semantic segmentation. For the task of\nsemantic segmentation (or any dense pixel prediction), we propose a new\nefficient segmentation decoder Lite Reduced Atrous Spatial Pyramid Pooling\n(LR-ASPP). We achieve new state of the art results for mobile classification,\ndetection and segmentation. MobileNetV3-Large is 3.2\\% more accurate on\nImageNet classification while reducing latency by 15\\% compared to MobileNetV2.\nMobileNetV3-Small is 4.6\\% more accurate while reducing latency by 5\\% compared\nto MobileNetV2. MobileNetV3-Large detection is 25\\% faster at roughly the same\naccuracy as MobileNetV2 on COCO detection. MobileNetV3-Large LR-ASPP is 30\\%\nfaster than MobileNetV2 R-ASPP at similar accuracy for Cityscapes segmentation.", "published": "2019-05-06T19:38:31Z", "version": 5}, {"aid": "1905.02249", "authors": ["David Berthelot", "Nicholas Carlini", "Ian Goodfellow", "Nicolas Papernot", "Avital Oliver", "Colin Raffel"], "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning", "url": "http://arxiv.org/pdf/1905.02249v2", "summary": "Semi-supervised learning has proven to be a powerful paradigm for leveraging\nunlabeled data to mitigate the reliance on large labeled datasets. In this\nwork, we unify the current dominant approaches for semi-supervised learning to\nproduce a new algorithm, MixMatch, that works by guessing low-entropy labels\nfor data-augmented unlabeled examples and mixing labeled and unlabeled data\nusing MixUp. We show that MixMatch obtains state-of-the-art results by a large\nmargin across many datasets and labeled data amounts. For example, on CIFAR-10\nwith 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by\na factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a\ndramatically better accuracy-privacy trade-off for differential privacy.\nFinally, we perform an ablation study to tease apart which components of\nMixMatch are most important for its success.", "published": "2019-05-06T19:56:03Z", "version": 2}, {"aid": "1905.02876", "authors": ["Giorgos Bouritsas", "Sergiy Bokhnyak", "Stylianos Ploumpis", "Michael Bronstein", "Stefanos Zafeiriou"], "title": "Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape Representation Learning and Generation", "url": "http://arxiv.org/pdf/1905.02876v3", "summary": "Generative models for 3D geometric data arise in many important applications\nin 3D computer vision and graphics. In this paper, we focus on 3D deformable\nshapes that share a common topological structure, such as human faces and\nbodies. Morphable Models and their variants, despite their linear formulation,\nhave been widely used for shape representation, while most of the recently\nproposed nonlinear approaches resort to intermediate representations, such as\n3D voxel grids or 2D views. In this work, we introduce a novel graph\nconvolutional operator, acting directly on the 3D mesh, that explicitly models\nthe inductive bias of the fixed underlying graph. This is achieved by enforcing\nconsistent local orderings of the vertices of the graph, through the spiral\noperator, thus breaking the permutation invariance property that is adopted by\nall the prior work on Graph Neural Networks. Our operator comes by construction\nwith desirable properties (anisotropic, topology-aware, lightweight,\neasy-to-optimise), and by using it as a building block for traditional deep\ngenerative architectures, we demonstrate state-of-the-art results on a variety\nof 3D shape datasets compared to the linear Morphable Model and other graph\nconvolutional operators.", "published": "2019-05-08T02:37:27Z", "version": 3}, {"aid": "1905.03329", "authors": ["Charlie Frogner", "Farzaneh Mirzazadeh", "Justin Solomon"], "title": "Learning Embeddings into Entropic Wasserstein Spaces", "url": "http://arxiv.org/pdf/1905.03329v1", "summary": "Euclidean embeddings of data are fundamentally limited in their ability to\ncapture latent semantic structures, which need not conform to Euclidean spatial\nassumptions. Here we consider an alternative, which embeds data as discrete\nprobability distributions in a Wasserstein space, endowed with an optimal\ntransport metric. Wasserstein spaces are much larger and more flexible than\nEuclidean spaces, in that they can successfully embed a wider variety of metric\nstructures. We exploit this flexibility by learning an embedding that captures\nsemantic information in the Wasserstein distance between embedded\ndistributions. We examine empirically the representational capacity of our\nlearned Wasserstein embeddings, showing that they can embed a wide variety of\nmetric structures with smaller distortion than an equivalent Euclidean\nembedding. We also investigate an application to word embedding, demonstrating\na unique advantage of Wasserstein embeddings: We can visualize the\nhigh-dimensional embedding directly, since it is a probability distribution on\na low-dimensional space. This obviates the need for dimensionality reduction\ntechniques like t-SNE for visualization.", "published": "2019-05-08T20:48:28Z", "version": 1}, {"aid": "1905.03658", "authors": ["Jason Ramapuram", "Russ Webb"], "title": "Improving Discrete Latent Representations With Differentiable Approximation Bridges", "url": "http://arxiv.org/pdf/1905.03658v3", "summary": "Modern neural network training relies on piece-wise (sub-)differentiable\nfunctions in order to use backpropagation to update model parameters. In this\nwork, we introduce a novel method to allow simple non-differentiable functions\nat intermediary layers of deep neural networks. We do so by training with a\ndifferentiable approximation bridge (DAB) neural network which approximates the\nnon-differentiable forward function and provides gradient updates during\nbackpropagation. We present strong empirical results (performing over 600\nexperiments) in four different domains: unsupervised (image) representation\nlearning, variational (image) density estimation, image classification, and\nsequence sorting to demonstrate that our proposed method improves state of the\nart performance. We demonstrate that training with DAB aided discrete\nnon-differentiable functions improves image reconstruction quality and\nposterior linear separability by 10% against the Gumbel-Softmax relaxed\nestimator [37, 26] as well as providing a 9% improvement in the test\nvariational lower bound in comparison to the state of the art RELAX [16]\ndiscrete estimator. We also observe an accuracy improvement of 77% in neural\nsequence sorting and a 25% improvement against the straight-through estimator\n[5] in an image classification setting. The DAB network is not used for\ninference and expands the class of functions that are usable in neural\nnetworks.", "published": "2019-05-09T14:31:59Z", "version": 3}, {"aid": "1905.04149", "authors": ["Xiang Zhang", "Lina Yao", "Xianzhi Wang", "Jessica Monaghan", "David Mcalpine", "Yu Zhang"], "title": "A Survey on Deep Learning-based Non-Invasive Brain Signals:Recent Advances and New Frontiers", "url": "http://arxiv.org/pdf/1905.04149v5", "summary": "Brain-Computer Interface (BCI) bridges the human's neural world and the outer\nphysical world by decoding individuals' brain signals into commands\nrecognizable by computer devices. Deep learning has lifted the performance of\nbrain-computer interface systems significantly in recent years. In this\narticle, we systematically investigate brain signal types for BCI and related\ndeep learning concepts for brain signal analysis. We then present a\ncomprehensive survey of deep learning techniques used for BCI, by summarizing\nover 230 contributions most published in the past five years. Finally, we\ndiscuss the applied areas, opening challenges, and future directions for deep\nlearning-based BCI.", "published": "2019-05-10T13:04:00Z", "version": 5}, {"aid": "1905.04215", "authors": ["Xudong Mao", "Yun Ma", "Zhenguo Yang", "Yangbin Chen", "Qing Li"], "title": "Virtual Mixup Training for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/1905.04215v4", "summary": "We study the problem of unsupervised domain adaptation which aims to adapt\nmodels trained on a labeled source domain to a completely unlabeled target\ndomain. Recently, the cluster assumption has been applied to unsupervised\ndomain adaptation and achieved strong performance. One critical factor in\nsuccessful training of the cluster assumption is to impose the\nlocally-Lipschitz constraint to the model. Existing methods only impose the\nlocally-Lipschitz constraint around the training points while miss the other\nareas, such as the points in-between training data. In this paper, we address\nthis issue by encouraging the model to behave linearly in-between training\npoints. We propose a new regularization method called Virtual Mixup Training\n(VMT), which is able to incorporate the locally-Lipschitz constraint to the\nareas in-between training data. Unlike the traditional mixup model, our method\nconstructs the combination samples without using the label information,\nallowing it to apply to unsupervised domain adaptation. The proposed method is\ngeneric and can be combined with most existing models such as the recent\nstate-of-the-art model called VADA. Extensive experiments demonstrate that VMT\nsignificantly improves the performance of VADA on six domain adaptation\nbenchmark datasets. For the challenging task of adapting MNIST to SVHN, VMT can\nimprove the accuracy of VADA by over 30\\%. Code is available at\n\\url{https://github.com/xudonmao/VMT}.", "published": "2019-05-10T15:24:17Z", "version": 4}, {"aid": "1905.04243", "authors": ["Zhengwei Wang", "Qi She", "Alan F. Smeaton", "Tomas E. Ward", "Graham Healy"], "title": "Synthetic-Neuroscore: Using A Neuro-AI Interface for Evaluating Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1905.04243v2", "summary": "Generative adversarial networks (GANs) are increasingly attracting attention\nin the computer vision, natural language processing, speech synthesis and\nsimilar domains. Arguably the most striking results have been in the area of\nimage synthesis. However, evaluating the performance of GANs is still an open\nand challenging problem. Existing evaluation metrics primarily measure the\ndissimilarity between real and generated images using automated statistical\nmethods. They often require large sample sizes for evaluation and do not\ndirectly reflect human perception of image quality. In this work, we describe\nan evaluation metric we call Neuroscore, for evaluating the performance of\nGANs, that more directly reflects psychoperceptual image quality through the\nutilization of brain signals. Our results show that Neuroscore has superior\nperformance to the current evaluation metrics in that: (1) It is more\nconsistent with human judgment; (2) The evaluation process needs much smaller\nnumbers of samples; and (3) It is able to rank the quality of images on a per\nGAN basis. A convolutional neural network (CNN) based neuro-AI interface is\nproposed to predict Neuroscore from GAN-generated images directly without the\nneed for neural responses. Importantly, we show that including neural responses\nduring the training phase of the network can significantly improve the\nprediction capability of the proposed model. Materials related to this work are\nprovided at https://github.com/villawang/Neuro-AI-Interface.", "published": "2019-05-10T16:25:07Z", "version": 2}, {"aid": "1906.01704", "authors": ["Yang Li", "Wenming Zheng", "Lei Wang", "Yuan Zong", "Lei Qi", "Zhen Cui", "Tong Zhang", "Tengfei Song"], "title": "A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition", "url": "http://arxiv.org/pdf/1906.01704v1", "summary": "The neuroscience study has revealed the discrepancy of emotion expression\nbetween left and right hemispheres of human brain. Inspired by this study, in\nthis paper, we propose a novel bi-hemispheric discrepancy model (BiHDM) to\nlearn the asymmetric differences between two hemispheres for\nelectroencephalograph (EEG) emotion recognition. Concretely, we first employ\nfour directed recurrent neural networks (RNNs) based on two spatial\norientations to traverse electrode signals on two separate brain regions, which\nenables the model to obtain the deep representations of all the EEG electrodes'\nsignals while keeping the intrinsic spatial dependence. Then we design a\npairwise subnetwork to capture the discrepancy information between two\nhemispheres and extract higher-level features for final classification.\nBesides, in order to reduce the domain shift between training and testing data,\nwe use a domain discriminator that adversarially induces the overall feature\nlearning module to generate emotion-related but domain-invariant feature, which\ncan further promote EEG emotion recognition. We conduct experiments on three\npublic EEG emotional datasets, and the experiments show that the new\nstate-of-the-art results can be achieved.", "published": "2019-05-11T01:17:22Z", "version": 1}, {"aid": "1905.05055", "authors": ["Zhengxia Zou", "Keyan Chen", "Zhenwei Shi", "Yuhong Guo", "Jieping Ye"], "title": "Object Detection in 20 Years: A Survey", "url": "http://arxiv.org/pdf/1905.05055v3", "summary": "Object detection, as of one the most fundamental and challenging problems in\ncomputer vision, has received great attention in recent years. Over the past\ntwo decades, we have seen a rapid technological evolution of object detection\nand its profound impact on the entire computer vision field. If we consider\ntoday's object detection technique as a revolution driven by deep learning,\nthen back in the 1990s, we would see the ingenious thinking and long-term\nperspective design of early computer vision. This paper extensively reviews\nthis fast-moving research field in the light of technical evolution, spanning\nover a quarter-century's time (from the 1990s to 2022). A number of topics have\nbeen covered in this paper, including the milestone detectors in history,\ndetection datasets, metrics, fundamental building blocks of the detection\nsystem, speed-up techniques, and the recent state-of-the-art detection methods.", "published": "2019-05-13T14:26:50Z", "version": 3}, {"aid": "1905.06484", "authors": ["Wenyuan Li", "Zichen Wang", "Jiayun Li", "Jennifer Polson", "William Speier", "Corey Arnold"], "title": "Semi-supervised learning based on generative adversarial network: a comparison between good GAN and bad GAN approach", "url": "http://arxiv.org/pdf/1905.06484v2", "summary": "Recently, semi-supervised learning methods based on generative adversarial\nnetworks (GANs) have received much attention. Among them, two distinct\napproaches have achieved competitive results on a variety of benchmark\ndatasets. Bad GAN learns a classifier with unrealistic samples distributed on\nthe complement of the support of the input data. Conversely, Triple GAN\nconsists of a three-player game that tries to leverage good generated samples\nto boost classification results. In this paper, we perform a comprehensive\ncomparison of these two approaches on different benchmark datasets. We\ndemonstrate their different properties on image generation, and sensitivity to\nthe amount of labeled data provided. By comprehensively comparing these two\nmethods, we hope to shed light on the future of GAN-based semi-supervised\nlearning.", "published": "2019-05-16T00:43:47Z", "version": 2}, {"aid": "1905.07177", "authors": ["Hui Yin", "Yuanhao Gong", "Guoping Qiu"], "title": "Side Window Filtering", "url": "http://arxiv.org/pdf/1905.07177v1", "summary": "Local windows are routinely used in computer vision and almost without\nexception the center of the window is aligned with the pixels being processed.\nWe show that this conventional wisdom is not universally applicable. When a\npixel is on an edge, placing the center of the window on the pixel is one of\nthe fundamental reasons that cause many filtering algorithms to blur the edges.\nBased on this insight, we propose a new Side Window Filtering (SWF) technique\nwhich aligns the window's side or corner with the pixel being processed. The\nSWF technique is surprisingly simple yet theoretically rooted and very\neffective in practice. We show that many traditional linear and nonlinear\nfilters can be easily implemented under the SWF framework. Extensive analysis\nand experiments show that implementing the SWF principle can significantly\nimprove their edge preserving capabilities and achieve state of the art\nperformances in applications such as image smoothing, denoising, enhancement,\nstructure-preserving texture-removing, mutual-structure extraction, and HDR\ntone mapping. In addition to image filtering, we further show that the SWF\nprinciple can be extended to other applications involving the use of a local\nwindow. Using colorization by optimization as an example, we demonstrate that\nimplementing the SWF principle can effectively prevent artifacts such as color\nleakage associated with the conventional implementation. Given the ubiquity of\nwindow based operations in computer vision, the new SWF technique is likely to\nbenefit many more applications.", "published": "2019-05-17T09:39:53Z", "version": 1}, {"aid": "1905.07373", "authors": ["Chen Lin", "Minghao Guo", "Chuming Li", "Yuan Xin", "Wei Wu", "Dahua Lin", "Wanli Ouyang", "Junjie Yan"], "title": "Online Hyper-parameter Learning for Auto-Augmentation Strategy", "url": "http://arxiv.org/pdf/1905.07373v2", "summary": "Data augmentation is critical to the success of modern deep learning\ntechniques. In this paper, we propose Online Hyper-parameter Learning for\nAuto-Augmentation (OHL-Auto-Aug), an economical solution that learns the\naugmentation policy distribution along with network training. Unlike previous\nmethods on auto-augmentation that search augmentation strategies in an offline\nmanner, our method formulates the augmentation policy as a parameterized\nprobability distribution, thus allowing its parameters to be optimized jointly\nwith network parameters. Our proposed OHL-Auto-Aug eliminates the need of\nre-training and dramatically reduces the cost of the overall search process,\nwhile establishes significantly accuracy improvements over baseline models. On\nboth CIFAR-10 and ImageNet, our method achieves remarkable on search accuracy,\n60x faster on CIFAR-10 and 24x faster on ImageNet, while maintaining\ncompetitive accuracies.", "published": "2019-05-17T16:59:31Z", "version": 2}, {"aid": "1905.07375", "authors": ["Chuming Li", "Yuan Xin", "Chen Lin", "Minghao Guo", "Wei Wu", "Wanli Ouyang", "Junjie Yan"], "title": "AM-LFS: AutoML for Loss Function Search", "url": "http://arxiv.org/pdf/1905.07375v2", "summary": "Designing an effective loss function plays an important role in visual\nanalysis. Most existing loss function designs rely on hand-crafted heuristics\nthat require domain experts to explore the large design space, which is usually\nsub-optimal and time-consuming. In this paper, we propose AutoML for Loss\nFunction Search (AM-LFS) which leverages REINFORCE to search loss functions\nduring the training process. The key contribution of this work is the design of\nsearch space which can guarantee the generalization and transferability on\ndifferent vision tasks by including a bunch of existing prevailing loss\nfunctions in a unified formulation. We also propose an efficient optimization\nframework which can dynamically optimize the parameters of loss function's\ndistribution during training. Extensive experimental results on four benchmark\ndatasets show that, without any tricks, our method outperforms existing\nhand-crafted loss functions in various computer vision tasks.", "published": "2019-05-17T17:06:49Z", "version": 2}, {"aid": "1905.07562", "authors": ["Feng Qi", "Wenchuan Wu"], "title": "Human-like machine thinking: Language guided imagination", "url": "http://arxiv.org/pdf/1905.07562v2", "summary": "Human thinking requires the brain to understand the meaning of language\nexpression and to properly organize the thoughts flow using the language.\nHowever, current natural language processing models are primarily limited in\nthe word probability estimation. Here, we proposed a Language guided\nimagination (LGI) network to incrementally learn the meaning and usage of\nnumerous words and syntaxes, aiming to form a human-like machine thinking\nprocess. LGI contains three subsystems: (1) vision system that contains an\nencoder to disentangle the input or imagined scenarios into abstract population\nrepresentations, and an imagination decoder to reconstruct imagined scenario\nfrom higher level representations; (2) Language system, that contains a\nbinarizer to transfer symbol texts into binary vectors, an IPS (mimicking the\nhuman IntraParietal Sulcus, implemented by an LSTM) to extract the quantity\ninformation from the input texts, and a textizer to convert binary vectors into\ntext symbols; (3) a PFC (mimicking the human PreFrontal Cortex, implemented by\nan LSTM) to combine inputs of both language and vision representations, and\npredict text symbols and manipulated images accordingly. LGI has incrementally\nlearned eight different syntaxes (or tasks), with which a machine thinking loop\nhas been formed and validated by the proper interaction between language and\nvision system. The paper provides a new architecture to let the machine learn,\nunderstand and use language in a human-like way that could ultimately enable a\nmachine to construct fictitious 'mental' scenario and possess intelligence.", "published": "2019-05-18T09:23:00Z", "version": 2}, {"aid": "1905.12601", "authors": ["Harikrishnan N B", "Nithin Nagaraj"], "title": "A Novel Chaos Theory Inspired Neuronal Architecture", "url": "http://arxiv.org/pdf/1905.12601v1", "summary": "The practical success of widely used machine learning (ML) and deep learning\n(DL) algorithms in Artificial Intelligence (AI) community owes to availability\nof large datasets for training and huge computational resources. Despite the\nenormous practical success of AI, these algorithms are only loosely inspired\nfrom the biological brain and do not mimic any of the fundamental properties of\nneurons in the brain, one such property being the chaotic firing of biological\nneurons. This motivates us to develop a novel neuronal architecture where the\nindividual neurons are intrinsically chaotic in nature. By making use of the\ntopological transitivity property of chaos, our neuronal network is able to\nperform classification tasks with very less number of training samples. For the\nMNIST dataset, with as low as $0.1 \\%$ of the total training data, our method\noutperforms ML and matches DL in classification accuracy for up to $7$ training\nsamples/class. For the Iris dataset, our accuracy is comparable with ML\nalgorithms, and even with just two training samples/class, we report an\naccuracy as high as $95.8 \\%$. This work highlights the effectiveness of chaos\nand its properties for learning and paves the way for chaos-inspired neuronal\narchitectures by closely mimicking the chaotic nature of neurons in the brain.", "published": "2019-05-19T07:45:57Z", "version": 1}, {"aid": "1905.07870", "authors": ["Qingyun Wang", "Lifu Huang", "Zhiying Jiang", "Kevin Knight", "Heng Ji", "Mohit Bansal", "Yi Luan"], "title": "PaperRobot: Incremental Draft Generation of Scientific Ideas", "url": "http://arxiv.org/pdf/1905.07870v4", "summary": "We present a PaperRobot who performs as an automatic research assistant by\n(1) conducting deep understanding of a large collection of human-written papers\nin a target domain and constructing comprehensive background knowledge graphs\n(KGs); (2) creating new ideas by predicting links from the background KGs, by\ncombining graph attention and contextual text attention; (3) incrementally\nwriting some key elements of a new paper based on memory-attention networks:\nfrom the input title along with predicted related entities to generate a paper\nabstract, from the abstract to generate conclusion and future work, and finally\nfrom future work to generate a title for a follow-on paper. Turing Tests, where\na biomedical domain expert is asked to compare a system output and a\nhuman-authored string, show PaperRobot generated abstracts, conclusion and\nfuture work sections, and new titles are chosen over human-written ones up to\n30%, 24% and 12% of the time, respectively.", "published": "2019-05-20T04:41:10Z", "version": 4}, {"aid": "1905.10924", "authors": ["Zalan Gyenis", "Andras Kornai"], "title": "Naive probability", "url": "http://arxiv.org/pdf/1905.10924v2", "summary": "We describe a rational, but low resolution model of probability.", "published": "2019-05-20T22:32:21Z", "version": 2}, {"aid": "1905.09688", "authors": ["Ole-Christoffer Granmo", "Sondre Glimsdal", "Lei Jiao", "Morten Goodwin", "Christian W. Omlin", "Geir Thore Berge"], "title": "The Convolutional Tsetlin Machine", "url": "http://arxiv.org/pdf/1905.09688v5", "summary": "Convolutional neural networks (CNNs) have obtained astounding successes for\nimportant pattern recognition tasks, but they suffer from high computational\ncomplexity and the lack of interpretability. The recent Tsetlin Machine (TM)\nattempts to address this lack by using easy-to-interpret conjunctive clauses in\npropositional logic to solve complex pattern recognition problems. The TM\nprovides competitive accuracy in several benchmarks, while keeping the\nimportant property of interpretability. It further facilitates hardware-near\nimplementation since inputs, patterns, and outputs are expressed as bits, while\nrecognition and learning rely on straightforward bit manipulation. In this\npaper, we exploit the TM paradigm by introducing the Convolutional Tsetlin\nMachine (CTM), as an interpretable alternative to CNNs. Whereas the TM\ncategorizes an image by employing each clause once to the whole image, the CTM\nuses each clause as a convolution filter. That is, a clause is evaluated\nmultiple times, once per image patch taking part in the convolution. To make\nthe clauses location-aware, each patch is further augmented with its\ncoordinates within the image. The output of a convolution clause is obtained\nsimply by ORing the outcome of evaluating the clause on each patch. In the\nlearning phase of the TM, clauses that evaluate to 1 are contrasted against the\ninput. For the CTM, we instead contrast against one of the patches, randomly\nselected among the patches that made the clause evaluate to 1. Accordingly, the\nstandard Type I and Type II feedback of the classic TM can be employed\ndirectly, without further modification. The CTM obtains a peak test accuracy of\n99.4% on MNIST, 96.31% on Kuzushiji-MNIST, 91.5% on Fashion-MNIST, and 100.0%\non the 2D Noisy XOR Problem, which is competitive with results reported for\nsimple 4-layer CNNs, BinaryConnect, Logistic Circuits and an FPGA-accelerated\nBinary CNN.", "published": "2019-05-23T14:47:33Z", "version": 5}, {"aid": "1905.10037", "authors": ["Satoshi Nishida", "Yusuke Nakano", "Antoine Blanc", "Naoya Maeda", "Masataka Kado", "Shinji Nishimoto"], "title": "Brain-mediated Transfer Learning of Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1905.10037v3", "summary": "The human brain can effectively learn a new task from a small number of\nsamples, which indicate that the brain can transfer its prior knowledge to\nsolve tasks in different domains. This function is analogous to transfer\nlearning (TL) in the field of machine learning. TL uses a well-trained feature\nspace in a specific task domain to improve performance in new tasks with\ninsufficient training data. TL with rich feature representations, such as\nfeatures of convolutional neural networks (CNNs), shows high generalization\nability across different task domains. However, such TL is still insufficient\nin making machine learning attain generalization ability comparable to that of\nthe human brain. To examine if the internal representation of the brain could\nbe used to achieve more efficient TL, we introduce a method for TL mediated by\nhuman brains. Our method transforms feature representations of audiovisual\ninputs in CNNs into those in activation patterns of individual brains via their\nassociation learned ahead using measured brain responses. Then, to estimate\nlabels reflecting human cognition and behavior induced by the audiovisual\ninputs, the transformed representations are used for TL. We demonstrate that\nour brain-mediated TL (BTL) shows higher performance in the label estimation\nthan the standard TL. In addition, we illustrate that the estimations mediated\nby different brains vary from brain to brain, and the variability reflects the\nindividual variability in perception. Thus, our BTL provides a framework to\nimprove the generalization ability of machine-learning feature representations\nand enable machine learning to estimate human-like cognition and behavior,\nincluding individual variability.", "published": "2019-05-24T05:15:17Z", "version": 3}, {"aid": "1905.10404", "authors": ["Aadil Hayat", "Utsav Singh", "Vinay P. Namboodiri"], "title": "InfoRL: Interpretable Reinforcement Learning using Information Maximization", "url": "http://arxiv.org/pdf/1905.10404v1", "summary": "Recent advances in reinforcement learning have proved that given an\nenvironment we can learn to perform a task in that environment if we have\naccess to some form of a reward function (dense, sparse or derived from IRL).\nBut most of the algorithms focus on learning a single best policy to perform a\ngiven set of tasks. In this paper, we focus on an algorithm that learns to not\njust perform a task but different ways to perform the same task. As we know\nwhen the environment is complex enough there always exists multiple ways to\nperform a task. We show that using the concept of information maximization it\nis possible to learn latent codes for discovering multiple ways to perform any\ngiven task in an environment.", "published": "2019-05-24T18:47:09Z", "version": 1}, {"aid": "1905.10448", "authors": ["Michael Perlmutter", "Feng Gao", "Guy Wolf", "Matthew Hirn"], "title": "Geometric Wavelet Scattering Networks on Compact Riemannian Manifolds", "url": "http://arxiv.org/pdf/1905.10448v4", "summary": "The Euclidean scattering transform was introduced nearly a decade ago to\nimprove the mathematical understanding of convolutional neural networks.\nInspired by recent interest in geometric deep learning, which aims to\ngeneralize convolutional neural networks to manifold and graph-structured\ndomains, we define a geometric scattering transform on manifolds. Similar to\nthe Euclidean scattering transform, the geometric scattering transform is based\non a cascade of wavelet filters and pointwise nonlinearities. It is invariant\nto local isometries and stable to certain types of diffeomorphisms. Empirical\nresults demonstrate its utility on several geometric learning tasks. Our\nresults generalize the deformation stability and local translation invariance\nof Euclidean scattering, and demonstrate the importance of linking the used\nfilter structures to the underlying geometry of the data.", "published": "2019-05-24T21:19:04Z", "version": 4}, {"aid": "1905.10484", "authors": ["Keegan Lensink", "Bas Peters", "Eldad Haber"], "title": "Fully Hyperbolic Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1905.10484v3", "summary": "Convolutional Neural Networks (CNN) have recently seen tremendous success in\nvarious computer vision tasks. However, their application to problems with high\ndimensional input and output, such as high-resolution image and video\nsegmentation or 3D medical imaging, has been limited by various factors.\nPrimarily, in the training stage, it is necessary to store network activations\nfor back propagation. In these settings, the memory requirements associated\nwith storing activations can exceed what is feasible with current hardware,\nespecially for problems in 3D. Motivated by the propagation of signals over\nphysical networks, that are governed by the hyperbolic Telegraph equation, in\nthis work we introduce a fully conservative hyperbolic network for problems\nwith high dimensional input and output. We introduce a coarsening operation\nthat allows completely reversible CNNs by using a learnable Discrete Wavelet\nTransform and its inverse to both coarsen and interpolate the network state and\nchange the number of channels. We show that fully reversible networks are able\nto achieve results comparable to the state of the art in 4D time-lapse hyper\nspectral image segmentation and full 3D video segmentation, with a much lower\nmemory footprint that is a constant independent of the network depth. We also\nextend the use of such networks to Variational Auto Encoders with high\nresolution input and output.", "published": "2019-05-24T23:43:36Z", "version": 3}, {"aid": "1905.10575", "authors": ["Xiang Ma", "Liangzhe Chen", "Zhaohong Deng", "Peng Xu", "Qisheng Yan", "Kup-Sze Choi", "Shitong Wang"], "title": "Deep Image Feature Learning with Fuzzy Rules", "url": "http://arxiv.org/pdf/1905.10575v3", "summary": "The methods of extracting image features are the key to many image processing\ntasks. At present, the most popular method is the deep neural network which can\nautomatically extract robust features through end-to-end training instead of\nhand-crafted feature extraction. However, the deep neural network currently\nfaces many challenges: 1) its effectiveness is heavily dependent on large\ndatasets, so the computational complexity is very high; 2) it is usually\nregarded as a black box model with poor interpretability. To meet the above\nchallenges, a more interpretable and scalable feature learning method, i.e.,\ndeep image feature learning with fuzzy rules (DIFL-FR), is proposed in the\npaper, which combines the rule-based fuzzy modeling technique and the deep\nstacked learning strategy. The method progressively learns image features\nthrough a layer-by-layer manner based on fuzzy rules, so the feature learning\nprocess can be better explained by the generated rules. More importantly, the\nlearning process of the method is only based on forward propagation without\nback propagation and iterative learning, which results in the high learning\nefficiency. In addition, the method is under the settings of unsupervised\nlearning and can be easily extended to scenes of supervised and semi-supervised\nlearning. Extensive experiments are conducted on image datasets of different\nscales. The results obviously show the effectiveness of the proposed method.", "published": "2019-05-25T11:33:02Z", "version": 3}, {"aid": "1905.10671", "authors": ["Zhongzhan Huang", "Senwei Liang", "Mingfu Liang", "Haizhao Yang"], "title": "DIANet: Dense-and-Implicit Attention Network", "url": "http://arxiv.org/pdf/1905.10671v2", "summary": "Attention networks have successfully boosted the performance in various\nvision problems. Previous works lay emphasis on designing a new attention\nmodule and individually plug them into the networks. Our paper proposes a\nnovel-and-simple framework that shares an attention module throughout different\nnetwork layers to encourage the integration of layer-wise information and this\nparameter-sharing module is referred as Dense-and-Implicit-Attention (DIA)\nunit. Many choices of modules can be used in the DIA unit. Since Long Short\nTerm Memory (LSTM) has a capacity of capturing long-distance dependency, we\nfocus on the case when the DIA unit is the modified LSTM (refer as DIA-LSTM).\nExperiments on benchmark datasets show that the DIA-LSTM unit is capable of\nemphasizing layer-wise feature interrelation and leads to significant\nimprovement of image classification accuracy. We further empirically show that\nthe DIA-LSTM has a strong regularization ability on stabilizing the training of\ndeep networks by the experiments with the removal of skip connections or Batch\nNormalization in the whole residual network. The code is released at\nhttps://github.com/gbup-group/DIANet.", "published": "2019-05-25T20:51:07Z", "version": 2}, {"aid": "1905.10681", "authors": ["Ahmed H. Qureshi", "Jacob J. Johnson", "Yuzhe Qin", "Taylor Henderson", "Byron Boots", "Michael C. Yip"], "title": "Composing Task-Agnostic Policies with Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1905.10681v2", "summary": "The composition of elementary behaviors to solve challenging transfer\nlearning problems is one of the key elements in building intelligent machines.\nTo date, there has been plenty of work on learning task-specific policies or\nskills but almost no focus on composing necessary, task-agnostic skills to find\na solution to new problems. In this paper, we propose a novel deep\nreinforcement learning-based skill transfer and composition method that takes\nthe agent's primitive policies to solve unseen tasks. We evaluate our method in\ndifficult cases where training policy through standard reinforcement learning\n(RL) or even hierarchical RL is either not feasible or exhibits high sample\ncomplexity. We show that our method not only transfers skills to new problem\nsettings but also solves the challenging environments requiring both task\nplanning and motion control with high data efficiency.", "published": "2019-05-25T21:40:38Z", "version": 2}, {"aid": "1905.10710", "authors": ["Alexander Tong", "Guy Wolf", "Smita Krishnaswamy"], "title": "Fixing Bias in Reconstruction-based Anomaly Detection with Lipschitz Discriminators", "url": "http://arxiv.org/pdf/1905.10710v3", "summary": "Anomaly detection is of great interest in fields where abnormalities need to\nbe identified and corrected (e.g., medicine and finance). Deep learning methods\nfor this task often rely on autoencoder reconstruction error, sometimes in\nconjunction with other errors. We show that this approach exhibits intrinsic\nbiases that lead to undesirable results. Reconstruction-based methods are\nsensitive to training-data outliers and simple-to-reconstruct points. Instead,\nwe introduce a new unsupervised Lipschitz anomaly discriminator that does not\nsuffer from these biases. Our anomaly discriminator is trained, similar to the\nones used in GANs, to detect the difference between the training data and\ncorruptions of the training data. We show that this procedure successfully\ndetects unseen anomalies with guarantees on those that have a certain\nWasserstein distance from the data or corrupted training set. These additions\nallow us to show improved performance on MNIST, CIFAR10, and health record\ndata.", "published": "2019-05-26T01:57:42Z", "version": 3}, {"aid": "1905.10836", "authors": ["Bingchen Liu", "Yizhe Zhu", "Zuohui Fu", "Gerard de Melo", "Ahmed Elgammal"], "title": "OOGAN: Disentangling GAN with One-Hot Sampling and Orthogonal Regularization", "url": "http://arxiv.org/pdf/1905.10836v5", "summary": "Exploring the potential of GANs for unsupervised disentanglement learning,\nthis paper proposes a novel GAN-based disentanglement framework with One-Hot\nSampling and Orthogonal Regularization (OOGAN). While previous works mostly\nattempt to tackle disentanglement learning through VAE and seek to implicitly\nminimize the Total Correlation (TC) objective with various sorts of\napproximation methods, we show that GANs have a natural advantage in\ndisentangling with an alternating latent variable (noise) sampling method that\nis straightforward and robust. Furthermore, we provide a brand-new perspective\non designing the structure of the generator and discriminator, demonstrating\nthat a minor structural change and an orthogonal regularization on model\nweights entails an improved disentanglement. Instead of experimenting on simple\ntoy datasets, we conduct experiments on higher-resolution images and show that\nOOGAN greatly pushes the boundary of unsupervised disentanglement.", "published": "2019-05-26T16:42:56Z", "version": 5}, {"aid": "1905.11006", "authors": ["Jiatao Gu", "Changhan Wang", "Jake Zhao"], "title": "Levenshtein Transformer", "url": "http://arxiv.org/pdf/1905.11006v2", "summary": "Modern neural sequence generation models are built to either generate tokens\nstep-by-step from scratch or (iteratively) modify a sequence of tokens bounded\nby a fixed length. In this work, we develop Levenshtein Transformer, a new\npartially autoregressive model devised for more flexible and amenable sequence\ngeneration. Unlike previous approaches, the atomic operations of our model are\ninsertion and deletion. The combination of them facilitates not only generation\nbut also sequence refinement allowing dynamic length changes. We also propose a\nset of new training techniques dedicated at them, effectively exploiting one as\nthe other's learning signal thanks to their complementary nature. Experiments\napplying the proposed model achieve comparable performance but much-improved\nefficiency on both generation (e.g. machine translation, text summarization)\nand refinement tasks (e.g. automatic post-editing). We further confirm the\nflexibility of our model by showing a Levenshtein Transformer trained by\nmachine translation can straightforwardly be used for automatic post-editing.", "published": "2019-05-27T07:08:12Z", "version": 2}, {"aid": "1905.11498", "authors": ["Chu Wang", "Babak Samari", "Vladimir Kim", "Siddhartha Chaudhuri", "Kaleem Siddiqi"], "title": "FAN: Focused Attention Networks", "url": "http://arxiv.org/pdf/1905.11498v3", "summary": "Attention networks show promise for both vision and language tasks, by\nemphasizing relationships between constituent elements through weighting\nfunctions. Such elements could be regions in an image output by a region\nproposal network, or words in a sentence, represented by word embedding. Thus\nfar the learning of attention weights has been driven solely by the\nminimization of task specific loss functions. We introduce a method for\nlearning attention weights to better emphasize informative pair-wise relations\nbetween entities. The key component is a novel center-mass cross entropy loss,\nwhich can be applied in conjunction with the task specific ones. We further\nintroduce a focused attention backbone to learn these attention weights for\ngeneral tasks. We demonstrate that the focused supervision leads to improved\nattention distribution across meaningful entities, and that it enhances the\nrepresentation by aggregating features from them. Our focused attention module\nleads to state-of-the-art recovery of relations in a relationship proposal task\nand boosts performance for various vision and language tasks.", "published": "2019-05-27T20:41:53Z", "version": 3}, {"aid": "1905.11926", "authors": ["Chengxi Ye", "Matthew Evanusa", "Hua He", "Anton Mitrokhin", "Tom Goldstein", "James A. Yorke", "Cornelia Ferm\u00fcller", "Yiannis Aloimonos"], "title": "Network Deconvolution", "url": "http://arxiv.org/pdf/1905.11926v4", "summary": "Convolution is a central operation in Convolutional Neural Networks (CNNs),\nwhich applies a kernel to overlapping regions shifted across the image.\nHowever, because of the strong correlations in real-world image data,\nconvolutional kernels are in effect re-learning redundant data. In this work,\nwe show that this redundancy has made neural network training challenging, and\npropose network deconvolution, a procedure which optimally removes pixel-wise\nand channel-wise correlations before the data is fed into each layer. Network\ndeconvolution can be efficiently calculated at a fraction of the computational\ncost of a convolution layer. We also show that the deconvolution filters in the\nfirst layer of the network resemble the center-surround structure found in\nbiological neurons in the visual regions of the brain. Filtering with such\nkernels results in a sparse representation, a desired property that has been\nmissing in the training of neural networks. Learning from the sparse\nrepresentation promotes faster convergence and superior results without the use\nof batch normalization. We apply our network deconvolution operation to 10\nmodern neural network models by replacing batch normalization within each.\nExtensive experiments show that the network deconvolution operation is able to\ndeliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST,\nFashion-MNIST, Cityscapes, and ImageNet datasets.", "published": "2019-05-28T16:38:34Z", "version": 4}, {"aid": "1905.13545", "authors": ["Haohan Wang", "Xindi Wu", "Zeyi Huang", "Eric P. Xing"], "title": "High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1905.13545v3", "summary": "We investigate the relationship between the frequency spectrum of image data\nand the generalization behavior of convolutional neural networks (CNN). We\nfirst notice CNN's ability in capturing the high-frequency components of\nimages. These high-frequency components are almost imperceptible to a human.\nThus the observation leads to multiple hypotheses that are related to the\ngeneralization behaviors of CNN, including a potential explanation for\nadversarial examples, a discussion of CNN's trade-off between robustness and\naccuracy, and some evidence in understanding training heuristics.", "published": "2019-05-28T19:42:04Z", "version": 3}, {"aid": "1905.12100", "authors": ["Owen Marschall", "Kyunghyun Cho", "Cristina Savin"], "title": "Using local plasticity rules to train recurrent neural networks", "url": "http://arxiv.org/pdf/1905.12100v1", "summary": "To learn useful dynamics on long time scales, neurons must use plasticity\nrules that account for long-term, circuit-wide effects of synaptic changes. In\nother words, neural circuits must solve a credit assignment problem to\nappropriately assign responsibility for global network behavior to individual\ncircuit components. Furthermore, biological constraints demand that plasticity\nrules are spatially and temporally local; that is, synaptic changes can depend\nonly on variables accessible to the pre- and postsynaptic neurons. While\nartificial intelligence offers a computational solution for credit assignment,\nnamely backpropagation through time (BPTT), this solution is wildly\nbiologically implausible. It requires both nonlocal computations and unlimited\nmemory capacity, as any synaptic change is a complicated function of the entire\nhistory of network activity. Similar nonlocality issues plague other approaches\nsuch as FORCE (Sussillo et al. 2009). Overall, we are still missing a model for\nlearning in recurrent circuits that both works computationally and uses only\nlocal updates. Leveraging recent advances in machine learning on approximating\ngradients for BPTT, we derive biologically plausible plasticity rules that\nenable recurrent networks to accurately learn long-term dependencies in\nsequential data. The solution takes the form of neurons with segregated voltage\ncompartments, with several synaptic sub-populations that have different\nfunctional properties. The network operates in distinct phases during which\neach synaptic sub-population is updated by its own local plasticity rule. Our\nresults provide new insights into the potential roles of segregated dendritic\ncompartments, branch-specific inhibition, and global circuit phases in\nlearning.", "published": "2019-05-28T21:32:26Z", "version": 1}, {"aid": "1905.13010", "authors": ["Arthur Charlesworth"], "title": "Definitively Identifying an Inherent Limitation to Actual Cognition", "url": "http://arxiv.org/pdf/1905.13010v2", "summary": "A century ago, discoveries of a serious kind of logical error made separately\nby several leading mathematicians led to acceptance of a sharply enhanced\nstandard for rigor within what ultimately became the foundation for Computer\nScience. By 1931, Godel had obtained a definitive and remarkable result: an\ninherent limitation to that foundation. The resulting limitation is not\napplicable to actual human cognition, to even the smallest extent, unless both\nof these extremely brittle assumptions hold: humans are infallible reasoners\nand reason solely via formal inference rules. Both assumptions are contradicted\nby empirical data from well-known Cognitive Science experiments. This article\ninvestigates how a novel multi-part methodology recasts computability theory\nwithin Computer Science to obtain a definitive limitation whose application to\nhuman cognition avoids assumptions contradicting empirical data. The limitation\napplies to individual humans, to finite sets of humans, and more generally to\nany real-world entity.", "published": "2019-05-29T17:55:38Z", "version": 2}, {"aid": "1905.12775", "authors": ["Xiang Xu", "Xiong Zhou", "Ragav Venkatesan", "Gurumurthy Swaminathan", "Orchid Majumder"], "title": "$d$-SNE: Domain Adaptation using Stochastic Neighborhood Embedding", "url": "http://arxiv.org/pdf/1905.12775v1", "summary": "Deep neural networks often require copious amount of labeled-data to train\ntheir scads of parameters. Training larger and deeper networks is hard without\nappropriate regularization, particularly while using a small dataset.\nLaterally, collecting well-annotated data is expensive, time-consuming and\noften infeasible. A popular way to regularize these networks is to simply train\nthe network with more data from an alternate representative dataset. This can\nlead to adverse effects if the statistics of the representative dataset are\ndissimilar to our target. This predicament is due to the problem of domain\nshift. Data from a shifted domain might not produce bespoke features when a\nfeature extractor from the representative domain is used. In this paper, we\npropose a new technique ($d$-SNE) of domain adaptation that cleverly uses\nstochastic neighborhood embedding techniques and a novel modified-Hausdorff\ndistance. The proposed technique is learnable end-to-end and is therefore,\nideally suited to train neural networks. Extensive experiments demonstrate that\n$d$-SNE outperforms the current states-of-the-art and is robust to the\nvariances in different datasets, even in the one-shot and semi-supervised\nlearning settings. $d$-SNE also demonstrates the ability to generalize to\nmultiple domains concurrently.", "published": "2019-05-29T23:16:51Z", "version": 1}, {"aid": "1905.12830", "authors": ["Haijun Liu", "Jian Cheng", "Shiguang Wang", "Wen Wang"], "title": "Attention: A Big Surprise for Cross-Domain Person Re-Identification", "url": "http://arxiv.org/pdf/1905.12830v1", "summary": "In this paper, we focus on model generalization and adaptation for\ncross-domain person re-identification (Re-ID). Unlike existing cross-domain\nRe-ID methods, leveraging the auxiliary information of those unlabeled\ntarget-domain data, we aim at enhancing the model generalization and adaptation\nby discriminative feature learning, and directly exploiting a pre-trained model\nto new domains (datasets) without any utilization of the information from\ntarget domains. To address the discriminative feature learning problem, we\nsurprisingly find that simply introducing the attention mechanism to adaptively\nextract the person features for every domain is of great effectiveness. We\nadopt two popular type of attention mechanisms, long-range dependency based\nattention and direct generation based attention. Both of them can perform the\nattention via spatial or channel dimensions alone, even the combination of\nspatial and channel dimensions. The outline of different attentions are well\nillustrated. Moreover, we also incorporate the attention results into the final\noutput of model through skip-connection to improve the features with both high\nand middle level semantic visual information. In the manner of directly\nexploiting a pre-trained model to new domains, the attention incorporation\nmethod truly could enhance the model generalization and adaptation to perform\nthe cross-domain person Re-ID. We conduct extensive experiments between three\nlarge datasets, Market-1501, DukeMTMC-reID and MSMT17. Surprisingly,\nintroducing only attention can achieve state-of-the-art performance, even much\nbetter than those cross-domain Re-ID methods utilizing auxiliary information\nfrom the target domain.", "published": "2019-05-30T02:17:07Z", "version": 1}, {"aid": "1905.12837", "authors": ["Haijun Liu", "Jian Cheng", "Wen Wang", "Yanzhou Su"], "title": "The General Pair-based Weighting Loss for Deep Metric Learning", "url": "http://arxiv.org/pdf/1905.12837v1", "summary": "Deep metric learning aims at learning the distance metric between pair of\nsamples, through the deep neural networks to extract the semantic feature\nembeddings where similar samples are close to each other while dissimilar\nsamples are farther apart. A large amount of loss functions based on pair\ndistances have been presented in the literature for guiding the training of\ndeep metric learning. In this paper, we unify them in a general pair-based\nweighting loss function, where the minimizing objective loss is just the\ndistances weighting of informative pairs. The general pair-based weighting loss\nincludes two main aspects, (1) samples mining and (2) pairs weighting. Samples\nmining aims at selecting the informative positive and negative pair sets to\nexploit the structured relationship of samples in a mini-batch and also reduce\nthe number of non-trivial pairs. Pair weighting aims at assigning different\nweights for different pairs according to the pair distances for\ndiscriminatively training the network. We detailedly review those existing\npair-based losses inline with our general loss function, and explore some\npossible methods from the perspective of samples mining and pairs weighting.\nFinally, extensive experiments on three image retrieval datasets show that our\ngeneral pair-based weighting loss obtains new state-of-the-art performance,\ndemonstrating the effectiveness of the pair-based samples mining and pairs\nweighting for deep metric learning.", "published": "2019-05-30T02:59:26Z", "version": 1}, {"aid": "1905.12871", "authors": ["Hideaki Hayashi", "Seiichi Uchida"], "title": "A Trainable Multiplication Layer for Auto-correlation and Co-occurrence Extraction", "url": "http://arxiv.org/pdf/1905.12871v1", "summary": "In this paper, we propose a trainable multiplication layer (TML) for a neural\nnetwork that can be used to calculate the multiplication between the input\nfeatures. Taking an image as an input, the TML raises each pixel value to the\npower of a weight and then multiplies them, thereby extracting the higher-order\nlocal auto-correlation from the input image. The TML can also be used to\nextract co-occurrence from the feature map of a convolutional network. The\ntraining of the TML is formulated based on backpropagation with constraints to\nthe weights, enabling us to learn discriminative multiplication patterns in an\nend-to-end manner. In the experiments, the characteristics of the TML are\ninvestigated by visualizing learned kernels and the corresponding output\nfeatures. The applicability of the TML for classification and neural network\ninterpretation is also evaluated using public datasets.", "published": "2019-05-30T06:21:54Z", "version": 1}, {"aid": "1905.13049", "authors": ["Xiaoran Xu", "Wei Feng", "Zhiqing Sun", "Zhi-Hong Deng"], "title": "Neural Consciousness Flow", "url": "http://arxiv.org/pdf/1905.13049v1", "summary": "The ability of reasoning beyond data fitting is substantial to deep learning\nsystems in order to make a leap forward towards artificial general\nintelligence. A lot of efforts have been made to model neural-based reasoning\nas an iterative decision-making process based on recurrent networks and\nreinforcement learning. Instead, inspired by the consciousness prior proposed\nby Yoshua Bengio, we explore reasoning with the notion of attentive awareness\nfrom a cognitive perspective, and formulate it in the form of attentive message\npassing on graphs, called neural consciousness flow (NeuCFlow). Aiming to\nbridge the gap between deep learning systems and reasoning, we propose an\nattentive computation framework with a three-layer architecture, which consists\nof an unconsciousness flow layer, a consciousness flow layer, and an attention\nflow layer. We implement the NeuCFlow model with graph neural networks (GNNs)\nand conditional transition matrices. Our attentive computation greatly reduces\nthe complexity of vanilla GNN-based methods, capable of running on large-scale\ngraphs. We validate our model for knowledge graph reasoning by solving a series\nof knowledge base completion (KBC) tasks. The experimental results show\nNeuCFlow significantly outperforms previous state-of-the-art KBC methods,\nincluding the embedding-based and the path-based. The reproducible code can be\nfound by the link below.", "published": "2019-05-30T13:33:55Z", "version": 1}, {"aid": "1905.13211", "authors": ["Keyulu Xu", "Jingling Li", "Mozhi Zhang", "Simon S. Du", "Ken-ichi Kawarabayashi", "Stefanie Jegelka"], "title": "What Can Neural Networks Reason About?", "url": "http://arxiv.org/pdf/1905.13211v4", "summary": "Neural networks have succeeded in many reasoning tasks. Empirically, these\ntasks require specialized network structures, e.g., Graph Neural Networks\n(GNNs) perform well on many such tasks, but less structured networks fail.\nTheoretically, there is limited understanding of why and when a network\nstructure generalizes better than others, although they have equal expressive\npower. In this paper, we develop a framework to characterize which reasoning\ntasks a network can learn well, by studying how well its computation structure\naligns with the algorithmic structure of the relevant reasoning process. We\nformally define this algorithmic alignment and derive a sample complexity bound\nthat decreases with better alignment. This framework offers an explanation for\nthe empirical success of popular reasoning models, and suggests their\nlimitations. As an example, we unify seemingly different reasoning tasks, such\nas intuitive physics, visual question answering, and shortest paths, via the\nlens of a powerful algorithmic paradigm, dynamic programming (DP). We show that\nGNNs align with DP and thus are expected to solve these tasks. On several\nreasoning tasks, our theory is supported by empirical results.", "published": "2019-05-30T17:53:30Z", "version": 4}, {"aid": "1906.01703", "authors": ["Jiawei Zhang"], "title": "Basic Neural Units of the Brain: Neurons, Synapses and Action Potential", "url": "http://arxiv.org/pdf/1906.01703v1", "summary": "As a follow-up tutorial article of [29], in this paper, we will introduce the\nbasic compositional units of the human brain, which will further illustrate the\ncell-level bio-structure of the brain. On average, the human brain contains\nabout 100 billion neurons and many more neuroglia which serve to support and\nprotect the neurons. Each neuron may be connected to up to 10,000 other\nneurons, passing signals to each other via as many as 1,000 trillion synapses.\nIn the nervous system, a synapse is a structure that permits a neuron to pass\nan electrical or chemical signal to another neuron or to the target effector\ncell. Such signals will be accumulated as the membrane potential of the\nneurons, and it will trigger and pass the signal pulse (i.e., action potential)\nto other neurons when the membrane potential is greater than a precisely\ndefined threshold voltage. To be more specific, in this paper, we will talk\nabout the neurons, synapses and the action potential concepts in detail. Many\nof the materials used in this paper are from wikipedia and several other\nneuroscience introductory articles, which will be properly cited in this paper.\nThis is the second of the three tutorial articles about the brain (the other\ntwo are [29] and [28]). The readers are suggested to read the previous tutorial\narticle [29] to get more background information about the brain structure and\nfunctions prior to reading this paper.", "published": "2019-05-30T23:11:57Z", "version": 1}, {"aid": "1905.13386", "authors": ["Kai Rothauge", "Zhewei Yao", "Zixi Hu", "Michael W. Mahoney"], "title": "Residual Networks as Nonlinear Systems: Stability Analysis using Linearization", "url": "http://arxiv.org/pdf/1905.13386v1", "summary": "We regard pre-trained residual networks (ResNets) as nonlinear systems and\nuse linearization, a common method used in the qualitative analysis of\nnonlinear systems, to understand the behavior of the networks under small\nperturbations of the input images. We work with ResNet-56 and ResNet-110\ntrained on the CIFAR-10 data set. We linearize these networks at the level of\nresidual units and network stages, and the singular value decomposition is used\nin the stability analysis of these components. It is found that most of the\nsingular values of the linearizations of residual units are 1 and, in spite of\nthe fact that the linearizations depend directly on the activation maps, the\nsingular values differ only slightly for different input images. However,\nadjusting the scaling of the skip connection or the values of the weights in a\nresidual unit has a significant impact on the singular value distributions.\nInspection of how random and adversarial perturbations of input images\npropagate through the network reveals that there is a dramatic jump in the\nmagnitude of adversarial perturbations towards the end of the final stage of\nthe network that is not present in the case of random perturbations. We attempt\nto gain a better understanding of this phenomenon by projecting the\nperturbations onto singular vectors of the linearizations of the residual\nunits.", "published": "2019-05-31T02:44:28Z", "version": 1}, {"aid": "1905.13388", "authors": ["Haonan Wang", "Jun Lin", "Zhongfeng Wang"], "title": "Design Light-weight 3D Convolutional Networks for Video Recognition Temporal Residual, Fully Separable Block, and Fast Algorithm", "url": "http://arxiv.org/pdf/1905.13388v1", "summary": "Deep 3-dimensional (3D) Convolutional Network (ConvNet) has shown promising\nperformance on video recognition tasks because of its powerful spatio-temporal\ninformation fusion ability. However, the extremely intensive requirements on\nmemory access and computing power prohibit it from being used in\nresource-constrained scenarios, such as portable and edge devices. So in this\npaper, we first propose a two-stage Fully Separable Block (FSB) to\nsignificantly compress the model sizes of 3D ConvNets. Then a feature\nenhancement approach named Temporal Residual Gradient (TRG) is developed to\nimprove the performance of compressed model on video tasks, which provides\nhigher accuracy, faster convergency and better robustness. Moreover, in order\nto further decrease the computing workload, we propose a hybrid Fast Algorithm\n(hFA) to drastically reduce the computation complexity of convolutions. These\nmethods are effectively combined to design a light-weight and efficient ConvNet\nfor video recognition tasks. Experiments on the popular dataset report 2.3x\ncompression rate, 3.6x workload reduction, and 6.3% top-1 accuracy gain, over\nthe state-of-the-art SlowFast model, which is already a highly compact model.\nThe proposed methods also show good adaptability on traditional 3D ConvNet,\ndemonstrating 7.4x more compact model, 11.0x less workload, and 3.0% higher\naccuracy", "published": "2019-05-31T02:48:21Z", "version": 1}, {"aid": "1906.00025", "authors": ["Heinrich Jiang", "Maya Gupta"], "title": "Minimum-Margin Active Learning", "url": "http://arxiv.org/pdf/1906.00025v1", "summary": "We present a new active sampling method we call min-margin which trains\nmultiple learners on bootstrap samples and then chooses the examples to label\nbased on the candidates' minimum margin amongst the bootstrapped models. This\nextends standard margin sampling in a way that increases its diversity in a\nsupervised manner as it arises from the model uncertainty. We focus on the\none-shot batch active learning setting, and show theoretically and through\nextensive experiments on a broad set of problems that min-margin outperforms\nother methods, particularly as batch size grows.", "published": "2019-05-31T18:32:18Z", "version": 1}, {"aid": "1906.00131", "authors": ["Arsh Javed Rehman", "Pradeep Tomar"], "title": "Decision-Making in Reinforcement Learning", "url": "http://arxiv.org/pdf/1906.00131v1", "summary": "In this research work, probabilistic decision-making approaches are studied,\ne.g. Bayesian and Boltzmann strategies, along with various deterministic\nexploration strategies, e.g. greedy, epsilon-Greedy and random approaches. In\nthis research work, a comparative study has been done between probabilistic and\ndeterministic decision-making approaches, the experiments are performed in\nOpenAI gym environment, solving Cart Pole problem. This research work discusses\nabout the Bayesian approach to decision-making in deep reinforcement learning,\nand about dropout, how it can reduce the computational cost. All the\nexploration approaches are compared. It also discusses about the importance of\nexploration in deep reinforcement learning, and how improving exploration\nstrategies may help in science and technology. This research work shows how\nprobabilistic decision-making approaches are better in the long run as compared\nto the deterministic approaches. When there is uncertainty, Bayesian dropout\napproach proved to be better than all other approaches in this research work.", "published": "2019-06-01T02:36:42Z", "version": 1}, {"aid": "1906.00180", "authors": ["Mathijs Mul", "Willem Zuidema"], "title": "Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization", "url": "http://arxiv.org/pdf/1906.00180v1", "summary": "Can neural nets learn logic? We approach this classic question with current\nmethods, and demonstrate that recurrent neural networks can learn to recognize\nfirst order logical entailment relations between expressions. We define an\nartificial language in first-order predicate logic, generate a large dataset of\nsample 'sentences', and use an automatic theorem prover to infer the relation\nbetween random pairs of such sentences. We describe a Siamese neural\narchitecture trained to predict the logical relation, and experiment with\nrecurrent and recursive networks. Siamese Recurrent Networks are surprisingly\nsuccessful at the entailment recognition task, reaching near perfect\nperformance on novel sentences (consisting of known words), and even\noutperforming recursive networks. We report a series of experiments to test the\nability of the models to perform compositional generalization. In particular,\nwe study how they deal with sentences of unseen length, and sentences\ncontaining unseen words. We show that set-ups using LSTMs and GRUs obtain high\nscores on these tests, demonstrating a form of compositionality.", "published": "2019-06-01T08:17:42Z", "version": 1}, {"aid": "1906.00184", "authors": ["Jianxin Lin", "Yingce Xia", "Sen Liu", "Shuqin Zhao", "Zhibo Chen"], "title": "ZstGAN: An Adversarial Approach for Unsupervised Zero-Shot Image-to-Image Translation", "url": "http://arxiv.org/pdf/1906.00184v2", "summary": "Image-to-image translation models have shown remarkable ability on\ntransferring images among different domains. Most of existing work follows the\nsetting that the source domain and target domain keep the same at training and\ninference phases, which cannot be generalized to the scenarios for translating\nan image from an unseen domain to another unseen domain. In this work, we\npropose the Unsupervised Zero-Shot Image-to-image Translation (UZSIT) problem,\nwhich aims to learn a model that can translate samples from image domains that\nare not observed during training. Accordingly, we propose a framework called\nZstGAN: By introducing an adversarial training scheme, ZstGAN learns to model\neach domain with domain-specific feature distribution that is semantically\nconsistent on vision and attribute modalities. Then the domain-invariant\nfeatures are disentangled with an shared encoder for image generation. We carry\nout extensive experiments on CUB and FLO datasets, and the results demonstrate\nthe effectiveness of proposed method on UZSIT task. Moreover, ZstGAN shows\nsignificant accuracy improvements over state-of-the-art zero-shot learning\nmethods on CUB and FLO.", "published": "2019-06-01T08:43:44Z", "version": 2}, {"aid": "1906.00254", "authors": ["Ivan Kiskin", "Udeepa Meepegama", "Steven Roberts"], "title": "Super-resolution of Time-series Labels for Bootstrapped Event Detection", "url": "http://arxiv.org/pdf/1906.00254v1", "summary": "Solving real-world problems, particularly with deep learning, relies on the\navailability of abundant, quality data. In this paper we develop a novel\nframework that maximises the utility of time-series datasets that contain only\nsmall quantities of expertly-labelled data, larger quantities of weakly (or\ncoarsely) labelled data and a large volume of unlabelled data. This represents\nscenarios commonly encountered in the real world, such as in crowd-sourcing\napplications. In our work, we use a nested loop using a Kernel Density\nEstimator (KDE) to super-resolve the abundant low-quality data labels, thereby\nenabling effective training of a Convolutional Neural Network (CNN). We\ndemonstrate two key results: a) The KDE is able to super-resolve labels more\naccurately, and with better calibrated probabilities, than well-established\nclassifiers acting as baselines; b) Our CNN, trained on super-resolved labels\nfrom the KDE, achieves an improvement in F1 score of 22.1% over the next best\nbaseline system in our candidate problem domain.", "published": "2019-06-01T16:29:50Z", "version": 1}, {"aid": "1906.00332", "authors": ["Haekyu Park", "Fred Hohman", "Duen Horng Chau"], "title": "NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions", "url": "http://arxiv.org/pdf/1906.00332v1", "summary": "As deep neural networks are increasingly used in solving high-stake problems,\nthere is a pressing need to understand their internal decision mechanisms.\nVisualization has helped address this problem by assisting with interpreting\ncomplex deep neural networks. However, current tools often support only single\ndata instances, or visualize layers in isolation. We present NeuralDivergence,\nan interactive visualization system that uses activation distributions as a\nhigh-level summary of what a model has learned. NeuralDivergence enables users\nto interactively summarize and compare activation distributions across layers,\nclasses, and instances (e.g., pairs of adversarial attacked and benign images),\nhelping them gain better understanding of neural network models.", "published": "2019-06-02T03:03:51Z", "version": 1}, {"aid": "1906.00446", "authors": ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2", "url": "http://arxiv.org/pdf/1906.00446v1", "summary": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE)\nmodels for large scale image generation. To this end, we scale and enhance the\nautoregressive priors used in VQ-VAE to generate synthetic samples of much\nhigher coherence and fidelity than possible before. We use simple feed-forward\nencoder and decoder networks, making our model an attractive candidate for\napplications where the encoding and/or decoding speed is critical.\nAdditionally, VQ-VAE requires sampling an autoregressive model only in the\ncompressed latent space, which is an order of magnitude faster than sampling in\nthe pixel space, especially for large images. We demonstrate that a multi-scale\nhierarchical organization of VQ-VAE, augmented with powerful priors over the\nlatent codes, is able to generate samples with quality that rivals that of\nstate of the art Generative Adversarial Networks on multifaceted datasets such\nas ImageNet, while not suffering from GAN's known shortcomings such as mode\ncollapse and lack of diversity.", "published": "2019-06-02T16:46:42Z", "version": 1}, {"aid": "1906.00511", "authors": ["Christian Meisel", "Rima El Atrache", "Michele Jackson", "Sarah Schubach", "Claire Ufongene", "Tobias Loddenkemper"], "title": "Deep learning from wristband sensor data: towards wearable, non-invasive seizure forecasting", "url": "http://arxiv.org/pdf/1906.00511v2", "summary": "Seizure forecasting may provide patients with timely warnings to adapt their\ndaily activities and help clinicians deliver more objective, personalized\ntreatments. While recent work has convincingly demonstrated that seizure risk\nassessment is possible, these early approaches relied largely on complex, often\ninvasive setups including intracranial electrocorticography, implanted devices\nand multi-channel EEG, which limits translation of these methods to broad\nclinical application. To facilitate broader adaptation of seizure forecasting\nin clinical practice, non-invasive, easily applicable techniques that reliably\nassess seizure risk, in combination with clinical information, are crucial.\nWristbands that continuously record physiological parameters, including\nelectrodermal activity, body temperature, blood volume pressure and actigraphy,\nmay afford monitoring of autonomous nervous system function and movement\nrelevant for such a task, hence minimizing potential complications associated\nwith invasive monitoring, and avoiding stigma associated with bulky external\nmonitoring devices on the head. Here, we use deep learning to analyze\nlong-term, multi-modal wristband sensor data from 50 patients with epilepsy\n(total duration $>$1400 hours) to assess its capability to distinguish preictal\nfrom interictal states. Prediction performance is assessed using area under the\nreceiver operating charateristic (AUC) and improvement over chance (IoC) based\non F1 scores. Using one- and two-dimensional convolutional neural networks, we\nidentified better-than-chance predictability in out-of-sample test data in 60\\%\nof the patients in leave-one-out and 43\\% of patients in pseudo-prospective\napproaches. These results provide a step towards developing easier to apply,\nnon-invasive methods for seizure risk assessments in patients with epilepsy.", "published": "2019-06-03T00:34:55Z", "version": 2}, {"aid": "1906.00532", "authors": ["Aishwarya Bhandare", "Vamsi Sripathi", "Deepthi Karkada", "Vivek Menon", "Sun Choi", "Kushal Datta", "Vikram Saletore"], "title": "Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model", "url": "http://arxiv.org/pdf/1906.00532v2", "summary": "In this work, we quantize a trained Transformer machine language translation\nmodel leveraging INT8/VNNI instructions in the latest Intel$^\\circledR$\nXeon$^\\circledR$ Cascade Lake processors to improve inference performance while\nmaintaining less than 0.5$\\%$ drop in accuracy. To the best of our knowledge,\nthis is the first attempt in the industry to quantize the Transformer model.\nThis has high impact as it clearly demonstrates the various complexities of\nquantizing the language translation model. We present novel quantization\ntechniques directly in TensorFlow to opportunistically replace 32-bit floating\npoint (FP32) computations with 8-bit integers (INT8) and transform the FP32\ncomputational graph. We also present a bin-packing parallel batching technique\nto maximize CPU utilization. Overall, our optimizations with INT8/VNNI deliver\n1.5X improvement over the best FP32 performance. Furthermore, it reveals the\nopportunities and challenges to boost performance of quantized deep learning\ninference and establishes best practices to run inference with high efficiency\non Intel CPUs.", "published": "2019-06-03T02:29:22Z", "version": 2}, {"aid": "1906.00586", "authors": ["Mitchell Wortsman", "Ali Farhadi", "Mohammad Rastegari"], "title": "Discovering Neural Wirings", "url": "http://arxiv.org/pdf/1906.00586v5", "summary": "The success of neural networks has driven a shift in focus from feature\nengineering to architecture engineering. However, successful networks today are\nconstructed using a small and manually defined set of building blocks. Even in\nmethods of neural architecture search (NAS) the network connectivity patterns\nare largely constrained. In this work we propose a method for discovering\nneural wirings. We relax the typical notion of layers and instead enable\nchannels to form connections independent of each other. This allows for a much\nlarger space of possible networks. The wiring of our network is not fixed\nduring training -- as we learn the network parameters we also learn the\nstructure itself. Our experiments demonstrate that our learned connectivity\noutperforms hand engineered and randomly wired networks. By learning the\nconnectivity of MobileNetV1we boost the ImageNet accuracy by 10% at ~41M FLOPs.\nMoreover, we show that our method generalizes to recurrent and continuous time\nnetworks. Our work may also be regarded as unifying core aspects of the neural\narchitecture search problem with sparse neural network learning. As NAS becomes\nmore fine grained, finding a good architecture is akin to finding a sparse\nsubnetwork of the complete graph. Accordingly, DNW provides an effective\nmechanism for discovering sparse subnetworks of predefined architectures in a\nsingle training run. Though we only ever use a small percentage of the weights\nduring the forward pass, we still play the so-called initialization lottery\nwith a combinatorial number of subnetworks. Code and pretrained models are\navailable at https://github.com/allenai/dnw while additional visualizations may\nbe found at https://mitchellnw.github.io/blog/2019/dnw/.", "published": "2019-06-03T05:58:33Z", "version": 5}, {"aid": "1906.00695", "authors": ["Johannes von Oswald", "Christian Henning", "Benjamin F. Grewe", "Jo\u00e3o Sacramento"], "title": "Continual learning with hypernetworks", "url": "http://arxiv.org/pdf/1906.00695v4", "summary": "Artificial neural networks suffer from catastrophic forgetting when they are\nsequentially trained on multiple tasks. To overcome this problem, we present a\nnovel approach based on task-conditioned hypernetworks, i.e., networks that\ngenerate the weights of a target model based on task identity. Continual\nlearning (CL) is less difficult for this class of models thanks to a simple key\nfeature: instead of recalling the input-output relations of all previously seen\ndata, task-conditioned hypernetworks only require rehearsing task-specific\nweight realizations, which can be maintained in memory using a simple\nregularizer. Besides achieving state-of-the-art performance on standard CL\nbenchmarks, additional experiments on long task sequences reveal that\ntask-conditioned hypernetworks display a very large capacity to retain previous\nmemories. Notably, such long memory lifetimes are achieved in a compressive\nregime, when the number of trainable hypernetwork weights is comparable or\nsmaller than target network size. We provide insight into the structure of\nlow-dimensional task embedding spaces (the input space of the hypernetwork) and\nshow that task-conditioned hypernetworks demonstrate transfer learning.\nFinally, forward information transfer is further supported by empirical results\non a challenging CL benchmark based on the CIFAR-10/100 image datasets.", "published": "2019-06-03T10:45:08Z", "version": 4}, {"aid": "1906.00709", "authors": ["Min-Cheol Sagong", "Yong-Goo Shin", "Yoon-Jae Yeo", "Seung Park", "Sung-Jea Ko"], "title": "cGANs with Conditional Convolution Layer", "url": "http://arxiv.org/pdf/1906.00709v2", "summary": "Conditional generative adversarial networks (cGANs) have been widely\nresearched to generate class conditional images using a single generator.\nHowever, in the conventional cGANs techniques, it is still challenging for the\ngenerator to learn condition-specific features, since a standard convolutional\nlayer with the same weights is used regardless of the condition. In this paper,\nwe propose a novel convolution layer, called the conditional convolution layer,\nwhich directly generates different feature maps by employing the weights which\nare adjusted depending on the conditions. More specifically, in each\nconditional convolution layer, the weights are conditioned in a simple but\neffective way through filter-wise scaling and channel-wise shifting operations.\nIn contrast to the conventional methods, the proposed method with a single\ngenerator can effectively handle condition-specific characteristics. The\nexperimental results on CIFAR, LSUN and ImageNet datasets show that the\ngenerator with the proposed conditional convolution layer achieves a higher\nquality of conditional image generation than that with the standard convolution\nlayer.", "published": "2019-06-03T11:15:51Z", "version": 2}, {"aid": "1906.00889", "authors": ["Benjamin James Lansdell", "Prashanth Ravi Prakash", "Konrad Paul Kording"], "title": "Learning to solve the credit assignment problem", "url": "http://arxiv.org/pdf/1906.00889v4", "summary": "Backpropagation is driving today's artificial neural networks (ANNs).\nHowever, despite extensive research, it remains unclear if the brain implements\nthis algorithm. Among neuroscientists, reinforcement learning (RL) algorithms\nare often seen as a realistic alternative: neurons can randomly introduce\nchange, and use unspecific feedback signals to observe their effect on the cost\nand thus approximate their gradient. However, the convergence rate of such\nlearning scales poorly with the number of involved neurons. Here we propose a\nhybrid learning approach. Each neuron uses an RL-type strategy to learn how to\napproximate the gradients that backpropagation would provide. We provide proof\nthat our approach converges to the true gradient for certain classes of\nnetworks. In both feedforward and convolutional networks, we empirically show\nthat our approach learns to approximate the gradient, and can match or the\nperformance of exact gradient-based learning. Learning feedback weights\nprovides a biologically plausible mechanism of achieving good performance,\nwithout the need for precise, pre-specified learning rules.", "published": "2019-06-03T15:48:38Z", "version": 4}, {"aid": "1906.00917", "authors": ["Yichang Wang", "R\u00e9mi Emonet", "Elisa Fromont", "Simon Malinowski", "Etienne Menager", "Lo\u00efc Mosser", "Romain Tavenard"], "title": "Learning Interpretable Shapelets for Time Series Classification through Adversarial Regularization", "url": "http://arxiv.org/pdf/1906.00917v2", "summary": "Times series classification can be successfully tackled by jointly learning a\nshapelet-based representation of the series in the dataset and classifying the\nseries according to this representation. However, although the learned\nshapelets are discriminative, they are not always similar to pieces of a real\nseries in the dataset. This makes it difficult to interpret the decision, i.e.\ndifficult to analyze if there are particular behaviors in a series that\ntriggered the decision. In this paper, we make use of a simple convolutional\nnetwork to tackle the time series classification task and we introduce an\nadversarial regularization to constrain the model to learn more interpretable\nshapelets. Our classification results on all the usual time series benchmarks\nare comparable with the results obtained by similar state-of-the-art algorithms\nbut our adversarially regularized method learns shapelets that are, by design,\ninterpretable.", "published": "2019-06-03T16:38:20Z", "version": 2}, {"aid": "1906.00925", "authors": ["Yawei Li", "Vagia Tsiminaki", "Radu Timofte", "Marc Pollefeys", "Luc van Gool"], "title": "3D Appearance Super-Resolution with Deep Learning", "url": "http://arxiv.org/pdf/1906.00925v2", "summary": "We tackle the problem of retrieving high-resolution (HR) texture maps of\nobjects that are captured from multiple view points. In the multi-view case,\nmodel-based super-resolution (SR) methods have been recently proved to recover\nhigh quality texture maps. On the other hand, the advent of deep learning-based\nmethods has already a significant impact on the problem of video and image SR.\nYet, a deep learning-based approach to super-resolve the appearance of 3D\nobjects is still missing. The main limitation of exploiting the power of deep\nlearning techniques in the multi-view case is the lack of data. We introduce a\n3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31],\nMiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] and\nRelief [53]. We provide the high- and low-resolution texture maps, the 3D\ngeometric model, images and projection matrices. We exploit the power of 2D\nlearning-based SR methods and design networks suitable for the 3D multi-view\ncase. We incorporate the geometric information by introducing normal maps and\nfurther improve the learning process. Experimental results demonstrate that our\nproposed networks successfully incorporate the 3D geometric information and\nsuper-resolve the texture maps.", "published": "2019-06-03T16:51:35Z", "version": 2}, {"aid": "1906.01039", "authors": ["Guruprasad Raghavan", "Matt Thomson"], "title": "Neural networks grown and self-organized by noise", "url": "http://arxiv.org/pdf/1906.01039v1", "summary": "Living neural networks emerge through a process of growth and\nself-organization that begins with a single cell and results in a brain, an\norganized and functional computational device. Artificial neural networks,\nhowever, rely on human-designed, hand-programmed architectures for their\nremarkable performance. Can we develop artificial computational devices that\ncan grow and self-organize without human intervention? In this paper, we\npropose a biologically inspired developmental algorithm that can 'grow' a\nfunctional, layered neural network from a single initial cell. The algorithm\norganizes inter-layer connections to construct a convolutional pooling layer, a\nkey constituent of convolutional neural networks (CNN's). Our approach is\ninspired by the mechanisms employed by the early visual system to wire the\nretina to the lateral geniculate nucleus (LGN), days before animals open their\neyes. The key ingredients for robust self-organization are an emergent\nspontaneous spatiotemporal activity wave in the first layer and a local\nlearning rule in the second layer that 'learns' the underlying activity pattern\nin the first layer. The algorithm is adaptable to a wide-range of input-layer\ngeometries, robust to malfunctioning units in the first layer, and so can be\nused to successfully grow and self-organize pooling architectures of different\npool-sizes and shapes. The algorithm provides a primitive procedure for\nconstructing layered neural networks through growth and self-organization.\nBroadly, our work shows that biologically inspired developmental algorithms can\nbe applied to autonomously grow functional 'brains' in-silico.", "published": "2019-06-03T19:33:39Z", "version": 1}, {"aid": "1906.01166", "authors": ["Yuchao Li", "Rongrong Ji", "Shaohui Lin", "Baochang Zhang", "Chenqian Yan", "Yongjian Wu", "Feiyue Huang", "Ling Shao"], "title": "Interpretable Neural Network Decoupling", "url": "http://arxiv.org/pdf/1906.01166v2", "summary": "The remarkable performance of convolutional neural networks (CNNs) is\nentangled with their huge number of uninterpretable parameters, which has\nbecome the bottleneck limiting the exploitation of their full potential.\nTowards network interpretation, previous endeavors mainly resort to the single\nfilter analysis, which however ignores the relationship between filters. In\nthis paper, we propose a novel architecture decoupling method to interpret the\nnetwork from a perspective of investigating its calculation paths. More\nspecifically, we introduce a novel architecture controlling module in each\nlayer to encode the network architecture by a vector. By maximizing the mutual\ninformation between the vectors and input images, the module is trained to\nselect specific filters to distill a unique calculation path for each input.\nFurthermore, to improve the interpretability and compactness of the decoupled\nnetwork, the output of each layer is encoded to align the architecture encoding\nvector with the constraint of sparsity regularization. Unlike conventional\npixel-level or filter-level network interpretation methods, we propose a\npath-level analysis to explore the relationship between the combination of\nfilter and semantic concepts, which is more suitable to interpret the working\nrationale of the decoupled network. Extensive experiments show that the\ndecoupled network achieves several applications, i.e., network interpretation,\nnetwork acceleration, and adversarial samples detection.", "published": "2019-06-04T02:40:38Z", "version": 2}, {"aid": "1906.01984", "authors": ["Xianxu Hou", "Ke Sun", "Linlin Shen", "Guoping Qiu"], "title": "Improving Variational Autoencoder with Deep Feature Consistent and Generative Adversarial Training", "url": "http://arxiv.org/pdf/1906.01984v1", "summary": "We present a new method for improving the performances of variational\nautoencoder (VAE). In addition to enforcing the deep feature consistent\nprinciple thus ensuring the VAE output and its corresponding input images to\nhave similar deep features, we also implement a generative adversarial training\nmechanism to force the VAE to output realistic and natural images. We present\nexperimental results to show that the VAE trained with our new method\noutperforms state of the art in generating face images with much clearer and\nmore natural noses, eyes, teeth, hair textures as well as reasonable\nbackgrounds. We also show that our method can learn powerful embeddings of\ninput face images, which can be used to achieve facial attribute manipulation.\nMoreover we propose a multi-view feature extraction strategy to extract\neffective image representations, which can be used to achieve state of the art\nperformance in facial attribute prediction.", "published": "2019-06-04T03:17:30Z", "version": 1}, {"aid": "1906.01234", "authors": ["Kris Korrel", "Dieuwke Hupkes", "Verna Dankers", "Elia Bruni"], "title": "Transcoding compositionally: using attention to find more generalizable solutions", "url": "http://arxiv.org/pdf/1906.01234v2", "summary": "While sequence-to-sequence models have shown remarkable generalization power\nacross several natural language tasks, their construct of solutions are argued\nto be less compositional than human-like generalization. In this paper, we\npresent seq2attn, a new architecture that is specifically designed to exploit\nattention to find compositional patterns in the input. In seq2attn, the two\nstandard components of an encoder-decoder model are connected via a transcoder,\nthat modulates the information flow between them. We show that seq2attn can\nsuccessfully generalize, without requiring any additional supervision, on two\ntasks which are specifically constructed to challenge the compositional skills\nof neural networks. The solutions found by the model are highly interpretable,\nallowing easy analysis of both the types of solutions that are found and\npotential causes for mistakes. We exploit this opportunity to introduce a new\nparadigm to test compositionality that studies the extent to which a model\novergeneralizes when confronted with exceptions. We show that seq2attn exhibits\nsuch overgeneralization to a larger degree than a standard sequence-to-sequence\nmodel.", "published": "2019-06-04T07:07:56Z", "version": 2}, {"aid": "1906.01478", "authors": ["Laura Thesing", "Vegard Antun", "Anders C. Hansen"], "title": "What do AI algorithms actually learn? - On false structures in deep learning", "url": "http://arxiv.org/pdf/1906.01478v1", "summary": "There are two big unsolved mathematical questions in artificial intelligence\n(AI): (1) Why is deep learning so successful in classification problems and (2)\nwhy are neural nets based on deep learning at the same time universally\nunstable, where the instabilities make the networks vulnerable to adversarial\nattacks. We present a solution to these questions that can be summed up in two\nwords; false structures. Indeed, deep learning does not learn the original\nstructures that humans use when recognising images (cats have whiskers, paws,\nfur, pointy ears, etc), but rather different false structures that correlate\nwith the original structure and hence yield the success. However, the false\nstructure, unlike the original structure, is unstable. The false structure is\nsimpler than the original structure, hence easier to learn with less data and\nthe numerical algorithm used in the training will more easily converge to the\nneural network that captures the false structure. We formally define the\nconcept of false structures and formulate the solution as a conjecture. Given\nthat trained neural networks always are computed with approximations, this\nconjecture can only be established through a combination of theoretical and\ncomputational results similar to how one establishes a postulate in theoretical\nphysics (e.g. the speed of light is constant). Establishing the conjecture\nfully will require a vast research program characterising the false structures.\nWe provide the foundations for such a program establishing the existence of the\nfalse structures in practice. Finally, we discuss the far reaching consequences\nthe existence of the false structures has on state-of-the-art AI and Smale's\n18th problem.", "published": "2019-06-04T14:35:32Z", "version": 1}, {"aid": "1906.01529", "authors": ["Zhengwei Wang", "Qi She", "Tomas E. Ward"], "title": "Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy", "url": "http://arxiv.org/pdf/1906.01529v6", "summary": "Generative adversarial networks (GANs) have been extensively studied in the\npast few years. Arguably their most significant impact has been in the area of\ncomputer vision where great advances have been made in challenges such as\nplausible image generation, image-to-image translation, facial attribute\nmanipulation and similar domains. Despite the significant successes achieved to\ndate, applying GANs to real-world problems still poses significant challenges,\nthree of which we focus on here. These are: (1) the generation of high quality\nimages, (2) diversity of image generation, and (3) stable training. Focusing on\nthe degree to which popular GAN technologies have made progress against these\nchallenges, we provide a detailed review of the state of the art in GAN-related\nresearch in the published scientific literature. We further structure this\nreview through a convenient taxonomy we have adopted based on variations in GAN\narchitectures and loss functions. While several reviews for GANs have been\npresented to date, none have considered the status of this field based on their\nprogress towards addressing practical challenges relevant to computer vision.\nAccordingly, we review and critically discuss the most popular\narchitecture-variant, and loss-variant GANs, for tackling these challenges. Our\nobjective is to provide an overview as well as a critical analysis of the\nstatus of GAN research in terms of relevant progress towards important computer\nvision application requirements. As we do this we also discuss the most\ncompelling applications in computer vision in which GANs have demonstrated\nconsiderable success along with some suggestions for future research\ndirections. Code related to GAN-variants studied in this work is summarized on\nhttps://github.com/sheqi/GAN_Review.", "published": "2019-06-04T15:40:53Z", "version": 6}, {"aid": "1906.02182", "authors": ["Huijuan Xu", "Abir Das", "Kate Saenko"], "title": "Two-Stream Region Convolutional 3D Network for Temporal Activity Detection", "url": "http://arxiv.org/pdf/1906.02182v1", "summary": "We address the problem of temporal activity detection in continuous,\nuntrimmed video streams. This is a difficult task that requires extracting\nmeaningful spatio-temporal features to capture activities, accurately\nlocalizing the start and end times of each activity. We introduce a new model,\nRegion Convolutional 3D Network (R-C3D), which encodes the video streams using\na three-dimensional fully convolutional network, then generates candidate\ntemporal regions containing activities and finally classifies selected regions\ninto specific activities. Computation is saved due to the sharing of\nconvolutional features between the proposal and the classification pipelines.\nWe further improve the detection performance by efficiently integrating an\noptical flow based motion stream with the original RGB stream. The two-stream\nnetwork is jointly optimized by fusing the flow and RGB feature maps at\ndifferent levels. Additionally, the training stage incorporates an online hard\nexample mining strategy to address the extreme foreground-background imbalance\ntypically observed in any detection pipeline. Instead of heuristically sampling\nthe candidate segments for the final activity classification stage, we rank\nthem according to their performance and only select the worst performers to\nupdate the model. This improves the model without heavy hyper-parameter tuning.\nExtensive experiments on three benchmark datasets are carried out to show\nsuperior performance over existing temporal activity detection methods. Our\nmodel achieves state-of-the-art results on the THUMOS'14 and Charades datasets.\nWe further demonstrate that our model is a general temporal activity detection\nframework that does not rely on assumptions about particular dataset properties\nby evaluating our approach on the ActivityNet dataset.", "published": "2019-06-05T02:48:37Z", "version": 1}, {"aid": "1906.01862", "authors": ["Pierrick Coup\u00e9", "Boris Mansencal", "Micha\u00ebl Cl\u00e9ment", "R\u00e9mi Giraud", "Baudouin Denis de Senneville", "Vinh-Thong Ta", "Vincent Lepetit", "Jos\u00e9 V. Manjon"], "title": "AssemblyNet: A Novel Deep Decision-Making Process for Whole Brain MRI Segmentation", "url": "http://arxiv.org/pdf/1906.01862v1", "summary": "Whole brain segmentation using deep learning (DL) is a very challenging task\nsince the number of anatomical labels is very high compared to the number of\navailable training images. To address this problem, previous DL methods\nproposed to use a global convolution neural network (CNN) or few independent\nCNNs. In this paper, we present a novel ensemble method based on a large number\nof CNNs processing different overlapping brain areas. Inspired by parliamentary\ndecision-making systems, we propose a framework called AssemblyNet, made of two\n\"assemblies\" of U-Nets. Such a parliamentary system is capable of dealing with\ncomplex decisions and reaching a consensus quickly. AssemblyNet introduces\nsharing of knowledge among neighboring U-Nets, an \"amendment\" procedure made by\nthe second assembly at higher-resolution to refine the decision taken by the\nfirst one, and a final decision obtained by majority voting. When using the\nsame 45 training images, AssemblyNet outperforms global U-Net by 28% in terms\nof the Dice metric, patch-based joint label fusion by 15% and SLANT-27 by 10%.\nFinally, AssemblyNet demonstrates high capacity to deal with limited training\ndata to achieve whole brain segmentation in practical training and testing\ntimes.", "published": "2019-06-05T07:35:37Z", "version": 1}, {"aid": "1906.02076", "authors": ["David Calhas", "Enrique Romero", "Rui Henriques"], "title": "On the use of Pairwise Distance Learning for Brain Signal Classification with Limited Observations", "url": "http://arxiv.org/pdf/1906.02076v2", "summary": "The increasing access to brain signal data using electroencephalography\ncreates new opportunities to study electrophysiological brain activity and\nperform ambulatory diagnoses of neuronal diseases. This work proposes a\npairwise distance learning approach for Schizophrenia classification relying on\nthe spectral properties of the signal. Given the limited number of observations\n(i.e. the case and/or control individuals) in clinical trials, we propose a\nSiamese neural network architecture to learn a discriminative feature space\nfrom pairwise combinations of observations per channel. In this way, the\nmultivariate order of the signal is used as a form of data augmentation,\nfurther supporting the network generalization ability. Convolutional layers\nwith parameters learned under a cosine contrastive loss are proposed to\nadequately explore spectral images derived from the brain signal. Results on a\ncase-control population show that the features extracted using the proposed\nneural network lead to an improved Schizophrenia diagnosis (+10pp in accuracy\nand sensitivity) against spectral features, thus suggesting the existence of\nnon-trivial, discriminative electrophysiological brain patterns.", "published": "2019-06-05T15:36:57Z", "version": 2}, {"aid": "1906.02164", "authors": ["L. Elisa Celis", "Vijay Keswani", "Nisheeth K. Vishnoi"], "title": "Data preprocessing to mitigate bias: A maximum entropy based approach", "url": "http://arxiv.org/pdf/1906.02164v2", "summary": "Data containing human or social attributes may over- or under-represent\ngroups with respect to salient social attributes such as gender or race, which\ncan lead to biases in downstream applications. This paper presents an\nalgorithmic framework that can be used as a data preprocessing method towards\nmitigating such bias. Unlike prior work, it can efficiently learn distributions\nover large domains, controllably adjust the representation rates of protected\ngroups and achieve target fairness metrics such as statistical parity, yet\nremains close to the empirical distribution induced by the given dataset. Our\napproach leverages the principle of maximum entropy - amongst all distributions\nsatisfying a given set of constraints, we should choose the one closest in\nKL-divergence to a given prior. While maximum entropy distributions can\nsuccinctly encode distributions over large domains, they can be difficult to\ncompute. Our main contribution is an instantiation of this framework for our\nset of constraints and priors, which encode our bias mitigation goals, and that\nruns in time polynomial in the dimension of the data. Empirically, we observe\nthat samples from the learned distribution have desired representation rates\nand statistical rates, and when used for training a classifier incurs only a\nslight loss in accuracy while maintaining fairness properties.", "published": "2019-06-05T17:54:00Z", "version": 2}, {"aid": "1906.02168", "authors": ["Vaishaal Shankar", "Achal Dave", "Rebecca Roelofs", "Deva Ramanan", "Benjamin Recht", "Ludwig Schmidt"], "title": "Do Image Classifiers Generalize Across Time?", "url": "http://arxiv.org/pdf/1906.02168v3", "summary": "We study the robustness of image classifiers to temporal perturbations\nderived from videos. As part of this study, we construct two datasets,\nImageNet-Vid-Robust and YTBB-Robust , containing a total 57,897 images grouped\ninto 3,139 sets of perceptually similar images. Our datasets were derived from\nImageNet-Vid and Youtube-BB respectively and thoroughly re-annotated by human\nexperts for image similarity. We evaluate a diverse array of classifiers\npre-trained on ImageNet and show a median classification accuracy drop of 16\nand 10 on our two datasets. Additionally, we evaluate three detection models\nand show that natural perturbations induce both classification as well as\nlocalization errors, leading to a median drop in detection mAP of 14 points.\nOur analysis demonstrates that perturbations occurring naturally in videos pose\na substantial and realistic challenge to deploying convolutional neural\nnetworks in environments that require both reliable and low-latency predictions", "published": "2019-06-05T17:55:42Z", "version": 3}, {"aid": "1906.02256", "authors": ["Keivan Alizadeh Vahid", "Anish Prabhu", "Ali Farhadi", "Mohammad Rastegari"], "title": "Butterfly Transform: An Efficient FFT Based Neural Architecture Design", "url": "http://arxiv.org/pdf/1906.02256v2", "summary": "In this paper, we show that extending the butterfly operations from the FFT\nalgorithm to a general Butterfly Transform (BFT) can be beneficial in building\nan efficient block structure for CNN designs. Pointwise convolutions, which we\nrefer to as channel fusions, are the main computational bottleneck in the\nstate-of-the-art efficient CNNs (e.g. MobileNets ). We introduce a set of\ncriteria for channel fusion and prove that BFT yields an asymptotically optimal\nFLOP count with respect to these criteria. By replacing pointwise convolutions\nwith BFT, we reduce the computational complexity of these layers from O(n^2) to\nO(n\\log n) with respect to the number of channels. Our experimental evaluations\nshow that our method results in significant accuracy gains across a wide range\nof network architectures, especially at low FLOP ranges. For example, BFT\nresults in up to a 6.75% absolute Top-1 improvement for MobileNetV1, 4.4 \\% for\nShuffleNet V2 and 5.4% for MobileNetV3 on ImageNet under a similar number of\nFLOPS. Notably, ShuffleNet-V2+BFT outperforms state-of-the-art architecture\nsearch methods MNasNet, FBNet and MobilenetV3 in the low FLOP regime.", "published": "2019-06-05T19:04:06Z", "version": 2}, {"aid": "1906.02355", "authors": ["Xuanqing Liu", "Tesi Xiao", "Si Si", "Qin Cao", "Sanjiv Kumar", "Cho-Jui Hsieh"], "title": "Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise", "url": "http://arxiv.org/pdf/1906.02355v1", "summary": "Neural Ordinary Differential Equation (Neural ODE) has been proposed as a\ncontinuous approximation to the ResNet architecture. Some commonly used\nregularization mechanisms in discrete neural networks (e.g. dropout, Gaussian\nnoise) are missing in current Neural ODE networks. In this paper, we propose a\nnew continuous neural network framework called Neural Stochastic Differential\nEquation (Neural SDE) network, which naturally incorporates various commonly\nused regularization mechanisms based on random noise injection. Our framework\ncan model various types of noise injection frequently used in discrete networks\nfor regularization purpose, such as dropout and additive/multiplicative noise\nin each block. We provide theoretical analysis explaining the improved\nrobustness of Neural SDE models against input perturbations/adversarial\nattacks. Furthermore, we demonstrate that the Neural SDE network can achieve\nbetter generalization than the Neural ODE and is more resistant to adversarial\nand non-adversarial input perturbations.", "published": "2019-06-05T23:19:50Z", "version": 1}, {"aid": "1906.02641", "authors": ["Matthew Rahtz", "James Fang", "Anca D. Dragan", "Dylan Hadfield-Menell"], "title": "An Extensible Interactive Interface for Agent Design", "url": "http://arxiv.org/pdf/1906.02641v3", "summary": "In artificial intelligence, we often specify tasks through a reward function.\nWhile this works well in some settings, many tasks are hard to specify this\nway. In deep reinforcement learning, for example, directly specifying a reward\nas a function of a high-dimensional observation is challenging. Instead, we\npresent an interface for specifying tasks interactively using demonstrations.\nOur approach defines a set of increasingly complex policies. The interface\nallows the user to switch between these policies at fixed intervals to generate\ndemonstrations of novel, more complex, tasks. We train new policies based on\nthese demonstrations and repeat the process. We present a case study of our\napproach in the Lunar Lander domain, and show that this simple approach can\nquickly learn a successful landing policy and outperforms an existing\ncomparison-based deep RL method.", "published": "2019-06-06T15:18:40Z", "version": 3}, {"aid": "1906.02717", "authors": ["Mikhail Khodak", "Maria-Florina Balcan", "Ameet Talwalkar"], "title": "Adaptive Gradient-Based Meta-Learning Methods", "url": "http://arxiv.org/pdf/1906.02717v3", "summary": "We build a theoretical framework for designing and understanding practical\nmeta-learning methods that integrates sophisticated formalizations of\ntask-similarity with the extensive literature on online convex optimization and\nsequential prediction algorithms. Our approach enables the task-similarity to\nbe learned adaptively, provides sharper transfer-risk bounds in the setting of\nstatistical learning-to-learn, and leads to straightforward derivations of\naverage-case regret bounds for efficient algorithms in settings where the\ntask-environment changes dynamically or the tasks share a certain geometric\nstructure. We use our theory to modify several popular meta-learning algorithms\nand improve their meta-test-time performance on standard problems in few-shot\nlearning and federated learning.", "published": "2019-06-06T17:36:34Z", "version": 3}, {"aid": "1906.02858", "authors": ["Joe Mathai", "Iacopo Masi", "Wael AbdAlmageed"], "title": "Does Generative Face Completion Help Face Recognition?", "url": "http://arxiv.org/pdf/1906.02858v1", "summary": "Face occlusions, covering either the majority or discriminative parts of the\nface, can break facial perception and produce a drastic loss of information.\nBiometric systems such as recent deep face recognition models are not immune to\nobstructions or other objects covering parts of the face. While most of the\ncurrent face recognition methods are not optimized to handle occlusions, there\nhave been a few attempts to improve robustness directly in the training stage.\nUnlike those, we propose to study the effect of generative face completion on\nthe recognition. We offer a face completion encoder-decoder, based on a\nconvolutional operator with a gating mechanism, trained with an ample set of\nface occlusions. To systematically evaluate the impact of realistic occlusions\non recognition, we propose to play the occlusion game: we render 3D objects\nonto different face parts, providing precious knowledge of what the impact is\nof effectively removing those occlusions. Extensive experiments on the Labeled\nFaces in the Wild (LFW), and its more difficult variant LFW-BLUFR, testify that\nface completion is able to partially restore face perception in machine vision\nsystems for improved recognition.", "published": "2019-06-07T01:48:28Z", "version": 1}, {"aid": "1906.02909", "authors": ["Wei Wen", "Feng Yan", "Yiran Chen", "Hai Li"], "title": "AutoGrow: Automatic Layer Growing in Deep Convolutional Networks", "url": "http://arxiv.org/pdf/1906.02909v5", "summary": "Depth is a key component of Deep Neural Networks (DNNs), however, designing\ndepth is heuristic and requires many human efforts. We propose AutoGrow to\nautomate depth discovery in DNNs: starting from a shallow seed architecture,\nAutoGrow grows new layers if the growth improves the accuracy; otherwise, stops\ngrowing and thus discovers the depth. We propose robust growing and stopping\npolicies to generalize to different network architectures and datasets. Our\nexperiments show that by applying the same policy to different network\narchitectures, AutoGrow can always discover near-optimal depth on various\ndatasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet. For\nexample, in terms of accuracy-computation trade-off, AutoGrow discovers a\nbetter depth combination in ResNets than human experts. Our AutoGrow is\nefficient. It discovers depth within similar time of training a single DNN. Our\ncode is available at https://github.com/wenwei202/autogrow.", "published": "2019-06-07T05:54:41Z", "version": 5}, {"aid": "1906.02940", "authors": ["Trieu H. Trinh", "Minh-Thang Luong", "Quoc V. Le"], "title": "Selfie: Self-supervised Pretraining for Image Embedding", "url": "http://arxiv.org/pdf/1906.02940v3", "summary": "We introduce a pretraining technique called Selfie, which stands for SELFie\nsupervised Image Embedding. Selfie generalizes the concept of masked language\nmodeling of BERT (Devlin et al., 2019) to continuous data, such as images, by\nmaking use of the Contrastive Predictive Coding loss (Oord et al., 2018). Given\nmasked-out patches in an input image, our method learns to select the correct\npatch, among other \"distractor\" patches sampled from the same image, to fill in\nthe masked location. This classification objective sidesteps the need for\npredicting exact pixel values of the target patches. The pretraining\narchitecture of Selfie includes a network of convolutional blocks to process\npatches followed by an attention pooling network to summarize the content of\nunmasked patches before predicting masked ones. During finetuning, we reuse the\nconvolutional weights found by pretraining. We evaluate Selfie on three\nbenchmarks (CIFAR-10, ImageNet 32 x 32, and ImageNet 224 x 224) with varying\namounts of labeled data, from 5% to 100% of the training sets. Our pretraining\nmethod provides consistent improvements to ResNet-50 across all settings\ncompared to the standard supervised training of the same network. Notably, on\nImageNet 224 x 224 with 60 examples per class (5%), our method improves the\nmean accuracy of ResNet-50 from 35.6% to 46.7%, an improvement of 11.1 points\nin absolute accuracy. Our pretraining method also improves ResNet-50 training\nstability, especially on low data regime, by significantly lowering the\nstandard deviation of test accuracies across different runs.", "published": "2019-06-07T07:47:24Z", "version": 3}, {"aid": "1906.03051", "authors": ["Feihong Liu", "Jun Feng", "Geng Chen", "Ye Wu", "Yoonmi Hong", "Pew-Thian Yap", "Dinggang Shen"], "title": "DeepBundle: Fiber Bundle Parcellation with Graph Convolution Neural Networks", "url": "http://arxiv.org/pdf/1906.03051v2", "summary": "Parcellation of whole-brain tractography streamlines is an important step for\ntract-based analysis of brain white matter microstructure. Existing fiber\nparcellation approaches rely on accurate registration between an atlas and the\ntractograms of an individual, however, due to large individual differences,\naccurate registration is hard to guarantee in practice. To resolve this issue,\nwe propose a novel deep learning method, called DeepBundle, for\nregistration-free fiber parcellation. Our method utilizes graph convolution\nneural networks (GCNNs) to predict the parcellation label of each fiber tract.\nGCNNs are capable of extracting the geometric features of each fiber tract and\nharnessing the resulting features for accurate fiber parcellation and\nultimately avoiding the use of atlases and any registration method. We evaluate\nDeepBundle using data from the Human Connectome Project. Experimental results\ndemonstrate the advantages of DeepBundle and suggest that the geometric\nfeatures extracted from each fiber tract can be used to effectively parcellate\nthe fiber tracts.", "published": "2019-06-07T12:37:08Z", "version": 2}, {"aid": "1906.03352", "authors": ["Allan Zhou", "Eric Jang", "Daniel Kappler", "Alex Herzog", "Mohi Khansari", "Paul Wohlhart", "Yunfei Bai", "Mrinal Kalakrishnan", "Sergey Levine", "Chelsea Finn"], "title": "Watch, Try, Learn: Meta-Learning from Demonstrations and Reward", "url": "http://arxiv.org/pdf/1906.03352v4", "summary": "Imitation learning allows agents to learn complex behaviors from\ndemonstrations. However, learning a complex vision-based task may require an\nimpractical number of demonstrations. Meta-imitation learning is a promising\napproach towards enabling agents to learn a new task from one or a few\ndemonstrations by leveraging experience from learning similar tasks. In the\npresence of task ambiguity or unobserved dynamics, demonstrations alone may not\nprovide enough information; an agent must also try the task to successfully\ninfer a policy. In this work, we propose a method that can learn to learn from\nboth demonstrations and trial-and-error experience with sparse reward feedback.\nIn comparison to meta-imitation, this approach enables the agent to effectively\nand efficiently improve itself autonomously beyond the demonstration data. In\ncomparison to meta-reinforcement learning, we can scale to substantially\nbroader distributions of tasks, as the demonstration reduces the burden of\nexploration. Our experiments show that our method significantly outperforms\nprior approaches on a set of challenging, vision-based control tasks.", "published": "2019-06-07T22:46:35Z", "version": 4}, {"aid": "1906.03516", "authors": ["Sachin Mehta", "Hannaneh Hajishirzi", "Mohammad Rastegari"], "title": "DiCENet: Dimension-wise Convolutions for Efficient Networks", "url": "http://arxiv.org/pdf/1906.03516v3", "summary": "We introduce a novel and generic convolutional unit, DiCE unit, that is built\nusing dimension-wise convolutions and dimension-wise fusion. The dimension-wise\nconvolutions apply light-weight convolutional filtering across each dimension\nof the input tensor while dimension-wise fusion efficiently combines these\ndimension-wise representations; allowing the DiCE unit to efficiently encode\nspatial and channel-wise information contained in the input tensor. The DiCE\nunit is simple and can be seamlessly integrated with any architecture to\nimprove its efficiency and performance. Compared to depth-wise separable\nconvolutions, the DiCE unit shows significant improvements across different\narchitectures. When DiCE units are stacked to build the DiCENet model, we\nobserve significant improvements over state-of-the-art models across various\ncomputer vision tasks including image classification, object detection, and\nsemantic segmentation. On the ImageNet dataset, the DiCENet delivers 2-4%\nhigher accuracy than state-of-the-art manually designed models (e.g.,\nMobileNetv2 and ShuffleNetv2). Also, DiCENet generalizes better to tasks (e.g.,\nobject detection) that are often used in resource-constrained devices in\ncomparison to state-of-the-art separable convolution-based efficient networks,\nincluding neural search-based methods (e.g., MobileNetv3 and MixNet. Our source\ncode in PyTorch is open-source and is available at\nhttps://github.com/sacmehta/EdgeNets/", "published": "2019-06-08T20:17:06Z", "version": 3}, {"aid": "1906.04721", "authors": ["Markus Nagel", "Mart van Baalen", "Tijmen Blankevoort", "Max Welling"], "title": "Data-Free Quantization Through Weight Equalization and Bias Correction", "url": "http://arxiv.org/pdf/1906.04721v3", "summary": "We introduce a data-free quantization method for deep neural networks that\ndoes not require fine-tuning or hyperparameter selection. It achieves\nnear-original model performance on common computer vision architectures and\ntasks. 8-bit fixed-point quantization is essential for efficient inference on\nmodern deep learning hardware. However, quantizing models to run in 8-bit is a\nnon-trivial task, frequently leading to either significant performance\nreduction or engineering time spent on training a network to be amenable to\nquantization. Our approach relies on equalizing the weight ranges in the\nnetwork by making use of a scale-equivariance property of activation functions.\nIn addition the method corrects biases in the error that are introduced during\nquantization. This improves quantization accuracy performance, and can be\napplied to many common computer vision architectures with a straight forward\nAPI call. For common architectures, such as the MobileNet family, we achieve\nstate-of-the-art quantized model performance. We further show that the method\nalso extends to other computer vision architectures and tasks such as semantic\nsegmentation and object detection.", "published": "2019-06-11T17:47:51Z", "version": 3}, {"aid": "1906.04893", "authors": ["Mahyar Fazlyab", "Alexander Robey", "Hamed Hassani", "Manfred Morari", "George J. Pappas"], "title": "Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks", "url": "http://arxiv.org/pdf/1906.04893v2", "summary": "Tight estimation of the Lipschitz constant for deep neural networks (DNNs) is\nuseful in many applications ranging from robustness certification of\nclassifiers to stability analysis of closed-loop systems with reinforcement\nlearning controllers. Existing methods in the literature for estimating the\nLipschitz constant suffer from either lack of accuracy or poor scalability. In\nthis paper, we present a convex optimization framework to compute guaranteed\nupper bounds on the Lipschitz constant of DNNs both accurately and efficiently.\nOur main idea is to interpret activation functions as gradients of convex\npotential functions. Hence, they satisfy certain properties that can be\ndescribed by quadratic constraints. This particular description allows us to\npose the Lipschitz constant estimation problem as a semidefinite program (SDP).\nThe resulting SDP can be adapted to increase either the estimation accuracy (by\ncapturing the interaction between activation functions of different layers) or\nscalability (by decomposition and parallel implementation). We illustrate the\nutility of our approach with a variety of experiments on randomly generated\nnetworks and on classifiers trained on the MNIST and Iris datasets. In\nparticular, we experimentally demonstrate that our Lipschitz bounds are the\nmost accurate compared to those in the literature. We also study the impact of\nadversarial training methods on the Lipschitz bounds of the resulting\nclassifiers and show that our bounds can be used to efficiently provide\nrobustness guarantees.", "published": "2019-06-12T02:18:19Z", "version": 2}, {"aid": "1906.05909", "authors": ["Prajit Ramachandran", "Niki Parmar", "Ashish Vaswani", "Irwan Bello", "Anselm Levskaya", "Jonathon Shlens"], "title": "Stand-Alone Self-Attention in Vision Models", "url": "http://arxiv.org/pdf/1906.05909v1", "summary": "Convolutions are a fundamental building block of modern computer vision\nsystems. Recent approaches have argued for going beyond convolutions in order\nto capture long-range dependencies. These efforts focus on augmenting\nconvolutional models with content-based interactions, such as self-attention\nand non-local means, to achieve gains on a number of vision tasks. The natural\nquestion that arises is whether attention can be a stand-alone primitive for\nvision models instead of serving as just an augmentation on top of\nconvolutions. In developing and testing a pure self-attention vision model, we\nverify that self-attention can indeed be an effective stand-alone layer. A\nsimple procedure of replacing all instances of spatial convolutions with a form\nof self-attention applied to ResNet model produces a fully self-attentional\nmodel that outperforms the baseline on ImageNet classification with 12% fewer\nFLOPS and 29% fewer parameters. On COCO object detection, a pure self-attention\nmodel matches the mAP of a baseline RetinaNet while having 39% fewer FLOPS and\n34% fewer parameters. Detailed ablation studies demonstrate that self-attention\nis especially impactful when used in later layers. These results establish that\nstand-alone self-attention is an important addition to the vision\npractitioner's toolbox.", "published": "2019-06-13T19:43:01Z", "version": 1}, {"aid": "1906.06841", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Byungmoon Kim", "Dinesh Manocha"], "title": "LPaintB: Learning to Paint from Self-Supervision", "url": "http://arxiv.org/pdf/1906.06841v2", "summary": "We present a novel reinforcement learning-based natural media painting\nalgorithm. Our goal is to reproduce a reference image using brush strokes and\nwe encode the objective through observations. Our formulation takes into\naccount that the distribution of the reward in the action space is sparse and\ntraining a reinforcement learning algorithm from scratch can be difficult. We\npresent an approach that combines self-supervised learning and reinforcement\nlearning to effectively transfer negative samples into positive ones and change\nthe reward distribution. We demonstrate the benefits of our painting agent to\nreproduce reference images with brush strokes. The training phase takes about\none hour and the runtime algorithm takes about 30 seconds on a GTX1080 GPU\nreproducing a 1000x800 image with 20,000 strokes.", "published": "2019-06-17T04:52:15Z", "version": 2}, {"aid": "1906.07413", "authors": ["Kaidi Cao", "Colin Wei", "Adrien Gaidon", "Nikos Arechiga", "Tengyu Ma"], "title": "Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss", "url": "http://arxiv.org/pdf/1906.07413v2", "summary": "Deep learning algorithms can fare poorly when the training dataset suffers\nfrom heavy class-imbalance but the testing criterion requires good\ngeneralization on less frequent classes. We design two novel methods to improve\nperformance in such scenarios. First, we propose a theoretically-principled\nlabel-distribution-aware margin (LDAM) loss motivated by minimizing a\nmargin-based generalization bound. This loss replaces the standard\ncross-entropy objective during training and can be applied with prior\nstrategies for training with class-imbalance such as re-weighting or\nre-sampling. Second, we propose a simple, yet effective, training schedule that\ndefers re-weighting until after the initial stage, allowing the model to learn\nan initial representation while avoiding some of the complications associated\nwith re-weighting or re-sampling. We test our methods on several benchmark\nvision tasks including the real-world imbalanced dataset iNaturalist 2018. Our\nexperiments show that either of these methods alone can already improve over\nexisting techniques and their combination achieves even better performance\ngains.", "published": "2019-06-18T07:21:18Z", "version": 2}, {"aid": "1906.08804", "authors": ["Alianna J. Maren"], "title": "Derivation of the Variational Bayes Equations", "url": "http://arxiv.org/pdf/1906.08804v6", "summary": "The derivation of key equations for the variational Bayes approach is\nwell-known in certain circles. However, translating the fundamental derivations\n(e.g., as found in Beal's work) to Friston's notation is somewhat delicate.\nFurther, the notion of using variational Bayes in the context of a system with\na Markov blanket requires special attention. This Technical Report presents the\nderivation in detail. It further illustrates how the variational Bayes method\nprovides a framework for a new computational engine, incorporating the 2-D\ncluster variation method (CVM), which provides a necessary free energy equation\nthat can be minimized across both the external and representational systems'\nstates, respectively.", "published": "2019-06-20T18:43:47Z", "version": 6}, {"aid": "1907.01361", "authors": ["Matias Tassano", "Julie Delon", "Thomas Veit"], "title": "FastDVDnet: Towards Real-Time Deep Video Denoising Without Flow Estimation", "url": "http://arxiv.org/pdf/1907.01361v2", "summary": "In this paper, we propose a state-of-the-art video denoising algorithm based\non a convolutional neural network architecture. Until recently, video denoising\nwith neural networks had been a largely under explored domain, and existing\nmethods could not compete with the performance of the best patch-based methods.\nThe approach we introduce in this paper, called FastDVDnet, shows similar or\nbetter performance than other state-of-the-art competitors with significantly\nlower computing times. In contrast to other existing neural network denoisers,\nour algorithm exhibits several desirable properties such as fast runtimes, and\nthe ability to handle a wide range of noise levels with a single network model.\nThe characteristics of its architecture make it possible to avoid using a\ncostly motion compensation stage while achieving excellent performance. The\ncombination between its denoising performance and lower computational load\nmakes this algorithm attractive for practical denoising applications. We\ncompare our method with different state-of-art algorithms, both visually and\nwith respect to objective quality metrics.", "published": "2019-07-01T14:10:34Z", "version": 2}, {"aid": "1907.03876", "authors": ["Beren Millidge"], "title": "Deep Active Inference as Variational Policy Gradients", "url": "http://arxiv.org/pdf/1907.03876v1", "summary": "Active Inference is a theory of action arising from neuroscience which casts\naction and planning as a bayesian inference problem to be solved by minimizing\na single quantity - the variational free energy. Active Inference promises a\nunifying account of action and perception coupled with a biologically plausible\nprocess theory. Despite these potential advantages, current implementations of\nActive Inference can only handle small, discrete policy and state-spaces and\ntypically require the environmental dynamics to be known. In this paper we\npropose a novel deep Active Inference algorithm which approximates key\ndensities using deep neural networks as flexible function approximators, which\nenables Active Inference to scale to significantly larger and more complex\ntasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and\nobtain performance comparable with common reinforcement learning baselines.\nMoreover, our algorithm shows similarities with maximum entropy reinforcement\nlearning and the policy gradients algorithm, which reveals interesting\nconnections between the Active Inference framework and reinforcement learning.", "published": "2019-07-08T21:14:29Z", "version": 1}, {"aid": "1907.04312", "authors": ["Boyi Li", "Felix Wu", "Kilian Q. Weinberger", "Serge Belongie"], "title": "Positional Normalization", "url": "http://arxiv.org/pdf/1907.04312v2", "summary": "A popular method to reduce the training time of deep neural networks is to\nnormalize activations at each layer. Although various normalization schemes\nhave been proposed, they all follow a common theme: normalize across spatial\ndimensions and discard the extracted statistics. In this paper, we propose an\nalternative normalization method that noticeably departs from this convention\nand normalizes exclusively across channels. We argue that the channel dimension\nis naturally appealing as it allows us to extract the first and second moments\nof features extracted at a particular image position. These moments capture\nstructural information about the input image and extracted features, which\nopens a new avenue along which a network can benefit from feature\nnormalization: Instead of disregarding the normalization constants, we propose\nto re-inject them into later layers to preserve or transfer structural\ninformation in generative networks. Codes are available at\nhttps://github.com/Boyiliee/PONO.", "published": "2019-07-09T17:52:01Z", "version": 2}, {"aid": "1907.06592", "authors": ["Paschalis Bizopoulos", "Dimitrios Koutsouris"], "title": "Sparsely Activated Networks", "url": "http://arxiv.org/pdf/1907.06592v11", "summary": "Previous literature on unsupervised learning focused on designing structural\npriors with the aim of learning meaningful features. However, this was done\nwithout considering the description length of the learned representations which\nis a direct and unbiased measure of the model complexity. In this paper, first\nwe introduce the $\\varphi$ metric that evaluates unsupervised models based on\ntheir reconstruction accuracy and the degree of compression of their internal\nrepresentations. We then present and define two activation functions (Identity,\nReLU) as base of reference and three sparse activation functions (top-k\nabsolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize\nthe previously defined $\\varphi$. We lastly present Sparsely Activated Networks\n(SANs) that consist of kernels with shared weights that, during encoding, are\nconvolved with the input and then passed through a sparse activation function.\nDuring decoding, the same weights are convolved with the sparse activation map\nand subsequently the partial reconstructions from each weight are summed to\nreconstruct the input. We compare SANs using the five previously defined\nactivation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,\nFMNIST) and show that models that are selected using $\\varphi$ have small\ndescription representation length and consist of interpretable kernels.", "published": "2019-07-12T08:01:47Z", "version": 11}, {"aid": "1907.05686", "authors": ["Pierre Stock", "Armand Joulin", "R\u00e9mi Gribonval", "Benjamin Graham", "Herv\u00e9 J\u00e9gou"], "title": "And the Bit Goes Down: Revisiting the Quantization of Neural Networks", "url": "http://arxiv.org/pdf/1907.05686v5", "summary": "In this paper, we address the problem of reducing the memory footprint of\nconvolutional network architectures. We introduce a vector quantization method\nthat aims at preserving the quality of the reconstruction of the network\noutputs rather than its weights. The principle of our approach is that it\nminimizes the loss reconstruction error for in-domain inputs. Our method only\nrequires a set of unlabelled data at quantization time and allows for efficient\ninference on CPU by using byte-aligned codebooks to store the compressed\nweights. We validate our approach by quantizing a high performing ResNet-50\nmodel to a memory size of 5MB (20x compression factor) while preserving a top-1\naccuracy of 76.1% on ImageNet object classification and by compressing a Mask\nR-CNN with a 26x factor.", "published": "2019-07-12T11:52:54Z", "version": 5}, {"aid": "1907.06916", "authors": ["Mark D. McDonnell", "Hesham Mostafa", "Runchun Wang", "Andre van Schaik"], "title": "Single-bit-per-weight deep convolutional neural networks without batch-normalization layers for embedded systems", "url": "http://arxiv.org/pdf/1907.06916v2", "summary": "Batch-normalization (BN) layers are thought to be an integrally important\nlayer type in today's state-of-the-art deep convolutional neural networks for\ncomputer vision tasks such as classification and detection. However, BN layers\nintroduce complexity and computational overheads that are highly undesirable\nfor training and/or inference on low-power custom hardware implementations of\nreal-time embedded vision systems such as UAVs, robots and Internet of Things\n(IoT) devices. They are also problematic when batch sizes need to be very small\nduring training, and innovations such as residual connections introduced more\nrecently than BN layers could potentially have lessened their impact. In this\npaper we aim to quantify the benefits BN layers offer in image classification\nnetworks, in comparison with alternative choices. In particular, we study\nnetworks that use shifted-ReLU layers instead of BN layers. We found, following\nexperiments with wide residual networks applied to the ImageNet, CIFAR 10 and\nCIFAR 100 image classification datasets, that BN layers do not consistently\noffer a significant advantage. We found that the accuracy margin offered by BN\nlayers depends on the data set, the network size, and the bit-depth of weights.\nWe conclude that in situations where BN layers are undesirable due to speed,\nmemory or complexity costs, that using shifted-ReLU layers instead should be\nconsidered; we found they can offer advantages in all these areas, and often do\nnot impose a significant accuracy cost.", "published": "2019-07-16T09:42:02Z", "version": 2}, {"aid": "1907.08610", "authors": ["Michael R. Zhang", "James Lucas", "Geoffrey Hinton", "Jimmy Ba"], "title": "Lookahead Optimizer: k steps forward, 1 step back", "url": "http://arxiv.org/pdf/1907.08610v2", "summary": "The vast majority of successful deep neural networks are trained using\nvariants of stochastic gradient descent (SGD) algorithms. Recent attempts to\nimprove SGD can be broadly categorized into two approaches: (1) adaptive\nlearning rate schemes, such as AdaGrad and Adam, and (2) accelerated schemes,\nsuch as heavy-ball and Nesterov momentum. In this paper, we propose a new\noptimization algorithm, Lookahead, that is orthogonal to these previous\napproaches and iteratively updates two sets of weights. Intuitively, the\nalgorithm chooses a search direction by looking ahead at the sequence of fast\nweights generated by another optimizer. We show that Lookahead improves the\nlearning stability and lowers the variance of its inner optimizer with\nnegligible computation and memory cost. We empirically demonstrate Lookahead\ncan significantly improve the performance of SGD and Adam, even with their\ndefault hyperparameter settings on ImageNet, CIFAR-10/100, neural machine\ntranslation, and Penn Treebank.", "published": "2019-07-19T17:59:50Z", "version": 2}, {"aid": "1907.08650", "authors": ["Khushbu Agarwal", "Tome Eftimov", "Raghavendra Addanki", "Sutanay Choudhury", "Suzanne Tamang", "Robert Rallo"], "title": "Snomed2Vec: Random Walk and Poincar\u00e9 Embeddings of a Clinical Knowledge Base for Healthcare Analytics", "url": "http://arxiv.org/pdf/1907.08650v1", "summary": "Representation learning methods that transform encoded data (e.g., diagnosis\nand drug codes) into continuous vector spaces (i.e., vector embeddings) are\ncritical for the application of deep learning in healthcare. Initial work in\nthis area explored the use of variants of the word2vec algorithm to learn\nembeddings for medical concepts from electronic health records or medical\nclaims datasets. We propose learning embeddings for medical concepts by using\ngraph-based representation learning methods on SNOMED-CT, a widely popular\nknowledge graph in the healthcare domain with numerous operational and research\napplications. Current work presents an empirical analysis of various embedding\nmethods, including the evaluation of their performance on multiple tasks of\nbiomedical relevance (node classification, link prediction, and patient state\nprediction). Our results show that concept embeddings derived from the\nSNOMED-CT knowledge graph significantly outperform state-of-the-art embeddings,\nshowing 5-6x improvement in ``concept similarity\" and 6-20\\% improvement in\npatient diagnosis.", "published": "2019-07-19T19:11:39Z", "version": 1}, {"aid": "1907.08801", "authors": ["Amadeus Maes", "Mauricio Barahona", "Claudia Clopath"], "title": "Learning spatiotemporal signals using a recurrent spiking network that discretizes time", "url": "http://arxiv.org/pdf/1907.08801v2", "summary": "Learning to produce spatiotemporal sequences is a common task that the brain\nhas to solve. The same neural substrate may be used by the brain to produce\ndifferent sequential behaviours. The way the brain learns and encodes such\ntasks remains unknown as current computational models do not typically use\nrealistic biologically-plausible learning. Here, we propose a model where a\nspiking recurrent network of excitatory and inhibitory biophysical neurons\ndrives a read-out layer: the dynamics of the driver recurrent network is\ntrained to encode time which is then mapped through the read-out neurons to\nencode another dimension, such as space or a phase. Different spatiotemporal\npatterns can be learned and encoded through the synaptic weights to the\nread-out neurons that follow common Hebbian learning rules. We demonstrate that\nthe model is able to learn spatiotemporal dynamics on time scales that are\nbehaviourally relevant and we show that the learned sequences are robustly\nreplayed during a regime of spontaneous activity.", "published": "2019-07-20T11:54:20Z", "version": 2}, {"aid": "1907.09008", "authors": ["Dong Wang", "Yicheng Liu", "Wenwo Tang", "Fanhua Shang", "Hongying Liu", "Qigong Sun", "Licheng Jiao"], "title": "signADAM: Learning Confidences for Deep Neural Networks", "url": "http://arxiv.org/pdf/1907.09008v1", "summary": "In this paper, we propose a new first-order gradient-based algorithm to train\ndeep neural networks. We first introduce the sign operation of stochastic\ngradients (as in sign-based methods, e.g., SIGN-SGD) into ADAM, which is called\nas signADAM. Moreover, in order to make the rate of fitting each feature\ncloser, we define a confidence function to distinguish different components of\ngradients and apply it to our algorithm. It can generate more sparse gradients\nthan existing algorithms do. We call this new algorithm signADAM++. In\nparticular, both our algorithms are easy to implement and can speed up training\nof various deep neural networks. The motivation of signADAM++ is preferably\nlearning features from the most different samples by updating large and useful\ngradients regardless of useless information in stochastic gradients. We also\nestablish theoretical convergence guarantees for our algorithms. Empirical\nresults on various datasets and models show that our algorithms yield much\nbetter performance than many state-of-the-art algorithms including SIGN-SGD,\nSIGNUM and ADAM. We also analyze the performance from multiple perspectives\nincluding the loss landscape and develop an adaptive method to further improve\ngeneralization. The source code is available at\nhttps://github.com/DongWanginxdu/signADAM-Learn-by-Confidence.", "published": "2019-07-21T17:08:50Z", "version": 1}, {"aid": "1907.09472", "authors": ["Alexandru Baltag", "Soroush Rafiee Rad", "Sonja Smets"], "title": "Learning Probabilities: Towards a Logic of Statistical Learning", "url": "http://arxiv.org/pdf/1907.09472v1", "summary": "We propose a new model for forming beliefs and learning about unknown\nprobabilities (such as the probability of picking a red marble from a bag with\nan unknown distribution of coloured marbles). The most widespread model for\nsuch situations of 'radical uncertainty' is in terms of imprecise\nprobabilities, i.e. representing the agent's knowledge as a set of probability\nmeasures. We add to this model a plausibility map, associating to each measure\na plausibility number, as a way to go beyond what is known with certainty and\nrepresent the agent's beliefs about probability. There are a number of standard\nexamples: Shannon Entropy, Centre of Mass etc. We then consider learning of two\ntypes of information: (1) learning by repeated sampling from the unknown\ndistribution (e.g. picking marbles from the bag); and (2) learning higher-order\ninformation about the distribution (in the shape of linear inequalities, e.g.\nwe are told there are more red marbles than green marbles). The first changes\nonly the plausibility map (via a 'plausibilistic' version of Bayes' Rule), but\nleaves the given set of measures unchanged; the second shrinks the set of\nmeasures, without changing their plausibility. Beliefs are defined as in Belief\nRevision Theory, in terms of truth in the most plausible worlds. But our belief\nchange does not comply with standard AGM axioms, since the revision induced by\n(1) is of a non-AGM type. This is essential, as it allows our agents to learn\nthe true probability: we prove that the beliefs obtained by repeated sampling\nconverge almost surely to the correct belief (in the true probability). We end\nby sketching the contours of a dynamic doxastic logic for statistical learning.", "published": "2019-07-22T03:13:04Z", "version": 1}, {"aid": "1907.09200", "authors": ["Matthew C. H. Lee", "Ozan Oktay", "Andreas Schuh", "Michiel Schaap", "Ben Glocker"], "title": "Image-and-Spatial Transformer Networks for Structure-Guided Image Registration", "url": "http://arxiv.org/pdf/1907.09200v1", "summary": "Image registration with deep neural networks has become an active field of\nresearch and exciting avenue for a long standing problem in medical imaging.\nThe goal is to learn a complex function that maps the appearance of input image\npairs to parameters of a spatial transformation in order to align corresponding\nanatomical structures. We argue and show that the current direct, non-iterative\napproaches are sub-optimal, in particular if we seek accurate alignment of\nStructures-of-Interest (SoI). Information about SoI is often available at\ntraining time, for example, in form of segmentations or landmarks. We introduce\na novel, generic framework, Image-and-Spatial Transformer Networks (ISTNs), to\nleverage SoI information allowing us to learn new image representations that\nare optimised for the downstream registration task. Thanks to these\nrepresentations we can employ a test-specific, iterative refinement over the\ntransformation parameters which yields highly accurate registration even with\nvery limited training data. Performance is demonstrated on pairwise 3D brain\nregistration and illustrative synthetic data.", "published": "2019-07-22T09:39:53Z", "version": 1}, {"aid": "1907.09245", "authors": ["Kaan Karaman", "Erhan Gundogdu", "Aykut Koc", "A. Aydin Alatan"], "title": "Quadruplet Selection Methods for Deep Embedding Learning", "url": "http://arxiv.org/pdf/1907.09245v1", "summary": "Recognition of objects with subtle differences has been used in many\npractical applications, such as car model recognition and maritime vessel\nidentification. For discrimination of the objects in fine-grained detail, we\nfocus on deep embedding learning by using a multi-task learning framework, in\nwhich the hierarchical labels (coarse and fine labels) of the samples are\nutilized both for classification and a quadruplet-based loss function. In order\nto improve the recognition strength of the learned features, we present a novel\nfeature selection method specifically designed for four training samples of a\nquadruplet. By experiments, it is observed that the selection of very hard\nnegative samples with relatively easy positive ones from the same coarse and\nfine classes significantly increases some performance metrics in a fine-grained\ndataset when compared to selecting the quadruplet samples randomly. The feature\nembedding learned by the proposed method achieves favorable performance against\nits state-of-the-art counterparts.", "published": "2019-07-22T11:39:15Z", "version": 1}, {"aid": "1907.10473", "authors": ["Ping Luo", "Ruimao Zhang", "Jiamin Ren", "Zhanglin Peng", "Jingyu Li"], "title": "Switchable Normalization for Learning-to-Normalize Deep Representation", "url": "http://arxiv.org/pdf/1907.10473v1", "summary": "We address a learning-to-normalize problem by proposing Switchable\nNormalization (SN), which learns to select different normalizers for different\nnormalization layers of a deep neural network. SN employs three distinct scopes\nto compute statistics (means and variances) including a channel, a layer, and a\nminibatch. SN switches between them by learning their importance weights in an\nend-to-end manner. It has several good properties. First, it adapts to various\nnetwork architectures and tasks. Second, it is robust to a wide range of batch\nsizes, maintaining high performance even when small minibatch is presented\n(e.g. 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike\ngroup normalization that searches the number of groups as a hyper-parameter.\nWithout bells and whistles, SN outperforms its counterparts on various\nchallenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, MegaFace,\nand Kinetics. Analyses of SN are also presented to answer the following three\nquestions: (a) Is it useful to allow each normalization layer to select its own\nnormalizer? (b) What impacts the choices of normalizers? (c) Do different tasks\nand datasets prefer different normalizers? We hope SN will help ease the usage\nand understand the normalization techniques in deep learning. The code of SN\nhas been released at https://github.com/switchablenorms.", "published": "2019-07-22T17:50:31Z", "version": 1}, {"aid": "1907.09533", "authors": ["Ozan \u00d6zdenizci", "Timm Meyer", "Felix Wichmann", "Jan Peters", "Bernhard Sch\u00f6lkopf", "M\u00fcjdat \u00c7etin", "Moritz Grosse-Wentrup"], "title": "Neural Signatures of Motor Skill in the Resting Brain", "url": "http://arxiv.org/pdf/1907.09533v1", "summary": "Stroke-induced disturbances of large-scale cortical networks are known to be\nassociated with the extent of motor deficits. We argue that identifying brain\nnetworks representative of motor behavior in the resting brain would provide\nsignificant insights for current neurorehabilitation approaches. Particularly,\nwe aim to investigate the global configuration of brain rhythms and their\nrelation to motor skill, instead of learning performance as broadly studied. We\nempirically approach this problem by conducting a three-dimensional physical\nspace visuomotor learning experiment during electroencephalographic (EEG) data\nrecordings with thirty-seven healthy participants. We demonstrate that\nacross-subjects variations in average movement smoothness as the quantified\nmeasure of subjects' motor skills can be predicted from the global\nconfiguration of resting-state EEG alpha-rhythms (8-14 Hz) recorded prior to\nthe experiment. Importantly, this neural signature of motor skill was found to\nbe orthogonal to (independent of) task -- as well as to learning-related\nchanges in alpha-rhythms, which we interpret as an organizing principle of the\nbrain. We argue that disturbances of such configurations in the brain may\ncontribute to motor deficits in stroke, and that reconfiguring stroke patients'\nbrain rhythms by neurofeedback may enhance post-stroke neurorehabilitation.", "published": "2019-07-22T19:09:13Z", "version": 1}, {"aid": "1907.09540", "authors": ["Ozan Ozdenizci", "Barry Oken", "Tab Memmott", "Melanie Fried-Oken", "Deniz Erdogmus"], "title": "Adversarial Feature Learning in Brain Interfacing: An Experimental Study on Eliminating Drowsiness Effects", "url": "http://arxiv.org/pdf/1907.09540v1", "summary": "Across- and within-recording variabilities in electroencephalographic (EEG)\nactivity is a major limitation in EEG-based brain-computer interfaces (BCIs).\nSpecifically, gradual changes in fatigue and vigilance levels during long EEG\nrecording durations and BCI system usage bring along significant fluctuations\nin BCI performances even when these systems are calibrated daily. We address\nthis in an experimental offline study from EEG-based BCI speller usage data\nacquired for one hour duration. As the main part of our methodological\napproach, we propose the concept of adversarial invariant feature learning for\nBCIs as a regularization approach on recently expanding EEG deep learning\narchitectures, to learn nuisance-invariant discriminative features. We\nempirically demonstrate the feasibility of adversarial feature learning on\neliminating drowsiness effects from event related EEG activity features, by\nusing temporal recording block ordering as the source of drowsiness\nvariability.", "published": "2019-07-22T19:28:37Z", "version": 1}, {"aid": "1907.10597", "authors": ["Roy Schwartz", "Jesse Dodge", "Noah A. Smith", "Oren Etzioni"], "title": "Green AI", "url": "http://arxiv.org/pdf/1907.10597v3", "summary": "The computations required for deep learning research have been doubling every\nfew months, resulting in an estimated 300,000x increase from 2012 to 2018 [2].\nThese computations have a surprisingly large carbon footprint [38]. Ironically,\ndeep learning was inspired by the human brain, which is remarkably energy\nefficient. Moreover, the financial cost of the computations can make it\ndifficult for academics, students, and researchers, in particular those from\nemerging economies, to engage in deep learning research.\n  This position paper advocates a practical solution by making efficiency an\nevaluation criterion for research alongside accuracy and related measures. In\naddition, we propose reporting the financial cost or \"price tag\" of developing,\ntraining, and running models to provide baselines for the investigation of\nincreasingly efficient methods. Our goal is to make AI both greener and more\ninclusive---enabling any inspired undergraduate with a laptop to write\nhigh-quality research papers. Green AI is an emerging focus at the Allen\nInstitute for AI.", "published": "2019-07-22T19:36:18Z", "version": 3}, {"aid": "1907.09595", "authors": ["Mingxing Tan", "Quoc V. Le"], "title": "MixConv: Mixed Depthwise Convolutional Kernels", "url": "http://arxiv.org/pdf/1907.09595v3", "summary": "Depthwise convolution is becoming increasingly popular in modern efficient\nConvNets, but its kernel size is often overlooked. In this paper, we\nsystematically study the impact of different kernel sizes, and observe that\ncombining the benefits of multiple kernel sizes can lead to better accuracy and\nefficiency. Based on this observation, we propose a new mixed depthwise\nconvolution (MixConv), which naturally mixes up multiple kernel sizes in a\nsingle convolution. As a simple drop-in replacement of vanilla depthwise\nconvolution, our MixConv improves the accuracy and efficiency for existing\nMobileNets on both ImageNet classification and COCO object detection. To\ndemonstrate the effectiveness of MixConv, we integrate it into AutoML search\nspace and develop a new family of models, named as MixNets, which outperform\nprevious mobile models including MobileNetV2 [20] (ImageNet top-1 accuracy\n+4.2%), ShuffleNetV2 [16] (+3.5%), MnasNet [26] (+1.3%), ProxylessNAS [2]\n(+2.2%), and FBNet [27] (+2.0%). In particular, our MixNet-L achieves a new\nstate-of-the-art 78.9% ImageNet top-1 accuracy under typical mobile settings\n(<600M FLOPS). Code is at https://github.com/\ntensorflow/tpu/tree/master/models/official/mnasnet/mixnet", "published": "2019-07-22T21:49:25Z", "version": 3}, {"aid": "1907.09798", "authors": ["Liang Pan", "Chee-Meng Chew", "Gim Hee Lee"], "title": "PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points", "url": "http://arxiv.org/pdf/1907.09798v2", "summary": "Motivated by the success of encoding multi-scale contextual information for\nimage analysis, we propose our PointAtrousGraph (PAG) - a deep\npermutation-invariant hierarchical encoder-decoder for efficiently exploiting\nmulti-scale edge features in point clouds. Our PAG is constructed by several\nnovel modules, such as Point Atrous Convolution (PAC), Edge-preserved Pooling\n(EP) and Edge-preserved Unpooling (EU). Similar with atrous convolution, our\nPAC can effectively enlarge receptive fields of filters and thus densely learn\nmulti-scale point features. Following the idea of non-overlapping max-pooling\noperations, we propose our EP to preserve critical edge features during\nsubsampling. Correspondingly, our EU modules gradually recover spatial\ninformation for edge features. In addition, we introduce chained skip\nsubsampling/upsampling modules that directly propagate edge features to the\nfinal stage. Particularly, our proposed auxiliary loss functions can further\nimprove our performance. Experimental results show that our PAG outperform\nprevious state-of-the-art methods on various 3D semantic perception\napplications.", "published": "2019-07-23T10:16:58Z", "version": 2}, {"aid": "1907.10060", "authors": ["Massimiliano Zanin", "Bahar G\u00fcntekin", "Tuba Akt\u00fcrk", "L\u00fctf\u00fc Hano\u011flu", "David Papo"], "title": "Time irreversibility of resting brain activity in the healthy brain and pathology", "url": "http://arxiv.org/pdf/1907.10060v1", "summary": "Characterising brain activity at rest is of paramount importance to our\nunderstanding both of general principles of brain functioning and of the way\nbrain dynamics is affected in the presence of neurological or psychiatric\npathologies. We measured the time-reversal symmetry of spontaneous\nelectroencephalographic brain activity recorded from three groups of patients\nand their respective control group under two experimental conditions (eyes open\nand closed). We evaluated differences in time irreversibility in terms of\npossible underlying physical generating mechanisms. The results showed that\nresting brain activity is generically time-irreversible at sufficiently long\ntime scales, and that brain pathology is generally associated with a reduction\nin time-asymmetry, albeit with pathology-specific patterns. The significance of\nthese results and their possible dynamical aetiology are discussed. Some\nimplications of the differential modulation of time asymmetry by pathology and\nexperimental condition are examined.", "published": "2019-07-23T16:37:55Z", "version": 1}, {"aid": "1907.10104", "authors": ["Omid Abdollahi Aghdam", "Behzad Bozorgtabar", "Haz\u0131m Kemal Ekenel", "Jean-Philippe Thiran"], "title": "Exploring Factors for Improving Low Resolution Face Recognition", "url": "http://arxiv.org/pdf/1907.10104v2", "summary": "State-of-the-art deep face recognition approaches report near perfect\nperformance on popular benchmarks, e.g., Labeled Faces in the Wild. However,\ntheir performance deteriorates significantly when they are applied on low\nquality images, such as those acquired by surveillance cameras. A further\nchallenge for low resolution face recognition for surveillance applications is\nthe matching of recorded low resolution probe face images with high resolution\nreference images, which could be the case in watchlist scenarios. In this\npaper, we have addressed these problems and investigated the factors that would\ncontribute to the identification performance of the state-of-the-art deep face\nrecognition models when they are applied to low resolution face recognition\nunder mismatched conditions. We have observed that the following factors affect\nperformance in a positive way: appearance variety and resolution distribution\nof the training dataset, resolution matching between the gallery and probe\nimages, and the amount of information included in the probe images. By\nleveraging this information, we have utilized deep face models trained on\nMS-Celeb-1M and fine-tuned on VGGFace2 dataset and achieved state-of-the-art\naccuracies on the SCFace and ICB-RW benchmarks, even without using any training\ndata from the datasets of these benchmarks.", "published": "2019-07-23T19:16:48Z", "version": 2}, {"aid": "1907.10107", "authors": ["Mengyao Zhai", "Lei Chen", "Fred Tung", "Jiawei He", "Megha Nawhal", "Greg Mori"], "title": "Lifelong GAN: Continual Learning for Conditional Image Generation", "url": "http://arxiv.org/pdf/1907.10107v2", "summary": "Lifelong learning is challenging for deep neural networks due to their\nsusceptibility to catastrophic forgetting. Catastrophic forgetting occurs when\na trained network is not able to maintain its ability to accomplish previously\nlearned tasks when it is trained to perform new tasks. We study the problem of\nlifelong learning for generative models, extending a trained network to new\nconditional generation tasks without forgetting previous tasks, while assuming\naccess to the training data for the current task only. In contrast to\nstate-of-the-art memory replay based approaches which are limited to\nlabel-conditioned image generation tasks, a more generic framework for\ncontinual learning of generative models under different conditional image\ngeneration settings is proposed in this paper. Lifelong GAN employs knowledge\ndistillation to transfer learned knowledge from previous networks to the new\nnetwork. This makes it possible to perform image-conditioned generation tasks\nin a lifelong learning setting. We validate Lifelong GAN for both\nimage-conditioned and label-conditioned generation tasks, and provide\nqualitative and quantitative results to show the generality and effectiveness\nof our method.", "published": "2019-07-23T19:25:15Z", "version": 2}, {"aid": "1907.10213", "authors": ["Qi Zhang", "Huafeng Wang", "Sichen Yang"], "title": "Image Super-Resolution Using a Wavelet-based Generative Adversarial Network", "url": "http://arxiv.org/pdf/1907.10213v1", "summary": "In this paper, we consider the problem of super-resolution recons-truction.\nThis is a hot topic because super-resolution reconstruction has a wide range of\napplications in the medical field, remote sensing monitoring, and criminal\ninvestigation. Compared with traditional algorithms, the current\nsuper-resolution reconstruction algorithm based on deep learning greatly\nimproves the clarity of reconstructed pictures. Existing work like\nSuper-Resolution Using a Generative Adversarial Network (SRGAN) can effectively\nrestore the texture details of the image. However, experimentally verified that\nthe texture details of the image recovered by the SRGAN are not robust. In\norder to get super-resolution reconstructed images with richer high-frequency\ndetails, we improve the network structure and propose a super-resolution\nreconstruction algorithm combining wavelet transform and Generative Adversarial\nNetwork. The proposed algorithm can efficiently reconstruct high-resolution\nimages with rich global information and local texture details. We have trained\nour model by PyTorch framework and VOC2012 dataset, and tested it by Set5,\nSet14, BSD100 and Urban100 test datasets.", "published": "2019-07-24T02:44:41Z", "version": 1}, {"aid": "1907.10244", "authors": ["Hyeongmin Lee", "Taeoh Kim", "Tae-young Chung", "Daehyun Pak", "Yuseok Ban", "Sangyoun Lee"], "title": "AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation", "url": "http://arxiv.org/pdf/1907.10244v3", "summary": "Video frame interpolation is one of the most challenging tasks in video\nprocessing research. Recently, many studies based on deep learning have been\nsuggested. Most of these methods focus on finding locations with useful\ninformation to estimate each output pixel using their own frame warping\noperations. However, many of them have Degrees of Freedom (DoF) limitations and\nfail to deal with the complex motions found in real world videos. To solve this\nproblem, we propose a new warping module named Adaptive Collaboration of Flows\n(AdaCoF). Our method estimates both kernel weights and offset vectors for each\ntarget pixel to synthesize the output frame. AdaCoF is one of the most\ngeneralized warping modules compared to other approaches, and covers most of\nthem as special cases of it. Therefore, it can deal with a significantly wide\ndomain of complex motions. To further improve our framework and synthesize more\nrealistic outputs, we introduce dual-frame adversarial loss which is applicable\nonly to video frame interpolation tasks. The experimental results show that our\nmethod outperforms the state-of-the-art methods for both fixed training set\nenvironments and the Middlebury benchmark.", "published": "2019-07-24T05:40:53Z", "version": 3}, {"aid": "1907.10628", "authors": ["Vinod Kumar Kurmi", "Vipul Bajaj", "Venkatesh K Subramanian", "Vinay P Namboodiri"], "title": "Curriculum based Dropout Discriminator for Domain Adaptation", "url": "http://arxiv.org/pdf/1907.10628v2", "summary": "Domain adaptation is essential to enable wide usage of deep learning based\nnetworks trained using large labeled datasets. Adversarial learning based\ntechniques have shown their utility towards solving this problem using a\ndiscriminator that ensures source and target distributions are close. However,\nhere we suggest that rather than using a point estimate, it would be useful if\na distribution based discriminator could be used to bridge this gap. This could\nbe achieved using multiple classifiers or using traditional ensemble methods.\nIn contrast, we suggest that a Monte Carlo dropout based ensemble discriminator\ncould suffice to obtain the distribution based discriminator. Specifically, we\npropose a curriculum based dropout discriminator that gradually increases the\nvariance of the sample based distribution and the corresponding reverse\ngradients are used to align the source and target feature representations. The\ndetailed results and thorough ablation analysis show that our model outperforms\nstate-of-the-art results.", "published": "2019-07-24T18:00:12Z", "version": 2}, {"aid": "1907.10786", "authors": ["Yujun Shen", "Jinjin Gu", "Xiaoou Tang", "Bolei Zhou"], "title": "Interpreting the Latent Space of GANs for Semantic Face Editing", "url": "http://arxiv.org/pdf/1907.10786v3", "summary": "Despite the recent advance of Generative Adversarial Networks (GANs) in\nhigh-fidelity image synthesis, there lacks enough understanding of how GANs are\nable to map a latent code sampled from a random distribution to a\nphoto-realistic image. Previous work assumes the latent space learned by GANs\nfollows a distributed representation but observes the vector arithmetic\nphenomenon. In this work, we propose a novel framework, called InterFaceGAN,\nfor semantic face editing by interpreting the latent semantics learned by GANs.\nIn this framework, we conduct a detailed study on how different semantics are\nencoded in the latent space of GANs for face synthesis. We find that the latent\ncode of well-trained generative models actually learns a disentangled\nrepresentation after linear transformations. We explore the disentanglement\nbetween various semantics and manage to decouple some entangled semantics with\nsubspace projection, leading to more precise control of facial attributes.\nBesides manipulating gender, age, expression, and the presence of eyeglasses,\nwe can even vary the face pose as well as fix the artifacts accidentally\ngenerated by GAN models. The proposed method is further applied to achieve real\nimage manipulation when combined with GAN inversion methods or some\nencoder-involved models. Extensive results suggest that learning to synthesize\nfaces spontaneously brings a disentangled and controllable facial attribute\nrepresentation.", "published": "2019-07-25T01:30:16Z", "version": 3}, {"aid": "1907.10830", "authors": ["Junho Kim", "Minjae Kim", "Hyeonwoo Kang", "Kwanghee Lee"], "title": "U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation", "url": "http://arxiv.org/pdf/1907.10830v4", "summary": "We propose a novel method for unsupervised image-to-image translation, which\nincorporates a new attention module and a new learnable normalization function\nin an end-to-end manner. The attention module guides our model to focus on more\nimportant regions distinguishing between source and target domains based on the\nattention map obtained by the auxiliary classifier. Unlike previous\nattention-based method which cannot handle the geometric changes between\ndomains, our model can translate both images requiring holistic changes and\nimages requiring large shape changes. Moreover, our new AdaLIN (Adaptive\nLayer-Instance Normalization) function helps our attention-guided model to\nflexibly control the amount of change in shape and texture by learned\nparameters depending on datasets. Experimental results show the superiority of\nthe proposed method compared to the existing state-of-the-art models with a\nfixed network architecture and hyper-parameters. Our code and datasets are\navailable at https://github.com/taki0112/UGATIT or\nhttps://github.com/znxlwm/UGATIT-pytorch.", "published": "2019-07-25T04:17:25Z", "version": 4}, {"aid": "1907.10949", "authors": ["Massimiliano Patacchiola", "Patrick Fox-Roberts", "Edward Rosten"], "title": "Y-Autoencoders: disentangling latent representations via sequential-encoding", "url": "http://arxiv.org/pdf/1907.10949v1", "summary": "In the last few years there have been important advancements in generative\nmodels with the two dominant approaches being Generative Adversarial Networks\n(GANs) and Variational Autoencoders (VAEs). However, standard Autoencoders\n(AEs) and closely related structures have remained popular because they are\neasy to train and adapt to different tasks. An interesting question is if we\ncan achieve state-of-the-art performance with AEs while retaining their good\nproperties. We propose an answer to this question by introducing a new model\ncalled Y-Autoencoder (Y-AE). The structure and training procedure of a Y-AE\nenclose a representation into an implicit and an explicit part. The implicit\npart is similar to the output of an autoencoder and the explicit part is\nstrongly correlated with labels in the training set. The two parts are\nseparated in the latent space by splitting the output of the encoder into two\npaths (forming a Y shape) before decoding and re-encoding. We then impose a\nnumber of losses, such as reconstruction loss, and a loss on dependence between\nthe implicit and explicit parts. Additionally, the projection in the explicit\nmanifold is monitored by a predictor, that is embedded in the encoder and\ntrained end-to-end with no adversarial losses. We provide significant\nexperimental results on various domains, such as separation of style and\ncontent, image-to-image translation, and inverse graphics.", "published": "2019-07-25T10:28:15Z", "version": 1}, {"aid": "1907.11357", "authors": ["Gen Li", "Inyoung Yun", "Jonghyun Kim", "Joongkyu Kim"], "title": "DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation", "url": "http://arxiv.org/pdf/1907.11357v2", "summary": "As a pixel-level prediction task, semantic segmentation needs large\ncomputational cost with enormous parameters to obtain high performance.\nRecently, due to the increasing demand for autonomous systems and robots, it is\nsignificant to make a tradeoff between accuracy and inference speed. In this\npaper, we propose a novel Depthwise Asymmetric Bottleneck (DAB) module to\naddress this dilemma, which efficiently adopts depth-wise asymmetric\nconvolution and dilated convolution to build a bottleneck structure. Based on\nthe DAB module, we design a Depth-wise Asymmetric Bottleneck Network (DABNet)\nespecially for real-time semantic segmentation, which creates sufficient\nreceptive field and densely utilizes the contextual information. Experiments on\nCityscapes and CamVid datasets demonstrate that the proposed DABNet achieves a\nbalance between speed and precision. Specifically, without any pretrained model\nand postprocessing, it achieves 70.1% Mean IoU on the Cityscapes test dataset\nwith only 0.76 million parameters and a speed of 104 FPS on a single GTX 1080Ti\ncard.", "published": "2019-07-26T01:50:31Z", "version": 2}, {"aid": "1907.11432", "authors": ["Kumara Kahatapitiya", "Ranga Rodrigo"], "title": "Exploiting the Redundancy in Convolutional Filters for Parameter Reduction", "url": "http://arxiv.org/pdf/1907.11432v3", "summary": "Convolutional Neural Networks (CNNs) have achieved state-of-the-art\nperformance in many computer vision tasks over the years. However, this comes\nat the cost of heavy computation and memory intensive network designs,\nsuggesting potential improvements in efficiency. Convolutional layers of CNNs\npartly account for such an inefficiency, as they are known to learn redundant\nfeatures. In this work, we exploit this redundancy, observing it as the\ncorrelation between convolutional filters of a layer, and propose an\nalternative approach to reproduce it efficiently. The proposed 'LinearConv'\nlayer learns a set of orthogonal filters, and a set of coefficients that\nlinearly combines them to introduce a controlled redundancy. We introduce a\ncorrelation-based regularization loss to achieve such flexibility over\nredundancy, and control the number of parameters in turn. This is designed as a\nplug-and-play layer to conveniently replace a conventional convolutional layer,\nwithout any additional changes required in the network architecture or the\nhyperparameter settings. Our experiments verify that LinearConv models achieve\na performance on-par with their counterparts, with almost a 50% reduction in\nparameters on average, and the same computational requirement and speed at\ninference.", "published": "2019-07-26T08:39:31Z", "version": 3}, {"aid": "1907.11440", "authors": ["Junhyuk Hyun", "Hongje Seong", "Euntai Kim"], "title": "Universal Pooling -- A New Pooling Method for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1907.11440v1", "summary": "Pooling is one of the main elements in convolutional neural networks. The\npooling reduces the size of the feature map, enabling training and testing with\na limited amount of computation. This paper proposes a new pooling method named\nuniversal pooling. Unlike the existing pooling methods such as average pooling,\nmax pooling, and stride pooling with fixed pooling function, universal pooling\ngenerates any pooling function, depending on a given problem and dataset.\nUniversal pooling was inspired by attention methods and can be considered as a\nchannel-wise form of local spatial attention. Universal pooling is trained\njointly with the main network and it is shown that it includes the existing\npooling methods. Finally, when applied to two benchmark problems, the proposed\nmethod outperformed the existing pooling methods and performed with the\nexpected diversity, adapting to the given problem.", "published": "2019-07-26T09:00:00Z", "version": 1}, {"aid": "1907.11503", "authors": ["Bulla Rajesh", "Mohammed Javed", "Ratnesh", "Shubham Srivastava"], "title": "DCT-CompCNN: A Novel Image Classification Network Using JPEG Compressed DCT Coefficients", "url": "http://arxiv.org/pdf/1907.11503v1", "summary": "The popularity of Convolutional Neural Network (CNN) in the field of Image\nProcessing and Computer Vision has motivated researchers and industrialist\nexperts across the globe to solve different challenges with high accuracy. The\nsimplest way to train a CNN classifier is to directly feed the original RGB\npixels images into the network. However, if we intend to classify images\ndirectly with its compressed data, the same approach may not work better, like\nin case of JPEG compressed images. This research paper investigates the issues\nof modifying the input representation of the JPEG compressed data, and then\nfeeding into the CNN. The architecture is termed as DCT-CompCNN. This novel\napproach has shown that CNNs can also be trained with JPEG compressed DCT\ncoefficients, and subsequently can produce a better performance in comparison\nwith the conventional CNN approach. The efficiency of the modified input\nrepresentation is tested with the existing ResNet-50 architecture and the\nproposed DCT-CompCNN architecture on a public image classification datasets\nlike Dog Vs Cat and CIFAR-10 datasets, reporting a better performance", "published": "2019-07-26T12:01:21Z", "version": 1}, {"aid": "1907.11559", "authors": ["Guilherme Pombo", "Robert Gray", "Tom Varsavsky", "John Ashburner", "Parashkev Nachev"], "title": "Bayesian Volumetric Autoregressive generative models for better semisupervised learning", "url": "http://arxiv.org/pdf/1907.11559v1", "summary": "Deep generative models are rapidly gaining traction in medical imaging.\nNonetheless, most generative architectures struggle to capture the underlying\nprobability distributions of volumetric data, exhibit convergence problems, and\noffer no robust indices of model uncertainty. By comparison, the autoregressive\ngenerative model PixelCNN can be extended to volumetric data with relative\nease, it readily attempts to learn the true underlying probability distribution\nand it still admits a Bayesian reformulation that provides a principled\nframework for reasoning about model uncertainty. Our contributions in this\npaper are two fold: first, we extend PixelCNN to work with volumetric brain\nmagnetic resonance imaging data. Second, we show that reformulating this model\nto approximate a deep Gaussian process yields a measure of uncertainty that\nimproves the performance of semi-supervised learning, in particular\nclassification performance in settings where the proportion of labelled data is\nlow. We quantify this improvement across classification, regression, and\nsemantic segmentation tasks, training and testing on clinical magnetic\nresonance brain imaging data comprising T1-weighted and diffusion-weighted\nsequences.", "published": "2019-07-26T13:08:36Z", "version": 1}, {"aid": "1907.11818", "authors": ["Il Yong Chun", "Zhengyu Huang", "Hongki Lim", "Jeffrey A. Fessler"], "title": "Momentum-Net: Fast and convergent iterative neural network for inverse problems", "url": "http://arxiv.org/pdf/1907.11818v3", "summary": "Iterative neural networks (INN) are rapidly gaining attention for solving\ninverse problems in imaging, image processing, and computer vision. INNs\ncombine regression NNs and an iterative model-based image reconstruction (MBIR)\nalgorithm, often leading to both good generalization capability and\noutperforming reconstruction quality over existing MBIR optimization models.\nThis paper proposes the first fast and convergent INN architecture,\nMomentum-Net, by generalizing a block-wise MBIR algorithm that uses momentum\nand majorizers with regression NNs. For fast MBIR, Momentum-Net uses momentum\nterms in extrapolation modules, and noniterative MBIR modules at each iteration\nby using majorizers, where each iteration of Momentum-Net consists of three\ncore modules: image refining, extrapolation, and MBIR. Momentum-Net guarantees\nconvergence to a fixed-point for general differentiable (non)convex MBIR\nfunctions (or data-fit terms) and convex feasible sets, under two asymptomatic\nconditions. To consider data-fit variations across training and testing\nsamples, we also propose a regularization parameter selection scheme based on\nthe \"spectral spread\" of majorization matrices. Numerical experiments for\nlight-field photography using a focal stack and sparse-view computational\ntomography demonstrate that, given identical regression NN architectures,\nMomentum-Net significantly improves MBIR speed and accuracy over several\nexisting INNs; it significantly improves reconstruction quality compared to a\nstate-of-the-art MBIR method in each application.", "published": "2019-07-26T23:42:37Z", "version": 3}, {"aid": "1907.12046", "authors": ["Francis Engelmann", "Theodora Kontogianni", "Bastian Leibe"], "title": "Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds", "url": "http://arxiv.org/pdf/1907.12046v3", "summary": "In this work, we propose Dilated Point Convolutions (DPC). In a thorough\nablation study, we show that the receptive field size is directly related to\nthe performance of 3D point cloud processing tasks, including semantic\nsegmentation and object classification. Point convolutions are widely used to\nefficiently process 3D data representations such as point clouds or graphs.\nHowever, we observe that the receptive field size of recent point convolutional\nnetworks is inherently limited. Our dilated point convolutions alleviate this\nissue, they significantly increase the receptive field size of point\nconvolutions. Importantly, our dilation mechanism can easily be integrated into\nmost existing point convolutional networks. To evaluate the resulting network\narchitectures, we visualize the receptive field and report competitive scores\non popular point cloud benchmarks.", "published": "2019-07-28T08:52:41Z", "version": 3}, {"aid": "1907.12256", "authors": ["Xianyang Li", "Feng Wang", "Qinghao Hu", "Cong Leng"], "title": "AirFace: Lightweight and Efficient Model for Face Recognition", "url": "http://arxiv.org/pdf/1907.12256v3", "summary": "With the development of convolutional neural network, significant progress\nhas been made in computer vision tasks. However, the commonly used loss\nfunction softmax loss and highly efficient network architecture for common\nvisual tasks are not as effective for face recognition. In this paper, we\npropose a novel loss function named Li-ArcFace based on ArcFace. Li-ArcFace\ntakes the value of the angle through linear function as the target logit rather\nthan through cosine function, which has better convergence and performance on\nlow dimensional embedding feature learning for face recognition. In terms of\nnetwork architecture, we improved the the perfomance of MobileFaceNet by\nincreasing the network depth, width and adding attention module. Besides, we\nfound some useful training tricks for face recognition. With all the above\nresults, we won the second place in the deepglint-light challenge of LFR2019.", "published": "2019-07-29T08:04:37Z", "version": 3}, {"aid": "1907.12537", "authors": ["Andrew Cook", "Bappaditya Mandal", "Donna Berry", "Matthew Johnson"], "title": "Towards Automatic Screening of Typical and Atypical Behaviors in Children With Autism", "url": "http://arxiv.org/pdf/1907.12537v2", "summary": "This paper has been withdrawn by the authors due to insufficient or\ndefinition error(s) in the ethics approval protocol.\n  Autism spectrum disorders (ASD) impact the cognitive, social, communicative\nand behavioral abilities of an individual. The development of new clinical\ndecision support systems is of importance in reducing the delay between\npresentation of symptoms and an accurate diagnosis. In this work, we contribute\na new database consisting of video clips of typical (normal) and atypical (such\nas hand flapping, spinning or rocking) behaviors, displayed in natural\nsettings, which have been collected from the YouTube video website. We propose\na preliminary non-intrusive approach based on skeleton keypoint identification\nusing pretrained deep neural networks on human body video clips to extract\nfeatures and perform body movement analysis that differentiates typical and\natypical behaviors of children. Experimental results on the newly contributed\ndatabase show that our platform performs best with decision tree as the\nclassifier when compared to other popular methodologies and offers a baseline\nagainst which alternate approaches may developed and tested.", "published": "2019-07-29T17:18:11Z", "version": 2}, {"aid": "1908.04396", "authors": ["Xi Zhang", "Xiaolin Wu", "Jun Du"], "title": "Challenge of Spatial Cognition for Deep Learning", "url": "http://arxiv.org/pdf/1908.04396v2", "summary": "Given the success of the deep convolutional neural networks (DCNNs) in\napplications of visual recognition and classification, it would be tantalizing\nto test if DCNNs can also learn spatial concepts, such as straightness,\nconvexity, left/right, front/back, relative size, aspect ratio, polygons, etc.,\nfrom varied visual examples of these concepts that are simple and yet vital for\nspatial reasoning. Much to our dismay, extensive experiments of the type of\ncognitive psychology demonstrate that the data-driven deep learning (DL) cannot\nsee through superficial variations in visual representations and grasp the\nspatial concept in abstraction. The root cause of failure turns out to be the\nlearning methodology, not the computational model of the neural network itself.\nBy incorporating task-specific convolutional kernels, we are able to construct\nDCNNs for spatial cognition tasks that can generalize to input images not drawn\nfrom the same distribution of the training set. This work raises a precaution\nthat without manually-incorporated priors or features DCCNs may fail spatial\ncognitive tasks at rudimentary level.", "published": "2019-07-30T11:35:40Z", "version": 2}, {"aid": "1907.13196", "authors": ["Mohammed Amin Abdullah", "Hang Ren", "Haitham Bou Ammar", "Vladimir Milenkovic", "Rui Luo", "Mingtian Zhang", "Jun Wang"], "title": "Wasserstein Robust Reinforcement Learning", "url": "http://arxiv.org/pdf/1907.13196v4", "summary": "Reinforcement learning algorithms, though successful, tend to over-fit to\ntraining environments hampering their application to the real-world. This paper\nproposes $\\text{W}\\text{R}^{2}\\text{L}$ -- a robust reinforcement learning\nalgorithm with significant robust performance on low and high-dimensional\ncontrol tasks. Our method formalises robust reinforcement learning as a novel\nmin-max game with a Wasserstein constraint for a correct and convergent solver.\nApart from the formulation, we also propose an efficient and scalable solver\nfollowing a novel zero-order optimisation method that we believe can be useful\nto numerical optimisation in general. We empirically demonstrate significant\ngains compared to standard and robust state-of-the-art algorithms on\nhigh-dimensional MuJuCo environments.", "published": "2019-07-30T19:42:52Z", "version": 4}, {"aid": "1907.13255", "authors": ["Amit Kumar", "Rama Chellappa"], "title": "Landmark Detection in Low Resolution Faces with Semi-Supervised Learning", "url": "http://arxiv.org/pdf/1907.13255v1", "summary": "Landmark detection algorithms trained on high resolution images perform\npoorly on datasets containing low resolution images. This deters the\nperformance of algorithms relying on quality landmarks, for example, face\nrecognition. To the best of our knowledge, there does not exist any dataset\nconsisting of low resolution face images along with their annotated landmarks,\nmaking supervised training infeasible. In this paper, we present a\nsemi-supervised approach to predict landmarks on low resolution images by\nlearning them from labeled high resolution images. The objective of this work\nis to show that predicting landmarks directly on low resolution images is more\neffective than the current practice of aligning images after rescaling or\nsuperresolution. In a two-step process, the proposed approach first learns to\ngenerate low resolution images by modeling the distribution of target low\nresolution images. In the second stage, the roles of generated images and real\nlow resolution images are switched and the model learns to predict landmarks\nfor real low resolution images from generated low resolution images. With\nextensive experimentation, we study the impact of each of the design choices\nand also show that prediction of landmarks directly on low resolution images\nimproves the performance of important tasks such as face recognition in low\nresolution images.", "published": "2019-07-30T23:12:01Z", "version": 1}, {"aid": "1908.00077", "authors": ["Jennifer Stiso", "Marie-Constance Corsi", "Jean M. Vettel", "Javier O. Garcia", "Fabio Pasqualetti", "Fabrizio De Vico Fallani", "Timothy H. Lucas", "Danielle S. Bassett"], "title": "Learning in brain-computer interface control evidenced by joint decomposition of brain and behavior", "url": "http://arxiv.org/pdf/1908.00077v2", "summary": "Motor imagery-based brain-computer interfaces (BCIs) use an individuals\nability to volitionally modulate localized brain activity as a therapy for\nmotor dysfunction or to probe causal relations between brain activity and\nbehavior. However, many individuals cannot learn to successfully modulate their\nbrain activity, greatly limiting the efficacy of BCI for therapy and for basic\nscientific inquiry. Previous research suggests that coherent activity across\ndiverse cognitive systems is a hallmark of individuals who can successfully\nlearn to control the BCI. However, little is known about how these distributed\nnetworks interact through time to support learning. Here, we address this gap\nin knowledge by constructing and applying a multimodal network approach to\ndecipher brain-behavior relations in motor imagery-based brain-computer\ninterface learning using MEG. Specifically, we employ a minimally constrained\nmatrix decomposition method (non-negative matrix factorization) to\nsimultaneously identify regularized, covarying subgraphs of functional\nconnectivity, to assess their similarity to task performance, and to detect\ntheir time-varying expression. Individuals also displayed marked variation in\nthe spatial properties of subgraphs such as the connectivity between the\nfrontal lobe and the rest of the brain, and in the temporal properties of\nsubgraphs such as the stage of learning at which they reached maximum\nexpression. From these observations, we posit a conceptual model in which\ncertain subgraphs support learning by modulating brain activity in regions\nimportant for sustaining attention. To test this model, we use tools that\nstipulate regional dynamics on a networked system (network control theory), and\nfind that good learners display a single subgraph whose temporal expression\ntracked performance and whose architecture supports easy modulation of brain\nregions important for attention.", "published": "2019-07-31T20:17:07Z", "version": 2}, {"aid": "1908.00473", "authors": ["Pengyi Zhang", "Yunxin Zhong", "Yulin Deng", "Xiaoying Tang", "Xiaoqiong Li"], "title": "A Survey on Deep Learning of Small Sample in Biomedical Image Analysis", "url": "http://arxiv.org/pdf/1908.00473v1", "summary": "The success of deep learning has been witnessed as a promising technique for\ncomputer-aided biomedical image analysis, due to end-to-end learning framework\nand availability of large-scale labelled samples. However, in many cases of\nbiomedical image analysis, deep learning techniques suffer from the small\nsample learning (SSL) dilemma caused mainly by lack of annotations. To be more\npractical for biomedical image analysis, in this paper we survey the key SSL\ntechniques that help relieve the suffering of deep learning by combining with\nthe development of related techniques in computer vision applications. In order\nto accelerate the clinical usage of biomedical image analysis based on deep\nlearning techniques, we intentionally expand this survey to include the\nexplanation methods for deep models that are important to clinical decision\nmaking. We survey the key SSL techniques by dividing them into five categories:\n(1) explanation techniques, (2) weakly supervised learning techniques, (3)\ntransfer learning techniques, (4) active learning techniques, and (5)\nmiscellaneous techniques involving data augmentation, domain knowledge,\ntraditional shallow methods and attention mechanism. These key techniques are\nexpected to effectively support the application of deep learning in clinical\nbiomedical image analysis, and furtherly improve the analysis performance,\nespecially when large-scale annotated samples are not available. We bulid demos\nat https://github.com/PengyiZhang/MIADeepSSL.", "published": "2019-08-01T16:01:31Z", "version": 1}, {"aid": "1908.00682", "authors": ["Feifan Lv", "Yu Li", "Feng Lu"], "title": "Attention Guided Low-light Image Enhancement with a Large Scale Low-light Simulation Dataset", "url": "http://arxiv.org/pdf/1908.00682v3", "summary": "Low-light image enhancement is challenging in that it needs to consider not\nonly brightness recovery but also complex issues like color distortion and\nnoise, which usually hide in the dark. Simply adjusting the brightness of a\nlow-light image will inevitably amplify those artifacts. To address this\ndifficult problem, this paper proposes a novel end-to-end attention-guided\nmethod based on multi-branch convolutional neural network. To this end, we\nfirst construct a synthetic dataset with carefully designed low-light\nsimulation strategies. The dataset is much larger and more diverse than\nexisting ones. With the new dataset for training, our method learns two\nattention maps to guide the brightness enhancement and denoising tasks\nrespectively. The first attention map distinguishes underexposed regions from\nwell lit regions, and the second attention map distinguishes noises from real\ntextures. With their guidance, the proposed multi-branch\ndecomposition-and-fusion enhancement network works in an input adaptive way.\nMoreover, a reinforcement-net further enhances color and contrast of the output\nimage. Extensive experiments on multiple datasets demonstrate that our method\ncan produce high fidelity enhancement results for low-light images and\noutperforms the current state-of-the-art methods by a large margin both\nquantitatively and visually.", "published": "2019-08-02T02:28:00Z", "version": 3}, {"aid": "1908.00704", "authors": ["Alireza Naghizadeh", "Mohammadsajad Abavisani", "Dimitris N. Metaxas"], "title": "Greedy AutoAugment", "url": "http://arxiv.org/pdf/1908.00704v2", "summary": "A major problem in data augmentation is to ensure that the generated new\nsamples cover the search space. This is a challenging problem and requires\nexploration for data augmentation policies to ensure their effectiveness in\ncovering the search space. In this paper, we propose Greedy AutoAugment as a\nhighly efficient search algorithm to find the best augmentation policies. We\nuse a greedy approach to reduce the exponential growth of the number of\npossible trials to linear growth. The Greedy Search also helps us to lead the\nsearch towards the sub-policies with better results, which eventually helps to\nincrease the accuracy. The proposed method can be used as a reliable addition\nto the current artifitial neural networks. Our experiments on four datasets\n(Tiny ImageNet, CIFAR-10, CIFAR-100, and SVHN) show that Greedy AutoAugment\nprovides better accuracy, while using 360 times fewer computational resources.", "published": "2019-08-02T05:28:03Z", "version": 2}, {"aid": "1908.00821", "authors": ["Yuenan Hou", "Zheng Ma", "Chunxiao Liu", "Chen Change Loy"], "title": "Learning Lightweight Lane Detection CNNs by Self Attention Distillation", "url": "http://arxiv.org/pdf/1908.00821v1", "summary": "Training deep models for lane detection is challenging due to the very subtle\nand sparse supervisory signals inherent in lane annotations. Without learning\nfrom much richer context, these models often fail in challenging scenarios,\ne.g., severe occlusion, ambiguous lanes, and poor lighting conditions. In this\npaper, we present a novel knowledge distillation approach, i.e., Self Attention\nDistillation (SAD), which allows a model to learn from itself and gains\nsubstantial improvement without any additional supervision or labels.\nSpecifically, we observe that attention maps extracted from a model trained to\na reasonable level would encode rich contextual information. The valuable\ncontextual information can be used as a form of 'free' supervision for further\nrepresentation learning through performing topdown and layer-wise attention\ndistillation within the network itself. SAD can be easily incorporated in any\nfeedforward convolutional neural networks (CNN) and does not increase the\ninference time. We validate SAD on three popular lane detection benchmarks\n(TuSimple, CULane and BDD100K) using lightweight models such as ENet, ResNet-18\nand ResNet-34. The lightest model, ENet-SAD, performs comparatively or even\nsurpasses existing algorithms. Notably, ENet-SAD has 20 x fewer parameters and\nruns 10 x faster compared to the state-of-the-art SCNN, while still achieving\ncompelling performance in all benchmarks. Our code is available at\nhttps://github.com/cardwing/Codes-for-Lane-Detection.", "published": "2019-08-02T12:13:34Z", "version": 1}, {"aid": "1908.01070", "authors": ["Brian Teixeira", "Birgi Tamersoy", "Vivek Singh", "Ankur Kapoor"], "title": "Adaloss: Adaptive Loss Function for Landmark Localization", "url": "http://arxiv.org/pdf/1908.01070v1", "summary": "Landmark localization is a challenging problem in computer vision with a\nmultitude of applications. Recent deep learning based methods have shown\nimproved results by regressing likelihood maps instead of regressing the\ncoordinates directly. However, setting the precision of these regression\ntargets during the training is a cumbersome process since it creates a\ntrade-off between trainability vs localization accuracy. Using precise targets\nintroduces a significant sampling bias and hence makes the training more\ndifficult, whereas using imprecise targets results in inaccurate landmark\ndetectors. In this paper, we introduce \"Adaloss\", an objective function that\nadapts itself during the training by updating the target precision based on the\ntraining statistics. This approach does not require setting problem-specific\nparameters and shows improved stability in training and better localization\naccuracy during inference. We demonstrate the effectiveness of our proposed\nmethod in three different applications of landmark localization: 1) the\nchallenging task of precisely detecting catheter tips in medical X-ray images,\n2) localizing surgical instruments in endoscopic images, and 3) localizing\nfacial features on in-the-wild images where we show state-of-the-art results on\nthe 300-W benchmark dataset.", "published": "2019-08-02T21:18:50Z", "version": 1}, {"aid": "1908.01166", "authors": ["Menglei Zhang", "Zhou Liu", "Lei Yu"], "title": "CRNet: Image Super-Resolution Using A Convolutional Sparse Coding Inspired Network", "url": "http://arxiv.org/pdf/1908.01166v1", "summary": "Convolutional Sparse Coding (CSC) has been attracting more and more attention\nin recent years, for making full use of image global correlation to improve\nperformance on various computer vision applications. However, very few studies\nfocus on solving CSC based image Super-Resolution (SR) problem. As a\nconsequence, there is no significant progress in this area over a period of\ntime. In this paper, we exploit the natural connection between CSC and\nConvolutional Neural Networks (CNN) to address CSC based image SR.\nSpecifically, Convolutional Iterative Soft Thresholding Algorithm (CISTA) is\nintroduced to solve CSC problem and it can be implemented using CNN\narchitectures. Then we develop a novel CSC based SR framework analogy to the\ntraditional SC based SR methods. Two models inspired by this framework are\nproposed for pre-/post-upsampling SR, respectively. Compared with recent\nstate-of-the-art SR methods, both of our proposed models show superior\nperformance in terms of both quantitative and qualitative measurements.", "published": "2019-08-03T13:10:03Z", "version": 1}, {"aid": "1908.01259", "authors": ["Xilai Li", "Wei Sun", "Tianfu Wu"], "title": "Attentive Normalization", "url": "http://arxiv.org/pdf/1908.01259v3", "summary": "In state-of-the-art deep neural networks, both feature normalization and\nfeature attention have become ubiquitous. % with significant performance\nimprovement shown in a vast amount of tasks. They are usually studied as\nseparate modules, however. In this paper, we propose a light-weight integration\nbetween the two schema and present Attentive Normalization (AN). Instead of\nlearning a single affine transformation, AN learns a mixture of affine\ntransformations and utilizes their weighted-sum as the final affine\ntransformation applied to re-calibrate features in an instance-specific way.\nThe weights are learned by leveraging channel-wise feature attention. In\nexperiments, we test the proposed AN using four representative neural\narchitectures in the ImageNet-1000 classification benchmark and the MS-COCO\n2017 object detection and instance segmentation benchmark. AN obtains\nconsistent performance improvement for different neural architectures in both\nbenchmarks with absolute increase of top-1 accuracy in ImageNet-1000 between\n0.5\\% and 2.7\\%, and absolute increase up to 1.8\\% and 2.2\\% for bounding box\nand mask AP in MS-COCO respectively. We observe that the proposed AN provides a\nstrong alternative to the widely used Squeeze-and-Excitation (SE) module. The\nsource codes are publicly available at https://github.com/iVMCL/AOGNet-v2 (the\nImageNet Classification Repo) and\nhttps://github.com/iVMCL/AttentiveNorm\\_Detection (the MS-COCO Detection and\nSegmentation Repo).", "published": "2019-08-04T02:17:34Z", "version": 3}, {"aid": "1908.01477", "authors": ["Haibao Yu", "Tuopu Wen", "Guangliang Cheng", "Jiankai Sun", "Qi Han", "Jianping Shi"], "title": "GDRQ: Group-based Distribution Reshaping for Quantization", "url": "http://arxiv.org/pdf/1908.01477v1", "summary": "Low-bit quantization is challenging to maintain high performance with limited\nmodel capacity (e.g., 4-bit for both weights and activations). Naturally, the\ndistribution of both weights and activations in deep neural network are\nGaussian-like. Nevertheless, due to the limited bitwidth of low-bit model,\nuniform-like distributed weights and activations have been proved to be more\nfriendly to quantization while preserving accuracy~\\cite{Han2015Learning}.\nMotivated by this, we propose Scale-Clip, a Distribution Reshaping technique\nthat can reshape weights or activations into a uniform-like distribution in a\ndynamic manner. Furthermore, to increase the model capability for a low-bit\nmodel, a novel Group-based Quantization algorithm is proposed to split the\nfilters into several groups. Different groups can learn different quantization\nparameters, which can be elegantly merged in to batch normalization layer\nwithout extra computational cost in the inference stage. Finally, we integrate\nScale-Clip technique with Group-based Quantization algorithm and propose the\nGroup-based Distribution Reshaping Quantization (GDQR) framework to further\nimprove the quantization performance. Experiments on various networks (e.g.\nVGGNet and ResNet) and vision tasks (e.g. classification, detection and\nsegmentation) demonstrate that our framework achieves good performance.", "published": "2019-08-05T05:44:52Z", "version": 1}, {"aid": "1908.01581", "authors": ["Ruofan Liang", "Tianlin Li", "Longfei Li", "Jing Wang", "Quanshi Zhang"], "title": "Knowledge Consistency between Neural Networks and Beyond", "url": "http://arxiv.org/pdf/1908.01581v2", "summary": "This paper aims to analyze knowledge consistency between pre-trained deep\nneural networks. We propose a generic definition for knowledge consistency\nbetween neural networks at different fuzziness levels. A task-agnostic method\nis designed to disentangle feature components, which represent the consistent\nknowledge, from raw intermediate-layer features of each neural network. As a\ngeneric tool, our method can be broadly used for different applications. In\npreliminary experiments, we have used knowledge consistency as a tool to\ndiagnose representations of neural networks. Knowledge consistency provides new\ninsights to explain the success of existing deep-learning techniques, such as\nknowledge distillation and network compression. More crucially, knowledge\nconsistency can also be used to refine pre-trained networks and boost\nperformance.", "published": "2019-08-05T12:25:37Z", "version": 2}, {"aid": "1908.01867", "authors": ["Cengiz Pehlevan", "Dmitri B. Chklovskii"], "title": "Neuroscience-inspired online unsupervised learning algorithms", "url": "http://arxiv.org/pdf/1908.01867v2", "summary": "Although the currently popular deep learning networks achieve unprecedented\nperformance on some tasks, the human brain still has a monopoly on general\nintelligence. Motivated by this and biological implausibility of deep learning\nnetworks, we developed a family of biologically plausible artificial neural\nnetworks (NNs) for unsupervised learning. Our approach is based on optimizing\nprincipled objective functions containing a term that matches the pairwise\nsimilarity of outputs to the similarity of inputs, hence the name -\nsimilarity-based. Gradient-based online optimization of such similarity-based\nobjective functions can be implemented by NNs with biologically plausible local\nlearning rules. Similarity-based cost functions and associated NNs solve\nunsupervised learning tasks such as linear dimensionality reduction, sparse\nand/or nonnegative feature extraction, blind nonnegative source separation,\nclustering and manifold learning.", "published": "2019-08-05T21:30:35Z", "version": 2}, {"aid": "1908.02197", "authors": ["Dongwei Ren", "Kai Zhang", "Qilong Wang", "Qinghua Hu", "Wangmeng Zuo"], "title": "Neural Blind Deconvolution Using Deep Priors", "url": "http://arxiv.org/pdf/1908.02197v2", "summary": "Blind deconvolution is a classical yet challenging low-level vision problem\nwith many real-world applications. Traditional maximum a posterior (MAP) based\nmethods rely heavily on fixed and handcrafted priors that certainly are\ninsufficient in characterizing clean images and blur kernels, and usually adopt\nspecially designed alternating minimization to avoid trivial solution. In\ncontrast, existing deep motion deblurring networks learn from massive training\nimages the mapping to clean image or blur kernel, but are limited in handling\nvarious complex and large size blur kernels. To connect MAP and deep models, we\nin this paper present two generative networks for respectively modeling the\ndeep priors of clean image and blur kernel, and propose an unconstrained neural\noptimization solution to blind deconvolution. In particular, we adopt an\nasymmetric Autoencoder with skip connections for generating latent clean image,\nand a fully-connected network (FCN) for generating blur kernel. Moreover, the\nSoftMax nonlinearity is applied to the output layer of FCN to meet the\nnon-negative and equality constraints. The process of neural optimization can\nbe explained as a kind of \"zero-shot\" self-supervised learning of the\ngenerative networks, and thus our proposed method is dubbed SelfDeblur.\nExperimental results show that our SelfDeblur can achieve notable quantitative\ngains as well as more visually plausible deblurring results in comparison to\nstate-of-the-art blind deconvolution methods on benchmark datasets and\nreal-world blurry images. The source code is available at\nhttps://github.com/csdwren/SelfDeblur", "published": "2019-08-06T15:03:44Z", "version": 2}, {"aid": "1908.02498", "authors": ["Gihyun Kwon", "Chihye Han", "Dae-shik Kim"], "title": "Generation of 3D Brain MRI Using Auto-Encoding Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1908.02498v1", "summary": "As deep learning is showing unprecedented success in medical image analysis\ntasks, the lack of sufficient medical data is emerging as a critical problem.\nWhile recent attempts to solve the limited data problem using Generative\nAdversarial Networks (GAN) have been successful in generating realistic images\nwith diversity, most of them are based on image-to-image translation and thus\nrequire extensive datasets from different domains. Here, we propose a novel\nmodel that can successfully generate 3D brain MRI data from random vectors by\nlearning the data distribution. Our 3D GAN model solves both image blurriness\nand mode collapse problems by leveraging alpha-GAN that combines the advantages\nof Variational Auto-Encoder (VAE) and GAN with an additional code discriminator\nnetwork. We also use the Wasserstein GAN with Gradient Penalty (WGAN-GP) loss\nto lower the training instability. To demonstrate the effectiveness of our\nmodel, we generate new images of normal brain MRI and show that our model\noutperforms baseline models in both quantitative and qualitative measurements.\nWe also train the model to synthesize brain disorder MRI data to demonstrate\nthe wide applicability of our model. Our results suggest that the proposed\nmodel can successfully generate various types and modalities of 3D whole brain\nvolumes from a small set of training data.", "published": "2019-08-07T09:33:03Z", "version": 1}, {"aid": "1908.02626", "authors": ["Marco Rudolph", "Bastian Wandt", "Bodo Rosenhahn"], "title": "Structuring Autoencoders", "url": "http://arxiv.org/pdf/1908.02626v1", "summary": "In this paper we propose Structuring AutoEncoders (SAE). SAEs are neural\nnetworks which learn a low dimensional representation of data which are\nadditionally enriched with a desired structure in this low dimensional space.\nWhile traditional Autoencoders have proven to structure data naturally they\nfail to discover semantic structure that is hard to recognize in the raw data.\nThe SAE solves the problem by enhancing a traditional Autoencoder using weak\nsupervision to form a structured latent space. In the experiments we\ndemonstrate, that the structured latent space allows for a much more efficient\ndata representation for further tasks such as classification for sparsely\nlabeled data, an efficient choice of data to label, and morphing between\nclasses. To demonstrate the general applicability of our method, we show\nexperiments on the benchmark image datasets MNIST, Fashion-MNIST, DeepFashion2\nand on a dataset of 3D human shapes.", "published": "2019-08-07T13:29:11Z", "version": 1}, {"aid": "1908.02648", "authors": ["Seongmin Hwang", "Gwanghuyn Yu", "Cheolkon Jung", "Jinyoung Kim"], "title": "Attention-Aware Linear Depthwise Convolution for Single Image Super-Resolution", "url": "http://arxiv.org/pdf/1908.02648v3", "summary": "Although deep convolutional neural networks (CNNs) have obtained outstanding\nperformance in image superresolution (SR), their computational cost increases\ngeometrically as CNN models get deeper and wider. Meanwhile, the features of\nintermediate layers are treated equally across the channel, thus hindering the\nrepresentational capability of CNNs. In this paper, we propose an\nattention-aware linear depthwise network to address the problems for single\nimage SR, named ALDNet. Specifically, linear depthwise convolution allows\nCNN-based SR models to preserve useful information for reconstructing a\nsuper-resolved image while reducing computational burden. Furthermore, we\ndesign an attention-aware branch that enhances the representation ability of\ndepthwise convolution layers by making full use of depthwise filter\ninterdependency. Experiments on publicly available benchmark datasets show that\nALDNet achieves superior performance to traditional depthwise separable\nconvolutions in terms of quantitative measurements and visual quality.", "published": "2019-08-07T14:09:46Z", "version": 3}, {"aid": "1908.02735", "authors": ["Pierre Jacob", "David Picard", "Aymeric Histace", "Edouard Klein"], "title": "Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings", "url": "http://arxiv.org/pdf/1908.02735v1", "summary": "Learning an effective similarity measure between image representations is key\nto the success of recent advances in visual search tasks (e.g. verification or\nzero-shot learning). Although the metric learning part is well addressed, this\nmetric is usually computed over the average of the extracted deep features.\nThis representation is then trained to be discriminative. However, these deep\nfeatures tend to be scattered across the feature space. Consequently, the\nrepresentations are not robust to outliers, object occlusions, background\nvariations, etc. In this paper, we tackle this scattering problem with a\ndistribution-aware regularization named HORDE. This regularizer enforces\nvisually-close images to have deep features with the same distribution which\nare well localized in the feature space. We provide a theoretical analysis\nsupporting this regularization effect. We also show the effectiveness of our\napproach by obtaining state-of-the-art results on 4 well-known datasets\n(Cub-200-2011, Cars-196, Stanford Online Products and Inshop Clothes\nRetrieval).", "published": "2019-08-07T17:22:01Z", "version": 1}, {"aid": "1908.03015", "authors": ["Felix Berkhahn", "Richard Keys", "Wajih Ouertani", "Nikhil Shetty", "Dominik Gei\u00dfler"], "title": "Augmenting Variational Autoencoders with Sparse Labels: A Unified Framework for Unsupervised, Semi-(un)supervised, and Supervised Learning", "url": "http://arxiv.org/pdf/1908.03015v2", "summary": "We present a new flavor of Variational Autoencoder (VAE) that interpolates\nseamlessly between unsupervised, semi-supervised and fully supervised learning\ndomains. We show that unlabeled datapoints not only boost unsupervised tasks,\nbut also the classification performance. Vice versa, every label not only\nimproves classification, but also unsupervised tasks. The proposed architecture\nis simple: A classification layer is connected to the topmost encoder layer,\nand then combined with the resampled latent layer for the decoder. The usual\nevidence lower bound (ELBO) loss is supplemented with a supervised loss target\non this classification layer that is only applied for labeled datapoints. This\nsimplicity allows for extending any existing VAE model to our proposed\nsemi-supervised framework with minimal effort. In the context of\nclassification, we found that this approach even outperforms a direct\nsupervised setup.", "published": "2019-08-08T11:07:22Z", "version": 2}, {"aid": "1908.03532", "authors": ["Leendert A Remmelzwaal", "George F R Ellis", "Jonathan Tapson", "Amit K Mishra"], "title": "Biologically-inspired Salience Affected Artificial Neural Network (SANN)", "url": "http://arxiv.org/pdf/1908.03532v5", "summary": "In this paper we introduce a novel Salience Affected Artificial Neural\nNetwork (SANN) that models the way neuromodulators such as dopamine and\nnoradrenaline affect neural dynamics in the human brain by being distributed\ndiffusely through neocortical regions, allowing both salience signals to\nmodulate cognition immediately, and one time learning to take place through\nstrengthening entire patterns of activation at one go. We present a model that\nis capable of one-time salience tagging in a neural network trained to classify\nobjects, and returns a salience response during classification (inference). We\nexplore the effects of salience on learning via its effect on the activation\nfunctions of each node, as well as on the strength of weights between nodes in\nthe network. We demonstrate that salience tagging can improve classification\nconfidence for both the individual image as well as the class of images it\nbelongs to. We also show that the computation impact of producing a salience\nresponse is minimal. This research serves as a proof of concept, and could be\nthe first step towards introducing salience tagging into Deep Learning Networks\nand robotics.", "published": "2019-08-09T16:40:52Z", "version": 5}, {"aid": "1908.03682", "authors": ["Yang Liu", "Jianpeng Zhang", "Chao Gao", "Jinghua Qu", "Lixin Ji"], "title": "Natural-Logarithm-Rectified Activation Function in Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1908.03682v2", "summary": "Activation functions play a key role in providing remarkable performance in\ndeep neural networks, and the rectified linear unit (ReLU) is one of the most\nwidely used activation functions. Various new activation functions and\nimprovements on ReLU have been proposed, but each carry performance drawbacks.\nIn this paper, we propose an improved activation function, which we name the\nnatural-logarithm-rectified linear unit (NLReLU). This activation function uses\nthe parametric natural logarithmic transform to improve ReLU and is simply\ndefined as. NLReLU not only retains the sparse activation characteristic of\nReLU, but it also alleviates the \"dying ReLU\" and vanishing gradient problems\nto some extent. It also reduces the bias shift effect and heteroscedasticity of\nneuron data distributions among network layers in order to accelerate the\nlearning process. The proposed method was verified across ten convolutional\nneural networks with different depths for two essential datasets. Experiments\nillustrate that convolutional neural networks with NLReLU exhibit higher\naccuracy than those with ReLU, and that NLReLU is comparable to other\nwell-known activation functions. NLReLU provides 0.16% and 2.04% higher\nclassification accuracy on average compared to ReLU when used in shallow\nconvolutional neural networks with the MNIST and CIFAR-10 datasets,\nrespectively. The average accuracy of deep convolutional neural networks with\nNLReLU is 1.35% higher on average with the CIFAR-10 dataset.", "published": "2019-08-10T03:51:36Z", "version": 2}, {"aid": "1908.05845", "authors": ["Matthias Springer"], "title": "Memory-Efficient Object-Oriented Programming on GPUs", "url": "http://arxiv.org/pdf/1908.05845v1", "summary": "Object-oriented programming is often regarded as too inefficient for\nhigh-performance computing (HPC), despite the fact that many important HPC\nproblems have an inherent object structure. Our goal is to bring efficient,\nobject-oriented programming to massively parallel SIMD architectures,\nespecially GPUs.\n  In this thesis, we develop various techniques for optimizing object-oriented\nGPU code. Most notably, we identify the object-oriented Single-Method\nMultiple-Objects (SMMO) programming model. We first develop an embedded C++\nStructure of Arrays (SOA) data layout DSL for SMMO applications. We then design\na lock-free, dynamic memory allocator that stores allocations in SOA layout.\nFinally, we show how to further optimize the memory access of SMMO applications\nwith memory defragmentation.", "published": "2019-08-16T04:50:29Z", "version": 1}, {"aid": "1908.07644", "authors": ["Gamaleldin F. Elsayed", "Simon Kornblith", "Quoc V. Le"], "title": "Saccader: Improving Accuracy of Hard Attention Models for Vision", "url": "http://arxiv.org/pdf/1908.07644v3", "summary": "Although deep convolutional neural networks achieve state-of-the-art\nperformance across nearly all image classification tasks, their decisions are\ndifficult to interpret. One approach that offers some level of interpretability\nby design is \\textit{hard attention}, which uses only relevant portions of the\nimage. However, training hard attention models with only class label\nsupervision is challenging, and hard attention has proved difficult to scale to\ncomplex datasets. Here, we propose a novel hard attention model, which we term\nSaccader. Key to Saccader is a pretraining step that requires only class labels\nand provides initial attention locations for policy gradient optimization. Our\nbest models narrow the gap to common ImageNet baselines, achieving $75\\%$ top-1\nand $91\\%$ top-5 while attending to less than one-third of the image.", "published": "2019-08-20T23:40:21Z", "version": 3}, {"aid": "1908.08466", "authors": ["Xiao-Yun Zhou", "Peichao Li", "Zhao-Yang Wang", "Guang-Zhong Yang"], "title": "U-Net Training with Instance-Layer Normalization", "url": "http://arxiv.org/pdf/1908.08466v2", "summary": "Normalization layers are essential in a Deep Convolutional Neural Network\n(DCNN). Various normalization methods have been proposed. The statistics used\nto normalize the feature maps can be computed at batch, channel, or instance\nlevel. However, in most of existing methods, the normalization for each layer\nis fixed. Batch-Instance Normalization (BIN) is one of the first proposed\nmethods that combines two different normalization methods and achieve diverse\nnormalization for different layers. However, two potential issues exist in BIN:\nfirst, the Clip function is not differentiable at input values of 0 and 1;\nsecond, the combined feature map is not with a normalized distribution which is\nharmful for signal propagation in DCNN. In this paper, an Instance-Layer\nNormalization (ILN) layer is proposed by using the Sigmoid function for the\nfeature map combination, and cascading group normalization. The performance of\nILN is validated on image segmentation of the Right Ventricle (RV) and Left\nVentricle (LV) using U-Net as the network architecture. The results show that\nthe proposed ILN outperforms previous traditional and popular normalization\nmethods with noticeable accuracy improvements for most validations, supporting\nthe effectiveness of the proposed ILN.", "published": "2019-08-21T11:24:25Z", "version": 2}, {"aid": "1908.08331", "authors": ["Dominique Beaini", "Sofiane Achiche", "Alexandre Duperr\u00e9", "Maxime Raison"], "title": "Deep Green Function Convolution for Improving Saliency in Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1908.08331v2", "summary": "Current saliency methods require to learn large scale regional features using\nsmall convolutional kernels, which is not possible with a simple feed-forward\nnetwork. Some methods solve this problem by using segmentation into superpixels\nwhile others downscale the image through the network and rescale it back to its\noriginal size. The objective of this paper is to show that saliency\nconvolutional neural networks (CNN) can be improved by using a Green's function\nconvolution (GFC) to extrapolate edges features into salient regions. The GFC\nacts as a gradient integrator, allowing to produce saliency features by filling\nthin edges directly inside the CNN. Hence, we propose the gradient integration\nand sum (GIS) layer that combines the edges features with the saliency\nfeatures. Using the HED and DSS architecture, we demonstrated that adding a GIS\nlayer near the network's output allows to reduce the sensitivity to the\nparameter initialization, to reduce the overfitting and to improve the\nrepeatability of the training. By simply adding a GIS layer to the\nstate-of-the-art DSS model, there is an absolute increase of 1.6% for the\nF-measure on the DUT-OMRON dataset, with only 10ms of additional computation\ntime. The GIS layer further allows the network to perform significantly better\nin the case of highly noisy images or low-brightness images. In fact, we\nobserved an F-measure improvement of 5.2% when noise was added to the dataset\nand 2.8% when the brightness was reduced. Since the GIS layer is model\nagnostic, it can be implemented into different fully convolutional networks. A\nmajor contribution of the current work is the first implementation of Green's\nfunction convolution inside a neural network, which allows the network to\noperate in the feature domain and in the gradient domain at the same time, thus\nimproving the regional representation via edge filling.", "published": "2019-08-22T12:14:26Z", "version": 2}, {"aid": "1908.08807", "authors": ["Hao Wu", "Ziyu Zhu", "Jiayi Wang", "Nanning Zheng", "Badong Chen"], "title": "An encoding framework with brain inner state for natural image identification", "url": "http://arxiv.org/pdf/1908.08807v1", "summary": "Neural encoding and decoding, which aim to characterize the relationship\nbetween stimuli and brain activities, have emerged as an important area in\ncognitive neuroscience. Traditional encoding models, which focus on feature\nextraction and mapping, consider the brain as an input-output mapper without\ninner states. In this work, inspired by the fact that human brain acts like a\nstate machine, we proposed a novel encoding framework that combines information\nfrom both the external world and the inner state to predict brain activity. The\nframework comprises two parts: forward encoding model that deals with visual\nstimuli and inner state model that captures influence from intrinsic\nconnections in the brain. The forward model can be any traditional encoding\nmodel, making the framework flexible. The inner state model is a linear model\nto utilize information in the prediction residuals of the forward model. The\nproposed encoding framework can achieve much better performance on natural\nimage identification from fMRI response than forwardonly models. The\nidentification accuracy will decrease slightly with the dataset size\nincreasing, but remain relatively stable with different identification methods.\nThe results confirm that the new encoding framework is effective and robust\nwhen used for brain decoding.", "published": "2019-08-22T13:41:49Z", "version": 1}, {"aid": "1908.08453", "authors": ["Abdelrahman Abdelhamed", "Marcus A. Brubaker", "Michael S. Brown"], "title": "Noise Flow: Noise Modeling with Conditional Normalizing Flows", "url": "http://arxiv.org/pdf/1908.08453v1", "summary": "Modeling and synthesizing image noise is an important aspect in many computer\nvision applications. The long-standing additive white Gaussian and\nheteroscedastic (signal-dependent) noise models widely used in the literature\nprovide only a coarse approximation of real sensor noise. This paper introduces\nNoise Flow, a powerful and accurate noise model based on recent normalizing\nflow architectures. Noise Flow combines well-established basic parametric noise\nmodels (e.g., signal-dependent noise) with the flexibility and expressiveness\nof normalizing flow networks. The result is a single, comprehensive, compact\nnoise model containing fewer than 2500 parameters yet able to represent\nmultiple cameras and gain factors. Noise Flow dramatically outperforms existing\nnoise models, with 0.42 nats/pixel improvement over the camera-calibrated noise\nlevel functions, which translates to 52% improvement in the likelihood of\nsampled noise. Noise Flow represents the first serious attempt to go beyond\nsimple parametric models to one that leverages the power of deep learning and\ndata-driven noise distributions.", "published": "2019-08-22T15:30:32Z", "version": 1}, {"aid": "1908.08681", "authors": ["Diganta Misra"], "title": "Mish: A Self Regularized Non-Monotonic Activation Function", "url": "http://arxiv.org/pdf/1908.08681v3", "summary": "We propose $\\textit{Mish}$, a novel self-regularized non-monotonic activation\nfunction which can be mathematically defined as: $f(x)=x\\tanh(softplus(x))$. As\nactivation functions play a crucial role in the performance and training\ndynamics in neural networks, we validated experimentally on several well-known\nbenchmarks against the best combinations of architectures and activation\nfunctions. We also observe that data augmentation techniques have a favorable\neffect on benchmarks like ImageNet-1k and MS-COCO across multiple\narchitectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a\nCSP-DarkNet-53 backbone on average precision ($AP_{50}^{val}$) by 2.1$\\%$ in\nMS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy\nby $\\approx$1$\\%$ while keeping all other network parameters and\nhyperparameters constant. Furthermore, we explore the mathematical formulation\nof Mish in relation with the Swish family of functions and propose an intuitive\nunderstanding on how the first derivative behavior may be acting as a\nregularizer helping the optimization of deep neural networks. Code is publicly\navailable at https://github.com/digantamisra98/Mish.", "published": "2019-08-23T06:22:06Z", "version": 3}, {"aid": "1909.04138", "authors": ["Jiang Lu", "Lei Li", "Changshui Zhang"], "title": "Self-reinforcing Unsupervised Matching", "url": "http://arxiv.org/pdf/1909.04138v1", "summary": "Remarkable gains in deep learning usually rely on tremendous supervised data.\nEnsuring the modality diversity for one object in training set is critical for\nthe generalization of cutting-edge deep models, but it burdens human with heavy\nmanual labor on data collection and annotation. In addition, some rare or\nunexpected modalities are new for the current model, causing reduced\nperformance under such emerging modalities. Inspired by the achievements in\nspeech recognition, psychology and behavioristics, we present a practical\nsolution, self-reinforcing unsupervised matching (SUM), to annotate the images\nwith 2D structure-preserving property in an emerging modality by cross-modality\nmatching. This approach requires no any supervision in emerging modality and\nonly one template in seen modality, providing a possible route towards\ncontinual learning.", "published": "2019-08-23T10:43:43Z", "version": 1}, {"aid": "1908.08999", "authors": ["Tomas Jenicek", "Ond\u0159ej Chum"], "title": "No Fear of the Dark: Image Retrieval under Varying Illumination Conditions", "url": "http://arxiv.org/pdf/1908.08999v1", "summary": "Image retrieval under varying illumination conditions, such as day and night\nimages, is addressed by image preprocessing, both hand-crafted and learned.\nPrior to extracting image descriptors by a convolutional neural network, images\nare photometrically normalised in order to reduce the descriptor sensitivity to\nillumination changes. We propose a learnable normalisation based on the U-Net\narchitecture, which is trained on a combination of single-camera multi-exposure\nimages and a newly constructed collection of similar views of landmarks during\nday and night. We experimentally show that both hand-crafted normalisation\nbased on local histogram equalisation and the learnable normalisation\noutperform standard approaches in varying illumination conditions, while\nstaying on par with the state-of-the-art methods on daylight illumination\nbenchmarks, such as Oxford or Paris datasets.", "published": "2019-08-23T19:30:37Z", "version": 1}, {"aid": "1908.09066", "authors": ["Le Zhang", "Zenglin Shi", "Ming-Ming Cheng", "Yun Liu", "Jia-Wang Bian", "Joey Tianyi Zhou", "Guoyan Zheng", "Zeng Zeng"], "title": "Robust Regression via Deep Negative Correlation Learning", "url": "http://arxiv.org/pdf/1908.09066v1", "summary": "Nonlinear regression has been extensively employed in many computer vision\nproblems (e.g., crowd counting, age estimation, affective computing). Under the\numbrella of deep learning, two common solutions exist i) transforming nonlinear\nregression to a robust loss function which is jointly optimizable with the deep\nconvolutional network, and ii) utilizing ensemble of deep networks. Although\nsome improved performance is achieved, the former may be lacking due to the\nintrinsic limitation of choosing a single hypothesis and the latter usually\nsuffers from much larger computational complexity. To cope with those issues,\nwe propose to regress via an efficient \"divide and conquer\" manner. The core of\nour approach is the generalization of negative correlation learning that has\nbeen shown, both theoretically and empirically, to work well for non-deep\nregression problems. Without extra parameters, the proposed method controls the\nbias-variance-covariance trade-off systematically and usually yields a deep\nregression ensemble where each base model is both \"accurate\" and \"diversified\".\nMoreover, we show that each sub-problem in the proposed method has less\nRademacher Complexity and thus is easier to optimize. Extensive experiments on\nseveral diverse and challenging tasks including crowd counting, personality\nanalysis, age estimation, and image super-resolution demonstrate the\nsuperiority over challenging baselines as well as the versatility of the\nproposed method.", "published": "2019-08-24T01:26:03Z", "version": 1}, {"aid": "1908.09124", "authors": ["Jintao Zhang"], "title": "SeesawFaceNets: sparse and robust face verification model for mobile platform", "url": "http://arxiv.org/pdf/1908.09124v3", "summary": "Deep Convolutional Neural Network (DCNNs) come to be the most widely used\nsolution for most computer vision related tasks, and one of the most important\napplication scenes is face verification. Due to its high-accuracy performance,\ndeep face verification models of which the inference stage occurs on cloud\nplatform through internet plays the key role on most prectical scenes. However,\ntwo critical issues exist: First, individual privacy may not be well protected\nsince they have to upload their personal photo and other private information to\nthe online cloud backend. Secondly, either training or inference stage is\ntime-comsuming and the latency may affect customer experience, especially when\nthe internet link speed is not so stable or in remote areas where mobile\nreception is not so good, but also in cities where building and other\nconstruction may block mobile signals. Therefore, designing lightweight\nnetworks with low memory requirement and computational cost is one of the most\npractical solutions for face verification on mobile platform. In this paper, a\nnovel mobile network named SeesawFaceNets, a simple but effective model, is\nproposed for productively deploying face recognition for mobile devices. Dense\nexperimental results have shown that our proposed model SeesawFaceNets\noutperforms the baseline MobilefaceNets, with only {\\bf66\\%}(146M VS 221M\nMAdds) computational cost, smaller batch size and less training steps, and\nSeesawFaceNets achieve comparable performance with other SOTA model e.g.\nmobiface with only {\\bf54.2\\%}(1.3M VS 2.4M) parameters and {\\bf31.6\\%}(146M VS\n462M MAdds) computational cost, It is also eventually competitive against\nlarge-scale deep-networks face recognition on all 5 listed public validation\ndatasets, with {\\bf6.5\\%}(4.2M VS 65M) parameters and {\\bf4.35\\%}(526M VS 12G\nMAdds) computational cost.", "published": "2019-08-24T11:21:38Z", "version": 3}, {"aid": "1908.09257", "authors": ["Ivan Kobyzev", "Simon J. D. Prince", "Marcus A. Brubaker"], "title": "Normalizing Flows: An Introduction and Review of Current Methods", "url": "http://arxiv.org/pdf/1908.09257v4", "summary": "Normalizing Flows are generative models which produce tractable distributions\nwhere both sampling and density evaluation can be efficient and exact. The goal\nof this survey article is to give a coherent and comprehensive review of the\nliterature around the construction and use of Normalizing Flows for\ndistribution learning. We aim to provide context and explanation of the models,\nreview current state-of-the-art literature, and identify open questions and\npromising future directions.", "published": "2019-08-25T06:14:08Z", "version": 4}, {"aid": "1909.09588", "authors": ["Rene Schaub"], "title": "What are Neural Networks made of?", "url": "http://arxiv.org/pdf/1909.09588v1", "summary": "The success of Deep Learning methods is not well understood, though various\nattempts at explaining it have been made, typically centered on properties of\nstochastic gradient descent. Even less clear is why certain neural network\narchitectures perform better than others. We provide a potential opening with\nthe hypothesis that neural network training is a form of Genetic Programming.", "published": "2019-08-25T21:59:26Z", "version": 1}, {"aid": "1908.09442", "authors": ["Xin Li", "Tianwei Lin", "Xiao Liu", "Chuang Gan", "Wangmeng Zuo", "Chao Li", "Xiang Long", "Dongliang He", "Fu Li", "Shilei Wen"], "title": "Deep Concept-wise Temporal Convolutional Networks for Action Localization", "url": "http://arxiv.org/pdf/1908.09442v1", "summary": "Existing action localization approaches adopt shallow temporal convolutional\nnetworks (\\ie, TCN) on 1D feature map extracted from video frames. In this\npaper, we empirically find that stacking more conventional temporal convolution\nlayers actually deteriorates action classification performance, possibly\nascribing to that all channels of 1D feature map, which generally are highly\nabstract and can be regarded as latent concepts, are excessively recombined in\ntemporal convolution. To address this issue, we introduce a novel concept-wise\ntemporal convolution (CTC) layer as an alternative to conventional temporal\nconvolution layer for training deeper action localization networks. Instead of\nrecombining latent concepts, CTC layer deploys a number of temporal filters to\neach concept separately with shared filter parameters across concepts. Thus can\ncapture common temporal patterns of different concepts and significantly enrich\nrepresentation ability. Via stacking CTC layers, we proposed a deep\nconcept-wise temporal convolutional network (C-TCN), which boosts the\nstate-of-the-art action localization performance on THUMOS'14 from 42.8 to 52.1\nin terms of mAP(\\%), achieving a relative improvement of 21.7\\%. Favorable\nresult is also obtained on ActivityNet.", "published": "2019-08-26T02:56:07Z", "version": 1}, {"aid": "1908.09791", "authors": ["Han Cai", "Chuang Gan", "Tianzhe Wang", "Zhekai Zhang", "Song Han"], "title": "Once-for-All: Train One Network and Specialize it for Efficient Deployment", "url": "http://arxiv.org/pdf/1908.09791v5", "summary": "We address the challenging problem of efficient inference across many devices\nand resource constraints, especially on edge devices. Conventional approaches\neither manually design or use neural architecture search (NAS) to find a\nspecialized neural network and train it from scratch for each case, which is\ncomputationally prohibitive (causing $CO_2$ emission as much as 5 cars'\nlifetime) thus unscalable. In this work, we propose to train a once-for-all\n(OFA) network that supports diverse architectural settings by decoupling\ntraining and search, to reduce the cost. We can quickly get a specialized\nsub-network by selecting from the OFA network without additional training. To\nefficiently train OFA networks, we also propose a novel progressive shrinking\nalgorithm, a generalized pruning method that reduces the model size across many\nmore dimensions than pruning (depth, width, kernel size, and resolution). It\ncan obtain a surprisingly large number of sub-networks ($> 10^{19}$) that can\nfit different hardware platforms and latency constraints while maintaining the\nsame level of accuracy as training independently. On diverse edge devices, OFA\nconsistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0%\nImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x\nfaster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency)\nwhile reducing many orders of magnitude GPU hours and $CO_2$ emission. In\nparticular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the\nmobile setting ($<$600M MACs). OFA is the winning solution for the 3rd Low\nPower Computer Vision Challenge (LPCVC), DSP classification track and the 4th\nLPCVC, both classification track and detection track. Code and 50 pre-trained\nmodels (for many devices & many latency constraints) are released at\nhttps://github.com/mit-han-lab/once-for-all.", "published": "2019-08-26T16:46:23Z", "version": 5}, {"aid": "1908.10059", "authors": ["Zhijun Mai", "Guosheng Hu", "Dexiong Chen", "Fumin Shen", "Heng Tao Shen"], "title": "MetaMixUp: Learning Adaptive Interpolation Policy of MixUp with Meta-Learning", "url": "http://arxiv.org/pdf/1908.10059v1", "summary": "MixUp is an effective data augmentation method to regularize deep neural\nnetworks via random linear interpolations between pairs of samples and their\nlabels. It plays an important role in model regularization, semi-supervised\nlearning and domain adaption. However, despite its empirical success, its\ndeficiency of randomly mixing samples has poorly been studied. Since deep\nnetworks are capable of memorizing the entire dataset, the corrupted samples\ngenerated by vanilla MixUp with a badly chosen interpolation policy will\ndegrade the performance of networks. To overcome the underfitting by corrupted\nsamples, inspired by Meta-learning (learning to learn), we propose a novel\ntechnique of learning to mixup in this work, namely, MetaMixUp. Unlike the\nvanilla MixUp that samples interpolation policy from a predefined distribution,\nthis paper introduces a meta-learning based online optimization approach to\ndynamically learn the interpolation policy in a data-adaptive way. The\nvalidation set performance via meta-learning captures the underfitting issue,\nwhich provides more information to refine interpolation policy. Furthermore, we\nadapt our method for pseudo-label based semisupervised learning (SSL) along\nwith a refined pseudo-labeling strategy. In our experiments, our method\nachieves better performance than vanilla MixUp and its variants under\nsupervised learning configuration. In particular, extensive experiments show\nthat our MetaMixUp adapted SSL greatly outperforms MixUp and many\nstate-of-the-art methods on CIFAR-10 and SVHN benchmarks under SSL\nconfiguration.", "published": "2019-08-27T07:26:35Z", "version": 1}, {"aid": "1908.10417", "authors": ["Corneliu Arsene"], "title": "Complex Deep Learning Models for Denoising of Human Heart ECG signals", "url": "http://arxiv.org/pdf/1908.10417v3", "summary": "Effective and powerful methods for denoising real electrocardiogram (ECG)\nsignals are important for wearable sensors and devices. Deep Learning (DL)\nmodels have been used extensively in image processing and other domains with\ngreat success but only very recently have been used in processing ECG signals.\nThis paper presents several DL models namely Convolutional Neural Networks\n(CNNs), Long Short-Term Memory (LSTM), Restricted Boltzmann Machine (RBM)\ntogether with the more conventional filtering methods (low pass filtering, high\npass filtering, Notch filtering) and the standard wavelet-based technique for\ndenoising EEG signals. These methods are trained, tested and evaluated on\ndifferent synthetic and real ECG datasets taken from the MIT PhysioNet database\nand for different simulation conditions (i.e. various lengths of the ECG\nsignals, single or multiple records). The results show the CNN model is a\nperformant model that can be used for off-line denoising ECG applications where\nit is satisfactory to train on a clean part of an ECG signal from an ECG\nrecord, and then to test on the same ECG signal, which would have some high\nlevel of noise added to it. However, for real-time applications or near-real\ntime applications, this task becomes more cumbersome, as the clean part of an\nECG signal is very probable to be very limited in size. Therefore the solution\nput forth in this work is to train a CNN model on 1 second ECG noisy artificial\nmultiple heartbeat data (i.e. ECG at effort), which was generated in a first\ninstance based on few sequences of real signal heartbeat ECG data (i.e. ECG at\nrest). Afterwards it would be possible to use the trained CNN model in real\nlife situations to denoise the ECG signal.", "published": "2019-08-27T19:14:32Z", "version": 3}, {"aid": "1908.11494", "authors": ["Jingbin Liu", "Xinyang Gu", "Shuai Liu"], "title": "Reinforcement learning with world model", "url": "http://arxiv.org/pdf/1908.11494v4", "summary": "Nowadays, model-free reinforcement learning algorithms have achieved\nremarkable performance on many decision making and control tasks, but high\nsample complexity and low sample efficiency still hinder the wide use of\nmodel-free reinforcement learning algorithms. In this paper, we argue that if\nwe intend to design an intelligent agent that learns fast and transfers well,\nthe agent must be able to reflect key elements of intelligence, like intuition,\nMemory, PredictionandCuriosity. We propose an agent framework that integrates\noff-policy reinforcement learning with world model learning, so as to embody\nthe important features of intelligence in our algorithm design. We adopt the\nstate-of-art model-free reinforcement learning algorithm, Soft Actor-Critic, as\nthe agent intuition, and world model learning through RNN to endow the agent\nwith memory, curiosity, and the ability to predict. We show that these ideas\ncan work collaboratively with each other and our agent (RMC) can give new\nstate-of-art results while maintaining sample efficiency and training\nstability. Moreover, our agent framework can be easily extended from MDP to\nPOMDP problems without performance loss.", "published": "2019-08-30T00:29:32Z", "version": 4}, {"aid": "1908.11628", "authors": ["Sagie Benaim", "Michael Khaitov", "Tomer Galanti", "Lior Wolf"], "title": "Domain Intersection and Domain Difference", "url": "http://arxiv.org/pdf/1908.11628v1", "summary": "We present a method for recovering the shared content between two visual\ndomains as well as the content that is unique to each domain. This allows us to\nmap from one domain to the other, in a way in which the content that is\nspecific for the first domain is removed and the content that is specific for\nthe second is imported from any image in the second domain. In addition, our\nmethod enables generation of images from the intersection of the two domains as\nwell as their union, despite having no such samples during training. The method\nis shown analytically to contain all the sufficient and necessary constraints.\nIt also outperforms the literature methods in an extensive set of experiments.\nOur code is available at\nhttps://github.com/sagiebenaim/DomainIntersectionDifference.", "published": "2019-08-30T10:08:43Z", "version": 1}, {"aid": "1909.01779", "authors": ["Matthia Sabatelli", "Gilles Louppe", "Pierre Geurts", "Marco A. Wiering"], "title": "Approximating two value functions instead of one: towards characterizing a new family of Deep Reinforcement Learning algorithms", "url": "http://arxiv.org/pdf/1909.01779v2", "summary": "This paper makes one step forward towards characterizing a new family of\n\\textit{model-free} Deep Reinforcement Learning (DRL) algorithms. The aim of\nthese algorithms is to jointly learn an approximation of the state-value\nfunction ($V$), alongside an approximation of the state-action value function\n($Q$). Our analysis starts with a thorough study of the Deep Quality-Value\nLearning (DQV) algorithm, a DRL algorithm which has been shown to outperform\npopular techniques such as Deep-Q-Learning (DQN) and Double-Deep-Q-Learning\n(DDQN) \\cite{sabatelli2018deep}. Intending to investigate why DQV's learning\ndynamics allow this algorithm to perform so well, we formulate a set of\nresearch questions which help us characterize a new family of DRL algorithms.\nAmong our results, we present some specific cases in which DQV's performance\ncan get harmed and introduce a novel \\textit{off-policy} DRL algorithm, called\nDQV-Max, which can outperform DQV. We then study the behavior of the $V$ and\n$Q$ functions that are learned by DQV and DQV-Max and show that both algorithms\nmight perform so well on several DRL test-beds because they are less prone to\nsuffer from the overestimation bias of the $Q$ function.", "published": "2019-09-01T10:29:54Z", "version": 2}, {"aid": "1909.00390", "authors": ["Philip May"], "title": "Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing", "url": "http://arxiv.org/pdf/1909.00390v2", "summary": "Image augmentation is a widely used technique to improve the performance of\nconvolutional neural networks (CNNs). In common image shifting, cropping,\nflipping, shearing and rotating are used for augmentation. But there are more\nadvanced techniques like Cutout and SamplePairing. In this work we present two\nimprovements of the state-of-the-art Cutout and SamplePairing techniques. Our\nnew method called Copyout takes a square patch of another random training image\nand copies it onto a random location of each image used for training. The\nsecond technique we discovered is called CopyPairing. It combines Copyout and\nSamplePairing for further augmentation and even better performance. We apply\ndifferent experiments with these augmentation techniques on the CIFAR-10\ndataset to evaluate and compare them under different configurations. In our\nexperiments we show that Copyout reduces the test error rate by 8.18% compared\nwith Cutout and 4.27% compared with SamplePairing. CopyPairing reduces the test\nerror rate by 11.97% compared with Cutout and 8.21% compared with\nSamplePairing. Copyout and CopyPairing implementations are available at\nhttps://github.com/t-systems-on-site-services-gmbh/coocop.", "published": "2019-09-01T12:59:09Z", "version": 2}, {"aid": "1909.05632", "authors": ["Arno Khachatourian"], "title": "Reusing Convolutional Activations from Frame to Frame to Speed up Training and Inference", "url": "http://arxiv.org/pdf/1909.05632v2", "summary": "When processing similar frames in succession, we can take advantage of the\nlocality of the convolution operation to reevaluate only portions of the image\nthat changed from the previous frame. By saving the output of a layer of\nconvolutions and calculating the change from frame to frame, we can reuse\nprevious activations and save computational resources that would otherwise be\nwasted recalculating convolutions whose outputs we have already observed. This\ntechnique can be applied to many domains, such as processing videos from\nstationary video cameras, studying the effects of occluding or distorting\nsections of images, applying convolution to multiple frames of audio or time\nseries data, or playing Atari games. Furthermore, this technique can be applied\nto speed up both training and inference.", "published": "2019-09-02T00:21:03Z", "version": 2}, {"aid": "1909.01939", "authors": ["Pengfei Zhang", "Jianru Xue", "Cuiling Lan", "Wenjun Zeng", "Zhanning Gao", "Nanning Zheng"], "title": "EleAtt-RNN: Adding Attentiveness to Neurons in Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1909.01939v1", "summary": "Recurrent neural networks (RNNs) are capable of modeling temporal\ndependencies of complex sequential data. In general, current available\nstructures of RNNs tend to concentrate on controlling the contributions of\ncurrent and previous information. However, the exploration of different\nimportance levels of different elements within an input vector is always\nignored. We propose a simple yet effective Element-wise-Attention Gate\n(EleAttG), which can be easily added to an RNN block (e.g. all RNN neurons in\nan RNN layer), to empower the RNN neurons to have attentiveness capability. For\nan RNN block, an EleAttG is used for adaptively modulating the input by\nassigning different levels of importance, i.e., attention, to each\nelement/dimension of the input. We refer to an RNN block equipped with an\nEleAttG as an EleAtt-RNN block. Instead of modulating the input as a whole, the\nEleAttG modulates the input at fine granularity, i.e., element-wise, and the\nmodulation is content adaptive. The proposed EleAttG, as an additional\nfundamental unit, is general and can be applied to any RNN structures, e.g.,\nstandard RNN, Long Short-Term Memory (LSTM), or Gated Recurrent Unit (GRU). We\ndemonstrate the effectiveness of the proposed EleAtt-RNN by applying it to\ndifferent tasks including the action recognition, from both skeleton-based data\nand RGB videos, gesture recognition, and sequential MNIST classification.\nExperiments show that adding attentiveness through EleAttGs to RNN blocks\nsignificantly improves the power of RNNs.", "published": "2019-09-03T08:15:09Z", "version": 1}, {"aid": "1909.01039", "authors": ["Henrich Kolkhorst", "Wolfram Burgard", "Michael Tangermann"], "title": "Learning User Preferences for Trajectories from Brain Signals", "url": "http://arxiv.org/pdf/1909.01039v2", "summary": "Robot motions in the presence of humans should not only be feasible and safe,\nbut also conform to human preferences. This, however, requires user feedback on\nthe robot's behavior. In this work, we propose a novel approach to leverage the\nuser's brain signals as a feedback modality in order to decode the judgment of\nrobot trajectories and rank them according to the user's preferences. We show\nthat brain signals measured using electroencephalography during observation of\na robotic arm's trajectory as well as in response to preference statements are\ninformative regarding the user's preference. Furthermore, we demonstrate that\nuser feedback from brain signals can be used to reliably infer pairwise\ntrajectory preferences as well as to retrieve the preferred observed\ntrajectories of the user with a performance comparable to explicit behavioral\nfeedback.", "published": "2019-09-03T10:20:50Z", "version": 2}, {"aid": "1909.01815", "authors": ["Bernhard Egger", "William A. P. Smith", "Ayush Tewari", "Stefanie Wuhrer", "Michael Zollhoefer", "Thabo Beeler", "Florian Bernard", "Timo Bolkart", "Adam Kortylewski", "Sami Romdhani", "Christian Theobalt", "Volker Blanz", "Thomas Vetter"], "title": "3D Morphable Face Models -- Past, Present and Future", "url": "http://arxiv.org/pdf/1909.01815v2", "summary": "In this paper, we provide a detailed survey of 3D Morphable Face Models over\nthe 20 years since they were first proposed. The challenges in building and\napplying these models, namely capture, modeling, image formation, and image\nanalysis, are still active research topics, and we review the state-of-the-art\nin each of these areas. We also look ahead, identifying unsolved challenges,\nproposing directions for future research and highlighting the broad range of\ncurrent and future applications.", "published": "2019-09-03T16:49:53Z", "version": 2}, {"aid": "1909.01498", "authors": ["Parth Natekar", "Avinash Kori", "Ganapathy Krishnamurthi"], "title": "Demystifying Brain Tumour Segmentation Networks: Interpretability and Uncertainty Analysis", "url": "http://arxiv.org/pdf/1909.01498v3", "summary": "The accurate automatic segmentation of gliomas and its intra-tumoral\nstructures is important not only for treatment planning but also for follow-up\nevaluations. Several methods based on 2D and 3D Deep Neural Networks (DNN) have\nbeen developed to segment brain tumors and to classify different categories of\ntumors from different MRI modalities. However, these networks are often\nblack-box models and do not provide any evidence regarding the process they\ntake to perform this task. Increasing transparency and interpretability of such\ndeep learning techniques are necessary for the complete integration of such\nmethods into medical practice. In this paper, we explore various techniques to\nexplain the functional organization of brain tumor segmentation models and to\nextract visualizations of internal concepts to understand how these networks\nachieve highly accurate tumor segmentations. We use the BraTS 2018 dataset to\ntrain three different networks with standard architectures and outline\nsimilarities and differences in the process that these networks take to segment\nbrain tumors. We show that brain tumor segmentation networks learn certain\nhuman-understandable disentangled concepts on a filter level. We also show that\nthey take a top-down or hierarchical approach to localizing the different parts\nof the tumor. We then extract visualizations of some internal feature maps and\nalso provide a measure of uncertainty with regards to the outputs of the models\nto give additional qualitative evidence about the predictions of these\nnetworks. We believe that the emergence of such human-understandable\norganization and concepts might aid in the acceptance and integration of such\nmethods in medical diagnosis.", "published": "2019-09-03T23:53:11Z", "version": 3}, {"aid": "1909.01500", "authors": ["Adam Stooke", "Pieter Abbeel"], "title": "rlpyt: A Research Code Base for Deep Reinforcement Learning in PyTorch", "url": "http://arxiv.org/pdf/1909.01500v2", "summary": "Since the recent advent of deep reinforcement learning for game play and\nsimulated robotic control, a multitude of new algorithms have flourished. Most\nare model-free algorithms which can be categorized into three families: deep\nQ-learning, policy gradients, and Q-value policy gradients. These have\ndeveloped along separate lines of research, such that few, if any, code bases\nincorporate all three kinds. Yet these algorithms share a great depth of common\ndeep reinforcement learning machinery. We are pleased to share rlpyt, which\nimplements all three algorithm families on top of a shared, optimized\ninfrastructure, in a single repository. It contains modular implementations of\nmany common deep RL algorithms in Python using PyTorch, a leading deep learning\nlibrary. rlpyt is designed as a high-throughput code base for small- to\nmedium-scale research in deep RL. This white paper summarizes its features,\nalgorithms implemented, and relation to prior work, and concludes with detailed\nimplementation and usage notes. rlpyt is available at\nhttps://github.com/astooke/rlpyt.", "published": "2019-09-03T23:57:13Z", "version": 2}, {"aid": "1909.01542", "authors": ["Yang Li", "Jianhe Yuan", "Zhiqun Zhao", "Hao Sun", "Zhihai He"], "title": "Snowball: Iterative Model Evolution and Confident Sample Discovery for Semi-Supervised Learning on Very Small Labeled Datasets", "url": "http://arxiv.org/pdf/1909.01542v1", "summary": "In this work, we develop a joint sample discovery and iterative model\nevolution method for semi-supervised learning on very small labeled training\nsets. We propose a master-teacher-student model framework to provide\nmulti-layer guidance during the model evolution process with multiple\niterations and generations. The teacher model is constructed by performing an\nexponential moving average of the student models obtained from past training\nsteps. The master network combines the knowledge of the student and teacher\nmodels with additional access to newly discovered samples. The master and\nteacher models are then used to guide the training of the student network by\nenforcing the consistence between their predictions of unlabeled samples and\nevolve all models when more and more samples are discovered. Our extensive\nexperiments demonstrate that the discovering confident samples from the\nunlabeled dataset, once coupled with the above master-teacher-student network\nevolution, can significantly improve the overall semi-supervised learning\nperformance. For example, on the CIFAR-10 dataset, with a very small set of 250\nlabeled samples, our method achieves an error rate of 11.81 %, more than 38 %\nlower than the state-of-the-art method Mean-Teacher (49.91 %).", "published": "2019-09-04T03:41:27Z", "version": 1}, {"aid": "1909.06012", "authors": ["Chao Huang", "Hu Han", "Qingsong Yao", "Shankuan Zhu", "S. Kevin Zhou"], "title": "3D U$^2$-Net: A 3D Universal U-Net for Multi-Domain Medical Image Segmentation", "url": "http://arxiv.org/pdf/1909.06012v1", "summary": "Fully convolutional neural networks like U-Net have been the state-of-the-art\nmethods in medical image segmentation. Practically, a network is highly\nspecialized and trained separately for each segmentation task. Instead of a\ncollection of multiple models, it is highly desirable to learn a universal data\nrepresentation for different tasks, ideally a single model with the addition of\na minimal number of parameters steered to each task. Inspired by the recent\nsuccess of multi-domain learning in image classification, for the first time we\nexplore a promising universal architecture that handles multiple medical\nsegmentation tasks and is extendable for new tasks, regardless of different\norgans and imaging modalities. Our 3D Universal U-Net (3D U$^2$-Net) is built\nupon separable convolution, assuming that {\\it images from different domains\nhave domain-specific spatial correlations which can be probed with channel-wise\nconvolution while also share cross-channel correlations which can be modeled\nwith pointwise convolution}. We evaluate the 3D U$^2$-Net on five organ\nsegmentation datasets. Experimental results show that this universal network is\ncapable of competing with traditional models in terms of segmentation accuracy,\nwhile requiring only about $1\\%$ of the parameters. Additionally, we observe\nthat the architecture can be easily and effectively adapted to a new domain\nwithout sacrificing performance in the domains used to learn the shared\nparameterization of the universal network. We put the code of 3D U$^2$-Net into\npublic domain. \\url{https://github.com/huangmozhilv/u2net_torch/}", "published": "2019-09-04T15:03:08Z", "version": 1}, {"aid": "1909.01861", "authors": ["Hui Zhu", "Zhulin An", "Chuanguang Yang", "Xiaolong Hu", "Kaiqiang Xu", "Yongjun Xu"], "title": "Rethinking the Number of Channels for the Convolutional Neural Network", "url": "http://arxiv.org/pdf/1909.01861v1", "summary": "Latest algorithms for automatic neural architecture search perform remarkable\nbut few of them can effectively design the number of channels for convolutional\nneural networks and consume less computational efforts. In this paper, we\npropose a method for efficient automatic architecture search which is special\nto the widths of networks instead of the connections of neural architecture.\nOur method, functionally incremental search based on function-preserving, will\nexplore the number of channels rapidly while controlling the number of\nparameters of the target network. On CIFAR-10 and CIFAR-100 classification, our\nmethod using minimal computational resources (0.4~1.3 GPU-days) can discover\nmore efficient rules of the widths of networks to improve the accuracy by about\n0.5% on CIFAR-10 and a~2.33% on CIFAR-100 with fewer number of parameters. In\nparticular, our method is suitable for exploring the number of channels of\nalmost any convolutional neural network rapidly.", "published": "2019-09-04T15:09:22Z", "version": 1}, {"aid": "1909.01960", "authors": ["Kristofer Schlachter", "Connor DeFanti", "Sebastian Herscher", "Ken Perlin", "Jonathan Tompson"], "title": "Beyond Photo Realism for Domain Adaptation from Synthetic Data", "url": "http://arxiv.org/pdf/1909.01960v1", "summary": "As synthetic imagery is used more frequently in training deep models, it is\nimportant to understand how different synthesis techniques impact the\nperformance of such models. In this work, we perform a thorough evaluation of\nthe effectiveness of several different synthesis techniques and their impact on\nthe complexity of classifier domain adaptation to the \"real\" underlying data\ndistribution that they seek to replicate. In addition, we propose a novel\nlearned synthesis technique to better train classifier models than\nstate-of-the-art offline graphical methods, while using significantly less\ncomputational resources. We accomplish this by learning a generative model to\nperform shading of synthetic geometry conditioned on a \"g-buffer\"\nrepresentation of the scene to render, as well as a low sample Monte Carlo\nrendered image. The major contributions are (i) a dataset that allows\ncomparison of real and synthetic versions of the same scene, (ii) an augmented\ndata representation that boosts the stability of learning and improves the\ndatasets accuracy, (iii) three different partially differentiable rendering\ntechniques where lighting, denoising and shading are learned, and (iv) we\nimprove a state of the art generative adversarial network (GAN) approach by\nusing an ensemble of trained models to generate datasets that approach the\nperformance of training on real data and surpass the performance of the full\nglobal illumination rendering.", "published": "2019-09-04T17:38:05Z", "version": 1}, {"aid": "1909.01963", "authors": ["Aman Shrivastava", "Will Adorno", "Yash Sharma", "Lubaina Ehsan", "S. Asad Ali", "Sean R. Moore", "Beatrice C. Amadi", "Paul Kelly", "Sana Syed", "Donald E. Brown"], "title": "Self-Attentive Adversarial Stain Normalization", "url": "http://arxiv.org/pdf/1909.01963v3", "summary": "Hematoxylin and Eosin (H&E) stained Whole Slide Images (WSIs) are utilized\nfor biopsy visualization-based diagnostic and prognostic assessment of\ndiseases. Variation in the H&E staining process across different lab sites can\nlead to significant variations in biopsy image appearance. These variations\nintroduce an undesirable bias when the slides are examined by pathologists or\nused for training deep learning models. To reduce this bias, slides need to be\ntranslated to a common domain of stain appearance before analysis. We propose a\nSelf-Attentive Adversarial Stain Normalization (SAASN) approach for the\nnormalization of multiple stain appearances to a common domain. This\nunsupervised generative adversarial approach includes self-attention mechanism\nfor synthesizing images with finer detail while preserving the structural\nconsistency of the biopsy features during translation. SAASN demonstrates\nconsistent and superior performance compared to other popular stain\nnormalization techniques on H&E stained duodenal biopsy image data.", "published": "2019-09-04T17:41:19Z", "version": 3}, {"aid": "1909.02040", "authors": ["Zihui Wu", "Yu Sun", "Jiaming Liu", "Ulugbek S. Kamilov"], "title": "Online Regularization by Denoising with Applications to Phase Retrieval", "url": "http://arxiv.org/pdf/1909.02040v1", "summary": "Regularization by denoising (RED) is a powerful framework for solving imaging\ninverse problems. Most RED algorithms are iterative batch procedures, which\nlimits their applicability to very large datasets. In this paper, we address\nthis limitation by introducing a novel online RED (On-RED) algorithm, which\nprocesses a small subset of the data at a time. We establish the theoretical\nconvergence of On-RED in convex settings and empirically discuss its\neffectiveness in non-convex ones by illustrating its applicability to phase\nretrieval. Our results suggest that On-RED is an effective alternative to the\ntraditional RED algorithms when dealing with large datasets.", "published": "2019-09-04T18:29:10Z", "version": 1}, {"aid": "1909.02214", "authors": ["Yifan Liu", "Bohan Zhuang", "Chunhua Shen", "Hao Chen", "Wei Yin"], "title": "Auxiliary Learning for Deep Multi-task Learning", "url": "http://arxiv.org/pdf/1909.02214v2", "summary": "Multi-task learning (MTL) is an efficient solution to solve multiple tasks\nsimultaneously in order to get better speed and performance than handling each\nsingle-task in turn. The most current methods can be categorized as either: (i)\nhard parameter sharing where a subset of the parameters is shared among tasks\nwhile other parameters are task-specific; or (ii) soft parameter sharing where\nall parameters are task-specific but they are jointly regularized. Both methods\nsuffer from limitations: the shared hidden layers of the former are difficult\nto optimize due to the competing objectives while the complexity of the latter\ngrows linearly with the increasing number of tasks. To mitigate those\ndrawbacks, this paper proposes an alternative, where we explicitly construct an\nauxiliary module to mimic the soft parameter sharing for assisting the\noptimization of the hard parameter sharing layers in the training phase. In\nparticular, the auxiliary module takes the outputs of the shared hidden layers\nas inputs and is supervised by the auxiliary task loss. During training, the\nauxiliary module is jointly optimized with the MTL network, serving as a\nregularization by introducing an inductive bias to the shared layers. In the\ntesting phase, only the original MTL network is kept. Thus our method avoids\nthe limitation of both categories. We evaluate the proposed auxiliary module on\npixel-wise prediction tasks, including semantic segmentation, depth estimation,\nand surface normal prediction with different network structures. The extensive\nexperiments over various settings verify the effectiveness of our methods.", "published": "2019-09-05T05:29:15Z", "version": 2}, {"aid": "1909.02603", "authors": ["Kameron Decker Harris"], "title": "Additive function approximation in the brain", "url": "http://arxiv.org/pdf/1909.02603v2", "summary": "Many biological learning systems such as the mushroom body, hippocampus, and\ncerebellum are built from sparsely connected networks of neurons. For a new\nunderstanding of such networks, we study the function spaces induced by sparse\nrandom features and characterize what functions may and may not be learned. A\nnetwork with $d$ inputs per neuron is found to be equivalent to an additive\nmodel of order $d$, whereas with a degree distribution the network combines\nadditive terms of different orders. We identify three specific advantages of\nsparsity: additive function approximation is a powerful inductive bias that\nlimits the curse of dimensionality, sparse networks are stable to outlier noise\nin the inputs, and sparse random features are scalable. Thus, even simple brain\narchitectures can be powerful function approximators. Finally, we hope that\nthis work helps popularize kernel theories of networks among computational\nneuroscientists.", "published": "2019-09-05T19:07:33Z", "version": 2}, {"aid": "1909.02620", "authors": ["Ozan Ciga", "Jianan Chen", "Anne Martel"], "title": "Multi-layer Domain Adaptation for Deep Convolutional Networks", "url": "http://arxiv.org/pdf/1909.02620v1", "summary": "Despite their success in many computer vision tasks, convolutional networks\ntend to require large amounts of labeled data to achieve generalization.\nFurthermore, the performance is not guaranteed on a sample from an unseen\ndomain at test time, if the network was not exposed to similar samples from\nthat domain at training time. This hinders the adoption of these techniques in\nclinical setting where the imaging data is scarce, and where the intra- and\ninter-domain variance of the data can be substantial. We propose a domain\nadaptation technique that is especially suitable for deep networks to alleviate\nthis requirement of labeled data. Our method utilizes gradient reversal layers\nand Squeezeand-Excite modules to stabilize the training in deep networks. The\nproposed method was applied to publicly available histopathology and chest\nX-ray databases and achieved superior performance to existing state-of-the-art\nnetworks with and without domain adaptation. Depending on the application, our\nmethod can improve multi-class classification accuracy by 5-20% compared to\nDANN introduced in (Ganin, 2014).", "published": "2019-09-05T20:24:49Z", "version": 1}, {"aid": "1909.02765", "authors": ["Zhuoran Ji"], "title": "ILP-M Conv: Optimize Convolution Algorithm for Single-Image Convolution Neural Network Inference on Mobile GPUs", "url": "http://arxiv.org/pdf/1909.02765v2", "summary": "Convolution neural networks are widely used for mobile applications. However,\nGPU convolution algorithms are designed for mini-batch neural network training,\nthe single-image convolution neural network inference algorithm on mobile GPUs\nis not well-studied. After discussing the usage difference and examining the\nexisting convolution algorithms, we proposed the HNTMP convolution algorithm.\nThe HNTMP convolution algorithm achieves $14.6 \\times$ speedup than the most\npopular \\textit{im2col} convolution algorithm, and $2.30 \\times$ speedup than\nthe fastest existing convolution algorithm (direct convolution) as far as we\nknow.", "published": "2019-09-06T08:36:05Z", "version": 2}, {"aid": "1909.03834", "authors": ["Dongsheng Ruan", "Jun Wen", "Nenggan Zheng", "Min Zheng"], "title": "Linear Context Transform Block", "url": "http://arxiv.org/pdf/1909.03834v2", "summary": "Squeeze-and-Excitation (SE) block presents a channel attention mechanism for\nmodeling global context via explicitly capturing dependencies across channels.\nHowever, we are still far from understanding how the SE block works. In this\nwork, we first revisit the SE block, and then present a detailed empirical\nstudy of the relationship between global context and attention distribution,\nbased on which we propose a simple yet effective module, called Linear Context\nTransform (LCT) block. We divide all channels into different groups and\nnormalize the globally aggregated context features within each channel group,\nreducing the disturbance from irrelevant channels. Through linear transform of\nthe normalized context features, we model global context for each channel\nindependently. The LCT block is extremely lightweight and easy to be plugged\ninto different backbone models while with negligible parameters and\ncomputational burden increase. Extensive experiments show that the LCT block\noutperforms the SE block in image classification task on the ImageNet and\nobject detection/segmentation on the COCO dataset with different backbone\nmodels. Moreover, LCT yields consistent performance gains over existing\nstate-of-the-art detection architectures, e.g., 1.5$\\sim$1.7% AP$^{bbox}$ and\n1.0$\\sim$1.2% AP$^{mask}$ improvements on the COCO benchmark, irrespective of\ndifferent baseline models of varied capacities. We hope our simple yet\neffective approach will shed some light on future research of attention-based\nmodels.", "published": "2019-09-06T12:31:28Z", "version": 2}, {"aid": "1909.04586", "authors": ["Prashant C. Raju"], "title": "A Theory on Formatting Sensory Input for Cognition", "url": "http://arxiv.org/pdf/1909.04586v5", "summary": "Over the last few decades, a lot of progress has been made in understanding\ndifferent aspects of the brain's ability to form abstract representations, but\na specific mechanism for how they are created and used remains to emerge. Here,\nwe review recent findings on the subject and we propose a mechanism for the\ndynamics of forming abstract representations, where the formation of local\nconnectivity in neural networks determines the of search terms between the\nprefrontal cortex and the hippocampus, as well as the amount of detail that is\ntranscribed into abstract representations.", "published": "2019-09-08T20:00:55Z", "version": 5}, {"aid": "1909.04110", "authors": ["Zengming Shen", "S. Kevin Zhou", "Yifan Chen", "Bogdan Georgescu", "Xuqi Liu", "Thomas S. Huang"], "title": "One-to-one Mapping for Unpaired Image-to-image Translation", "url": "http://arxiv.org/pdf/1909.04110v6", "summary": "Recently image-to-image translation has attracted significant interests in\nthe literature, starting from the successful use of the generative adversarial\nnetwork (GAN), to the introduction of cyclic constraint, to extensions to\nmultiple domains. However, in existing approaches, there is no guarantee that\nthe mapping between two image domains is unique or one-to-one. Here we propose\na self-inverse network learning approach for unpaired image-to-image\ntranslation. Building on top of CycleGAN, we learn a self-inverse function by\nsimply augmenting the training samples by swapping inputs and outputs during\ntraining and with separated cycle consistency loss for each mapping direction.\nThe outcome of such learning is a proven one-to-one mapping function. Our\nextensive experiments on a variety of datasets, including cross-modal medical\nimage synthesis, object transfiguration, and semantic labeling, consistently\ndemonstrate clear improvement over the CycleGAN method both qualitatively and\nquantitatively. Especially our proposed method reaches the state-of-the-art\nresult on the cityscapes benchmark dataset for the label to photo unpaired\ndirectional image translation.", "published": "2019-09-09T19:10:05Z", "version": 6}, {"aid": "1909.04170", "authors": ["Giacomo Spigler"], "title": "Meta-learnt priors slow down catastrophic forgetting in neural networks", "url": "http://arxiv.org/pdf/1909.04170v2", "summary": "Current training regimes for deep learning usually involve exposure to a\nsingle task / dataset at a time. Here we start from the observation that in\nthis context the trained model is not given any knowledge of anything outside\nits (single-task) training distribution, and has thus no way to learn\nparameters (i.e., feature detectors or policies) that could be helpful to solve\nother tasks, and to limit future interference with the acquired knowledge, and\nthus catastrophic forgetting. Here we show that catastrophic forgetting can be\nmitigated in a meta-learning context, by exposing a neural network to multiple\ntasks in a sequential manner during training. Finally, we present SeqFOMAML, a\nmeta-learning algorithm that implements these principles, and we evaluate it on\nsequential learning problems composed by Omniglot and MiniImageNet\nclassification tasks.", "published": "2019-09-09T21:46:19Z", "version": 2}, {"aid": "1909.04358", "authors": ["Friedrich Schuessler", "Alexis Dubreuil", "Francesca Mastrogiuseppe", "Srdjan Ostojic", "Omri Barak"], "title": "Dynamics of random recurrent networks with correlated low-rank structure", "url": "http://arxiv.org/pdf/1909.04358v3", "summary": "A given neural network in the brain is involved in many different tasks. This\nimplies that, when considering a specific task, the network's connectivity\ncontains a component which is related to the task and another component which\ncan be considered random. Understanding the interplay between the structured\nand random components, and their effect on network dynamics and functionality\nis an important open question. Recent studies addressed the co-existence of\nrandom and structured connectivity, but considered the two parts to be\nuncorrelated. This constraint limits the dynamics and leaves the random\nconnectivity non-functional. Algorithms that train networks to perform specific\ntasks typically generate correlations between structure and random\nconnectivity. Here we study nonlinear networks with correlated structured and\nrandom components, assuming the structure to have a low rank. We develop an\nanalytic framework to establish the precise effect of the correlations on the\neigenvalue spectrum of the joint connectivity. We find that the spectrum\nconsists of a bulk and multiple outliers, whose location is predicted by our\ntheory. Using mean-field theory, we show that these outliers directly determine\nboth the fixed points of the system and their stability. Taken together, our\nanalysis elucidates how correlations allow structured and random connectivity\nto synergistically extend the range of computations available to networks.", "published": "2019-09-10T09:01:33Z", "version": 3}, {"aid": "1909.04630", "authors": ["Aravind Rajeswaran", "Chelsea Finn", "Sham Kakade", "Sergey Levine"], "title": "Meta-Learning with Implicit Gradients", "url": "http://arxiv.org/pdf/1909.04630v1", "summary": "A core capability of intelligent systems is the ability to quickly learn new\ntasks by drawing on prior experience. Gradient (or optimization) based\nmeta-learning has recently emerged as an effective approach for few-shot\nlearning. In this formulation, meta-parameters are learned in the outer loop,\nwhile task-specific models are learned in the inner-loop, by using only a small\namount of data from the current task. A key challenge in scaling these\napproaches is the need to differentiate through the inner loop learning\nprocess, which can impose considerable computational and memory burdens. By\ndrawing upon implicit differentiation, we develop the implicit MAML algorithm,\nwhich depends only on the solution to the inner level optimization and not the\npath taken by the inner loop optimizer. This effectively decouples the\nmeta-gradient computation from the choice of inner loop optimizer. As a result,\nour approach is agnostic to the choice of inner loop optimizer and can\ngracefully handle many gradient steps without vanishing gradients or memory\nconstraints. Theoretically, we prove that implicit MAML can compute accurate\nmeta-gradients with a memory footprint that is, up to small constant factors,\nno more than that which is required to compute a single inner loop gradient and\nat no overall increase in the total computational cost. Experimentally, we show\nthat these benefits of implicit MAML translate into empirical gains on few-shot\nimage recognition benchmarks.", "published": "2019-09-10T17:14:14Z", "version": 1}, {"aid": "1909.04866", "authors": ["Stephen Gould", "Richard Hartley", "Dylan Campbell"], "title": "Deep Declarative Networks: A New Hope", "url": "http://arxiv.org/pdf/1909.04866v2", "summary": "We explore a new class of end-to-end learnable models wherein data processing\nnodes (or network layers) are defined in terms of desired behavior rather than\nan explicit forward function. Specifically, the forward function is implicitly\ndefined as the solution to a mathematical optimization problem. Consistent with\nnomenclature in the programming languages community, we name these models deep\ndeclarative networks. Importantly, we show that the class of deep declarative\nnetworks subsumes current deep learning models. Moreover, invoking the implicit\nfunction theorem, we show how gradients can be back-propagated through many\ndeclaratively defined data processing nodes thereby enabling end-to-end\nlearning. We show how these declarative processing nodes can be implemented in\nthe popular PyTorch deep learning software library allowing declarative and\nimperative nodes to co-exist within the same network. We also provide numerous\ninsights and illustrative examples of declarative nodes and demonstrate their\napplication for image and point cloud classification tasks.", "published": "2019-09-11T06:19:25Z", "version": 2}, {"aid": "1909.05784", "authors": ["Dashan Gao", "Ce Ju", "Xiguang Wei", "Yang Liu", "Tianjian Chen", "Qiang Yang"], "title": "HHHFL: Hierarchical Heterogeneous Horizontal Federated Learning for Electroencephalography", "url": "http://arxiv.org/pdf/1909.05784v3", "summary": "Electroencephalography (EEG) classification techniques have been widely\nstudied for human behavior and emotion recognition tasks. But it is still a\nchallenging issue since the data may vary from subject to subject, may change\nover time for the same subject, and maybe heterogeneous. Recent years,\nincreasing privacy-preserving demands poses new challenges to this task. The\ndata heterogeneity, as well as the privacy constraint of the EEG data, is not\nconcerned in previous studies. To fill this gap, in this paper, we propose a\nheterogeneous federated learning approach to train machine learning models over\nheterogeneous EEG data, while preserving the data privacy of each party. To\nverify the effectiveness of our approach, we conduct experiments on a\nreal-world EEG dataset, consisting of heterogeneous data collected from diverse\ndevices. Our approach achieves consistent performance improvement on every\ntask.", "published": "2019-09-11T06:29:23Z", "version": 3}, {"aid": "1909.05085", "authors": ["Dennis Bontempi", "Sergio Benini", "Alberto Signoroni", "Michele Svanera", "Lars Muckli"], "title": "CEREBRUM: a fast and fully-volumetric Convolutional Encoder-decodeR for weakly-supervised sEgmentation of BRain strUctures from out-of-the-scanner MRI", "url": "http://arxiv.org/pdf/1909.05085v2", "summary": "Many functional and structural neuroimaging studies call for accurate\nmorphometric segmentation of different brain structures starting from image\nintensity values of MRI scans. Current automatic (multi-) atlas-based\nsegmentation strategies often lack accuracy on difficult-to-segment brain\nstructures and, since these methods rely on atlas-to-scan alignment, they may\ntake long processing times. Recently, methods deploying solutions based on\nConvolutional Neural Networks (CNNs) are making the direct analysis of\nout-of-the-scanner data feasible. However, current CNN-based solutions\npartition the test volume into 2D or 3D patches, which are processed\nindependently. This entails a loss of global contextual information thereby\nnegatively impacting the segmentation accuracy. In this work, we design and\ntest an optimised end-to-end CNN architecture that makes the exploitation of\nglobal spatial information computationally tractable, allowing to process a\nwhole MRI volume at once. We adopt a weakly supervised learning strategy by\nexploiting a large dataset composed by 947 out-of-the-scanner (3 Tesla\nT1-weighted 1mm isotropic MP-RAGE 3D sequences) MR Images. The resulting model\nis able to produce accurate multi-structure segmentation results in only few\nseconds. Different quantitative measures demonstrate an improved accuracy of\nour solution when compared to state-of-the-art techniques. Moreover, through a\nrandomised survey involving expert neuroscientists, we show that subjective\njudgements clearly prefer our solution with respect to the widely adopted\natlas-based FreeSurfer software.", "published": "2019-09-11T14:40:30Z", "version": 2}, {"aid": "1909.05235", "authors": ["Qi Qian", "Lei Shang", "Baigui Sun", "Juhua Hu", "Hao Li", "Rong Jin"], "title": "SoftTriple Loss: Deep Metric Learning Without Triplet Sampling", "url": "http://arxiv.org/pdf/1909.05235v2", "summary": "Distance metric learning (DML) is to learn the embeddings where examples from\nthe same class are closer than examples from different classes. It can be cast\nas an optimization problem with triplet constraints. Due to the vast number of\ntriplet constraints, a sampling strategy is essential for DML. With the\ntremendous success of deep learning in classifications, it has been applied for\nDML. When learning embeddings with deep neural networks (DNNs), only a\nmini-batch of data is available at each iteration. The set of triplet\nconstraints has to be sampled within the mini-batch. Since a mini-batch cannot\ncapture the neighbors in the original set well, it makes the learned embeddings\nsub-optimal. On the contrary, optimizing SoftMax loss, which is a\nclassification loss, with DNN shows a superior performance in certain DML\ntasks. It inspires us to investigate the formulation of SoftMax. Our analysis\nshows that SoftMax loss is equivalent to a smoothed triplet loss where each\nclass has a single center. In real-world data, one class can contain several\nlocal clusters rather than a single one, e.g., birds of different poses.\nTherefore, we propose the SoftTriple loss to extend the SoftMax loss with\nmultiple centers for each class. Compared with conventional deep metric\nlearning algorithms, optimizing SoftTriple loss can learn the embeddings\nwithout the sampling phase by mildly increasing the size of the last fully\nconnected layer. Experiments on the benchmark fine-grained data sets\ndemonstrate the effectiveness of the proposed loss function. Code is available\nat https://github.com/idstcv/SoftTriple", "published": "2019-09-11T17:47:25Z", "version": 2}, {"aid": "1909.11015", "authors": ["Shiv Ram Dubey", "Soumendu Chakraborty", "Swalpa Kumar Roy", "Snehasis Mukherjee", "Satish Kumar Singh", "Bidyut Baran Chaudhuri"], "title": "diffGrad: An Optimization Method for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1909.11015v4", "summary": "Stochastic Gradient Decent (SGD) is one of the core techniques behind the\nsuccess of deep neural networks. The gradient provides information on the\ndirection in which a function has the steepest rate of change. The main problem\nwith basic SGD is to change by equal sized steps for all parameters,\nirrespective of gradient behavior. Hence, an efficient way of deep network\noptimization is to make adaptive step sizes for each parameter. Recently,\nseveral attempts have been made to improve gradient descent methods such as\nAdaGrad, AdaDelta, RMSProp and Adam. These methods rely on the square roots of\nexponential moving averages of squared past gradients. Thus, these methods do\nnot take advantage of local change in gradients. In this paper, a novel\noptimizer is proposed based on the difference between the present and the\nimmediate past gradient (i.e., diffGrad). In the proposed diffGrad optimization\ntechnique, the step size is adjusted for each parameter in such a way that it\nshould have a larger step size for faster gradient changing parameters and a\nlower step size for lower gradient changing parameters. The convergence\nanalysis is done using the regret bound approach of online learning framework.\nRigorous analysis is made in this paper over three synthetic complex non-convex\nfunctions. The image categorization experiments are also conducted over the\nCIFAR10 and CIFAR100 datasets to observe the performance of diffGrad with\nrespect to the state-of-the-art optimizers such as SGDM, AdaGrad, AdaDelta,\nRMSProp, AMSGrad, and Adam. The residual unit (ResNet) based Convolutional\nNeural Networks (CNN) architecture is used in the experiments. The experiments\nshow that diffGrad outperforms other optimizers. Also, we show that diffGrad\nperforms uniformly well for training CNN using different activation functions.\nThe source code is made publicly available at\nhttps://github.com/shivram1987/diffGrad.", "published": "2019-09-12T06:20:05Z", "version": 4}, {"aid": "1909.07156", "authors": ["Masanari Kimura", "Masayuki Tanaka"], "title": "New Perspective of Interpretability of Deep Neural Networks", "url": "http://arxiv.org/pdf/1909.07156v1", "summary": "Deep neural networks (DNNs) are known as black-box models. In other words, it\nis difficult to interpret the internal state of the model. Improving the\ninterpretability of DNNs is one of the hot research topics. However, at\npresent, the definition of interpretability for DNNs is vague, and the question\nof what is a highly explanatory model is still controversial. To address this\nissue, we provide the definition of the human predictability of the model, as a\npart of the interpretability of the DNNs. The human predictability proposed in\nthis paper is defined by easiness to predict the change of the inference when\nperturbating the model of the DNNs. In addition, we introduce one example of\nhigh human-predictable DNNs. We discuss that our definition will help to the\nresearch of the interpretability of the DNNs considering various types of\napplications.", "published": "2019-09-12T07:24:20Z", "version": 1}, {"aid": "1909.06043", "authors": ["Bo Chen", "Alvaro Parra", "Jiewei Cao", "Nan Li", "Tat-Jun Chin"], "title": "End-to-End Learnable Geometric Vision by Backpropagating PnP Optimization", "url": "http://arxiv.org/pdf/1909.06043v3", "summary": "Deep networks excel in learning patterns from large amounts of data. On the\nother hand, many geometric vision tasks are specified as optimization problems.\nTo seamlessly combine deep learning and geometric vision, it is vital to\nperform learning and geometric optimization end-to-end. Towards this aim, we\npresent BPnP, a novel network module that backpropagates gradients through a\nPerspective-n-Points (PnP) solver to guide parameter updates of a neural\nnetwork. Based on implicit differentiation, we show that the gradients of a\n\"self-contained\" PnP solver can be derived accurately and efficiently, as if\nthe optimizer block were a differentiable function. We validate BPnP by\nincorporating it in a deep model that can learn camera intrinsics, camera\nextrinsics (poses) and 3D structure from training datasets. Further, we develop\nan end-to-end trainable pipeline for object pose estimation, which achieves\ngreater accuracy by combining feature-based heatmap losses with 2D-3D\nreprojection errors. Since our approach can be extended to other optimization\nproblems, our work helps to pave the way to perform learnable geometric vision\nin a principled manner. Our PyTorch implementation of BPnP is available on\nhttp://github.com/BoChenYS/BPnP.", "published": "2019-09-13T05:45:25Z", "version": 3}, {"aid": "1909.06161", "authors": ["Jonas Kubilius", "Martin Schrimpf", "Kohitij Kar", "Ha Hong", "Najib J. Majaj", "Rishi Rajalingham", "Elias B. Issa", "Pouya Bashivan", "Jonathan Prescott-Roy", "Kailyn Schmidt", "Aran Nayebi", "Daniel Bear", "Daniel L. K. Yamins", "James J. DiCarlo"], "title": "Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs", "url": "http://arxiv.org/pdf/1909.06161v2", "summary": "Deep convolutional artificial neural networks (ANNs) are the leading class of\ncandidate models of the mechanisms of visual processing in the primate ventral\nstream. While initially inspired by brain anatomy, over the past years, these\nANNs have evolved from a simple eight-layer architecture in AlexNet to\nextremely deep and branching architectures, demonstrating increasingly better\nobject categorization performance, yet bringing into question how brain-like\nthey still are. In particular, typical deep models from the machine learning\ncommunity are often hard to map onto the brain's anatomy due to their vast\nnumber of layers and missing biologically-important connections, such as\nrecurrence. Here we demonstrate that better anatomical alignment to the brain\nand high performance on machine learning as well as neuroscience measures do\nnot have to be in contradiction. We developed CORnet-S, a shallow ANN with four\nanatomically mapped areas and recurrent connectivity, guided by Brain-Score, a\nnew large-scale composite of neural and behavioral benchmarks for quantifying\nthe functional fidelity of models of the primate ventral visual stream. Despite\nbeing significantly shallower than most models, CORnet-S is the top model on\nBrain-Score and outperforms similarly compact models on ImageNet. Moreover, our\nextensive analyses of CORnet-S circuitry variants reveal that recurrence is the\nmain predictive factor of both Brain-Score and ImageNet top-1 performance.\nFinally, we report that the temporal evolution of the CORnet-S \"IT\" neural\npopulation resembles the actual monkey IT population dynamics. Taken together,\nthese results establish CORnet-S, a compact, recurrent ANN, as the current best\nmodel of the primate ventral visual stream.", "published": "2019-09-13T12:09:34Z", "version": 2}, {"aid": "1909.06236", "authors": ["Sohrab Ferdowsi", "Maurits Diephuis", "Shideh Rezaeifar", "Slava Voloshynovskiy"], "title": "$\u03c1$-VAE: Autoregressive parametrization of the VAE encoder", "url": "http://arxiv.org/pdf/1909.06236v1", "summary": "We make a minimal, but very effective alteration to the VAE model. This is\nabout a drop-in replacement for the (sample-dependent) approximate posterior to\nchange it from the standard white Gaussian with diagonal covariance to the\nfirst-order autoregressive Gaussian. We argue that this is a more reasonable\nchoice to adopt for natural signals like images, as it does not force the\nexisting correlation in the data to disappear in the posterior. Moreover, it\nallows more freedom for the approximate posterior to match the true posterior.\nThis allows for the repararametrization trick, as well as the KL-divergence\nterm to still have closed-form expressions, obviating the need for its\nsample-based estimation. Although providing more freedom to adapt to correlated\ndistributions, our parametrization has even less number of parameters than the\ndiagonal covariance, as it requires only two scalars, $\\rho$ and $s$, to\ncharacterize correlation and scaling, respectively. As validated by the\nexperiments, our proposition noticeably and consistently improves the quality\nof image generation in a plug-and-play manner, needing no further parameter\ntuning, and across all setups. The code to reproduce our experiments is\navailable at \\url{https://github.com/sssohrab/rho_VAE/}.", "published": "2019-09-13T14:01:33Z", "version": 1}, {"aid": "1909.06860", "authors": ["Alex Tong Lin", "Yonatan Dukler", "Wuchen Li", "Guido Montufar"], "title": "Wasserstein Diffusion Tikhonov Regularization", "url": "http://arxiv.org/pdf/1909.06860v1", "summary": "We propose regularization strategies for learning discriminative models that\nare robust to in-class variations of the input data. We use the Wasserstein-2\ngeometry to capture semantically meaningful neighborhoods in the space of\nimages, and define a corresponding input-dependent additive noise data\naugmentation model. Expanding and integrating the augmented loss yields an\neffective Tikhonov-type Wasserstein diffusion smoothness regularizer. This\napproach allows us to apply high levels of regularization and train functions\nthat have low variability within classes but remain flexible across classes. We\nprovide efficient methods for computing the regularizer at a negligible cost in\ncomparison to training with adversarial data augmentation. Initial experiments\ndemonstrate improvements in generalization performance under adversarial\nperturbations and also large in-class variations of the input data.", "published": "2019-09-15T19:10:16Z", "version": 1}, {"aid": "1909.06970", "authors": ["Alicia Montserrat Alvarado-Gonzalez", "Gibran Fuentes-Pineda", "Jorge Cervantes-Ojeda"], "title": "A few filters are enough: Convolutional Neural Network for P300 Detection", "url": "http://arxiv.org/pdf/1909.06970v3", "summary": "Over the past decade, convolutional neural networks (CNNs) have become the\ndriving force of an ever-increasing set of applications, achieving\nstate-of-the-art performance. Most of the modern CNN architectures are composed\nof many convolutional and fully connected layers and typically require\nthousands or millions of parameters to learn. CNNs have also been effective in\nthe detection of Event-Related Potentials from electroencephalogram (EEG)\nsignals, notably the P300 component which is frequently employed in\nBrain-Computer Interfaces (BCIs). However, for this task, the increase in\ndetection rates compared to approaches based on human-engineered features has\nnot been as impressive as in other areas and might not justify such a large\nnumber of parameters. In this paper, we study the performances of existing CNN\narchitectures with diverse complexities for single-trial within-subject and\ncross-subject P300 detection on four different datasets. We also proposed\nSepConv1D, a very simple CNN architecture consisting of a single depthwise\nseparable 1D convolutional layer followed by a fully connected Sigmoid\nclassification neuron. We found that with as few as four filters in its\nconvolutional layer and a small overall number of parameters, SepConv1D\nobtained competitive performances in the four datasets. We believe this may\nrepresent an important step towards building simpler, cheaper, faster, and more\nportable BCIs.", "published": "2019-09-16T03:48:28Z", "version": 3}, {"aid": "1909.07375", "authors": ["Keehang Kwon"], "title": "Extending and Automating Basic Probability Theory with Propositional Computability Logic", "url": "http://arxiv.org/pdf/1909.07375v3", "summary": "Classical probability theory is formulated using sets. In this paper, we\nextend classical probability theory with propositional computability logic.\nUnlike other formalisms, computability logic is built on the notion of\nevents/games, which is central to probability theory.\n  The probability theory based on CoL is therefore useful for {\\it automating}\nuncertainty reasoning. We describe some basic properties of this new\nprobability theory. We also discuss a novel isomorphism between the set\noperations and computability logic operations.", "published": "2019-09-16T04:51:19Z", "version": 3}, {"aid": "1909.07636", "authors": ["Gil Shomron", "Ron Banner", "Moran Shkolnik", "Uri Weiser"], "title": "Thanks for Nothing: Predicting Zero-Valued Activations with Lightweight Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1909.07636v3", "summary": "Convolutional neural networks (CNNs) introduce state-of-the-art results for\nvarious tasks with the price of high computational demands. Inspired by the\nobservation that spatial correlation exists in CNN output feature maps (ofms),\nwe propose a method to dynamically predict whether ofm activations are\nzero-valued or not according to their neighboring activation values, thereby\navoiding zero-valued activations and reducing the number of convolution\noperations. We implement the zero activation predictor (ZAP) with a lightweight\nCNN, which imposes negligible overheads and is easy to deploy on existing\nmodels. ZAPs are trained by mimicking hidden layer ouputs; thereby, enabling a\nparallel and label-free training. Furthermore, without retraining, each ZAP can\nbe tuned to a different operating point trading accuracy for MAC reduction.", "published": "2019-09-17T07:56:54Z", "version": 3}, {"aid": "1909.07932", "authors": ["Yujiang Wang", "Nishant Sinha", "Gabrielle M. Schroeder", "Sriharsha Ramaraju", "Andrew W. McEvoy", "Anna Miserocchi", "Jane de Tisi", "Fahmida A. Chowdhury", "Beate Diehl", "John S. Duncan", "Peter N. Taylor"], "title": "Interictal intracranial EEG for predicting surgical success: the importance of space and time", "url": "http://arxiv.org/pdf/1909.07932v1", "summary": "Predicting post-operative seizure freedom using functional correlation\nnetworks derived from interictal intracranial EEG has shown some success.\nHowever, there are important challenges to consider. 1: electrodes physically\ncloser to each other naturally tend to be more correlated causing a spatial\nbias. 2: implantation location and number of electrodes differ between\npatients, making cross-subject comparisons difficult. 3: functional correlation\nnetworks can vary over time but are currently assumed as static. In this study\nwe address these three substantial challenges using intracranial EEG data from\n55 patients with intractable focal epilepsy. Patients additionally underwent\npreoperative MR imaging, intra-operative CT, and post-operative MRI allowing\naccurate localisation of electrodes and delineation of removed tissue. We show\nthat normalising for spatial proximity between nearby electrodes improves\nprediction of post-surgery seizure outcomes. Moreover, patients with more\nextensive electrode coverage were more likely to have their outcome predicted\ncorrectly (ROC-AUC >0.9, p<<0.05), but not necessarily more likely to have a\nbetter outcome. Finally, our predictions are robust regardless of the time\nsegment. Future studies should account for the spatial proximity of electrodes\nin functional network construction to improve prediction of post-surgical\nseizure outcomes. Greater coverage of both removed and spared tissue allows for\npredictions with higher accuracy.", "published": "2019-09-17T17:00:18Z", "version": 1}, {"aid": "1909.08097", "authors": ["Umar Asif", "Jianbin Tang", "Stefan Harrer"], "title": "Ensemble Knowledge Distillation for Learning Improved and Efficient Networks", "url": "http://arxiv.org/pdf/1909.08097v3", "summary": "Ensemble models comprising of deep Convolutional Neural Networks (CNN) have\nshown significant improvements in model generalization but at the cost of large\ncomputation and memory requirements. In this paper, we present a framework for\nlearning compact CNN models with improved classification performance and model\ngeneralization. For this, we propose a CNN architecture of a compact student\nmodel with parallel branches which are trained using ground truth labels and\ninformation from high capacity teacher networks in an ensemble learning\nfashion. Our framework provides two main benefits: i) Distilling knowledge from\ndifferent teachers into the student network promotes heterogeneity in feature\nlearning at different branches of the student network and enables the network\nto learn diverse solutions to the target problem. ii) Coupling the branches of\nthe student network through ensembling encourages collaboration and improves\nthe quality of the final predictions by reducing variance in the network\noutputs. Experiments on the well established CIFAR-10 and CIFAR-100 datasets\nshow that our Ensemble Knowledge Distillation (EKD) improves classification\naccuracy and model generalization especially in situations with limited\ntraining data. Experiments also show that our EKD based compact networks\noutperform in terms of mean accuracy on the test datasets compared to\nstate-of-the-art knowledge distillation based methods.", "published": "2019-09-17T21:03:19Z", "version": 3}, {"aid": "1909.08250", "authors": ["Van Duc Nguyen", "Tran Cao Son", "Enrico Pontelli"], "title": "Natural Language Generation for Non-Expert Users", "url": "http://arxiv.org/pdf/1909.08250v1", "summary": "Motivated by the difficulty in presenting computational results, especially\nwhen the results are a collection of atoms in a logical language, to users, who\nare not proficient in computer programming and/or the logical representation of\nthe results, we propose a system for automatic generation of natural language\ndescriptions for applications targeting mainstream users. Differently from many\nearlier systems with the same aim, the proposed system does not employ\ntemplates for the generation task. It assumes that there exist some natural\nlanguage sentences in the application domain and uses this repository for the\nnatural language description. It does not require, however, a large corpus as\nit is often required in machine learning approaches. The systems consist of two\nmain components. The first one aims at analyzing the sentences and constructs a\nGrammatical Framework (GF) for given sentences and is implemented using the\nStanford parser and an answer set program. The second component is for sentence\nconstruction and relies on GF Library. The paper includes two use cases to\ndemostrate the capability of the system. As the sentence construction is done\nvia GF, the paper includes a use case evaluation showing that the proposed\nsystem could also be utilized in addressing a challenge to create an abstract\nWikipedia, which is recently discussed in the BlueSky session of the 2018\nInternational Semantic Web Conference.", "published": "2019-09-18T07:09:07Z", "version": 1}, {"aid": "1909.08341", "authors": ["Shao-Qun Zhang", "Zhao-Yu Zhang", "Zhi-Hua Zhou"], "title": "Bifurcation Spiking Neural Network", "url": "http://arxiv.org/pdf/1909.08341v3", "summary": "Spiking neural networks (SNNs) has attracted much attention due to its great\npotential of modeling time-dependent signals. The firing rate of spiking\nneurons is decided by control rate which is fixed manually in advance, and\nthus, whether the firing rate is adequate for modeling actual time series\nrelies on fortune. Though it is demanded to have an adaptive control rate, it\nis a non-trivial task because the control rate and the connection weights\nlearned during the training process are usually entangled. In this paper, we\nshow that the firing rate is related to the eigenvalue of the spike generation\nfunction. Inspired by this insight, by enabling the spike generation function\nto have adaptable eigenvalues rather than parametric control rates, we develop\nthe Bifurcation Spiking Neural Network (BSNN), which has an adaptive firing\nrate and is insensitive to the setting of control rates. Experiments validate\nthe effectiveness of BSNN on a broad range of tasks, showing that BSNN achieves\nsuperior performance to existing SNNs and is robust to the setting of control\nrates.", "published": "2019-09-18T10:34:59Z", "version": 3}, {"aid": "1909.09278", "authors": ["Harshala Gammulle", "Simon Denman", "Sridha Sridharan", "Clinton Fookes"], "title": "Forecasting Future Action Sequences with Neural Memory Networks", "url": "http://arxiv.org/pdf/1909.09278v1", "summary": "We propose a novel neural memory network based framework for future action\nsequence forecasting. This is a challenging task where we have to consider\nshort-term, within sequence relationships as well as relationships in between\nsequences, to understand how sequences of actions evolve over time. To capture\nthese relationships effectively, we introduce neural memory networks to our\nmodelling scheme. We show the significance of using two input streams, the\nobserved frames and the corresponding action labels, which provide different\ninformation cues for our prediction task. Furthermore, through the proposed\nmethod we effectively map the long-term relationships among individual input\nsequences through separate memory modules, which enables better fusion of the\nsalient features. Our method outperforms the state-of-the-art approaches by a\nlarge margin on two publicly available datasets: Breakfast and 50 Salads.", "published": "2019-09-20T01:04:38Z", "version": 1}, {"aid": "1909.09349", "authors": ["Juan Luis Gonzalez Bello", "Munchurl Kim"], "title": "Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom", "url": "http://arxiv.org/pdf/1909.09349v2", "summary": "The 3D-zoom operation is the positive translation of the camera in the\nZ-axis, perpendicular to the image plane. In contrast, the optical zoom changes\nthe focal length and the digital zoom is used to enlarge a certain region of an\nimage to the original image size. In this paper, we are the first to formulate\nan unsupervised 3D-zoom learning problem where images with an arbitrary zoom\nfactor can be generated from a given single image. An unsupervised framework is\nconvenient, as it is a challenging task to obtain a 3D-zoom dataset of natural\nscenes due to the need for special equipment to ensure camera movement is\nrestricted to the Z-axis. In addition, the objects in the scenes should not\nmove when being captured, which hinders the construction of a large dataset of\noutdoor scenes. We present a novel unsupervised framework to learn how to\ngenerate arbitrarily 3D-zoomed versions of a single image, not requiring a\n3D-zoom ground truth, called the Deep 3D-Zoom Net. The Deep 3D-Zoom Net\nincorporates the following features: (i) transfer learning from a pre-trained\ndisparity estimation network via a back re-projection reconstruction loss; (ii)\na fully convolutional network architecture that models depth-image-based\nrendering (DIBR), taking into account high-frequency details without the need\nfor estimating the intermediate disparity; and (iii) incorporating a\ndiscriminator network that acts as a no-reference penalty for unnaturally\nrendered areas. Even though there is no baseline to fairly compare our results,\nour method outperforms previous novel view synthesis research in terms of\nrealistic appearance on large camera baselines. We performed extensive\nexperiments to verify the effectiveness of our method on the KITTI and\nCityscapes datasets.", "published": "2019-09-20T07:18:39Z", "version": 2}, {"aid": "1909.09629", "authors": ["Andreas Lugmayr", "Martin Danelljan", "Radu Timofte"], "title": "Unsupervised Learning for Real-World Super-Resolution", "url": "http://arxiv.org/pdf/1909.09629v1", "summary": "Most current super-resolution methods rely on low and high resolution image\npairs to train a network in a fully supervised manner. However, such image\npairs are not available in real-world applications. Instead of directly\naddressing this problem, most works employ the popular bicubic downsampling\nstrategy to artificially generate a corresponding low resolution image.\nUnfortunately, this strategy introduces significant artifacts, removing natural\nsensor noise and other real-world characteristics. Super-resolution networks\ntrained on such bicubic images therefore struggle to generalize to natural\nimages. In this work, we propose an unsupervised approach for image\nsuper-resolution. Given only unpaired data, we learn to invert the effects of\nbicubic downsampling in order to restore the natural image characteristics\npresent in the data. This allows us to generate realistic image pairs,\nfaithfully reflecting the distribution of real-world images. Our\nsuper-resolution network can therefore be trained with direct pixel-wise\nsupervision in the high resolution domain, while robustly generalizing to real\ninput. We demonstrate the effectiveness of our approach in quantitative and\nqualitative experiments.", "published": "2019-09-20T17:37:55Z", "version": 1}, {"aid": "1909.09706", "authors": ["Hassan Hafez-Kolahi", "Shohreh Kasaei", "Mahdiyeh Soleymani-Baghshah"], "title": "Do Compressed Representations Generalize Better?", "url": "http://arxiv.org/pdf/1909.09706v2", "summary": "One of the most studied problems in machine learning is finding reasonable\nconstraints that guarantee the generalization of a learning algorithm. These\nconstraints are usually expressed as some simplicity assumptions on the target.\nFor instance, in the Vapnik-Chervonenkis (VC) theory the space of possible\nhypotheses is considered to have a limited VC dimension. In this paper, the\nconstraint on the entropy $H(X)$ of the input variable $X$ is studied as a\nsimplicity assumption. It is proven that the sample complexity to achieve an\n$\\epsilon$-$\\delta$ Probably Approximately Correct (PAC) hypothesis is bounded\nby $\\frac{2^{\n\\left.6H(X)\\middle/\\epsilon\\right.}+\\log{\\frac{1}{\\delta}}}{\\epsilon^2}$ which\nis sharp up to the $\\frac{1}{\\epsilon^2}$ factor. Morever, it is shown that if\na feature learning process is employed to learn the compressed representation\nfrom the dataset, this bound no longer exists. These findings have important\nimplications on the Information Bottleneck (IB) theory which had been utilized\nto explain the generalization power of Deep Neural Networks (DNNs), but its\napplicability for this purpose is currently under debate by researchers. In\nparticular, this is a rigorous proof for the previous heuristic that compressed\nrepresentations are exponentially easier to be learned. However, our analysis\npinpoints two factors preventing the IB, in its current form, to be applicable\nin studying neural networks. Firstly, the exponential dependence of sample\ncomplexity on $\\frac{1}{\\epsilon}$, which can lead to a dramatic effect on the\nbounds in practical applications when $\\epsilon$ is small. Secondly, our\nanalysis reveals that arguments based on input compression are inherently\ninsufficient to explain generalization of methods like DNNs in which the\nfeatures are also learned using available data.", "published": "2019-09-20T19:54:42Z", "version": 2}, {"aid": "1909.09785", "authors": ["Hunter Lang", "Pengchuan Zhang", "Lin Xiao"], "title": "Using Statistics to Automate Stochastic Optimization", "url": "http://arxiv.org/pdf/1909.09785v1", "summary": "Despite the development of numerous adaptive optimizers, tuning the learning\nrate of stochastic gradient methods remains a major roadblock to obtaining good\npractical performance in machine learning. Rather than changing the learning\nrate at each iteration, we propose an approach that automates the most common\nhand-tuning heuristic: use a constant learning rate until \"progress stops,\"\nthen drop. We design an explicit statistical test that determines when the\ndynamics of stochastic gradient descent reach a stationary distribution. This\ntest can be performed easily during training, and when it fires, we decrease\nthe learning rate by a constant multiplicative factor. Our experiments on\nseveral deep learning tasks demonstrate that this statistical adaptive\nstochastic approximation (SASA) method can automatically find good learning\nrate schedules and match the performance of hand-tuned methods using default\nsettings of its parameters. The statistical testing helps to control the\nvariance of this procedure and improves its robustness.", "published": "2019-09-21T07:27:48Z", "version": 1}, {"aid": "1909.09801", "authors": ["Saypraseuth Mounsaveng", "David Vazquez", "Ismail Ben Ayed", "Marco Pedersoli"], "title": "Adversarial Learning of General Transformations for Data Augmentation", "url": "http://arxiv.org/pdf/1909.09801v1", "summary": "Data augmentation (DA) is fundamental against overfitting in large\nconvolutional neural networks, especially with a limited training dataset. In\nimages, DA is usually based on heuristic transformations, like geometric or\ncolor transformations. Instead of using predefined transformations, our work\nlearns data augmentation directly from the training data by learning to\ntransform images with an encoder-decoder architecture combined with a spatial\ntransformer network. The transformed images still belong to the same class but\nare new, more complex samples for the classifier. Our experiments show that our\napproach is better than previous generative data augmentation methods, and\ncomparable to predefined transformation methods when training an image\nclassifier.", "published": "2019-09-21T09:43:24Z", "version": 1}, {"aid": "1909.09934", "authors": ["Bohan Zhuang", "Chunhua Shen", "Mingkui Tan", "Peng Chen", "Lingqiao Liu", "Ian Reid"], "title": "Structured Binary Neural Networks for Image Recognition", "url": "http://arxiv.org/pdf/1909.09934v4", "summary": "We propose methods to train convolutional neural networks (CNNs) with both\nbinarized weights and activations, leading to quantized models that are\nspecifically friendly to mobile devices with limited power capacity and\ncomputation resources. Previous works on quantizing CNNs often seek to\napproximate the floating-point information using a set of discrete values,\nwhich we call value approximation, typically assuming the same architecture as\nthe full-precision networks. Here we take a novel \"structure approximation\"\nview of quantization -- it is very likely that different architectures designed\nfor low-bit networks may be better for achieving good performance. In\nparticular, we propose a \"network decomposition\" strategy, termed Group-Net, in\nwhich we divide the network into groups. Thus, each full-precision group can be\neffectively reconstructed by aggregating a set of homogeneous binary branches.\nIn addition, we learn effective connections among groups to improve the\nrepresentation capability. Moreover, the proposed Group-Net shows strong\ngeneralization to other tasks. For instance, we extend Group-Net for accurate\nsemantic segmentation by embedding rich context into the binary structure.\nFurthermore, for the first time, we apply binary neural networks to object\ndetection. Experiments on both classification, semantic segmentation and object\ndetection tasks demonstrate the superior performance of the proposed methods\nover various quantized networks in the literature. Our methods outperform the\nprevious best binary neural networks in terms of accuracy and computation\nefficiency.", "published": "2019-09-22T03:45:49Z", "version": 4}, {"aid": "1909.10007", "authors": ["Tilo Schwalger", "Anton V. Chizhov"], "title": "Mind the Last Spike -- Firing Rate Models for Mesoscopic Populations of Spiking Neurons", "url": "http://arxiv.org/pdf/1909.10007v1", "summary": "The dominant modeling framework for understanding cortical computations are\nheuristic firing rate models. Despite their success, these models fall short to\ncapture spike synchronization effects, to link to biophysical parameters and to\ndescribe finite-size fluctuations. In this opinion article, we propose that the\nrefractory density method (RDM), also known as age-structured population\ndynamics or quasi-renewal theory, yields a powerful theoretical framework to\nbuild rate-based models for mesoscopic neural populations from realistic neuron\ndynamics at the microscopic level. We review recent advances achieved by the\nRDM to obtain efficient population density equations for networks of\ngeneralized integrate-and-fire (GIF) neurons -- a class of neuron models that\nhas been successfully fitted to various cell types. The theory not only\npredicts the nonstationary dynamics of large populations of neurons but also\npermits an extension to finite-size populations and a systematic reduction to\nlow-dimensional rate dynamics. The new types of rate models will allow a\nre-examination of models of cortical computations under biological constraints.", "published": "2019-09-22T13:57:44Z", "version": 1}, {"aid": "1909.10300", "authors": ["J\u00e9r\u00f4me Bolte", "Edouard Pauwels"], "title": "Conservative set valued fields, automatic differentiation, stochastic gradient method and deep learning", "url": "http://arxiv.org/pdf/1909.10300v4", "summary": "Modern problems in AI or in numerical analysis require nonsmooth approaches\nwith a flexible calculus. We introduce generalized derivatives called\nconservative fields for which we develop a calculus and provide representation\nformulas. Functions having a conservative field are called path differentiable:\nconvex, concave, Clarke regular and any semialgebraic Lipschitz continuous\nfunctions are path differentiable. Using Whitney stratification techniques for\nsemialgebraic and definable sets, our model provides variational formulas for\nnonsmooth automatic differentiation oracles, as for instance the famous\nbackpropagation algorithm in deep learning. Our differential model is applied\nto establish the convergence in values of nonsmooth stochastic gradient methods\nas they are implemented in practice.", "published": "2019-09-23T11:39:16Z", "version": 4}, {"aid": "1909.10340", "authors": ["Gideon Kowadlo", "Abdelrahman Ahmed", "David Rawlinson"], "title": "AHA! an 'Artificial Hippocampal Algorithm' for Episodic Machine Learning", "url": "http://arxiv.org/pdf/1909.10340v5", "summary": "The majority of ML research concerns slow, statistical learning of i.i.d.\nsamples from large, labelled datasets. Animals do not learn this way. An\nenviable characteristic of animal learning is `episodic' learning - the ability\nto memorise a specific experience as a composition of existing concepts, after\njust one experience, without provided labels. The new knowledge can then be\nused to distinguish between similar experiences, to generalise between classes,\nand to selectively consolidate to long-term memory. The Hippocampus is known to\nbe vital to these abilities. AHA is a biologically-plausible computational\nmodel of the Hippocampus. Unlike most machine learning models, AHA is trained\nwithout external labels and uses only local credit assignment. We demonstrate\nAHA in a superset of the Omniglot one-shot classification benchmark. The\nextended benchmark covers a wider range of known hippocampal functions by\ntesting pattern separation, completion, and recall of original input. These\nfunctions are all performed within a single configuration of the computational\nmodel. Despite these constraints, image classification results are comparable\nto conventional deep convolutional ANNs.", "published": "2019-09-23T12:49:47Z", "version": 5}, {"aid": "1909.11483", "authors": ["Jordan Ott", "Erik Linstead", "Nicholas LaHaye", "Pierre Baldi"], "title": "Learning in the Machine: To Share or Not to Share?", "url": "http://arxiv.org/pdf/1909.11483v2", "summary": "Weight-sharing is one of the pillars behind Convolutional Neural Networks and\ntheir successes. However, in physical neural systems such as the brain,\nweight-sharing is implausible. This discrepancy raises the fundamental question\nof whether weight-sharing is necessary. If so, to which degree of precision? If\nnot, what are the alternatives? The goal of this study is to investigate these\nquestions, primarily through simulations where the weight-sharing assumption is\nrelaxed. Taking inspiration from neural circuitry, we explore the use of Free\nConvolutional Networks and neurons with variable connection patterns. Using\nFree Convolutional Networks, we show that while weight-sharing is a pragmatic\noptimization approach, it is not a necessity in computer vision applications.\nFurthermore, Free Convolutional Networks match the performance observed in\nstandard architectures when trained using properly translated data (akin to\nvideo). Under the assumption of translationally augmented data, Free\nConvolutional Networks learn translationally invariant representations that\nyield an approximate form of weight sharing.", "published": "2019-09-23T20:10:50Z", "version": 2}, {"aid": "1909.10702", "authors": ["Nitish Bahadur", "Randy Paffenroth"], "title": "Dimension Estimation Using Autoencoders", "url": "http://arxiv.org/pdf/1909.10702v1", "summary": "Dimension Estimation (DE) and Dimension Reduction (DR) are two closely\nrelated topics, but with quite different goals. In DE, one attempts to estimate\nthe intrinsic dimensionality or number of latent variables in a set of\nmeasurements of a random vector. However, in DR, one attempts to project a\nrandom vector, either linearly or non-linearly, to a lower dimensional space\nthat preserves the information contained in the original higher dimensional\nspace. Of course, these two ideas are quite closely linked since, for example,\ndoing DR to a dimension smaller than suggested by DE will likely lead to\ninformation loss. Accordingly, in this paper we will focus on a particular\nclass of deep neural networks called autoencoders which are used extensively\nfor DR but are less well studied for DE. We show that several important\nquestions arise when using autoencoders for DE, above and beyond those that\narise for more classic DR/DE techniques such as Principal Component Analysis.\nWe address autoencoder architectural choices and regularization techniques that\nallow one to transform autoencoder latent layer representations into estimates\nof intrinsic dimension.", "published": "2019-09-24T04:09:48Z", "version": 1}, {"aid": "1909.10819", "authors": ["Risheng Liu", "Pan Mu", "Jin Zhang"], "title": "Investigating Customization Strategies and Convergence Behaviors of Task-specific ADMM", "url": "http://arxiv.org/pdf/1909.10819v2", "summary": "Alternating Direction Method of Multiplier (ADMM) has been a popular\nalgorithmic framework for separable optimization problems with linear\nconstraints. For numerical ADMM fail to exploit the particular structure of the\nproblem at hand nor the input data information, leveraging task-specific\nmodules (e.g., neural networks and other data-driven architectures) to extend\nADMM is a significant but challenging task. This work focuses on designing a\nflexible algorithmic framework to incorporate various task-specific modules\n(with no additional constraints) to improve the performance of ADMM in\nreal-world applications. Specifically, we propose Guidance from Optimality\n(GO), a new customization strategy, to embed task-specific modules into ADMM\n(GO-ADMM). By introducing an optimality-based criterion to guide the\npropagation, GO-ADMM establishes an updating scheme agnostic to the choice of\nadditional modules. The existing task-specific methods just plug their\ntask-specific modules into the numerical iterations in a straightforward\nmanner. Even with some restrictive constraints on the plug-in modules, they can\nonly obtain some relatively weaker convergence properties for the resulted ADMM\niterations. Fortunately, without any restrictions on the embedded modules, we\nprove the convergence of GO-ADMM regarding objective values and constraint\nviolations, and derive the worst-case convergence rate measured by iteration\ncomplexity. Extensive experiments are conducted to verify the theoretical\nresults and demonstrate the efficiency of GO-ADMM.", "published": "2019-09-24T11:29:13Z", "version": 2}, {"aid": "1909.10893", "authors": ["Anirudh Goyal", "Alex Lamb", "Jordan Hoffmann", "Shagun Sodhani", "Sergey Levine", "Yoshua Bengio", "Bernhard Sch\u00f6lkopf"], "title": "Recurrent Independent Mechanisms", "url": "http://arxiv.org/pdf/1909.10893v6", "summary": "Learning modular structures which reflect the dynamics of the environment can\nlead to better generalization and robustness to changes which only affect a few\nof the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a\nnew recurrent architecture in which multiple groups of recurrent cells operate\nwith nearly independent transition dynamics, communicate only sparingly through\nthe bottleneck of attention, and are only updated at time steps where they are\nmost relevant. We show that this leads to specialization amongst the RIMs,\nwhich in turn allows for dramatically improved generalization on tasks where\nsome factors of variation differ systematically between training and\nevaluation.", "published": "2019-09-24T13:28:00Z", "version": 6}, {"aid": "1909.11145", "authors": ["Timo C. Wunderlich", "Akos F. Kungl", "Eric M\u00fcller", "Johannes Schemmel", "Mihai Petrovici"], "title": "Brain-Inspired Hardware for Artificial Intelligence: Accelerated Learning in a Physical-Model Spiking Neural Network", "url": "http://arxiv.org/pdf/1909.11145v2", "summary": "Future developments in artificial intelligence will profit from the existence\nof novel, non-traditional substrates for brain-inspired computing. Neuromorphic\ncomputers aim to provide such a substrate that reproduces the brain's\ncapabilities in terms of adaptive, low-power information processing. We present\nresults from a prototype chip of the BrainScaleS-2 mixed-signal neuromorphic\nsystem that adopts a physical-model approach with a 1000-fold acceleration of\nspiking neural network dynamics relative to biological real time. Using the\nembedded plasticity processor, we both simulate the Pong arcade video game and\nimplement a local plasticity rule that enables reinforcement learning, allowing\nthe on-chip neural network to learn to play the game. The experiment\ndemonstrates key aspects of the employed approach, such as accelerated and\nflexible learning, high energy efficiency and resilience to noise.", "published": "2019-09-24T19:29:30Z", "version": 2}, {"aid": "1910.02020", "authors": ["Himanshu Goyal", "Pramit Saha", "Bryan Gick", "Sidney Fels"], "title": "EEG-to-F0: Establishing artificial neuro-muscular pathway for kinematics-based fundamental frequency control", "url": "http://arxiv.org/pdf/1910.02020v1", "summary": "The fundamental frequency (F0) of human voice is generally controlled by\nchanging the vocal fold parameters (including tension, length and mass), which\nin turn is manipulated by the muscle exciters, activated by the neural\nsynergies. In order to begin investigating the neuromuscular F0 control\npathway, we simulate a simple biomechanical arm prototype (instead of an\nartificial vocal tract) that tends to control F0 of an artificial sound\nsynthesiser based on the elbow movements. The intended arm movements are\ndecoded from the EEG signal inputs (collected simultaneously with the kinematic\nhand data of the participant) through a combined machine learning and\nbiomechanical modeling strategy. The machine learning model is employed to\nidentify the muscle activation of a single-muscle arm model in ArtiSynth (from\ninput brain signal), in order to match the actual kinematic (elbow joint angle)\ndata . The biomechanical model utilises this estimated muscle excitation to\nproduce corresponding changes in elbow angle, which is then linearly mapped to\nF0 of a vocal sound synthesiser. We use the F0 value mapped from the actual\nkinematic hand data (via same function) as the ground truth and compare the F0\nestimated from brain signal. A detailed qualitative and quantitative\nperformance comparison shows that the proposed neuromuscular pathway can indeed\nbe utilised to accurately control the vocal fundamental frequency, thereby\ndemonstrating the success of our closed loop neuro-biomechanical control\nscheme.", "published": "2019-09-25T02:49:12Z", "version": 1}, {"aid": "1909.11286", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "title": "Stochastic Conditional Generative Networks with Basis Decomposition", "url": "http://arxiv.org/pdf/1909.11286v2", "summary": "While generative adversarial networks (GANs) have revolutionized machine\nlearning, a number of open questions remain to fully understand them and\nexploit their power. One of these questions is how to efficiently achieve\nproper diversity and sampling of the multi-mode data space. To address this, we\nintroduce BasisGAN, a stochastic conditional multi-mode image generator. By\nexploiting the observation that a convolutional filter can be well approximated\nas a linear combination of a small set of basis elements, we learn a\nplug-and-played basis generator to stochastically generate basis elements, with\njust a few hundred of parameters, to fully embed stochasticity into\nconvolutional filters. By sampling basis elements instead of filters, we\ndramatically reduce the cost of modeling the parameter space with no sacrifice\non either image diversity or fidelity. To illustrate this proposed\nplug-and-play framework, we construct variants of BasisGAN based on\nstate-of-the-art conditional image generation networks, and train the networks\nby simply plugging in a basis generator, without additional auxiliary\ncomponents, hyperparameters, or training objectives. The experimental success\nis complemented with theoretical results indicating how the perturbations\nintroduced by the proposed sampling of basis elements can propagate to the\nappearance of generated images.", "published": "2019-09-25T04:37:38Z", "version": 2}, {"aid": "1909.11321", "authors": ["Jun-Gi Jang", "Chun Quan", "Hyun Dong Lee", "U Kang"], "title": "FALCON: Lightweight and Accurate Convolution", "url": "http://arxiv.org/pdf/1909.11321v2", "summary": "How can we efficiently compress Convolutional Neural Network (CNN) while\nretaining their accuracy on classification tasks? Depthwise Separable\nConvolution (DSConv), which replaces a standard convolution with a depthwise\nconvolution and a pointwise convolution, has been used for building lightweight\narchitectures. However, previous works based on depthwise separable convolution\nare limited when compressing a trained CNN model since 1) they are mostly\nheuristic approaches without a precise understanding of their relations to\nstandard convolution, and 2) their accuracies do not match that of the standard\nconvolution. In this paper, we propose FALCON, an accurate and lightweight\nmethod to compress CNN. FALCON uses GEP, our proposed mathematical formulation\nto approximate the standard convolution kernel, to interpret existing\nconvolution methods based on depthwise separable convolution. By exploiting the\nknowledge of a trained standard model and carefully determining the order of\ndepthwise separable convolution via GEP, FALCON achieves sufficient accuracy\nclose to that of the trained standard model. Furthermore, this interpretation\nleads to developing a generalized version rank-k FALCON which performs k\nindependent FALCON operations and sums up the result. Experiments show that\nFALCON 1) provides higher accuracy than existing methods based on depthwise\nseparable convolution and tensor decomposition, and 2) reduces the number of\nparameters and FLOPs of standard convolution by up to a factor of 8 while\nensuring similar accuracy. We also demonstrate that rank-k FALCON further\nimproves the accuracy while sacrificing a bit of compression and computation\nreduction rates.", "published": "2019-09-25T07:48:31Z", "version": 2}, {"aid": "1909.11825", "authors": ["Yu Sun", "Eric Tzeng", "Trevor Darrell", "Alexei A. Efros"], "title": "Unsupervised Domain Adaptation through Self-Supervision", "url": "http://arxiv.org/pdf/1909.11825v2", "summary": "This paper addresses unsupervised domain adaptation, the setting where\nlabeled training data is available on a source domain, but the goal is to have\ngood performance on a target domain with only unlabeled data. Like much of\nprevious work, we seek to align the learned representations of the source and\ntarget domains while preserving discriminability. The way we accomplish\nalignment is by learning to perform auxiliary self-supervised task(s) on both\ndomains simultaneously. Each self-supervised task brings the two domains closer\ntogether along the direction relevant to that task. Training this jointly with\nthe main task classifier on the source domain is shown to successfully\ngeneralize to the unlabeled target domain. The presented objective is\nstraightforward to implement and easy to optimize. We achieve state-of-the-art\nresults on four out of seven standard benchmarks, and competitive results on\nsegmentation adaptation. We also demonstrate that our method composes well with\nanother popular pixel-level adaptation method.", "published": "2019-09-26T00:21:16Z", "version": 2}, {"aid": "1909.11851", "authors": ["Dennis Lee", "Christian Szegedy", "Markus N. Rabe", "Sarah M. Loos", "Kshitij Bansal"], "title": "Mathematical Reasoning in Latent Space", "url": "http://arxiv.org/pdf/1909.11851v1", "summary": "We design and conduct a simple experiment to study whether neural networks\ncan perform several steps of approximate reasoning in a fixed dimensional\nlatent space. The set of rewrites (i.e. transformations) that can be\nsuccessfully performed on a statement represents essential semantic features of\nthe statement. We can compress this information by embedding the formula in a\nvector space, such that the vector associated with a statement can be used to\npredict whether a statement can be rewritten by other theorems. Predicting the\nembedding of a formula generated by some rewrite rule is naturally viewed as\napproximate reasoning in the latent space. In order to measure the\neffectiveness of this reasoning, we perform approximate deduction sequences in\nthe latent space and use the resulting embedding to inform the semantic\nfeatures of the corresponding formal statement (which is obtained by performing\nthe corresponding rewrite sequence using real formulas). Our experiments show\nthat graph neural networks can make non-trivial predictions about the\nrewrite-success of statements, even when they propagate predicted latent\nrepresentations for several steps. Since our corpus of mathematical formulas\nincludes a wide variety of mathematical disciplines, this experiment is a\nstrong indicator for the feasibility of deduction in latent space in general.", "published": "2019-09-26T02:33:07Z", "version": 1}, {"aid": "1909.11862", "authors": ["Yi Wang", "Zhen-Peng Bian", "Junhui Hou", "Lap-Pui Chau"], "title": "Convolutional Neural Networks with Dynamic Regularization", "url": "http://arxiv.org/pdf/1909.11862v3", "summary": "Regularization is commonly used for alleviating overfitting in machine\nlearning. For convolutional neural networks (CNNs), regularization methods,\nsuch as DropBlock and Shake-Shake, have illustrated the improvement in the\ngeneralization performance. However, these methods lack a self-adaptive ability\nthroughout training. That is, the regularization strength is fixed to a\npredefined schedule, and manual adjustments are required to adapt to various\nnetwork architectures. In this paper, we propose a dynamic regularization\nmethod for CNNs. Specifically, we model the regularization strength as a\nfunction of the training loss. According to the change of the training loss,\nour method can dynamically adjust the regularization strength in the training\nprocedure, thereby balancing the underfitting and overfitting of CNNs. With\ndynamic regularization, a large-scale model is automatically regularized by the\nstrong perturbation, and vice versa. Experimental results show that the\nproposed method can improve the generalization capability on off-the-shelf\nnetwork architectures and outperform state-of-the-art regularization methods.", "published": "2019-09-26T03:06:49Z", "version": 3}, {"aid": "1909.11926", "authors": ["Guilin Li", "Xing Zhang", "Zitong Wang", "Matthias Tan", "Jiashi Feng", "Zhenguo Li", "Tong Zhang"], "title": "Hierarchical Neural Architecture Search via Operator Clustering", "url": "http://arxiv.org/pdf/1909.11926v5", "summary": "Recently, the efficiency of automatic neural architecture design has been\nsignificantly improved by gradient-based search methods such as DARTS. However,\nrecent literature has brought doubt to the generalization ability of DARTS,\narguing that DARTS performs poorly when the search space is changed, i.e, when\ndifferent set of candidate operators are used. Regularization techniques such\nas early stopping have been proposed to partially solve this problem. In this\npaper, we tackle this problem from a different perspective by identifying two\ncontributing factors to the collapse of DARTS when the search space changes:\n(1) the correlation of similar operators incurs unfavorable competition among\nthem and makes their relative importance score unreliable and (2) the\noptimization complexity gap between the proxy search stage and the final\ntraining. Based on these findings, we propose a new hierarchical search\nalgorithm. With its operator clustering and optimization complexity match, the\nalgorithm can consistently find high-performance architecture across various\nsearch spaces. For all the five variants of the popular cell-based search\nspaces, the proposed algorithm always obtains state-of-the-art architecture\nwith best accuracy on the CIFAR-10, CIFAR-100 and ImageNet over other\nwell-established DARTS-alike algorithms. Code is available at\nhttps://github.com/susan0199/StacNAS.", "published": "2019-09-26T06:26:58Z", "version": 5}, {"aid": "1909.11932", "authors": ["Md Sazzad Hossain", "Andrew P Paplinski", "John M Betts"], "title": "Adaptive Class Weight based Dual Focal Loss for Improved Semantic Segmentation", "url": "http://arxiv.org/pdf/1909.11932v3", "summary": "In this paper, we propose a Dual Focal Loss (DFL) function, as a replacement\nfor the standard cross entropy (CE) function to achieve a better treatment of\nthe unbalanced classes in a dataset. Our DFL method is an improvement on the\nrecently reported Focal Loss (FL) cross-entropy function, which proposes a\nscaling method that puts more weight on the examples that are difficult to\nclassify over those that are easy. However, the scaling parameter of FL is\nempirically set, which is problem-dependent. In addition, like other CE\nvariants, FL only focuses on the loss of true classes. Therefore, no loss\nfeedback is gained from the false classes. Although focusing only on true\nexamples increases probability on true classes and correspondingly reduces\nprobability on false classes due to the nature of the softmax function, it does\nnot achieve the best convergence due to avoidance of the loss on false classes.\nOur DFL method improves on the simple FL in two ways. Firstly, it takes the\nidea of FL to focus more on difficult examples than the easy ones, but\nevaluates loss on both true and negative classes with equal importance.\nSecondly, the scaling parameter of DFL has been made learnable so that it can\ntune itself by backpropagation rather than being dependent on manual tuning. In\nthis way, our proposed DFL method offers an auto-tunable loss function that can\nreduce the class imbalance effect as well as put more focus on both true\ndifficult examples and negative easy examples.", "published": "2019-09-26T06:36:21Z", "version": 3}, {"aid": "1910.13351", "authors": ["Donald C. Wunsch"], "title": "Admiring the Great Mountain: A Celebration Special Issue in Honor of Stephen Grossbergs 80th Birthday", "url": "http://arxiv.org/pdf/1910.13351v1", "summary": "This editorial summarizes selected key contributions of Prof. Stephen\nGrossberg and describes the papers in this 80th birthday special issue in his\nhonor. His productivity, creativity, and vision would each be enough to mark a\nscientist of the first caliber. In combination, they have resulted in\ncontributions that have changed the entire discipline of neural networks.\nGrossberg has been tremendously influential in engineering, dynamical systems,\nand artificial intelligence as well. Indeed, he has been one of the most\nimportant mentors and role models in my career, and has done so with\nextraordinary generosity and encouragement. All authors in this special issue\nhave taken great pleasure in hereby commemorating his extraordinary career and\ncontributions.", "published": "2019-09-26T09:17:01Z", "version": 1}, {"aid": "1909.12579", "authors": ["Yulong Wang", "Xiaolu Zhang", "Lingxi Xie", "Jun Zhou", "Hang Su", "Bo Zhang", "Xiaolin Hu"], "title": "Pruning from Scratch", "url": "http://arxiv.org/pdf/1909.12579v1", "summary": "Network pruning is an important research field aiming at reducing\ncomputational costs of neural networks. Conventional approaches follow a fixed\nparadigm which first trains a large and redundant network, and then determines\nwhich units (e.g., channels) are less important and thus can be removed. In\nthis work, we find that pre-training an over-parameterized model is not\nnecessary for obtaining the target pruned structure. In fact, a fully-trained\nover-parameterized model will reduce the search space for the pruned structure.\nWe empirically show that more diverse pruned structures can be directly pruned\nfrom randomly initialized weights, including potential models with better\nperformance. Therefore, we propose a novel network pruning pipeline which\nallows pruning from scratch. In the experiments for compressing classification\nmodels on CIFAR10 and ImageNet datasets, our approach not only greatly reduces\nthe pre-training burden of traditional pruning methods, but also achieves\nsimilar or even higher accuracy under the same computation budgets. Our results\nfacilitate the community to rethink the effectiveness of existing techniques\nused for network pruning.", "published": "2019-09-27T09:38:31Z", "version": 1}, {"aid": "1909.12638", "authors": ["Jinchen Xuan", "Yunchang Yang", "Ze Yang", "Di He", "Liwei Wang"], "title": "On the Anomalous Generalization of GANs", "url": "http://arxiv.org/pdf/1909.12638v2", "summary": "Generative models, especially Generative Adversarial Networks (GANs), have\nreceived significant attention recently. However, it has been observed that in\nterms of some attributes, e.g. the number of simple geometric primitives in an\nimage, GANs are not able to learn the target distribution in practice.\nMotivated by this observation, we discover two specific problems of GANs\nleading to anomalous generalization behaviour, which we refer to as the sample\ninsufficiency and the pixel-wise combination. For the first problem of sample\ninsufficiency, we show theoretically and empirically that the batchsize of the\ntraining samples in practice may be insufficient for the discriminator to learn\nan accurate discrimination function. It could result in unstable training\ndynamics for the generator, leading to anomalous generalization. For the second\nproblem of pixel-wise combination, we find that besides recognizing the\npositive training samples as real, under certain circumstances, the\ndiscriminator could be fooled to recognize the pixel-wise combinations (e.g.\npixel-wise average) of the positive training samples as real. However, those\ncombinations could be visually different from the real samples in the target\ndistribution. With the fooled discriminator as reference, the generator would\nobtain biased supervision further, leading to the anomalous generalization\nbehaviour. Additionally, in this paper, we propose methods to mitigate the\nanomalous generalization of GANs. Extensive experiments on benchmark show our\nproposed methods improve the FID score up to 30\\% on natural image dataset.", "published": "2019-09-27T12:00:41Z", "version": 2}, {"aid": "1909.12778", "authors": ["Xiaohan Ding", "Guiguang Ding", "Xiangxin Zhou", "Yuchen Guo", "Jungong Han", "Ji Liu"], "title": "Global Sparse Momentum SGD for Pruning Very Deep Neural Networks", "url": "http://arxiv.org/pdf/1909.12778v3", "summary": "Deep Neural Network (DNN) is powerful but computationally expensive and\nmemory intensive, thus impeding its practical usage on resource-constrained\nfront-end devices. DNN pruning is an approach for deep model compression, which\naims at eliminating some parameters with tolerable performance degradation. In\nthis paper, we propose a novel momentum-SGD-based optimization method to reduce\nthe network complexity by on-the-fly pruning. Concretely, given a global\ncompression ratio, we categorize all the parameters into two parts at each\ntraining iteration which are updated using different rules. In this way, we\ngradually zero out the redundant parameters, as we update them using only the\nordinary weight decay but no gradients derived from the objective function. As\na departure from prior methods that require heavy human works to tune the\nlayer-wise sparsity ratios, prune by solving complicated non-differentiable\nproblems or finetune the model after pruning, our method is characterized by 1)\nglobal compression that automatically finds the appropriate per-layer sparsity\nratios; 2) end-to-end training; 3) no need for a time-consuming re-training\nprocess after pruning; and 4) superior capability to find better winning\ntickets which have won the initialization lottery.", "published": "2019-09-27T16:24:19Z", "version": 3}, {"aid": "1910.04858", "authors": ["Lu Mi", "Hao Wang", "Yonglong Tian", "Hao He", "Nir Shavit"], "title": "Training-Free Uncertainty Estimation for Dense Regression: Sensitivity as a Surrogate", "url": "http://arxiv.org/pdf/1910.04858v3", "summary": "Uncertainty estimation is an essential step in the evaluation of the\nrobustness for deep learning models in computer vision, especially when applied\nin risk-sensitive areas. However, most state-of-the-art deep learning models\neither fail to obtain uncertainty estimation or need significant modification\n(e.g., formulating a proper Bayesian treatment) to obtain it. Most previous\nmethods are not able to take an arbitrary model off the shelf and generate\nuncertainty estimation without retraining or redesigning it. To address this\ngap, we perform a systematic exploration into training-free uncertainty\nestimation for dense regression, an unrecognized yet important problem, and\nprovide a theoretical construction justifying such estimations. We propose\nthree simple and scalable methods to analyze the variance of outputs from a\ntrained network under tolerable perturbations: infer-transformation,\ninfer-noise, and infer-dropout. They operate solely during the inference,\nwithout the need to re-train, re-design, or fine-tune the models, as typically\nrequired by state-of-the-art uncertainty estimation methods. Surprisingly, even\nwithout involving such perturbations in training, our methods produce\ncomparable or even better uncertainty estimation when compared to\ntraining-required state-of-the-art methods.", "published": "2019-09-28T02:30:02Z", "version": 3}, {"aid": "1909.13063", "authors": ["Jiao Xie", "Shaohui Lin", "Yichen Zhang", "Linkai Luo"], "title": "Training convolutional neural networks with cheap convolutions and online distillation", "url": "http://arxiv.org/pdf/1909.13063v3", "summary": "The large memory and computation consumption in convolutional neural networks\n(CNNs) has been one of the main barriers for deploying them on resource-limited\nsystems. To this end, most cheap convolutions (e.g., group convolution,\ndepth-wise convolution, and shift convolution) have recently been used for\nmemory and computation reduction but with the specific architecture designing.\nFurthermore, it results in a low discriminability of the compressed networks by\ndirectly replacing the standard convolution with these cheap ones. In this\npaper, we propose to use knowledge distillation to improve the performance of\nthe compact student networks with cheap convolutions. In our case, the teacher\nis a network with the standard convolution, while the student is a simple\ntransformation of the teacher architecture without complicated redesigning. In\nparticular, we propose a novel online distillation method, which online\nconstructs the teacher network without pre-training and conducts mutual\nlearning between the teacher and student network, to improve the performance of\nthe student model. Extensive experiments demonstrate that the proposed approach\nachieves superior performance to simultaneously reduce memory and computation\noverhead of cutting-edge CNNs on different datasets, including CIFAR-10/100 and\nImageNet ILSVRC 2012, compared to the state-of-the-art CNN compression and\nacceleration methods. The codes are publicly available at\nhttps://github.com/EthanZhangYC/OD-cheap-convolution.", "published": "2019-09-28T10:16:17Z", "version": 3}, {"aid": "1910.00138", "authors": ["Victor Bogdan", "Cosmin Bonchi\u015f", "Ciprian Orhei"], "title": "Custom Extended Sobel Filters", "url": "http://arxiv.org/pdf/1910.00138v1", "summary": "Edge detection is widely and fundamental feature used in various algorithms\nin computer vision to determine the edges in an image. The edge detection\nalgorithm is used to determine the edges in an image which are further used by\nvarious algorithms from line detection to machine learning that can determine\nobjects based on their contour. Inspired by new convolution techniques in\nmachine learning we discuss here the idea of extending the standard Sobel\nkernels, which are used to compute the gradient of an image in order to find\nits edges. We compare the result of our custom extended filters with the\nresults of the standard Sobel filter and other edge detection filters using\ndifferent image sets and algorithms. We present statistical results regarding\nthe custom extended Sobel filters improvements.", "published": "2019-09-30T22:30:09Z", "version": 1}, {"aid": "1910.00724", "authors": ["Souvik Kundu", "Saurav Prakash", "Haleh Akrami", "Peter A. Beerel", "Keith M. Chugg"], "title": "A Pre-defined Sparse Kernel Based Convolution for Deep CNNs", "url": "http://arxiv.org/pdf/1910.00724v2", "summary": "The high demand for computational and storage resources severely impede the\ndeployment of deep convolutional neural networks (CNNs) in limited-resource\ndevices. Recent CNN architectures have proposed reduced complexity versions\n(e.g. SuffleNet and MobileNet) but at the cost of modest decreases inaccuracy.\nThis paper proposes pSConv, a pre-defined sparse 2D kernel-based convolution,\nwhich promises significant improvements in the trade-off between complexity and\naccuracy for both CNN training and inference. To explore the potential of this\napproach, we have experimented with two widely accepted datasets, CIFAR-10 and\nTiny ImageNet, in sparse variants of both the ResNet18 and VGG16 architectures.\nOur approach shows a parameter count reduction of up to 4.24x with modest\ndegradation in classification accuracy relative to that of standard CNNs. Our\napproach outperforms a popular variant of ShuffleNet using a variant of\nResNet18 with pSConv having 3x3 kernels with only four of nine elements not\nfixed at zero. In particular, the parameter count is reduced by 1.7x for\nCIFAR-10 and 2.29x for Tiny ImageNet with an increased accuracy of ~4%.", "published": "2019-10-02T00:38:38Z", "version": 2}, {"aid": "1910.00775", "authors": ["Taesup Kim", "Sungjin Ahn", "Yoshua Bengio"], "title": "Variational Temporal Abstraction", "url": "http://arxiv.org/pdf/1910.00775v1", "summary": "We introduce a variational approach to learning and inference of temporally\nhierarchical structure and representation for sequential data. We propose the\nVariational Temporal Abstraction (VTA), a hierarchical recurrent state space\nmodel that can infer the latent temporal structure and thus perform the\nstochastic state transition hierarchically. We also propose to apply this model\nto implement the jumpy-imagination ability in imagination-augmented\nagent-learning in order to improve the efficiency of the imagination. In\nexperiments, we demonstrate that our proposed method can model 2D and 3D visual\nsequence datasets with interpretable temporal structure discovery and that its\napplication to jumpy imagination enables more efficient agent-learning in a 3D\nnavigation task.", "published": "2019-10-02T04:37:23Z", "version": 1}, {"aid": "1910.01089", "authors": ["Juan Luis Gonzalez Bello", "Munchurl Kim"], "title": "Deep 3D Pan via adaptive \"t-shaped\" convolutions with global and local adaptive dilations", "url": "http://arxiv.org/pdf/1910.01089v3", "summary": "Recent advances in deep learning have shown promising results in many\nlow-level vision tasks. However, solving the single-image-based view synthesis\nis still an open problem. In particular, the generation of new images at\nparallel camera views given a single input image is of great interest, as it\nenables 3D visualization of the 2D input scenery. We propose a novel network\narchitecture to perform stereoscopic view synthesis at arbitrary camera\npositions along the X-axis, or Deep 3D Pan, with \"t-shaped\" adaptive kernels\nequipped with globally and locally adaptive dilations. Our proposed network\narchitecture, the monster-net, is devised with a novel \"t-shaped\" adaptive\nkernel with globally and locally adaptive dilation, which can efficiently\nincorporate global camera shift into and handle local 3D geometries of the\ntarget image's pixels for the synthesis of naturally looking 3D panned views\nwhen a 2-D input image is given. Extensive experiments were performed on the\nKITTI, CityScapes and our VICLAB_STEREO indoors dataset to prove the efficacy\nof our method. Our monster-net significantly outperforms the state-of-the-art\nmethod, SOTA, by a large margin in all metrics of RMSE, PSNR, and SSIM. Our\nproposed monster-net is capable of reconstructing more reliable image\nstructures in synthesized images with coherent geometry. Moreover, the\ndisparity information that can be extracted from the \"t-shaped\" kernel is much\nmore reliable than that of the SOTA for the unsupervised monocular depth\nestimation task, confirming the effectiveness of our method.", "published": "2019-10-02T17:09:58Z", "version": 3}, {"aid": "1910.01409", "authors": ["Dexuan Zhang", "Tatsuya Harada"], "title": "A General Upper Bound for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/1910.01409v2", "summary": "In this work, we present a novel upper bound of target error to address the\nproblem for unsupervised domain adaptation. Recent studies reveal that a deep\nneural network can learn transferable features which generalize well to novel\ntasks. Furthermore, a theory proposed by Ben-David et al. (2010) provides a\nupper bound for target error when transferring the knowledge, which can be\nsummarized as minimizing the source error and distance between marginal\ndistributions simultaneously. However, common methods based on the theory\nusually ignore the joint error such that samples from different classes might\nbe mixed together when matching marginal distribution. And in such case, no\nmatter how we minimize the marginal discrepancy, the target error is not\nbounded due to an increasing joint error. To address this problem, we propose a\ngeneral upper bound taking joint error into account, such that the undesirable\ncase can be properly penalized. In addition, we utilize constrained hypothesis\nspace to further formalize a tighter bound as well as a novel cross margin\ndiscrepancy to measure the dissimilarity between hypotheses which alleviates\ninstability during adversarial learning. Extensive empirical evidence shows\nthat our proposal outperforms related approaches in image classification error\nrates on standard domain adaptation benchmarks.", "published": "2019-10-03T11:31:14Z", "version": 2}, {"aid": "1910.01708", "authors": ["Scott Fujimoto", "Edoardo Conti", "Mohammad Ghavamzadeh", "Joelle Pineau"], "title": "Benchmarking Batch Deep Reinforcement Learning Algorithms", "url": "http://arxiv.org/pdf/1910.01708v1", "summary": "Widely-used deep reinforcement learning algorithms have been shown to fail in\nthe batch setting--learning from a fixed data set without interaction with the\nenvironment. Following this result, there have been several papers showing\nreasonable performances under a variety of environments and batch settings. In\nthis paper, we benchmark the performance of recent off-policy and batch\nreinforcement learning algorithms under unified settings on the Atari domain,\nwith data generated by a single partially-trained behavioral policy. We find\nthat under these conditions, many of these algorithms underperform DQN trained\nonline with the same amount of data, as well as the partially-trained\nbehavioral policy. To introduce a strong baseline, we adapt the\nBatch-Constrained Q-learning algorithm to a discrete-action setting, and show\nit outperforms all existing algorithms at this task.", "published": "2019-10-03T20:15:55Z", "version": 1}, {"aid": "1910.02840", "authors": ["Aram-Alexandre Pooladian", "Chris Finlay", "Adam M Oberman"], "title": "Farkas layers: don't shift the data, fix the geometry", "url": "http://arxiv.org/pdf/1910.02840v1", "summary": "Successfully training deep neural networks often requires either batch\nnormalization, appropriate weight initialization, both of which come with their\nown challenges. We propose an alternative, geometrically motivated method for\ntraining. Using elementary results from linear programming, we introduce Farkas\nlayers: a method that ensures at least one neuron is active at a given layer.\nFocusing on residual networks with ReLU activation, we empirically demonstrate\na significant improvement in training capacity in the absence of batch\nnormalization or methods of initialization across a broad range of network\nsizes on benchmark datasets.", "published": "2019-10-04T15:24:37Z", "version": 1}, {"aid": "1910.02560", "authors": ["Wenju Xu", "Shawn Keshmiri", "Guanghui Wang"], "title": "Stacked Wasserstein Autoencoder", "url": "http://arxiv.org/pdf/1910.02560v1", "summary": "Approximating distributions over complicated manifolds, such as natural\nimages, are conceptually attractive. The deep latent variable model, trained\nusing variational autoencoders and generative adversarial networks, is now a\nkey technique for representation learning. However, it is difficult to unify\nthese two models for exact latent-variable inference and parallelize both\nreconstruction and sampling, partly due to the regularization under the latent\nvariables, to match a simple explicit prior distribution. These approaches are\nprone to be oversimplified, and can only characterize a few modes of the true\ndistribution. Based on the recently proposed Wasserstein autoencoder (WAE) with\na new regularization as an optimal transport. The paper proposes a stacked\nWasserstein autoencoder (SWAE) to learn a deep latent variable model. SWAE is a\nhierarchical model, which relaxes the optimal transport constraints at two\nstages. At the first stage, the SWAE flexibly learns a representation\ndistribution, i.e., the encoded prior; and at the second stage, the encoded\nrepresentation distribution is approximated with a latent variable model under\nthe regularization encouraging the latent distribution to match the explicit\nprior. This model allows us to generate natural textual outputs as well as\nperform manipulations in the latent space to induce changes in the output\nspace. Both quantitative and qualitative results demonstrate the superior\nperformance of SWAE compared with the state-of-the-art approaches in terms of\nfaithful reconstruction and generation quality.", "published": "2019-10-04T17:07:42Z", "version": 1}, {"aid": "1910.02054", "authors": ["Samyam Rajbhandari", "Jeff Rasley", "Olatunji Ruwase", "Yuxiong He"], "title": "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models", "url": "http://arxiv.org/pdf/1910.02054v3", "summary": "Large deep learning models offer significant accuracy gains, but training\nbillions to trillions of parameters is challenging. Existing solutions such as\ndata and model parallelisms exhibit fundamental limitations to fit these models\ninto limited device memory, while obtaining computation, communication and\ndevelopment efficiency. We develop a novel solution, Zero Redundancy Optimizer\n(ZeRO), to optimize memory, vastly improving training speed while increasing\nthe model size that can be efficiently trained. ZeRO eliminates memory\nredundancies in data- and model-parallel training while retaining low\ncommunication volume and high computational granularity, allowing us to scale\nthe model size proportional to the number of devices with sustained high\nefficiency. Our analysis on memory requirements and communication volume\ndemonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters\nusing today's hardware.\n  We implement and evaluate ZeRO: it trains large models of over 100B parameter\nwith super-linear speedup on 400 GPUs, achieving throughput of 15 Petaflops.\nThis represents an 8x increase in model size and 10x increase in achievable\nperformance over state-of-the-art. In terms of usability, ZeRO can train large\nmodels of up to 13B parameters (e.g., larger than Megatron GPT 8.3B and T5 11B)\nwithout requiring model parallelism which is harder for scientists to apply.\nLast but not the least, researchers have used the system breakthroughs of ZeRO\nto create the world's largest language model (Turing-NLG, 17B parameters) with\nrecord breaking accuracy.", "published": "2019-10-04T17:29:39Z", "version": 3}, {"aid": "1910.02190", "authors": ["Edgar Riba", "Dmytro Mishkin", "Daniel Ponsa", "Ethan Rublee", "Gary Bradski"], "title": "Kornia: an Open Source Differentiable Computer Vision Library for PyTorch", "url": "http://arxiv.org/pdf/1910.02190v2", "summary": "This work presents Kornia -- an open source computer vision library which\nconsists of a set of differentiable routines and modules to solve generic\ncomputer vision problems. The package uses PyTorch as its main backend both for\nefficiency and to take advantage of the reverse-mode auto-differentiation to\ndefine and compute the gradient of complex functions. Inspired by OpenCV,\nKornia is composed of a set of modules containing operators that can be\ninserted inside neural networks to train models to perform image\ntransformations, camera calibration, epipolar geometry, and low level image\nprocessing techniques, such as filtering and edge detection that operate\ndirectly on high dimensional tensor representations. Examples of classical\nvision problems implemented using our framework are provided including a\nbenchmark comparing to existing vision libraries.", "published": "2019-10-05T01:29:54Z", "version": 2}, {"aid": "1910.04875", "authors": ["Xiaomeng Dong", "Junpyo Hong", "Hsi-Ming Chang", "Michael Potter", "Aritra Chowdhury", "Purujit Bahl", "Vivek Soni", "Yun-Chan Tsai", "Rajesh Tamada", "Gaurav Kumar", "Caroline Favart", "V. Ratna Saripalli", "Gopal Avinash"], "title": "FastEstimator: A Deep Learning Library for Fast Prototyping and Productization", "url": "http://arxiv.org/pdf/1910.04875v2", "summary": "As the complexity of state-of-the-art deep learning models increases by the\nmonth, implementation, interpretation, and traceability become\never-more-burdensome challenges for AI practitioners around the world. Several\nAI frameworks have risen in an effort to stem this tide, but the steady advance\nof the field has begun to test the bounds of their flexibility, expressiveness,\nand ease of use. To address these concerns, we introduce a radically flexible\nhigh-level open source deep learning framework for both research and industry.\nWe introduce FastEstimator.", "published": "2019-10-07T01:01:27Z", "version": 2}, {"aid": "1910.02629", "authors": ["Zhenyue Qin", "Dongwoo Kim"], "title": "Softmax Is Not an Artificial Trick: An Information-Theoretic View of Softmax in Neural Networks", "url": "http://arxiv.org/pdf/1910.02629v3", "summary": "Despite great popularity of applying softmax to map the non-normalised\noutputs of a neural network to a probability distribution over predicting\nclasses, this normalised exponential transformation still seems to be\nartificial. A theoretic framework that incorporates softmax as an intrinsic\ncomponent is still lacking. In this paper, we view neural networks embedding\nsoftmax from an information-theoretic perspective. Under this view, we can\nnaturally and mathematically derive log-softmax as an inherent component in a\nneural network for evaluating the conditional mutual information between\nnetwork output vectors and labels given an input datum. We show that training\ndeterministic neural networks through maximising log-softmax is equivalent to\nenlarging the conditional mutual information, i.e., feeding label information\ninto network outputs. We also generalise our informative-theoretic perspective\nto neural networks with stochasticity and derive information upper and lower\nbounds of log-softmax. In theory, such an information-theoretic view offers\nrationality support for embedding softmax in neural networks; in practice, we\neventually demonstrate a computer vision application example of how to employ\nour information-theoretic view to filter out targeted objects on images.", "published": "2019-10-07T06:46:06Z", "version": 3}, {"aid": "1910.02940", "authors": ["Hang Gao", "Xizhou Zhu", "Steve Lin", "Jifeng Dai"], "title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "url": "http://arxiv.org/pdf/1910.02940v2", "summary": "Convolutional networks are not aware of an object's geometric variations,\nwhich leads to inefficient utilization of model and data capacity. To overcome\nthis issue, recent works on deformation modeling seek to spatially reconfigure\nthe data towards a common arrangement such that semantic recognition suffers\nless from deformation. This is typically done by augmenting static operators\nwith learned free-form sampling grids in the image space, dynamically tuned to\nthe data and task for adapting the receptive field. Yet adapting the receptive\nfield does not quite reach the actual goal -- what really matters to the\nnetwork is the \"effective\" receptive field (ERF), which reflects how much each\npixel contributes. It is thus natural to design other approaches to adapt the\nERF directly during runtime.\n  In this work, we instantiate one possible solution as Deformable Kernels\n(DKs), a family of novel and generic convolutional operators for handling\nobject deformations by directly adapting the ERF while leaving the receptive\nfield untouched. At the heart of our method is the ability to resample the\noriginal kernel space towards recovering the deformation of objects. This\napproach is justified with theoretical insights that the ERF is strictly\ndetermined by data sampling locations and kernel values. We implement DKs as\ngeneric drop-in replacements of rigid kernels and conduct a series of empirical\nstudies whose results conform with our theories. Over several tasks and\nstandard base models, our approach compares favorably against prior works that\nadapt during runtime. In addition, further experiments suggest a working\nmechanism orthogonal and complementary to previous works.", "published": "2019-10-07T17:58:10Z", "version": 2}, {"aid": "1910.04877", "authors": ["Prateeth Nayak", "David Zhang", "Sek Chai"], "title": "Bit Efficient Quantization for Deep Neural Networks", "url": "http://arxiv.org/pdf/1910.04877v1", "summary": "Quantization for deep neural networks have afforded models for edge devices\nthat use less on-board memory and enable efficient low-power inference. In this\npaper, we present a comparison of model-parameter driven quantization\napproaches that can achieve as low as 3-bit precision without affecting\naccuracy. The post-training quantization approaches are data-free, and the\nresulting weight values are closely tied to the dataset distribution on which\nthe model has converged to optimality. We show quantization results for a\nnumber of state-of-art deep neural networks (DNN) using large dataset like\nImageNet. To better analyze quantization results, we describe the overall range\nand local sparsity of values afforded through various quantization schemes. We\nshow the methods to lower bit-precision beyond quantization limits with object\nclass clustering.", "published": "2019-10-07T18:43:12Z", "version": 1}, {"aid": "1910.03151", "authors": ["Qilong Wang", "Banggu Wu", "Pengfei Zhu", "Peihua Li", "Wangmeng Zuo", "Qinghua Hu"], "title": "ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1910.03151v4", "summary": "Recently, channel attention mechanism has demonstrated to offer great\npotential in improving the performance of deep convolutional neural networks\n(CNNs). However, most existing methods dedicate to developing more\nsophisticated attention modules for achieving better performance, which\ninevitably increase model complexity. To overcome the paradox of performance\nand complexity trade-off, this paper proposes an Efficient Channel Attention\n(ECA) module, which only involves a handful of parameters while bringing clear\nperformance gain. By dissecting the channel attention module in SENet, we\nempirically show avoiding dimensionality reduction is important for learning\nchannel attention, and appropriate cross-channel interaction can preserve\nperformance while significantly decreasing model complexity. Therefore, we\npropose a local cross-channel interaction strategy without dimensionality\nreduction, which can be efficiently implemented via $1D$ convolution.\nFurthermore, we develop a method to adaptively select kernel size of $1D$\nconvolution, determining coverage of local cross-channel interaction. The\nproposed ECA module is efficient yet effective, e.g., the parameters and\ncomputations of our modules against backbone of ResNet50 are 80 vs. 24.37M and\n4.7e-4 GFLOPs vs. 3.86 GFLOPs, respectively, and the performance boost is more\nthan 2% in terms of Top-1 accuracy. We extensively evaluate our ECA module on\nimage classification, object detection and instance segmentation with backbones\nof ResNets and MobileNetV2. The experimental results show our module is more\nefficient while performing favorably against its counterparts.", "published": "2019-10-08T01:14:26Z", "version": 4}, {"aid": "1910.03676", "authors": ["Ehsan Adeli", "Qingyu Zhao", "Adolf Pfefferbaum", "Edith V. Sullivan", "Li Fei-Fei", "Juan Carlos Niebles", "Kilian M. Pohl"], "title": "Representation Learning with Statistical Independence to Mitigate Bias", "url": "http://arxiv.org/pdf/1910.03676v4", "summary": "Presence of bias (in datasets or tasks) is inarguably one of the most\ncritical challenges in machine learning applications that has alluded to\npivotal debates in recent years. Such challenges range from spurious\nassociations between variables in medical studies to the bias of race in gender\nor face recognition systems. Controlling for all types of biases in the dataset\ncuration stage is cumbersome and sometimes impossible. The alternative is to\nuse the available data and build models incorporating fair representation\nlearning. In this paper, we propose such a model based on adversarial training\nwith two competing objectives to learn features that have (1) maximum\ndiscriminative power with respect to the task and (2) minimal statistical mean\ndependence with the protected (bias) variable(s). Our approach does so by\nincorporating a new adversarial loss function that encourages a vanished\ncorrelation between the bias and the learned features. We apply our method to\nsynthetic data, medical images (containing task bias), and a dataset for gender\nclassification (containing dataset bias). Our results show that the learned\nfeatures by our method not only result in superior prediction performance but\nalso are unbiased. The code is available at\nhttps://github.com/QingyuZhao/BR-Net/.", "published": "2019-10-08T20:33:58Z", "version": 4}, {"aid": "1910.03866", "authors": ["Leonie Henschel", "Sailesh Conjeti", "Santiago Estrada", "Kersten Diers", "Bruce Fischl", "Martin Reuter"], "title": "FastSurfer -- A fast and accurate deep learning based neuroimaging pipeline", "url": "http://arxiv.org/pdf/1910.03866v4", "summary": "Traditional neuroimage analysis pipelines involve computationally intensive,\ntime-consuming optimization steps, and thus, do not scale well to large cohort\nstudies with thousands or tens of thousands of individuals. In this work we\npropose a fast and accurate deep learning based neuroimaging pipeline for the\nautomated processing of structural human brain MRI scans, replicating\nFreeSurfer's anatomical segmentation including surface reconstruction and\ncortical parcellation. To this end, we introduce an advanced deep learning\narchitecture capable of whole brain segmentation into 95 classes. The network\narchitecture incorporates local and global competition via competitive dense\nblocks and competitive skip pathways, as well as multi-slice information\naggregation that specifically tailor network performance towards accurate\nsegmentation of both cortical and sub-cortical structures. Further, we perform\nfast cortical surface reconstruction and thickness analysis by introducing a\nspectral spherical embedding and by directly mapping the cortical labels from\nthe image to the surface. This approach provides a full FreeSurfer alternative\nfor volumetric analysis (in under 1 minute) and surface-based thickness\nanalysis (within only around 1h runtime). For sustainability of this approach\nwe perform extensive validation: we assert high segmentation accuracy on\nseveral unseen datasets, measure generalizability and demonstrate increased\ntest-retest reliability, and high sensitivity to group differences in dementia.", "published": "2019-10-09T09:41:14Z", "version": 4}, {"aid": "1910.05448", "authors": ["Tharindu Fernando", "Simon Denman", "David Ahmedt-Aristizabal", "Sridha Sridharan", "Kristin Laurens", "Patrick Johnston", "Clinton Fookes"], "title": "Neural Memory Plasticity for Anomaly Detection", "url": "http://arxiv.org/pdf/1910.05448v1", "summary": "In the domain of machine learning, Neural Memory Networks (NMNs) have\nrecently achieved impressive results in a variety of application areas\nincluding visual question answering, trajectory prediction, object tracking,\nand language modelling. However, we observe that the attention based knowledge\nretrieval mechanisms used in current NMNs restricts them from achieving their\nfull potential as the attention process retrieves information based on a set of\nstatic connection weights. This is suboptimal in a setting where there are vast\ndifferences among samples in the data domain; such as anomaly detection where\nthere is no consistent criteria for what constitutes an anomaly. In this paper,\nwe propose a plastic neural memory access mechanism which exploits both static\nand dynamic connection weights in the memory read, write and output generation\nprocedures. We demonstrate the effectiveness and flexibility of the proposed\nmemory model in three challenging anomaly detection tasks in the medical\ndomain: abnormal EEG identification, MRI tumour type classification and\nschizophrenia risk detection in children. In all settings, the proposed\napproach outperforms the current state-of-the-art. Furthermore, we perform an\nin-depth analysis demonstrating the utility of neural plasticity for the\nknowledge retrieval process and provide evidence on how the proposed memory\nmodel generates sparse yet informative memory outputs.", "published": "2019-10-12T00:32:56Z", "version": 1}, {"aid": "1910.05546", "authors": ["Zedong Bi", "Changsong Zhou"], "title": "Understanding the computation of time using neural network models", "url": "http://arxiv.org/pdf/1910.05546v4", "summary": "To maximize future rewards in this ever-changing world, animals must be able\nto discover the temporal structure of stimuli and then anticipate or act\ncorrectly at the right time. How the animals perceive, maintain, and use time\nintervals ranging from hundreds of milliseconds to multi-seconds in working\nmemory? How temporal information is processed concurrently with spatial\ninformation and decision making? Why there are strong neuronal temporal signals\nin tasks in which temporal information is not required? A systematic\nunderstanding of the underlying neural mechanisms is still lacking. Here, we\naddressed these problems using supervised training of recurrent neural network\nmodels. We revealed that neural networks perceive elapsed time through state\nevolution along stereotypical trajectory, maintain time intervals in working\nmemory in the monotonic increase or decrease of the firing rates of\ninterval-tuned neurons, and compare or produce time intervals by scaling state\nevolution speed. Temporal and non-temporal information are coded in subspaces\northogonal with each other, and the state trajectories with time at different\nnon-temporal information are quasi-parallel and isomorphic. Such coding\ngeometry facilitates the decoding generalizability of temporal and non-temporal\ninformation across each other. The network structure exhibits multiple\nfeedforward sequences that mutually excite or inhibit depending on whether\ntheir preferences of non-temporal information are similar or not. We identified\nfour factors that facilitate strong temporal signals in non-timing tasks,\nincluding the anticipation of coming events. Our work discloses fundamental\ncomputational principles of temporal processing, and is supported by and gives\npredictions to a number of experimental phenomena.", "published": "2019-10-12T10:07:42Z", "version": 4}, {"aid": "1910.06764", "authors": ["Emilio Parisotto", "H. Francis Song", "Jack W. Rae", "Razvan Pascanu", "Caglar Gulcehre", "Siddhant M. Jayakumar", "Max Jaderberg", "Raphael Lopez Kaufman", "Aidan Clark", "Seb Noury", "Matthew M. Botvinick", "Nicolas Heess", "Raia Hadsell"], "title": "Stabilizing Transformers for Reinforcement Learning", "url": "http://arxiv.org/pdf/1910.06764v1", "summary": "Owing to their ability to both effectively integrate information over long\ntime horizons and scale to massive amounts of data, self-attention\narchitectures have recently shown breakthrough success in natural language\nprocessing (NLP), achieving state-of-the-art results in domains such as\nlanguage modeling and machine translation. Harnessing the transformer's ability\nto process long time horizons of information could provide a similar\nperformance boost in partially observable reinforcement learning (RL) domains,\nbut the large-scale transformers used in NLP have yet to be successfully\napplied to the RL setting. In this work we demonstrate that the standard\ntransformer architecture is difficult to optimize, which was previously\nobserved in the supervised learning setting but becomes especially pronounced\nwith RL objectives. We propose architectural modifications that substantially\nimprove the stability and learning speed of the original Transformer and XL\nvariant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses\nLSTMs on challenging memory environments and achieves state-of-the-art results\non the multi-task DMLab-30 benchmark suite, exceeding the performance of an\nexternal memory architecture. We show that the GTrXL, trained using the same\nlosses, has stability and performance that consistently matches or exceeds a\ncompetitive LSTM baseline, including on more reactive tasks where memory is\nless critical. GTrXL offers an easy-to-train, simple-to-implement but\nsubstantially more expressive architectural alternative to the standard\nmulti-layer LSTM ubiquitously used for RL agents in partially observable\nenvironments.", "published": "2019-10-13T20:02:15Z", "version": 1}, {"aid": "1910.05872", "authors": ["Hankook Lee", "Sung Ju Hwang", "Jinwoo Shin"], "title": "Self-supervised Label Augmentation via Input Transformations", "url": "http://arxiv.org/pdf/1910.05872v2", "summary": "Self-supervised learning, which learns by constructing artificial labels\ngiven only the input signals, has recently gained considerable attention for\nlearning representations with unlabeled datasets, i.e., learning without any\nhuman-annotated supervision. In this paper, we show that such a technique can\nbe used to significantly improve the model accuracy even under fully-labeled\ndatasets. Our scheme trains the model to learn both original and\nself-supervised tasks, but is different from conventional multi-task learning\nframeworks that optimize the summation of their corresponding losses. Our main\nidea is to learn a single unified task with respect to the joint distribution\nof the original and self-supervised labels, i.e., we augment original labels\nvia self-supervision of input transformation. This simple, yet effective\napproach allows to train models easier by relaxing a certain invariant\nconstraint during learning the original and self-supervised tasks\nsimultaneously. It also enables an aggregated inference which combines the\npredictions from different augmentations to improve the prediction accuracy.\nFurthermore, we propose a novel knowledge transfer technique, which we refer to\nas self-distillation, that has the effect of the aggregated inference in a\nsingle (faster) inference. We demonstrate the large accuracy improvement and\nwide applicability of our framework on various fully-supervised settings, e.g.,\nthe few-shot and imbalanced classification scenarios.", "published": "2019-10-14T00:37:33Z", "version": 2}, {"aid": "1910.05878", "authors": ["Wen Zhang", "Dongrui Wu"], "title": "Manifold Embedded Knowledge Transfer for Brain-Computer Interfaces", "url": "http://arxiv.org/pdf/1910.05878v2", "summary": "Transfer learning makes use of data or knowledge in one problem to help solve\na different, yet related, problem. It is particularly useful in brain-computer\ninterfaces (BCIs), for coping with variations among different subjects and/or\ntasks. This paper considers offline unsupervised cross-subject\nelectroencephalogram (EEG) classification, i.e., we have labeled EEG trials\nfrom one or more source subjects, but only unlabeled EEG trials from the target\nsubject. We propose a novel manifold embedded knowledge transfer (MEKT)\napproach, which first aligns the covariance matrices of the EEG trials in the\nRiemannian manifold, extracts features in the tangent space, and then performs\ndomain adaptation by minimizing the joint probability distribution shift\nbetween the source and the target domains, while preserving their geometric\nstructures. MEKT can cope with one or multiple source domains, and can be\ncomputed efficiently. We also propose a domain transferability estimation (DTE)\napproach to identify the most beneficial source domains, in case there are a\nlarge number of source domains. Experiments on four EEG datasets from two\ndifferent BCI paradigms demonstrated that MEKT outperformed several\nstate-of-the-art transfer learning approaches, and DTE can reduce more than\nhalf of the computational cost when the number of source subjects is large,\nwith little sacrifice of classification accuracy.", "published": "2019-10-14T01:33:33Z", "version": 2}, {"aid": "1910.06705", "authors": ["YoungJoon Yoo", "Sanghyuk Chun", "Sangdoo Yun", "Jung-Woo Ha", "Jaejun Yoo"], "title": "Neural Approximation of an Auto-Regressive Process through Confidence Guided Sampling", "url": "http://arxiv.org/pdf/1910.06705v1", "summary": "We propose a generic confidence-based approximation that can be plugged in\nand simplify the auto-regressive generation process with a proved convergence.\nWe first assume that the priors of future samples can be generated in an\nindependently and identically distributed (i.i.d.) manner using an efficient\npredictor. Given the past samples and future priors, the mother AR model can\npost-process the priors while the accompanied confidence predictor decides\nwhether the current sample needs a resampling or not. Thanks to the i.i.d.\nassumption, the post-processing can update each sample in a parallel way, which\nremarkably accelerates the mother model. Our experiments on different data\ndomains including sequences and images show that the proposed method can\nsuccessfully capture the complex structures of the data and generate the\nmeaningful future samples with lower computational cost while preserving the\nsequential relationship of the data.", "published": "2019-10-15T13:11:24Z", "version": 1}, {"aid": "1910.06849", "authors": ["Guohao Li", "Matthias M\u00fcller", "Guocheng Qian", "Itzel C. Delgadillo", "Abdulellah Abualshour", "Ali Thabet", "Bernard Ghanem"], "title": "DeepGCNs: Making GCNs Go as Deep as CNNs", "url": "http://arxiv.org/pdf/1910.06849v3", "summary": "Convolutional Neural Networks (CNNs) have been very successful at solving a\nvariety of computer vision tasks such as object classification and detection,\nsemantic segmentation, activity understanding, to name just a few. One key\nenabling factor for their great performance has been the ability to train very\ndeep networks. Despite their huge success in many tasks, CNNs do not work well\nwith non-Euclidean data, which is prevalent in many real-world applications.\nGraph Convolutional Networks (GCNs) offer an alternative that allows for\nnon-Eucledian data input to a neural network. While GCNs already achieve\nencouraging results, they are currently limited to architectures with a\nrelatively small number of layers, primarily due to vanishing gradients during\ntraining. This work transfers concepts such as residual/dense connections and\ndilated convolutions from CNNs to GCNs in order to successfully train very deep\nGCNs. We show the benefit of using deep GCNs (with as many as 112 layers)\nexperimentally across various datasets and tasks. Specifically, we achieve very\npromising performance in part segmentation and semantic segmentation on point\nclouds and in node classification of protein functions across biological\nprotein-protein interaction (PPI) graphs. We believe that the insights in this\nwork will open avenues for future research on GCNs and their application to\nfurther tasks not explored in this paper. The source code for this work is\navailable at https://github.com/lightaime/deep_gcns_torch and\nhttps://github.com/lightaime/deep_gcns for PyTorch and TensorFlow\nimplementation respectively.", "published": "2019-10-15T15:10:34Z", "version": 3}, {"aid": "1910.06950", "authors": ["Nicha C. Dvornek", "Xiaoxiao Li", "Juntang Zhuang", "James S. Duncan"], "title": "Jointly Discriminative and Generative Recurrent Neural Networks for Learning from fMRI", "url": "http://arxiv.org/pdf/1910.06950v1", "summary": "Recurrent neural networks (RNNs) were designed for dealing with time-series\ndata and have recently been used for creating predictive models from functional\nmagnetic resonance imaging (fMRI) data. However, gathering large fMRI datasets\nfor learning is a difficult task. Furthermore, network interpretability is\nunclear. To address these issues, we utilize multitask learning and design a\nnovel RNN-based model that learns to discriminate between classes while\nsimultaneously learning to generate the fMRI time-series data. Employing the\nlong short-term memory (LSTM) structure, we develop a discriminative model\nbased on the hidden state and a generative model based on the cell state. The\naddition of the generative model constrains the network to learn functional\ncommunities represented by the LSTM nodes that are both consistent with the\ndata generation as well as useful for the classification task. We apply our\napproach to the classification of subjects with autism vs. healthy controls\nusing several datasets from the Autism Brain Imaging Data Exchange. Experiments\nshow that our jointly discriminative and generative model improves\nclassification learning while also producing robust and meaningful functional\ncommunities for better model understanding.", "published": "2019-10-15T17:43:45Z", "version": 1}, {"aid": "1910.07117", "authors": ["Tianxing He", "Jun Liu", "Kyunghyun Cho", "Myle Ott", "Bing Liu", "James Glass", "Fuchun Peng"], "title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue Response Models", "url": "http://arxiv.org/pdf/1910.07117v5", "summary": "In this work, we study how the finetuning stage in the pretrain-finetune\nframework changes the behavior of a pretrained neural language generator. We\nfocus on the transformer encoder-decoder model for the open-domain dialogue\nresponse generation task. Our major finding is that after standard finetuning,\nthe model forgets some of the important language generation skills acquired\nduring large-scale pretraining. We demonstrate the forgetting phenomenon\nthrough a set of detailed behavior analysis from the perspectives of knowledge\ntransfer, context sensitivity, and function space projection. As a preliminary\nattempt to alleviate the forgetting problem, we propose an intuitive finetuning\nstrategy named \"mix-review\". We find that mix-review effectively regularizes\nthe finetuning process, and the forgetting problem is alleviated to some\nextent. Finally, we discuss interesting behavior of the resulting dialogue\nmodel and its implications.", "published": "2019-10-16T01:10:10Z", "version": 5}, {"aid": "1910.07133", "authors": ["Vasil Kolev", "Todor Cooklev", "Fritz Keinert"], "title": "Design of a Simple Orthogonal Multiwavelet Filter by Matrix Spectral Factorization", "url": "http://arxiv.org/pdf/1910.07133v2", "summary": "We consider the design of an orthogonal symmetric/antisymmetric multiwavelet\nfrom its matrix product filter by matrix spectral factorization (MSF). As a\ntest problem, we construct a simple matrix product filter with desirable\nproperties, and factor it using Bauer's method, which in this case can be done\nin closed form. The corresponding orthogonal multiwavelet function is derived\nusing algebraic techniques which allow symmetry to be considered. This leads to\nthe known orthogonal multiwavelet SA1, which can also be derived directly. We\nalso give a lifting scheme for SA1, investigate the influence of the number of\nsignificant digits in the calculations, and show some numerical experiments.", "published": "2019-10-16T02:21:52Z", "version": 2}, {"aid": "1910.10485", "authors": ["Gabriele Prato", "Ella Charlaix", "Mehdi Rezagholizadeh"], "title": "Fully Quantized Transformer for Machine Translation", "url": "http://arxiv.org/pdf/1910.10485v3", "summary": "State-of-the-art neural machine translation methods employ massive amounts of\nparameters. Drastically reducing computational costs of such methods without\naffecting performance has been up to this point unsuccessful. To this end, we\npropose FullyQT: an all-inclusive quantization strategy for the Transformer. To\nthe best of our knowledge, we are the first to show that it is possible to\navoid any loss in translation quality with a fully quantized Transformer.\nIndeed, compared to full-precision, our 8-bit models score greater or equal\nBLEU on most tasks. Comparing ourselves to all previously proposed methods, we\nachieve state-of-the-art quantization results.", "published": "2019-10-17T01:29:12Z", "version": 3}, {"aid": "1910.09217", "authors": ["Bingyi Kang", "Saining Xie", "Marcus Rohrbach", "Zhicheng Yan", "Albert Gordo", "Jiashi Feng", "Yannis Kalantidis"], "title": "Decoupling Representation and Classifier for Long-Tailed Recognition", "url": "http://arxiv.org/pdf/1910.09217v2", "summary": "The long-tail distribution of the visual world poses great challenges for\ndeep learning based classification models on how to handle the class imbalance\nproblem. Existing solutions usually involve class-balancing strategies, e.g.,\nby loss re-weighting, data re-sampling, or transfer learning from head- to\ntail-classes, but most of them adhere to the scheme of jointly learning\nrepresentations and classifiers. In this work, we decouple the learning\nprocedure into representation learning and classification, and systematically\nexplore how different balancing strategies affect them for long-tailed\nrecognition. The findings are surprising: (1) data imbalance might not be an\nissue in learning high-quality representations; (2) with representations\nlearned with the simplest instance-balanced (natural) sampling, it is also\npossible to achieve strong long-tailed recognition ability by adjusting only\nthe classifier. We conduct extensive experiments and set new state-of-the-art\nperformance on common long-tailed benchmarks like ImageNet-LT, Places-LT and\niNaturalist, showing that it is possible to outperform carefully designed\nlosses, sampling strategies, even complex modules with memory, by using a\nstraightforward approach that decouples representation and classification. Our\ncode is available at https://github.com/facebookresearch/classifier-balancing.", "published": "2019-10-21T09:03:19Z", "version": 2}, {"aid": "1910.10232", "authors": ["Luckeciano C. Melo", "Marcos R. O. A. Maximo", "Adilson Marques da Cunha"], "title": "Bottom-Up Meta-Policy Search", "url": "http://arxiv.org/pdf/1910.10232v2", "summary": "Despite of the recent progress in agents that learn through interaction,\nthere are several challenges in terms of sample efficiency and generalization\nacross unseen behaviors during training. To mitigate these problems, we propose\nand apply a first-order Meta-Learning algorithm called Bottom-Up Meta-Policy\nSearch (BUMPS), which works with two-phase optimization procedure: firstly, in\na meta-training phase, it distills few expert policies to create a meta-policy\ncapable of generalizing knowledge to unseen tasks during training; secondly, it\napplies a fast adaptation strategy named Policy Filtering, which evaluates few\npolicies sampled from the meta-policy distribution and selects which best\nsolves the task. We conducted all experiments in the RoboCup 3D Soccer\nSimulation domain, in the context of kick motion learning. We show that, given\nour experimental setup, BUMPS works in scenarios where simple multi-task\nReinforcement Learning does not. Finally, we performed experiments in a way to\nevaluate each component of the algorithm.", "published": "2019-10-22T21:12:54Z", "version": 2}, {"aid": "1910.10579", "authors": ["Richard J. Preen", "Stewart W. Wilson", "Larry Bull"], "title": "Autoencoding with a Classifier System", "url": "http://arxiv.org/pdf/1910.10579v8", "summary": "Autoencoders are data-specific compression algorithms learned automatically\nfrom examples. The predominant approach has been to construct single large\nglobal models that cover the domain. However, training and evaluating models of\nincreasing size comes at the price of additional time and computational cost.\nConditional computation, sparsity, and model pruning techniques can reduce\nthese costs while maintaining performance. Learning classifier systems (LCS)\nare a framework for adaptively subdividing input spaces into an ensemble of\nsimpler local approximations that together cover the domain. LCS perform\nconditional computation through the use of a population of individual\ngating/guarding components, each associated with a local approximation. This\narticle explores the use of an LCS to adaptively decompose the input domain\ninto a collection of small autoencoders where local solutions of different\ncomplexity may emerge. In addition to benefits in convergence time and\ncomputational cost, it is shown possible to reduce code size as well as the\nresulting decoder computational cost when compared with the global model\nequivalent.", "published": "2019-10-23T14:27:29Z", "version": 8}, {"aid": "1910.11853", "authors": ["Bin Sun", "Jun Li", "Ming Shao", "Yun Fu"], "title": "LPRNet: Lightweight Deep Network by Low-rank Pointwise Residual Convolution", "url": "http://arxiv.org/pdf/1910.11853v3", "summary": "Deep learning has become popular in recent years primarily due to the\npowerful computing device such as GPUs. However, deploying these deep models to\nend-user devices, smart phones, or embedded systems with limited resources is\nchallenging. To reduce the computation and memory costs, we propose a novel\nlightweight deep learning module by low-rank pointwise residual (LPR)\nconvolution, called LPRNet. Essentially, LPR aims at using low-rank\napproximation in pointwise convolution to further reduce the module size, while\nkeeping depthwise convolutions as the residual module to rectify the LPR\nmodule. This is critical when the low-rankness undermines the convolution\nprocess. We embody our design by replacing modules of identical input-output\ndimension in MobileNet and ShuffleNetv2. Experiments on visual recognition\ntasks including image classification and face alignment on popular benchmarks\nshow that our LPRNet achieves competitive performance but with significant\nreduction of Flops and memory cost compared to the state-of-the-art deep models\nfocusing on model compression.", "published": "2019-10-25T17:23:05Z", "version": 3}, {"aid": "1910.13931", "authors": ["Priyadarshini Panda", "Aparna Aketi", "Kaushik Roy"], "title": "Towards Scalable, Efficient and Accurate Deep Spiking Neural Networks with Backward Residual Connections, Stochastic Softmax and Hybridization", "url": "http://arxiv.org/pdf/1910.13931v1", "summary": "Spiking Neural Networks (SNNs) may offer an energy-efficient alternative for\nimplementing deep learning applications. In recent years, there have been\nseveral proposals focused on supervised (conversion, spike-based gradient\ndescent) and unsupervised (spike timing dependent plasticity) training methods\nto improve the accuracy of SNNs on large-scale tasks. However, each of these\nmethods suffer from scalability, latency and accuracy limitations. In this\npaper, we propose novel algorithmic techniques of modifying the SNN\nconfiguration with backward residual connections, stochastic softmax and hybrid\nartificial-and-spiking neuronal activations to improve the learning ability of\nthe training methodologies to yield competitive accuracy, while, yielding large\nefficiency gains over their artificial counterparts. Note, artificial\ncounterparts refer to conventional deep learning/artificial neural networks.\nOur techniques apply to VGG/Residual architectures, and are compatible with all\nforms of training methodologies. Our analysis reveals that the proposed\nsolutions yield near state-of-the-art accuracy with significant\nenergy-efficiency and reduced parameter overhead translating to hardware\nimprovements on complex visual recognition tasks, such as, CIFAR10, Imagenet\ndatatsets.", "published": "2019-10-30T15:31:15Z", "version": 1}, {"aid": "1911.00640", "authors": ["Xiang Zou", "Lie Yao", "Donghua Zhao", "Liang Chen", "Ying Mao"], "title": "The Intrinsic Properties of Brain Based on the Network Structure", "url": "http://arxiv.org/pdf/1911.00640v1", "summary": "Objective: Brain is a fantastic organ that helps creature adapting to the\nenvironment. Network is the most essential structure of brain, but the\ncapability of a simple network is still not very clear. In this study, we try\nto expound some brain functions only by the network property. Methods: Every\nnetwork can be equivalent to a simplified network, which is expressed by an\nequation set. The dynamic of the equation set can be described by some basic\nequations, which is based on the mathematical derivation. Results (1) In a\nclosed network, the stability is based on the excitatory/inhibitory synapse\nproportion. Spike probabilities in the assembly can meet the solution of a\nnonlinear equation set. (2) Network activity can spontaneously evolve into a\ncertain distribution under different stimulation, which is closely related to\ndecision making. (3) Short memory can be formed by coupling of network\nassemblies. Conclusion: The essential property of a network may contribute to\nsome important brain functions.", "published": "2019-11-02T03:47:18Z", "version": 1}, {"aid": "1911.00809", "authors": ["Zhiyuan Li", "Ruosong Wang", "Dingli Yu", "Simon S. Du", "Wei Hu", "Ruslan Salakhutdinov", "Sanjeev Arora"], "title": "Enhanced Convolutional Neural Tangent Kernels", "url": "http://arxiv.org/pdf/1911.00809v1", "summary": "Recent research shows that for training with $\\ell_2$ loss, convolutional\nneural networks (CNNs) whose width (number of channels in convolutional layers)\ngoes to infinity correspond to regression with respect to the CNN Gaussian\nProcess kernel (CNN-GP) if only the last layer is trained, and correspond to\nregression with respect to the Convolutional Neural Tangent Kernel (CNTK) if\nall layers are trained. An exact algorithm to compute CNTK (Arora et al., 2019)\nyielded the finding that classification accuracy of CNTK on CIFAR-10 is within\n6-7% of that of that of the corresponding CNN architecture (best figure being\naround 78%) which is interesting performance for a fixed kernel. Here we show\nhow to significantly enhance the performance of these kernels using two ideas.\n(1) Modifying the kernel using a new operation called Local Average Pooling\n(LAP) which preserves efficient computability of the kernel and inherits the\nspirit of standard data augmentation using pixel shifts. Earlier papers were\nunable to incorporate naive data augmentation because of the quadratic training\ncost of kernel regression. This idea is inspired by Global Average Pooling\n(GAP), which we show for CNN-GP and CNTK is equivalent to full translation data\naugmentation. (2) Representing the input image using a pre-processing technique\nproposed by Coates et al. (2011), which uses a single convolutional layer\ncomposed of random image patches. On CIFAR-10, the resulting kernel, CNN-GP\nwith LAP and horizontal flip data augmentation, achieves 89% accuracy, matching\nthe performance of AlexNet (Krizhevsky et al., 2012). Note that this is the\nbest such result we know of for a classifier that is not a trained neural\nnetwork. Similar improvements are obtained for Fashion-MNIST.", "published": "2019-11-03T02:24:39Z", "version": 1}, {"aid": "1911.01005", "authors": ["Fan Yang", "Zijian Zhang", "Haofan Wang", "Yuening Li", "Xia Hu"], "title": "XDeep: An Interpretation Tool for Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.01005v1", "summary": "XDeep is an open-source Python package developed to interpret deep models for\nboth practitioners and researchers. Overall, XDeep takes a trained deep neural\nnetwork (DNN) as the input, and generates relevant interpretations as the\noutput with the post-hoc manner. From the functionality perspective, XDeep\nintegrates a wide range of interpretation algorithms from the\nstate-of-the-arts, covering different types of methodologies, and is capable of\nproviding both local explanation and global explanation for DNN when\ninterpreting model behaviours. With the well-documented API designed in XDeep,\nend-users can easily obtain the interpretations for their deep models at hand\nwith several lines of codes, and compare the results among different\nalgorithms. XDeep is generally compatible with Python 3, and can be installed\nthrough Python Package Index (PyPI). The source codes are available at:\nhttps://github.com/datamllab/xdeep.", "published": "2019-11-04T01:59:41Z", "version": 1}, {"aid": "1911.01028", "authors": ["Dibakar Gope", "Jesse Beu", "Urmish Thakker", "Matthew Mattina"], "title": "Ternary MobileNets via Per-Layer Hybrid Filter Banks", "url": "http://arxiv.org/pdf/1911.01028v1", "summary": "MobileNets family of computer vision neural networks have fueled tremendous\nprogress in the design and organization of resource-efficient architectures in\nrecent years. New applications with stringent real-time requirements on highly\nconstrained devices require further compression of MobileNets-like already\ncompute-efficient networks. Model quantization is a widely used technique to\ncompress and accelerate neural network inference and prior works have quantized\nMobileNets to 4-6 bits albeit with a modest to significant drop in accuracy.\nWhile quantization to sub-byte values (i.e. precision less than or equal to 8\nbits) has been valuable, even further quantization of MobileNets to binary or\nternary values is necessary to realize significant energy savings and possibly\nruntime speedups on specialized hardware, such as ASICs and FPGAs. Under the\nkey observation that convolutional filters at each layer of a deep neural\nnetwork may respond differently to ternary quantization, we propose a novel\nquantization method that generates per-layer hybrid filter banks consisting of\nfull-precision and ternary weight filters for MobileNets. The layer-wise hybrid\nfilter banks essentially combine the strengths of full-precision and ternary\nweight filters to derive a compact, energy-efficient architecture for\nMobileNets. Using this proposed quantization method, we quantized a substantial\nportion of weight filters of MobileNets to ternary values resulting in 27.98%\nsavings in energy, and a 51.07% reduction in the model size, while achieving\ncomparable accuracy and no degradation in throughput on specialized hardware in\ncomparison to the baseline full-precision MobileNets.", "published": "2019-11-04T04:32:59Z", "version": 1}, {"aid": "1911.02362", "authors": ["Adam Safron"], "title": "Bayesian Analogical Cybernetics", "url": "http://arxiv.org/pdf/1911.02362v2", "summary": "It has been argued that all of cognition can be understood in terms of\nBayesian inference. It has also been argued that analogy is the core of\ncognition. Here I will propose that these perspectives are fully compatible, in\nthat analogical reasoning can be described in terms of Bayesian inference and\nvice versa, and that both of these positions require a thorough cybernetic\ngrounding in order to fulfill their promise as unifying frameworks for\nunderstanding minds. From the Bayesian perspective of the Free Energy Principle\nand Active Inference framework, thought is constituted by dynamics of cascading\nbelief propagation through the nodes of probabilistic generative models\nspecified by a cortical heterarchy \"rooted\" in action-perception cycles that\nground the mind as an embodied control system for an autonomous agent. From the\nanalogical structure mapping perspective, thought is constituted by the\nalignment and comparison of heterogeneous structural representations. Here I\nwill propose that this core cognitive process for analogical reasoning is\nnaturally implemented by predictive coding mechanisms. However, both Bayesian\ncognitive science and models of cognitive development via analogical reasoning\nrequire rich base domains and priors (or reliably learnable posteriors) from\nwhich they can commence the process of bootstrapping minds. Here in the spirit\nof the work of George Lakoff and Mark Johnson, I propose that embodiment\nprovides many of the inductive biases that are usually described in terms of\ninnate core knowledge. (Please note: this manuscript was written and finalized\nin 2012.)", "published": "2019-11-04T06:17:55Z", "version": 2}, {"aid": "1911.01058", "authors": ["Sheng Shi", "Xinfeng Zhang", "Wei Fan"], "title": "Explaining the Predictions of Any Image Classifier via Decision Trees", "url": "http://arxiv.org/pdf/1911.01058v2", "summary": "Despite outstanding contribution to the significant progress of Artificial\nIntelligence (AI), deep learning models remain mostly black boxes, which are\nextremely weak in explainability of the reasoning process and prediction\nresults. Explainability is not only a gateway between AI and society but also a\npowerful tool to detect flaws in the model and biases in the data. Local\nInterpretable Model-agnostic Explanation (LIME) is a recent approach that uses\nan interpretable model to form a local explanation for the individual\nprediction result. The current implementation of LIME adopts the linear\nregression as its interpretable function. However, being so restricted and\nusually over-simplifying the relationships, linear models fail in situations\nwhere nonlinear associations and interactions exist among features and\nprediction results. This paper implements a decision Tree-based LIME approach,\nwhich uses a decision tree model to form an interpretable representation that\nis locally faithful to the original model. Tree-LIME approach can capture\nnonlinear interactions among features in the data and creates plausible\nexplanations. Various experiments show that the Tree-LIME explanation of\nmultiple black-box models can achieve more reliable performance in terms of\nunderstandability, fidelity, and efficiency.", "published": "2019-11-04T07:31:30Z", "version": 2}, {"aid": "1911.04338", "authors": ["Xue Jiang", "Xiao Zhang", "Dongrui Wu"], "title": "Active Learning for Black-Box Adversarial Attacks in EEG-Based Brain-Computer Interfaces", "url": "http://arxiv.org/pdf/1911.04338v1", "summary": "Deep learning has made significant breakthroughs in many fields, including\nelectroencephalogram (EEG) based brain-computer interfaces (BCIs). However,\ndeep learning models are vulnerable to adversarial attacks, in which\ndeliberately designed small perturbations are added to the benign input samples\nto fool the deep learning model and degrade its performance. This paper\nconsiders transferability-based black-box attacks, where the attacker trains a\nsubstitute model to approximate the target model, and then generates\nadversarial examples from the substitute model to attack the target model.\nLearning a good substitute model is critical to the success of these attacks,\nbut it requires a large number of queries to the target model. We propose a\nnovel framework which uses query synthesis based active learning to improve the\nquery efficiency in training the substitute model. Experiments on three\nconvolutional neural network (CNN) classifiers and three EEG datasets\ndemonstrated that our method can improve the attack success rate with the same\nnumber of queries, or, in other words, our method requires fewer queries to\nachieve a desired attack performance. To our knowledge, this is the first work\nthat integrates active learning and adversarial attacks for EEG-based BCIs.", "published": "2019-11-07T15:00:24Z", "version": 1}, {"aid": "1911.04255", "authors": ["Abhiram Singh", "Ashwin Gumaste"], "title": "Decoding Imagined Speech and Computer Control using Brain Waves", "url": "http://arxiv.org/pdf/1911.04255v4", "summary": "In this work, we explore the possibility of decoding Imagined Speech brain\nwaves using machine learning techniques. We propose a covariance matrix of\nElectroencephalogram channels as input features, projection to tangent space of\ncovariance matrices for obtaining vectors from covariance matrices, principal\ncomponent analysis for dimension reduction of vectors, an artificial\nfeed-forward neural network as a classification model and bootstrap aggregation\nfor creating an ensemble of neural network models. After the classification,\ntwo different Finite State Machines are designed that create an interface for\ncontrolling a computer system using an Imagined Speech-based BCI system. The\nproposed approach is able to decode the Imagined Speech signal with a maximum\nmean classification accuracy of 85% on binary classification task of one long\nword and a short word. We also show that our proposed approach is able to\ndifferentiate between imagined speech brain signals and rest state brain\nsignals with maximum mean classification accuracy of 94%. We compared our\nproposed method with other approaches for decoding imagined speech and show\nthat our approach performs equivalent to the state of the art approach on\ndecoding long vs. short words and outperforms it significantly on the other two\ntasks of decoding three short words and three vowels with an average margin of\n11% and 9%, respectively. We also obtain an information transfer rate of\n21-bits-per-minute when using an IS based system to operate a computer. These\nresults show that the proposed approach is able to decode a wide variety of\nimagined speech signals without any human-designed features.", "published": "2019-11-08T12:18:36Z", "version": 4}, {"aid": "1911.03584", "authors": ["Jean-Baptiste Cordonnier", "Andreas Loukas", "Martin Jaggi"], "title": "On the Relationship between Self-Attention and Convolutional Layers", "url": "http://arxiv.org/pdf/1911.03584v2", "summary": "Recent trends of incorporating attention mechanisms in vision have led\nresearchers to reconsider the supremacy of convolutional layers as a primary\nbuilding block. Beyond helping CNNs to handle long-range dependencies,\nRamachandran et al. (2019) showed that attention can completely replace\nconvolution and achieve state-of-the-art performance on vision tasks. This\nraises the question: do learned attention layers operate similarly to\nconvolutional layers? This work provides evidence that attention layers can\nperform convolution and, indeed, they often learn to do so in practice.\nSpecifically, we prove that a multi-head self-attention layer with sufficient\nnumber of heads is at least as expressive as any convolutional layer. Our\nnumerical experiments then show that self-attention layers attend to pixel-grid\npatterns similarly to CNN layers, corroborating our analysis. Our code is\npublicly available.", "published": "2019-11-08T23:48:38Z", "version": 2}, {"aid": "1911.03599", "authors": ["Yuanyuan Xu", "Wan Yan", "Haixin Sun", "Genke Yang", "Jiliang Luo"], "title": "CenterFace: Joint Face Detection and Alignment Using Face as Point", "url": "http://arxiv.org/pdf/1911.03599v1", "summary": "Face detection and alignment in unconstrained environment is always deployed\non edge devices which have limited memory storage and low computing power. This\npaper proposes a one-stage method named CenterFace to simultaneously predict\nfacial box and landmark location with real-time speed and high accuracy. The\nproposed method also belongs to the anchor free category. This is achieved by:\n(a) learning face existing possibility by the semantic maps, (b) learning\nbounding box, offsets and five landmarks for each position that potentially\ncontains a face. Specifically, the method can run in real-time on a single CPU\ncore and 200 FPS using NVIDIA 2080TI for VGA-resolution images, and can\nsimultaneously achieve superior accuracy (WIDER FACE Val/Test-Easy:\n0.935/0.932, Medium: 0.924/0.921, Hard: 0.875/0.873 and FDDB discontinuous:\n0.980, continuous: 0.732). A demo of CenterFace can be available at\nhttps://github.com/Star-Clouds/CenterFace.", "published": "2019-11-09T03:06:11Z", "version": 1}, {"aid": "1911.05701", "authors": ["Junyi Shen", "Hankz Hankui Zhuo", "Jin Xu", "Bin Zhong", "Sinno Jialin Pan"], "title": "Transfer Value Iteration Networks", "url": "http://arxiv.org/pdf/1911.05701v2", "summary": "Value iteration networks (VINs) have been demonstrated to have a good\ngeneralization ability for reinforcement learning tasks across similar domains.\nHowever, based on our experiments, a policy learned by VINs still fail to\ngeneralize well on the domain whose action space and feature space are not\nidentical to those in the domain where it is trained. In this paper, we propose\na transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such\nthat a learned policy from a source domain can be generalized to a target\ndomain with only limited training data, even if the source domain and the\ntarget domain have domain-specific actions and features. We empirically verify\nthat our proposed TVINs outperform VINs when the source and the target domains\nhave similar but not identical action and feature spaces. Furthermore, we show\nthat the performance improvement is consistent across different environments,\nmaze sizes, dataset sizes as well as different values of hyperparameters such\nas number of iteration and kernel size.", "published": "2019-11-11T08:07:49Z", "version": 2}, {"aid": "1911.07925", "authors": ["Tianfu Li", "Zhibin Zhao", "Chuang Sun", "Li Cheng", "Xuefeng Chen", "Ruqiang Yan", "Robert X. Gao"], "title": "WaveletKernelNet: An Interpretable Deep Neural Network for Industrial Intelligent Diagnosis", "url": "http://arxiv.org/pdf/1911.07925v3", "summary": "Convolutional neural network (CNN), with ability of feature learning and\nnonlinear mapping, has demonstrated its effectiveness in prognostics and health\nmanagement (PHM). However, explanation on the physical meaning of a CNN\narchitecture has rarely been studied. In this paper, a novel wavelet driven\ndeep neural network termed as WaveletKernelNet (WKN) is presented, where a\ncontinuous wavelet convolutional (CWConv) layer is designed to replace the\nfirst convolutional layer of the standard CNN. This enables the first CWConv\nlayer to discover more meaningful filters. Furthermore, only the scale\nparameter and translation parameter are directly learned from raw data at this\nCWConv layer. This provides a very effective way to obtain a customized filter\nbank, specifically tuned for extracting defect-related impact component\nembedded in the vibration signal. In addition, three experimental verification\nusing data from laboratory environment are carried out to verify effectiveness\nof the proposed method for mechanical fault diagnosis. The results show the\nimportance of the designed CWConv layer and the output of CWConv layer is\ninterpretable. Besides, it is found that WKN has fewer parameters, higher fault\nclassification accuracy and faster convergence speed than standard CNN.", "published": "2019-11-12T07:22:56Z", "version": 3}, {"aid": "1911.05031", "authors": ["Maxwell A. Bertolero", "Danielle S. Bassett"], "title": "On the nature of explanations offered by network science: A perspective from and for practicing neuroscientists", "url": "http://arxiv.org/pdf/1911.05031v1", "summary": "Network neuroscience represents the brain as a collection of regions and\ninter-regional connections. Given its ability to formalize systems-level\nmodels, network neuroscience has generated unique explanations of neural\nfunction and behavior. The mechanistic status of these explanations and how\nthey can contribute to and fit within the field of neuroscience as a whole has\nreceived careful treatment from philosophers. However, these philosophical\ncontributions have not yet reached many neuroscientists. Here we complement\nformal philosophical efforts by providing an applied perspective from and for\nneuroscientists. We discuss the mechanistic status of the explanations offered\nby network neuroscience and how they contribute to, enhance, and interdigitate\nwith other types of explanations in neuroscience. In doing so, we rely on\nphilosophical work concerning the role of causality, scale, and mechanisms in\nscientific explanations. In particular, we make the distinction between an\nexplanation and the evidence supporting that explanation, and we argue for a\nscale-free nature of mechanistic explanations. In the course of these\ndiscussions, we hope to provide a useful applied framework in which network\nneuroscience explanations can be exercised across scales and combined with\nother fields of neuroscience to gain deeper insights into the brain and\nbehavior.", "published": "2019-11-12T17:49:10Z", "version": 1}, {"aid": "1911.05063", "authors": ["Krishna Murthy Jatavallabhula", "Edward Smith", "Jean-Francois Lafleche", "Clement Fuji Tsang", "Artem Rozantsev", "Wenzheng Chen", "Tommy Xiang", "Rev Lebaredian", "Sanja Fidler"], "title": "Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research", "url": "http://arxiv.org/pdf/1911.05063v2", "summary": "We present Kaolin, a PyTorch library aiming to accelerate 3D deep learning\nresearch. Kaolin provides efficient implementations of differentiable 3D\nmodules for use in deep learning systems. With functionality to load and\npreprocess several popular 3D datasets, and native functions to manipulate\nmeshes, pointclouds, signed distance functions, and voxel grids, Kaolin\nmitigates the need to write wasteful boilerplate code. Kaolin packages together\nseveral differentiable graphics modules including rendering, lighting, shading,\nand view warping. Kaolin also supports an array of loss functions and\nevaluation metrics for seamless evaluation and provides visualization\nfunctionality to render the 3D results. Importantly, we curate a comprehensive\nmodel zoo comprising many state-of-the-art 3D deep learning architectures, to\nserve as a starting point for future research endeavours. Kaolin is available\nas open-source software at https://github.com/NVIDIAGameWorks/kaolin/.", "published": "2019-11-12T18:47:37Z", "version": 2}, {"aid": "1911.05856", "authors": ["Shunwang Gong", "Lei Chen", "Michael Bronstein", "Stefanos Zafeiriou"], "title": "SpiralNet++: A Fast and Highly Efficient Mesh Convolution Operator", "url": "http://arxiv.org/pdf/1911.05856v1", "summary": "Intrinsic graph convolution operators with differentiable kernel functions\nplay a crucial role in analyzing 3D shape meshes. In this paper, we present a\nfast and efficient intrinsic mesh convolution operator that does not rely on\nthe intricate design of kernel function. We explicitly formulate the order of\naggregating neighboring vertices, instead of learning weights between nodes,\nand then a fully connected layer follows to fuse local geometric structure\ninformation with vertex features. We provide extensive evidence showing that\nmodels based on this convolution operator are easier to train, and can\nefficiently learn invariant shape features. Specifically, we evaluate our\nmethod on three different types of tasks of dense shape correspondence, 3D\nfacial expression classification, and 3D shape reconstruction, and show that it\nsignificantly outperforms state-of-the-art approaches while being significantly\nfaster, without relying on shape descriptors. Our source code is available on\nGitHub.", "published": "2019-11-13T22:59:19Z", "version": 1}, {"aid": "1911.05943", "authors": ["Shashwat Shukla", "Hideaki Shimazaki", "Udayan Ganguly"], "title": "Structured Mean-field Variational Inference and Learning in Winner-take-all Spiking Neural Networks", "url": "http://arxiv.org/pdf/1911.05943v1", "summary": "The Bayesian view of the brain hypothesizes that the brain constructs a\ngenerative model of the world, and uses it to make inferences via Bayes' rule.\nAlthough many types of approximate inference schemes have been proposed for\nhierarchical Bayesian models of the brain, the questions of how these distinct\ninference procedures can be realized by hierarchical networks of spiking\nneurons remains largely unresolved. Based on a previously proposed\nmulti-compartment neuron model in which dendrites perform logarithmic\ncompression, and stochastic spiking winner-take-all (WTA) circuits in which\nfiring probability of each neuron is normalized by activities of other neurons,\nhere we construct Spiking Neural Networks that perform \\emph{structured}\nmean-field variational inference and learning, on hierarchical directed\nprobabilistic graphical models with discrete random variables. In these models,\nwe do away with symmetric synaptic weights previously assumed for\n\\emph{unstructured} mean-field variational inference by learning both the\nfeedback and feedforward weights separately. The resulting online learning\nrules take the form of an error-modulated local Spike-Timing-Dependent\nPlasticity rule. Importantly, we consider two types of WTA circuits in which\nonly one neuron is allowed to fire at a time (hard WTA) or neurons can fire\nindependently (soft WTA), which makes neurons in these circuits operate in\nregimes of temporal and rate coding respectively. We show how the hard WTA\ncircuits can be used to perform Gibbs sampling whereas the soft WTA circuits\ncan be used to implement a message passing algorithm that computes the\nmarginals approximately. Notably, a simple change in the amount of lateral\ninhibition realizes switching between the hard and soft WTA spiking regimes.\nHence the proposed network provides a unified view of the two previously\ndisparate modes of inference and coding by spiking neurons.", "published": "2019-11-14T05:31:11Z", "version": 1}, {"aid": "1911.06276", "authors": ["Federico Bertoni", "Giovanna Citti", "Alessandro Sarti"], "title": "LGN-CNN: a biologically inspired CNN architecture", "url": "http://arxiv.org/pdf/1911.06276v3", "summary": "In this paper we introduce a biologically inspired Convolutional Neural\nNetwork (CNN) architecture called LGN-CNN that has a first convolutional layer\ncomposed by a single filter that mimics the role of the Lateral Geniculate\nNucleus (LGN). The first layer of the neural network shows a rotational\nsymmetric pattern justified by the structure of the net itself that turns up to\nbe an approximation of a Laplacian of Gaussian (LoG). The latter function is in\nturn a good approximation of the receptive field profiles (RFPs) of the cells\nin the LGN. The analogy with the visual system is established, emerging\ndirectly from the architecture of the neural network. A proof of rotation\ninvariance of the first layer is given on a fixed LGN-CNN architecture and the\ncomputational results are shown. Thus, contrast invariance capability of the\nLGN-CNN is investigated and a comparison between the Retinex effects of the\nfirst layer of LGN-CNN and the Retinex effects of a LoG is provided on\ndifferent images. A statistical study is done on the filters of the second\nconvolutional layer with respect to biological data. In conclusion, the model\nwe have introduced approximates well the RFPs of both LGN and V1 attaining\nsimilar behavior as regards long range connections of LGN cells that show\nRetinex effects.", "published": "2019-11-14T18:00:14Z", "version": 3}, {"aid": "1911.06602", "authors": ["Toby B. St Clere Smithe"], "title": "Radically Compositional Cognitive Concepts", "url": "http://arxiv.org/pdf/1911.06602v1", "summary": "Despite ample evidence that our concepts, our cognitive architecture, and\nmathematics itself are all deeply compositional, few models take advantage of\nthis structure. We therefore propose a radically compositional approach to\ncomputational neuroscience, drawing on the methods of applied category theory.\nWe describe how these tools grant us a means to overcome complexity and improve\ninterpretability, and supply a rigorous common language for scientific\nmodelling, analogous to the type theories of computer science. As a case study,\nwe sketch how to translate from compositional narrative concepts to neural\ncircuits and back again.", "published": "2019-11-14T18:20:36Z", "version": 1}, {"aid": "1911.08583", "authors": ["Jahan N. Schad"], "title": "Mirror Neuron; A Beautiful Unnecessary Concept", "url": "http://arxiv.org/pdf/1911.08583v1", "summary": "The mirror neuron theory that has enjoyed continued validations was developed\nwith no particular attention to the phenomenon of the vision. Understandably\nthe perception of vision has always been thought to happen, naturally, as that\nfor any of the other four senses. However, the reality that underlies this\npresumption is by no means obvious; vision perception is based on remote\nsensing of the ecology, fundamentally different form that of the other senses,\nwhich have tactile stimulation origin (contact with matter). While its reality,\nas explicated here, explains why the above presumption is true, it also bears\nheavily on the mirror neuron theory: the revelation of the nature of vision\nmakes mirror neurons unnecessary. The extensive cognitive neurosciences\ninvestigation of primates and humans, over the past three decades, have\nexperimentally validated the theory of mirror neurons which had been put\nforward early in the period (1980s and 1990s) based on the results of cognitive\nresearch experiments on the macaque monkeys. Based on further experimental\nworks, phenomena such as learning, empathy, and some aspects of survival, are\nascribed to the operations of this class of additional neurons. Here I reason\nthat all the results of the efforts of the proponents of the theory can, not\nonly find explanation in the context of the new theory of vision but also\nprovide support for it. This new take of the phenomenon of vision is developed\nbased on the nature of the experimental methods that have succeeded in\ndeveloping some measure of vision for the blinds, and the inferences from the\nvery likely nature of the computational strategy of the brain. I present\nevidence that the mental phenomena, which rendered the claim of the mirror\nneurons, are in essence the results of subjects beings variably touched by\ntheir ecology, through the coherent tactile operation of all senses.", "published": "2019-11-14T18:48:44Z", "version": 1}, {"aid": "1911.06396", "authors": ["V\u00edtor Albiero", "Kevin W. Bowyer", "Kushal Vangara", "Michael C. King"], "title": "Does Face Recognition Accuracy Get Better With Age? Deep Face Matchers Say No", "url": "http://arxiv.org/pdf/1911.06396v1", "summary": "Previous studies generally agree that face recognition accuracy is higher for\nolder persons than for younger persons. But most previous studies were before\nthe wave of deep learning matchers, and most considered accuracy only in terms\nof the verification rate for genuine pairs. This paper investigates accuracy\nfor age groups 16-29, 30-49 and 50-70, using three modern deep CNN matchers,\nand considers differences in the impostor and genuine distributions as well as\nverification rates and ROC curves. We find that accuracy is lower for older\npersons and higher for younger persons. In contrast, a pre deep learning\nmatcher on the same dataset shows the traditional result of higher accuracy for\nolder persons, although its overall accuracy is much lower than that of the\ndeep learning matchers. Comparing the impostor and genuine distributions, we\nconclude that impostor scores have a larger effect than genuine scores in\ncausing lower accuracy for the older age group. We also investigate the effects\nof training data across the age groups. Our results show that fine-tuning the\ndeep CNN models on additional images of older persons actually lowers accuracy\nfor the older age group. Also, we fine-tune and train from scratch two models\nusing age-balanced training datasets, and these results also show lower\naccuracy for older age group. These results argue that the lower accuracy for\nthe older age group is not due to imbalance in the original training data.", "published": "2019-11-14T21:52:54Z", "version": 1}, {"aid": "1911.08585", "authors": ["Thomas Mesnard", "Gaetan Vignoud", "Joao Sacramento", "Walter Senn", "Yoshua Bengio"], "title": "Ghost Units Yield Biologically Plausible Backprop in Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.08585v1", "summary": "In the past few years, deep learning has transformed artificial intelligence\nresearch and led to impressive performance in various difficult tasks. However,\nit is still unclear how the brain can perform credit assignment across many\nareas as efficiently as backpropagation does in deep neural networks. In this\npaper, we introduce a model that relies on a new role for a neuronal inhibitory\nmachinery, referred to as ghost units. By cancelling the feedback coming from\nthe upper layer when no target signal is provided to the top layer, the ghost\nunits enables the network to backpropagate errors and do efficient credit\nassignment in deep structures. While considering one-compartment neurons and\nrequiring very few biological assumptions, it is able to approximate the error\ngradient and achieve good performance on classification tasks. Error\nbackpropagation occurs through the recurrent dynamics of the network and thanks\nto biologically plausible local learning rules. In particular, it does not\nrequire separate feedforward and feedback circuits. Different mechanisms for\ncancelling the feedback were studied, ranging from complete duplication of the\nconnectivity by long term processes to online replication of the feedback\nactivity. This reduced system combines the essential elements to have a working\nbiologically abstracted analogue of backpropagation with a simple formulation\nand proofs of the associated results. Therefore, this model is a step towards\nunderstanding how learning and memory are implemented in cortical multilayer\nstructures, but it also raises interesting perspectives for neuromorphic\nhardware.", "published": "2019-11-15T17:47:00Z", "version": 1}, {"aid": "1911.06786", "authors": ["Akshay Kulkarni", "Navid Panchi", "Sharath Chandra Raparthy", "Shital Chiddarwar"], "title": "Data Efficient Stagewise Knowledge Distillation", "url": "http://arxiv.org/pdf/1911.06786v3", "summary": "Despite the success of Deep Learning (DL), the deployment of modern DL models\nrequiring large computational power poses a significant problem for\nresource-constrained systems. This necessitates building compact networks that\nreduce computations while preserving performance. Traditional Knowledge\nDistillation (KD) methods that transfer knowledge from teacher to student (a)\nuse a single-stage and (b) require the whole data set while distilling the\nknowledge to the student. In this work, we propose a new method called\nStagewise Knowledge Distillation (SKD) which builds on traditional KD methods\nby progressive stagewise training to leverage the knowledge gained from the\nteacher, resulting in data-efficient distillation process. We evaluate our\nmethod on classification and semantic segmentation tasks. We show, across the\ntested tasks, significant performance gains even with a fraction of the data\nused in distillation, without compromising on the metric. We also compare our\nmethod with existing KD techniques and show that SKD outperforms them.\nMoreover, our method can be viewed as a generalized model compression technique\nthat complements other model compression methods such as quantization or\npruning.", "published": "2019-11-15T18:06:26Z", "version": 3}, {"aid": "1911.07072", "authors": ["Xuefei Cao", "Bor-Chun Chen", "Ser-Nam Lim"], "title": "Unsupervised Deep Metric Learning via Auxiliary Rotation Loss", "url": "http://arxiv.org/pdf/1911.07072v1", "summary": "Deep metric learning is an important area due to its applicability to many\ndomains such as image retrieval and person re-identification. The main drawback\nof such models is the necessity for labeled data. In this work, we propose to\ngenerate pseudo-labels for deep metric learning directly from clustering\nassignment and we introduce unsupervised deep metric learning (UDML)\nregularized by a self-supervision (SS) task. In particular, we propose to\nregularize the training process by predicting image rotations. Our method\n(UDML-SS) jointly learns discriminative embeddings, unsupervised clustering\nassignments of the embeddings, as well as a self-supervised pretext task.\nUDML-SS iteratively cluster embeddings using traditional clustering algorithm\n(e.g., k-means), and sampling training pairs based on the cluster assignment\nfor metric learning, while optimizing self-supervised pretext task in a\nmulti-task fashion. The role of self-supervision is to stabilize the training\nprocess and encourages the model to learn meaningful feature representations\nthat are not distorted due to unreliable clustering assignments. The proposed\nmethod performs well on standard benchmarks for metric learning, where it\noutperforms current state-of-the-art approaches by a large margin and it also\nshows competitive performance with various metric learning loss functions.", "published": "2019-11-16T18:28:45Z", "version": 1}, {"aid": "1911.07086", "authors": ["Saeid Asgari Taghanaki", "Kumar Abhishek", "Ghassan Hamarneh"], "title": "Signed Input Regularization", "url": "http://arxiv.org/pdf/1911.07086v3", "summary": "Over-parameterized deep models usually over-fit to a given training\ndistribution, which makes them sensitive to small changes and\nout-of-distribution samples at inference time, leading to low generalization\nperformance. To this end, several model-based and randomized data-dependent\nregularization methods are applied, such as data augmentation, which prevents a\nmodel from memorizing the training distribution. Instead of the random\ntransformation of the input images, we propose SIGN, a new regularization\nmethod, which modifies the input variables using a linear transformation by\nestimating each variable's contribution to the final prediction. Our proposed\ntechnique maps the input data to a new manifold where the less important\nvariables are de-emphasized. To test the effectiveness of the proposed idea and\ncompare it with other competing methods, we design several test scenarios, such\nas classification performance, uncertainty, out-of-distribution, and robustness\nanalyses. We compare the methods using three different datasets and four\nmodels. We find that SIGN encourages more compact class representations, which\nresults in the model's robustness to random corruptions and out-of-distribution\nsamples while also simultaneously achieving superior performance on normal data\ncompared to other competing methods. Our experiments also demonstrate the\nsuccessful transferability of the SIGN samples from one model to another.", "published": "2019-11-16T19:56:43Z", "version": 3}, {"aid": "1911.07346", "authors": ["Haichao Yu", "Haoxiang Li", "Honghui Shi", "Thomas S. Huang", "Gang Hua"], "title": "Any-Precision Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.07346v2", "summary": "We present any-precision deep neural networks (DNNs), which are trained with\na new method that allows the learned DNNs to be flexible in numerical precision\nduring inference. The same model in runtime can be flexibly and directly set to\ndifferent bit-widths, by truncating the least significant bits, to support\ndynamic speed and accuracy trade-off. When all layers are set to low-bits, we\nshow that the model achieved accuracy comparable to dedicated models trained at\nthe same precision. This nice property facilitates flexible deployment of deep\nlearning models in real-world applications, where in practice trade-offs\nbetween model accuracy and runtime efficiency are often sought. Previous\nliterature presents solutions to train models at each individual fixed\nefficiency/accuracy trade-off point. But how to produce a model flexible in\nruntime precision is largely unexplored. When the demand of efficiency/accuracy\ntrade-off varies from time to time or even dynamically changes in runtime, it\nis infeasible to re-train models accordingly, and the storage budget may forbid\nkeeping multiple models. Our proposed framework achieves this flexibility\nwithout performance degradation. More importantly, we demonstrate that this\nachievement is agnostic to model architectures and applicable to multiple\nvision tasks. Our code is released at\nhttps://github.com/SHI-Labs/Any-Precision-DNNs.", "published": "2019-11-17T21:35:32Z", "version": 2}, {"aid": "1911.07381", "authors": ["Meng Zheng", "Srikrishna Karanam", "Terrence Chen", "Richard J. Radke", "Ziyan Wu"], "title": "Visual Similarity Attention", "url": "http://arxiv.org/pdf/1911.07381v2", "summary": "While there has been substantial progress in learning suitable distance\nmetrics, these techniques in general lack transparency and decision reasoning,\ni.e., explaining why the input set of images is similar or dissimilar. In this\nwork, we solve this key problem by proposing the first method to generate\ngeneric visual similarity explanations with gradient-based attention. We\ndemonstrate that our technique is agnostic to the specific similarity model\ntype, e.g., we show applicability to Siamese, triplet, and quadruplet models.\nFurthermore, we make our proposed similarity attention a principled part of the\nlearning process, resulting in a new paradigm for learning similarity\nfunctions. We demonstrate that our learning mechanism results in more\ngeneralizable, as well as explainable, similarity models. Finally, we\ndemonstrate the generality of our framework by means of experiments on a\nvariety of tasks, including image retrieval, person re-identification, and\nlow-shot semantic segmentation.", "published": "2019-11-18T00:46:40Z", "version": 2}, {"aid": "1911.07532", "authors": ["Michael Poli", "Stefano Massaroli", "Junyoung Park", "Atsushi Yamashita", "Hajime Asama", "Jinkyoo Park"], "title": "Graph Neural Ordinary Differential Equations", "url": "http://arxiv.org/pdf/1911.07532v4", "summary": "We introduce the framework of continuous--depth graph neural networks (GNNs).\nGraph neural ordinary differential equations (GDEs) are formalized as the\ncounterpart to GNNs where the input-output relationship is determined by a\ncontinuum of GNN layers, blending discrete topological structures and\ndifferential equations. The proposed framework is shown to be compatible with\nvarious static and autoregressive GNN models. Results prove general\neffectiveness of GDEs: in static settings they offer computational advantages\nby incorporating numerical methods in their forward pass; in dynamic settings,\non the other hand, they are shown to improve performance by exploiting the\ngeometry of the underlying dynamics.", "published": "2019-11-18T10:46:15Z", "version": 4}, {"aid": "1911.07956", "authors": ["Xiaoxia Wu", "Edgar Dobriban", "Tongzheng Ren", "Shanshan Wu", "Zhiyuan Li", "Suriya Gunasekar", "Rachel Ward", "Qiang Liu"], "title": "Implicit Regularization and Convergence for Weight Normalization", "url": "http://arxiv.org/pdf/1911.07956v5", "summary": "Normalization methods such as batch [Ioffe and Szegedy, 2015], weight\n[Salimansand Kingma, 2016], instance [Ulyanov et al., 2016], and layer\nnormalization [Baet al., 2016] have been widely used in modern machine\nlearning. Here, we study the weight normalization (WN) method [Salimans and\nKingma, 2016] and a variant called reparametrized projected gradient descent\n(rPGD) for overparametrized least-squares regression. WN and rPGD reparametrize\nthe weights with a scale g and a unit vector w and thus the objective function\nbecomes non-convex. We show that this non-convex formulation has beneficial\nregularization effects compared to gradient descent on the original objective.\nThese methods adaptively regularize the weights and converge close to the\nminimum l2 norm solution, even for initializations far from zero. For certain\nstepsizes of g and w , we show that they can converge close to the minimum norm\nsolution. This is different from the behavior of gradient descent, which\nconverges to the minimum norm solution only when started at a point in the\nrange space of the feature matrix, and is thus more sensitive to\ninitialization.", "published": "2019-11-18T21:10:21Z", "version": 5}, {"aid": "1911.10979", "authors": ["Yong-Goo Shin", "Yoon-Jae Yeo", "Sung-Jea Ko"], "title": "Simple yet Effective Way for Improving the Performance of GAN", "url": "http://arxiv.org/pdf/1911.10979v4", "summary": "In adversarial learning, discriminator often fails to guide the generator\nsuccessfully since it distinguishes between real and generated images using\nsilly or non-robust features. To alleviate this problem, this brief presents a\nsimple but effective way that improves the performance of generative\nadversarial network (GAN) without imposing the training overhead or modifying\nthe network architectures of existing methods. The proposed method employs a\nnovel cascading rejection (CR) module for discriminator, which extracts\nmultiple non-overlapped features in an iterative manner using the vector\nrejection operation. Since the extracted diverse features prevent the\ndiscriminator from concentrating on non-meaningful features, the discriminator\ncan guide the generator effectively to produce the images that are more similar\nto the real images. In addition, since the proposed CR module requires only a\nfew simple vector operations, it can be readily applied to existing frameworks\nwith marginal training overheads. Quantitative evaluations on various datasets\nincluding CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet confirm that the\nproposed method significantly improves the performance of GAN and conditional\nGAN in terms of Frechet inception distance (FID) indicating the diversity and\nvisual appearance of the generated images.", "published": "2019-11-19T10:31:19Z", "version": 4}, {"aid": "1911.08265", "authors": ["Julian Schrittwieser", "Ioannis Antonoglou", "Thomas Hubert", "Karen Simonyan", "Laurent Sifre", "Simon Schmitt", "Arthur Guez", "Edward Lockhart", "Demis Hassabis", "Thore Graepel", "Timothy Lillicrap", "David Silver"], "title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model", "url": "http://arxiv.org/pdf/1911.08265v2", "summary": "Constructing agents with planning capabilities has long been one of the main\nchallenges in the pursuit of artificial intelligence. Tree-based planning\nmethods have enjoyed huge success in challenging domains, such as chess and Go,\nwhere a perfect simulator is available. However, in real-world problems the\ndynamics governing the environment are often complex and unknown. In this work\nwe present the MuZero algorithm which, by combining a tree-based search with a\nlearned model, achieves superhuman performance in a range of challenging and\nvisually complex domains, without any knowledge of their underlying dynamics.\nMuZero learns a model that, when applied iteratively, predicts the quantities\nmost directly relevant to planning: the reward, the action-selection policy,\nand the value function. When evaluated on 57 different Atari games - the\ncanonical video game environment for testing AI techniques, in which\nmodel-based planning approaches have historically struggled - our new algorithm\nachieved a new state of the art. When evaluated on Go, chess and shogi, without\nany knowledge of the game rules, MuZero matched the superhuman performance of\nthe AlphaZero algorithm that was supplied with the game rules.", "published": "2019-11-19T13:58:52Z", "version": 2}, {"aid": "1911.08509", "authors": ["Dami\u00e1n G. Hern\u00e1ndez", "Samuel J. Sober", "Ilya Nemenman"], "title": "Unsupervised Bayesian Ising Approximation for revealing the neural dictionary in songbirds", "url": "http://arxiv.org/pdf/1911.08509v1", "summary": "The problem of deciphering how low-level patterns (action potentials in the\nbrain, amino acids in a protein, etc.) drive high-level biological features\n(sensorimotor behavior, enzymatic function) represents the central challenge of\nquantitative biology. The lack of general methods for doing so from the size of\ndatasets that can be collected experimentally severely limits our understanding\nof the biological world. For example, in neuroscience, some sensory and motor\ncodes have been shown to consist of precisely timed multi-spike patterns.\nHowever, the combinatorial complexity of such pattern codes have precluded\ndevelopment of methods for their comprehensive analysis. Thus, just as it is\nhard to predict a protein's function based on its sequence, we still do not\nunderstand how to accurately predict an organism's behavior based on neural\nactivity. Here we derive a method for solving this class of problems. We\ndemonstrate its utility in an application to neural data, detecting precisely\ntimed spike patterns that code for specific motor behaviors in a songbird vocal\nsystem. Our method detects such codewords with an arbitrary number of spikes,\ndoes so from small data sets, and accounts for dependencies in occurrences of\ncodewords. Detecting such dictionaries of important spike patterns --- rather\nthan merely identifying the timescale on which such patterns exist, as in some\nprior approaches --- opens the door for understanding fine motor control and\nthe neural bases of sensorimotor learning in animals. For example, for the\nfirst time, we identify differences in encoding motor exploration versus\ntypical behavior. Crucially, our method can be used not only for analysis of\nneural systems, but also for understanding the structure of correlations in\nother biological and nonbiological datasets.", "published": "2019-11-19T19:11:49Z", "version": 1}, {"aid": "1911.08691", "authors": ["Xiaolong Hu", "Zhulin An", "Chuanguang Yang", "Hui Zhu", "Kaiqaing Xu", "Yongjun Xu"], "title": "DRNet: Dissect and Reconstruct the Convolutional Neural Network via Interpretable Manners", "url": "http://arxiv.org/pdf/1911.08691v2", "summary": "Convolutional neural networks (ConvNets) are widely used in real life. People\nusually use ConvNets which pre-trained on a fixed number of classes. However,\nfor different application scenarios, we usually do not need all of the classes,\nwhich means ConvNets are redundant when dealing with these tasks. This paper\nfocuses on the redundancy of ConvNet channels. We proposed a novel idea: using\nan interpretable manner to find the most important channels for every single\nclass (dissect), and dynamically run channels according to classes in need\n(reconstruct). For VGG16 pre-trained on CIFAR-10, we only run 11\\% parameters\nfor two-classes sub-tasks on average with negligible accuracy loss. For VGG16\npre-trained on ImageNet, our method averagely gains 14.29\\% accuracy promotion\nfor two-classes sub-tasks. In addition, analysis show that our method captures\nsome semantic meanings of channels, and uses the context information more\ntargeted for sub-tasks of ConvNets.", "published": "2019-11-20T03:52:28Z", "version": 2}, {"aid": "1911.08764", "authors": ["Matteo Testa", "Arslan Ali", "Tiziano Bianchi", "Enrico Magli"], "title": "Learning mappings onto regularized latent spaces for biometric authentication", "url": "http://arxiv.org/pdf/1911.08764v1", "summary": "We propose a novel architecture for generic biometric authentication based on\ndeep neural networks: RegNet. Differently from other methods, RegNet learns a\nmapping of the input biometric traits onto a target distribution in a\nwell-behaved space in which users can be separated by means of simple and\ntunable boundaries. More specifically, authorized and unauthorized users are\nmapped onto two different and well behaved Gaussian distributions. The novel\napproach of learning the mapping instead of the boundaries further avoids the\nproblem encountered in typical classifiers for which the learnt boundaries may\nbe complex and difficult to analyze. RegNet achieves high performance in terms\nof security metrics such as Equal Error Rate (EER), False Acceptance Rate (FAR)\nand Genuine Acceptance Rate (GAR). The experiments we conducted on publicly\navailable datasets of face and fingerprint confirm the effectiveness of the\nproposed system.", "published": "2019-11-20T08:40:44Z", "version": 1}, {"aid": "1911.09071", "authors": ["Katherine L. Hermann", "Ting Chen", "Simon Kornblith"], "title": "The Origins and Prevalence of Texture Bias in Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1911.09071v3", "summary": "Recent work has indicated that, unlike humans, ImageNet-trained CNNs tend to\nclassify images by texture rather than by shape. How pervasive is this bias,\nand where does it come from? We find that, when trained on datasets of images\nwith conflicting shape and texture, CNNs learn to classify by shape at least as\neasily as by texture. What factors, then, produce the texture bias in CNNs\ntrained on ImageNet? Different unsupervised training objectives and different\narchitectures have small but significant and largely independent effects on the\nlevel of texture bias. However, all objectives and architectures still lead to\nmodels that make texture-based classification decisions a majority of the time,\neven if shape information is decodable from their hidden representations. The\neffect of data augmentation is much larger. By taking less aggressive random\ncrops at training time and applying simple, naturalistic augmentation (color\ndistortion, noise, and blur), we train models that classify ambiguous images by\nshape a majority of the time, and outperform baselines on out-of-distribution\ntest sets. Our results indicate that apparent differences in the way humans and\nImageNet-trained CNNs process images may arise not primarily from differences\nin their internal workings, but from differences in the data that they see.", "published": "2019-11-20T18:16:38Z", "version": 3}, {"aid": "1911.09257", "authors": ["Andrew Hryniowski", "Alexander Wong"], "title": "DeepLABNet: End-to-end Learning of Deep Radial Basis Networks with Fully Learnable Basis Functions", "url": "http://arxiv.org/pdf/1911.09257v1", "summary": "From fully connected neural networks to convolutional neural networks, the\nlearned parameters within a neural network have been primarily relegated to the\nlinear parameters (e.g., convolutional filters). The non-linear functions\n(e.g., activation functions) have largely remained, with few exceptions in\nrecent years, parameter-less, static throughout training, and seen limited\nvariation in design. Largely ignored by the deep learning community, radial\nbasis function (RBF) networks provide an interesting mechanism for learning\nmore complex non-linear activation functions in addition to the linear\nparameters in a network. However, the interest in RBF networks has waned over\ntime due to the difficulty of integrating RBFs into more complex deep neural\nnetwork architectures in a tractable and stable manner. In this work, we\npresent a novel approach that enables end-to-end learning of deep RBF networks\nwith fully learnable activation basis functions in an automatic and tractable\nmanner. We demonstrate that our approach for enabling the use of learnable\nactivation basis functions in deep neural networks, which we will refer to as\nDeepLABNet, is an effective tool for automated activation function learning\nwithin complex network architectures.", "published": "2019-11-21T03:06:15Z", "version": 1}, {"aid": "1911.09287", "authors": ["Adam Dziedzic", "John Paparrizos", "Sanjay Krishnan", "Aaron Elmore", "Michael Franklin"], "title": "Band-limited Training and Inference for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1911.09287v1", "summary": "The convolutional layers are core building blocks of neural network\narchitectures. In general, a convolutional filter applies to the entire\nfrequency spectrum of the input data. We explore artificially constraining the\nfrequency spectra of these filters and data, called band-limiting, during\ntraining. The frequency domain constraints apply to both the feed-forward and\nback-propagation steps. Experimentally, we observe that Convolutional Neural\nNetworks (CNNs) are resilient to this compression scheme and results suggest\nthat CNNs learn to leverage lower-frequency components. In particular, we\nfound: (1) band-limited training can effectively control the resource usage\n(GPU and memory); (2) models trained with band-limited layers retain high\nprediction accuracy; and (3) requires no modification to existing training\nalgorithms or neural network architectures to use unlike other compression\nschemes.", "published": "2019-11-21T04:43:02Z", "version": 1}, {"aid": "1911.09723", "authors": ["Erich Elsen", "Marat Dukhan", "Trevor Gale", "Karen Simonyan"], "title": "Fast Sparse ConvNets", "url": "http://arxiv.org/pdf/1911.09723v1", "summary": "Historically, the pursuit of efficient inference has been one of the driving\nforces behind research into new deep learning architectures and building\nblocks. Some recent examples include: the squeeze-and-excitation module,\ndepthwise separable convolutions in Xception, and the inverted bottleneck in\nMobileNet v2. Notably, in all of these cases, the resulting building blocks\nenabled not only higher efficiency, but also higher accuracy, and found wide\nadoption in the field. In this work, we further expand the arsenal of efficient\nbuilding blocks for neural network architectures; but instead of combining\nstandard primitives (such as convolution), we advocate for the replacement of\nthese dense primitives with their sparse counterparts. While the idea of using\nsparsity to decrease the parameter count is not new, the conventional wisdom is\nthat this reduction in theoretical FLOPs does not translate into real-world\nefficiency gains. We aim to correct this misconception by introducing a family\nof efficient sparse kernels for ARM and WebAssembly, which we open-source for\nthe benefit of the community as part of the XNNPACK library. Equipped with our\nefficient implementation of sparse primitives, we show that sparse versions of\nMobileNet v1, MobileNet v2 and EfficientNet architectures substantially\noutperform strong dense baselines on the efficiency-accuracy curve. On\nSnapdragon 835 our sparse networks outperform their dense equivalents by\n$1.3-2.4\\times$ -- equivalent to approximately one entire generation of\nMobileNet-family improvement. We hope that our findings will facilitate wider\nadoption of sparsity as a tool for creating efficient and accurate deep\nlearning architectures.", "published": "2019-11-21T19:48:14Z", "version": 1}, {"aid": "1911.09737", "authors": ["Saurabh Singh", "Shankar Krishnan"], "title": "Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.09737v2", "summary": "Batch Normalization (BN) uses mini-batch statistics to normalize the\nactivations during training, introducing dependence between mini-batch\nelements. This dependency can hurt the performance if the mini-batch size is\ntoo small, or if the elements are correlated. Several alternatives, such as\nBatch Renormalization and Group Normalization (GN), have been proposed to\naddress this issue. However, they either do not match the performance of BN for\nlarge batches, or still exhibit degradation in performance for smaller batches,\nor introduce artificial constraints on the model architecture. In this paper we\npropose the Filter Response Normalization (FRN) layer, a novel combination of a\nnormalization and an activation function, that can be used as a replacement for\nother normalizations and activations. Our method operates on each activation\nchannel of each batch element independently, eliminating the dependency on\nother batch elements. Our method outperforms BN and other alternatives in a\nvariety of settings for all batch sizes. FRN layer performs $\\approx 0.7-1.0\\%$\nbetter than BN on top-1 validation accuracy with large mini-batch sizes for\nImagenet classification using InceptionV3 and ResnetV2-50 architectures.\nFurther, it performs $>1\\%$ better than GN on the same problem in the small\nmini-batch size regime. For object detection problem on COCO dataset, FRN layer\noutperforms all other methods by at least $0.3-0.5\\%$ in all batch size\nregimes.", "published": "2019-11-21T20:32:04Z", "version": 2}, {"aid": "1911.09738", "authors": ["Siyuan Qiao", "Huiyu Wang", "Chenxi Liu", "Wei Shen", "Alan Yuille"], "title": "Rethinking Normalization and Elimination Singularity in Neural Networks", "url": "http://arxiv.org/pdf/1911.09738v1", "summary": "In this paper, we study normalization methods for neural networks from the\nperspective of elimination singularity. Elimination singularities correspond to\nthe points on the training trajectory where neurons become consistently\ndeactivated. They cause degenerate manifolds in the loss landscape which will\nslow down training and harm model performances. We show that channel-based\nnormalizations (e.g. Layer Normalization and Group Normalization) are unable to\nguarantee a far distance from elimination singularities, in contrast with Batch\nNormalization which by design avoids models from getting too close to them. To\naddress this issue, we propose BatchChannel Normalization (BCN), which uses\nbatch knowledge to avoid the elimination singularities in the training of\nchannel-normalized models. Unlike Batch Normalization, BCN is able to run in\nboth large-batch and micro-batch training settings. The effectiveness of BCN is\nverified on many tasks, including image classification, object detection,\ninstance segmentation, and semantic segmentation. The code is here:\nhttps://github.com/joe-siyuan-qiao/Batch-Channel-Normalization.", "published": "2019-11-21T20:36:04Z", "version": 1}, {"aid": "1911.09976", "authors": ["Xinshao Wang", "Elyor Kodirov", "Yang Hua", "Neil Robertson"], "title": "Instance Cross Entropy for Deep Metric Learning", "url": "http://arxiv.org/pdf/1911.09976v1", "summary": "Loss functions play a crucial role in deep metric learning thus a variety of\nthem have been proposed. Some supervise the learning process by pairwise or\ntripletwise similarity constraints while others take advantage of structured\nsimilarity information among multiple data points. In this work, we approach\ndeep metric learning from a novel perspective. We propose instance cross\nentropy (ICE) which measures the difference between an estimated instance-level\nmatching distribution and its ground-truth one. ICE has three main appealing\nproperties. Firstly, similar to categorical cross entropy (CCE), ICE has clear\nprobabilistic interpretation and exploits structured semantic similarity\ninformation for learning supervision. Secondly, ICE is scalable to infinite\ntraining data as it learns on mini-batches iteratively and is independent of\nthe training set size. Thirdly, motivated by our relative weight analysis,\nseamless sample reweighting is incorporated. It rescales samples' gradients to\ncontrol the differentiation degree over training examples instead of truncating\nthem by sample mining. In addition to its simplicity and intuitiveness,\nextensive experiments on three real-world benchmarks demonstrate the\nsuperiority of ICE.", "published": "2019-11-22T11:12:48Z", "version": 1}, {"aid": "1911.10129", "authors": ["Karthik Gopinath", "Christian Desrosiers", "Herve Lombaert"], "title": "Learnable Pooling in Graph Convolution Networks for Brain Surface Analysis", "url": "http://arxiv.org/pdf/1911.10129v1", "summary": "Brain surface analysis is essential to neuroscience, however, the complex\ngeometry of the brain cortex hinders computational methods for this task. The\ndifficulty arises from a discrepancy between 3D imaging data, which is\nrepresented in Euclidean space, and the non-Euclidean geometry of the\nhighly-convoluted brain surface. Recent advances in machine learning have\nenabled the use of neural networks for non-Euclidean spaces. These facilitate\nthe learning of surface data, yet pooling strategies often remain constrained\nto a single fixed-graph. This paper proposes a new learnable graph pooling\nmethod for processing multiple surface-valued data to output subject-based\ninformation. The proposed method innovates by learning an intrinsic aggregation\nof graph nodes based on graph spectral embedding. We illustrate the advantages\nof our approach with in-depth experiments on two large-scale benchmark\ndatasets. The flexibility of the pooling strategy is evaluated on four\ndifferent prediction tasks, namely, subject-sex classification, regression of\ncortical region sizes, classification of Alzheimer's disease stages, and brain\nage regression. Our experiments demonstrate the superiority of our learnable\npooling approach compared to other pooling techniques for graph convolution\nnetworks, with results improving the state-of-the-art in brain surface\nanalysis.", "published": "2019-11-22T16:34:58Z", "version": 1}, {"aid": "1911.10477", "authors": ["Jiancheng Yang", "Xiaoyang Huang", "Yi He", "Jingwei Xu", "Canqian Yang", "Guozheng Xu", "Bingbing Ni"], "title": "Reinventing 2D Convolutions for 3D Images", "url": "http://arxiv.org/pdf/1911.10477v4", "summary": "There have been considerable debates over 2D and 3D representation learning\non 3D medical images. 2D approaches could benefit from large-scale 2D\npretraining, whereas they are generally weak in capturing large 3D contexts. 3D\napproaches are natively strong in 3D contexts, however few publicly available\n3D medical dataset is large and diverse enough for universal 3D pretraining.\nEven for hybrid (2D + 3D) approaches, the intrinsic disadvantages within the 2D\n/ 3D parts still exist. In this study, we bridge the gap between 2D and 3D\nconvolutions by reinventing the 2D convolutions. We propose ACS\n(axial-coronal-sagittal) convolutions to perform natively 3D representation\nlearning, while utilizing the pretrained weights on 2D datasets. In ACS\nconvolutions, 2D convolution kernels are split by channel into three parts, and\nconvoluted separately on the three views (axial, coronal and sagittal) of 3D\nrepresentations. Theoretically, ANY 2D CNN (ResNet, DenseNet, or DeepLab) is\nable to be converted into a 3D ACS CNN, with pretrained weight of a same\nparameter size. Extensive experiments on several medical benchmarks (including\nclassification, segmentation and detection tasks) validate the consistent\nsuperiority of the pretrained ACS CNNs, over the 2D / 3D CNN counterparts with\n/ without pretraining. Even without pretraining, the ACS convolution can be\nused as a plug-and-play replacement of standard 3D convolution, with smaller\nmodel size and less computation.", "published": "2019-11-24T09:05:06Z", "version": 4}, {"aid": "1911.10538", "authors": ["Ori Nizan", "Ayellet Tal"], "title": "Breaking the cycle -- Colleagues are all you need", "url": "http://arxiv.org/pdf/1911.10538v2", "summary": "This paper proposes a novel approach to performing image-to-image translation\nbetween unpaired domains. Rather than relying on a cycle constraint, our method\ntakes advantage of collaboration between various GANs. This results in a\nmulti-modal method, in which multiple optional and diverse images are produced\nfor a given image. Our model addresses some of the shortcomings of classical\nGANs: (1) It is able to remove large objects, such as glasses. (2) Since it\ndoes not need to support the cycle constraint, no irrelevant traces of the\ninput are left on the generated image. (3) It manages to translate between\ndomains that require large shape modifications. Our results are shown to\noutperform those generated by state-of-the-art methods for several challenging\napplications on commonly-used datasets, both qualitatively and quantitatively.", "published": "2019-11-24T14:43:45Z", "version": 2}, {"aid": "1911.10572", "authors": ["Yongzhe Yan", "Stefan Duffner", "Priyanka Phutane", "Anthony Berthelier", "Christophe Blanc", "Christophe Garcia", "Thierry Chateau"], "title": "2D Wasserstein Loss for Robust Facial Landmark Detection", "url": "http://arxiv.org/pdf/1911.10572v2", "summary": "The recent performance of facial landmark detection has been significantly\nimproved by using deep Convolutional Neural Networks (CNNs), especially the\nHeatmap Regression Models (HRMs). Although their performance on common\nbenchmark datasets has reached a high level, the robustness of these models\nstill remains a challenging problem in the practical use under noisy conditions\nof realistic environments. Contrary to most existing work focusing on the\ndesign of new models, we argue that improving the robustness requires\nrethinking many other aspects, including the use of datasets, the format of\nlandmark annotation, the evaluation metric as well as the training and\ndetection algorithm itself. In this paper, we propose a novel method for robust\nfacial landmark detection, using a loss function based on the 2D Wasserstein\ndistance combined with a new landmark coordinate sampling relying on the\nbarycenter of the individual probability distributions. Our method can be\nplugged-and-play on most state-of-the-art HRMs with neither additional\ncomplexity nor structural modifications of the models. Further, with the large\nperformance increase, we found that current evaluation metrics can no longer\nfully reflect the robustness of these models. Therefore, we propose several\nimprovements to the standard evaluation protocol. Extensive experimental\nresults on both traditional evaluation metrics and our evaluation metrics\ndemonstrate that our approach significantly improves the robustness of\nstate-of-the-art facial landmark detection models.", "published": "2019-11-24T16:56:10Z", "version": 2}, {"aid": "1911.11238", "authors": ["Ganesh Sundaramoorthi", "Timothy E. Wang"], "title": "Translation Insensitive CNNs", "url": "http://arxiv.org/pdf/1911.11238v1", "summary": "We address the problem that state-of-the-art Convolution Neural Networks\n(CNN) classifiers are not invariant to small shifts. The problem can be solved\nby the removal of sub-sampling operations such as stride and max pooling, but\nat a cost of severely degraded training and test efficiency. We present a novel\nusage of Gaussian-Hermite basis to efficiently approximate arbitrary filters\nwithin the CNN framework to obtain translation invariance. This is shown to be\ninvariant to small shifts, and preserves the efficiency of training. Further,\nto improve efficiency in memory usage as well as computational speed, we show\nthat it is still possible to sub-sample with this approach and retain a weaker\nform of invariance that we call \\emph{translation insensitivity}, which leads\nto stability with respect to shifts. We prove these claims analytically and\nempirically. Our analytic methods further provide a framework for understanding\nany architecture in terms of translation insensitivity, and provide guiding\nprinciples for design.", "published": "2019-11-25T21:22:06Z", "version": 1}, {"aid": "1911.11323", "authors": ["Yang Wang", "Yang Cao", "Zheng-Jun Zha", "Jing Zhang", "Zhiwei Xiong", "Wei Zhang", "Feng Wu"], "title": "Progressive Retinex: Mutually Reinforced Illumination-Noise Perception Network for Low Light Image Enhancement", "url": "http://arxiv.org/pdf/1911.11323v1", "summary": "Contrast enhancement and noise removal are coupled problems for low-light\nimage enhancement. The existing Retinex based methods do not take the coupling\nrelation into consideration, resulting in under or over-smoothing of the\nenhanced images. To address this issue, this paper presents a novel progressive\nRetinex framework, in which illumination and noise of low-light image are\nperceived in a mutually reinforced manner, leading to noise reduction low-light\nenhancement results. Specifically, two fully pointwise convolutional neural\nnetworks are devised to model the statistical regularities of ambient light and\nimage noise respectively, and to leverage them as constraints to facilitate the\nmutual learning process. The proposed method not only suppresses the\ninterference caused by the ambiguity between tiny textures and image noises,\nbut also greatly improves the computational efficiency. Moreover, to solve the\nproblem of insufficient training data, we propose an image synthesis strategy\nbased on camera imaging model, which generates color images corrupted by\nillumination-dependent noises. Experimental results on both synthetic and real\nlow-light images demonstrate the superiority of our proposed approaches against\nthe State-Of-The-Art (SOTA) low-light enhancement methods.", "published": "2019-11-26T03:56:45Z", "version": 1}, {"aid": "1911.11759", "authors": ["Xiuye Gu", "Weixin Luo", "Michael S. Ryoo", "Yong Jae Lee"], "title": "Password-conditioned Anonymization and Deanonymization with Face Identity Transformers", "url": "http://arxiv.org/pdf/1911.11759v4", "summary": "Cameras are prevalent in our daily lives, and enable many useful systems\nbuilt upon computer vision technologies such as smart cameras and home robots\nfor service applications. However, there is also an increasing societal concern\nas the captured images/videos may contain privacy-sensitive information (e.g.,\nface identity). We propose a novel face identity transformer which enables\nautomated photo-realistic password-based anonymization as well as\ndeanonymization of human faces appearing in visual data. Our face identity\ntransformer is trained to (1) remove face identity information after\nanonymization, (2) make the recovery of the original face possible when given\nthe correct password, and (3) return a wrong--but photo-realistic--face given a\nwrong password. Extensive experiments show that our approach enables multimodal\npassword-conditioned face anonymizations and deanonymizations, without\nsacrificing privacy compared to existing anonymization approaches.", "published": "2019-11-26T18:50:53Z", "version": 4}, {"aid": "1911.11800", "authors": ["Hirunima Jayasekara", "Vinoj Jayasundara", "Mohamed Athif", "Jathushan Rajasegaran", "Sandaru Jayasekara", "Suranga Seneviratne", "Ranga Rodrigo"], "title": "TimeCaps: Capturing Time Series Data With Capsule Networks", "url": "http://arxiv.org/pdf/1911.11800v4", "summary": "Capsule networks excel in understanding spatial relationships in 2D data for\nvision related tasks. Even though they are not designed to capture 1D temporal\nrelationships, with TimeCaps we demonstrate that given the ability, capsule\nnetworks excel in understanding temporal relationships. To this end, we\ngenerate capsules along the temporal and channel dimensions creating two\ntemporal feature detectors which learn contrasting relationships. TimeCaps\nsurpasses the state-of-the-art results by achieving 96.21% accuracy on\nidentifying 13 Electrocardiogram (ECG) signal beat categories, while achieving\non-par results on identifying 30 classes of short audio commands. Further, the\ninstantiation parameters inherently learnt by the capsule networks allow us to\ncompletely parameterize 1D signals which opens various possibilities in signal\nprocessing.", "published": "2019-11-26T19:28:57Z", "version": 4}, {"aid": "1911.11907", "authors": ["Kai Han", "Yunhe Wang", "Qi Tian", "Jianyuan Guo", "Chunjing Xu", "Chang Xu"], "title": "GhostNet: More Features from Cheap Operations", "url": "http://arxiv.org/pdf/1911.11907v2", "summary": "Deploying convolutional neural networks (CNNs) on embedded devices is\ndifficult due to the limited memory and computation resources. The redundancy\nin feature maps is an important characteristic of those successful CNNs, but\nhas rarely been investigated in neural architecture design. This paper proposes\na novel Ghost module to generate more feature maps from cheap operations. Based\non a set of intrinsic feature maps, we apply a series of linear transformations\nwith cheap cost to generate many ghost feature maps that could fully reveal\ninformation underlying intrinsic features. The proposed Ghost module can be\ntaken as a plug-and-play component to upgrade existing convolutional neural\nnetworks. Ghost bottlenecks are designed to stack Ghost modules, and then the\nlightweight GhostNet can be easily established. Experiments conducted on\nbenchmarks demonstrate that the proposed Ghost module is an impressive\nalternative of convolution layers in baseline models, and our GhostNet can\nachieve higher recognition performance (e.g. $75.7\\%$ top-1 accuracy) than\nMobileNetV3 with similar computational cost on the ImageNet ILSVRC-2012\nclassification dataset. Code is available at\nhttps://github.com/huawei-noah/ghostnet", "published": "2019-11-27T01:36:42Z", "version": 2}, {"aid": "1911.12110", "authors": ["Xin-Yu Zhang", "Le Zhang", "Zao-Yi Zheng", "Yun Liu", "Jia-Wang Bian", "Ming-Ming Cheng"], "title": "AdaSample: Adaptive Sampling of Hard Positives for Descriptor Learning", "url": "http://arxiv.org/pdf/1911.12110v1", "summary": "Triplet loss has been widely employed in a wide range of computer vision\ntasks, including local descriptor learning. The effectiveness of the triplet\nloss heavily relies on the triplet selection, in which a common practice is to\nfirst sample intra-class patches (positives) from the dataset for batch\nconstruction and then mine in-batch negatives to form triplets. For\nhigh-informativeness triplet collection, researchers mostly focus on mining\nhard negatives in the second stage, while paying relatively less attention to\nconstructing informative batches. To alleviate this issue, we propose\nAdaSample, an adaptive online batch sampler, in this paper. Specifically, hard\npositives are sampled based on their informativeness. In this way, we formulate\na hardness-aware positive mining pipeline within a novel maximum loss\nminimization training protocol. The efficacy of the proposed method is\nevaluated on several standard benchmarks, where it demonstrates a significant\nand consistent performance gain on top of the existing strong baselines.", "published": "2019-11-27T12:38:08Z", "version": 1}, {"aid": "1911.12116", "authors": ["Vanessa Buhrmester", "David M\u00fcnch", "Michael Arens"], "title": "Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey", "url": "http://arxiv.org/pdf/1911.12116v1", "summary": "Deep Learning is a state-of-the-art technique to make inference on extensive\nor complex data. As a black box model due to their multilayer nonlinear\nstructure, Deep Neural Networks are often criticized to be non-transparent and\ntheir predictions not traceable by humans. Furthermore, the models learn from\nartificial datasets, often with bias or contaminated discriminating content.\nThrough their increased distribution, decision-making algorithms can contribute\npromoting prejudge and unfairness which is not easy to notice due to lack of\ntransparency. Hence, scientists developed several so-called explanators or\nexplainers which try to point out the connection between input and output to\nrepresent in a simplified way the inner structure of machine learning black\nboxes. In this survey we differ the mechanisms and properties of explaining\nsystems for Deep Neural Networks for Computer Vision tasks. We give a\ncomprehensive overview about taxonomy of related studies and compare several\nsurvey papers that deal with explainability in general. We work out the\ndrawbacks and gaps and summarize further research ideas.", "published": "2019-11-27T12:58:52Z", "version": 1}, {"aid": "1911.12207", "authors": ["Jiayun Wang", "Yubei Chen", "Rudrasis Chakraborty", "Stella X. Yu"], "title": "Orthogonal Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1911.12207v3", "summary": "Deep convolutional neural networks are hindered by training instability and\nfeature redundancy towards further performance improvement. A promising\nsolution is to impose orthogonality on convolutional filters.\n  We develop an efficient approach to impose filter orthogonality on a\nconvolutional layer based on the doubly block-Toeplitz matrix representation of\nthe convolutional kernel instead of using the common kernel orthogonality\napproach, which we show is only necessary but not sufficient for ensuring\northogonal convolutions.\n  Our proposed orthogonal convolution requires no additional parameters and\nlittle computational overhead. This method consistently outperforms the kernel\northogonality alternative on a wide range of tasks such as image classification\nand inpainting under supervised, semi-supervised and unsupervised settings.\nFurther, it learns more diverse and expressive features with better training\nstability, robustness, and generalization. Our code is publicly available at\nhttps://github.com/samaonline/Orthogonal-Convolutional-Neural-Networks.", "published": "2019-11-27T15:04:26Z", "version": 3}, {"aid": "1911.12287", "authors": ["Giannis Daras", "Augustus Odena", "Han Zhang", "Alexandros G. Dimakis"], "title": "Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models", "url": "http://arxiv.org/pdf/1911.12287v2", "summary": "We introduce a new local sparse attention layer that preserves\ntwo-dimensional geometry and locality. We show that by just replacing the dense\nattention layer of SAGAN with our construction, we obtain very significant FID,\nInception score and pure visual improvements. FID score is improved from\n$18.65$ to $15.94$ on ImageNet, keeping all other parameters the same. The\nsparse attention patterns that we propose for our new layer are designed using\na novel information theoretic criterion that uses information flow graphs. We\nalso present a novel way to invert Generative Adversarial Networks with\nattention. Our method extracts from the attention layer of the discriminator a\nsaliency map, which we use to construct a new loss function for the inversion.\nThis allows us to visualize the newly introduced attention heads and show that\nthey indeed capture interesting aspects of two-dimensional geometry of real\nimages.", "published": "2019-11-27T17:03:16Z", "version": 2}, {"aid": "1911.12291", "authors": ["Mangal Prakash", "Manan Lalit", "Pavel Tomancak", "Alexander Krull", "Florian Jug"], "title": "Fully Unsupervised Probabilistic Noise2Void", "url": "http://arxiv.org/pdf/1911.12291v2", "summary": "Image denoising is the first step in many biomedical image analysis pipelines\nand Deep Learning (DL) based methods are currently best performing. A new\ncategory of DL methods such as Noise2Void or Noise2Self can be used fully\nunsupervised, requiring nothing but the noisy data. However, this comes at the\nprice of reduced reconstruction quality. The recently proposed Probabilistic\nNoise2Void (PN2V) improves results, but requires an additional noise model for\nwhich calibration data needs to be acquired. Here, we present improvements to\nPN2V that (i) replace histogram based noise models by parametric noise models,\nand (ii) show how suitable noise models can be created even in the absence of\ncalibration data. This is a major step since it actually renders PN2V fully\nunsupervised. We demonstrate that all proposed improvements are not only\nacademic but indeed relevant.", "published": "2019-11-27T17:11:59Z", "version": 2}, {"aid": "1911.12675", "authors": ["Xu Shen", "Xinmei Tian", "Tongliang Liu", "Fang Xu", "Dacheng Tao"], "title": "Continuous Dropout", "url": "http://arxiv.org/pdf/1911.12675v1", "summary": "Dropout has been proven to be an effective algorithm for training robust deep\nnetworks because of its ability to prevent overfitting by avoiding the\nco-adaptation of feature detectors. Current explanations of dropout include\nbagging, naive Bayes, regularization, and sex in evolution. According to the\nactivation patterns of neurons in the human brain, when faced with different\nsituations, the firing rates of neurons are random and continuous, not binary\nas current dropout does. Inspired by this phenomenon, we extend the traditional\nbinary dropout to continuous dropout. On the one hand, continuous dropout is\nconsiderably closer to the activation characteristics of neurons in the human\nbrain than traditional binary dropout. On the other hand, we demonstrate that\ncontinuous dropout has the property of avoiding the co-adaptation of feature\ndetectors, which suggests that we can extract more independent feature\ndetectors for model averaging in the test stage. We introduce the proposed\ncontinuous dropout to a feedforward neural network and comprehensively compare\nit with binary dropout, adaptive dropout, and DropConnect on MNIST, CIFAR-10,\nSVHN, NORB, and ILSVRC-12. Thorough experiments demonstrate that our method\nperforms better in preventing the co-adaptation of feature detectors and\nimproves test performance. The code is available at:\nhttps://github.com/jasonustc/caffe-multigpu/tree/dropout.", "published": "2019-11-28T12:37:48Z", "version": 1}, {"aid": "1912.00009", "authors": ["Shiyuan Li"], "title": "MSTDP: A More Biologically Plausible Learning", "url": "http://arxiv.org/pdf/1912.00009v2", "summary": "Spike-timing dependent plasticity (STDP) which observed in the brain has\nproven to be important in biological learning. On the other hand, artificial\nneural networks use a different way to learn, such as Back-Propagation or\nContrastive Hebbian Learning. In this work, we propose a new framework called\nmstdp that learn almost the same way biological learning use, it only uses STDP\nrules for supervised and unsupervised learning and don' t need a global loss or\nother supervise information. The framework works like an auto-encoder by making\neach input neuron also an output neuron. It can make predictions or generate\npatterns in one model without additional configuration. We also brought a new\niterative inference method using momentum to make the framework more efficient,\nwhich can be used in training and testing phases. Finally, we verified our\nframework on MNIST dataset for classification and generation task.", "published": "2019-11-29T05:42:50Z", "version": 2}, {"aid": "1911.13135", "authors": ["Gabriel Turinici"], "title": "Radon Sobolev Variational Auto-Encoders", "url": "http://arxiv.org/pdf/1911.13135v3", "summary": "The quality of generative models (such as Generative adversarial networks and\nVariational Auto-Encoders) depends heavily on the choice of a good probability\ndistance. However some popular metrics like the Wasserstein or the Sliced\nWasserstein distances, the Jensen-Shannon divergence, the Kullback-Leibler\ndivergence, lack convenient properties such as (geodesic) convexity, fast\nevaluation and so on. To address these shortcomings, we introduce a class of\ndistances that have built-in convexity. We investigate the relationship with\nsome known paradigms (sliced distances - a synonym for Radon distances -,\nreproducing kernel Hilbert spaces, energy distances). The distances are shown\nto possess fast implementations and are included in an adapted Variational\nAuto-Encoder termed Radon Sobolev Variational Auto-Encoder (RS-VAE) which\nproduces high quality results on standard generative datasets.\n  Keywords: Variational Auto-Encoder; Generative model; Sobolev spaces; Radon\nSobolev Variational Auto-Encoder;", "published": "2019-11-29T15:02:28Z", "version": 3}, {"aid": "1911.13173", "authors": ["Brendan Ruff", "Taylor Beck", "Joscha Bach"], "title": "Mean Shift Rejection: Training Deep Neural Networks Without Minibatch Statistics or Normalization", "url": "http://arxiv.org/pdf/1911.13173v1", "summary": "Deep convolutional neural networks are known to be unstable during training\nat high learning rate unless normalization techniques are employed. Normalizing\nweights or activations allows the use of higher learning rates, resulting in\nfaster convergence and higher test accuracy. Batch normalization requires\nminibatch statistics that approximate the dataset statistics but this incurs\nadditional compute and memory costs and causes a communication bottleneck for\ndistributed training. Weight normalization and initialization-only schemes do\nnot achieve comparable test accuracy.\n  We introduce a new understanding of the cause of training instability and\nprovide a technique that is independent of normalization and minibatch\nstatistics. Our approach treats training instability as a spatial common mode\nsignal which is suppressed by placing the model on a channel-wise zero-mean\nisocline that is maintained throughout training. Firstly, we apply channel-wise\nzero-mean initialization of filter kernels with overall unity kernel magnitude.\nAt each training step we modify the gradients of spatial kernels so that their\nweighted channel-wise mean is subtracted in order to maintain the common mode\nrejection condition. This prevents the onset of mean shift. This new technique\nallows direct training of the test graph so that training and test models are\nidentical. We also demonstrate that injecting random noise throughout the\nnetwork during training improves generalization. This is based on the idea\nthat, as a side effect, batch normalization performs deep data augmentation by\ninjecting minibatch noise due to the weakness of the dataset approximation.\n  Our technique achieves higher accuracy compared to batch normalization and\nfor the first time shows that minibatches and normalization are unnecessary for\nstate-of-the-art training.", "published": "2019-11-29T16:19:00Z", "version": 1}, {"aid": "1911.13175", "authors": ["Sean Moran", "Steven McDonagh", "Gregory Slabaugh"], "title": "CURL: Neural Curve Layers for Global Image Enhancement", "url": "http://arxiv.org/pdf/1911.13175v4", "summary": "We present a novel approach to adjust global image properties such as colour,\nsaturation, and luminance using human-interpretable image enhancement curves,\ninspired by the Photoshop curves tool. Our method, dubbed neural CURve Layers\n(CURL), is designed as a multi-colour space neural retouching block trained\njointly in three different colour spaces (HSV, CIELab, RGB) guided by a novel\nmulti-colour space loss. The curves are fully differentiable and are trained\nend-to-end for different computer vision problems including photo enhancement\n(RGB-to-RGB) and as part of the image signal processing pipeline for image\nformation (RAW-to-RGB). To demonstrate the effectiveness of CURL we combine\nthis global image transformation block with a pixel-level (local) image\nmulti-scale encoder-decoder backbone network. In an extensive experimental\nevaluation we show that CURL produces state-of-the-art image quality versus\nrecently proposed deep learning approaches in both objective and perceptual\nmetrics, setting new state-of-the-art performance on multiple public datasets.\nOur code is publicly available at: https://github.com/sjmoran/CURL.", "published": "2019-11-29T16:20:05Z", "version": 4}, {"aid": "1912.00091", "authors": ["Liane Gabora"], "title": "Creativity", "url": "http://arxiv.org/pdf/1912.00091v1", "summary": "Creativity is perhaps what most differentiates humans from other species. It\ninvolves the capacity to shift between divergent and convergent modes of\nthought in response to task demands. Divergent thought has been characterized\nas the kind of thinking needed to generate multiple solutions, while convergent\nthought has been characterized as the kind of thinking needed for tasks in with\none solution. Divergent thought has been conceived of as reflecting on the task\nfrom unconventional perspectives, while convergent thought has been conceived\nof as reflecting on it from conventional perspectives. Personality traits\ncorrelated with creativity include openness to experience, tolerance of\nambiguity, and self-confidence. Evidence that creativity is linked with\naffective disorders is mixed. Neuroscientific research using\nelectroencephalography (EEG) or functional magnetic resonance imaging (fMRI)\nsuggests that creativity is associated with a loosening of cognitive control\nand decreased arousal. The distributed, content-addressable structure of\nassociative memory is conducive to bringing task-relevant items to mind without\nthe need for explicit search. Human creativity dates back to the earliest stone\ntools over three million years ago, with the Paleolithic marking the onset of\nart, science, and religion. Areas of controversy concern the relative\ncontributions of expertise, chance, and intuition, the importance of process\nversus product, whether creativity is domain-specific versus domain-general,\nthe extent to which creativity is correlated with affective disorders, and\nwhether divergent thought entails the generation of multiple ideas or the\nhoning of a single initially ambiguous mental representation that may manifest\nas different external outputs. Areas for further research include computational\nmodeling, the biological basis of creativity, and studies that track ideation\nprocesses over time.", "published": "2019-11-29T23:17:03Z", "version": 1}, {"aid": "1912.00144", "authors": ["Huangxing Lin", "Weihong Zeng", "Xinghao Ding", "Yue Huang", "Chenxi Huang", "John Paisley"], "title": "Learning Rate Dropout", "url": "http://arxiv.org/pdf/1912.00144v2", "summary": "The performance of a deep neural network is highly dependent on its training,\nand finding better local optimal solutions is the goal of many optimization\nalgorithms. However, existing optimization algorithms show a preference for\ndescent paths that converge slowly and do not seek to avoid bad local optima.\nIn this work, we propose Learning Rate Dropout (LRD), a simple gradient descent\ntechnique for training related to coordinate descent. LRD empirically aids the\noptimizer to actively explore in the parameter space by randomly setting some\nlearning rates to zero; at each iteration, only parameters whose learning rate\nis not 0 are updated. As the learning rate of different parameters is dropped,\nthe optimizer will sample a new loss descent path for the current update. The\nuncertainty of the descent path helps the model avoid saddle points and bad\nlocal minima. Experiments show that LRD is surprisingly effective in\naccelerating training while preventing overfitting.", "published": "2019-11-30T06:58:40Z", "version": 2}, {"aid": "1912.00226", "authors": ["Yoshiki Ito", "Taro Toyoizumi"], "title": "Learning poly-synaptic paths with traveling waves", "url": "http://arxiv.org/pdf/1912.00226v2", "summary": "Traveling waves are commonly observed across the brain. While previous\nstudies have suggested the role of traveling waves in learning, the mechanism\nis still unclear. We adopted a computational approach to investigate the effect\nof traveling waves on synaptic plasticity. Our results indicate that traveling\nwaves facilitate the learning of poly-synaptic network-paths when combined with\na reward-dependent local synaptic plasticity rule. We also demonstrate that\ntraveling waves expedite finding the shortest paths and learning nonlinear\ninput/output-mapping, such as exclusive or (XOR) function.", "published": "2019-11-30T16:28:36Z", "version": 2}, {"aid": "1912.00385", "authors": ["Ismail Elezi", "Sebastiano Vascon", "Alessandro Torcinovich", "Marcello Pelillo", "Laura Leal-Taixe"], "title": "The Group Loss for Deep Metric Learning", "url": "http://arxiv.org/pdf/1912.00385v4", "summary": "Deep metric learning has yielded impressive results in tasks such as\nclustering and image retrieval by leveraging neural networks to obtain highly\ndiscriminative feature embeddings, which can be used to group samples into\ndifferent classes. Much research has been devoted to the design of smart loss\nfunctions or data mining strategies for training such networks. Most methods\nconsider only pairs or triplets of samples within a mini-batch to compute the\nloss function, which is commonly based on the distance between embeddings. We\npropose Group Loss, a loss function based on a differentiable label-propagation\nmethod that enforces embedding similarity across all samples of a group while\npromoting, at the same time, low-density regions amongst data points belonging\nto different groups. Guided by the smoothness assumption that \"similar objects\nshould belong to the same group\", the proposed loss trains the neural network\nfor a classification task, enforcing a consistent labelling amongst samples\nwithin a class. We show state-of-the-art results on clustering and image\nretrieval on several datasets, and show the potential of our method when\ncombined with other techniques such as ensembles", "published": "2019-12-01T11:09:57Z", "version": 4}, {"aid": "2001.01680", "authors": ["Mingyuan Meng", "Xingyu Yang", "Lei Bi", "Jinman Kim", "Shanlin Xiao", "Zhiyi Yu"], "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised Feature Learning", "url": "http://arxiv.org/pdf/2001.01680v5", "summary": "Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine\nlearning algorithms that have been widely recognized in producing\nultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs\nbased on synaptic plasticity, especially Spike-Timing-Dependent Plasticity\n(STDP), are considered to have great potential in imitating the learning\nprocess of the biological brain. Nevertheless, the existing STDP-based SNNs\nhave limitations in constrained learning capability and/or slow learning speed.\nMost STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture\nand used a sub-optimal vote-based scheme for spike decoding. In this paper, we\novercome these limitations with: 1) a design of high-parallelism network\narchitecture, inspired by the Inception module in Artificial Neural Networks\n(ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the\nstandard vote-based spike decoding scheme, to reduce the information loss in\nspike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism\nthat accelerates SNNs' learning by enhancing spiking activities. Our\nexperimental results on two established benchmark datasets (MNIST/EMNIST) show\nthat our network architecture resulted in superior performance compared to the\nwidely used FC architecture and a more advanced Locally-Connected (LC)\narchitecture, and that our SNN achieved competitive results with\nstate-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE\ndataset) while having superior learning efficiency and robustness against\nhardware damage. Our SNN achieved great classification accuracy with only\nhundreds of training iterations, and random destruction of large numbers of\nsynapses or neurons only led to negligible performance degradation.", "published": "2019-12-02T17:19:17Z", "version": 5}, {"aid": "1912.01137", "authors": ["Pitoyo Hartono"], "title": "Mixing autoencoder with classifier: conceptual data visualization", "url": "http://arxiv.org/pdf/1912.01137v3", "summary": "In this short paper, a neural network that is able to form a low dimensional\ntopological hidden representation is explained. The neural network can be\ntrained as an autoencoder, a classifier or mix of both, and produces different\nlow dimensional topological map for each of them. When it is trained as an\nautoencoder, the inherent topological structure of the data can be visualized,\nwhile when it is trained as a classifier, the topological structure is further\nconstrained by the concept, for example the labels the data, hence the\nvisualization is not only structural but also conceptual. The proposed neural\nnetwork significantly differ from many dimensional reduction models, primarily\nin its ability to execute both supervised and unsupervised dimensional\nreduction. The neural network allows multi perspective visualization of the\ndata, and thus giving more flexibility in data analysis. This paper is\nsupported by preliminary but intuitive visualization experiments.", "published": "2019-12-03T00:33:26Z", "version": 3}, {"aid": "1912.01166", "authors": ["He He", "Dongrui Wu"], "title": "Different Set Domain Adaptation for Brain-Computer Interfaces: A Label Alignment Approach", "url": "http://arxiv.org/pdf/1912.01166v4", "summary": "A brain-computer interface (BCI) system usually needs a long calibration\nsession for each new subject/task to adjust its parameters, which impedes its\ntransition from the laboratory to real-world applications. Domain adaptation,\nwhich leverages labeled data from auxiliary subjects/tasks (source domains),\nhas demonstrated its effectiveness in reducing such calibration effort.\nCurrently, most domain adaptation approaches require the source domains to have\nthe same feature space and label space as the target domain, which limits their\napplications, as the auxiliary data may have different feature spaces and/or\ndifferent label spaces. This paper considers different set domain adaptation\nfor BCIs, i.e., the source and target domains have different label spaces. We\nintroduce a practical setting of different label sets for BCIs, and propose a\nnovel label alignment (LA) approach to align the source label space with the\ntarget label space. It has three desirable properties: 1) LA only needs as few\nas one labeled sample from each class of the target subject; 2) LA can be used\nas a preprocessing step before different feature extraction and classification\nalgorithms; and, 3) LA can be integrated with other domain adaptation\napproaches to achieve even better performance. Experiments on two motor imagery\ndatasets demonstrated the effectiveness of LA.", "published": "2019-12-03T02:46:56Z", "version": 4}, {"aid": "1912.01171", "authors": ["Zihan Liu", "Lubin Meng", "Xiao Zhang", "Weili Fang", "Dongrui Wu"], "title": "Universal Adversarial Perturbations for CNN Classifiers in EEG-Based BCIs", "url": "http://arxiv.org/pdf/1912.01171v5", "summary": "Multiple convolutional neural network (CNN) classifiers have been proposed\nfor electroencephalogram (EEG) based brain-computer interfaces (BCIs). However,\nCNN models have been found vulnerable to universal adversarial perturbations\n(UAPs), which are small and example-independent, yet powerful enough to degrade\nthe performance of a CNN model, when added to a benign example. This paper\nproposes a novel total loss minimization (TLM) approach to generate UAPs for\nEEG-based BCIs. Experimental results demonstrated the effectiveness of TLM on\nthree popular CNN classifiers for both target and non-target attacks. We also\nverified the transferability of UAPs in EEG-based BCI systems. To our\nknowledge, this is the first study on UAPs of CNN classifiers in EEG-based\nBCIs. UAPs are easy to construct, and can attack BCIs in real-time, exposing a\npotentially critical security concern of BCIs.", "published": "2019-12-03T03:00:08Z", "version": 5}, {"aid": "1912.01521", "authors": ["Oren Barkan"], "title": "Multiscale Self Attentive Convolutions for Vision and Language Modeling", "url": "http://arxiv.org/pdf/1912.01521v1", "summary": "Self attention mechanisms have become a key building block in many\nstate-of-the-art language understanding models. In this paper, we show that the\nself attention operator can be formulated in terms of 1x1 convolution\noperations. Following this observation, we propose several novel operators:\nFirst, we introduce a 2D version of self attention that is applicable for 2D\nsignals such as images. Second, we present the 1D and 2D Self Attentive\nConvolutions (SAC) operator that generalizes self attention beyond 1x1\nconvolutions to 1xm and nxm convolutions, respectively. While 1D and 2D self\nattention operate on individual words and pixels, SAC operates on m-grams and\nimage patches, respectively. Third, we present a multiscale version of SAC\n(MSAC) which analyzes the input by employing multiple SAC operators that vary\nby filter size, in parallel. Finally, we explain how MSAC can be utilized for\nvision and language modeling, and further harness MSAC to form a cross\nattentive image similarity machinery.", "published": "2019-12-03T16:51:09Z", "version": 1}, {"aid": "1912.01839", "authors": ["Yuval Bahat", "Tomer Michaeli"], "title": "Explorable Super Resolution", "url": "http://arxiv.org/pdf/1912.01839v3", "summary": "Single image super resolution (SR) has seen major performance leaps in recent\nyears. However, existing methods do not allow exploring the infinitely many\nplausible reconstructions that might have given rise to the observed\nlow-resolution (LR) image. These different explanations to the LR image may\ndramatically vary in their textures and fine details, and may often encode\ncompletely different semantic information. In this paper, we introduce the task\nof explorable super resolution. We propose a framework comprising a graphical\nuser interface with a neural network backend, allowing editing the SR output so\nas to explore the abundance of plausible HR explanations to the LR input. At\nthe heart of our method is a novel module that can wrap any existing SR\nnetwork, analytically guaranteeing that its SR outputs would precisely match\nthe LR input, when downsampled. Besides its importance in our setting, this\nmodule is guaranteed to decrease the reconstruction error of any SR network it\nwraps, and can be used to cope with blur kernels that are different from the\none the network was trained for. We illustrate our approach in a variety of use\ncases, ranging from medical imaging and forensics, to graphics.", "published": "2019-12-04T08:01:58Z", "version": 3}, {"aid": "1912.02040", "authors": ["Carlos Calvo Tapia", "Ivan Tyukin", "Valeri A. Makarov"], "title": "Universal principles justify the existence of concept cells", "url": "http://arxiv.org/pdf/1912.02040v1", "summary": "It is largely believed that complex cognitive phenomena require the perfect\norchestrated collaboration of many neurons. However, this is not what\nconverging experimental evidence suggests. Single neurons, the so-called\nconcept cells, may be responsible for complex tasks performed by an individual.\nHere, starting from a few first principles, we layout physical foundations\nshowing that concept cells are not only possible but highly likely, given that\nneurons work in a high dimensional space.", "published": "2019-12-04T15:06:17Z", "version": 1}, {"aid": "1912.02279", "authors": ["Beidi Chen", "Weiyang Liu", "Zhiding Yu", "Jan Kautz", "Anshumali Shrivastava", "Animesh Garg", "Anima Anandkumar"], "title": "Angular Visual Hardness", "url": "http://arxiv.org/pdf/1912.02279v4", "summary": "Recent convolutional neural networks (CNNs) have led to impressive\nperformance but often suffer from poor calibration. They tend to be\noverconfident, with the model confidence not always reflecting the underlying\ntrue ambiguity and hardness. In this paper, we propose angular visual hardness\n(AVH), a score given by the normalized angular distance between the sample\nfeature embedding and the target classifier to measure sample hardness. We\nvalidate this score with an in-depth and extensive scientific study, and\nobserve that CNN models with the highest accuracy also have the best AVH\nscores. This agrees with an earlier finding that state-of-art models improve on\nthe classification of harder examples. We observe that the training dynamics of\nAVH is vastly different compared to the training loss. Specifically, AVH\nquickly reaches a plateau for all samples even though the training loss keeps\nimproving. This suggests the need for designing better loss functions that can\ntarget harder examples more effectively. We also find that AVH has a\nstatistically significant correlation with human visual hardness. Finally, we\ndemonstrate the benefit of AVH to a variety of applications such as\nself-training for domain adaptation and domain generalization.", "published": "2019-12-04T22:12:42Z", "version": 4}, {"aid": "1912.02413", "authors": ["Boyan Zhou", "Quan Cui", "Xiu-Shen Wei", "Zhao-Min Chen"], "title": "BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition", "url": "http://arxiv.org/pdf/1912.02413v4", "summary": "Our work focuses on tackling the challenging but natural visual recognition\ntask of long-tailed data distribution (i.e., a few classes occupy most of the\ndata, while most classes have rarely few samples). In the literature, class\nre-balancing strategies (e.g., re-weighting and re-sampling) are the prominent\nand effective methods proposed to alleviate the extreme imbalance for dealing\nwith long-tailed problems. In this paper, we firstly discover that these\nre-balancing methods achieving satisfactory recognition accuracy owe to that\nthey could significantly promote the classifier learning of deep networks.\nHowever, at the same time, they will unexpectedly damage the representative\nability of the learned deep features to some extent. Therefore, we propose a\nunified Bilateral-Branch Network (BBN) to take care of both representation\nlearning and classifier learning simultaneously, where each branch does perform\nits own duty separately. In particular, our BBN model is further equipped with\na novel cumulative learning strategy, which is designed to first learn the\nuniversal patterns and then pay attention to the tail data gradually. Extensive\nexperiments on four benchmark datasets, including the large-scale iNaturalist\nones, justify that the proposed BBN can significantly outperform\nstate-of-the-art methods. Furthermore, validation experiments can demonstrate\nboth our preliminary discovery and effectiveness of tailored designs in BBN for\nlong-tailed problems. Our method won the first place in the iNaturalist 2019\nlarge scale species classification competition, and our code is open-source and\navailable at https://github.com/Megvii-Nanjing/BBN.", "published": "2019-12-05T07:32:28Z", "version": 4}, {"aid": "1912.02745", "authors": ["Tiziana Cattai", "Stefania Colonnese", "Marie-Constance Corsi", "Danielle S. Bassett", "Gaetano Scarano", "Fabrizio De Vico Fallani"], "title": "Phase/amplitude synchronization of brain signals during motor imagery BCI tasks", "url": "http://arxiv.org/pdf/1912.02745v1", "summary": "The extraction of brain functioning features is a crucial step in the\ndefinition of brain-computer interfaces (BCIs). In the last decade, functional\nconnectivity (FC) estimators have been increasingly explored based on their\nability to capture synchronization between multivariate brain signals. However,\nthe underlying neurophysiological mechanisms and the extent to which they can\nimprove performance in BCI-related tasks, is still poorly understood. To\naddress this gap in knowledge, we considered a group of 20 healthy subjects\nduring an EEG-based hand motor imagery (MI) task. We studied two\nwell-established FC estimators, i.e. spectral- and imaginary-coherence, and\ninvestigated how they were modulated by the MI task. We characterized the\nresulting FC networks by extracting the strength of connectivity of each EEG\nsensor and compared the discriminant power with respect to standard power\nspectrum features. At the group level, results showed that while\nspectral-coherence based network features were increasing the controlateral\nmotor area, those based on imaginary-coherence were decreasing. We demonstrated\nthat this opposite, but complementary, behavior was respectively determined by\nthe increase in amplitude and phase synchronization between the brain signals.\nAt the individual level, we proved that including these network connectivity\nfeatures in the classification of MI mental states led to an overall\nimprovement in accuracy. Taken together, our results provide fresh insights\ninto the oscillatory mechanisms subserving brain network changes during MI and\noffer new perspectives to improve BCI performance.", "published": "2019-12-05T17:33:12Z", "version": 1}, {"aid": "1912.02762", "authors": ["George Papamakarios", "Eric Nalisnick", "Danilo Jimenez Rezende", "Shakir Mohamed", "Balaji Lakshminarayanan"], "title": "Normalizing Flows for Probabilistic Modeling and Inference", "url": "http://arxiv.org/pdf/1912.02762v2", "summary": "Normalizing flows provide a general mechanism for defining expressive\nprobability distributions, only requiring the specification of a (usually\nsimple) base distribution and a series of bijective transformations. There has\nbeen much recent work on normalizing flows, ranging from improving their\nexpressive power to expanding their application. We believe the field has now\nmatured and is in need of a unified perspective. In this review, we attempt to\nprovide such a perspective by describing flows through the lens of\nprobabilistic modeling and inference. We place special emphasis on the\nfundamental principles of flow design, and discuss foundational topics such as\nexpressive power and computational trade-offs. We also broaden the conceptual\nframing of flows by relating them to more general probability transformations.\nLastly, we summarize the use of flows for tasks such as generative modeling,\napproximate inference, and supervised learning.", "published": "2019-12-05T17:55:27Z", "version": 2}, {"aid": "1912.03203", "authors": ["Thomas Verelst", "Tinne Tuytelaars"], "title": "Dynamic Convolutions: Exploiting Spatial Sparsity for Faster Inference", "url": "http://arxiv.org/pdf/1912.03203v3", "summary": "Modern convolutional neural networks apply the same operations on every pixel\nin an image. However, not all image regions are equally important. To address\nthis inefficiency, we propose a method to dynamically apply convolutions\nconditioned on the input image. We introduce a residual block where a small\ngating branch learns which spatial positions should be evaluated. These\ndiscrete gating decisions are trained end-to-end using the Gumbel-Softmax\ntrick, in combination with a sparsity criterion. Our experiments on CIFAR,\nImageNet and MPII show that our method has better focus on the region of\ninterest and better accuracy than existing methods, at a lower computational\ncomplexity. Moreover, we provide an efficient CUDA implementation of our\ndynamic convolutions using a gather-scatter approach, achieving a significant\nimprovement in inference speed with MobileNetV2 residual blocks. On human pose\nestimation, a task that is inherently spatially sparse, the processing speed is\nincreased by 60% with no loss in accuracy.", "published": "2019-12-06T16:11:16Z", "version": 3}, {"aid": "1912.03458", "authors": ["Yinpeng Chen", "Xiyang Dai", "Mengchen Liu", "Dongdong Chen", "Lu Yuan", "Zicheng Liu"], "title": "Dynamic Convolution: Attention over Convolution Kernels", "url": "http://arxiv.org/pdf/1912.03458v2", "summary": "Light-weight convolutional neural networks (CNNs) suffer performance\ndegradation as their low computational budgets constrain both the depth (number\nof convolution layers) and the width (number of channels) of CNNs, resulting in\nlimited representation capability. To address this issue, we present Dynamic\nConvolution, a new design that increases model complexity without increasing\nthe network depth or width. Instead of using a single convolution kernel per\nlayer, dynamic convolution aggregates multiple parallel convolution kernels\ndynamically based upon their attentions, which are input dependent. Assembling\nmultiple kernels is not only computationally efficient due to the small kernel\nsize, but also has more representation power since these kernels are aggregated\nin a non-linear way via attention. By simply using dynamic convolution for the\nstate-of-the-art architecture MobileNetV3-Small, the top-1 accuracy of ImageNet\nclassification is boosted by 2.9% with only 4% additional FLOPs and 2.9 AP gain\nis achieved on COCO keypoint detection.", "published": "2019-12-07T07:51:35Z", "version": 2}, {"aid": "1912.03467", "authors": ["Mohamed Karim Belaid"], "title": "Comparison of Neuronal Attention Models", "url": "http://arxiv.org/pdf/1912.03467v1", "summary": "Recent models for image processing are using the Convolutional neural network\n(CNN) which requires a pixel per pixel analysis of the input image. This method\nworks well. However, it is time-consuming if we have large images. To increase\nthe performance, by improving the training time or the accuracy, we need a\nsize-independent method. As a solution, we can add a Neuronal Attention model\n(NAM). The power of this new approach is that it can efficiently choose several\nsmall regions from the initial image to focus on. The purpose of this paper is\nto explain and also test each of the NAM's parameters.", "published": "2019-12-07T09:00:18Z", "version": 1}, {"aid": "1912.03647", "authors": ["Dingheng Wang", "Guangshe Zhao", "Guoqi Li", "Lei Deng", "Yang Wu"], "title": "Compressing 3DCNNs Based on Tensor Train Decomposition", "url": "http://arxiv.org/pdf/1912.03647v2", "summary": "Three dimensional convolutional neural networks (3DCNNs) have been applied in\nmany tasks, e.g., video and 3D point cloud recognition. However, due to the\nhigher dimension of convolutional kernels, the space complexity of 3DCNNs is\ngenerally larger than that of traditional two dimensional convolutional neural\nnetworks (2DCNNs). To miniaturize 3DCNNs for the deployment in confining\nenvironments such as embedded devices, neural network compression is a\npromising approach. In this work, we adopt the tensor train (TT) decomposition,\na straightforward and simple in situ training compression method, to shrink the\n3DCNN models. Through proposing tensorizing 3D convolutional kernels in TT\nformat, we investigate how to select appropriate TT ranks for achieving higher\ncompression ratio. We have also discussed the redundancy of 3D convolutional\nkernels for compression, core significance and future directions of this work,\nas well as the theoretical computation complexity versus practical executing\ntime of convolution in TT. In the light of multiple contrast experiments based\non VIVA challenge, UCF11, and UCF101 datasets, we conclude that TT\ndecomposition can compress 3DCNNs by around one hundred times without\nsignificant accuracy loss, which will enable its applications in extensive real\nworld scenarios.", "published": "2019-12-08T09:51:08Z", "version": 2}, {"aid": "1912.03820", "authors": ["Mingzhang Yin", "George Tucker", "Mingyuan Zhou", "Sergey Levine", "Chelsea Finn"], "title": "Meta-Learning without Memorization", "url": "http://arxiv.org/pdf/1912.03820v3", "summary": "The ability to learn new concepts with small amounts of data is a critical\naspect of intelligence that has proven challenging for deep learning methods.\nMeta-learning has emerged as a promising technique for leveraging data from\nprevious tasks to enable efficient learning of new tasks. However, most\nmeta-learning algorithms implicitly require that the meta-training tasks be\nmutually-exclusive, such that no single model can solve all of the tasks at\nonce. For example, when creating tasks for few-shot image classification, prior\nwork uses a per-task random assignment of image classes to N-way classification\nlabels. If this is not done, the meta-learner can ignore the task training data\nand learn a single model that performs all of the meta-training tasks\nzero-shot, but does not adapt effectively to new image classes. This\nrequirement means that the user must take great care in designing the tasks,\nfor example by shuffling labels or removing task identifying information from\nthe inputs. In some domains, this makes meta-learning entirely inapplicable. In\nthis paper, we address this challenge by designing a meta-regularization\nobjective using information theory that places precedence on data-driven\nadaptation. This causes the meta-learner to decide what must be learned from\nthe task training data and what should be inferred from the task testing input.\nBy doing so, our algorithm can successfully use data from\nnon-mutually-exclusive tasks to efficiently adapt to novel tasks. We\ndemonstrate its applicability to both contextual and gradient-based\nmeta-learning algorithms, and apply it in practical settings where applying\nstandard meta-learning has been difficult. Our approach substantially\noutperforms standard meta-learning algorithms in these settings.", "published": "2019-12-09T02:30:46Z", "version": 3}, {"aid": "1912.05743", "authors": ["Akanksha Atrey", "Kaleigh Clary", "David Jensen"], "title": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1912.05743v2", "summary": "Saliency maps are frequently used to support explanations of the behavior of\ndeep reinforcement learning (RL) agents. However, a review of how saliency maps\nare used in practice indicates that the derived explanations are often\nunfalsifiable and can be highly subjective. We introduce an empirical approach\ngrounded in counterfactual reasoning to test the hypotheses generated from\nsaliency maps and assess the degree to which they correspond to the semantics\nof RL environments. We use Atari games, a common benchmark for deep RL, to\nevaluate three types of saliency maps. Our results show the extent to which\nexisting claims about Atari games can be evaluated and suggest that saliency\nmaps are best viewed as an exploratory tool rather than an explanatory tool.", "published": "2019-12-09T12:42:07Z", "version": 2}, {"aid": "1912.04478", "authors": ["Pei Xie", "He-Feng Yin", "Xiao-Jun Wu"], "title": "Low-rank representations with incoherent dictionary for face recognition", "url": "http://arxiv.org/pdf/1912.04478v1", "summary": "Face recognition remains a hot topic in computer vision, and it is\nchallenging to tackle the problem that both the training and testing images are\ncorrupted. In this paper, we propose a novel semi-supervised method based on\nthe theory of the low-rank matrix recovery for face recognition, which can\nsimultaneously learn discriminative low-rank and sparse representations for\nboth training and testing images. To this end, a correlation penalty term is\nintroduced into the formulation of our proposed method to learn an incoherent\ndictionary. Experimental results on several face image databases demonstrate\nthe effectiveness of our method, i.e., the proposed method is robust to the\nillumination, expression and pose variations, as well as images with noises\nsuch as block occlusion or uniform noises.", "published": "2019-12-10T03:44:25Z", "version": 1}, {"aid": "1912.04486", "authors": ["Junjie Zhang", "Lingqiao Liu", "Peng Wang", "Chunhua Shen"], "title": "To Balance or Not to Balance: A Simple-yet-Effective Approach for Learning with Long-Tailed Distributions", "url": "http://arxiv.org/pdf/1912.04486v2", "summary": "Real-world visual data often exhibits a long-tailed distribution, where some\n''head'' classes have a large number of samples, yet only a few samples are\navailable for ''tail'' classes. Such imbalanced distribution causes a great\nchallenge for learning a deep neural network, which can be boiled down into a\ndilemma: on the one hand, we prefer to increase the exposure of tail class\nsamples to avoid the excessive dominance of head classes in the classifier\ntraining. On the other hand, oversampling tail classes makes the network prone\nto over-fitting, since head class samples are often consequently\nunder-represented. To resolve this dilemma, in this paper, we propose a\nsimple-yet-effective auxiliary learning approach. The key idea is to split a\nnetwork into a classifier part and a feature extractor part, and then employ\ndifferent training strategies for each part. Specifically, to promote the\nawareness of tail-classes, a class-balanced sampling scheme is utilised for\ntraining both the classifier and the feature extractor. For the feature\nextractor, we also introduce an auxiliary training task, which is to train a\nclassifier under the regular random sampling scheme. In this way, the feature\nextractor is jointly trained from both sampling strategies and thus can take\nadvantage of all training data and avoid the over-fitting issue. Apart from\nthis basic auxiliary task, we further explore the benefit of using\nself-supervised learning as the auxiliary task. Without using any bells and\nwhistles, our model achieves superior performance over the state-of-the-art\nsolutions.", "published": "2019-12-10T04:11:53Z", "version": 2}, {"aid": "1912.04518", "authors": ["Shuaicheng Liu", "Zehao Zhang", "Kai Song", "Bing Zeng"], "title": "Arithmetic addition of two integers by deep image classification networks: experiments to quantify their autonomous reasoning ability", "url": "http://arxiv.org/pdf/1912.04518v1", "summary": "The unprecedented performance achieved by deep convolutional neural networks\nfor image classification is linked primarily to their ability of capturing rich\nstructural features at various layers within networks. Here we design a series\nof experiments, inspired by children's learning of the arithmetic addition of\ntwo integers, to showcase that such deep networks can go beyond the structural\nfeatures to learn deeper knowledge. In our experiments, a set of images is\nconstructed, each image containing an arithmetic addition $n+m$ in its central\narea, and several classification networks are then trained over a subset of\nimages, using the sum as the label. Tests on the excluded images show that, as\nthe image set gets larger, the networks have well learnt the law of arithmetic\nadditions so as to build up their autonomous reasoning ability strongly. For\ninstance, networks trained over a small percentage of images can classify a big\nmajority of the remaining images correctly, and many arithmetic additions\ninvolving some integers that have never been seen during the training can also\nbe solved correctly by the trained networks.", "published": "2019-12-10T06:02:59Z", "version": 1}, {"aid": "1912.04564", "authors": ["Arnab Kumar Mondal", "Sankalan Pal Chowdhury", "Aravind Jayendran", "Parag Singla", "Himanshu Asnani", "Prathosh AP"], "title": "MaskAAE: Latent space optimization for Adversarial Auto-Encoders", "url": "http://arxiv.org/pdf/1912.04564v2", "summary": "The field of neural generative models is dominated by the highly successful\nGenerative Adversarial Networks (GANs) despite their challenges, such as\ntraining instability and mode collapse. Auto-Encoders (AE) with regularized\nlatent space provide an alternative framework for generative models, albeit\ntheir performance levels have not reached that of GANs. In this work, we\nhypothesise that the dimensionality of the AE model's latent space has a\ncritical effect on the quality of generated data. Under the assumption that\nnature generates data by sampling from a \"true\" generative latent space\nfollowed by a deterministic function, we show that the optimal performance is\nobtained when the dimensionality of the latent space of the AE-model matches\nwith that of the \"true\" generative latent space. Further, we propose an\nalgorithm called the Mask Adversarial Auto-Encoder (MaskAAE), in which the\ndimensionality of the latent space of an adversarial auto encoder is brought\ncloser to that of the \"true\" generative latent space, via a procedure to mask\nthe spurious latent dimensions. We demonstrate through experiments on synthetic\nand several real-world datasets that the proposed formulation yields betterment\nin the generation quality.", "published": "2019-12-10T08:18:13Z", "version": 2}, {"aid": "1912.04591", "authors": ["Konstantinos Rematas", "Vittorio Ferrari"], "title": "Neural Voxel Renderer: Learning an Accurate and Controllable Rendering Tool", "url": "http://arxiv.org/pdf/1912.04591v2", "summary": "We present a neural rendering framework that maps a voxelized scene into a\nhigh quality image. Highly-textured objects and scene element interactions are\nrealistically rendered by our method, despite having a rough representation as\nan input. Moreover, our approach allows controllable rendering: geometric and\nappearance modifications in the input are accurately propagated to the output.\nThe user can move, rotate and scale an object, change its appearance and\ntexture or modify the position of the light and all these edits are represented\nin the final rendering. We demonstrate the effectiveness of our approach by\nrendering scenes with varying appearance, from single color per object to\ncomplex, high-frequency textures. We show that our rerendering network can\ngenerate very detailed images that represent precisely the appearance of the\ninput scene. Our experiments illustrate that our approach achieves more\naccurate image synthesis results compared to alternatives and can also handle\nlow voxel grid resolutions. Finally, we show how our neural rendering framework\ncan capture and faithfully render objects from real images and from a diverse\nset of classes.", "published": "2019-12-10T09:30:03Z", "version": 2}, {"aid": "1912.04749", "authors": ["Shoufa Chen", "Yunpeng Chen", "Shuicheng Yan", "Jiashi Feng"], "title": "Efficient Differentiable Neural Architecture Search with Meta Kernels", "url": "http://arxiv.org/pdf/1912.04749v1", "summary": "The searching procedure of neural architecture search (NAS) is notoriously\ntime consuming and cost prohibitive.To make the search space continuous, most\nexisting gradient-based NAS methods relax the categorical choice of a\nparticular operation to a softmax over all possible operations and calculate\nthe weighted sum of multiple features, resulting in a large memory requirement\nand a huge computation burden. In this work, we propose an efficient and novel\nsearch strategy with meta kernels. We directly encode the supernet from the\nperspective on convolution kernels and \"shrink\" multiple convolution kernel\ncandidates into a single one before these candidates operate on the input\nfeature. In this way, only a single feature is generated between two\nintermediate nodes. The memory for storing intermediate features and the\nresource budget for conducting convolution operations are both reduced\nremarkably. Despite high efficiency, our search strategy can search in a more\nfine-grained way than existing works and increases the capacity for\nrepresenting possible networks. We demonstrate the effectiveness of our search\nstrategy by conducting extensive experiments. Specifically, our method achieves\n77.0% top-1 accuracy on ImageNet benchmark dataset with merely 357M FLOPs,\noutperforming both EfficientNet and MobileNetV3 under the same FLOPs\nconstraints. Compared to models discovered by the start-of-the-art NAS method,\nour method achieves the same (sometimes even better) performance, while faster\nby three orders of magnitude.", "published": "2019-12-10T15:08:50Z", "version": 1}, {"aid": "1912.04964", "authors": ["Dimiter Dobrev"], "title": "Before we can find a model, we must forget about perfection", "url": "http://arxiv.org/pdf/1912.04964v1", "summary": "With Reinforcement Learning we assume that a model of the world does exist.\nWe assume furthermore that the model in question is perfect (i.e. it describes\nthe world completely and unambiguously). This article will demonstrate that it\ndoes not make sense to search for the perfect model because this model is too\ncomplicated and practically impossible to find. We will show that we should\nabandon the pursuit of perfection and pursue Event-Driven (ED) models instead.\nThese models are generalization of Markov Decision Process (MDP) models. This\ngeneralization is essential because nothing can be found without it. Rather\nthan a single MDP, we will aim to find a raft of neat simple ED models each one\ndescribing a simple dependency or property. In other words, we will replace the\nsearch for a singular and complex perfect model with a search for a large\nnumber of simple models.", "published": "2019-12-10T20:20:34Z", "version": 1}, {"aid": "1912.05035", "authors": ["Maria Ximena Bastidas Rodriguez", "Adrien Gruson", "Luisa F. Polania", "Shin Fujieda", "Flavio Prieto Ortiz", "Kohei Takayama", "Toshiya Hachisuka"], "title": "Deep Adaptive Wavelet Network", "url": "http://arxiv.org/pdf/1912.05035v1", "summary": "Even though convolutional neural networks have become the method of choice in\nmany fields of computer vision, they still lack interpretability and are\nusually designed manually in a cumbersome trial-and-error process. This paper\naims at overcoming those limitations by proposing a deep neural network, which\nis designed in a systematic fashion and is interpretable, by integrating\nmultiresolution analysis at the core of the deep neural network design. By\nusing the lifting scheme, it is possible to generate a wavelet representation\nand design a network capable of learning wavelet coefficients in an end-to-end\nform. Compared to state-of-the-art architectures, the proposed model requires\nless hyper-parameter tuning and achieves competitive accuracy in image\nclassification tasks", "published": "2019-12-10T22:43:16Z", "version": 1}, {"aid": "1912.05074", "authors": ["Zongwei Zhou", "Md Mahfuzur Rahman Siddiquee", "Nima Tajbakhsh", "Jianming Liang"], "title": "UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation", "url": "http://arxiv.org/pdf/1912.05074v2", "summary": "The state-of-the-art models for medical image segmentation are variants of\nU-Net and fully convolutional networks (FCN). Despite their success, these\nmodels have two limitations: (1) their optimal depth is apriori unknown,\nrequiring extensive architecture search or inefficient ensemble of models of\nvarying depths; and (2) their skip connections impose an unnecessarily\nrestrictive fusion scheme, forcing aggregation only at the same-scale feature\nmaps of the encoder and decoder sub-networks. To overcome these two\nlimitations, we propose UNet++, a new neural architecture for semantic and\ninstance segmentation, by (1) alleviating the unknown network depth with an\nefficient ensemble of U-Nets of varying depths, which partially share an\nencoder and co-learn simultaneously using deep supervision; (2) redesigning\nskip connections to aggregate features of varying semantic scales at the\ndecoder sub-networks, leading to a highly flexible feature fusion scheme; and\n(3) devising a pruning scheme to accelerate the inference speed of UNet++. We\nhave evaluated UNet++ using six different medical image segmentation datasets,\ncovering multiple imaging modalities such as computed tomography (CT), magnetic\nresonance imaging (MRI), and electron microscopy (EM), and demonstrating that\n(1) UNet++ consistently outperforms the baseline models for the task of\nsemantic segmentation across different datasets and backbone architectures; (2)\nUNet++ enhances segmentation quality of varying-size objects -- an improvement\nover the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design)\noutperforms the original Mask R-CNN for the task of instance segmentation; and\n(4) pruned UNet++ models achieve significant speedup while showing only modest\nperformance degradation. Our implementation and pre-trained models are\navailable at https://github.com/MrGiovanni/UNetPlusPlus.", "published": "2019-12-11T01:26:22Z", "version": 2}, {"aid": "1912.05433", "authors": ["Tiberiu Tesileanu", "Mary M. Conte", "John J. Briguglio", "Ann M. Hermundstad", "Jonathan D. Victor", "Vijay Balasubramanian"], "title": "Efficient coding of natural scene statistics predicts discrimination thresholds for grayscale textures", "url": "http://arxiv.org/pdf/1912.05433v2", "summary": "Previously, in (Hermundstad et al., 2014), we showed that when sampling is\nlimiting, the efficient coding principle leads to a \"variance is salience\"\nhypothesis, and that this hypothesis accounts for visual sensitivity to binary\nimage statistics. Here, using extensive new psychophysical data and image\nanalysis, we show that this hypothesis accounts for visual sensitivity to a\nlarge set of grayscale image statistics at a striking level of detail, and also\nidentify the limits of the prediction. We define a 66-dimensional space of\nlocal grayscale light-intensity correlations, and measure the relevance of each\ndirection to natural scenes. The \"variance is salience\" hypothesis predicts\nthat two-point correlations are most salient, and predicts their relative\nsalience. We tested these predictions in a texture-segregation task using\nun-natural, synthetic textures. As predicted, correlations beyond second order\nare not salient, and predicted thresholds for over 300 second-order\ncorrelations match psychophysical thresholds closely (median fractional error\n<0.13).", "published": "2019-12-11T16:41:27Z", "version": 2}, {"aid": "1912.05845", "authors": ["Anthony Ortiz", "Caleb Robinson", "Dan Morris", "Olac Fuentes", "Christopher Kiekintveld", "Md Mahmudulla Hassan", "Nebojsa Jojic"], "title": "Local Context Normalization: Revisiting Local Normalization", "url": "http://arxiv.org/pdf/1912.05845v3", "summary": "Normalization layers have been shown to improve convergence in deep neural\nnetworks, and even add useful inductive biases. In many vision applications the\nlocal spatial context of the features is important, but most common\nnormalization schemes including Group Normalization (GN), Instance\nNormalization (IN), and Layer Normalization (LN) normalize over the entire\nspatial dimension of a feature. This can wash out important signals and degrade\nperformance. For example, in applications that use satellite imagery, input\nimages can be arbitrarily large; consequently, it is nonsensical to normalize\nover the entire area. Positional Normalization (PN), on the other hand, only\nnormalizes over a single spatial position at a time. A natural compromise is to\nnormalize features by local context, while also taking into account group level\ninformation. In this paper, we propose Local Context Normalization (LCN): a\nnormalization layer where every feature is normalized based on a window around\nit and the filters in its group. We propose an algorithmic solution to make LCN\nefficient for arbitrary window sizes, even if every point in the image has a\nunique window. LCN outperforms its Batch Normalization (BN), GN, IN, and LN\ncounterparts for object detection, semantic segmentation, and instance\nsegmentation applications in several benchmark datasets, while keeping\nperformance independent of the batch size and facilitating transfer learning.", "published": "2019-12-12T09:28:24Z", "version": 3}, {"aid": "1912.05864", "authors": ["Hichem Sahbi"], "title": "Totally Deep Support Vector Machines", "url": "http://arxiv.org/pdf/1912.05864v1", "summary": "Support vector machines (SVMs) have been successful in solving many computer\nvision tasks including image and video category recognition especially for\nsmall and mid-scale training problems. The principle of these non-parametric\nmodels is to learn hyperplanes that separate data belonging to different\nclasses while maximizing their margins. However, SVMs constrain the learned\nhyperplanes to lie in the span of support vectors, fixed/taken from training\ndata, and this reduces their representational power and may lead to limited\ngeneralization performances. In this paper, we relax this constraint and allow\nthe support vectors to be learned (instead of being fixed/taken from training\ndata) in order to better fit a given classification task. Our approach,\nreferred to as deep total variation support vector machines, is parametric and\nrelies on a novel deep architecture that learns not only the SVM and the kernel\nparameters but also the support vectors, resulting into highly effective\nclassifiers. We also show (under a particular setting of the activation\nfunctions in this deep architecture) that a large class of kernels and their\ncombinations can be learned. Experiments conducted on the challenging task of\nskeleton-based action recognition show the outperformance of our deep total\nvariation SVMs w.r.t different baselines as well as the related work.", "published": "2019-12-12T10:18:17Z", "version": 1}, {"aid": "1912.05888", "authors": ["Aaron Wewior", "Joachim Weickert"], "title": "Variational Coupling Revisited: Simpler Models, Theoretical Connections, and Novel Applications", "url": "http://arxiv.org/pdf/1912.05888v1", "summary": "Variational models with coupling terms are becoming increasingly popular in\nimage analysis. They involve auxiliary variables, such that their energy\nminimisation splits into multiple fractional steps that can be solved easier\nand more efficiently. In our paper we show that coupling models offer a number\nof interesting properties that go far beyond their obvious numerical benefits.\nWe demonstrate that discontinuity-preserving denoising can be achieved even\nwith quadratic data and smoothness terms, provided that the coupling term\ninvolves the $L^1$ norm. We show that such an $L^1$ coupling term provides\nadditional information as a powerful edge detector that has remained unexplored\nso far. While coupling models in the literature approximate higher order\nregularisation, we argue that already first order coupling models can be\nuseful. As a specific example, we present a first order coupling model that\noutperforms classical TV regularisation. It also establishes a theoretical\nconnection between TV regularisation and the Mumford-Shah segmentation\napproach. Unlike other Mumford-Shah algorithms, it is a strictly convex\napproximation, for which we can guarantee convergence of a split Bregman\nalgorithm.", "published": "2019-12-12T11:44:53Z", "version": 1}, {"aid": "1912.06044", "authors": ["Mor Avi-Aharon", "Assaf Arbelle", "Tammy Riklin Raviv"], "title": "Hue-Net: Intensity-based Image-to-Image Translation with Differentiable Histogram Loss Functions", "url": "http://arxiv.org/pdf/1912.06044v1", "summary": "We present the Hue-Net - a novel Deep Learning framework for Intensity-based\nImage-to-Image Translation. The key idea is a new technique termed network\naugmentation which allows a differentiable construction of intensity histograms\nfrom images. We further introduce differentiable representations of (1D) cyclic\nand joint (2D) histograms and use them for defining loss functions based on\ncyclic Earth Mover's Distance (EMD) and Mutual Information (MI). While the\nHue-Net can be applied to several image-to-image translation tasks, we choose\nto demonstrate its strength on color transfer problems, where the aim is to\npaint a source image with the colors of a different target image. Note that the\ndesired output image does not exist and therefore cannot be used for supervised\npixel-to-pixel learning. This is accomplished by using the HSV color-space and\ndefining an intensity-based loss that is built on the EMD between the cyclic\nhue histograms of the output and the target images. To enforce color-free\nsimilarity between the source and the output images, we define a semantic-based\nloss by a differentiable approximation of the MI of these images. The\nincorporation of histogram loss functions in addition to an adversarial loss\nenables the construction of semantically meaningful and realistic images.\nPromising results are presented for different datasets.", "published": "2019-12-12T15:48:55Z", "version": 1}, {"aid": "1912.06088", "authors": ["Dibya Ghosh", "Abhishek Gupta", "Ashwin Reddy", "Justin Fu", "Coline Devin", "Benjamin Eysenbach", "Sergey Levine"], "title": "Learning to Reach Goals via Iterated Supervised Learning", "url": "http://arxiv.org/pdf/1912.06088v4", "summary": "Current reinforcement learning (RL) algorithms can be brittle and difficult\nto use, especially when learning goal-reaching behaviors from sparse rewards.\nAlthough supervised imitation learning provides a simple and stable\nalternative, it requires access to demonstrations from a human supervisor. In\nthis paper, we study RL algorithms that use imitation learning to acquire goal\nreaching policies from scratch, without the need for expert demonstrations or a\nvalue function. In lieu of demonstrations, we leverage the property that any\ntrajectory is a successful demonstration for reaching the final state in that\nsame trajectory. We propose a simple algorithm in which an agent continually\nrelabels and imitates the trajectories it generates to progressively learn\ngoal-reaching behaviors from scratch. Each iteration, the agent collects new\ntrajectories using the latest policy, and maximizes the likelihood of the\nactions along these trajectories under the goal that was actually reached, so\nas to improve the policy. We formally show that this iterated supervised\nlearning procedure optimizes a bound on the RL objective, derive performance\nbounds of the learned policy, and empirically demonstrate improved\ngoal-reaching performance and robustness over current RL algorithms in several\nbenchmark tasks.", "published": "2019-12-12T17:26:47Z", "version": 4}, {"aid": "1912.06101", "authors": ["Carlos Purves", "C\u0103t\u0103lina Cangea", "Petar Veli\u010dkovi\u0107"], "title": "The PlayStation Reinforcement Learning Environment (PSXLE)", "url": "http://arxiv.org/pdf/1912.06101v1", "summary": "We propose a new benchmark environment for evaluating Reinforcement Learning\n(RL) algorithms: the PlayStation Learning Environment (PSXLE), a PlayStation\nemulator modified to expose a simple control API that enables rich game-state\nrepresentations. We argue that the PlayStation serves as a suitable progression\nfor agent evaluation and propose a framework for such an evaluation. We build\nan action-driven abstraction for a PlayStation game with support for the OpenAI\nGym interface and demonstrate its use by running OpenAI Baselines.", "published": "2019-12-12T17:59:52Z", "version": 1}, {"aid": "1912.06126", "authors": ["Kyle Genova", "Forrester Cole", "Avneesh Sud", "Aaron Sarna", "Thomas Funkhouser"], "title": "Local Deep Implicit Functions for 3D Shape", "url": "http://arxiv.org/pdf/1912.06126v2", "summary": "The goal of this project is to learn a 3D shape representation that enables\naccurate surface reconstruction, compact storage, efficient computation,\nconsistency for similar shapes, generalization across diverse shape categories,\nand inference from depth camera observations. Towards this end, we introduce\nLocal Deep Implicit Functions (LDIF), a 3D shape representation that decomposes\nspace into a structured set of learned implicit functions. We provide networks\nthat infer the space decomposition and local deep implicit functions from a 3D\nmesh or posed depth image. During experiments, we find that it provides 10.3\npoints higher surface reconstruction accuracy (F-Score) than the\nstate-of-the-art (OccNet), while requiring fewer than 1 percent of the network\nparameters. Experiments on posed depth image completion and generalization to\nunseen classes show 15.8 and 17.8 point improvements over the state-of-the-art,\nwhile producing a structured 3D representation for each input with consistency\nacross diverse shape collections.", "published": "2019-12-12T18:50:46Z", "version": 2}, {"aid": "1912.06798", "authors": ["Xun Wang", "Haozhi Zhang", "Weilin Huang", "Matthew R. Scott"], "title": "Cross-Batch Memory for Embedding Learning", "url": "http://arxiv.org/pdf/1912.06798v3", "summary": "Mining informative negative instances are of central importance to deep\nmetric learning (DML), however this task is intrinsically limited by mini-batch\ntraining, where only a mini-batch of instances is accessible at each iteration.\nIn this paper, we identify a \"slow drift\" phenomena by observing that the\nembedding features drift exceptionally slow even as the model parameters are\nupdating throughout the training process. This suggests that the features of\ninstances computed at preceding iterations can be used to considerably\napproximate their features extracted by the current model. We propose a\ncross-batch memory (XBM) mechanism that memorizes the embeddings of past\niterations, allowing the model to collect sufficient hard negative pairs across\nmultiple mini-batches - even over the whole dataset. Our XBM can be directly\nintegrated into a general pair-based DML framework, where the XBM augmented DML\ncan boost performance considerably. In particular, without bells and whistles,\na simple contrastive loss with our XBM can have large R@1 improvements of\n12%-22.5% on three large-scale image retrieval datasets, surpassing the most\nsophisticated state-of-the-art methods, by a large margin. Our XBM is\nconceptually simple, easy to implement - using several lines of codes, and is\nmemory efficient - with a negligible 0.2 GB extra GPU memory. Code is available\nat: https://github.com/MalongTech/research-xbm.", "published": "2019-12-14T07:38:53Z", "version": 3}, {"aid": "1912.11531", "authors": ["Luca Pasqualini", "Maurizio Parton"], "title": "Pseudo Random Number Generation: a Reinforcement Learning approach", "url": "http://arxiv.org/pdf/1912.11531v1", "summary": "Pseudo-Random Numbers Generators (PRNGs) are algorithms produced to generate\nlong sequences of statistically uncorrelated numbers, i.e. Pseudo-Random\nNumbers (PRNs). These numbers are widely employed in mid-level cryptography and\nin software applications. Test suites are used to evaluate PRNGs quality by\nchecking statistical properties of the generated sequences. Machine learning\ntechniques are often used to break these generators, for instance approximating\na certain generator or a certain sequence using a neural network. But what\nabout using machine learning to generate PRNs generators? This paper proposes a\nReinforcement Learning (RL) approach to the task of generating PRNGs from\nscratch by learning a policy to solve an N-dimensional navigation problem. In\nthis context, N is the length of the period of the generated sequence, and the\npolicy is iteratively improved using the average value of an appropriate test\nsuite run over that period. Aim of this work is to demonstrate the feasibility\nof the proposed approach, to compare it with classical methods, and to lay the\nfoundation of a research path which combines RL and PRNGs.", "published": "2019-12-15T13:32:07Z", "version": 1}, {"aid": "1912.12138", "authors": ["Zhao Zhang", "Yulin Sun", "Yang Wang", "Zhengjun Zha", "Shuicheng Yan", "Meng Wang"], "title": "Convolutional Dictionary Pair Learning Network for Image Representation Learning", "url": "http://arxiv.org/pdf/1912.12138v3", "summary": "Both the Dictionary Learning (DL) and Convolutional Neural Networks (CNN) are\npowerful image representation learning systems based on different mechanisms\nand principles, however whether we can seamlessly integrate them to improve the\nper-formance is noteworthy exploring. To address this issue, we propose a novel\ngeneralized end-to-end representation learning architecture, dubbed\nConvolutional Dictionary Pair Learning Network (CDPL-Net) in this paper, which\nintegrates the learning schemes of the CNN and dictionary pair learning into a\nunified framework. Generally, the architecture of CDPL-Net includes two\nconvolutional/pooling layers and two dictionary pair learn-ing (DPL) layers in\nthe representation learning module. Besides, it uses two fully-connected layers\nas the multi-layer perception layer in the nonlinear classification module. In\nparticular, the DPL layer can jointly formulate the discriminative synthesis\nand analysis representations driven by minimizing the batch based\nreconstruction error over the flatted feature maps from the convolution/pooling\nlayer. Moreover, DPL layer uses l1-norm on the analysis dictionary so that\nsparse representation can be delivered, and the embedding process will also be\nrobust to noise. To speed up the training process of DPL layer, the efficient\nstochastic gradient descent is used. Extensive simulations on real databases\nshow that our CDPL-Net can deliver enhanced performance over other\nstate-of-the-art methods.", "published": "2019-12-17T01:34:28Z", "version": 3}, {"aid": "1912.07863", "authors": ["Ye Yuan", "Wuyang Chen", "Yang Yang", "Zhangyang Wang"], "title": "In Defense of the Triplet Loss Again: Learning Robust Person Re-Identification with Fast Approximated Triplet Loss and Label Distillation", "url": "http://arxiv.org/pdf/1912.07863v2", "summary": "The comparative losses (typically, triplet loss) are appealing choices for\nlearning person re-identification (ReID) features. However, the triplet loss is\ncomputationally much more expensive than the (practically more popular)\nclassification loss, limiting their wider usage in massive datasets. Moreover,\nthe abundance of label noise and outliers in ReID datasets may also put the\nmargin-based loss in jeopardy. This work addresses the above two shortcomings\nof triplet loss, extending its effectiveness to large-scale ReID datasets with\npotentially noisy labels. We propose a fast-approximated triplet (FAT) loss,\nwhich provably converts the point-wise triplet loss into its upper bound form,\nconsisting of a point-to-set loss term plus cluster compactness regularization.\nIt preserves the effectiveness of triplet loss, while leading to linear\ncomplexity to the training set size. A label distillation strategy is further\ndesigned to learn refined soft-labels in place of the potentially noisy labels,\nfrom only an identified subset of confident examples, through teacher-student\nnetworks. We conduct extensive experiments on three most popular ReID\nbenchmarks (Market-1501, DukeMTMC-reID, and MSMT17), and demonstrate that FAT\nloss with distilled labels lead to ReID features with remarkable accuracy,\nefficiency, robustness, and direct transferability to unseen datasets.", "published": "2019-12-17T08:16:45Z", "version": 2}, {"aid": "1912.08812", "authors": ["Frederico Guth", "Teofilo Emidio de-Campos"], "title": "Research Frontiers in Transfer Learning -- a systematic and bibliometric review", "url": "http://arxiv.org/pdf/1912.08812v1", "summary": "Humans can learn from very few samples, demonstrating an outstanding\ngeneralization ability that learning algorithms are still far from reaching.\nCurrently, the most successful models demand enormous amounts of well-labeled\ndata, which are expensive and difficult to obtain, becoming one of the biggest\nobstacles to the use of machine learning in practice. This scenario shows the\nmassive potential for Transfer Learning, which aims to harness previously\nacquired knowledge to the learning of new tasks more effectively and\nefficiently. In this systematic review, we apply a quantitative method to\nselect the main contributions to the field and make use of bibliographic\ncoupling metrics to identify research frontiers. We further analyze the\nlinguistic variation between the classics of the field and the frontier and map\npromising research directions.", "published": "2019-12-18T15:08:19Z", "version": 1}, {"aid": "1912.08795", "authors": ["Hongxu Yin", "Pavlo Molchanov", "Zhizhong Li", "Jose M. Alvarez", "Arun Mallya", "Derek Hoiem", "Niraj K. Jha", "Jan Kautz"], "title": "Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion", "url": "http://arxiv.org/pdf/1912.08795v2", "summary": "We introduce DeepInversion, a new method for synthesizing images from the\nimage distribution used to train a deep neural network. We 'invert' a trained\nnetwork (teacher) to synthesize class-conditional input images starting from\nrandom noise, without using any additional information about the training\ndataset. Keeping the teacher fixed, our method optimizes the input while\nregularizing the distribution of intermediate feature maps using information\nstored in the batch normalization layers of the teacher. Further, we improve\nthe diversity of synthesized images using Adaptive DeepInversion, which\nmaximizes the Jensen-Shannon divergence between the teacher and student network\nlogits. The resulting synthesized images from networks trained on the CIFAR-10\nand ImageNet datasets demonstrate high fidelity and degree of realism, and help\nenable a new breed of data-free applications - ones that do not require any\nreal images or labeled data. We demonstrate the applicability of our proposed\nmethod to three tasks of immense practical importance -- (i) data-free network\npruning, (ii) data-free knowledge transfer, and (iii) data-free continual\nlearning. Code is available at https://github.com/NVlabs/DeepInversion", "published": "2019-12-18T18:50:10Z", "version": 2}, {"aid": "1912.08957", "authors": ["Ruoyu Sun"], "title": "Optimization for deep learning: theory and algorithms", "url": "http://arxiv.org/pdf/1912.08957v1", "summary": "When and why can a neural network be successfully trained? This article\nprovides an overview of optimization algorithms and theory for training neural\nnetworks. First, we discuss the issue of gradient explosion/vanishing and the\nmore general issue of undesirable spectrum, and then discuss practical\nsolutions including careful initialization and normalization methods. Second,\nwe review generic optimization methods used in training neural networks, such\nas SGD, adaptive gradient methods and distributed methods, and theoretical\nresults for these algorithms. Third, we review existing research on the global\nissues of neural network training, including results on bad local minima, mode\nconnectivity, lottery ticket hypothesis and infinite-width analysis.", "published": "2019-12-19T00:23:18Z", "version": 1}, {"aid": "1912.08998", "authors": ["Masahiro Kazama", "Yoshihiko Suhara", "Andrey Bogomolov", "Alex `Sandy' Pentland"], "title": "Understanding Human Judgments of Causality", "url": "http://arxiv.org/pdf/1912.08998v1", "summary": "Discriminating between causality and correlation is a major problem in\nmachine learning, and theoretical tools for determining causality are still\nbeing developed. However, people commonly make causality judgments and are\noften correct, even in unfamiliar domains. What are humans doing to make these\njudgments? This paper examines differences in human experts' and non-experts'\nability to attribute causality by comparing their performances to those of\nmachine-learning algorithms. We collected human judgments by using Amazon\nMechanical Turk (MTurk) and then divided the human subjects into two groups:\nexperts and non-experts. We also prepared expert and non-expert machine\nalgorithms based on different training of convolutional neural network (CNN)\nmodels. The results showed that human experts' judgments were similar to those\nmade by an \"expert\" CNN model trained on a large number of examples from the\ntarget domain. The human non-experts' judgments resembled the prediction\noutputs of the CNN model that was trained on only the small number of examples\nused during the MTurk instruction. We also analyzed the differences between the\nexpert and non-expert machine algorithms based on their neural representations\nto evaluate the performances, providing insight into the human experts' and\nnon-experts' cognitive abilities.", "published": "2019-12-19T03:08:11Z", "version": 1}, {"aid": "1912.09336", "authors": ["Nilavra Bhattacharya", "Danna Gurari"], "title": "VizWiz Dataset Browser: A Tool for Visualizing Machine Learning Datasets", "url": "http://arxiv.org/pdf/1912.09336v1", "summary": "We present a visualization tool to exhaustively search and browse through a\nset of large-scale machine learning datasets. Built on the top of the VizWiz\ndataset, our dataset browser tool has the potential to support and enable a\nvariety of qualitative and quantitative research, and open new directions for\nvisualizing and researching with multimodal information. The tool is publicly\navailable at https://vizwiz.org/browse.", "published": "2019-12-19T16:18:34Z", "version": 1}, {"aid": "1912.10891", "authors": ["Jingbin Liu", "Shuai Liu", "Xinyang Gu"], "title": "Soft Q Network", "url": "http://arxiv.org/pdf/1912.10891v2", "summary": "Deep Q Network (DQN) is a very successful algorithm, yet the inherent problem\nof reinforcement learning, i.e. the exploit-explore balance, remains. In this\nwork, we introduce entropy regularization into DQN and propose SQN. We find\nthat the backup equation of soft Q learning can enjoy the corrective feedback\nif we view the soft backup as policy improvement in the form of Q, instead of\npolicy evaluation. We show that Soft Q Learning with Corrective Feedback\n(SQL-CF) underlies the on-plicy nature of SQL and the equivalence of SQL and\nSoft Policy Gradient (SPG). With these insights, we propose an on-policy\nversion of deep Q learning algorithm, i.e. Q On-Policy (QOP). We experiment\nwith QOP on a self-play environment called Google Research Football (GRF). The\nQOP algorithm exhibits great stability and efficiency in training GRF agents.", "published": "2019-12-20T01:55:40Z", "version": 2}, {"aid": "1912.12180", "authors": ["Jonathan Ho", "Nal Kalchbrenner", "Dirk Weissenborn", "Tim Salimans"], "title": "Axial Attention in Multidimensional Transformers", "url": "http://arxiv.org/pdf/1912.12180v1", "summary": "We propose Axial Transformers, a self-attention-based autoregressive model\nfor images and other data organized as high dimensional tensors. Existing\nautoregressive models either suffer from excessively large computational\nresource requirements for high dimensional data, or make compromises in terms\nof distribution expressiveness or ease of implementation in order to decrease\nresource requirements. Our architecture, by contrast, maintains both full\nexpressiveness over joint distributions over data and ease of implementation\nwith standard deep learning frameworks, while requiring reasonable memory and\ncomputation and achieving state-of-the-art results on standard generative\nmodeling benchmarks. Our models are based on axial attention, a simple\ngeneralization of self-attention that naturally aligns with the multiple\ndimensions of the tensors in both the encoding and the decoding settings.\nNotably the proposed structure of the layers allows for the vast majority of\nthe context to be computed in parallel during decoding without introducing any\nindependence assumptions. This semi-parallel structure goes a long way to\nmaking decoding from even a very large Axial Transformer broadly applicable. We\ndemonstrate state-of-the-art results for the Axial Transformer on the\nImageNet-32 and ImageNet-64 image benchmarks as well as on the BAIR Robotic\nPushing video benchmark. We open source the implementation of Axial\nTransformers.", "published": "2019-12-20T13:27:27Z", "version": 1}, {"aid": "1912.10092", "authors": ["Cory J. Butz", "Jhonatan S. Oliveira", "Robert Peharz"], "title": "Sum-Product Network Decompilation", "url": "http://arxiv.org/pdf/1912.10092v2", "summary": "There exists a dichotomy between classical probabilistic graphical models,\nsuch as Bayesian networks (BNs), and modern tractable models, such as\nsum-product networks (SPNs). The former generally have intractable inference,\nbut provide a high level of interpretability, while the latter admits a wide\nrange of tractable inference routines, but are typically harder to interpret.\nDue to this dichotomy, tools to convert between BNs and SPNs are desirable.\nWhile one direction -- compiling BNs into SPNs -- is well discussed in\nDarwiche's seminal work on arithmetic circuit compilation, the converse\ndirection -- decompiling SPNs into BNs -- has received surprisingly little\nattention.\n  In this paper, we fill this gap by proposing SPN2BN, an algorithm that\ndecompiles an SPN into a BN. SPN2BN has several salient features when compared\nto the only other two works decompiling SPNs. Most significantly, the BNs\nreturned by SPN2BN are minimal independence-maps that are more parsimonious\nwith respect to the introduction of latent variables. Secondly, the output BN\nproduced by SPN2BN can be precisely characterized with respect to a compiled\nBN. More specifically, a certain set of directed edges will be added to the\ninput BN, giving what we will call the moral-closure. Lastly, it is established\nthat our compilation-decompilation process is idempotent. This has practical\nsignificance as it limits the size of the decompiled SPN.", "published": "2019-12-20T20:39:28Z", "version": 2}, {"aid": "1912.11037", "authors": ["Ulysse C\u00f4t\u00e9-Allard", "Gabriel Gagnon-Turcotte", "Angkoon Phinyomark", "Kyrre Glette", "Erik Scheme", "Fran\u00e7ois Laviolette", "Benoit Gosselin"], "title": "Unsupervised Domain Adversarial Self-Calibration for Electromyographic-based Gesture Recognition", "url": "http://arxiv.org/pdf/1912.11037v5", "summary": "Surface electromyography (sEMG) provides an intuitive and non-invasive\ninterface from which to control machines. However, preserving the myoelectric\ncontrol system's performance over multiple days is challenging, due to the\ntransient nature of the signals obtained with this recording technique. In\npractice, if the system is to remain usable, a time-consuming and periodic\nrecalibration is necessary. In the case where the sEMG interface is employed\nevery few days, the user might need to do this recalibration before every use.\nThus, severely limiting the practicality of such a control method.\nConsequently, this paper proposes tackling the especially challenging task of\nunsupervised adaptation of sEMG signals, when multiple days have elapsed\nbetween each recording, by introducing Self-Calibrating Asynchronous Domain\nAdversarial Neural Network (SCADANN). SCADANN is compared with two\nstate-of-the-art self-calibrating algorithms developed specifically for deep\nlearning within the context of EMG-based gesture recognition and three\nstate-of-the-art domain adversarial algorithms. The comparison is made both on\nan offline and a dynamic dataset (20 participants per dataset), using two\ndifferent deep network architectures with two different input modalities\n(temporal-spatial descriptors and spectrograms). Overall, SCADANN is shown to\nsubstantially and systematically improves classification performances over no\nrecalibration and obtains the highest average accuracy for all tested cases\nacross all methods.", "published": "2019-12-21T17:42:26Z", "version": 5}, {"aid": "1912.10321", "authors": ["Ari Heljakka", "Yuxin Hou", "Juho Kannala", "Arno Solin"], "title": "Deep Automodulators", "url": "http://arxiv.org/pdf/1912.10321v4", "summary": "We introduce a new category of generative autoencoders called automodulators.\nThese networks can faithfully reproduce individual real-world input images like\nregular autoencoders, but also generate a fused sample from an arbitrary\ncombination of several such images, allowing instantaneous 'style-mixing' and\nother new applications. An automodulator decouples the data flow of decoder\noperations from statistical properties thereof and uses the latent vector to\nmodulate the former by the latter, with a principled approach for mutual\ndisentanglement of decoder layers. Prior work has explored similar decoder\narchitecture with GANs, but their focus has been on random sampling. A\ncorresponding autoencoder could operate on real input images. For the first\ntime, we show how to train such a general-purpose model with sharp outputs in\nhigh resolution, using novel training techniques, demonstrated on four image\ndata sets. Besides style-mixing, we show state-of-the-art results in\nautoencoder comparison, and visual image quality nearly indistinguishable from\nstate-of-the-art GANs. We expect the automodulator variants to become a useful\nbuilding block for image applications and other data domains.", "published": "2019-12-21T19:16:33Z", "version": 4}, {"aid": "2001.01686", "authors": ["Omolbanin Yazdanbakhsh", "Scott Dick"], "title": "A Deep Neuro-Fuzzy Network for Image Classification", "url": "http://arxiv.org/pdf/2001.01686v1", "summary": "The combination of neural network and fuzzy systems into neuro-fuzzy systems\nintegrates fuzzy reasoning rules into the connectionist networks. However, the\nexisting neuro-fuzzy systems are developed under shallow structures having\nlower generalization capacity. We propose the first end-to-end deep neuro-fuzzy\nnetwork and investigate its application for image classification. Two new\noperations are developed based on definitions of Takagi-Sugeno-Kang (TSK) fuzzy\nmodel namely fuzzy inference operation and fuzzy pooling operations; stacks of\nthese operations comprise the layers in this network. We evaluate the network\non MNIST, CIFAR-10 and CIFAR-100 datasets, finding that the network has a\nreasonable accuracy in these benchmarks.", "published": "2019-12-22T03:28:05Z", "version": 1}, {"aid": "1912.10557", "authors": ["Vishal Monga", "Yuelong Li", "Yonina C. Eldar"], "title": "Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing", "url": "http://arxiv.org/pdf/1912.10557v3", "summary": "Deep neural networks provide unprecedented performance gains in many real\nworld problems in signal and image processing. Despite these gains, future\ndevelopment and practical deployment of deep networks is hindered by their\nblackbox nature, i.e., lack of interpretability, and by the need for very large\ntraining sets. An emerging technique called algorithm unrolling or unfolding\noffers promise in eliminating these issues by providing a concrete and\nsystematic connection between iterative algorithms that are used widely in\nsignal processing and deep neural networks. Unrolling methods were first\nproposed to develop fast neural network approximations for sparse coding. More\nrecently, this direction has attracted enormous attention and is rapidly\ngrowing both in theoretic investigations and practical applications. The\ngrowing popularity of unrolled deep networks is due in part to their potential\nin developing efficient, high-performance and yet interpretable network\narchitectures from reasonable size training sets. In this article, we review\nalgorithm unrolling for signal and image processing. We extensively cover\npopular techniques for algorithm unrolling in various domains of signal and\nimage processing including imaging, vision and recognition, and speech\nprocessing. By reviewing previous works, we reveal the connections between\niterative algorithms and neural networks and present recent theoretical\nresults. Finally, we provide a discussion on current limitations of unrolling\nand suggest possible future research directions.", "published": "2019-12-22T23:02:18Z", "version": 3}, {"aid": "1912.10752", "authors": ["S. Balaji", "T. Kavya", "Natasha Sebastian"], "title": "Learn-able parameter guided Activation Functions", "url": "http://arxiv.org/pdf/1912.10752v1", "summary": "In this paper, we explore the concept of adding learn-able slope and mean\nshift parameters to an activation function to improve the total response\nregion. The characteristics of an activation function depend highly on the\nvalue of parameters. Making the parameters learn-able, makes the activation\nfunction more dynamic and capable to adapt as per the requirements of its\nneighboring layers. The introduced slope parameter is independent of other\nparameters in the activation function. The concept was applied to ReLU to\ndevelop Dual Line and DualParametric ReLU activation function. Evaluation on\nMNIST and CIFAR10 show that the proposed activation function Dual Line achieves\ntop-5 position for mean accuracy among 43 activation functions tested with\nLENET4, LENET5, and WideResNet architectures. This is the first time more than\n40 activation functions were analyzed on MNIST andCIFAR10 dataset at the same\ntime. The study on the distribution of positive slope parameter beta indicates\nthat the activation function adapts as per the requirements of the neighboring\nlayers. The study shows that model performance increases with the proposed\nactivation functions", "published": "2019-12-23T11:54:05Z", "version": 1}, {"aid": "1912.11554", "authors": ["Du Phan", "Neeraj Pradhan", "Martin Jankowiak"], "title": "Composable Effects for Flexible and Accelerated Probabilistic Programming in NumPyro", "url": "http://arxiv.org/pdf/1912.11554v1", "summary": "NumPyro is a lightweight library that provides an alternate NumPy backend to\nthe Pyro probabilistic programming language with the same modeling interface,\nlanguage primitives and effect handling abstractions. Effect handlers allow\nPyro's modeling API to be extended to NumPyro despite its being built atop a\nfundamentally different JAX-based functional backend. In this work, we\ndemonstrate the power of composing Pyro's effect handlers with the program\ntransformations that enable hardware acceleration, automatic differentiation,\nand vectorization in JAX. In particular, NumPyro provides an iterative\nformulation of the No-U-Turn Sampler (NUTS) that can be end-to-end JIT\ncompiled, yielding an implementation that is much faster than existing\nalternatives in both the small and large dataset regimes.", "published": "2019-12-24T22:09:36Z", "version": 1}, {"aid": "1912.13200", "authors": ["Hanting Chen", "Yunhe Wang", "Chunjing Xu", "Boxin Shi", "Chao Xu", "Qi Tian", "Chang Xu"], "title": "AdderNet: Do We Really Need Multiplications in Deep Learning?", "url": "http://arxiv.org/pdf/1912.13200v6", "summary": "Compared with cheap addition operation, multiplication operation is of much\nhigher computation complexity. The widely-used convolutions in deep neural\nnetworks are exactly cross-correlation to measure the similarity between input\nfeature and convolution filters, which involves massive multiplications between\nfloat values. In this paper, we present adder networks (AdderNets) to trade\nthese massive multiplications in deep neural networks, especially convolutional\nneural networks (CNNs), for much cheaper additions to reduce computation costs.\nIn AdderNets, we take the $\\ell_1$-norm distance between filters and input\nfeature as the output response. The influence of this new similarity measure on\nthe optimization of neural network have been thoroughly analyzed. To achieve a\nbetter performance, we develop a special back-propagation approach for\nAdderNets by investigating the full-precision gradient. We then propose an\nadaptive learning rate strategy to enhance the training procedure of AdderNets\naccording to the magnitude of each neuron's gradient. As a result, the proposed\nAdderNets can achieve 74.9% Top-1 accuracy 91.7% Top-5 accuracy using ResNet-50\non the ImageNet dataset without any multiplication in convolution layer. The\ncodes are publicly available at: https://github.com/huaweinoah/AdderNet.", "published": "2019-12-31T06:56:47Z", "version": 6}, {"aid": "2001.00215", "authors": ["Joshua Peeples", "Weihuang Xu", "Alina Zare"], "title": "Histogram Layers for Texture Analysis", "url": "http://arxiv.org/pdf/2001.00215v12", "summary": "An essential aspect of texture analysis is the extraction of features that\ndescribe the distribution of values in local, spatial regions. We present a\nlocalized histogram layer for artificial neural networks. Instead of computing\nglobal histograms as done previously, the proposed histogram layer directly\ncomputes the local, spatial distribution of features for texture analysis and\nparameters for the layer are estimated during backpropagation. We compare our\nmethod with state-of-the-art texture encoding methods such as the Deep Encoding\nNetwork Pooling, Deep Texture Encoding Network, Fisher Vector convolutional\nneural network, and Multi-level Texture Encoding and Representation on three\nmaterial/texture datasets: (1) the Describable Texture Dataset; (2) an\nextension of the ground terrain in outdoor scenes; (3) and a subset of the\nMaterials in Context dataset. Results indicate that the inclusion of the\nproposed histogram layer improves performance. The source code for the\nhistogram layer is publicly available:\nhttps://github.com/GatorSense/Histogram_Layer.", "published": "2020-01-01T14:41:54Z", "version": 12}, {"aid": "2001.01034", "authors": ["Yifei Li", "Kuangyan Song", "Yiming Sun", "Liao Zhu"], "title": "FrequentNet: A Novel Interpretable Deep Learning Model for Image Classification", "url": "http://arxiv.org/pdf/2001.01034v4", "summary": "This paper has proposed a new baseline deep learning model of more benefits\nfor image classification. Different from the convolutional neural network(CNN)\npractice where filters are trained by back propagation to represent different\npatterns of an image, we are inspired by a method called \"PCANet\" in \"PCANet: A\nSimple Deep Learning Baseline for Image Classification?\" to choose filter\nvectors from basis vectors in frequency domain like Fourier coefficients or\nwavelets without back propagation. Researchers have demonstrated that those\nbasis in frequency domain can usually provide physical insights, which adds to\nthe interpretability of the model by analyzing the frequencies selected.\nBesides, the training process will also be more time efficient, mathematically\nclear and interpretable compared with the \"black-box\" training process of CNN.", "published": "2020-01-04T04:31:32Z", "version": 4}, {"aid": "2001.03288", "authors": ["Yury Pisarchyk", "Juhyun Lee"], "title": "Efficient Memory Management for Deep Neural Net Inference", "url": "http://arxiv.org/pdf/2001.03288v3", "summary": "While deep neural net inference was considered a task for servers only,\nlatest advances in technology allow the task of inference to be moved to mobile\nand embedded devices, desired for various reasons ranging from latency to\nprivacy. These devices are not only limited by their compute power and battery,\nbut also by their inferior physical memory and cache, and thus, an efficient\nmemory manager becomes a crucial component for deep neural net inference at the\nedge. We explore various strategies to smartly share memory buffers among\nintermediate tensors in deep neural nets. Employing these can result in up to\n11% smaller memory footprint than the state of the art.", "published": "2020-01-10T02:45:41Z", "version": 3}, {"aid": "2001.03354", "authors": ["Chan Li", "Haiping Huang"], "title": "Learning credit assignment", "url": "http://arxiv.org/pdf/2001.03354v2", "summary": "Deep learning has achieved impressive prediction accuracies in a variety of\nscientific and industrial domains. However, the nested non-linear feature of\ndeep learning makes the learning highly non-transparent, i.e., it is still\nunknown how the learning coordinates a huge number of parameters to achieve a\ndecision making. To explain this hierarchical credit assignment, we propose a\nmean-field learning model by assuming that an ensemble of sub-networks, rather\nthan a single network, are trained for a classification task. Surprisingly, our\nmodel reveals that apart from some deterministic synaptic weights connecting\ntwo neurons at neighboring layers, there exist a large number of connections\nthat can be absent, and other connections can allow for a broad distribution of\ntheir weight values. Therefore, synaptic connections can be classified into\nthree categories: very important ones, unimportant ones, and those of\nvariability that may partially encode nuisance factors. Therefore, our model\nlearns the credit assignment leading to the decision, and predicts an ensemble\nof sub-networks that can accomplish the same task, thereby providing insights\ntoward understanding the macroscopic behavior of deep learning through the lens\nof distinct roles of synaptic weights.", "published": "2020-01-10T09:06:46Z", "version": 2}, {"aid": "2001.03698", "authors": ["Dongsheng An", "Yang Guo", "Min Zhang", "Xin Qi", "Na Lei", "Shing-Tung Yau", "Xianfeng Gu"], "title": "AE-OT-GAN: Training GANs from data specific latent distribution", "url": "http://arxiv.org/pdf/2001.03698v2", "summary": "Though generative adversarial networks (GANs) areprominent models to generate\nrealistic and crisp images,they often encounter the mode collapse problems and\narehard to train, which comes from approximating the intrinsicdiscontinuous\ndistribution transform map with continuousDNNs. The recently proposed AE-OT\nmodel addresses thisproblem by explicitly computing the discontinuous\ndistribu-tion transform map through solving a semi-discrete optimaltransport\n(OT) map in the latent space of the autoencoder.However the generated images\nare blurry. In this paper, wepropose the AE-OT-GAN model to utilize the\nadvantages ofthe both models: generate high quality images and at thesame time\novercome the mode collapse/mixture problems.Specifically, we first faithfully\nembed the low dimensionalimage manifold into the latent space by training an\nautoen-coder (AE). Then we compute the optimal transport (OT)map that pushes\nforward the uniform distribution to the la-tent distribution supported on the\nlatent manifold. Finally,our GAN model is trained to generate high quality\nimagesfrom the latent distribution, the distribution transform mapfrom which to\nthe empirical data distribution will be con-tinuous. The paired data between\nthe latent code and thereal images gives us further constriction about the\ngenerator.Experiments on simple MNIST dataset and complex datasetslike Cifar-10\nand CelebA show the efficacy and efficiency ofour proposed method.", "published": "2020-01-11T01:18:00Z", "version": 2}, {"aid": "2001.04147", "authors": ["Andrzej Bedychaj", "Przemys\u0142aw Spurek", "Aleksandra Nowak", "Jacek Tabor"], "title": "WICA: nonlinear weighted ICA", "url": "http://arxiv.org/pdf/2001.04147v2", "summary": "Independent Component Analysis (ICA) aims to find a coordinate system in\nwhich the components of the data are independent. In this paper we construct a\nnew nonlinear ICA model, called WICA, which obtains better and more stable\nresults than other algorithms. A crucial tool is given by a new efficient\nmethod of verifying nonlinear dependence with the use of computation of\ncorrelation coefficients for normally weighted data. In addition, authors\npropose a new baseline nonlinear mixing to perform comparable experiments, and\na~reliable measure which allows fair comparison of nonlinear models. Our code\nfor WICA is available on Github https://github.com/gmum/wica.", "published": "2020-01-13T10:38:03Z", "version": 2}, {"aid": "2001.04418", "authors": ["Michiel van der Meer", "Matteo Pirotta", "Elia Bruni"], "title": "Exploiting Language Instructions for Interpretable and Compositional Reinforcement Learning", "url": "http://arxiv.org/pdf/2001.04418v1", "summary": "In this work, we present an alternative approach to making an agent\ncompositional through the use of a diagnostic classifier. Because of the need\nfor explainable agents in automated decision processes, we attempt to interpret\nthe latent space from an RL agent to identify its current objective in a\ncomplex language instruction. Results show that the classification process\ncauses changes in the hidden states which makes them more easily interpretable,\nbut also causes a shift in zero-shot performance to novel instructions. Lastly,\nwe limit the supervisory signal on the classification, and observe a similar\nbut less notable effect.", "published": "2020-01-13T17:35:56Z", "version": 1}, {"aid": "2001.05005", "authors": ["Erich Kobler", "Alexander Effland", "Karl Kunisch", "Thomas Pock"], "title": "Total Deep Variation for Linear Inverse Problems", "url": "http://arxiv.org/pdf/2001.05005v2", "summary": "Diverse inverse problems in imaging can be cast as variational problems\ncomposed of a task-specific data fidelity term and a regularization term. In\nthis paper, we propose a novel learnable general-purpose regularizer exploiting\nrecent architectural design patterns from deep learning. We cast the learning\nproblem as a discrete sampled optimal control problem, for which we derive the\nadjoint state equations and an optimality condition. By exploiting the\nvariational structure of our approach, we perform a sensitivity analysis with\nrespect to the learned parameters obtained from different training datasets.\nMoreover, we carry out a nonlinear eigenfunction analysis, which reveals\ninteresting properties of the learned regularizer. We show state-of-the-art\nperformance for classical image restoration and medical image reconstruction\nproblems.", "published": "2020-01-14T19:01:50Z", "version": 2}, {"aid": "2001.05868", "authors": ["Fanxu Meng", "Hao Cheng", "Ke Li", "Zhixin Xu", "Rongrong Ji", "Xing Sun", "Gaungming Lu"], "title": "Filter Grafting for Deep Neural Networks", "url": "http://arxiv.org/pdf/2001.05868v3", "summary": "This paper proposes a new learning paradigm called filter grafting, which\naims to improve the representation capability of Deep Neural Networks (DNNs).\nThe motivation is that DNNs have unimportant (invalid) filters (e.g., l1 norm\nclose to 0). These filters limit the potential of DNNs since they are\nidentified as having little effect on the network. While filter pruning removes\nthese invalid filters for efficiency consideration, filter grafting\nre-activates them from an accuracy boosting perspective. The activation is\nprocessed by grafting external information (weights) into invalid filters. To\nbetter perform the grafting process, we develop an entropy-based criterion to\nmeasure the information of filters and an adaptive weighting strategy for\nbalancing the grafted information among networks. After the grafting operation,\nthe network has very few invalid filters compared with its untouched state,\nenpowering the model with more representation capacity. We also perform\nextensive experiments on the classification and recognition tasks to show the\nsuperiority of our method. For example, the grafted MobileNetV2 outperforms the\nnon-grafted MobileNetV2 by about 7 percent on CIFAR-100 dataset. Code is\navailable at https://github.com/fxmeng/filter-grafting.git.", "published": "2020-01-15T03:18:57Z", "version": 3}, {"aid": "2001.06769", "authors": ["Kaiyu Shan", "Yongtao Wang", "Zhuoying Wang", "Tingting Liang", "Zhi Tang", "Ying Chen", "Yangyan Li"], "title": "MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion", "url": "http://arxiv.org/pdf/2001.06769v3", "summary": "To efficiently extract spatiotemporal features of video for action\nrecognition, most state-of-the-art methods integrate 1D temporal convolution\ninto a conventional 2D CNN backbone. However, they all exploit 1D temporal\nconvolution of fixed kernel size (i.e., 3) in the network building block, thus\nhave suboptimal temporal modeling capability to handle both long-term and\nshort-term actions. To address this problem, we first investigate the impacts\nof different kernel sizes for the 1D temporal convolutional filters. Then, we\npropose a simple yet efficient operation called Mixed Temporal Convolution\n(MixTConv), which consists of multiple depthwise 1D convolutional filters with\ndifferent kernel sizes. By plugging MixTConv into the conventional 2D CNN\nbackbone ResNet-50, we further propose an efficient and effective network\narchitecture named MSTNet for action recognition, and achieve state-of-the-art\nresults on multiple benchmarks.", "published": "2020-01-19T04:21:51Z", "version": 3}, {"aid": "2001.06782", "authors": ["Tianhe Yu", "Saurabh Kumar", "Abhishek Gupta", "Sergey Levine", "Karol Hausman", "Chelsea Finn"], "title": "Gradient Surgery for Multi-Task Learning", "url": "http://arxiv.org/pdf/2001.06782v4", "summary": "While deep learning and deep reinforcement learning (RL) systems have\ndemonstrated impressive results in domains such as image classification, game\nplaying, and robotic control, data efficiency remains a major challenge.\nMulti-task learning has emerged as a promising approach for sharing structure\nacross multiple tasks to enable more efficient learning. However, the\nmulti-task setting presents a number of optimization challenges, making it\ndifficult to realize large efficiency gains compared to learning tasks\nindependently. The reasons why multi-task learning is so challenging compared\nto single-task learning are not fully understood. In this work, we identify a\nset of three conditions of the multi-task optimization landscape that cause\ndetrimental gradient interference, and develop a simple yet general approach\nfor avoiding such interference between task gradients. We propose a form of\ngradient surgery that projects a task's gradient onto the normal plane of the\ngradient of any other task that has a conflicting gradient. On a series of\nchallenging multi-task supervised and multi-task RL problems, this approach\nleads to substantial gains in efficiency and performance. Further, it is\nmodel-agnostic and can be combined with previously-proposed multi-task\narchitectures for enhanced performance.", "published": "2020-01-19T06:33:47Z", "version": 4}, {"aid": "2001.06810", "authors": ["Xiankai Lu", "Wenguan Wang", "Chao Ma", "Jianbing Shen", "Ling Shao", "Fatih Porikli"], "title": "See More, Know More: Unsupervised Video Object Segmentation with Co-Attention Siamese Networks", "url": "http://arxiv.org/pdf/2001.06810v1", "summary": "We introduce a novel network, called CO-attention Siamese Network (COSNet),\nto address the unsupervised video object segmentation task from a holistic\nview. We emphasize the importance of inherent correlation among video frames\nand incorporate a global co-attention mechanism to improve further the\nstate-of-the-art deep learning based solutions that primarily focus on learning\ndiscriminative foreground representations over appearance and motion in\nshort-term temporal segments. The co-attention layers in our network provide\nefficient and competent stages for capturing global correlations and scene\ncontext by jointly computing and appending co-attention responses into a joint\nfeature space. We train COSNet with pairs of video frames, which naturally\naugments training data and allows increased learning capacity. During the\nsegmentation stage, the co-attention model encodes useful information by\nprocessing multiple reference frames together, which is leveraged to infer the\nfrequently reappearing and salient foreground objects better. We propose a\nunified and end-to-end trainable framework where different co-attention\nvariants can be derived for mining the rich context within videos. Our\nextensive experiments over three large benchmarks manifest that COSNet\noutperforms the current alternatives by a large margin.", "published": "2020-01-19T11:10:39Z", "version": 1}, {"aid": "2001.06838", "authors": ["Junjie Yan", "Ruosi Wan", "Xiangyu Zhang", "Wei Zhang", "Yichen Wei", "Jian Sun"], "title": "Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization", "url": "http://arxiv.org/pdf/2001.06838v2", "summary": "Batch Normalization (BN) is one of the most widely used techniques in Deep\nLearning field. But its performance can awfully degrade with insufficient batch\nsize. This weakness limits the usage of BN on many computer vision tasks like\ndetection or segmentation, where batch size is usually small due to the\nconstraint of memory consumption. Therefore many modified normalization\ntechniques have been proposed, which either fail to restore the performance of\nBN completely, or have to introduce additional nonlinear operations in\ninference procedure and increase huge consumption. In this paper, we reveal\nthat there are two extra batch statistics involved in backward propagation of\nBN, on which has never been well discussed before. The extra batch statistics\nassociated with gradients also can severely affect the training of deep neural\nnetwork. Based on our analysis, we propose a novel normalization method, named\nMoving Average Batch Normalization (MABN). MABN can completely restore the\nperformance of vanilla BN in small batch cases, without introducing any\nadditional nonlinear operations in inference procedure. We prove the benefits\nof MABN by both theoretical analysis and experiments. Our experiments\ndemonstrate the effectiveness of MABN in multiple computer vision tasks\nincluding ImageNet and COCO. The code has been released in\nhttps://github.com/megvii-model/MABN.", "published": "2020-01-19T14:41:22Z", "version": 2}, {"aid": "2001.06881", "authors": ["Maurizio De Pitt\u00e0"], "title": "Neuron-Glial Interactions", "url": "http://arxiv.org/pdf/2001.06881v1", "summary": "Although lagging behind classical computational neuroscience, theoretical and\ncomputational approaches are beginning to emerge to characterize different\naspects of neuron-glial interactions. This chapter aims to provide essential\nknowledge on neuron-glial interactions in the mammalian brain, leveraging on\ncomputational studies that focus on structure (anatomy) and function\n(physiology) of such interactions in the healthy brain. Although our\nunderstanding of the need of neuron-glial interactions in the brain is still at\nits infancy, being mostly based on predictions that await for experimental\nvalidation, simple general modeling arguments borrowed from control theory are\nintroduced to support the importance of including such interactions in\ntraditional neuron-based modeling paradigms.", "published": "2020-01-19T18:30:07Z", "version": 1}, {"aid": "2001.07203", "authors": ["Lancelot Da Costa", "Thomas Parr", "Noor Sajid", "Sebastijan Veselic", "Victorita Neacsu", "Karl Friston"], "title": "Active inference on discrete state-spaces: a synthesis", "url": "http://arxiv.org/pdf/2001.07203v2", "summary": "Active inference is a normative principle underwriting perception, action,\nplanning, decision-making and learning in biological or artificial agents. From\nits inception, its associated process theory has grown to incorporate complex\ngenerative models, enabling simulation of a wide range of complex behaviours.\nDue to successive developments in active inference, it is often difficult to\nsee how its underlying principle relates to process theories and practical\nimplementation. In this paper, we try to bridge this gap by providing a\ncomplete mathematical synthesis of active inference on discrete state-space\nmodels. This technical summary provides an overview of the theory, derives\nneuronal dynamics from first principles and relates this dynamics to biological\nprocesses. Furthermore, this paper provides a fundamental building block needed\nto understand active inference for mixed generative models; allowing continuous\nsensations to inform discrete representations. This paper may be used as\nfollows: to guide research towards outstanding challenges, a practical guide on\nhow to implement active inference to simulate experimental behaviour, or a\npointer towards various in-silico neurophysiological responses that may be used\nto make empirical predictions.", "published": "2020-01-20T18:24:21Z", "version": 2}, {"aid": "2001.07342", "authors": ["Rajath S", "Sumukh Aithal K", "Natarajan Subramanyam"], "title": "Transfer Learning using Neural Ordinary Differential Equations", "url": "http://arxiv.org/pdf/2001.07342v1", "summary": "A concept of using Neural Ordinary Differential Equations(NODE) for Transfer\nLearning has been introduced. In this paper we use the EfficientNets to explore\ntransfer learning on CIFAR-10 dataset. We use NODE for fine-tuning our model.\nUsing NODE for fine tuning provides more stability during training and\nvalidation.These continuous depth blocks can also have a trade off between\nnumerical precision and speed .Using Neural ODEs for transfer learning has\nresulted in much stable convergence of the loss function.", "published": "2020-01-21T04:59:08Z", "version": 1}, {"aid": "2001.08028", "authors": ["Lancelot Da Costa", "Thomas Parr", "Biswa Sengupta", "Karl Friston"], "title": "Neural dynamics under active inference: plausibility and efficiency of information processing", "url": "http://arxiv.org/pdf/2001.08028v2", "summary": "Active inference is a normative framework for explaining behaviour under the\nfree energy principle -- a theory of self-organisation originating in\nneuroscience. It specifies neuronal dynamics for state-estimation in terms of a\ndescent on (variational) free energy -- a measure of the fit between an\ninternal (generative) model and sensory observations. The free energy gradient\nis a prediction error -- plausibly encoded in the average membrane potentials\nof neuronal populations. Conversely, the expected probability of a state can be\nexpressed in terms of neuronal firing rates. We show that this is consistent\nwith current models of neuronal dynamics and establish face validity by\nsynthesising plausible electrophysiological responses. We then show that these\nneuronal dynamics approximate natural gradient descent, a well-known\noptimisation algorithm from information geometry that follows the steepest\ndescent of the objective in information space. We compare the information\nlength of belief updating in both schemes, a measure of the distance traveled\nin information space that has a direct interpretation in terms of metabolic\ncost. We show that neural dynamics under active inference are metabolically\nefficient and suggest that neural representations in biological agents may\nevolve by approximating steepest descent in information space towards the point\nof optimal inference.", "published": "2020-01-22T14:15:05Z", "version": 2}, {"aid": "2001.08248", "authors": ["Md Amirul Islam", "Sen Jia", "Neil D. B. Bruce"], "title": "How Much Position Information Do Convolutional Neural Networks Encode?", "url": "http://arxiv.org/pdf/2001.08248v1", "summary": "In contrast to fully connected networks, Convolutional Neural Networks (CNNs)\nachieve efficiency by learning weights associated with local filters with a\nfinite spatial extent. An implication of this is that a filter may know what it\nis looking at, but not where it is positioned in the image. Information\nconcerning absolute position is inherently useful, and it is reasonable to\nassume that deep CNNs may implicitly learn to encode this information if there\nis a means to do so. In this paper, we test this hypothesis revealing the\nsurprising degree of absolute position information that is encoded in commonly\nused neural networks. A comprehensive set of experiments show the validity of\nthis hypothesis and shed light on how and where this information is represented\nwhile offering clues to where positional information is derived from in deep\nCNNs.", "published": "2020-01-22T19:44:43Z", "version": 1}, {"aid": "2001.08559", "authors": ["Zehao Wang", "Kaili Wang", "Tinne Tuytelaars", "Jose Oramas"], "title": "Information Compensation for Deep Conditional Generative Networks", "url": "http://arxiv.org/pdf/2001.08559v3", "summary": "In recent years, unsupervised/weakly-supervised conditional generative\nadversarial networks (GANs) have achieved many successes on the task of\nmodeling and generating data. However, one of their weaknesses lies in their\npoor ability to separate, or disentangle, the different factors that\ncharacterize the representation encoded in their latent space. To address this\nissue, we propose a novel structure for unsupervised conditional GANs powered\nby a novel Information Compensation Connection (IC-Connection). The proposed\nIC-Connection enables GANs to compensate for information loss incurred during\ndeconvolution operations. In addition, to quantify the degree of\ndisentanglement on both discrete and continuous latent variables, we design a\nnovel evaluation procedure. Our empirical results suggest that our method\nachieves better disentanglement compared to the state-of-the-art GANs in a\nconditional generation setting.", "published": "2020-01-23T14:39:53Z", "version": 3}, {"aid": "2001.08578", "authors": ["Mohammed Abuhamad", "Ahmed Abusnaina", "DaeHun Nyang", "David Mohaisen"], "title": "Sensor-based Continuous Authentication of Smartphones' Users Using Behavioral Biometrics: A Contemporary Survey", "url": "http://arxiv.org/pdf/2001.08578v2", "summary": "Mobile devices and technologies have become increasingly popular, offering\ncomparable storage and computational capabilities to desktop computers allowing\nusers to store and interact with sensitive and private information. The\nsecurity and protection of such personal information are becoming more and more\nimportant since mobile devices are vulnerable to unauthorized access or theft.\nUser authentication is a task of paramount importance that grants access to\nlegitimate users at the point-of-entry and continuously through the usage\nsession. This task is made possible with today's smartphones' embedded sensors\nthat enable continuous and implicit user authentication by capturing behavioral\nbiometrics and traits. In this paper, we survey more than 140 recent behavioral\nbiometric-based approaches for continuous user authentication, including\nmotion-based methods (28 studies), gait-based methods (19 studies), keystroke\ndynamics-based methods (20 studies), touch gesture-based methods (29 studies),\nvoice-based methods (16 studies), and multimodal-based methods (34 studies).\nThe survey provides an overview of the current state-of-the-art approaches for\ncontinuous user authentication using behavioral biometrics captured by\nsmartphones' embedded sensors, including insights and open challenges for\nadoption, usability, and performance.", "published": "2020-01-23T15:07:28Z", "version": 2}, {"aid": "2001.08680", "authors": ["Zijie Zhuang", "Longhui Wei", "Lingxi Xie", "Tianyu Zhang", "Hengheng Zhang", "Haozhe Wu", "Haizhou Ai", "Qi Tian"], "title": "Rethinking the Distribution Gap of Person Re-identification with Camera-based Batch Normalization", "url": "http://arxiv.org/pdf/2001.08680v3", "summary": "The fundamental difficulty in person re-identification (ReID) lies in\nlearning the correspondence among individual cameras. It strongly demands\ncostly inter-camera annotations, yet the trained models are not guaranteed to\ntransfer well to previously unseen cameras. These problems significantly limit\nthe application of ReID. This paper rethinks the working mechanism of\nconventional ReID approaches and puts forward a new solution. With an effective\noperator named Camera-based Batch Normalization (CBN), we force the image data\nof all cameras to fall onto the same subspace, so that the distribution gap\nbetween any camera pair is largely shrunk. This alignment brings two benefits.\nFirst, the trained model enjoys better abilities to generalize across scenarios\nwith unseen cameras as well as transfer across multiple training sets. Second,\nwe can rely on intra-camera annotations, which have been undervalued before due\nto the lack of cross-camera information, to achieve competitive ReID\nperformance. Experiments on a wide range of ReID tasks demonstrate the\neffectiveness of our approach. The code is available at\nhttps://github.com/automan000/Camera-based-Person-ReID.", "published": "2020-01-23T17:22:34Z", "version": 3}, {"aid": "2001.09219", "authors": ["Bhavya Ghai", "Q. Vera Liao", "Yunfeng Zhang", "Rachel Bellamy", "Klaus Mueller"], "title": "Explainable Active Learning (XAL): An Empirical Study of How Local Explanations Impact Annotator Experience", "url": "http://arxiv.org/pdf/2001.09219v4", "summary": "The wide adoption of Machine Learning technologies has created a rapidly\ngrowing demand for people who can train ML models. Some advocated the term\n\"machine teacher\" to refer to the role of people who inject domain knowledge\ninto ML models. One promising learning paradigm is Active Learning (AL), by\nwhich the model intelligently selects instances to query the machine teacher\nfor labels. However, in current AL settings, the human-AI interface remains\nminimal and opaque. We begin considering AI explanations as a core element of\nthe human-AI interface for teaching machines. When a human student learns, it\nis a common pattern to present one's own reasoning and solicit feedback from\nthe teacher. When a ML model learns and still makes mistakes, the human teacher\nshould be able to understand the reasoning underlying the mistakes. When the\nmodel matures, the machine teacher should be able to recognize its progress in\norder to trust and feel confident about their teaching outcome. Toward this\nvision, we propose a novel paradigm of explainable active learning (XAL), by\nintroducing techniques from the recently surging field of explainable AI (XAI)\ninto an AL setting. We conducted an empirical study comparing the model\nlearning outcomes, feedback content and experience with XAL, to that of\ntraditional AL and coactive learning (providing the model's prediction without\nthe explanation). Our study shows benefits of AI explanation as interfaces for\nmachine teaching--supporting trust calibration and enabling rich forms of\nteaching feedback, and potential drawbacks--anchoring effect with the model\njudgment and cognitive workload. Our study also reveals important individual\nfactors that mediate a machine teacher's reception to AI explanations,\nincluding task knowledge, AI experience and need for cognition. By reflecting\non the results, we suggest future directions and design implications for XAL.", "published": "2020-01-24T22:52:18Z", "version": 4}, {"aid": "2001.09424", "authors": ["Matteo Demuru", "Matteo Fraschini"], "title": "EEG fingerprinting: subject specific signature based on the aperiodic component of power spectrum", "url": "http://arxiv.org/pdf/2001.09424v1", "summary": "During the last few years, there has been growing interest in the effects\ninduced by individual variability on activation patterns and brain\nconnectivity. The practical implications of individual variability is of basic\nrelevance for both group level and subject level studies. The\nElectroencephalogram (EEG), still represents one of the most used recording\ntechniques to investigate a wide range of brain related features. In this work,\nwe aim to estimate the effect of individual variability on a set of very simple\nand easily interpretable features extracted from the EEG power spectra. In\nparticular, in an identification scenario, we investigated how the aperiodic\n(1/f background) component of the EEG power spectra can accurately identify\nsubjects from a large EEG dataset. The results of this study show that the\naperiodic component of the EEG signal is characterized by strong\nsubject-specific properties, that this feature is consistent across different\nexperimental conditions (eyes-open and eyes-closed) and outperforms the\ncanonically-defined frequency bands. These findings suggest that the simple\nfeatures (slope and offset) extracted from the aperiodic component of the EEG\nsignal are sensitive to individual traits and may help to characterize and make\ninferences at single subject level.", "published": "2020-01-26T09:04:26Z", "version": 1}, {"aid": "2002.00556", "authors": ["Jeong-Hyun Cho", "Ji-Hoon Jeong", "Dong-Joo Kim", "Seong-Whan Lee"], "title": "A novel approach to classify natural grasp actions by estimating muscle activity patterns from EEG signals", "url": "http://arxiv.org/pdf/2002.00556v1", "summary": "Developing electroencephalogram (EEG) based brain-computer interface (BCI)\nsystems is challenging. In this study, we analyzed natural grasp actions from\nEEG. Ten healthy subjects participated in this experiment. They executed and\nimagined three sustained grasp actions. We proposed a novel approach which\nestimates muscle activity patterns from EEG signals to improve the overall\nclassification accuracy. For implementation, we have recorded EEG and\nelectromyogram (EMG) simultaneously. Using the similarity of the estimated\npattern from EEG signals compare to the activity pattern from EMG signals\nshowed higher classification accuracy than competitive methods. As a result, we\nobtained the average classification accuracy of 63.89($\\pm$7.54)% for actual\nmovement and 46.96($\\pm$15.30)% for motor imagery. These are 21.59% and 5.66%\nhigher than the result of the competitive model, respectively. This result is\nencouraging, and the proposed method could potentially be used in future\napplications, such as a BCI-driven robot control for handling various daily use\nobjects.", "published": "2020-02-03T04:40:17Z", "version": 1}, {"aid": "2002.00623", "authors": ["Magomed Yu. Malsagov", "Emil M. Khayrov", "Maria M. Pushkareva", "Iakov M. Karandashev"], "title": "Exponential discretization of weights of neural network connections in pre-trained neural networks", "url": "http://arxiv.org/pdf/2002.00623v1", "summary": "To reduce random access memory (RAM) requirements and to increase speed of\nrecognition algorithms we consider a weight discretization problem for trained\nneural networks. We show that an exponential discretization is preferable to a\nlinear discretization since it allows one to achieve the same accuracy when the\nnumber of bits is 1 or 2 less. The quality of the neural network VGG-16 is\nalready satisfactory (top5 accuracy 69%) in the case of 3 bit exponential\ndiscretization. The ResNet50 neural network shows top5 accuracy 84% at 4 bits.\nOther neural networks perform fairly well at 5 bits (top5 accuracies of\nXception, Inception-v3, and MobileNet-v2 top5 were 87%, 90%, and 77%,\nrespectively). At less number of bits, the accuracy decreases rapidly.", "published": "2020-02-03T09:41:24Z", "version": 1}, {"aid": "2002.02342", "authors": ["Xiaoliang Luo", "Brett D. Roads", "Bradley C. Love"], "title": "The Costs and Benefits of Goal-Directed Attention in Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2002.02342v3", "summary": "People deploy top-down, goal-directed attention to accomplish tasks, such as\nfinding lost keys. By tuning the visual system to relevant information sources,\nobject recognition can become more efficient (a benefit) and more biased toward\nthe target (a potential cost). Motivated by selective attention in\ncategorisation models, we developed a goal-directed attention mechanism that\ncan process naturalistic (photographic) stimuli. Our attention mechanism can be\nincorporated into any existing deep convolutional neural network (DCNNs). The\nprocessing stages in DCNNs have been related to ventral visual stream. In that\nlight, our attentional mechanism incorporates top-down influences from\nprefrontal cortex (PFC) to support goal-directed behaviour. Akin to how\nattention weights in categorisation models warp representational spaces, we\nintroduce a layer of attention weights to the mid-level of a DCNN that amplify\nor attenuate activity to further a goal. We evaluated the attentional mechanism\nusing photographic stimuli, varying the attentional target. We found that\nincreasing goal-directed attention has benefits (increasing hit rates) and\ncosts (increasing false alarm rates). At a moderate level, attention improves\nsensitivity (i.e., increases $d^\\prime$) at only a moderate increase in bias\nfor tasks involving standard images, blended images, and natural adversarial\nimages chosen to fool DCNNs. These results suggest that goal-directed attention\ncan reconfigure general-purpose DCNNs to better suit the current task goal,\nmuch like PFC modulates activity along the ventral stream. In addition to being\nmore parsimonious and brain consistent, the mid-level attention approach\nperformed better than a standard machine learning approach for transfer\nlearning, namely retraining the final network layer to accommodate the new\ntask.", "published": "2020-02-06T16:42:00Z", "version": 3}, {"aid": "2002.03231", "authors": ["Aditya Kusupati", "Vivek Ramanujan", "Raghav Somani", "Mitchell Wortsman", "Prateek Jain", "Sham Kakade", "Ali Farhadi"], "title": "Soft Threshold Weight Reparameterization for Learnable Sparsity", "url": "http://arxiv.org/pdf/2002.03231v9", "summary": "Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus\nof maximizing prediction accuracy given an overall parameter budget. Existing\nmethods rely on uniform or heuristic non-uniform sparsity budgets which have\nsub-optimal layer-wise parameter allocation resulting in a) lower prediction\naccuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold\nReparameterization (STR), a novel use of the soft-threshold operator on DNN\nweights. STR smoothly induces sparsity while learning pruning thresholds\nthereby obtaining a non-uniform sparsity budget. Our method achieves\nstate-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and\nMobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that\nempirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy\nover existing results by up to 10% in the ultra sparse (99%) regime and can\nalso be used to induce low-rank (structured sparsity) in RNNs. In short, STR is\na simple mechanism which learns effective sparsity budgets that contrast with\npopular heuristics. Code, pretrained models and sparsity budgets are at\nhttps://github.com/RAIVNLab/STR.", "published": "2020-02-08T21:31:25Z", "version": 9}, {"aid": "2002.04688", "authors": ["Jeremy Howard", "Sylvain Gugger"], "title": "fastai: A Layered API for Deep Learning", "url": "http://arxiv.org/pdf/2002.04688v2", "summary": "fastai is a deep learning library which provides practitioners with\nhigh-level components that can quickly and easily provide state-of-the-art\nresults in standard deep learning domains, and provides researchers with\nlow-level components that can be mixed and matched to build new approaches. It\naims to do both things without substantial compromises in ease of use,\nflexibility, or performance. This is possible thanks to a carefully layered\narchitecture, which expresses common underlying patterns of many deep learning\nand data processing techniques in terms of decoupled abstractions. These\nabstractions can be expressed concisely and clearly by leveraging the dynamism\nof the underlying Python language and the flexibility of the PyTorch library.\nfastai includes: a new type dispatch system for Python along with a semantic\ntype hierarchy for tensors; a GPU-optimized computer vision library which can\nbe extended in pure Python; an optimizer which refactors out the common\nfunctionality of modern optimizers into two basic pieces, allowing optimization\nalgorithms to be implemented in 4-5 lines of code; a novel 2-way callback\nsystem that can access any part of the data, model, or optimizer and change it\nat any point during training; a new data block API; and much more. We have used\nthis library to successfully create a complete deep learning course, which we\nwere able to write more quickly than using previous approaches, and the code\nwas more clear. The library is already in wide use in research, industry, and\nteaching. NB: This paper covers fastai v2, which is currently in pre-release at\nhttp://dev.fast.ai/", "published": "2020-02-11T21:16:48Z", "version": 2}, {"aid": "2002.05709", "authors": ["Ting Chen", "Simon Kornblith", "Mohammad Norouzi", "Geoffrey Hinton"], "title": "A Simple Framework for Contrastive Learning of Visual Representations", "url": "http://arxiv.org/pdf/2002.05709v3", "summary": "This paper presents SimCLR: a simple framework for contrastive learning of\nvisual representations. We simplify recently proposed contrastive\nself-supervised learning algorithms without requiring specialized architectures\nor a memory bank. In order to understand what enables the contrastive\nprediction tasks to learn useful representations, we systematically study the\nmajor components of our framework. We show that (1) composition of data\naugmentations plays a critical role in defining effective predictive tasks, (2)\nintroducing a learnable nonlinear transformation between the representation and\nthe contrastive loss substantially improves the quality of the learned\nrepresentations, and (3) contrastive learning benefits from larger batch sizes\nand more training steps compared to supervised learning. By combining these\nfindings, we are able to considerably outperform previous methods for\nself-supervised and semi-supervised learning on ImageNet. A linear classifier\ntrained on self-supervised representations learned by SimCLR achieves 76.5%\ntop-1 accuracy, which is a 7% relative improvement over previous\nstate-of-the-art, matching the performance of a supervised ResNet-50. When\nfine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy,\noutperforming AlexNet with 100X fewer labels.", "published": "2020-02-13T18:50:45Z", "version": 3}, {"aid": "2002.06100", "authors": ["Emile van Krieken", "Erman Acar", "Frank van Harmelen"], "title": "Analyzing Differentiable Fuzzy Logic Operators", "url": "http://arxiv.org/pdf/2002.06100v2", "summary": "The AI community is increasingly putting its attention towards combining\nsymbolic and neural approaches, as it is often argued that the strengths and\nweaknesses of these approaches are complementary. One recent trend in the\nliterature are weakly supervised learning techniques that employ operators from\nfuzzy logics. In particular, these use prior background knowledge described in\nsuch logics to help the training of a neural network from unlabeled and noisy\ndata. By interpreting logical symbols using neural networks, this background\nknowledge can be added to regular loss functions, hence making reasoning a part\nof learning. We study, both formally and empirically, how a large collection of\nlogical operators from the fuzzy logic literature behave in a differentiable\nlearning setting. We find that many of these operators, including some of the\nmost well-known, are highly unsuitable in this setting. A further finding\nconcerns the treatment of implication in these fuzzy logics, and shows a strong\nimbalance between gradients driven by the antecedent and the consequent of the\nimplication. Furthermore, we introduce a new family of fuzzy implications\n(called sigmoidal implications) to tackle this phenomenon. Finally, we\nempirically show that it is possible to use Differentiable Fuzzy Logics for\nsemi-supervised learning, and compare how different operators behave in\npractice. We find that, to achieve the largest performance improvement over a\nsupervised baseline, we have to resort to non-standard combinations of logical\noperators which perform well in learning, but no longer satisfy the usual\nlogical laws.", "published": "2020-02-14T16:11:36Z", "version": 2}, {"aid": "2002.06642", "authors": ["Tab Memmott", "Aziz Ko\u00e7anao\u011fullar\u0131", "Matthew Lawhead", "Daniel Klee", "Shiran Dudy", "Melanie Fried-Oken", "Barry Oken"], "title": "BciPy: Brain-Computer Interface Software in Python", "url": "http://arxiv.org/pdf/2002.06642v1", "summary": "There are high technological and software demands associated with conducting\nbrain-computer interface (BCI) research. In order to accelerate the development\nand accessibility of BCI, it is worthwhile to focus on open-source and desired\ntooling. Python, a prominent computer language, has emerged as a language of\nchoice for many research and engineering purposes. In this manuscript, we\npresent BciPy, an open-source, Python-based software for conducting BCI\nresearch. It was developed with a focus on restoring communication using\nevent-related potential (ERP) spelling interfaces, however, it may be used for\nother non-spelling and non-ERP BCI paradigms. Major modules in this system\ninclude support for data acquisition, data queries, stimuli presentation,\nsignal processing, signal viewing and modeling, language modeling, task\nbuilding, and a simple Graphical User Interface (GUI).", "published": "2020-02-16T18:36:43Z", "version": 1}, {"aid": "2002.08473", "authors": ["Karsten Roth", "Timo Milbich", "Samarth Sinha", "Prateek Gupta", "Bj\u00f6rn Ommer", "Joseph Paul Cohen"], "title": "Revisiting Training Strategies and Generalization Performance in Deep Metric Learning", "url": "http://arxiv.org/pdf/2002.08473v9", "summary": "Deep Metric Learning (DML) is arguably one of the most influential lines of\nresearch for learning visual similarities with many proposed approaches every\nyear. Although the field benefits from the rapid progress, the divergence in\ntraining protocols, architectures, and parameter choices make an unbiased\ncomparison difficult. To provide a consistent reference point, we revisit the\nmost widely used DML objective functions and conduct a study of the crucial\nparameter choices as well as the commonly neglected mini-batch sampling\nprocess. Under consistent comparison, DML objectives show much higher\nsaturation than indicated by literature. Further based on our analysis, we\nuncover a correlation between the embedding space density and compression to\nthe generalization performance of DML models. Exploiting these insights, we\npropose a simple, yet effective, training regularization to reliably boost the\nperformance of ranking-based DML models on various standard benchmark datasets.\nCode and a publicly accessible WandB-repo are available at\nhttps://github.com/Confusezius/Revisiting_Deep_Metric_Learning_PyTorch.", "published": "2020-02-19T22:16:12Z", "version": 9}, {"aid": "2003.00880", "authors": ["Stanton R. Price", "Steven R. Price", "Derek T. Anderson"], "title": "Introducing Fuzzy Layers for Deep Learning", "url": "http://arxiv.org/pdf/2003.00880v1", "summary": "Many state-of-the-art technologies developed in recent years have been\ninfluenced by machine learning to some extent. Most popular at the time of this\nwriting are artificial intelligence methodologies that fall under the umbrella\nof deep learning. Deep learning has been shown across many applications to be\nextremely powerful and capable of handling problems that possess great\ncomplexity and difficulty. In this work, we introduce a new layer to deep\nlearning: the fuzzy layer. Traditionally, the network architecture of neural\nnetworks is composed of an input layer, some combination of hidden layers, and\nan output layer. We propose the introduction of fuzzy layers into the deep\nlearning architecture to exploit the powerful aggregation properties expressed\nthrough fuzzy methodologies, such as the Choquet and Sugueno fuzzy integrals.\nTo date, fuzzy approaches taken to deep learning have been through the\napplication of various fusion strategies at the decision level to aggregate\noutputs from state-of-the-art pre-trained models, e.g., AlexNet, VGG16,\nGoogLeNet, Inception-v3, ResNet-18, etc. While these strategies have been shown\nto improve accuracy performance for image classification tasks, none have\nexplored the use of fuzzified intermediate, or hidden, layers. Herein, we\npresent a new deep learning strategy that incorporates fuzzy strategies into\nthe deep learning architecture focused on the application of semantic\nsegmentation using per-pixel classification. Experiments are conducted on a\nbenchmark data set as well as a data set collected via an unmanned aerial\nsystem at a U.S. Army test site for the task of automatic road segmentation,\nand preliminary results are promising.", "published": "2020-02-21T19:33:30Z", "version": 1}, {"aid": "2002.10319", "authors": ["Lang Huang", "Chao Zhang", "Hongyang Zhang"], "title": "Self-Adaptive Training: beyond Empirical Risk Minimization", "url": "http://arxiv.org/pdf/2002.10319v2", "summary": "We propose self-adaptive training---a new training algorithm that dynamically\ncorrects problematic training labels by model predictions without incurring\nextra computational cost---to improve generalization of deep learning for\npotentially corrupted training data. This problem is crucial towards robustly\nlearning from data that are corrupted by, e.g., label noises and\nout-of-distribution samples. The standard empirical risk minimization (ERM) for\nsuch data, however, may easily overfit noises and thus suffers from sub-optimal\nperformance. In this paper, we observe that model predictions can substantially\nbenefit the training process: self-adaptive training significantly improves\ngeneralization over ERM under various levels of noises, and mitigates the\noverfitting issue in both natural and adversarial training. We evaluate the\nerror-capacity curve of self-adaptive training: the test error is monotonously\ndecreasing w.r.t. model capacity. This is in sharp contrast to the\nrecently-discovered double-descent phenomenon in ERM which might be a result of\noverfitting of noises. Experiments on CIFAR and ImageNet datasets verify the\neffectiveness of our approach in two applications: classification with label\nnoise and selective classification. We release our code at\nhttps://github.com/LayneH/self-adaptive-training.", "published": "2020-02-24T15:47:10Z", "version": 2}, {"aid": "2003.03488", "authors": ["Zechun Liu", "Zhiqiang Shen", "Marios Savvides", "Kwang-Ting Cheng"], "title": "ReActNet: Towards Precise Binary Neural Network with Generalized Activation Functions", "url": "http://arxiv.org/pdf/2003.03488v2", "summary": "In this paper, we propose several ideas for enhancing a binary network to\nclose its accuracy gap from real-valued networks without incurring any\nadditional computational cost. We first construct a baseline network by\nmodifying and binarizing a compact real-valued network with parameter-free\nshortcuts, bypassing all the intermediate convolutional layers including the\ndownsampling layers. This baseline network strikes a good trade-off between\naccuracy and efficiency, achieving superior performance than most of existing\nbinary networks at approximately half of the computational cost. Through\nextensive experiments and analysis, we observed that the performance of binary\nnetworks is sensitive to activation distribution variations. Based on this\nimportant observation, we propose to generalize the traditional Sign and PReLU\nfunctions, denoted as RSign and RPReLU for the respective generalized\nfunctions, to enable explicit learning of the distribution reshape and shift at\nnear-zero extra cost. Lastly, we adopt a distributional loss to further enforce\nthe binary network to learn similar output distributions as those of a\nreal-valued network. We show that after incorporating all these ideas, the\nproposed ReActNet outperforms all the state-of-the-arts by a large margin.\nSpecifically, it outperforms Real-to-Binary Net and MeliusNet29 by 4.0% and\n3.6% respectively for the top-1 accuracy and also reduces the gap to its\nreal-valued counterpart to within 3.0% top-1 accuracy on ImageNet dataset. Code\nand models are available at: https://github.com/liuzechun/ReActNet.", "published": "2020-03-07T02:12:02Z", "version": 2}, {"aid": "2003.04151", "authors": ["Pau Rodr\u00edguez", "Issam Laradji", "Alexandre Drouin", "Alexandre Lacoste"], "title": "Embedding Propagation: Smoother Manifold for Few-Shot Classification", "url": "http://arxiv.org/pdf/2003.04151v2", "summary": "Few-shot classification is challenging because the data distribution of the\ntraining set can be widely different to the test set as their classes are\ndisjoint. This distribution shift often results in poor generalization.\nManifold smoothing has been shown to address the distribution shift problem by\nextending the decision boundaries and reducing the noise of the class\nrepresentations. Moreover, manifold smoothness is a key factor for\nsemi-supervised learning and transductive learning algorithms. In this work, we\npropose to use embedding propagation as an unsupervised non-parametric\nregularizer for manifold smoothing in few-shot classification. Embedding\npropagation leverages interpolations between the extracted features of a neural\nnetwork based on a similarity graph. We empirically show that embedding\npropagation yields a smoother embedding manifold. We also show that applying\nembedding propagation to a transductive classifier achieves new\nstate-of-the-art results in mini-Imagenet, tiered-Imagenet, Imagenet-FS, and\nCUB. Furthermore, we show that embedding propagation consistently improves the\naccuracy of the models in multiple semi-supervised learning scenarios by up to\n16\\% points. The proposed embedding propagation operation can be easily\nintegrated as a non-parametric layer into a neural network. We provide the\ntraining code and usage examples at\nhttps://github.com/ElementAI/embedding-propagation.", "published": "2020-03-09T13:51:09Z", "version": 2}, {"aid": "2003.08505", "authors": ["Kevin Musgrave", "Serge Belongie", "Ser-Nam Lim"], "title": "A Metric Learning Reality Check", "url": "http://arxiv.org/pdf/2003.08505v3", "summary": "Deep metric learning papers from the past four years have consistently\nclaimed great advances in accuracy, often more than doubling the performance of\ndecade-old methods. In this paper, we take a closer look at the field to see if\nthis is actually true. We find flaws in the experimental methodology of\nnumerous metric learning papers, and show that the actual improvements over\ntime have been marginal at best.", "published": "2020-03-18T23:28:04Z", "version": 3}, {"aid": "2003.08936", "authors": ["Muyang Li", "Ji Lin", "Yaoyao Ding", "Zhijian Liu", "Jun-Yan Zhu", "Song Han"], "title": "GAN Compression: Efficient Architectures for Interactive Conditional GANs", "url": "http://arxiv.org/pdf/2003.08936v4", "summary": "Conditional Generative Adversarial Networks (cGANs) have enabled controllable\nimage synthesis for many vision and graphics applications. However, recent\ncGANs are 1-2 orders of magnitude more compute-intensive than modern\nrecognition CNNs. For example, GauGAN consumes 281G MACs per image, compared to\n0.44G MACs for MobileNet-v3, making it difficult for interactive deployment. In\nthis work, we propose a general-purpose compression framework for reducing the\ninference time and model size of the generator in cGANs. Directly applying\nexisting compression methods yields poor performance due to the difficulty of\nGAN training and the differences in generator architectures. We address these\nchallenges in two ways. First, to stabilize GAN training, we transfer knowledge\nof multiple intermediate representations of the original model to its\ncompressed model and unify unpaired and paired learning. Second, instead of\nreusing existing CNN designs, our method finds efficient architectures via\nneural architecture search. To accelerate the search process, we decouple the\nmodel training and search via weight sharing. Experiments demonstrate the\neffectiveness of our method across different supervision settings, network\narchitectures, and learning methods. Without losing image quality, we reduce\nthe computation of CycleGAN by 21x, Pix2pix by 12x, MUNIT by 29x, and GauGAN by\n9x, paving the way for interactive image synthesis.", "published": "2020-03-19T17:59:05Z", "version": 4}, {"aid": "2003.08983", "authors": ["Malik Boudiaf", "J\u00e9r\u00f4me Rony", "Imtiaz Masud Ziko", "Eric Granger", "Marco Pedersoli", "Pablo Piantanida", "Ismail Ben Ayed"], "title": "A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses", "url": "http://arxiv.org/pdf/2003.08983v3", "summary": "Recently, substantial research efforts in Deep Metric Learning (DML) focused\non designing complex pairwise-distance losses, which require convoluted schemes\nto ease optimization, such as sample mining or pair weighting. The standard\ncross-entropy loss for classification has been largely overlooked in DML. On\nthe surface, the cross-entropy may seem unrelated and irrelevant to metric\nlearning as it does not explicitly involve pairwise distances. However, we\nprovide a theoretical analysis that links the cross-entropy to several\nwell-known and recent pairwise losses. Our connections are drawn from two\ndifferent perspectives: one based on an explicit optimization insight; the\nother on discriminative and generative views of the mutual information between\nthe labels and the learned features. First, we explicitly demonstrate that the\ncross-entropy is an upper bound on a new pairwise loss, which has a structure\nsimilar to various pairwise losses: it minimizes intra-class distances while\nmaximizing inter-class distances. As a result, minimizing the cross-entropy can\nbe seen as an approximate bound-optimization (or Majorize-Minimize) algorithm\nfor minimizing this pairwise loss. Second, we show that, more generally,\nminimizing the cross-entropy is actually equivalent to maximizing the mutual\ninformation, to which we connect several well-known pairwise losses.\nFurthermore, we show that various standard pairwise losses can be explicitly\nrelated to one another via bound relationships. Our findings indicate that the\ncross-entropy represents a proxy for maximizing the mutual information -- as\npairwise losses do -- without the need for convoluted sample-mining heuristics.\nOur experiments over four standard DML benchmarks strongly support our\nfindings. We obtain state-of-the-art results, outperforming recent and complex\nDML methods.", "published": "2020-03-19T18:59:54Z", "version": 3}, {"aid": "2003.10027", "authors": ["Yinpeng Chen", "Xiyang Dai", "Mengchen Liu", "Dongdong Chen", "Lu Yuan", "Zicheng Liu"], "title": "Dynamic ReLU", "url": "http://arxiv.org/pdf/2003.10027v2", "summary": "Rectified linear units (ReLU) are commonly used in deep neural networks. So\nfar ReLU and its generalizations (non-parametric or parametric) are static,\nperforming identically for all input samples. In this paper, we propose dynamic\nReLU (DY-ReLU), a dynamic rectifier of which parameters are generated by a\nhyper function over all in-put elements. The key insight is that DY-ReLU\nencodes the global context into the hyper function, and adapts the piecewise\nlinear activation function accordingly. Compared to its static counterpart,\nDY-ReLU has negligible extra computational cost, but significantly more\nrepresentation capability, especially for light-weight neural networks. By\nsimply using DY-ReLU for MobileNetV2, the top-1 accuracy on ImageNet\nclassification is boosted from 72.0% to 76.2% with only 5% additional FLOPs.", "published": "2020-03-22T23:45:35Z", "version": 2}, {"aid": "2003.12039", "authors": ["Zachary Teed", "Jia Deng"], "title": "RAFT: Recurrent All-Pairs Field Transforms for Optical Flow", "url": "http://arxiv.org/pdf/2003.12039v3", "summary": "We introduce Recurrent All-Pairs Field Transforms (RAFT), a new deep network\narchitecture for optical flow. RAFT extracts per-pixel features, builds\nmulti-scale 4D correlation volumes for all pairs of pixels, and iteratively\nupdates a flow field through a recurrent unit that performs lookups on the\ncorrelation volumes. RAFT achieves state-of-the-art performance. On KITTI, RAFT\nachieves an F1-all error of 5.10%, a 16% error reduction from the best\npublished result (6.10%). On Sintel (final pass), RAFT obtains an\nend-point-error of 2.855 pixels, a 30% error reduction from the best published\nresult (4.098 pixels). In addition, RAFT has strong cross-dataset\ngeneralization as well as high efficiency in inference time, training speed,\nand parameter count. Code is available at https://github.com/princeton-vl/RAFT.", "published": "2020-03-26T17:12:42Z", "version": 3}, {"aid": "2003.13630", "authors": ["Tal Ridnik", "Hussam Lawen", "Asaf Noy", "Emanuel Ben Baruch", "Gilad Sharir", "Itamar Friedman"], "title": "TResNet: High Performance GPU-Dedicated Architecture", "url": "http://arxiv.org/pdf/2003.13630v3", "summary": "Many deep learning models, developed in recent years, reach higher ImageNet\naccuracy than ResNet50, with fewer or comparable FLOPS count. While FLOPs are\noften seen as a proxy for network efficiency, when measuring actual GPU\ntraining and inference throughput, vanilla ResNet50 is usually significantly\nfaster than its recent competitors, offering better throughput-accuracy\ntrade-off.\n  In this work, we introduce a series of architecture modifications that aim to\nboost neural networks' accuracy, while retaining their GPU training and\ninference efficiency. We first demonstrate and discuss the bottlenecks induced\nby FLOPs-optimizations. We then suggest alternative designs that better utilize\nGPU structure and assets. Finally, we introduce a new family of GPU-dedicated\nmodels, called TResNet, which achieve better accuracy and efficiency than\nprevious ConvNets.\n  Using a TResNet model, with similar GPU throughput to ResNet50, we reach 80.8\ntop-1 accuracy on ImageNet. Our TResNet models also transfer well and achieve\nstate-of-the-art accuracy on competitive single-label classification datasets\nsuch as Stanford cars (96.0%), CIFAR-10 (99.0%), CIFAR-100 (91.5%) and\nOxford-Flowers (99.1%). They also perform well on multi-label classification\nand object detection tasks. Implementation is available at:\nhttps://github.com/mrT23/TResNet.", "published": "2020-03-30T17:04:47Z", "version": 3}, {"aid": "2003.13985", "authors": ["Sean Moran", "Pierre Marza", "Steven McDonagh", "Sarah Parisot", "Gregory Slabaugh"], "title": "DeepLPF: Deep Local Parametric Filters for Image Enhancement", "url": "http://arxiv.org/pdf/2003.13985v1", "summary": "Digital artists often improve the aesthetic quality of digital photographs\nthrough manual retouching. Beyond global adjustments, professional image\nediting programs provide local adjustment tools operating on specific parts of\nan image. Options include parametric (graduated, radial filters) and\nunconstrained brush tools. These highly expressive tools enable a diverse set\nof local image enhancements. However, their use can be time consuming, and\nrequires artistic capability. State-of-the-art automated image enhancement\napproaches typically focus on learning pixel-level or global enhancements. The\nformer can be noisy and lack interpretability, while the latter can fail to\ncapture fine-grained adjustments. In this paper, we introduce a novel approach\nto automatically enhance images using learned spatially local filters of three\ndifferent types (Elliptical Filter, Graduated Filter, Polynomial Filter). We\nintroduce a deep neural network, dubbed Deep Local Parametric Filters\n(DeepLPF), which regresses the parameters of these spatially localized filters\nthat are then automatically applied to enhance the image. DeepLPF provides a\nnatural form of model regularization and enables interpretable, intuitive\nadjustments that lead to visually pleasing results. We report on multiple\nbenchmarks and show that DeepLPF produces state-of-the-art performance on two\nvariants of the MIT-Adobe-5K dataset, often using a fraction of the parameters\nrequired for competing methods.", "published": "2020-03-31T06:51:21Z", "version": 1}, {"aid": "2004.00049", "authors": ["Jiapeng Zhu", "Yujun Shen", "Deli Zhao", "Bolei Zhou"], "title": "In-Domain GAN Inversion for Real Image Editing", "url": "http://arxiv.org/pdf/2004.00049v3", "summary": "Recent work has shown that a variety of semantics emerge in the latent space\nof Generative Adversarial Networks (GANs) when being trained to synthesize\nimages. However, it is difficult to use these learned semantics for real image\nediting. A common practice of feeding a real image to a trained GAN generator\nis to invert it back to a latent code. However, existing inversion methods\ntypically focus on reconstructing the target image by pixel values yet fail to\nland the inverted code in the semantic domain of the original latent space. As\na result, the reconstructed image cannot well support semantic editing through\nvarying the inverted code. To solve this problem, we propose an in-domain GAN\ninversion approach, which not only faithfully reconstructs the input image but\nalso ensures the inverted code to be semantically meaningful for editing. We\nfirst learn a novel domain-guided encoder to project a given image to the\nnative latent space of GANs. We then propose domain-regularized optimization by\ninvolving the encoder as a regularizer to fine-tune the code produced by the\nencoder and better recover the target image. Extensive experiments suggest that\nour inversion method achieves satisfying real image reconstruction and more\nimportantly facilitates various image editing tasks, significantly\noutperforming start-of-the-arts.", "published": "2020-03-31T18:20:18Z", "version": 3}, {"aid": "2004.01461", "authors": ["Hongwei Yong", "Jianqiang Huang", "Xiansheng Hua", "Lei Zhang"], "title": "Gradient Centralization: A New Optimization Technique for Deep Neural Networks", "url": "http://arxiv.org/pdf/2004.01461v2", "summary": "Optimization techniques are of great importance to effectively and\nefficiently train a deep neural network (DNN). It has been shown that using the\nfirst and second order statistics (e.g., mean and variance) to perform Z-score\nstandardization on network activations or weight vectors, such as batch\nnormalization (BN) and weight standardization (WS), can improve the training\nperformance. Different from these existing methods that mostly operate on\nactivations or weights, we present a new optimization technique, namely\ngradient centralization (GC), which operates directly on gradients by\ncentralizing the gradient vectors to have zero mean. GC can be viewed as a\nprojected gradient descent method with a constrained loss function. We show\nthat GC can regularize both the weight space and output feature space so that\nit can boost the generalization performance of DNNs. Moreover, GC improves the\nLipschitzness of the loss function and its gradient so that the training\nprocess becomes more efficient and stable. GC is very simple to implement and\ncan be easily embedded into existing gradient based DNN optimizers with only\none line of code. It can also be directly used to fine-tune the pre-trained\nDNNs. Our experiments on various applications, including general image\nclassification, fine-grained image classification, detection and segmentation,\ndemonstrate that GC can consistently improve the performance of DNN learning.\nThe code of GC can be found at\nhttps://github.com/Yonghongwei/Gradient-Centralization.", "published": "2020-04-03T10:25:00Z", "version": 2}, {"aid": "2004.02215", "authors": ["Jing Jin", "Junhui Hou", "Jie Chen", "Sam Kwong"], "title": "Light Field Spatial Super-resolution via Deep Combinatorial Geometry Embedding and Structural Consistency Regularization", "url": "http://arxiv.org/pdf/2004.02215v1", "summary": "Light field (LF) images acquired by hand-held devices usually suffer from low\nspatial resolution as the limited sampling resources have to be shared with the\nangular dimension. LF spatial super-resolution (SR) thus becomes an\nindispensable part of the LF camera processing pipeline. The\nhigh-dimensionality characteristic and complex geometrical structure of LF\nimages make the problem more challenging than traditional single-image SR. The\nperformance of existing methods is still limited as they fail to thoroughly\nexplore the coherence among LF views and are insufficient in accurately\npreserving the parallax structure of the scene. In this paper, we propose a\nnovel learning-based LF spatial SR framework, in which each view of an LF image\nis first individually super-resolved by exploring the complementary information\namong views with combinatorial geometry embedding. For accurate preservation of\nthe parallax structure among the reconstructed views, a regularization network\ntrained over a structure-aware loss function is subsequently appended to\nenforce correct parallax relationships over the intermediate estimation. Our\nproposed approach is evaluated over datasets with a large number of testing\nimages including both synthetic and real-world scenes. Experimental results\ndemonstrate the advantage of our approach over state-of-the-art methods, i.e.,\nour method not only improves the average PSNR by more than 1.0 dB but also\npreserves more accurate parallax details, at a lower computational cost.", "published": "2020-04-05T14:39:57Z", "version": 1}, {"aid": "2004.02546", "authors": ["Erik H\u00e4rk\u00f6nen", "Aaron Hertzmann", "Jaakko Lehtinen", "Sylvain Paris"], "title": "GANSpace: Discovering Interpretable GAN Controls", "url": "http://arxiv.org/pdf/2004.02546v3", "summary": "This paper describes a simple technique to analyze Generative Adversarial\nNetworks (GANs) and create interpretable controls for image synthesis, such as\nchange of viewpoint, aging, lighting, and time of day. We identify important\nlatent directions based on Principal Components Analysis (PCA) applied either\nin latent space or feature space. Then, we show that a large number of\ninterpretable controls can be defined by layer-wise perturbation along the\nprincipal directions. Moreover, we show that BigGAN can be controlled with\nlayer-wise inputs in a StyleGAN-like manner. We show results on different GANs\ntrained on various datasets, and demonstrate good qualitative matches to edit\ndirections found through earlier supervised approaches.", "published": "2020-04-06T10:41:44Z", "version": 3}, {"aid": "2004.03791", "authors": ["Longguang Wang", "Yingqian Wang", "Zaiping Lin", "Jungang Yang", "Wei An", "Yulan Guo"], "title": "Learning A Single Network for Scale-Arbitrary Super-Resolution", "url": "http://arxiv.org/pdf/2004.03791v2", "summary": "Recently, the performance of single image super-resolution (SR) has been\nsignificantly improved with powerful networks. However, these networks are\ndeveloped for image SR with a single specific integer scale (e.g., x2;x3,x4),\nand cannot be used for non-integer and asymmetric SR. In this paper, we propose\nto learn a scale-arbitrary image SR network from scale-specific networks.\nSpecifically, we propose a plug-in module for existing SR networks to perform\nscale-arbitrary SR, which consists of multiple scale-aware feature adaption\nblocks and a scale-aware upsampling layer. Moreover, we introduce a scale-aware\nknowledge transfer paradigm to transfer knowledge from scale-specific networks\nto the scale-arbitrary network. Our plug-in module can be easily adapted to\nexisting networks to achieve scale-arbitrary SR. These networks plugged with\nour module can achieve promising results for non-integer and asymmetric SR\nwhile maintaining state-of-the-art performance for SR with integer scale\nfactors. Besides, the additional computational and memory cost of our module is\nvery small.", "published": "2020-04-08T03:40:15Z", "version": 2}, {"aid": "2004.04433", "authors": ["Marcel C. B\u00fchler", "Andr\u00e9s Romero", "Radu Timofte"], "title": "DeepSEE: Deep Disentangled Semantic Explorative Extreme Super-Resolution", "url": "http://arxiv.org/pdf/2004.04433v3", "summary": "Super-resolution (SR) is by definition ill-posed. There are infinitely many\nplausible high-resolution variants for a given low-resolution natural image.\nMost of the current literature aims at a single deterministic solution of\neither high reconstruction fidelity or photo-realistic perceptual quality. In\nthis work, we propose an explorative facial super-resolution framework,\nDeepSEE, for Deep disentangled Semantic Explorative Extreme super-resolution.\nTo the best of our knowledge, DeepSEE is the first method to leverage semantic\nmaps for explorative super-resolution. In particular, it provides control of\nthe semantic regions, their disentangled appearance and it allows a broad range\nof image manipulations. We validate DeepSEE on faces, for up to 32x\nmagnification and exploration of the space of super-resolution. Our code and\nmodels are available at: https://mcbuehler.github.io/DeepSEE/", "published": "2020-04-09T09:14:42Z", "version": 3}, {"aid": "2004.05479", "authors": ["Alper T. Erdogan", "Cengiz Pehlevan"], "title": "Blind Bounded Source Separation Using Neural Networks with Local Learning Rules", "url": "http://arxiv.org/pdf/2004.05479v1", "summary": "An important problem encountered by both natural and engineered signal\nprocessing systems is blind source separation. In many instances of the\nproblem, the sources are bounded by their nature and known to be so, even\nthough the particular bound may not be known. To separate such bounded sources\nfrom their mixtures, we propose a new optimization problem, Bounded Similarity\nMatching (BSM). A principled derivation of an adaptive BSM algorithm leads to a\nrecurrent neural network with a clipping nonlinearity. The network adapts by\nlocal learning rules, satisfying an important constraint for both biological\nplausibility and implementability in neuromorphic hardware.", "published": "2020-04-11T20:20:22Z", "version": 1}, {"aid": "2004.07320", "authors": ["Angela Fan", "Pierre Stock", "Benjamin Graham", "Edouard Grave", "Remi Gribonval", "Herve Jegou", "Armand Joulin"], "title": "Training with Quantization Noise for Extreme Model Compression", "url": "http://arxiv.org/pdf/2004.07320v3", "summary": "We tackle the problem of producing compact models, maximizing their accuracy\nfor a given model size. A standard solution is to train networks with\nQuantization Aware Training, where the weights are quantized during training\nand the gradients approximated with the Straight-Through Estimator. In this\npaper, we extend this approach to work beyond int8 fixed-point quantization\nwith extreme compression methods where the approximations introduced by STE are\nsevere, such as Product Quantization. Our proposal is to only quantize a\ndifferent random subset of weights during each forward, allowing for unbiased\ngradients to flow through the other weights. Controlling the amount of noise\nand its form allows for extreme compression rates while maintaining the\nperformance of the original model. As a result we establish new\nstate-of-the-art compromises between accuracy and model size both in natural\nlanguage processing and image classification. For example, applying our method\nto state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5%\naccuracy on MNLI by compressing RoBERTa to 14MB and 80.0 top-1 accuracy on\nImageNet by compressing an EfficientNet-B3 to 3.3MB.", "published": "2020-04-15T20:10:53Z", "version": 3}, {"aid": "2004.08128", "authors": ["Beren Millidge", "Alexander Tschantz", "Christopher L Buckley"], "title": "Whence the Expected Free Energy?", "url": "http://arxiv.org/pdf/2004.08128v5", "summary": "The Expected Free Energy (EFE) is a central quantity in the theory of active\ninference. It is the quantity that all active inference agents are mandated to\nminimize through action, and its decomposition into extrinsic and intrinsic\nvalue terms is key to the balance of exploration and exploitation that active\ninference agents evince. Despite its importance, the mathematical origins of\nthis quantity and its relation to the Variational Free Energy (VFE) remain\nunclear. In this paper, we investigate the origins of the EFE in detail and\nshow that it is not simply \"the free energy in the future\". We present a\nfunctional that we argue is the natural extension of the VFE, but which\nactively discourages exploratory behaviour, thus demonstrating that exploration\ndoes not directly follow from free energy minimization into the future. We then\ndevelop a novel objective, the Free-Energy of the Expected Future (FEEF), which\npossesses both the epistemic component of the EFE as well as an intuitive\nmathematical grounding as the divergence between predicted and desired futures.", "published": "2020-04-17T09:06:56Z", "version": 5}, {"aid": "2004.09576", "authors": ["Yash Bhalgat", "Jinwon Lee", "Markus Nagel", "Tijmen Blankevoort", "Nojun Kwak"], "title": "LSQ+: Improving low-bit quantization through learnable offsets and better initialization", "url": "http://arxiv.org/pdf/2004.09576v1", "summary": "Unlike ReLU, newer activation functions (like Swish, H-swish, Mish) that are\nfrequently employed in popular efficient architectures can also result in\nnegative activation values, with skewed positive and negative ranges. Typical\nlearnable quantization schemes [PACT, LSQ] assume unsigned quantization for\nactivations and quantize all negative activations to zero which leads to\nsignificant loss in performance. Naively using signed quantization to\naccommodate these negative values requires an extra sign bit which is expensive\nfor low-bit (2-, 3-, 4-bit) quantization. To solve this problem, we propose\nLSQ+, a natural extension of LSQ, wherein we introduce a general asymmetric\nquantization scheme with trainable scale and offset parameters that can learn\nto accommodate the negative activations. Gradient-based learnable quantization\nschemes also commonly suffer from high instability or variance in the final\ntraining performance, hence requiring a great deal of hyper-parameter tuning to\nreach a satisfactory performance. LSQ+ alleviates this problem by using an\nMSE-based initialization scheme for the quantization parameters. We show that\nthis initialization leads to significantly lower variance in final performance\nacross multiple training runs. Overall, LSQ+ shows state-of-the-art results for\nEfficientNet and MixNet and also significantly outperforms LSQ for low-bit\nquantization of neural nets with Swish activations (e.g.: 1.8% gain with W4A4\nquantization and upto 5.6% gain with W2A2 quantization of EfficientNet-B0 on\nImageNet dataset). To the best of our knowledge, ours is the first work to\nquantize such architectures to extremely low bit-widths.", "published": "2020-04-20T19:04:51Z", "version": 1}, {"aid": "2004.11362", "authors": ["Prannay Khosla", "Piotr Teterwak", "Chen Wang", "Aaron Sarna", "Yonglong Tian", "Phillip Isola", "Aaron Maschinot", "Ce Liu", "Dilip Krishnan"], "title": "Supervised Contrastive Learning", "url": "http://arxiv.org/pdf/2004.11362v5", "summary": "Contrastive learning applied to self-supervised representation learning has\nseen a resurgence in recent years, leading to state of the art performance in\nthe unsupervised training of deep image models. Modern batch contrastive\napproaches subsume or significantly outperform traditional contrastive losses\nsuch as triplet, max-margin and the N-pairs loss. In this work, we extend the\nself-supervised batch contrastive approach to the fully-supervised setting,\nallowing us to effectively leverage label information. Clusters of points\nbelonging to the same class are pulled together in embedding space, while\nsimultaneously pushing apart clusters of samples from different classes. We\nanalyze two possible versions of the supervised contrastive (SupCon) loss,\nidentifying the best-performing formulation of the loss. On ResNet-200, we\nachieve top-1 accuracy of 81.4% on the ImageNet dataset, which is 0.8% above\nthe best number reported for this architecture. We show consistent\noutperformance over cross-entropy on other datasets and two ResNet variants.\nThe loss shows benefits for robustness to natural corruptions and is more\nstable to hyperparameter settings such as optimizers and data augmentations.\nOur loss function is simple to implement, and reference TensorFlow code is\nreleased at https://t.ly/supcon.", "published": "2020-04-23T17:58:56Z", "version": 5}, {"aid": "2004.12399", "authors": ["Jerry Zikun Chen"], "title": "Reinforcement Learning Generalization with Surprise Minimization", "url": "http://arxiv.org/pdf/2004.12399v2", "summary": "Generalization remains a challenging problem for deep reinforcement learning\nalgorithms, which are often trained and tested on the same set of deterministic\ngame environments. When test environments are unseen and perturbed but the\nnature of the task remains the same, generalization gaps can arise. In this\nwork, we propose and evaluate a surprise minimizing agent on a generalization\nbenchmark to show an additional reward learned from a simple density model can\nshow robustness in procedurally generated game environments that provide\nconstant source of entropy and stochasticity.", "published": "2020-04-26T14:50:59Z", "version": 2}, {"aid": "2004.13612", "authors": ["Calypso Herrera", "Florian Krach", "Anastasis Kratsios", "Pierre Ruyssen", "Josef Teichmann"], "title": "Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices", "url": "http://arxiv.org/pdf/2004.13612v4", "summary": "The robust PCA of covariance matrices plays an essential role when isolating\nkey explanatory features. The currently available methods for performing such a\nlow-rank plus sparse decomposition are matrix specific, meaning, those\nalgorithms must re-run for every new matrix. Since these algorithms are\ncomputationally expensive, it is preferable to learn and store a function that\nnearly instantaneously performs this decomposition when evaluated. Therefore,\nwe introduce Denise, a deep learning-based algorithm for robust PCA of\ncovariance matrices, or more generally, of symmetric positive semidefinite\nmatrices, which learns precisely such a function. Theoretical guarantees for\nDenise are provided. These include a novel universal approximation theorem\nadapted to our geometric deep learning problem and convergence to an optimal\nsolution to the learning problem. Our experiments show that Denise matches\nstate-of-the-art performance in terms of decomposition quality, while being\napproximately $2000\\times$ faster than the state-of-the-art, principal\ncomponent pursuit (PCP), and $200 \\times$ faster than the current\nspeed-optimized method, fast PCP.", "published": "2020-04-28T15:45:21Z", "version": 4}, {"aid": "2005.00695", "authors": ["Sen Wu", "Hongyang R. Zhang", "Gregory Valiant", "Christopher R\u00e9"], "title": "On the Generalization Effects of Linear Transformations in Data Augmentation", "url": "http://arxiv.org/pdf/2005.00695v3", "summary": "Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations that preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations that mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms random sampling methods by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "published": "2020-05-02T04:10:21Z", "version": 3}, {"aid": "2005.03098", "authors": ["Arne Decadt", "Jasper De Bock", "Gert de Cooman"], "title": "Inference with Choice Functions Made Practical", "url": "http://arxiv.org/pdf/2005.03098v3", "summary": "We study how to infer new choices from previous choices in a conservative\nmanner. To make such inferences, we use the theory of choice functions: a\nunifying mathematical framework for conservative decision making that allows\none to impose axioms directly on the represented decisions. We here adopt the\ncoherence axioms of De Bock and De Cooman (2019). We show how to naturally\nextend any given choice assessment to such a coherent choice function, whenever\npossible, and use this natural extension to make new choices. We present a\npractical algorithm to compute this natural extension and provide several\nmethods that can be used to improve its scalability.", "published": "2020-05-07T12:58:05Z", "version": 3}, {"aid": "2005.04298", "authors": ["Jinkyu Kim", "Mayank Bansal"], "title": "Attentional Bottleneck: Towards an Interpretable Deep Driving Network", "url": "http://arxiv.org/pdf/2005.04298v1", "summary": "Deep neural networks are a key component of behavior prediction and motion\ngeneration for self-driving cars. One of their main drawbacks is a lack of\ntransparency: they should provide easy to interpret rationales for what\ntriggers certain behaviors. We propose an architecture called Attentional\nBottleneck with the goal of improving transparency. Our key idea is to combine\nvisual attention, which identifies what aspects of the input the model is\nusing, with an information bottleneck that enables the model to only use\naspects of the input which are important. This not only provides sparse and\ninterpretable attention maps (e.g. focusing only on specific vehicles in the\nscene), but it adds this transparency at no cost to model accuracy. In fact, we\nfind slight improvements in accuracy when applying Attentional Bottleneck to\nthe ChauffeurNet model, whereas we find that the accuracy deteriorates with a\ntraditional visual attention model.", "published": "2020-05-08T21:51:15Z", "version": 1}, {"aid": "2005.04551", "authors": ["Yihui He", "Rui Yan", "Katerina Fragkiadaki", "Shoou-I Yu"], "title": "Epipolar Transformers", "url": "http://arxiv.org/pdf/2005.04551v1", "summary": "A common approach to localize 3D human joints in a synchronized and\ncalibrated multi-view setup consists of two-steps: (1) apply a 2D detector\nseparately on each view to localize joints in 2D, and (2) perform robust\ntriangulation on 2D detections from each view to acquire the 3D joint\nlocations. However, in step 1, the 2D detector is limited to solving\nchallenging cases which could potentially be better resolved in 3D, such as\nocclusions and oblique viewing angles, purely in 2D without leveraging any 3D\ninformation. Therefore, we propose the differentiable \"epipolar transformer\",\nwhich enables the 2D detector to leverage 3D-aware features to improve 2D pose\nestimation. The intuition is: given a 2D location p in the current view, we\nwould like to first find its corresponding point p' in a neighboring view, and\nthen combine the features at p' with the features at p, thus leading to a\n3D-aware feature at p. Inspired by stereo matching, the epipolar transformer\nleverages epipolar constraints and feature matching to approximate the features\nat p'. Experiments on InterHand and Human3.6M show that our approach has\nconsistent improvements over the baselines. Specifically, in the condition\nwhere no external data is used, our Human3.6M model trained with ResNet-50\nbackbone and image size 256 x 256 outperforms state-of-the-art by 4.23 mm and\nachieves MPJPE 26.9 mm.", "published": "2020-05-10T02:22:54Z", "version": 1}, {"aid": "2005.04559", "authors": ["Mahdi Biparva", "John Tsotsos"], "title": "Compact Neural Representation Using Attentive Network Pruning", "url": "http://arxiv.org/pdf/2005.04559v1", "summary": "Deep neural networks have evolved to become power demanding and consequently\ndifficult to apply to small-size mobile platforms. Network parameter reduction\nmethods have been introduced to systematically deal with the computational and\nmemory complexity of deep networks. We propose to examine the ability of\nattentive connection pruning to deal with redundancy reduction in neural\nnetworks as a contribution to the reduction of computational demand. In this\nwork, we describe a Top-Down attention mechanism that is added to a Bottom-Up\nfeedforward network to select important connections and subsequently prune\nredundant ones at all parametric layers. Our method not only introduces a novel\nhierarchical selection mechanism as the basis of pruning but also remains\ncompetitive with previous baseline methods in the experimental evaluation. We\nconduct experiments using different network architectures on popular benchmark\ndatasets to show high compression ratio is achievable with negligible loss of\naccuracy.", "published": "2020-05-10T03:20:01Z", "version": 1}, {"aid": "2005.04573", "authors": ["Li Zhang", "Mingliang Wang", "Mingxia Liu", "Daoqiang Zhang"], "title": "A Survey on Deep Learning for Neuroimaging-based Brain Disorder Analysis", "url": "http://arxiv.org/pdf/2005.04573v1", "summary": "Deep learning has been recently used for the analysis of neuroimages, such as\nstructural magnetic resonance imaging (MRI), functional MRI, and positron\nemission tomography (PET), and has achieved significant performance\nimprovements over traditional machine learning in computer-aided diagnosis of\nbrain disorders. This paper reviews the applications of deep learning methods\nfor neuroimaging-based brain disorder analysis. We first provide a\ncomprehensive overview of deep learning techniques and popular network\narchitectures, by introducing various types of deep neural networks and recent\ndevelopments. We then review deep learning methods for computer-aided analysis\nof four typical brain disorders, including Alzheimer's disease, Parkinson's\ndisease, Autism spectrum disorder, and Schizophrenia, where the first two\ndiseases are neurodegenerative disorders and the last two are\nneurodevelopmental and psychiatric disorders, respectively. More importantly,\nwe discuss the limitations of existing studies and present possible future\ndirections.", "published": "2020-05-10T04:20:50Z", "version": 1}, {"aid": "2005.04605", "authors": ["Miaohua Zhang", "Yongsheng Gao", "Changming Sun", "Michael Blumenstein"], "title": "Robust Tensor Decomposition for Image Representation Based on Generalized Correntropy", "url": "http://arxiv.org/pdf/2005.04605v1", "summary": "Traditional tensor decomposition methods, e.g., two dimensional principal\ncomponent analysis and two dimensional singular value decomposition, that\nminimize mean square errors, are sensitive to outliers. To overcome this\nproblem, in this paper we propose a new robust tensor decomposition method\nusing generalized correntropy criterion (Corr-Tensor). A Lagrange multiplier\nmethod is used to effectively optimize the generalized correntropy objective\nfunction in an iterative manner. The Corr-Tensor can effectively improve the\nrobustness of tensor decomposition with the existence of outliers without\nintroducing any extra computational cost. Experimental results demonstrated\nthat the proposed method significantly reduces the reconstruction error on face\nreconstruction and improves the accuracies on handwritten digit recognition and\nfacial image clustering.", "published": "2020-05-10T08:46:52Z", "version": 1}, {"aid": "2005.04613", "authors": ["Vignesh Prasad", "Dipanjan Das", "Brojeshwar Bhowmick"], "title": "Variational Clustering: Leveraging Variational Autoencoders for Image Clustering", "url": "http://arxiv.org/pdf/2005.04613v1", "summary": "Recent advances in deep learning have shown their ability to learn strong\nfeature representations for images. The task of image clustering naturally\nrequires good feature representations to capture the distribution of the data\nand subsequently differentiate data points from one another. Often these two\naspects are dealt with independently and thus traditional feature learning\nalone does not suffice in partitioning the data meaningfully. Variational\nAutoencoders (VAEs) naturally lend themselves to learning data distributions in\na latent space. Since we wish to efficiently discriminate between different\nclusters in the data, we propose a method based on VAEs where we use a Gaussian\nMixture prior to help cluster the images accurately. We jointly learn the\nparameters of both the prior and the posterior distributions. Our method\nrepresents a true Gaussian Mixture VAE. This way, our method simultaneously\nlearns a prior that captures the latent distribution of the images and a\nposterior to help discriminate well between data points. We also propose a\nnovel reparametrization of the latent space consisting of a mixture of discrete\nand continuous variables. One key takeaway is that our method generalizes\nbetter across different datasets without using any pre-training or learnt\nmodels, unlike existing methods, allowing it to be trained from scratch in an\nend-to-end manner. We verify our efficacy and generalizability experimentally\nby achieving state-of-the-art results among unsupervised methods on a variety\nof datasets. To the best of our knowledge, we are the first to pursue image\nclustering using VAEs in a purely unsupervised manner on real image datasets.", "published": "2020-05-10T09:34:48Z", "version": 1}, {"aid": "2005.04619", "authors": ["Miaohua Zhang", "Yongsheng Gao", "Jun Zhou"], "title": "A Unified Weight Learning and Low-Rank Regression Model for Robust Complex Error Modeling", "url": "http://arxiv.org/pdf/2005.04619v4", "summary": "One of the most important problems in regression-based error model is\nmodeling the complex representation error caused by various corruptions and\nenvironment changes in images. For example, in robust face recognition, images\nare often affected by varying types and levels of corruptions, such as random\npixel corruptions, block occlusions, or disguises. However, existing works are\nnot robust enough to solve this problem due to they cannot model the complex\ncorrupted errors very well. In this paper, we address this problem by a unified\nsparse weight learning and low-rank approximation regression model, which\nenables the random noises and contiguous occlusions in images to be treated\nsimultaneously. For the random noise, we define a generalized correntropy (GC)\nfunction to match the error distribution. For the structured error caused by\nocclusions or disguises, we propose a GC function based rank approximation to\nmeasure the rank of error matrices. Since the proposed objective function is\nnon-convex, an effective iterative optimization algorithm is developed to\nachieve the optimal weight learning and low-rank approximation. Extensive\nexperimental results on three public face databases show that the proposed\nmodel can fit the error distribution and structure very well, thus obtain\nbetter recognition accuracies in comparison with the existing methods.", "published": "2020-05-10T09:50:14Z", "version": 4}, {"aid": "2005.04623", "authors": ["Mateusz Michalkiewicz", "Eugene Belilovsky", "Mahsa Baktashmotlagh", "Anders Eriksson"], "title": "A Simple and Scalable Shape Representation for 3D Reconstruction", "url": "http://arxiv.org/pdf/2005.04623v1", "summary": "Deep learning applied to the reconstruction of 3D shapes has seen growing\ninterest. A popular approach to 3D reconstruction and generation in recent\nyears has been the CNN encoder-decoder model usually applied in voxel space.\nHowever, this often scales very poorly with the resolution limiting the\neffectiveness of these models. Several sophisticated alternatives for decoding\nto 3D shapes have been proposed typically relying on complex deep learning\narchitectures for the decoder model. In this work, we show that this additional\ncomplexity is not necessary, and that we can actually obtain high quality 3D\nreconstruction using a linear decoder, obtained from principal component\nanalysis on the signed distance function (SDF) of the surface. This approach\nallows easily scaling to larger resolutions. We show in multiple experiments\nthat our approach is competitive with state-of-the-art methods. It also allows\nthe decoder to be fine-tuned on the target task using a loss designed\nspecifically for SDF transforms, obtaining further gains.", "published": "2020-05-10T10:22:50Z", "version": 1}, {"aid": "2005.04625", "authors": ["Wang Zhu", "Hexiang Hu", "Jiacheng Chen", "Zhiwei Deng", "Vihan Jain", "Eugene Ie", "Fei Sha"], "title": "BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps", "url": "http://arxiv.org/pdf/2005.04625v2", "summary": "Learning to follow instructions is of fundamental importance to autonomous\nagents for vision-and-language navigation (VLN). In this paper, we study how an\nagent can navigate long paths when learning from a corpus that consists of\nshorter ones. We show that existing state-of-the-art agents do not generalize\nwell. To this end, we propose BabyWalk, a new VLN agent that is learned to\nnavigate by decomposing long instructions into shorter ones (BabySteps) and\ncompleting them sequentially. A special design memory buffer is used by the\nagent to turn its past experiences into contexts for future steps. The learning\nprocess is composed of two phases. In the first phase, the agent uses imitation\nlearning from demonstration to accomplish BabySteps. In the second phase, the\nagent uses curriculum-based reinforcement learning to maximize rewards on\nnavigation tasks with increasingly longer instructions. We create two new\nbenchmark datasets (of long navigation tasks) and use them in conjunction with\nexisting ones to examine BabyWalk's generalization ability. Empirical results\nshow that BabyWalk achieves state-of-the-art results on several metrics, in\nparticular, is able to follow long instructions better. The codes and the\ndatasets are released on our project page https://github.com/Sha-Lab/babywalk.", "published": "2020-05-10T10:46:41Z", "version": 2}, {"aid": "2005.04735", "authors": ["Dan Shiebler"], "title": "Categorical Stochastic Processes and Likelihood", "url": "http://arxiv.org/pdf/2005.04735v5", "summary": "In this work we take a Category Theoretic perspective on the relationship\nbetween probabilistic modeling and function approximation. We begin by defining\ntwo extensions of function composition to stochastic process subordination: one\nbased on the co-Kleisli category under the comonad (Omega x -) and one based on\nthe parameterization of a category with a Lawvere theory. We show how these\nextensions relate to the category Stoch and other Markov Categories. Next, we\napply the Para construction to extend stochastic processes to parameterized\nstatistical models and we define a way to compose the likelihood functions of\nthese models. We conclude with a demonstration of how the Maximum Likelihood\nEstimation procedure defines an identity-on-objects functor from the category\nof statistical models to the category of Learners. Code to accompany this paper\ncan be found at\nhttps://github.com/dshieble/Categorical_Stochastic_Processes_and_Likelihood", "published": "2020-05-10T18:00:56Z", "version": 5}, {"aid": "2005.04945", "authors": ["Zhiqing Guo", "Gaobo Yang", "Jiyou Chen", "Xingming Sun"], "title": "Fake face detection via adaptive manipulation traces extraction network", "url": "http://arxiv.org/pdf/2005.04945v2", "summary": "With the proliferation of face image manipulation (FIM) techniques such as\nFace2Face and Deepfake, more fake face images are spreading over the internet,\nwhich brings serious challenges to public confidence. Face image forgery\ndetection has made considerable progresses in exposing specific FIM, but it is\nstill in scarcity of a robust fake face detector to expose face image forgeries\nunder complex scenarios such as with further compression, blurring, scaling,\netc. Due to the relatively fixed structure, convolutional neural network (CNN)\ntends to learn image content representations. However, CNN should learn subtle\nmanipulation traces for image forensics tasks. Thus, we propose an adaptive\nmanipulation traces extraction network (AMTEN), which serves as pre-processing\nto suppress image content and highlight manipulation traces. AMTEN exploits an\nadaptive convolution layer to predict manipulation traces in the image, which\nare reused in subsequent layers to maximize manipulation artifacts by updating\nweights during the back-propagation pass. A fake face detector, namely\nAMTENnet, is constructed by integrating AMTEN with CNN. Experimental results\nprove that the proposed AMTEN achieves desirable pre-processing. When detecting\nfake face images generated by various FIM techniques, AMTENnet achieves an\naverage accuracy up to 98.52%, which outperforms the state-of-the-art works.\nWhen detecting face images with unknown post-processing operations, the\ndetector also achieves an average accuracy of 95.17%.", "published": "2020-05-11T09:16:39Z", "version": 2}, {"aid": "2005.05274", "authors": ["Dongsuk Kim", "Geonhee Lee", "Myungjae Lee", "Shin Uk Kang", "Dongmin Kim"], "title": "Normalized Convolutional Neural Network", "url": "http://arxiv.org/pdf/2005.05274v3", "summary": "In this paper, we propose Normalized Convolutional Neural Network(NCNN). NCNN\nis more fitted to a convolutional operator than other nomralizaiton methods.\nThe normalized process is similar to a normalization methods, but NCNN is more\nadapative to sliced-inputs and corresponding the convolutional kernel. Therefor\nNCNN can be targeted to micro-batch training. Normalizaing of NC is conducted\nduring convolutional process. In short, NC process is not usual normalization\nand can not be realized in deep learning framework optimizing standard\nconvolution process. Hence we named this method 'Normalized Convolution'. As a\nresult, NC process has universal property which means NC can be applied to any\nAI tasks involving convolution neural layer . Since NC don't need other\nnormalization layer, NCNN looks like convolutional version of Self Normalizing\nNetwork.(SNN). Among micro-batch trainings, NCNN outperforms other\nbatch-independent normalization methods. NCNN archives these superiority by\nstandardizing rows of im2col matrix of inputs, which theoretically smooths the\ngradient of loss. The code need to manipulate standard convolution neural\nnetworks step by step. The code is available : https://github.com/kimdongsuk1/\nNormalizedCNN.", "published": "2020-05-11T17:20:26Z", "version": 3}, {"aid": "2005.05402", "authors": ["Jie Lei", "Liwei Wang", "Yelong Shen", "Dong Yu", "Tamara L. Berg", "Mohit Bansal"], "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning", "url": "http://arxiv.org/pdf/2005.05402v1", "summary": "Generating multi-sentence descriptions for videos is one of the most\nchallenging captioning tasks due to its high requirements for not only visual\nrelevance but also discourse-based coherence across the sentences in the\nparagraph. Towards this goal, we propose a new approach called Memory-Augmented\nRecurrent Transformer (MART), which uses a memory module to augment the\ntransformer architecture. The memory module generates a highly summarized\nmemory state from the video segments and the sentence history so as to help\nbetter prediction of the next sentence (w.r.t. coreference and repetition\naspects), thus encouraging coherent paragraph generation. Extensive\nexperiments, human evaluations, and qualitative analyses on two popular\ndatasets ActivityNet Captions and YouCookII show that MART generates more\ncoherent and less repetitive paragraph captions than baseline methods, while\nmaintaining relevance to the input video events. All code is available\nopen-source at: https://github.com/jayleicn/recurrent-transformer", "published": "2020-05-11T20:01:41Z", "version": 1}, {"aid": "2005.05650", "authors": ["Mingqing Xiao", "Shuxin Zheng", "Chang Liu", "Yaolong Wang", "Di He", "Guolin Ke", "Jiang Bian", "Zhouchen Lin", "Tie-Yan Liu"], "title": "Invertible Image Rescaling", "url": "http://arxiv.org/pdf/2005.05650v1", "summary": "High-resolution digital images are usually downscaled to fit various display\nscreens or save the cost of storage and bandwidth, meanwhile the post-upscaling\nis adpoted to recover the original resolutions or the details in the zoom-in\nimages. However, typical image downscaling is a non-injective mapping due to\nthe loss of high-frequency information, which leads to the ill-posed problem of\nthe inverse upscaling procedure and poses great challenges for recovering\ndetails from the downscaled low-resolution images. Simply upscaling with image\nsuper-resolution methods results in unsatisfactory recovering performance. In\nthis work, we propose to solve this problem by modeling the downscaling and\nupscaling processes from a new perspective, i.e. an invertible bijective\ntransformation, which can largely mitigate the ill-posed nature of image\nupscaling. We develop an Invertible Rescaling Net (IRN) with deliberately\ndesigned framework and objectives to produce visually-pleasing low-resolution\nimages and meanwhile capture the distribution of the lost information using a\nlatent variable following a specified distribution in the downscaling process.\nIn this way, upscaling is made tractable by inversely passing a randomly-drawn\nlatent variable with the low-resolution image through the network. Experimental\nresults demonstrate the significant improvement of our model over existing\nmethods in terms of both quantitative and qualitative evaluations of image\nupscaling reconstruction from downscaled images.", "published": "2020-05-12T09:55:53Z", "version": 1}, {"aid": "2005.05824", "authors": ["Aysan Aghazadeh", "Maryam Amirmazlaghani"], "title": "A Distributed Approximate Nearest Neighbor Method for Real-Time Face Recognition", "url": "http://arxiv.org/pdf/2005.05824v2", "summary": "Nowadays, face recognition and more generally image recognition have many\napplications in the modern world and are widely used in our daily tasks. This\npaper aims to propose a distributed approximate nearest neighbor (ANN) method\nfor real-time face recognition using a big dataset that involves a lot of\nclasses. The proposed approach is based on using a clustering method to\nseparate the dataset into different clusters and on specifying the importance\nof each cluster by defining cluster weights. To this end, reference instances\nare selected from each cluster based on the cluster weights using a maximum\nlikelihood approach. This process leads to a more informed selection of\ninstances, so it enhances the performance of the algorithm. Experimental\nresults confirm the efficiency of the proposed method and its out-performance\nin terms of accuracy and the processing time.", "published": "2020-05-12T14:39:31Z", "version": 2}, {"aid": "2005.11035", "authors": ["Jangho Kim", "KiYoon Yoo", "Nojun Kwak"], "title": "Position-based Scaled Gradient for Model Quantization and Pruning", "url": "http://arxiv.org/pdf/2005.11035v4", "summary": "We propose the position-based scaled gradient (PSG) that scales the gradient\ndepending on the position of a weight vector to make it more\ncompression-friendly. First, we theoretically show that applying PSG to the\nstandard gradient descent (GD), which is called PSGD, is equivalent to the GD\nin the warped weight space, a space made by warping the original weight space\nvia an appropriately designed invertible function. Second, we empirically show\nthat PSG acting as a regularizer to a weight vector is favorable for model\ncompression domains such as quantization and pruning. PSG reduces the gap\nbetween the weight distributions of a full-precision model and its compressed\ncounterpart. This enables the versatile deployment of a model either as an\nuncompressed mode or as a compressed mode depending on the availability of\nresources. The experimental results on CIFAR-10/100 and ImageNet datasets show\nthe effectiveness of the proposed PSG in both domains of pruning and\nquantization even for extremely low bits. The code is released in Github.", "published": "2020-05-22T07:11:27Z", "version": 4}, {"aid": "2005.12320", "authors": ["Wouter Van Gansbeke", "Simon Vandenhende", "Stamatios Georgoulis", "Marc Proesmans", "Luc Van Gool"], "title": "SCAN: Learning to Classify Images without Labels", "url": "http://arxiv.org/pdf/2005.12320v2", "summary": "Can we automatically group images into semantically meaningful clusters when\nground-truth annotations are absent? The task of unsupervised image\nclassification remains an important, and open challenge in computer vision.\nSeveral recent approaches have tried to tackle this problem in an end-to-end\nfashion. In this paper, we deviate from recent works, and advocate a two-step\napproach where feature learning and clustering are decoupled. First, a\nself-supervised task from representation learning is employed to obtain\nsemantically meaningful features. Second, we use the obtained features as a\nprior in a learnable clustering approach. In doing so, we remove the ability\nfor cluster learning to depend on low-level features, which is present in\ncurrent end-to-end learning approaches. Experimental evaluation shows that we\noutperform state-of-the-art methods by large margins, in particular +26.6% on\nCIFAR10, +25.0% on CIFAR100-20 and +21.3% on STL10 in terms of classification\naccuracy. Furthermore, our method is the first to perform well on a large-scale\ndataset for image classification. In particular, we obtain promising results on\nImageNet, and outperform several semi-supervised learning methods in the\nlow-data regime without the use of any ground-truth annotations. The code is\nmade publicly available at\nhttps://github.com/wvangansbeke/Unsupervised-Classification.", "published": "2020-05-25T18:12:33Z", "version": 2}, {"aid": "2006.01424", "authors": ["Yiqun Mei", "Yuchen Fan", "Yuqian Zhou", "Lichao Huang", "Thomas S. Huang", "Humphrey Shi"], "title": "Image Super-Resolution with Cross-Scale Non-Local Attention and Exhaustive Self-Exemplars Mining", "url": "http://arxiv.org/pdf/2006.01424v1", "summary": "Deep convolution-based single image super-resolution (SISR) networks embrace\nthe benefits of learning from large-scale external image resources for local\nrecovery, yet most existing works have ignored the long-range feature-wise\nsimilarities in natural images. Some recent works have successfully leveraged\nthis intrinsic feature correlation by exploring non-local attention modules.\nHowever, none of the current deep models have studied another inherent property\nof images: cross-scale feature correlation. In this paper, we propose the first\nCross-Scale Non-Local (CS-NL) attention module with integration into a\nrecurrent neural network. By combining the new CS-NL prior with local and\nin-scale non-local priors in a powerful recurrent fusion cell, we can find more\ncross-scale feature correlations within a single low-resolution (LR) image. The\nperformance of SISR is significantly improved by exhaustively integrating all\npossible priors. Extensive experiments demonstrate the effectiveness of the\nproposed CS-NL module by setting new state-of-the-arts on multiple SISR\nbenchmarks.", "published": "2020-06-02T07:08:58Z", "version": 1}, {"aid": "2006.02361", "authors": ["Akshunna S. Dogra", "William T Redman"], "title": "Optimizing Neural Networks via Koopman Operator Theory", "url": "http://arxiv.org/pdf/2006.02361v3", "summary": "Koopman operator theory, a powerful framework for discovering the underlying\ndynamics of nonlinear dynamical systems, was recently shown to be intimately\nconnected with neural network training. In this work, we take the first steps\nin making use of this connection. As Koopman operator theory is a linear\ntheory, a successful implementation of it in evolving network weights and\nbiases offers the promise of accelerated training, especially in the context of\ndeep networks, where optimization is inherently a non-convex problem. We show\nthat Koopman operator theoretic methods allow for accurate predictions of\nweights and biases of feedforward, fully connected deep networks over a\nnon-trivial range of training time. During this window, we find that our\napproach is >10x faster than various gradient descent based methods (e.g. Adam,\nAdadelta, Adagrad), in line with our complexity analysis. We end by\nhighlighting open questions in this exciting intersection between dynamical\nsystems and neural network theory. We highlight additional methods by which our\nresults could be expanded to broader classes of networks and larger training\nintervals, which shall be the focus of future work.", "published": "2020-06-03T16:23:07Z", "version": 3}, {"aid": "2006.02713", "authors": ["Yixiao Ge", "Feng Zhu", "Dapeng Chen", "Rui Zhao", "Hongsheng Li"], "title": "Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID", "url": "http://arxiv.org/pdf/2006.02713v2", "summary": "Domain adaptive object re-ID aims to transfer the learned knowledge from the\nlabeled source domain to the unlabeled target domain to tackle the open-class\nre-identification problems. Although state-of-the-art pseudo-label-based\nmethods have achieved great success, they did not make full use of all valuable\ninformation because of the domain gap and unsatisfying clustering performance.\nTo solve these problems, we propose a novel self-paced contrastive learning\nframework with hybrid memory. The hybrid memory dynamically generates\nsource-domain class-level, target-domain cluster-level and un-clustered\ninstance-level supervisory signals for learning feature representations.\nDifferent from the conventional contrastive learning strategy, the proposed\nframework jointly distinguishes source-domain classes, and target-domain\nclusters and un-clustered instances. Most importantly, the proposed self-paced\nmethod gradually creates more reliable clusters to refine the hybrid memory and\nlearning targets, and is shown to be the key to our outstanding performance.\nOur method outperforms state-of-the-arts on multiple domain adaptation tasks of\nobject re-ID and even boosts the performance on the source domain without any\nextra annotations. Our generalized version on unsupervised object re-ID\nsurpasses state-of-the-art algorithms by considerable 16.7% and 7.9% on\nMarket-1501 and MSMT17 benchmarks.", "published": "2020-06-04T09:12:44Z", "version": 2}, {"aid": "2006.02854", "authors": ["Christian Anti\u0107"], "title": "Analogical proportions", "url": "http://arxiv.org/pdf/2006.02854v15", "summary": "Analogy-making is at the core of human and artificial intelligence and\ncreativity with applications to such diverse tasks as proving mathematical\ntheorems and building mathematical theories, common sense reasoning, learning,\nlanguage acquisition, and story telling. This paper introduces from first\nprinciples an abstract algebraic framework of analogical proportions of the\nform `$a$ is to $b$ what $c$ is to $d$' in the general setting of universal\nalgebra. This enables us to compare mathematical objects possibly across\ndifferent domains in a uniform way which is crucial for AI-systems. It turns\nout that our notion of analogical proportions has appealing mathematical\nproperties. As we construct our model from first principles using only\nelementary concepts of universal algebra, and since our model questions some\nbasic properties of analogical proportions presupposed in the literature, to\nconvince the reader of the plausibility of our model we show that it can be\nnaturally embedded into first-order logic via model-theoretic types and prove\nfrom that perspective that analogical proportions are compatible with\nstructure-preserving mappings. This provides conceptual evidence for its\napplicability. In a broader sense, this paper is a first step towards a theory\nof analogical reasoning and learning systems with potential applications to\nfundamental AI-problems like common sense reasoning and computational learning\nand creativity.", "published": "2020-06-04T13:44:36Z", "version": 15}, {"aid": "2006.03298", "authors": ["Javier Hernandez-Ortega", "Javier Galbally", "Julian Fierrez", "Laurent Beslay"], "title": "Biometric Quality: Review and Application to Face Recognition with FaceQnet", "url": "http://arxiv.org/pdf/2006.03298v3", "summary": "\"The output of a computerised system can only be as accurate as the\ninformation entered into it.\" This rather trivial statement is the basis behind\none of the driving concepts in biometric recognition: biometric quality.\nQuality is nowadays widely regarded as the number one factor responsible for\nthe good or bad performance of automated biometric systems. It refers to the\nability of a biometric sample to be used for recognition purposes and produce\nconsistent, accurate, and reliable results. Such a subjective term is\nobjectively estimated by the so-called biometric quality metrics. These\nalgorithms play nowadays a pivotal role in the correct functioning of systems,\nproviding feedback to the users and working as invaluable audit tools. In spite\nof their unanimously accepted relevance, some of the most used and deployed\nbiometric characteristics are lacking behind in the development of these\nmethods. This is the case of face recognition. After a gentle introduction to\nthe general topic of biometric quality and a review of past efforts in face\nquality metrics, in the present work, we address the need for better face\nquality metrics by developing FaceQnet. FaceQnet is a novel open-source face\nquality assessment tool, inspired and powered by deep learning technology,\nwhich assigns a scalar quality measure to facial images, as prediction of their\nrecognition accuracy. Two versions of FaceQnet have been thoroughly evaluated\nboth in this work and also independently by NIST, showing the soundness of the\napproach and its competitiveness with respect to current state-of-the-art\nmetrics. Even though our work is presented here particularly in the framework\nof face biometrics, the proposed methodology for building a fully automated\nquality metric can be very useful and easily adapted to other artificial\nintelligence tasks.", "published": "2020-06-05T08:33:22Z", "version": 3}, {"aid": "2006.04139", "authors": ["Fuzhi Yang", "Huan Yang", "Jianlong Fu", "Hongtao Lu", "Baining Guo"], "title": "Learning Texture Transformer Network for Image Super-Resolution", "url": "http://arxiv.org/pdf/2006.04139v2", "summary": "We study on image super-resolution (SR), which aims to recover realistic\ntextures from a low-resolution (LR) image. Recent progress has been made by\ntaking high-resolution images as references (Ref), so that relevant textures\ncan be transferred to LR images. However, existing SR approaches neglect to use\nattention mechanisms to transfer high-resolution (HR) textures from Ref images,\nwhich limits these approaches in challenging cases. In this paper, we propose a\nnovel Texture Transformer Network for Image Super-Resolution (TTSR), in which\nthe LR and Ref images are formulated as queries and keys in a transformer,\nrespectively. TTSR consists of four closely-related modules optimized for image\ngeneration tasks, including a learnable texture extractor by DNN, a relevance\nembedding module, a hard-attention module for texture transfer, and a\nsoft-attention module for texture synthesis. Such a design encourages joint\nfeature learning across LR and Ref images, in which deep feature\ncorrespondences can be discovered by attention, and thus accurate texture\nfeatures can be transferred. The proposed texture transformer can be further\nstacked in a cross-scale way, which enables texture recovery from different\nlevels (e.g., from 1x to 4x magnification). Extensive experiments show that\nTTSR achieves significant improvements over state-of-the-art approaches on both\nquantitative and qualitative evaluations.", "published": "2020-06-07T12:55:34Z", "version": 2}, {"aid": "2006.04768", "authors": ["Sinong Wang", "Belinda Z. Li", "Madian Khabsa", "Han Fang", "Hao Ma"], "title": "Linformer: Self-Attention with Linear Complexity", "url": "http://arxiv.org/pdf/2006.04768v3", "summary": "Large transformer models have shown extraordinary success in achieving\nstate-of-the-art results in many natural language processing applications.\nHowever, training and deploying these models can be prohibitively costly for\nlong sequences, as the standard self-attention mechanism of the Transformer\nuses $O(n^2)$ time and space with respect to sequence length. In this paper, we\ndemonstrate that the self-attention mechanism can be approximated by a low-rank\nmatrix. We further exploit this finding to propose a new self-attention\nmechanism, which reduces the overall self-attention complexity from $O(n^2)$ to\n$O(n)$ in both time and space. The resulting linear transformer, the\n\\textit{Linformer}, performs on par with standard Transformer models, while\nbeing much more memory- and time-efficient.", "published": "2020-06-08T17:37:52Z", "version": 3}, {"aid": "2006.11161", "authors": ["Aman Chadha", "John Britto", "M. Mani Roja"], "title": "iSeeBetter: Spatio-temporal video super-resolution using recurrent generative back-projection networks", "url": "http://arxiv.org/pdf/2006.11161v4", "summary": "Recently, learning-based models have enhanced the performance of single-image\nsuper-resolution (SISR). However, applying SISR successively to each video\nframe leads to a lack of temporal coherency. Convolutional neural networks\n(CNNs) outperform traditional approaches in terms of image quality metrics such\nas peak signal to noise ratio (PSNR) and structural similarity (SSIM). However,\ngenerative adversarial networks (GANs) offer a competitive advantage by being\nable to mitigate the issue of a lack of finer texture details, usually seen\nwith CNNs when super-resolving at large upscaling factors. We present\niSeeBetter, a novel GAN-based spatio-temporal approach to video\nsuper-resolution (VSR) that renders temporally consistent super-resolution\nvideos. iSeeBetter extracts spatial and temporal information from the current\nand neighboring frames using the concept of recurrent back-projection networks\nas its generator. Furthermore, to improve the \"naturality\" of the\nsuper-resolved image while eliminating artifacts seen with traditional\nalgorithms, we utilize the discriminator from super-resolution generative\nadversarial network (SRGAN). Although mean squared error (MSE) as a primary\nloss-minimization objective improves PSNR/SSIM, these metrics may not capture\nfine details in the image resulting in misrepresentation of perceptual quality.\nTo address this, we use a four-fold (MSE, perceptual, adversarial, and\ntotal-variation (TV)) loss function. Our results demonstrate that iSeeBetter\noffers superior VSR fidelity and surpasses state-of-the-art performance.", "published": "2020-06-13T01:36:30Z", "version": 4}, {"aid": "2006.07710", "authors": ["Harshay Shah", "Kaustav Tamuly", "Aditi Raghunathan", "Prateek Jain", "Praneeth Netrapalli"], "title": "The Pitfalls of Simplicity Bias in Neural Networks", "url": "http://arxiv.org/pdf/2006.07710v2", "summary": "Several works have proposed Simplicity Bias (SB)---the tendency of standard\ntraining procedures such as Stochastic Gradient Descent (SGD) to find simple\nmodels---to justify why neural networks generalize well [Arpit et al. 2017,\nNakkiran et al. 2019, Soudry et al. 2018]. However, the precise notion of\nsimplicity remains vague. Furthermore, previous settings that use SB to\ntheoretically justify why neural networks generalize well do not simultaneously\ncapture the non-robustness of neural networks---a widely observed phenomenon in\npractice [Goodfellow et al. 2014, Jo and Bengio 2017]. We attempt to reconcile\nSB and the superior standard generalization of neural networks with the\nnon-robustness observed in practice by designing datasets that (a) incorporate\na precise notion of simplicity, (b) comprise multiple predictive features with\nvarying levels of simplicity, and (c) capture the non-robustness of neural\nnetworks trained on real data. Through theory and empirics on these datasets,\nwe make four observations: (i) SB of SGD and variants can be extreme: neural\nnetworks can exclusively rely on the simplest feature and remain invariant to\nall predictive complex features. (ii) The extreme aspect of SB could explain\nwhy seemingly benign distribution shifts and small adversarial perturbations\nsignificantly degrade model performance. (iii) Contrary to conventional wisdom,\nSB can also hurt generalization on the same data distribution, as SB persists\neven when the simplest feature has less predictive power than the more complex\nfeatures. (iv) Common approaches to improve generalization and\nrobustness---ensembles and adversarial training---can fail in mitigating SB and\nits pitfalls. Given the role of SB in training neural networks, we hope that\nthe proposed datasets and methods serve as an effective testbed to evaluate\nnovel algorithmic approaches aimed at avoiding the pitfalls of SB.", "published": "2020-06-13T20:15:26Z", "version": 2}, {"aid": "2006.07776", "authors": ["Pengfei Ge", "Chuan-Xian Ren", "Dao-Qing Dai", "Hong Yan"], "title": "Domain Adaptation and Image Classification via Deep Conditional Adaptation Network", "url": "http://arxiv.org/pdf/2006.07776v2", "summary": "Unsupervised domain adaptation aims to generalize the supervised model\ntrained on a source domain to an unlabeled target domain. Marginal distribution\nalignment of feature spaces is widely used to reduce the domain discrepancy\nbetween the source and target domains. However, it assumes that the source and\ntarget domains share the same label distribution, which limits their\napplication scope. In this paper, we consider a more general application\nscenario where the label distributions of the source and target domains are not\nthe same. In this scenario, marginal distribution alignment-based methods will\nbe vulnerable to negative transfer. To address this issue, we propose a novel\nunsupervised domain adaptation method, Deep Conditional Adaptation Network\n(DCAN), based on conditional distribution alignment of feature spaces. To be\nspecific, we reduce the domain discrepancy by minimizing the Conditional\nMaximum Mean Discrepancy between the conditional distributions of deep features\non the source and target domains, and extract the discriminant information from\ntarget domain by maximizing the mutual information between samples and the\nprediction labels. In addition, DCAN can be used to address a special scenario,\nPartial unsupervised domain adaptation, where the target domain category is a\nsubset of the source domain category. Experiments on both unsupervised domain\nadaptation and Partial unsupervised domain adaptation show that DCAN achieves\nsuperior classification performance over state-of-the-art methods.", "published": "2020-06-14T02:56:01Z", "version": 2}, {"aid": "2006.09661", "authors": ["Vincent Sitzmann", "Julien N. P. Martel", "Alexander W. Bergman", "David B. Lindell", "Gordon Wetzstein"], "title": "Implicit Neural Representations with Periodic Activation Functions", "url": "http://arxiv.org/pdf/2006.09661v1", "summary": "Implicitly defined, continuous, differentiable signal representations\nparameterized by neural networks have emerged as a powerful paradigm, offering\nmany possible benefits over conventional representations. However, current\nnetwork architectures for such implicit neural representations are incapable of\nmodeling signals with fine detail, and fail to represent a signal's spatial and\ntemporal derivatives, despite the fact that these are essential to many\nphysical signals defined implicitly as the solution to partial differential\nequations. We propose to leverage periodic activation functions for implicit\nneural representations and demonstrate that these networks, dubbed sinusoidal\nrepresentation networks or Sirens, are ideally suited for representing complex\nnatural signals and their derivatives. We analyze Siren activation statistics\nto propose a principled initialization scheme and demonstrate the\nrepresentation of images, wavefields, video, sound, and their derivatives.\nFurther, we show how Sirens can be leveraged to solve challenging boundary\nvalue problems, such as particular Eikonal equations (yielding signed distance\nfunctions), the Poisson equation, and the Helmholtz and wave equations. Lastly,\nwe combine Sirens with hypernetworks to learn priors over the space of Siren\nfunctions.", "published": "2020-06-17T05:13:33Z", "version": 1}, {"aid": "2006.11239", "authors": ["Jonathan Ho", "Ajay Jain", "Pieter Abbeel"], "title": "Denoising Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2006.11239v2", "summary": "We present high quality image synthesis results using diffusion probabilistic\nmodels, a class of latent variable models inspired by considerations from\nnonequilibrium thermodynamics. Our best results are obtained by training on a\nweighted variational bound designed according to a novel connection between\ndiffusion probabilistic models and denoising score matching with Langevin\ndynamics, and our models naturally admit a progressive lossy decompression\nscheme that can be interpreted as a generalization of autoregressive decoding.\nOn the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and\na state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality\nsimilar to ProgressiveGAN. Our implementation is available at\nhttps://github.com/hojonathanho/diffusion", "published": "2020-06-19T17:24:44Z", "version": 2}, {"aid": "2006.11751", "authors": ["Aleksei Petrenko", "Zhehui Huang", "Tushar Kumar", "Gaurav Sukhatme", "Vladlen Koltun"], "title": "Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning", "url": "http://arxiv.org/pdf/2006.11751v2", "summary": "Increasing the scale of reinforcement learning experiments has allowed\nresearchers to achieve unprecedented results in both training sophisticated\nagents for video games, and in sim-to-real transfer for robotics. Typically\nsuch experiments rely on large distributed systems and require expensive\nhardware setups, limiting wider access to this exciting area of research. In\nthis work we aim to solve this problem by optimizing the efficiency and\nresource utilization of reinforcement learning algorithms instead of relying on\ndistributed computation. We present the \"Sample Factory\", a high-throughput\ntraining system optimized for a single-machine setting. Our architecture\ncombines a highly efficient, asynchronous, GPU-based sampler with off-policy\ncorrection techniques, allowing us to achieve throughput higher than $10^5$\nenvironment frames/second on non-trivial control problems in 3D without\nsacrificing sample efficiency. We extend Sample Factory to support self-play\nand population-based training and apply these techniques to train highly\ncapable agents for a multiplayer first-person shooter game. The source code is\navailable at https://github.com/alex-petrenko/sample-factory", "published": "2020-06-21T10:00:23Z", "version": 2}, {"aid": "2006.13554", "authors": ["Xingjun Ma", "Hanxun Huang", "Yisen Wang", "Simone Romano", "Sarah Erfani", "James Bailey"], "title": "Normalized Loss Functions for Deep Learning with Noisy Labels", "url": "http://arxiv.org/pdf/2006.13554v1", "summary": "Robust loss functions are essential for training accurate deep neural\nnetworks (DNNs) in the presence of noisy (incorrect) labels. It has been shown\nthat the commonly used Cross Entropy (CE) loss is not robust to noisy labels.\nWhilst new loss functions have been designed, they are only partially robust.\nIn this paper, we theoretically show by applying a simple normalization that:\nany loss can be made robust to noisy labels. However, in practice, simply being\nrobust is not sufficient for a loss function to train accurate DNNs. By\ninvestigating several robust loss functions, we find that they suffer from a\nproblem of underfitting. To address this, we propose a framework to build\nrobust loss functions called Active Passive Loss (APL). APL combines two robust\nloss functions that mutually boost each other. Experiments on benchmark\ndatasets demonstrate that the family of new loss functions created by our APL\nframework can consistently outperform state-of-the-art methods by large\nmargins, especially under large noise rates such as 60% or 80% incorrect\nlabels.", "published": "2020-06-24T08:25:46Z", "version": 1}, {"aid": "2006.13748", "authors": ["Arthur Douillard", "Eduardo Valle", "Charles Ollion", "Thomas Robert", "Matthieu Cord"], "title": "Insights from the Future for Continual Learning", "url": "http://arxiv.org/pdf/2006.13748v1", "summary": "Continual learning aims to learn tasks sequentially, with (often severe)\nconstraints on the storage of old learning samples, without suffering from\ncatastrophic forgetting. In this work, we propose prescient continual learning,\na novel experimental setting, to incorporate existing information about the\nclasses, prior to any training data. Usually, each task in a traditional\ncontinual learning setting evaluates the model on present and past classes, the\nlatter with a limited number of training samples. Our setting adds future\nclasses, with no training samples at all. We introduce Ghost Model, a\nrepresentation-learning-based model for continual learning using ideas from\nzero-shot learning. A generative model of the representation space in concert\nwith a careful adjustment of the losses allows us to exploit insights from\nfuture classes to constraint the spatial arrangement of the past and current\nclasses. Quantitative results on the AwA2 and aP\\&Y datasets and detailed\nvisualizations showcase the interest of this new setting and the method we\npropose to address it.", "published": "2020-06-24T14:05:45Z", "version": 1}, {"aid": "2006.15134", "authors": ["Ziyu Wang", "Alexander Novikov", "Konrad Zolna", "Jost Tobias Springenberg", "Scott Reed", "Bobak Shahriari", "Noah Siegel", "Josh Merel", "Caglar Gulcehre", "Nicolas Heess", "Nando de Freitas"], "title": "Critic Regularized Regression", "url": "http://arxiv.org/pdf/2006.15134v3", "summary": "Offline reinforcement learning (RL), also known as batch RL, offers the\nprospect of policy optimization from large pre-recorded datasets without online\nenvironment interaction. It addresses challenges with regard to the cost of\ndata collection and safety, both of which are particularly pertinent to\nreal-world applications of RL. Unfortunately, most off-policy algorithms\nperform poorly when learning from a fixed dataset. In this paper, we propose a\nnovel offline RL algorithm to learn policies from data using a form of\ncritic-regularized regression (CRR). We find that CRR performs surprisingly\nwell and scales to tasks with high-dimensional state and action spaces --\noutperforming several state-of-the-art offline RL algorithms by a significant\nmargin on a wide range of benchmark tasks.", "published": "2020-06-26T17:50:26Z", "version": 3}, {"aid": "2006.15486", "authors": ["Imtiaz Masud Ziko", "Jose Dolz", "Eric Granger", "Ismail Ben Ayed"], "title": "Laplacian Regularized Few-Shot Learning", "url": "http://arxiv.org/pdf/2006.15486v3", "summary": "We propose a transductive Laplacian-regularized inference for few-shot tasks.\nGiven any feature embedding learned from the base classes, we minimize a\nquadratic binary-assignment function containing two terms: (1) a unary term\nassigning query samples to the nearest class prototype, and (2) a pairwise\nLaplacian term encouraging nearby query samples to have consistent label\nassignments. Our transductive inference does not re-train the base model, and\ncan be viewed as a graph clustering of the query set, subject to supervision\nconstraints from the support set. We derive a computationally efficient bound\noptimizer of a relaxation of our function, which computes independent\n(parallel) updates for each query sample, while guaranteeing convergence.\nFollowing a simple cross-entropy training on the base classes, and without\ncomplex meta-learning strategies, we conducted comprehensive experiments over\nfive few-shot learning benchmarks. Our LaplacianShot consistently outperforms\nstate-of-the-art methods by significant margins across different models,\nsettings, and data sets. Furthermore, our transductive inference is very fast,\nwith computational times that are close to inductive inference, and can be used\nfor large-scale few-shot tasks.", "published": "2020-06-28T02:17:52Z", "version": 3}, {"aid": "2006.16241", "authors": ["Dan Hendrycks", "Steven Basart", "Norman Mu", "Saurav Kadavath", "Frank Wang", "Evan Dorundo", "Rahul Desai", "Tyler Zhu", "Samyak Parajuli", "Mike Guo", "Dawn Song", "Jacob Steinhardt", "Justin Gilmer"], "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization", "url": "http://arxiv.org/pdf/2006.16241v3", "summary": "We introduce four new real-world distribution shift datasets consisting of\nchanges in image style, image blurriness, geographic location, camera\noperation, and more. With our new datasets, we take stock of previously\nproposed methods for improving out-of-distribution robustness and put them to\nthe test. We find that using larger models and artificial data augmentations\ncan improve robustness on real-world distribution shifts, contrary to claims in\nprior work. We find improvements in artificial robustness benchmarks can\ntransfer to real-world distribution shifts, contrary to claims in prior work.\nMotivated by our observation that data augmentations can help with real-world\ndistribution shifts, we also introduce a new data augmentation method which\nadvances the state-of-the-art and outperforms models pretrained with 1000 times\nmore labeled data. Overall we find that some methods consistently help with\ndistribution shifts in texture and local image statistics, but these methods do\nnot help with some other distribution shifts like geographic changes. Our\nresults show that future research must study multiple distribution shifts\nsimultaneously, as we demonstrate that no evaluated method consistently\nimproves robustness.", "published": "2020-06-29T17:59:10Z", "version": 3}, {"aid": "2006.16669", "authors": ["Di Wu", "Qi Tang", "Yongle Zhao", "Ming Zhang", "Ying Fu", "Debing Zhang"], "title": "EasyQuant: Post-training Quantization via Scale Optimization", "url": "http://arxiv.org/pdf/2006.16669v1", "summary": "The 8 bits quantization has been widely applied to accelerate network\ninference in various deep learning applications. There are two kinds of\nquantization methods, training-based quantization and post-training\nquantization. Training-based approach suffers from a cumbersome training\nprocess, while post-training quantization may lead to unacceptable accuracy\ndrop. In this paper, we present an efficient and simple post-training method\nvia scale optimization, named EasyQuant (EQ),that could obtain comparable\naccuracy with the training-based method.Specifically, we first alternately\noptimize scales of weights and activations for all layers target at\nconvolutional outputs to further obtain the high quantization precision. Then,\nwe lower down bit width to INT7 both for weights and activations, and adopt\nINT16 intermediate storage and integer Winograd convolution implementation to\naccelerate inference.Experimental results on various computer vision tasks show\nthat EQ outperforms the TensorRT method and can achieve near INT8 accuracy in 7\nbits width post-training.", "published": "2020-06-30T10:43:02Z", "version": 1}, {"aid": "2007.00224", "authors": ["Ching-Yao Chuang", "Joshua Robinson", "Lin Yen-Chen", "Antonio Torralba", "Stefanie Jegelka"], "title": "Debiased Contrastive Learning", "url": "http://arxiv.org/pdf/2007.00224v3", "summary": "A prominent technique for self-supervised representation learning has been to\ncontrast semantically similar and dissimilar pairs of samples. Without access\nto labels, dissimilar (negative) points are typically taken to be randomly\nsampled datapoints, implicitly accepting that these points may, in reality,\nactually have the same label. Perhaps unsurprisingly, we observe that sampling\nnegative examples from truly different labels improves performance, in a\nsynthetic setting where labels are available. Motivated by this observation, we\ndevelop a debiased contrastive objective that corrects for the sampling of\nsame-label datapoints, even without knowledge of the true labels. Empirically,\nthe proposed objective consistently outperforms the state-of-the-art for\nrepresentation learning in vision, language, and reinforcement learning\nbenchmarks. Theoretically, we establish generalization bounds for the\ndownstream classification task.", "published": "2020-07-01T04:25:24Z", "version": 3}, {"aid": "2007.01378", "authors": ["Yonatan Sanz Perl", "Hern\u00e1n Boccacio", "Ignacio P\u00e9rez-Ipi\u00f1a", "Federico Zamberl\u00e1n", "Helmut Laufs", "Morten Kringelbach", "Gustavo Deco", "Enzo Tagliazucchi"], "title": "Generative embeddings of brain collective dynamics using variational autoencoders", "url": "http://arxiv.org/pdf/2007.01378v1", "summary": "We consider the problem of encoding pairwise correlations between coupled\ndynamical systems in a low-dimensional latent space based on few distinct\nobservations. We used variational autoencoders (VAE) to embed temporal\ncorrelations between coupled nonlinear oscillators that model brain states in\nthe wake-sleep cycle into a two-dimensional manifold. Training a VAE with\nsamples generated using two different parameter combinations resulted in an\nembedding that represented the whole repertoire of collective dynamics, as well\nas the topology of the underlying connectivity network. We first followed this\napproach to infer the trajectory of brain states measured from wakefulness to\ndeep sleep from the two endpoints of this trajectory; next, we showed that the\nsame architecture was capable of representing the pairwise correlations of\ngeneric Landau-Stuart oscillators coupled by complex network topology", "published": "2020-07-02T20:43:52Z", "version": 1}, {"aid": "2007.01476", "authors": ["Shipeng Fu", "Zhen Li", "Jun Xu", "Ming-Ming Cheng", "Zitao Liu", "Xiaomin Yang"], "title": "Interactive Knowledge Distillation", "url": "http://arxiv.org/pdf/2007.01476v3", "summary": "Knowledge distillation is a standard teacher-student learning framework to\ntrain a light-weight student network under the guidance of a well-trained large\nteacher network. As an effective teaching strategy, interactive teaching has\nbeen widely employed at school to motivate students, in which teachers not only\nprovide knowledge but also give constructive feedback to students upon their\nresponses, to improve their learning performance. In this work, we propose an\nInterActive Knowledge Distillation (IAKD) scheme to leverage the interactive\nteaching strategy for efficient knowledge distillation. In the distillation\nprocess, the interaction between teacher and student networks is implemented by\na swapping-in operation: randomly replacing the blocks in the student network\nwith the corresponding blocks in the teacher network. In the way, we directly\ninvolve the teacher's powerful feature transformation ability to largely boost\nthe student's performance. Experiments with typical settings of teacher-student\nnetworks demonstrate that the student networks trained by our IAKD achieve\nbetter performance than those trained by conventional knowledge distillation\nmethods on diverse image classification datasets.", "published": "2020-07-03T03:22:04Z", "version": 3}, {"aid": "2007.01524", "authors": ["Youngeun Kim", "Donghyeon Cho", "Kyeongtak Han", "Priyadarshini Panda", "Sungeun Hong"], "title": "Domain Adaptation without Source Data", "url": "http://arxiv.org/pdf/2007.01524v4", "summary": "Domain adaptation assumes that samples from source and target domains are\nfreely accessible during a training phase. However, such an assumption is\nrarely plausible in the real-world and possibly causes data-privacy issues,\nespecially when the label of the source domain can be a sensitive attribute as\nan identifier. To avoid accessing source data that may contain sensitive\ninformation, we introduce Source data-Free Domain Adaptation (SFDA). Our key\nidea is to leverage a pre-trained model from the source domain and\nprogressively update the target model in a self-learning manner. We observe\nthat target samples with lower self-entropy measured by the pre-trained source\nmodel are more likely to be classified correctly. From this, we select the\nreliable samples with the self-entropy criterion and define these as class\nprototypes. We then assign pseudo labels for every target sample based on the\nsimilarity score with class prototypes. Furthermore, to reduce the uncertainty\nfrom the pseudo labeling process, we propose set-to-set distance-based\nfiltering which does not require any tunable hyperparameters. Finally, we train\nthe target model with the filtered pseudo labels with regularization from the\npre-trained source model. Surprisingly, without direct usage of labeled source\nsamples, our PrDA outperforms conventional domain adaptation methods on\nbenchmark datasets. Our code is publicly available at\nhttps://github.com/youngryan1993/SFDA-SourceFreeDA", "published": "2020-07-03T07:21:30Z", "version": 4}, {"aid": "2007.01682", "authors": ["Miao Tian", "Dongyan Guo", "Ying Cui", "Xiang Pan", "Shengyong Chen"], "title": "Improving auto-encoder novelty detection using channel attention and entropy minimization", "url": "http://arxiv.org/pdf/2007.01682v2", "summary": "Novelty detection is a important research area which mainly solves the\nclassification problem of inliers which usually consists of normal samples and\noutliers composed of abnormal samples. Auto-encoder is often used for novelty\ndetection. However, the generalization ability of the auto-encoder may cause\nthe undesirable reconstruction of abnormal elements and reduce the\nidentification ability of the model. To solve the problem, we focus on the\nperspective of better reconstructing the normal samples as well as retaining\nthe unique information of normal samples to improve the performance of\nauto-encoder for novelty detection. Firstly, we introduce attention mechanism\ninto the task. Under the action of attention mechanism, auto-encoder can pay\nmore attention to the representation of inlier samples through adversarial\ntraining. Secondly, we apply the information entropy into the latent layer to\nmake it sparse and constrain the expression of diversity. Experimental results\non three public datasets show that the proposed method achieves comparable\nperformance compared with previous popular approaches.", "published": "2020-07-03T13:41:34Z", "version": 2}, {"aid": "2007.01755", "authors": ["Bin-Bin Gao", "Hong-Yu Zhou"], "title": "Learning to Discover Multi-Class Attentional Regions for Multi-Label Image Recognition", "url": "http://arxiv.org/pdf/2007.01755v3", "summary": "Multi-label image recognition is a practical and challenging task compared to\nsingle-label image classification. However, previous works may be suboptimal\nbecause of a great number of object proposals or complex attentional region\ngeneration modules. In this paper, we propose a simple but efficient two-stream\nframework to recognize multi-category objects from global image to local\nregions, similar to how human beings perceive objects. To bridge the gap\nbetween global and local streams, we propose a multi-class attentional region\nmodule which aims to make the number of attentional regions as small as\npossible and keep the diversity of these regions as high as possible. Our\nmethod can efficiently and effectively recognize multi-class objects with an\naffordable computation cost and a parameter-free region localization module.\nOver three benchmarks on multi-label image classification, we create new\nstate-of-the-art results with a single model only using image semantics without\nlabel dependency. In addition, the effectiveness of the proposed method is\nextensively demonstrated under different factors such as global pooling\nstrategy, input size and network architecture. Code has been made available\nat~\\url{https://github.com/gaobb/MCAR}.", "published": "2020-07-03T15:22:46Z", "version": 3}, {"aid": "2007.02443", "authors": ["Jary Pomponi", "Simone Scardapane", "Aurelio Uncini"], "title": "Pseudo-Rehearsal for Continual Learning with Normalizing Flows", "url": "http://arxiv.org/pdf/2007.02443v4", "summary": "Catastrophic forgetting (CF) happens whenever a neural network overwrites\npast knowledge while being trained on new tasks. Common techniques to handle CF\ninclude regularization of the weights (using, e.g., their importance on past\ntasks), and rehearsal strategies, where the network is constantly re-trained on\npast data. Generative models have also been applied for the latter, in order to\nhave endless sources of data. In this paper, we propose a novel method that\ncombines the strengths of regularization and generative-based rehearsal\napproaches. Our generative model consists of a normalizing flow (NF), a\nprobabilistic and invertible neural network, trained on the internal embeddings\nof the network. By keeping a single NF conditioned on the task, we show that\nour memory overhead remains constant. In addition, exploiting the invertibility\nof the NF, we propose a simple approach to regularize the network's embeddings\nwith respect to past tasks. We show that our method performs favorably with\nrespect to state-of-the-art approaches in the literature, with bounded\ncomputational power and memory overheads.", "published": "2020-07-05T20:43:52Z", "version": 4}, {"aid": "2007.02454", "authors": ["Zeyi Huang", "Haohan Wang", "Eric P. Xing", "Dong Huang"], "title": "Self-Challenging Improves Cross-Domain Generalization", "url": "http://arxiv.org/pdf/2007.02454v1", "summary": "Convolutional Neural Networks (CNN) conduct image classification by\nactivating dominant features that correlated with labels. When the training and\ntesting data are under similar distributions, their dominant features are\nsimilar, which usually facilitates decent performance on the testing data. The\nperformance is nonetheless unmet when tested on samples from different\ndistributions, leading to the challenges in cross-domain image classification.\nWe introduce a simple training heuristic, Representation Self-Challenging\n(RSC), that significantly improves the generalization of CNN to the\nout-of-domain data. RSC iteratively challenges (discards) the dominant features\nactivated on the training data, and forces the network to activate remaining\nfeatures that correlates with labels. This process appears to activate feature\nrepresentations applicable to out-of-domain data without prior knowledge of new\ndomain and without learning extra network parameters. We present theoretical\nproperties and conditions of RSC for improving cross-domain generalization. The\nexperiments endorse the simple, effective and architecture-agnostic nature of\nour RSC method.", "published": "2020-07-05T21:42:26Z", "version": 1}, {"aid": "2007.02731", "authors": ["Didrik Nielsen", "Priyank Jaini", "Emiel Hoogeboom", "Ole Winther", "Max Welling"], "title": "SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows", "url": "http://arxiv.org/pdf/2007.02731v2", "summary": "Normalizing flows and variational autoencoders are powerful generative models\nthat can represent complicated density functions. However, they both impose\nconstraints on the models: Normalizing flows use bijective transformations to\nmodel densities whereas VAEs learn stochastic transformations that are\nnon-invertible and thus typically do not provide tractable estimates of the\nmarginal likelihood. In this paper, we introduce SurVAE Flows: A modular\nframework of composable transformations that encompasses VAEs and normalizing\nflows. SurVAE Flows bridge the gap between normalizing flows and VAEs with\nsurjective transformations, wherein the transformations are deterministic in\none direction -- thereby allowing exact likelihood computation, and stochastic\nin the reverse direction -- hence providing a lower bound on the corresponding\nlikelihood. We show that several recently proposed methods, including\ndequantization and augmented normalizing flows, can be expressed as SurVAE\nFlows. Finally, we introduce common operations such as the max value, the\nabsolute value, sorting and stochastic permutation as composable layers in\nSurVAE Flows.", "published": "2020-07-06T13:13:22Z", "version": 2}, {"aid": "2007.02798", "authors": ["Sam Bond-Taylor", "Chris G. Willcocks"], "title": "Gradient Origin Networks", "url": "http://arxiv.org/pdf/2007.02798v5", "summary": "This paper proposes a new type of generative model that is able to quickly\nlearn a latent representation without an encoder. This is achieved using\nempirical Bayes to calculate the expectation of the posterior, which is\nimplemented by initialising a latent vector with zeros, then using the gradient\nof the log-likelihood of the data with respect to this zero vector as new\nlatent points. The approach has similar characteristics to autoencoders, but\nwith a simpler architecture, and is demonstrated in a variational autoencoder\nequivalent that permits sampling. This also allows implicit representation\nnetworks to learn a space of implicit functions without requiring a\nhypernetwork, retaining their representation advantages across datasets. The\nexperiments show that the proposed method converges faster, with significantly\nlower reconstruction error than autoencoders, while requiring half the\nparameters.", "published": "2020-07-06T15:00:11Z", "version": 5}, {"aid": "2007.07797", "authors": ["Varun Saravanan", "Gordon J Berman", "Samuel J Sober"], "title": "Application of the hierarchical bootstrap to multi-level data in neuroscience", "url": "http://arxiv.org/pdf/2007.07797v2", "summary": "A common feature in many neuroscience datasets is the presence of\nhierarchical data structures, most commonly recording the activity of multiple\nneurons in multiple animals across multiple trials. Accordingly, the\nmeasurements constituting the dataset are not independent, even though the\ntraditional statistical analyses often applied in such cases (e.g., Students\nt-test) treat them as such. The hierarchical bootstrap has been shown to be an\neffective tool to accurately analyze such data and while it has been used\nextensively in the statistical literature, its use is not widespread in\nneuroscience - despite the ubiquity of hierarchical datasets. In this paper, we\nillustrate the intuitiveness and utility of this approach to analyze\nhierarchically nested datasets. We use simulated neural data to show that\ntraditional statistical tests can result in a false positive rate of over 45%,\neven if the Type-I error rate is set at 5%. While summarizing data across\nnon-independent points (or lower levels) can potentially fix this problem, this\napproach greatly reduces the statistical power of the analysis. The\nhierarchical bootstrap, when applied sequentially over the levels of the\nhierarchical structure, keeps the Type-I error rate within the intended bound\nand retains more statistical power than summarizing methods. We conclude by\ndemonstrating the effectiveness of the method in two real-world examples, first\nanalyzing singing data in male Bengalese finches (Lonchura striata var.\ndomestica) and second quantifying changes in behavior under optogenetic control\nin flies (Drosophila melanogaster).", "published": "2020-07-15T16:20:25Z", "version": 2}, {"aid": "2008.02217", "authors": ["Hubert Ramsauer", "Bernhard Sch\u00e4fl", "Johannes Lehner", "Philipp Seidl", "Michael Widrich", "Thomas Adler", "Lukas Gruber", "Markus Holzleitner", "Milena Pavlovi\u0107", "Geir Kjetil Sandve", "Victor Greiff", "David Kreil", "Michael Kopp", "G\u00fcnter Klambauer", "Johannes Brandstetter", "Sepp Hochreiter"], "title": "Hopfield Networks is All You Need", "url": "http://arxiv.org/pdf/2008.02217v3", "summary": "We introduce a modern Hopfield network with continuous states and a\ncorresponding update rule. The new Hopfield network can store exponentially\n(with the dimension of the associative space) many patterns, retrieves the\npattern with one update, and has exponentially small retrieval errors. It has\nthree types of energy minima (fixed points of the update): (1) global fixed\npoint averaging over all patterns, (2) metastable states averaging over a\nsubset of patterns, and (3) fixed points which store a single pattern. The new\nupdate rule is equivalent to the attention mechanism used in transformers. This\nequivalence enables a characterization of the heads of transformer models.\nThese heads perform in the first layers preferably global averaging and in\nhigher layers partial averaging via metastable states. The new modern Hopfield\nnetwork can be integrated into deep learning architectures as layers to allow\nthe storage of and access to raw input data, intermediate results, or learned\nprototypes. These Hopfield layers enable new ways of deep learning, beyond\nfully-connected, convolutional, or recurrent networks, and provide pooling,\nmemory, association, and attention mechanisms. We demonstrate the broad\napplicability of the Hopfield layers across various domains. Hopfield layers\nimproved state-of-the-art on three out of four considered multiple instance\nlearning problems as well as on immune repertoire classification with several\nhundreds of thousands of instances. On the UCI benchmark collections of small\nclassification tasks, where deep learning methods typically struggle, Hopfield\nlayers yielded a new state-of-the-art when compared to different machine\nlearning methods. Finally, Hopfield layers achieved state-of-the-art on two\ndrug design datasets. The implementation is available at:\nhttps://github.com/ml-jku/hopfield-layers", "published": "2020-07-16T17:52:37Z", "version": 3}, {"aid": "2007.10412", "authors": ["Deniz Oktay", "Nick McGreivy", "Joshua Aduol", "Alex Beatson", "Ryan P. Adams"], "title": "Randomized Automatic Differentiation", "url": "http://arxiv.org/pdf/2007.10412v2", "summary": "The successes of deep learning, variational inference, and many other fields\nhave been aided by specialized implementations of reverse-mode automatic\ndifferentiation (AD) to compute gradients of mega-dimensional objectives. The\nAD techniques underlying these tools were designed to compute exact gradients\nto numerical precision, but modern machine learning models are almost always\ntrained with stochastic gradient descent. Why spend computation and memory on\nexact (minibatch) gradients only to use them for stochastic optimization? We\ndevelop a general framework and approach for randomized automatic\ndifferentiation (RAD), which can allow unbiased gradient estimates to be\ncomputed with reduced memory in return for variance. We examine limitations of\nthe general approach, and argue that we must leverage problem specific\nstructure to realize benefits. We develop RAD techniques for a variety of\nsimple neural network architectures, and show that for a fixed memory budget,\nRAD converges in fewer iterations than using a small batch size for feedforward\nnetworks, and in a similar number for recurrent networks. We also show that RAD\ncan be applied to scientific computing, and use it to develop a low-memory\nstochastic gradient method for optimizing the control parameters of a linear\nreaction-diffusion PDE representing a fission reactor.", "published": "2020-07-20T19:03:44Z", "version": 2}, {"aid": "2008.02496", "authors": ["Zihang Jiang", "Weihao Yu", "Daquan Zhou", "Yunpeng Chen", "Jiashi Feng", "Shuicheng Yan"], "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution", "url": "http://arxiv.org/pdf/2008.02496v3", "summary": "Pre-trained language models like BERT and its variants have recently achieved\nimpressive performance in various natural language understanding tasks.\nHowever, BERT heavily relies on the global self-attention block and thus\nsuffers large memory footprint and computation cost. Although all its attention\nheads query on the whole input sequence for generating the attention map from a\nglobal perspective, we observe some heads only need to learn local\ndependencies, which means the existence of computation redundancy. We therefore\npropose a novel span-based dynamic convolution to replace these self-attention\nheads to directly model local dependencies. The novel convolution heads,\ntogether with the rest self-attention heads, form a new mixed attention block\nthat is more efficient at both global and local context learning. We equip BERT\nwith this mixed attention design and build a ConvBERT model. Experiments have\nshown that ConvBERT significantly outperforms BERT and its variants in various\ndownstream tasks, with lower training cost and fewer model parameters.\nRemarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than\nELECTRAbase, while using less than 1/4 training cost. Code and pre-trained\nmodels will be released.", "published": "2020-08-06T07:43:19Z", "version": 3}, {"aid": "2008.03238", "authors": ["Maxwell J. D. Ramstead", "Casper Hesp", "Alec Tschantz", "Ryan Smith", "Axel Constant", "Karl Friston"], "title": "Neural and phenotypic representation under the free-energy principle", "url": "http://arxiv.org/pdf/2008.03238v2", "summary": "The aim of this paper is to leverage the free-energy principle and its\ncorollary process theory, active inference, to develop a generic, generalizable\nmodel of the representational capacities of living creatures; that is, a theory\nof phenotypic representation. Given their ubiquity, we are concerned with\ndistributed forms of representation (e.g., population codes), whereby patterns\nof ensemble activity in living tissue come to represent the causes of sensory\ninput or data. The active inference framework rests on the Markov blanket\nformalism, which allows us to partition systems of interest, such as biological\nsystems, into internal states, external states, and the blanket (active and\nsensory) states that render internal and external states conditionally\nindependent of each other. In this framework, the representational capacity of\nliving creatures emerges as a consequence of their Markovian structure and\nnonequilibrium dynamics, which together entail a dual-aspect information\ngeometry. This entails a modest representational capacity: internal states have\nan intrinsic information geometry that describes their trajectory over time in\nstate space, as well as an extrinsic information geometry that allows internal\nstates to encode (the parameters of) probabilistic beliefs about (fictive)\nexternal states. Building on this, we describe here how, in an automatic and\nemergent manner, information about stimuli can come to be encoded by groups of\nneurons bound by a Markov blanket; what is known as the neuronal packet\nhypothesis. As a concrete demonstration of this type of emergent\nrepresentation, we present numerical simulations showing that self-organizing\nensembles of active inference agents sharing the right kind of probabilistic\ngenerative model are able to encode recoverable information about a stimulus\narray.", "published": "2020-08-07T15:55:42Z", "version": 2}, {"aid": "2008.06021", "authors": ["Arslan Ali", "Matteo Testa", "Tiziano Bianchi", "Enrico Magli"], "title": "BioMetricNet: deep unconstrained face verification through learning of metrics regularized onto Gaussian distributions", "url": "http://arxiv.org/pdf/2008.06021v1", "summary": "We present BioMetricNet: a novel framework for deep unconstrained face\nverification which learns a regularized metric to compare facial features.\nDifferently from popular methods such as FaceNet, the proposed approach does\nnot impose any specific metric on facial features; instead, it shapes the\ndecision space by learning a latent representation in which matching and\nnon-matching pairs are mapped onto clearly separated and well-behaved target\ndistributions. In particular, the network jointly learns the best feature\nrepresentation, and the best metric that follows the target distributions, to\nbe used to discriminate face images. In this paper we present this general\nframework, first of its kind for facial verification, and tailor it to Gaussian\ndistributions. This choice enables the use of a simple linear decision boundary\nthat can be tuned to achieve the desired trade-off between false alarm and\ngenuine acceptance rate, and leads to a loss function that can be written in\nclosed form. Extensive analysis and experimentation on publicly available\ndatasets such as Labeled Faces in the wild (LFW), Youtube faces (YTF),\nCelebrities in Frontal-Profile in the Wild (CFP), and challenging datasets like\ncross-age LFW (CALFW), cross-pose LFW (CPLFW), In-the-wild Age Dataset (AgeDB)\nshow a significant performance improvement and confirms the effectiveness and\nsuperiority of BioMetricNet over existing state-of-the-art methods.", "published": "2020-08-13T17:22:46Z", "version": 1}, {"aid": "2009.01675", "authors": ["Zihao Wang", "Herv\u00e9 Delingette"], "title": "Quasi-symplectic Langevin Variational Autoencoder", "url": "http://arxiv.org/pdf/2009.01675v4", "summary": "Variational autoencoder (VAE) is a very popular and well-investigated\ngenerative model in neural learning research. To leverage VAE in practical\ntasks dealing with a massive dataset of large dimensions, it is required to\ndeal with the difficulty of building low variance evidence lower bounds (ELBO).\nMarkov Chain Monte Carlo (MCMC) is an effective approach to tighten the ELBO\nfor approximating the posterior distribution and Hamiltonian Variational\nAutoencoder (HVAE) is an effective MCMC inspired approach for constructing a\nlow-variance ELBO that is amenable to the reparameterization trick. The HVAE\nadapted the Hamiltonian dynamic flow into variational inference that\nsignificantly improves the performance of the posterior estimation. We propose\nin this work a Langevin dynamic flow-based inference approach by incorporating\nthe gradients information in the inference process through the Langevin dynamic\nwhich is a kind of MCMC based method similar to HVAE. Specifically, we employ a\nquasi-symplectic integrator to cope with the prohibit problem of the Hessian\ncomputing in naive Langevin flow. We show the theoretical and practical\neffectiveness of the proposed framework with other gradient flow-based methods.", "published": "2020-09-02T12:13:27Z", "version": 4}, {"aid": "2009.04765", "authors": ["Nicolas Affolter", "Beni Egressy", "Damian Pascual", "Roger Wattenhofer"], "title": "Brain2Word: Decoding Brain Activity for Language Generation", "url": "http://arxiv.org/pdf/2009.04765v3", "summary": "Brain decoding, understood as the process of mapping brain activities to the\nstimuli that generated them, has been an active research area in the last\nyears. In the case of language stimuli, recent studies have shown that it is\npossible to decode fMRI scans into an embedding of the word a subject is\nreading. However, such word embeddings are designed for natural language\nprocessing tasks rather than for brain decoding. Therefore, they limit our\nability to recover the precise stimulus. In this work, we propose to directly\nclassify an fMRI scan, mapping it to the corresponding word within a fixed\nvocabulary. Unlike existing work, we evaluate on scans from previously unseen\nsubjects. We argue that this is a more realistic setup and we present a model\nthat can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1\nand 13.59% Top-5 accuracy in this challenging task, significantly outperforming\nall the considered competitive baselines. Furthermore, we use the decoded words\nto guide language generation with the GPT-2 model. This way, we advance the\nquest for a system that translates brain activities into coherent text.", "published": "2020-09-10T10:47:36Z", "version": 3}, {"aid": "2009.07888", "authors": ["Zhuangdi Zhu", "Kaixiang Lin", "Anil K. Jain", "Jiayu Zhou"], "title": "Transfer Learning in Deep Reinforcement Learning: A Survey", "url": "http://arxiv.org/pdf/2009.07888v7", "summary": "Reinforcement learning is a learning paradigm for solving sequential\ndecision-making problems. Recent years have witnessed remarkable progress in\nreinforcement learning upon the fast development of deep neural networks. Along\nwith the promising prospects of reinforcement learning in numerous domains such\nas robotics and game-playing, transfer learning has arisen to tackle various\nchallenges faced by reinforcement learning, by transferring knowledge from\nexternal expertise to facilitate the efficiency and effectiveness of the\nlearning process. In this survey, we systematically investigate the recent\nprogress of transfer learning approaches in the context of deep reinforcement\nlearning. Specifically, we provide a framework for categorizing the\nstate-of-the-art transfer learning approaches, under which we analyze their\ngoals, methodologies, compatible reinforcement learning backbones, and\npractical applications. We also draw connections between transfer learning and\nother relevant topics from the reinforcement learning perspective and explore\ntheir potential challenges that await future research progress.", "published": "2020-09-16T18:38:54Z", "version": 7}, {"aid": "2009.09321", "authors": ["Christopher Ick", "Vincent Lostanlen"], "title": "Learning a Lie Algebra from Unlabeled Data Pairs", "url": "http://arxiv.org/pdf/2009.09321v3", "summary": "Deep convolutional networks (convnets) show a remarkable ability to learn\ndisentangled representations. In recent years, the generalization of deep\nlearning to Lie groups beyond rigid motion in $\\mathbb{R}^n$ has allowed to\nbuild convnets over datasets with non-trivial symmetries, such as patterns over\nthe surface of a sphere. However, one limitation of this approach is the need\nto explicitly define the Lie group underlying the desired invariance property\nbefore training the convnet. Whereas rotations on the sphere have a well-known\nsymmetry group ($\\mathrm{SO}(3)$), the same cannot be said of many real-world\nfactors of variability. For example, the disentanglement of pitch, intensity\ndynamics, and playing technique remains a challenging task in music information\nretrieval.\n  This article proposes a machine learning method to discover a nonlinear\ntransformation of the space $\\mathbb{R}^n$ which maps a collection of\n$n$-dimensional vectors $(\\boldsymbol{x}_i)_i$ onto a collection of target\nvectors $(\\boldsymbol{y}_i)_i$. The key idea is to approximate every target\n$\\boldsymbol{y}_i$ by a matrix--vector product of the form\n$\\boldsymbol{\\widetilde{y}}_i = \\boldsymbol{\\phi}(t_i) \\boldsymbol{x}_i$, where\nthe matrix $\\boldsymbol{\\phi}(t_i)$ belongs to a one-parameter subgroup of\n$\\mathrm{GL}_n (\\mathbb{R})$. Crucially, the value of the parameter $t_i \\in\n\\mathbb{R}$ may change between data pairs $(\\boldsymbol{x}_i,\n\\boldsymbol{y}_i)$ and does not need to be known in advance.", "published": "2020-09-19T23:23:52Z", "version": 3}, {"aid": "2009.10301", "authors": ["Benyamin Ghojogh", "Ali Ghodsi", "Fakhri Karray", "Mark Crowley"], "title": "Stochastic Neighbor Embedding with Gaussian and Student-t Distributions: Tutorial and Survey", "url": "http://arxiv.org/pdf/2009.10301v2", "summary": "Stochastic Neighbor Embedding (SNE) is a manifold learning and dimensionality\nreduction method with a probabilistic approach. In SNE, every point is consider\nto be the neighbor of all other points with some probability and this\nprobability is tried to be preserved in the embedding space. SNE considers\nGaussian distribution for the probability in both the input and embedding\nspaces. However, t-SNE uses the Student-t and Gaussian distributions in these\nspaces, respectively. In this tutorial and survey paper, we explain SNE,\nsymmetric SNE, t-SNE (or Cauchy-SNE), and t-SNE with general degrees of\nfreedom. We also cover the out-of-sample extension and acceleration for these\nmethods.", "published": "2020-09-22T03:32:05Z", "version": 2}, {"aid": "2009.13472", "authors": ["Matthew James Vowels", "Necati Cihan Camgoz", "Richard Bowden"], "title": "Targeted VAE: Variational and Targeted Learning for Causal Inference", "url": "http://arxiv.org/pdf/2009.13472v5", "summary": "Undertaking causal inference with observational data is incredibly useful\nacross a wide range of tasks including the development of medical treatments,\nadvertisements and marketing, and policy making. There are two significant\nchallenges associated with undertaking causal inference using observational\ndata: treatment assignment heterogeneity (\\textit{i.e.}, differences between\nthe treated and untreated groups), and an absence of counterfactual data\n(\\textit{i.e.}, not knowing what would have happened if an individual who did\nget treatment, were instead to have not been treated). We address these two\nchallenges by combining structured inference and targeted learning. In terms of\nstructure, we factorize the joint distribution into risk, confounding,\ninstrumental, and miscellaneous factors, and in terms of targeted learning, we\napply a regularizer derived from the influence curve in order to reduce\nresidual bias. An ablation study is undertaken, and an evaluation on benchmark\ndatasets demonstrates that TVAE has competitive and state of the art\nperformance.", "published": "2020-09-28T16:55:24Z", "version": 5}, {"aid": "2009.14788", "authors": ["Matteo Ronchetti"], "title": "TorchRadon: Fast Differentiable Routines for Computed Tomography", "url": "http://arxiv.org/pdf/2009.14788v1", "summary": "This work presents TorchRadon -- an open source CUDA library which contains a\nset of differentiable routines for solving computed tomography (CT)\nreconstruction problems. The library is designed to help researchers working on\nCT problems to combine deep learning and model-based approaches. The package is\ndeveloped as a PyTorch extension and can be seamlessly integrated into existing\ndeep learning training code. Compared to the existing Astra Toolbox, TorchRadon\nis up to 125 faster. The operators implemented by TorchRadon allow the\ncomputation of gradients using PyTorch backward(), and can therefore be easily\ninserted inside existing neural networks architectures. Because of its speed\nand GPU support, TorchRadon can also be effectively used as a fast backend for\nthe implementation of iterative algorithms. This paper presents the main\nfunctionalities of the library, compares results with existing libraries and\nprovides examples of usage.", "published": "2020-09-29T09:20:22Z", "version": 1}, {"aid": "2009.14237", "authors": ["Andrew Head", "Kyle Lo", "Dongyeop Kang", "Raymond Fok", "Sam Skjonsberg", "Daniel S. Weld", "Marti A. Hearst"], "title": "Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols", "url": "http://arxiv.org/pdf/2009.14237v3", "summary": "Despite the central importance of research papers to scientific progress,\nthey can be difficult to read. Comprehension is often stymied when the\ninformation needed to understand a passage resides somewhere else: in another\nsection, or in another paper. In this work, we envision how interfaces can\nbring definitions of technical terms and symbols to readers when and where they\nneed them most. We introduce ScholarPhi, an augmented reading interface with\nfour novel features: (1) tooltips that surface position-sensitive definitions\nfrom elsewhere in a paper, (2) a filter over the paper that \"declutters\" it to\nreveal how the term or symbol is used across the paper, (3) automatic equation\ndiagrams that expose multiple definitions in parallel, and (4) an automatically\ngenerated glossary of important terms and symbols. A usability study showed\nthat the tool helps researchers of all experience levels read papers.\nFurthermore, researchers were eager to have ScholarPhi's definitions available\nto support their everyday reading.", "published": "2020-09-29T18:11:19Z", "version": 3}, {"aid": "2009.14264", "authors": ["Amitai Bickel", "Alexey Gavrilov", "Shimon Ivry", "Neta B Maimon", "Lior Molcho", "Nathan Intrator"], "title": "Reduced neural activity during volatile anesthesia compared to TIVA: evidence from a novel EEG signal processing analysis", "url": "http://arxiv.org/pdf/2009.14264v3", "summary": "Post-operative cognitive decline is a well-known phenomenon and of crucial\nimportance especially in the elderly. General anesthesia can be accomplished by\ninhalation-based (volatile) or total intravenous anesthesia (TIVA). While their\neffects on post-operative symptoms have been investigated, little is known\nabout their influence on brain functionalities during the surgery itself. To\nassess differences 17 patients were divided to receive either volatile\nanesthesia (n=9), or TIVA (n=8). The level of anesthesia was kept to be equal\nin both groups. A single bipolar EEG electrode (Neurosteer system) was placed\non the participants foreheads. It presented real-time activity and collected\ntheir data during the surgery. The dependent variables included frequency bands\n(delta, theta, alpha, and beta), and three features (VC9, ST4, and A0)\npreviously extracted with the device and provided by Neurosteer. All surgeries\nwere uneventful, and all patients showed bispectral index (BIS) score less than\n60. Feature activity under volatile anesthesia (in comparison to TIVA) was\nsignificantly lower for the delta, theta and alpha frequency bands and for the\nthree features. Further analysis showed that the largest difference between\nanesthesia types was for feature A0. The EEG frequency bands and novel brain\nactivity features provide evidence that volatile anesthesia further reduces\ncomponents of brain activity in comparison to TIVA anesthesia. Specifically,\nA0, which previously showed a correlation with cognitive decline severity and\ncognitive load, exhibited the most prominent difference between anesthesia\ntypes. Together, this study suggests that measuring brain activity during\nanesthesia using sensitive features, enables revealing that different\nanesthesia types may affect brain activity differently, which could affect the\nrecovery from anesthesia, and consequently reduce post-operative cognitive\ndecline", "published": "2020-09-29T19:11:14Z", "version": 3}, {"aid": "2009.14385", "authors": ["Alexander Wong", "Mahmoud Famouri", "Mohammad Javad Shafiee"], "title": "AttendNets: Tiny Deep Image Recognition Neural Networks for the Edge via Visual Attention Condensers", "url": "http://arxiv.org/pdf/2009.14385v1", "summary": "While significant advances in deep learning has resulted in state-of-the-art\nperformance across a large number of complex visual perception tasks, the\nwidespread deployment of deep neural networks for TinyML applications involving\non-device, low-power image recognition remains a big challenge given the\ncomplexity of deep neural networks. In this study, we introduce AttendNets,\nlow-precision, highly compact deep neural networks tailored for on-device image\nrecognition. More specifically, AttendNets possess deep self-attention\narchitectures based on visual attention condensers, which extends on the\nrecently introduced stand-alone attention condensers to improve spatial-channel\nselective attention. Furthermore, AttendNets have unique machine-designed\nmacroarchitecture and microarchitecture designs achieved via a machine-driven\ndesign exploration strategy. Experimental results on ImageNet$_{50}$ benchmark\ndataset for the task of on-device image recognition showed that AttendNets have\nsignificantly lower architectural and computational complexity when compared to\nseveral deep neural networks in research literature designed for efficiency\nwhile achieving highest accuracies (with the smallest AttendNet achieving\n$\\sim$7.2% higher accuracy, while requiring $\\sim$3$\\times$ fewer multiply-add\noperations, $\\sim$4.17$\\times$ fewer parameters, and $\\sim$16.7$\\times$ lower\nweight memory requirements than MobileNet-V1). Based on these promising\nresults, AttendNets illustrate the effectiveness of visual attention condensers\nas building blocks for enabling various on-device visual perception tasks for\nTinyML applications.", "published": "2020-09-30T01:53:17Z", "version": 1}, {"aid": "2009.14410", "authors": ["Fanxu Meng", "Hao Cheng", "Ke Li", "Huixiang Luo", "Xiaowei Guo", "Guangming Lu", "Xing Sun"], "title": "Pruning Filter in Filter", "url": "http://arxiv.org/pdf/2009.14410v3", "summary": "Pruning has become a very powerful and effective technique to compress and\naccelerate modern neural networks. Existing pruning methods can be grouped into\ntwo categories: filter pruning (FP) and weight pruning (WP). FP wins at\nhardware compatibility but loses at the compression ratio compared with WP. To\nconverge the strength of both methods, we propose to prune the filter in the\nfilter. Specifically, we treat a filter $F \\in \\mathbb{R}^{C\\times K\\times K}$\nas $K \\times K$ stripes, i.e., $1\\times 1$ filters $\\in \\mathbb{R}^{C}$, then\nby pruning the stripes instead of the whole filter, we can achieve finer\ngranularity than traditional FP while being hardware friendly. We term our\nmethod as SWP (\\emph{Stripe-Wise Pruning}). SWP is implemented by introducing a\nnovel learnable matrix called Filter Skeleton, whose values reflect the shape\nof each filter. As some recent work has shown that the pruned architecture is\nmore crucial than the inherited important weights, we argue that the\narchitecture of a single filter, i.e., the shape, also matters. Through\nextensive experiments, we demonstrate that SWP is more effective compared to\nthe previous FP-based methods and achieves the state-of-art pruning ratio on\nCIFAR-10 and ImageNet datasets without obvious accuracy drop. Code is available\nat https://github.com/fxmeng/Pruning-Filter-in-Filter", "published": "2020-09-30T03:35:16Z", "version": 3}, {"aid": "2009.14416", "authors": ["Qi Qian", "Hao Li", "Juhua Hu"], "title": "Improved Knowledge Distillation via Full Kernel Matrix Transfer", "url": "http://arxiv.org/pdf/2009.14416v2", "summary": "Knowledge distillation is an effective way for model compression in deep\nlearning. Given a large model (i.e., teacher model), it aims to improve the\nperformance of a compact model (i.e., student model) by transferring the\ninformation from the teacher. Various information for distillation has been\nstudied. Recently, a number of works propose to transfer the pairwise\nsimilarity between examples to distill relative information. However, most of\nefforts are devoted to developing different similarity measurements, while only\na small matrix consisting of examples within a mini-batch is transferred at\neach iteration that can be inefficient for optimizing the pairwise similarity\nover the whole data set. In this work, we aim to transfer the full similarity\nmatrix effectively. The main challenge is from the size of the full matrix that\nis quadratic to the number of examples. To address the challenge, we decompose\nthe original full matrix with Nystr{\\\"{o}}m method. By selecting appropriate\nlandmark points, our theoretical analysis indicates that the loss for transfer\ncan be further simplified. Concretely, we find that the difference between the\noriginal full kernel matrices between teacher and student can be well bounded\nby that of the corresponding partial matrices, which only consists of\nsimilarities between original examples and landmark points. Compared with the\nfull matrix, the size of the partial matrix is linear in the number of\nexamples, which improves the efficiency of optimization significantly. The\nempirical study on benchmark data sets demonstrates the effectiveness of the\nproposed algorithm. Code is available at \\url{https://github.com/idstcv/KDA}.", "published": "2020-09-30T04:03:09Z", "version": 2}, {"aid": "2009.14441", "authors": ["Shay Deutsch", "Stefano Soatto"], "title": "Spectral Embedding of Graph Networks", "url": "http://arxiv.org/pdf/2009.14441v1", "summary": "We introduce an unsupervised graph embedding that trades off local node\nsimilarity and connectivity, and global structure. The embedding is based on a\ngeneralized graph Laplacian, whose eigenvectors compactly capture both network\nstructure and neighborhood proximity in a single representation. The key idea\nis to transform the given graph into one whose weights measure the centrality\nof an edge by the fraction of the number of shortest paths that pass through\nthat edge, and employ its spectral proprieties in the representation. Testing\nthe resulting graph network representation shows significant improvement over\nthe sate of the art in data analysis tasks including social networks and\nmaterial science. We also test our method on node classification from the\nhuman-SARS CoV-2 protein-protein interactome.", "published": "2020-09-30T04:59:10Z", "version": 1}, {"aid": "2009.14487", "authors": ["Arash Akbarinia", "Raquel Gil-Rodr\u00edguez", "Alban Flachot", "Matteo Toscani"], "title": "The Utility of Decorrelating Colour Spaces in Vector Quantised Variational Autoencoders", "url": "http://arxiv.org/pdf/2009.14487v1", "summary": "Vector quantised variational autoencoders (VQ-VAE) are characterised by three\nmain components: 1) encoding visual data, 2) assigning $k$ different vectors in\nthe so-called embedding space, and 3) decoding the learnt features. While\nimages are often represented in RGB colour space, the specific organisation of\ncolours in other spaces also offer interesting features, e.g. CIE L*a*b*\ndecorrelates chromaticity into opponent axes. In this article, we propose\ncolour space conversion, a simple quasi-unsupervised task, to enforce a network\nlearning structured representations. To this end, we trained several instances\nof VQ-VAE whose input is an image in one colour space, and its output in\nanother, e.g. from RGB to CIE L*a*b* (in total five colour spaces were\nconsidered). We examined the finite embedding space of trained networks in\norder to disentangle the colour representation in VQ-VAE models. Our analysis\nsuggests that certain vectors encode hue and others luminance information. We\nfurther evaluated the quality of reconstructed images at low-level using\npixel-wise colour metrics, and at high-level by inputting them to image\nclassification and scene segmentation networks. We conducted experiments in\nthree benchmark datasets: ImageNet, COCO and CelebA. Our results show, with\nrespect to the baseline network (whose input and output are RGB), colour\nconversion to decorrelated spaces obtains 1-2 Delta-E lower colour difference\nand 5-10% higher classification accuracy. We also observed that the learnt\nembedding space is easier to interpret in colour opponent models.", "published": "2020-09-30T07:44:01Z", "version": 1}, {"aid": "2010.00029", "authors": ["Hong-Ye Hu", "Dian Wu", "Yi-Zhuang You", "Bruno Olshausen", "Yubei Chen"], "title": "RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior", "url": "http://arxiv.org/pdf/2010.00029v5", "summary": "Flow-based generative models have become an important class of unsupervised\nlearning approaches. In this work, we incorporate the key ideas of\nrenormalization group (RG) and sparse prior distribution to design a\nhierarchical flow-based generative model, RG-Flow, which can separate\ninformation at different scales of images and extract disentangled\nrepresentations at each scale. We demonstrate our method on synthetic\nmulti-scale image datasets and the CelebA dataset, showing that the\ndisentangled representations enable semantic manipulation and style mixing of\nthe images at different scales. To visualize the latent representations, we\nintroduce receptive fields for flow-based models and show that the receptive\nfields of RG-Flow are similar to those of convolutional neural networks. In\naddition, we replace the widely adopted isotropic Gaussian prior distribution\nby the sparse Laplacian distribution to further enhance the disentanglement of\nrepresentations. From a theoretical perspective, our proposed method has\n$O(\\log L)$ complexity for inpainting of an image with edge length $L$,\ncompared to previous generative models with $O(L^2)$ complexity.", "published": "2020-09-30T18:04:04Z", "version": 5}, {"aid": "2010.00400", "authors": ["Javier Hernandez-Ortega", "Ruben Tolosana", "Julian Fierrez", "Aythami Morales"], "title": "DeepFakesON-Phys: DeepFakes Detection based on Heart Rate Estimation", "url": "http://arxiv.org/pdf/2010.00400v3", "summary": "This work introduces a novel DeepFake detection framework based on\nphysiological measurement. In particular, we consider information related to\nthe heart rate using remote photoplethysmography (rPPG). rPPG methods analyze\nvideo sequences looking for subtle color changes in the human skin, revealing\nthe presence of human blood under the tissues. In this work we investigate to\nwhat extent rPPG is useful for the detection of DeepFake videos.\n  The proposed fake detector named DeepFakesON-Phys uses a Convolutional\nAttention Network (CAN), which extracts spatial and temporal information from\nvideo frames, analyzing and combining both sources to better detect fake\nvideos. This detection approach has been experimentally evaluated using the\nlatest public databases in the field: Celeb-DF and DFDC. The results achieved,\nabove 98% AUC (Area Under the Curve) on both databases, outperform the state of\nthe art and prove the success of fake detectors based on physiological\nmeasurement to detect the latest DeepFake videos.", "published": "2020-10-01T13:37:58Z", "version": 3}, {"aid": "2010.00516", "authors": ["Meenakshi Khosla", "Gia H. Ngo", "Keith Jamison", "Amy Kuceyeski", "Mert R. Sabuncu"], "title": "Neural encoding with visual attention", "url": "http://arxiv.org/pdf/2010.00516v1", "summary": "Visual perception is critically influenced by the focus of attention. Due to\nlimited resources, it is well known that neural representations are biased in\nfavor of attended locations. Using concurrent eye-tracking and functional\nMagnetic Resonance Imaging (fMRI) recordings from a large cohort of human\nsubjects watching movies, we first demonstrate that leveraging gaze\ninformation, in the form of attentional masking, can significantly improve\nbrain response prediction accuracy in a neural encoding model. Next, we propose\na novel approach to neural encoding by including a trainable soft-attention\nmodule. Using our new approach, we demonstrate that it is possible to learn\nvisual attention policies by end-to-end learning merely on fMRI response data,\nand without relying on any eye-tracking. Interestingly, we find that attention\nlocations estimated by the model on independent data agree well with the\ncorresponding eye fixation patterns, despite no explicit supervision to do so.\nTogether, these findings suggest that attention modules can be instrumental in\nneural encoding models of visual stimuli.", "published": "2020-10-01T16:04:21Z", "version": 1}, {"aid": "2010.00525", "authors": ["David Lipshutz", "Yanis Bahroun", "Siavash Golkar", "Anirvan M. Sengupta", "Dmitri B. Chklovskii"], "title": "A biologically plausible neural network for multi-channel Canonical Correlation Analysis", "url": "http://arxiv.org/pdf/2010.00525v4", "summary": "Cortical pyramidal neurons receive inputs from multiple distinct neural\npopulations and integrate these inputs in separate dendritic compartments. We\nexplore the possibility that cortical microcircuits implement Canonical\nCorrelation Analysis (CCA), an unsupervised learning method that projects the\ninputs onto a common subspace so as to maximize the correlations between the\nprojections. To this end, we seek a multi-channel CCA algorithm that can be\nimplemented in a biologically plausible neural network. For biological\nplausibility, we require that the network operates in the online setting and\nits synaptic update rules are local. Starting from a novel CCA objective\nfunction, we derive an online optimization algorithm whose optimization steps\ncan be implemented in a single-layer neural network with multi-compartmental\nneurons and local non-Hebbian learning rules. We also derive an extension of\nour online CCA algorithm with adaptive output rank and output whitening.\nInterestingly, the extension maps onto a neural network whose neural\narchitecture and synaptic updates resemble neural circuitry and synaptic\nplasticity observed experimentally in cortical pyramidal neurons.", "published": "2020-10-01T16:17:53Z", "version": 4}, {"aid": "2010.00541", "authors": ["Nicol\u00e1s Vattuone", "Thomas Wachtler", "In\u00e9s Samengo"], "title": "Perceptual spaces and their symmetries: The geometry of color space", "url": "http://arxiv.org/pdf/2010.00541v5", "summary": "Our sensory systems transform external signals into neural activity, thereby\nproducing percepts. We are endowed with an intuitive notion of similarity\nbetween percepts, that need not reflect the proximity of the physical\nproperties of the corresponding external stimuli. The quantitative\ncharacterization of the geometry of percepts is therefore an endeavour that\nmust be accomplished behaviorally. Here we characterized the geometry of color\nspace using discrimination and matching experiments. We proposed an\nindividually tailored metric defined in terms of the minimal chromatic\ndifference required for each observer to differentiate a stimulus from its\nsurround. Next, we showed that this perceptual metric was particularly adequate\nto describe two additional experiments, since it revealed the natural symmetry\nof perceptual computations. In one of the experiments, observers were required\nto discriminate two stimuli surrounded by a chromaticity that differed from\nthat of the tested stimuli. In the perceptual coordinates, the change in\ndiscrimination thresholds induced by the surround followed a simple law that\nonly depended on the perceptual distance between the surround and each of the\ntwo compared stimuli. In the other experiment, subjects were asked to match the\ncolor of two stimuli surrounded by two different chromaticities. Again, in the\nperceptual coordinates the induction effect produced by surrounds followed a\nsimple, symmetric law. We conclude that the individually-tailored notion of\nperceptual distance reveals the symmetry of the laws governing perceptual\ncomputations.", "published": "2020-10-01T16:52:29Z", "version": 5}, {"aid": "2010.00567", "authors": ["Hassan Ismail Fawaz"], "title": "Deep learning for time series classification", "url": "http://arxiv.org/pdf/2010.00567v1", "summary": "Time series analysis is a field of data science which is interested in\nanalyzing sequences of numerical values ordered in time. Time series are\nparticularly interesting because they allow us to visualize and understand the\nevolution of a process over time. Their analysis can reveal trends,\nrelationships and similarities across the data. There exists numerous fields\ncontaining data in the form of time series: health care (electrocardiogram,\nblood sugar, etc.), activity recognition, remote sensing, finance (stock market\nprice), industry (sensors), etc. Time series classification consists of\nconstructing algorithms dedicated to automatically label time series data. The\nsequential aspect of time series data requires the development of algorithms\nthat are able to harness this temporal property, thus making the existing\noff-the-shelf machine learning models for traditional tabular data suboptimal\nfor solving the underlying task. In this context, deep learning has emerged in\nrecent years as one of the most effective methods for tackling the supervised\nclassification task, particularly in the field of computer vision. The main\nobjective of this thesis was to study and develop deep neural networks\nspecifically constructed for the classification of time series data. We thus\ncarried out the first large scale experimental study allowing us to compare the\nexisting deep methods and to position them compared other non-deep learning\nbased state-of-the-art methods. Subsequently, we made numerous contributions in\nthis area, notably in the context of transfer learning, data augmentation,\nensembling and adversarial attacks. Finally, we have also proposed a novel\narchitecture, based on the famous Inception network (Google), which ranks among\nthe most efficient to date.", "published": "2020-10-01T17:38:40Z", "version": 1}, {"aid": "2010.00578", "authors": ["Yuandong Tian", "Lantao Yu", "Xinlei Chen", "Surya Ganguli"], "title": "Understanding Self-supervised Learning with Dual Deep Networks", "url": "http://arxiv.org/pdf/2010.00578v6", "summary": "We propose a novel theoretical framework to understand contrastive\nself-supervised learning (SSL) methods that employ dual pairs of deep ReLU\nnetworks (e.g., SimCLR). First, we prove that in each SGD update of SimCLR with\nvarious loss functions, including simple contrastive loss, soft Triplet loss\nand InfoNCE loss, the weights at each layer are updated by a \\emph{covariance\noperator} that specifically amplifies initial random selectivities that vary\nacross data samples but survive averages over data augmentations. To further\nstudy what role the covariance operator plays and which features are learned in\nsuch a process, we model data generation and augmentation processes through a\n\\emph{hierarchical latent tree model} (HLTM) and prove that the hidden neurons\nof deep ReLU networks can learn the latent variables in HLTM, despite the fact\nthat the network receives \\emph{no direct supervision} from these unobserved\nlatent variables. This leads to a provable emergence of hierarchical features\nthrough the amplification of initially random selectivities through contrastive\nSSL. Extensive numerical studies justify our theoretical findings. Code is\nreleased in https://github.com/facebookresearch/luckmatters/tree/master/ssl.", "published": "2020-10-01T17:51:49Z", "version": 6}, {"aid": "2010.04434", "authors": ["Tielin Zhang", "Shuncheng Jia", "Xiang Cheng", "Bo Xu"], "title": "Tuning Convolutional Spiking Neural Network with Biologically-plausible Reward Propagation", "url": "http://arxiv.org/pdf/2010.04434v3", "summary": "Spiking Neural Networks (SNNs) contain more biologically realistic structures\nand biologically-inspired learning principles than those in standard Artificial\nNeural Networks (ANNs). SNNs are considered the third generation of ANNs,\npowerful on the robust computation with a low computational cost. The neurons\nin SNNs are non-differential, containing decayed historical states and\ngenerating event-based spikes after their states reaching the firing threshold.\nThese dynamic characteristics of SNNs make it difficult to be directly trained\nwith the standard backpropagation (BP), which is also considered not\nbiologically plausible. In this paper, a Biologically-plausible Reward\nPropagation (BRP) algorithm is proposed and applied to the SNN architecture\nwith both spiking-convolution (with both 1D and 2D convolutional kernels) and\nfull-connection layers. Unlike the standard BP that propagates error signals\nfrom post to presynaptic neurons layer by layer, the BRP propagates target\nlabels instead of errors directly from the output layer to all pre-hidden\nlayers. This effort is more consistent with the top-down reward-guiding\nlearning in cortical columns of the neocortex. Synaptic modifications with only\nlocal gradient differences are induced with pseudo-BP that might also be\nreplaced with the Spike-Timing Dependent Plasticity (STDP). The performance of\nthe proposed BRP-SNN is further verified on the spatial (including MNIST and\nCifar-10) and temporal (including TIDigits and DvsGesture) tasks, where the SNN\nusing BRP has reached a similar accuracy compared to other state-of-the-art\nBP-based SNNs and saved 50% more computational cost than ANNs. We think the\nintroduction of biologically plausible learning rules to the training procedure\nof biologically realistic SNNs will give us more hints and inspirations toward\na better understanding of the biological system's intelligent nature.", "published": "2020-10-09T08:42:13Z", "version": 3}, {"aid": "2010.05063", "authors": ["Yaoyao Liu", "Bernt Schiele", "Qianru Sun"], "title": "Adaptive Aggregation Networks for Class-Incremental Learning", "url": "http://arxiv.org/pdf/2010.05063v3", "summary": "Class-Incremental Learning (CIL) aims to learn a classification model with\nthe number of classes increasing phase-by-phase. An inherent problem in CIL is\nthe stability-plasticity dilemma between the learning of old and new classes,\ni.e., high-plasticity models easily forget old classes, but high-stability\nmodels are weak to learn new classes. We alleviate this issue by proposing a\nnovel network architecture called Adaptive Aggregation Networks (AANets), in\nwhich we explicitly build two types of residual blocks at each residual level\n(taking ResNet as the baseline architecture): a stable block and a plastic\nblock. We aggregate the output feature maps from these two blocks and then feed\nthe results to the next-level blocks. We adapt the aggregation weights in order\nto balance these two types of blocks, i.e., to balance stability and\nplasticity, dynamically. We conduct extensive experiments on three CIL\nbenchmarks: CIFAR-100, ImageNet-Subset, and ImageNet, and show that many\nexisting CIL methods can be straightforwardly incorporated into the\narchitecture of AANets to boost their performances.", "published": "2020-10-10T18:24:24Z", "version": 3}, {"aid": "2010.07468", "authors": ["Juntang Zhuang", "Tommy Tang", "Yifan Ding", "Sekhar Tatikonda", "Nicha Dvornek", "Xenophon Papademetris", "James S. Duncan"], "title": "AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients", "url": "http://arxiv.org/pdf/2010.07468v5", "summary": "Most popular optimizers for deep learning can be broadly categorized as\nadaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient\ndescent (SGD) with momentum). For many models such as convolutional neural\nnetworks (CNNs), adaptive methods typically converge faster but generalize\nworse compared to SGD; for complex settings such as generative adversarial\nnetworks (GANs), adaptive methods are typically the default because of their\nstability.We propose AdaBelief to simultaneously achieve three goals: fast\nconvergence as in adaptive methods, good generalization as in SGD, and training\nstability. The intuition for AdaBelief is to adapt the stepsize according to\nthe \"belief\" in the current gradient direction. Viewing the exponential moving\naverage (EMA) of the noisy gradient as the prediction of the gradient at the\nnext time step, if the observed gradient greatly deviates from the prediction,\nwe distrust the current observation and take a small step; if the observed\ngradient is close to the prediction, we trust it and take a large step. We\nvalidate AdaBelief in extensive experiments, showing that it outperforms other\nmethods with fast convergence and high accuracy on image classification and\nlanguage modeling. Specifically, on ImageNet, AdaBelief achieves comparable\naccuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief\ndemonstrates high stability and improves the quality of generated samples\ncompared to a well-tuned Adam optimizer. Code is available at\nhttps://github.com/juntang-zhuang/Adabelief-Optimizer", "published": "2020-10-15T01:46:13Z", "version": 5}, {"aid": "2010.07604", "authors": ["Dongjun Kim", "Kyungwoo Song", "YoonYeong Kim", "Yongjin Shin", "Wanmo Kang", "Il-Chul Moon", "Weonyoung Joo"], "title": "Sequential Likelihood-Free Inference with Neural Proposal", "url": "http://arxiv.org/pdf/2010.07604v3", "summary": "Bayesian inference without the likelihood evaluation, or likelihood-free\ninference, has been a key research topic in simulation studies for gaining\nquantitatively validated simulation models on real-world datasets. As the\nlikelihood evaluation is inaccessible, previous papers train the amortized\nneural network to estimate the ground-truth posterior for the simulation of\ninterest. Training the network and accumulating the dataset alternatively in a\nsequential manner could save the total simulation budget by orders of\nmagnitude. In the data accumulation phase, the new simulation inputs are chosen\nwithin a portion of the total simulation budget to accumulate upon the\ncollected dataset. This newly accumulated data degenerates because the set of\nsimulation inputs is hardly mixed, and this degenerated data collection process\nruins the posterior inference. This paper introduces a new sampling approach,\ncalled Neural Proposal (NP), of the simulation input that resolves the biased\ndata collection as it guarantees the i.i.d. sampling. The experiments show the\nimproved performance of our sampler, especially for the simulations with\nmulti-modal posteriors.", "published": "2020-10-15T08:59:23Z", "version": 3}, {"aid": "2010.07726", "authors": ["Benlei Cui", "XueMei Dong", "Qiaoqiao Zhan", "Jiangtao Peng", "Weiwei Sun"], "title": "LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image Classification", "url": "http://arxiv.org/pdf/2010.07726v1", "summary": "Deep learning methods have shown considerable potential for hyperspectral\nimage (HSI) classification, which can achieve high accuracy compared with\ntraditional methods. However, they often need a large number of training\nsamples and have a lot of parameters and high computational overhead. To solve\nthese problems, this paper proposes a new network architecture,\nLiteDepthwiseNet, for HSI classification. Based on 3D depthwise convolution,\nLiteDepthwiseNet can decompose standard convolution into depthwise convolution\nand pointwise convolution, which can achieve high classification performance\nwith minimal parameters. Moreover, we remove the ReLU layer and Batch\nNormalization layer in the original 3D depthwise convolution, which\nsignificantly improves the overfitting phenomenon of the model on small sized\ndatasets. In addition, focal loss is used as the loss function to improve the\nmodel's attention on difficult samples and unbalanced data, and its training\nperformance is significantly better than that of cross-entropy loss or balanced\ncross-entropy loss. Experiment results on three benchmark hyperspectral\ndatasets show that LiteDepthwiseNet achieves state-of-the-art performance with\na very small number of parameters and low computational cost.", "published": "2020-10-15T13:12:17Z", "version": 1}, {"aid": "2010.07810", "authors": ["Amil Merchant", "Barret Zoph", "Ekin Dogus Cubuk"], "title": "Does Data Augmentation Benefit from Split BatchNorms", "url": "http://arxiv.org/pdf/2010.07810v1", "summary": "Data augmentation has emerged as a powerful technique for improving the\nperformance of deep neural networks and led to state-of-the-art results in\ncomputer vision. However, state-of-the-art data augmentation strongly distorts\ntraining images, leading to a disparity between examples seen during training\nand inference. In this work, we explore a recently proposed training paradigm\nin order to correct for this disparity: using an auxiliary BatchNorm for the\npotentially out-of-distribution, strongly augmented images. Our experiments\nthen focus on how to define the BatchNorm parameters that are used at\nevaluation. To eliminate the train-test disparity, we experiment with using the\nbatch statistics defined by clean training images only, yet surprisingly find\nthat this does not yield improvements in model performance. Instead, we\ninvestigate using BatchNorm parameters defined by weak augmentations and find\nthat this method significantly improves the performance of common image\nclassification benchmarks such as CIFAR-10, CIFAR-100, and ImageNet. We then\nexplore a fundamental trade-off between accuracy and robustness coming from\nusing different BatchNorm parameters, providing greater insight into the\nbenefits of data augmentation on model performance.", "published": "2020-10-15T15:00:43Z", "version": 1}, {"aid": "2010.09931", "authors": ["Gil I. Shamir", "Dong Lin", "Lorenzo Coviello"], "title": "Smooth activations and reproducibility in deep networks", "url": "http://arxiv.org/pdf/2010.09931v2", "summary": "Deep networks are gradually penetrating almost every domain in our lives due\nto their amazing success. However, with substantive performance accuracy\nimprovements comes the price of \\emph{irreproducibility}. Two identical models,\ntrained on the exact same training dataset may exhibit large differences in\npredictions on individual examples even when average accuracy is similar,\nespecially when trained on highly distributed parallel systems. The popular\nRectified Linear Unit (ReLU) activation has been key to recent success of deep\nnetworks. We demonstrate, however, that ReLU is also a catalyzer to\nirreproducibility in deep networks. We show that not only can activations\nsmoother than ReLU provide better accuracy, but they can also provide better\naccuracy-reproducibility tradeoffs. We propose a new family of activations;\nSmooth ReLU (\\emph{SmeLU}), designed to give such better tradeoffs, while also\nkeeping the mathematical expression simple, and thus implementation cheap.\nSmeLU is monotonic, mimics ReLU, while providing continuous gradients, yielding\nbetter reproducibility. We generalize SmeLU to give even more flexibility and\nthen demonstrate that SmeLU and its generalized form are special cases of a\nmore general methodology of REctified Smooth Continuous Unit (RESCU)\nactivations. Empirical results demonstrate the superior\naccuracy-reproducibility tradeoffs with smooth activations, SmeLU in\nparticular.", "published": "2020-10-20T00:06:47Z", "version": 2}, {"aid": "2010.10604", "authors": ["Xinjie Fan", "Shujian Zhang", "Bo Chen", "Mingyuan Zhou"], "title": "Bayesian Attention Modules", "url": "http://arxiv.org/pdf/2010.10604v1", "summary": "Attention modules, as simple and effective tools, have not only enabled deep\nneural networks to achieve state-of-the-art results in many domains, but also\nenhanced their interpretability. Most current models use deterministic\nattention modules due to their simplicity and ease of optimization. Stochastic\ncounterparts, on the other hand, are less popular despite their potential\nbenefits. The main reason is that stochastic attention often introduces\noptimization issues or requires significant model changes. In this paper, we\npropose a scalable stochastic version of attention that is easy to implement\nand optimize. We construct simplex-constrained attention distributions by\nnormalizing reparameterizable distributions, making the training process\ndifferentiable. We learn their parameters in a Bayesian framework where a\ndata-dependent prior is introduced for regularization. We apply the proposed\nstochastic attention modules to various attention-based models, with\napplications to graph node classification, visual question answering, image\ncaptioning, machine translation, and language understanding. Our experiments\nshow the proposed method brings consistent improvements over the corresponding\nbaselines.", "published": "2020-10-20T20:30:55Z", "version": 1}, {"aid": "2010.10687", "authors": ["Vinay Rao", "Jascha Sohl-Dickstein"], "title": "Is Batch Norm unique? An empirical investigation and prescription to emulate the best properties of common normalizers without batch dependence", "url": "http://arxiv.org/pdf/2010.10687v1", "summary": "We perform an extensive empirical study of the statistical properties of\nBatch Norm and other common normalizers. This includes an examination of the\ncorrelation between representations of minibatches, gradient norms, and Hessian\nspectra both at initialization and over the course of training. Through this\nanalysis, we identify several statistical properties which appear linked to\nBatch Norm's superior performance. We propose two simple normalizers,\nPreLayerNorm and RegNorm, which better match these desirable properties without\ninvolving operations along the batch dimension. We show that PreLayerNorm and\nRegNorm achieve much of the performance of Batch Norm without requiring batch\ndependence, that they reliably outperform LayerNorm, and that they can be\napplied in situations where Batch Norm is ineffective.", "published": "2020-10-21T00:41:38Z", "version": 1}, {"aid": "2010.11248", "authors": ["Yuki Kawana", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Neural Star Domain as Primitive Representation", "url": "http://arxiv.org/pdf/2010.11248v2", "summary": "Reconstructing 3D objects from 2D images is a fundamental task in computer\nvision. Accurate structured reconstruction by parsimonious and semantic\nprimitive representation further broadens its application. When reconstructing\na target shape with multiple primitives, it is preferable that one can\ninstantly access the union of basic properties of the shape such as collective\nvolume and surface, treating the primitives as if they are one single shape.\nThis becomes possible by primitive representation with unified implicit and\nexplicit representations. However, primitive representations in current\napproaches do not satisfy all of the above requirements at the same time. To\nsolve this problem, we propose a novel primitive representation named neural\nstar domain (NSD) that learns primitive shapes in the star domain. We show that\nNSD is a universal approximator of the star domain and is not only parsimonious\nand semantic but also an implicit and explicit shape representation. We\ndemonstrate that our approach outperforms existing methods in image\nreconstruction tasks, semantic capabilities, and speed and quality of sampling\nhigh-resolution meshes.", "published": "2020-10-21T19:05:16Z", "version": 2}, {"aid": "2010.11929", "authors": ["Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Mostafa Dehghani", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Jakob Uszkoreit", "Neil Houlsby"], "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "url": "http://arxiv.org/pdf/2010.11929v2", "summary": "While the Transformer architecture has become the de-facto standard for\nnatural language processing tasks, its applications to computer vision remain\nlimited. In vision, attention is either applied in conjunction with\nconvolutional networks, or used to replace certain components of convolutional\nnetworks while keeping their overall structure in place. We show that this\nreliance on CNNs is not necessary and a pure transformer applied directly to\nsequences of image patches can perform very well on image classification tasks.\nWhen pre-trained on large amounts of data and transferred to multiple mid-sized\nor small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision\nTransformer (ViT) attains excellent results compared to state-of-the-art\nconvolutional networks while requiring substantially fewer computational\nresources to train.", "published": "2020-10-22T17:55:59Z", "version": 2}, {"aid": "2010.12785", "authors": ["Haoran You", "Xiaohan Chen", "Yongan Zhang", "Chaojian Li", "Sicheng Li", "Zihao Liu", "Zhangyang Wang", "Yingyan Celine Lin"], "title": "ShiftAddNet: A Hardware-Inspired Deep Network", "url": "http://arxiv.org/pdf/2010.12785v2", "summary": "Multiplication (e.g., convolution) is arguably a cornerstone of modern deep\nneural networks (DNNs). However, intensive multiplications cause expensive\nresource costs that challenge DNNs' deployment on resource-constrained edge\ndevices, driving several attempts for multiplication-less deep networks. This\npaper presented ShiftAddNet, whose main inspiration is drawn from a common\npractice in energy-efficient hardware implementation, that is, multiplication\ncan be instead performed with additions and logical bit-shifts. We leverage\nthis idea to explicitly parameterize deep networks in this way, yielding a new\ntype of deep network that involves only bit-shift and additive weight layers.\nThis hardware-inspired ShiftAddNet immediately leads to both energy-efficient\ninference and training, without compromising the expressive capacity compared\nto standard DNNs. The two complementary operation types (bit-shift and add)\nadditionally enable finer-grained control of the model's learning capacity,\nleading to more flexible trade-off between accuracy and (training) efficiency,\nas well as improved robustness to quantization and pruning. We conduct\nextensive experiments and ablation studies, all backed up by our FPGA-based\nShiftAddNet implementation and energy measurements. Compared to existing DNNs\nor other multiplication-less models, ShiftAddNet aggressively reduces over 80%\nhardware-quantified energy cost of DNNs training and inference, while offering\ncomparable or better accuracies. Codes and pre-trained models are available at\nhttps://github.com/RICE-EIC/ShiftAddNet.", "published": "2020-10-24T05:09:14Z", "version": 2}, {"aid": "2010.14819", "authors": ["Kai Han", "Yunhe Wang", "Qiulin Zhang", "Wei Zhang", "Chunjing Xu", "Tong Zhang"], "title": "Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets", "url": "http://arxiv.org/pdf/2010.14819v2", "summary": "To obtain excellent deep neural architectures, a series of techniques are\ncarefully designed in EfficientNets. The giant formula for simultaneously\nenlarging the resolution, depth and width provides us a Rubik's cube for neural\nnetworks. So that we can find networks with high efficiency and excellent\nperformance by twisting the three dimensions. This paper aims to explore the\ntwisting rules for obtaining deep neural networks with minimum model sizes and\ncomputational costs. Different from the network enlarging, we observe that\nresolution and depth are more important than width for tiny networks.\nTherefore, the original method, i.e., the compound scaling in EfficientNet is\nno longer suitable. To this end, we summarize a tiny formula for downsizing\nneural architectures through a series of smaller models derived from the\nEfficientNet-B0 with the FLOPs constraint. Experimental results on the ImageNet\nbenchmark illustrate that our TinyNet performs much better than the smaller\nversion of EfficientNets using the inversed giant formula. For instance, our\nTinyNet-E achieves a 59.9% Top-1 accuracy with only 24M FLOPs, which is about\n1.9% higher than that of the previous best MobileNetV3 with similar\ncomputational cost. Code will be available at\nhttps://github.com/huawei-noah/ghostnet/tree/master/tinynet_pytorch, and\nhttps://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/tinynet.", "published": "2020-10-28T08:49:45Z", "version": 2}, {"aid": "2010.14831", "authors": ["Stan Z. Li", "Zelin Zang", "Lirong Wu"], "title": "Deep Manifold Transformation for Nonlinear Dimensionality Reduction", "url": "http://arxiv.org/pdf/2010.14831v3", "summary": "Manifold learning-based encoders have been playing important roles in\nnonlinear dimensionality reduction (NLDR) for data exploration. However,\nexisting methods can often fail to preserve geometric, topological and/or\ndistributional structures of data. In this paper, we propose a deep manifold\nlearning framework, called deep manifold transformation (DMT) for unsupervised\nNLDR and embedding learning. DMT enhances deep neural networks by using\ncross-layer local geometry-preserving (LGP) constraints. The LGP constraints\nconstitute the loss for deep manifold learning and serve as geometric\nregularizers for NLDR network training. Extensive experiments on synthetic and\nreal-world data demonstrate that DMT networks outperform existing leading\nmanifold-based NLDR methods in terms of preserving the structures of data.", "published": "2020-10-28T09:09:41Z", "version": 3}, {"aid": "2010.15487", "authors": ["Arslan Ali", "Andrea Migliorati", "Tiziano Bianchi", "Enrico Magli"], "title": "Beyond cross-entropy: learning highly separable feature distributions for robust and accurate classification", "url": "http://arxiv.org/pdf/2010.15487v1", "summary": "Deep learning has shown outstanding performance in several applications\nincluding image classification. However, deep classifiers are known to be\nhighly vulnerable to adversarial attacks, in that a minor perturbation of the\ninput can easily lead to an error. Providing robustness to adversarial attacks\nis a very challenging task especially in problems involving a large number of\nclasses, as it typically comes at the expense of an accuracy decrease. In this\nwork, we propose the Gaussian class-conditional simplex (GCCS) loss: a novel\napproach for training deep robust multiclass classifiers that provides\nadversarial robustness while at the same time achieving or even surpassing the\nclassification accuracy of state-of-the-art methods. Differently from other\nframeworks, the proposed method learns a mapping of the input classes onto\ntarget distributions in a latent space such that the classes are linearly\nseparable. Instead of maximizing the likelihood of target labels for individual\nsamples, our objective function pushes the network to produce feature\ndistributions yielding high inter-class separation. The mean values of the\ndistributions are centered on the vertices of a simplex such that each class is\nat the same distance from every other class. We show that the regularization of\nthe latent space based on our approach yields excellent classification accuracy\nand inherently provides robustness to multiple adversarial attacks, both\ntargeted and untargeted, outperforming state-of-the-art approaches over\nchallenging datasets.", "published": "2020-10-29T11:15:17Z", "version": 1}, {"aid": "2011.06496", "authors": ["Roshan Reddy Yedla", "Shiv Ram Dubey"], "title": "On the Performance of Convolutional Neural Networks under High and Low Frequency Information", "url": "http://arxiv.org/pdf/2011.06496v1", "summary": "Convolutional neural networks (CNNs) have shown very promising performance in\nrecent years for different problems, including object recognition, face\nrecognition, medical image analysis, etc. However, generally the trained CNN\nmodels are tested over the test set which is very similar to the trained set.\nThe generalizability and robustness of the CNN models are very important\naspects to make it to work for the unseen data. In this letter, we study the\nperformance of CNN models over the high and low frequency information of the\nimages. We observe that the trained CNN fails to generalize over the high and\nlow frequency images. In order to make the CNN robust against high and low\nfrequency images, we propose the stochastic filtering based data augmentation\nduring training. A satisfactory performance improvement has been observed in\nterms of the high and low frequency generalization and robustness with the\nproposed stochastic filtering based data augmentation approach. The\nexperimentations are performed using ResNet50 model over the CIFAR-10 dataset\nand ResNet101 model over Tiny-ImageNet dataset.", "published": "2020-10-30T17:54:45Z", "version": 1}, {"aid": "2011.00071", "authors": ["Arissa Wongpanich", "Hieu Pham", "James Demmel", "Mingxing Tan", "Quoc Le", "Yang You", "Sameer Kumar"], "title": "Training EfficientNets at Supercomputer Scale: 83% ImageNet Top-1 Accuracy in One Hour", "url": "http://arxiv.org/pdf/2011.00071v2", "summary": "EfficientNets are a family of state-of-the-art image classification models\nbased on efficiently scaled convolutional neural networks. Currently,\nEfficientNets can take on the order of days to train; for example, training an\nEfficientNet-B0 model takes 23 hours on a Cloud TPU v2-8 node. In this paper,\nwe explore techniques to scale up the training of EfficientNets on TPU-v3 Pods\nwith 2048 cores, motivated by speedups that can be achieved when training at\nsuch scales. We discuss optimizations required to scale training to a batch\nsize of 65536 on 1024 TPU-v3 cores, such as selecting large batch optimizers\nand learning rate schedules as well as utilizing distributed evaluation and\nbatch normalization techniques. Additionally, we present timing and performance\nbenchmarks for EfficientNet models trained on the ImageNet dataset in order to\nanalyze the behavior of EfficientNets at scale. With our optimizations, we are\nable to train EfficientNet on ImageNet to an accuracy of 83% in 1 hour and 4\nminutes.", "published": "2020-10-30T19:27:11Z", "version": 2}, {"aid": "2011.02785", "authors": ["Dingyi Zhang", "Yingming Li", "Zhongfei Zhang"], "title": "Deep Metric Learning with Spherical Embedding", "url": "http://arxiv.org/pdf/2011.02785v1", "summary": "Deep metric learning has attracted much attention in recent years, due to\nseamlessly combining the distance metric learning and deep neural network. Many\nendeavors are devoted to design different pair-based angular loss functions,\nwhich decouple the magnitude and direction information for embedding vectors\nand ensure the training and testing measure consistency. However, these\ntraditional angular losses cannot guarantee that all the sample embeddings are\non the surface of the same hypersphere during the training stage, which would\nresult in unstable gradient in batch optimization and may influence the quick\nconvergence of the embedding learning. In this paper, we first investigate the\neffect of the embedding norm for deep metric learning with angular distance,\nand then propose a spherical embedding constraint (SEC) to regularize the\ndistribution of the norms. SEC adaptively adjusts the embeddings to fall on the\nsame hypersphere and performs more balanced direction update. Extensive\nexperiments on deep metric learning, face recognition, and contrastive\nself-supervised learning show that the SEC-based angular space learning\nstrategy significantly improves the performance of the state-of-the-art.", "published": "2020-11-05T12:32:12Z", "version": 1}, {"aid": "2011.02803", "authors": ["Ting Chen", "Calvin Luo", "Lala Li"], "title": "Intriguing Properties of Contrastive Losses", "url": "http://arxiv.org/pdf/2011.02803v3", "summary": "We study three intriguing properties of contrastive learning. First, we\ngeneralize the standard contrastive loss to a broader family of losses, and we\nfind that various instantiations of the generalized loss perform similarly\nunder the presence of a multi-layer non-linear projection head. Second, we\nstudy if instance-based contrastive learning (with a global image\nrepresentation) can learn well on images with multiple objects present. We find\nthat meaningful hierarchical local features can be learned despite the fact\nthat these objectives operate on global instance-level features. Finally, we\nstudy the phenomenon of feature suppression among competing features shared\nacross augmented views, such as \"color distribution\" vs \"object class\". We\nconstruct datasets with explicit and controllable competing features, and show\nthat, for contrastive learning, a few bits of easy-to-learn shared features can\nsuppress, and even fully prevent, the learning of other sets of competing\nfeatures. In scenarios where there are multiple objects in an image, the\ndominant object would suppress the learning of smaller objects. Existing\ncontrastive learning methods critically rely on data augmentation to favor\ncertain sets of features over others, and could suffer from learning saturation\nfor scenarios where existing augmentations cannot fully address the feature\nsuppression. This poses open challenges to existing contrastive learning\ntechniques.", "published": "2020-11-05T13:19:48Z", "version": 3}, {"aid": "2011.02956", "authors": ["David Peer", "Sebastian Stabinger", "Antonio Rodriguez-Sanchez"], "title": "Conflicting Bundles: Adapting Architectures Towards the Improved Training of Deep Neural Networks", "url": "http://arxiv.org/pdf/2011.02956v1", "summary": "Designing neural network architectures is a challenging task and knowing\nwhich specific layers of a model must be adapted to improve the performance is\nalmost a mystery. In this paper, we introduce a novel theory and metric to\nidentify layers that decrease the test accuracy of the trained models, this\nidentification is done as early as at the beginning of training. In the\nworst-case, such a layer could lead to a network that can not be trained at\nall. More precisely, we identified those layers that worsen the performance\nbecause they produce conflicting training bundles as we show in our novel\ntheoretical analysis, complemented by our extensive empirical studies. Based on\nthese findings, a novel algorithm is introduced to remove performance\ndecreasing layers automatically. Architectures found by this algorithm achieve\na competitive accuracy when compared against the state-of-the-art\narchitectures. While keeping such high accuracy, our approach drastically\nreduces memory consumption and inference time for different computer vision\ntasks.", "published": "2020-11-05T16:41:04Z", "version": 1}, {"aid": "2011.04441", "authors": ["Luka Ribar", "Rodolphe Sepulchre"], "title": "Neuromorphic Control", "url": "http://arxiv.org/pdf/2011.04441v2", "summary": "Neuromorphic engineering is a rapidly developing field that aims to take\ninspiration from the biological organization of neural systems to develop novel\ntechnology for computing, sensing, and actuating. The unique properties of such\nsystems call for new signal processing and control paradigms. The article\nintroduces the mixed feedback organization of excitable neuronal systems,\nconsisting of interlocked positive and negative feedback loops acting in\ndistinct timescales. The principles of biological neuromodulation suggest a\nmethodology for designing and controlling mixed-feedback systems\nneuromorphically. The proposed design consists of a parallel interconnection of\nelementary circuit elements that mirrors the organization of biological neurons\nand utilizes the hardware components of neuromorphic electronic circuits. The\ninterconnection structure endows the neuromorphic systems with a simple control\nmethodology that reframes the neuronal control as an input-output shaping\nproblem. The potential of neuronal control is illustrated on elementary network\nexamples that suggest the scalability of the mixed-feedback principles.", "published": "2020-11-09T14:06:06Z", "version": 2}, {"aid": "2011.06427", "authors": ["S. Rahimi Kari"], "title": "Realization of Stochastic Neural Networks and Its Potential Applications", "url": "http://arxiv.org/pdf/2011.06427v1", "summary": "Successive Cancellation Decoders have come a long way since the\nimplementation of traditional SC decoders, but there still is a potential for\nimprovement. The main struggle over the years was to find an optimal algorithm\nto implement them. Most of the proposed algorithms are not practical enough to\nbe implemented in real-life. In this research, we aim to introduce the\nEfficiency of stochastic neural networks as an SC decoder and Find the possible\nways of improving its performance and practicality. In this paper, after a\nbrief introduction to stochastic neurons and SNNs, we introduce methods to\nrealize Stochastic NNs on both deterministic and stochastic platforms.", "published": "2020-11-12T15:01:07Z", "version": 1}, {"aid": "2012.00695", "authors": ["W. A. Jacak", "J. E. Jacak"], "title": "The topological non-local braid-group concept of information processing in brain, the different role of the gray and white matter", "url": "http://arxiv.org/pdf/2012.00695v1", "summary": "The velocity of the action potential transduction along myelinated axons in\nthe peripheral nervous system or in the white matter of brain and spinal cord\nreaches hundreds of meters per second to assure proper functioning of the body,\nwhich exceeds the ability of diffusive ion conduction. We propose the new model\nof the saltatory conduction based on a plasmon-polariton kinetics in myelinated\naxons, which excludes, however, the white matter form the information storage\nand its identification in the brain via e-m response. We propose a nonlocal\ntopological approach to information processing in the cortex of brain in\nconsistence with the ion electricity of the gray matter and a supplementary\nonly communication role of the white matter.", "published": "2020-11-16T07:47:09Z", "version": 1}, {"aid": "2011.10566", "authors": ["Xinlei Chen", "Kaiming He"], "title": "Exploring Simple Siamese Representation Learning", "url": "http://arxiv.org/pdf/2011.10566v1", "summary": "Siamese networks have become a common structure in various recent models for\nunsupervised visual representation learning. These models maximize the\nsimilarity between two augmentations of one image, subject to certain\nconditions for avoiding collapsing solutions. In this paper, we report\nsurprising empirical results that simple Siamese networks can learn meaningful\nrepresentations even using none of the following: (i) negative sample pairs,\n(ii) large batches, (iii) momentum encoders. Our experiments show that\ncollapsing solutions do exist for the loss and structure, but a stop-gradient\noperation plays an essential role in preventing collapsing. We provide a\nhypothesis on the implication of stop-gradient, and further show\nproof-of-concept experiments verifying it. Our \"SimSiam\" method achieves\ncompetitive results on ImageNet and downstream tasks. We hope this simple\nbaseline will motivate people to rethink the roles of Siamese architectures for\nunsupervised representation learning. Code will be made available.", "published": "2020-11-20T18:59:33Z", "version": 1}, {"aid": "2011.11128", "authors": ["Shu Gong", "Kaibo Xing", "Andrzej Cichocki", "Junhua Li"], "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period", "url": "http://arxiv.org/pdf/2011.11128v3", "summary": "Deep learning has achieved excellent performance in a wide range of domains,\nespecially in speech recognition and computer vision. Relatively less work has\nbeen done for EEG, but there is still significant progress attained in the last\ndecade. Due to the lack of a comprehensive and topic widely covered survey for\ndeep learning in EEG, we attempt to summarize recent progress to provide an\noverview, as well as perspectives for future developments. We first briefly\nmention the artifacts removal for EEG signal and then introduce deep learning\nmodels that have been utilized in EEG processing and classification.\nSubsequently, the applications of deep learning in EEG are reviewed by\ncategorizing them into groups such as brain-computer interface, disease\ndetection, and emotion recognition. They are followed by the discussion, in\nwhich the pros and cons of deep learning are presented and future directions\nand challenges for deep learning in EEG are proposed. We hope that this paper\ncould serve as a summary of past work for deep learning in EEG and the\nbeginning of further developments and achievements of EEG studies based on deep\nlearning.", "published": "2020-11-22T22:34:26Z", "version": 3}, {"aid": "2012.00675", "authors": ["Tananun Songdechakraiwut", "Moo K. Chung"], "title": "Topological Learning for Brain Networks", "url": "http://arxiv.org/pdf/2012.00675v5", "summary": "This paper proposes a novel topological learning framework that integrates\nnetworks of different sizes and topology through persistent homology. Such\nchallenging task is made possible through the introduction of a computationally\nefficient topological loss. The use of the proposed loss bypasses the intrinsic\ncomputational bottleneck associated with matching networks. We validate the\nmethod in extensive statistical simulations to assess its effectiveness when\ndiscriminating networks with different topology. The method is further\ndemonstrated in a twin brain imaging study where we determine if brain networks\nare genetically heritable. The challenge here is due to the difficulty of\noverlaying the topologically different functional brain networks obtained from\nresting-state functional MRI onto the template structural brain network\nobtained through diffusion MRI.", "published": "2020-11-25T18:46:36Z", "version": 5}, {"aid": "2011.13456", "authors": ["Yang Song", "Jascha Sohl-Dickstein", "Diederik P. Kingma", "Abhishek Kumar", "Stefano Ermon", "Ben Poole"], "title": "Score-Based Generative Modeling through Stochastic Differential Equations", "url": "http://arxiv.org/pdf/2011.13456v2", "summary": "Creating noise from data is easy; creating data from noise is generative\nmodeling. We present a stochastic differential equation (SDE) that smoothly\ntransforms a complex data distribution to a known prior distribution by slowly\ninjecting noise, and a corresponding reverse-time SDE that transforms the prior\ndistribution back into the data distribution by slowly removing the noise.\nCrucially, the reverse-time SDE depends only on the time-dependent gradient\nfield (\\aka, score) of the perturbed data distribution. By leveraging advances\nin score-based generative modeling, we can accurately estimate these scores\nwith neural networks, and use numerical SDE solvers to generate samples. We\nshow that this framework encapsulates previous approaches in score-based\ngenerative modeling and diffusion probabilistic modeling, allowing for new\nsampling procedures and new modeling capabilities. In particular, we introduce\na predictor-corrector framework to correct errors in the evolution of the\ndiscretized reverse-time SDE. We also derive an equivalent neural ODE that\nsamples from the same distribution as the SDE, but additionally enables exact\nlikelihood computation, and improved sampling efficiency. In addition, we\nprovide a new way to solve inverse problems with score-based models, as\ndemonstrated with experiments on class-conditional generation, image\ninpainting, and colorization. Combined with multiple architectural\nimprovements, we achieve record-breaking performance for unconditional image\ngeneration on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a\ncompetitive likelihood of 2.99 bits/dim, and demonstrate high fidelity\ngeneration of 1024 x 1024 images for the first time from a score-based\ngenerative model.", "published": "2020-11-26T19:39:10Z", "version": 2}, {"aid": "2011.14285", "authors": ["Haoxi Ran", "Li Lu"], "title": "Deeper or Wider Networks of Point Clouds with Self-attention?", "url": "http://arxiv.org/pdf/2011.14285v2", "summary": "Prevalence of deeper networks driven by self-attention is in stark contrast\nto underexplored point-based methods. In this paper, we propose groupwise\nself-attention as the basic block to construct our network: SepNet. Our\nproposed module can effectively capture both local and global dependencies.\nThis module computes the features of a group based on the summation of the\nweighted features of any point within the group. For convenience, we generalize\ngroupwise operations to assemble this module. To further facilitate our\nnetworks, we deepen and widen SepNet on the tasks of segmentation and\nclassification respectively, and verify its practicality. Specifically, SepNet\nachieves state-of-the-art for the tasks of classification and segmentation on\nmost of the datasets. We show empirical evidence that SepNet can obtain extra\naccuracy in classification or segmentation from increased width or depth,\nrespectively.", "published": "2020-11-29T05:03:06Z", "version": 2}, {"aid": "2012.00868", "authors": ["Srikar Appalaraju", "Yi Zhu", "Yusheng Xie", "Istv\u00e1n Feh\u00e9rv\u00e1ri"], "title": "Towards Good Practices in Self-supervised Representation Learning", "url": "http://arxiv.org/pdf/2012.00868v1", "summary": "Self-supervised representation learning has seen remarkable progress in the\nlast few years. More recently, contrastive instance learning has shown\nimpressive results compared to its supervised learning counterparts. However,\neven with the ever increased interest in contrastive instance learning, it is\nstill largely unclear why these methods work so well. In this paper, we aim to\nunravel some of the mysteries behind their success, which are the good\npractices. Through an extensive empirical analysis, we hope to not only provide\ninsights but also lay out a set of best practices that led to the success of\nrecent work in self-supervised representation learning.", "published": "2020-12-01T22:13:43Z", "version": 1}, {"aid": "2012.01064", "authors": ["Ibrahim Merad", "Yiyang Yu", "Emmanuel Bacry", "St\u00e9phane Ga\u00efffas"], "title": "About contrastive unsupervised representation learning for classification and its convergence", "url": "http://arxiv.org/pdf/2012.01064v1", "summary": "Contrastive representation learning has been recently proved to be very\nefficient for self-supervised training. These methods have been successfully\nused to train encoders which perform comparably to supervised training on\ndownstream classification tasks. A few works have started to build a\ntheoretical framework around contrastive learning in which guarantees for its\nperformance can be proven. We provide extensions of these results to training\nwith multiple negative samples and for multiway classification. Furthermore, we\nprovide convergence guarantees for the minimization of the contrastive training\nerror with gradient descent of an overparametrized deep neural encoder, and\nprovide some numerical experiments that complement our theoretical findings", "published": "2020-12-02T10:08:57Z", "version": 1}, {"aid": "2012.01074", "authors": ["Giulia Cisotto", "Alessio Zanga", "Joanna Chlebus", "Italo Zoppis", "Sara Manzoni", "Urszula Markowska-Kaczmar"], "title": "Comparison of Attention-based Deep Learning Models for EEG Classification", "url": "http://arxiv.org/pdf/2012.01074v1", "summary": "Objective: To evaluate the impact on Electroencephalography (EEG)\nclassification of different kinds of attention mechanisms in Deep Learning (DL)\nmodels. Methods: We compared three attention-enhanced DL models, the brand-new\nInstaGATs, an LSTM with attention and a CNN with attention. We used these\nmodels to classify normal and abnormal (i.e., artifactual or pathological) EEG\npatterns. Results: We achieved the state of the art in all classification\nproblems, regardless the large variability of the datasets and the simple\narchitecture of the attention-enhanced models. We could also prove that,\ndepending on how the attention mechanism is applied and where the attention\nlayer is located in the model, we can alternatively leverage the information\ncontained in the time, frequency or space domain of the dataset. Conclusions:\nwith this work, we shed light over the role of different attention mechanisms\nin the classification of normal and abnormal EEG patterns. Moreover, we\ndiscussed how they can exploit the intrinsic relationships in the temporal,\nfrequency and spatial domains of our brain activity. Significance: Attention\nrepresents a promising strategy to evaluate the quality of the EEG information,\nand its relevance, in different real-world scenarios. Moreover, it can make it\neasier to parallelize the computation and, thus, to speed up the analysis of\nbig electrophysiological (e.g., EEG) datasets.", "published": "2020-12-02T10:43:41Z", "version": 1}, {"aid": "2012.06951", "authors": ["Qi Qi", "Yi Xu", "Rong Jin", "Wotao Yin", "Tianbao Yang"], "title": "Attentional-Biased Stochastic Gradient Descent", "url": "http://arxiv.org/pdf/2012.06951v5", "summary": "In this paper, we present a simple yet effective provable method (named\nABSGD) for addressing the data imbalance or label noise problem in deep\nlearning. Our method is a simple modification to momentum SGD where we assign\nan individual importance weight to each sample in the mini-batch. The\nindividual-level weight of sampled data is systematically proportional to the\nexponential of a scaled loss value of the data, where the scaling factor is\ninterpreted as the regularization parameter in the framework of\ndistributionally robust optimization (DRO). Depending on whether the scaling\nfactor is positive or negative, ABSGD is guaranteed to converge to a stationary\npoint of an information-regularized min-max or min-min DRO problem,\nrespectively. Compared with existing class-level weighting schemes, our method\ncan capture the diversity between individual examples within each class.\nCompared with existing individual-level weighting methods using meta-learning\nthat require three backward propagations for computing mini-batch stochastic\ngradients, our method is more efficient with only one backward propagation at\neach iteration as in standard deep learning methods. ABSGD is flexible enough\nto combine with other robust losses without any additional cost. Our empirical\nstudies on several benchmark datasets demonstrate the effectiveness of the\nproposed method.\\footnote{Code is available\nat:\\url{https://github.com/qiqi-helloworld/ABSGD/}}", "published": "2020-12-13T03:41:52Z", "version": 5}, {"aid": "2012.07297", "authors": ["Jian Liang", "Dapeng Hu", "Yunbo Wang", "Ran He", "Jiashi Feng"], "title": "Source Data-absent Unsupervised Domain Adaptation through Hypothesis Transfer and Labeling Transfer", "url": "http://arxiv.org/pdf/2012.07297v3", "summary": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a\nrelated but different well-labeled source domain to a new unlabeled target\ndomain. Most existing UDA methods require access to the source data, and thus\nare not applicable when the data are confidential and not shareable due to\nprivacy concerns. This paper aims to tackle a realistic setting with only a\nclassification model available trained over, instead of accessing to, the\nsource data. To effectively utilize the source model for adaptation, we propose\na novel approach called Source HypOthesis Transfer (SHOT), which learns the\nfeature extraction module for the target domain by fitting the target data\nfeatures to the frozen source classification module (representing\nclassification hypothesis). Specifically, SHOT exploits both information\nmaximization and self-supervised learning for the feature extraction module\nlearning to ensure the target features are implicitly aligned with the features\nof unseen source data via the same hypothesis. Furthermore, we propose a new\nlabeling transfer strategy, which separates the target data into two splits\nbased on the confidence of predictions (labeling information), and then employ\nsemi-supervised learning to improve the accuracy of less-confident predictions\nin the target domain. We denote labeling transfer as SHOT++ if the predictions\nare obtained by SHOT. Extensive experiments on both digit classification and\nobject recognition tasks show that SHOT and SHOT++ achieve results surpassing\nor comparable to the state-of-the-arts, demonstrating the effectiveness of our\napproaches for various visual domain adaptation problems. Code is available at\n\\url{https://github.com/tim-learn/SHOT-plus}.", "published": "2020-12-14T07:28:50Z", "version": 3}, {"aid": "2012.07810", "authors": ["Shanchuan Lin", "Andrey Ryabtsev", "Soumyadip Sengupta", "Brian Curless", "Steve Seitz", "Ira Kemelmacher-Shlizerman"], "title": "Real-Time High-Resolution Background Matting", "url": "http://arxiv.org/pdf/2012.07810v1", "summary": "We introduce a real-time, high-resolution background replacement technique\nwhich operates at 30fps in 4K resolution, and 60fps for HD on a modern GPU. Our\ntechnique is based on background matting, where an additional frame of the\nbackground is captured and used in recovering the alpha matte and the\nforeground layer. The main challenge is to compute a high-quality alpha matte,\npreserving strand-level hair details, while processing high-resolution images\nin real-time. To achieve this goal, we employ two neural networks; a base\nnetwork computes a low-resolution result which is refined by a second network\noperating at high-resolution on selective patches. We introduce two largescale\nvideo and image matting datasets: VideoMatte240K and PhotoMatte13K/85. Our\napproach yields higher quality results compared to the previous\nstate-of-the-art in background matting, while simultaneously yielding a\ndramatic boost in both speed and resolution.", "published": "2020-12-14T18:43:32Z", "version": 1}, {"aid": "2012.12351", "authors": ["Erfan Nozari", "Maxwell A. Bertolero", "Jennifer Stiso", "Lorenzo Caciagli", "Eli J. Cornblath", "Xiaosong He", "Arun S. Mahadevan", "George J. Pappas", "Dani Smith Bassett"], "title": "Is the brain macroscopically linear? A system identification of resting state dynamics", "url": "http://arxiv.org/pdf/2012.12351v2", "summary": "A central challenge in the computational modeling of neural dynamics is the\ntrade-off between accuracy and simplicity. At the level of individual neurons,\nnonlinear dynamics are both experimentally established and essential for\nneuronal functioning. An implicit assumption has thus formed that an accurate\ncomputational model of whole-brain dynamics must also be highly nonlinear,\nwhereas linear models may provide a first-order approximation. Here, we provide\na rigorous and data-driven investigation of this hypothesis at the level of\nwhole-brain blood-oxygen-level-dependent (BOLD) and macroscopic field potential\ndynamics by leveraging the theory of system identification. Using functional\nMRI (fMRI) and intracranial EEG (iEEG), we model the resting state activity of\n700 subjects in the Human Connectome Project (HCP) and 122 subjects from the\nRestoring Active Memory (RAM) project using state-of-the-art linear and\nnonlinear model families. We assess relative model fit using predictive power,\ncomputational complexity, and the extent of residual dynamics unexplained by\nthe model. Contrary to our expectations, linear auto-regressive models achieve\nthe best measures across all three metrics, eliminating the trade-off between\naccuracy and simplicity. To understand and explain this linearity, we highlight\nfour properties of macroscopic neurodynamics which can counteract or mask\nmicroscopic nonlinear dynamics: averaging over space, averaging over time,\nobservation noise, and limited data samples. Whereas the latter two are\ntechnological limitations and can improve in the future, the former two are\ninherent to aggregated macroscopic brain activity. Our results, together with\nthe unparalleled interpretability of linear models, can greatly facilitate our\nunderstanding of macroscopic neural dynamics and the principled design of\nmodel-based interventions for the treatment of neuropsychiatric disorders.", "published": "2020-12-22T20:51:42Z", "version": 2}, {"aid": "2012.12899", "authors": ["Ramtin Hosseini", "Pengtao Xie"], "title": "Learning by Self-Explanation, with Application to Neural Architecture Search", "url": "http://arxiv.org/pdf/2012.12899v2", "summary": "Learning by self-explanation is an effective learning technique in human\nlearning, where students explain a learned topic to themselves for deepening\ntheir understanding of this topic. It is interesting to investigate whether\nthis explanation-driven learning methodology broadly used by humans is helpful\nfor improving machine learning as well. Based on this inspiration, we propose a\nnovel machine learning method called learning by self-explanation (LeaSE). In\nour approach, an explainer model improves its learning ability by trying to\nclearly explain to an audience model regarding how a prediction outcome is\nmade. LeaSE is formulated as a four-level optimization problem involving a\nsequence of four learning stages which are conducted end-to-end in a unified\nframework: 1) explainer learns; 2) explainer explains; 3) audience learns; 4)\nexplainer re-learns based on the performance of the audience. We develop an\nefficient algorithm to solve the LeaSE problem. We apply LeaSE for neural\narchitecture search on CIFAR-100, CIFAR-10, and ImageNet. Experimental results\nstrongly demonstrate the effectiveness of our method.", "published": "2020-12-23T07:39:54Z", "version": 2}, {"aid": "2012.12556", "authors": ["Kai Han", "Yunhe Wang", "Hanting Chen", "Xinghao Chen", "Jianyuan Guo", "Zhenhua Liu", "Yehui Tang", "An Xiao", "Chunjing Xu", "Yixing Xu", "Zhaohui Yang", "Yiman Zhang", "Dacheng Tao"], "title": "A Survey on Visual Transformer", "url": "http://arxiv.org/pdf/2012.12556v6", "summary": "Transformer, first applied to the field of natural language processing, is a\ntype of deep neural network mainly based on the self-attention mechanism.\nThanks to its strong representation capabilities, researchers are looking at\nways to apply transformer to computer vision tasks. In a variety of visual\nbenchmarks, transformer-based models perform similar to or better than other\ntypes of networks such as convolutional and recurrent neural networks. Given\nits high performance and less need for vision-specific inductive bias,\ntransformer is receiving more and more attention from the computer vision\ncommunity. In this paper, we review these vision transformer models by\ncategorizing them in different tasks and analyzing their advantages and\ndisadvantages. The main categories we explore include the backbone network,\nhigh/mid-level vision, low-level vision, and video processing. We also include\nefficient transformer methods for pushing transformer into real device-based\napplications. Furthermore, we also take a brief look at the self-attention\nmechanism in computer vision, as it is the base component in transformer.\nToward the end of this paper, we discuss the challenges and provide several\nfurther research directions for vision transformers.", "published": "2020-12-23T09:37:54Z", "version": 6}, {"aid": "2012.13322", "authors": ["Yangyang Qu", "Chao liu", "Yongsheng Ou"], "title": "LEUGAN:Low-Light Image Enhancement by Unsupervised Generative Attentional Networks", "url": "http://arxiv.org/pdf/2012.13322v1", "summary": "Restoring images from low-light data is a challenging problem. Most existing\ndeep-network based algorithms are designed to be trained with pairwise images.\nDue to the lack of real-world datasets, they usually perform poorly when\ngeneralized in practice in terms of loss of image edge and color information.\nIn this paper, we propose an unsupervised generation network with\nattention-guidance to handle the low-light image enhancement task.\nSpecifically, our network contains two parts: an edge auxiliary module that\nrestores sharper edges and an attention guidance module that recovers more\nrealistic colors. Moreover, we propose a novel loss function to make the edges\nof the generated images more visible. Experiments validate that our proposed\nalgorithm performs favorably against state-of-the-art methods, especially for\nreal-world images in terms of image clarity and noise control.", "published": "2020-12-24T16:49:19Z", "version": 1}, {"aid": "2012.15020", "authors": ["Zhangkai Ni", "Wenhan Yang", "Shiqi Wang", "Lin Ma", "Sam Kwong"], "title": "Towards Unsupervised Deep Image Enhancement with Generative Adversarial Network", "url": "http://arxiv.org/pdf/2012.15020v1", "summary": "Improving the aesthetic quality of images is challenging and eager for the\npublic. To address this problem, most existing algorithms are based on\nsupervised learning methods to learn an automatic photo enhancer for paired\ndata, which consists of low-quality photos and corresponding expert-retouched\nversions. However, the style and characteristics of photos retouched by experts\nmay not meet the needs or preferences of general users. In this paper, we\npresent an unsupervised image enhancement generative adversarial network\n(UEGAN), which learns the corresponding image-to-image mapping from a set of\nimages with desired characteristics in an unsupervised manner, rather than\nlearning on a large number of paired images. The proposed model is based on\nsingle deep GAN which embeds the modulation and attention mechanisms to capture\nricher global and local features. Based on the proposed model, we introduce two\nlosses to deal with the unsupervised image enhancement: (1) fidelity loss,\nwhich is defined as a L2 regularization in the feature domain of a pre-trained\nVGG network to ensure the content between the enhanced image and the input\nimage is the same, and (2) quality loss that is formulated as a relativistic\nhinge adversarial loss to endow the input image the desired characteristics.\nBoth quantitative and qualitative results show that the proposed model\neffectively improves the aesthetic quality of images. Our code is available at:\nhttps://github.com/eezkni/UEGAN.", "published": "2020-12-30T03:22:46Z", "version": 1}, {"aid": "2101.01011", "authors": ["Christian P. Robert", "Gareth O. Roberts"], "title": "Rao-Blackwellization in the MCMC era", "url": "http://arxiv.org/pdf/2101.01011v1", "summary": "Rao-Blackwellization is a notion often occurring in the MCMC literature, with\npossibly different meanings and connections with the original Rao--Blackwell\ntheorem (Rao, 1945 and Blackwell,1947), including a reduction of the variance\nof the resulting Monte Carlo approximations. This survey reviews some of the\nmeanings of the term.", "published": "2021-01-04T14:44:36Z", "version": 1}, {"aid": "2101.02824", "authors": ["Tao Huang", "Songjiang Li", "Xu Jia", "Huchuan Lu", "Jianzhuang Liu"], "title": "Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images", "url": "http://arxiv.org/pdf/2101.02824v3", "summary": "In the last few years, image denoising has benefited a lot from the fast\ndevelopment of neural networks. However, the requirement of large amounts of\nnoisy-clean image pairs for supervision limits the wide use of these models.\nAlthough there have been a few attempts in training an image denoising model\nwith only single noisy images, existing self-supervised denoising approaches\nsuffer from inefficient network training, loss of useful information, or\ndependence on noise modeling. In this paper, we present a very simple yet\neffective method named Neighbor2Neighbor to train an effective image denoising\nmodel with only noisy images. Firstly, a random neighbor sub-sampler is\nproposed for the generation of training image pairs. In detail, input and\ntarget used to train a network are images sub-sampled from the same noisy\nimage, satisfying the requirement that paired pixels of paired images are\nneighbors and have very similar appearance with each other. Secondly, a\ndenoising network is trained on sub-sampled training pairs generated in the\nfirst stage, with a proposed regularizer as additional loss for better\nperformance. The proposed Neighbor2Neighbor framework is able to enjoy the\nprogress of state-of-the-art supervised denoising networks in network\narchitecture design. Moreover, it avoids heavy dependence on the assumption of\nthe noise distribution. We explain our approach from a theoretical perspective\nand further validate it through extensive experiments, including synthetic\nexperiments with different noise distributions in sRGB space and real-world\nexperiments on a denoising benchmark dataset in raw-RGB space.", "published": "2021-01-08T02:03:25Z", "version": 3}, {"aid": "2101.05278", "authors": ["Weihao Xia", "Yulun Zhang", "Yujiu Yang", "Jing-Hao Xue", "Bolei Zhou", "Ming-Hsuan Yang"], "title": "GAN Inversion: A Survey", "url": "http://arxiv.org/pdf/2101.05278v5", "summary": "GAN inversion aims to invert a given image back into the latent space of a\npretrained GAN model, for the image to be faithfully reconstructed from the\ninverted code by the generator. As an emerging technique to bridge the real and\nfake image domains, GAN inversion plays an essential role in enabling the\npretrained GAN models such as StyleGAN and BigGAN to be used for real image\nediting applications. Meanwhile, GAN inversion also provides insights on the\ninterpretation of GAN's latent space and how the realistic images can be\ngenerated. In this paper, we provide an overview of GAN inversion with a focus\non its recent algorithms and applications. We cover important techniques of GAN\ninversion and their applications to image restoration and image manipulation.\nWe further elaborate on some trends and challenges for future directions.", "published": "2021-01-14T14:11:00Z", "version": 5}, {"aid": "2101.10953", "authors": ["Wei Zhong Goh", "Varun Ursekar", "Marc W. Howard"], "title": "Predicting the future with a scale-invariant temporal memory for the past", "url": "http://arxiv.org/pdf/2101.10953v3", "summary": "In recent years it has become clear that the brain maintains a temporal\nmemory of recent events stretching far into the past. This paper presents a\nneurally-inspired algorithm to use a scale-invariant temporal representation of\nthe past to predict a scale-invariant future. The result is a scale-invariant\nestimate of future events as a function of the time at which they are expected\nto occur. The algorithm is time-local, with credit assigned to the present\nevent by observing how it affects the prediction of the future. To illustrate\nthe potential utility of this approach, we test the model on simultaneous\nrenewal processes with different time scales. The algorithm scales well on\nthese problems despite the fact that the number of states needed to describe\nthem as a Markov process grows exponentially.", "published": "2021-01-26T17:22:17Z", "version": 3}, {"aid": "2101.11075", "authors": ["Aaron Defazio", "Samy Jelassi"], "title": "Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic Optimization", "url": "http://arxiv.org/pdf/2101.11075v3", "summary": "We introduce MADGRAD, a novel optimization method in the family of AdaGrad\nadaptive gradient methods. MADGRAD shows excellent performance on deep learning\noptimization problems from multiple fields, including classification and\nimage-to-image tasks in vision, and recurrent and bidirectionally-masked models\nin natural language processing. For each of these tasks, MADGRAD matches or\noutperforms both SGD and ADAM in test set performance, even on problems for\nwhich adaptive methods normally perform poorly.", "published": "2021-01-26T20:38:26Z", "version": 3}, {"aid": "2101.11605", "authors": ["Aravind Srinivas", "Tsung-Yi Lin", "Niki Parmar", "Jonathon Shlens", "Pieter Abbeel", "Ashish Vaswani"], "title": "Bottleneck Transformers for Visual Recognition", "url": "http://arxiv.org/pdf/2101.11605v2", "summary": "We present BoTNet, a conceptually simple yet powerful backbone architecture\nthat incorporates self-attention for multiple computer vision tasks including\nimage classification, object detection and instance segmentation. By just\nreplacing the spatial convolutions with global self-attention in the final\nthree bottleneck blocks of a ResNet and no other changes, our approach improves\nupon the baselines significantly on instance segmentation and object detection\nwhile also reducing the parameters, with minimal overhead in latency. Through\nthe design of BoTNet, we also point out how ResNet bottleneck blocks with\nself-attention can be viewed as Transformer blocks. Without any bells and\nwhistles, BoTNet achieves 44.4% Mask AP and 49.7% Box AP on the COCO Instance\nSegmentation benchmark using the Mask R-CNN framework; surpassing the previous\nbest published single model and single scale results of ResNeSt evaluated on\nthe COCO validation set. Finally, we present a simple adaptation of the BoTNet\ndesign for image classification, resulting in models that achieve a strong\nperformance of 84.7% top-1 accuracy on the ImageNet benchmark while being up to\n1.64x faster in compute time than the popular EfficientNet models on TPU-v3\nhardware. We hope our simple and effective approach will serve as a strong\nbaseline for future research in self-attention models for vision", "published": "2021-01-27T18:55:27Z", "version": 2}, {"aid": "2102.00160", "authors": ["S. H. Shabbeer Basha", "Mohammad Farazuddin", "Viswanath Pulabaigari", "Shiv Ram Dubey", "Snehasis Mukherjee"], "title": "Deep Model Compression based on the Training History", "url": "http://arxiv.org/pdf/2102.00160v2", "summary": "Deep Convolutional Neural Networks (DCNNs) have shown promising performances\nin several visual recognition problems which motivated the researchers to\npropose popular architectures such as LeNet, AlexNet, VGGNet, ResNet, and many\nmore. These architectures come at a cost of high computational complexity and\nparameter storage. To get rid of storage and computational complexity, deep\nmodel compression methods have been evolved. We propose a \"History Based Filter\nPruning (HBFP)\" method that utilizes network training history for filter\npruning. Specifically, we prune the redundant filters by observing similar\npatterns in the filter's L1-norms (absolute sum of weights) over the training\nepochs. We iteratively prune the redundant filters of a CNN in three steps.\nFirst, we train the model and select the filter pairs with redundant filters in\neach pair. Next, we optimize the network to ensure an increased measure of\nsimilarity between the filters in a pair. This optimization of the network\nfacilitates us to prune one filter from each pair based on its importance\nwithout much information loss. Finally, we retrain the network to regain the\nperformance, which is dropped due to filter pruning. We test our approach on\npopular architectures such as LeNet-5 on MNIST dataset; VGG-16, ResNet-56, and\nResNet-110 on CIFAR-10 dataset, and ResNet-50 on ImageNet. The proposed pruning\nmethod outperforms the state-of-the-art in terms of FLOPs reduction\n(floating-point operations) by 97.98%, 83.42%, 78.43%, 74.95%, and 75.45% for\nLeNet-5, VGG-16, ResNet-56, ResNet-110, and ResNet-50, respectively, while\nmaintaining the less error rate.", "published": "2021-01-30T06:04:21Z", "version": 2}, {"aid": "2102.00719", "authors": ["Daniel Neimark", "Omri Bar", "Maya Zohar", "Dotan Asselmann"], "title": "Video Transformer Network", "url": "http://arxiv.org/pdf/2102.00719v3", "summary": "This paper presents VTN, a transformer-based framework for video recognition.\nInspired by recent developments in vision transformers, we ditch the standard\napproach in video action recognition that relies on 3D ConvNets and introduce a\nmethod that classifies actions by attending to the entire video sequence\ninformation. Our approach is generic and builds on top of any given 2D spatial\nnetwork. In terms of wall runtime, it trains $16.1\\times$ faster and runs\n$5.1\\times$ faster during inference while maintaining competitive accuracy\ncompared to other state-of-the-art methods. It enables whole video analysis,\nvia a single end-to-end pass, while requiring $1.5\\times$ fewer GFLOPs. We\nreport competitive results on Kinetics-400 and present an ablation study of VTN\nproperties and the trade-off between accuracy and inference speed. We hope our\napproach will serve as a new baseline and start a fresh line of research in the\nvideo recognition domain. Code and models are available at:\nhttps://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md", "published": "2021-02-01T09:29:10Z", "version": 3}, {"aid": "2102.02804", "authors": ["Ilke Cugu", "Emre Akbas"], "title": "A Deeper Look into Convolutions via Eigenvalue-based Pruning", "url": "http://arxiv.org/pdf/2102.02804v2", "summary": "Convolutional neural networks (CNNs) are able to attain better visual\nrecognition performance than fully connected neural networks despite having\nmuch fewer parameters due to their parameter sharing principle. Modern\narchitectures usually contain a small number of fully-connected layers, often\nat the end, after multiple layers of convolutions. In some cases, most of the\nconvolutions can be eliminated without suffering any loss in recognition\nperformance. However, there is no solid recipe to detect the hidden subset of\nconvolutional neurons that is responsible for the majority of the recognition\nwork. In this work, we formulate this as a pruning problem where the aim is to\nprune as many kernels as possible while preserving the vanilla generalization\nperformance. To this end, we use the matrix characteristics based on\neigenvalues for pruning, in comparison to the average absolute weight of a\nkernel which is the de facto standard in the literature to assess the\nimportance of an individual convolutional kernel, to shed light on the internal\nmechanisms of a widely used family of CNNs, namely residual neural networks\n(ResNets), for the image classification problem using CIFAR-10, CIFAR-100 and\nTiny ImageNet datasets.", "published": "2021-02-04T18:55:03Z", "version": 2}, {"aid": "2102.02811", "authors": ["Zhiqiang Tang", "Yunhe Gao", "Yi Zhu", "Zhi Zhang", "Mu Li", "Dimitris Metaxas"], "title": "CrossNorm and SelfNorm for Generalization under Distribution Shifts", "url": "http://arxiv.org/pdf/2102.02811v2", "summary": "Traditional normalization techniques (e.g., Batch Normalization and Instance\nNormalization) generally and simplistically assume that training and test data\nfollow the same distribution. As distribution shifts are inevitable in\nreal-world applications, well-trained models with previous normalization\nmethods can perform badly in new environments. Can we develop new normalization\nmethods to improve generalization robustness under distribution shifts? In this\npaper, we answer the question by proposing CrossNorm and SelfNorm. CrossNorm\nexchanges channel-wise mean and variance between feature maps to enlarge\ntraining distribution, while SelfNorm uses attention to recalibrate the\nstatistics to bridge gaps between training and test distributions. CrossNorm\nand SelfNorm can complement each other, though exploring different directions\nin statistics usage. Extensive experiments on different fields (vision and\nlanguage), tasks (classification and segmentation), settings (supervised and\nsemi-supervised), and distribution shift types (synthetic and natural) show the\neffectiveness. Code is available at\nhttps://github.com/amazon-research/crossnorm-selfnorm", "published": "2021-02-04T18:59:20Z", "version": 2}, {"aid": "2102.03814", "authors": ["Phairot Autthasan", "Rattanaphon Chaisaen", "Thapanun Sudhawiyangkul", "Phurin Rangpong", "Suktipol Kiatthaveephong", "Nat Dilokthanakul", "Gun Bhakdisongkhram", "Huy Phan", "Cuntai Guan", "Theerawit Wilaiprasitporn"], "title": "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification", "url": "http://arxiv.org/pdf/2102.03814v4", "summary": "Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)\nallow control of several applications by decoding neurophysiological phenomena,\nwhich are usually recorded by electroencephalography (EEG) using a non-invasive\ntechnique. Despite great advances in MI-based BCI, EEG rhythms are specific to\na subject and various changes over time. These issues point to significant\nchallenges to enhance the classification performance, especially in a\nsubject-independent manner. To overcome these challenges, we propose MIN2Net, a\nnovel end-to-end multi-task learning to tackle this task. We integrate deep\nmetric learning into a multi-task autoencoder to learn a compact and\ndiscriminative latent representation from EEG and perform classification\nsimultaneously. This approach reduces the complexity in pre-processing, results\nin significant performance improvement on EEG classification. Experimental\nresults in a subject-independent manner show that MIN2Net outperforms the\nstate-of-the-art techniques, achieving an F1-score improvement of 6.72%, and\n2.23% on the SMR-BCI, and OpenBMI datasets, respectively. We demonstrate that\nMIN2Net improves discriminative information in the latent representation. This\nstudy indicates the possibility and practicality of using this model to develop\nMI-based BCI applications for new users without the need for calibration.", "published": "2021-02-07T15:20:23Z", "version": 4}, {"aid": "2102.04965", "authors": ["Michal Balazia", "S L Happy", "Francois Bremond", "Antitza Dantcheva"], "title": "How Unique Is a Face: An Investigative Study", "url": "http://arxiv.org/pdf/2102.04965v3", "summary": "Face recognition has been widely accepted as a means of identification in\napplications ranging from border control to security in the banking sector.\nSurprisingly, while widely accepted, we still lack the understanding of\nuniqueness or distinctiveness of faces as biometric modality. In this work, we\nstudy the impact of factors such as image resolution, feature representation,\ndatabase size, age and gender on uniqueness denoted by the Kullback-Leibler\ndivergence between genuine and impostor distributions. Towards understanding\nthe impact, we present experimental results on the datasets AT&T, LFW,\nIMDb-Face, as well as ND-TWINS, with the feature extraction algorithms VGGFace,\nVGG16, ResNet50, InceptionV3, MobileNet and DenseNet121, that reveal the\nquantitative impact of the named factors. While these are early results, our\nfindings indicate the need for a better understanding of the concept of\nbiometric uniqueness and its implication on face recognition.", "published": "2021-02-09T17:35:39Z", "version": 3}, {"aid": "2102.05426", "authors": ["Yuhang Li", "Ruihao Gong", "Xu Tan", "Yang Yang", "Peng Hu", "Qi Zhang", "Fengwei Yu", "Wei Wang", "Shi Gu"], "title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction", "url": "http://arxiv.org/pdf/2102.05426v2", "summary": "We study the challenging task of neural network quantization without\nend-to-end retraining, called Post-training Quantization (PTQ). PTQ usually\nrequires a small subset of training data but produces less powerful quantized\nmodels than Quantization-Aware Training (QAT). In this work, we propose a novel\nPTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to\nINT2 for the first time. BRECQ leverages the basic building blocks in neural\nnetworks and reconstructs them one-by-one. In a comprehensive theoretical study\nof the second-order error, we show that BRECQ achieves a good balance between\ncross-layer dependency and generalization error. To further employ the power of\nquantization, the mixed precision technique is incorporated in our framework by\napproximating the inter-layer and intra-layer sensitivity. Extensive\nexperiments on various handcrafted and searched neural architectures are\nconducted for both image classification and object detection tasks. And for the\nfirst time we prove that, without bells and whistles, PTQ can attain 4-bit\nResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster\nproduction of quantized models. Codes are available at\nhttps://github.com/yhhhli/BRECQ.", "published": "2021-02-10T13:46:16Z", "version": 2}, {"aid": "2102.08663", "authors": ["Yuhta Takida", "Wei-Hsiang Liao", "Chieh-Hsin Lai", "Toshimitsu Uesaka", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "Preventing Oversmoothing in VAE via Generalized Variance Parameterization", "url": "http://arxiv.org/pdf/2102.08663v2", "summary": "Variational autoencoders (VAEs) often suffer from posterior collapse, which\nis a phenomenon in which the learned latent space becomes uninformative. This\nis often related to the hyperparameter resembling the data variance. It can be\nshown that an inappropriate choice of this hyperparameter causes the\noversmoothness in the linearly approximated case and can be empirically\nverified for the general cases. Moreover, determining such appropriate choice\nbecomes infeasible if the data variance is non-uniform or conditional.\nTherefore, we propose VAE extensions with generalized parameterizations of the\ndata variance and incorporate maximum likelihood estimation into the objective\nfunction to adaptively regularize the decoder smoothness. The images generated\nfrom proposed VAE extensions show improved Fr\\'echet inception distance (FID)\non MNIST and CelebA datasets.", "published": "2021-02-17T10:00:49Z", "version": 2}, {"aid": "2102.13519", "authors": ["Stefan Bl\u00fccher", "Johanna Vielhaben", "Nils Strodthoff"], "title": "PredDiff: Explanations and Interactions from Conditional Expectations", "url": "http://arxiv.org/pdf/2102.13519v4", "summary": "PredDiff is a model-agnostic, local attribution method that is firmly rooted\nin probability theory. Its simple intuition is to measure prediction changes\nwhile marginalizing features. In this work, we clarify properties of PredDiff\nand its close connection to Shapley values. We stress important differences\nbetween classification and regression, which require a specific treatment\nwithin both formalisms. We extend PredDiff by introducing a new, well-founded\nmeasure for interaction effects between arbitrary feature subsets. The study of\ninteraction effects represents an inevitable step towards a comprehensive\nunderstanding of black-box models and is particularly important for science\napplications. Equipped with our novel interaction measure, PredDiff is a\npromising model-agnostic approach for obtaining reliable, numerically\ninexpensive and theoretically sound attributions.", "published": "2021-02-26T14:46:47Z", "version": 4}, {"aid": "2103.00944", "authors": ["Dengyu Wu", "Xinping Yi", "Xiaowei Huang"], "title": "A Little Energy Goes a Long Way: Build an Energy-Efficient, Accurate Spiking Neural Network from Convolutional Neural Network", "url": "http://arxiv.org/pdf/2103.00944v3", "summary": "Spiking neural networks (SNNs) offer an inherent ability to process\nspatial-temporal data, or in other words, realworld sensory data, but suffer\nfrom the difficulty of training high accuracy models. A major thread of\nresearch on SNNs is on converting a pre-trained convolutional neural network\n(CNN) to an SNN of the same structure. State-of-the-art conversion methods are\napproaching the accuracy limit, i.e., the near-zero accuracy loss of SNN\nagainst the original CNN. However, we note that this is made possible only when\nsignificantly more energy is consumed to process an input. In this paper, we\nargue that this trend of \"energy for accuracy\" is not necessary -- a little\nenergy can go a long way to achieve the near-zero accuracy loss. Specifically,\nwe propose a novel CNN-to-SNN conversion method that is able to use a\nreasonably short spike train (e.g., 256 timesteps for CIFAR10 images) to\nachieve the near-zero accuracy loss. The new conversion method, named as\nexplicit current control (ECC), contains three techniques (current\nnormalisation, thresholding for residual elimination, and consistency\nmaintenance for batch-normalisation), in order to explicitly control the\ncurrents flowing through the SNN when processing inputs. We implement ECC into\na tool nicknamed SpKeras, which can conveniently import Keras CNN models and\nconvert them into SNNs. We conduct an extensive set of experiments with the\ntool -- working with VGG16 and various datasets such as CIFAR10 and CIFAR100 --\nand compare with state-of-the-art conversion methods. Results show that ECC is\na promising method that can optimise over energy consumption and accuracy loss\nsimultaneously.", "published": "2021-03-01T12:15:29Z", "version": 3}, {"aid": "2103.01209", "authors": ["Drew A. Hudson", "C. Lawrence Zitnick"], "title": "Generative Adversarial Transformers", "url": "http://arxiv.org/pdf/2103.01209v4", "summary": "We introduce the GANformer, a novel and efficient type of transformer, and\nexplore it for the task of visual generative modeling. The network employs a\nbipartite structure that enables long-range interactions across the image,\nwhile maintaining computation of linear efficiency, that can readily scale to\nhigh-resolution synthesis. It iteratively propagates information from a set of\nlatent variables to the evolving visual features and vice versa, to support the\nrefinement of each in light of the other and encourage the emergence of\ncompositional representations of objects and scenes. In contrast to the classic\ntransformer architecture, it utilizes multiplicative integration that allows\nflexible region-based modulation, and can thus be seen as a generalization of\nthe successful StyleGAN network. We demonstrate the model's strength and\nrobustness through a careful evaluation over a range of datasets, from\nsimulated multi-object environments to rich real-world indoor and outdoor\nscenes, showing it achieves state-of-the-art results in terms of image quality\nand diversity, while enjoying fast learning and better data-efficiency. Further\nqualitative and quantitative experiments offer us an insight into the model's\ninner workings, revealing improved interpretability and stronger\ndisentanglement, and illustrating the benefits and efficacy of our approach. An\nimplementation of the model is available at\nhttps://github.com/dorarad/gansformer.", "published": "2021-03-01T18:54:04Z", "version": 4}, {"aid": "2103.02339", "authors": ["Omar Chehab", "Alexandre Defossez", "Jean-Christophe Loiseau", "Alexandre Gramfort", "Jean-Remi King"], "title": "Deep Recurrent Encoder: A scalable end-to-end network to model brain signals", "url": "http://arxiv.org/pdf/2103.02339v3", "summary": "Understanding how the brain responds to sensory inputs is challenging: brain\nrecordings are partial, noisy, and high dimensional; they vary across sessions\nand subjects and they capture highly nonlinear dynamics. These challenges have\nled the community to develop a variety of preprocessing and analytical (almost\nexclusively linear) methods, each designed to tackle one of these issues.\nInstead, we propose to address these challenges through a specific end-to-end\ndeep learning architecture, trained to predict the brain responses of multiple\nsubjects at once. We successfully test this approach on a large cohort of\nmagnetoencephalography (MEG) recordings acquired during a one-hour reading\ntask. Our Deep Recurrent Encoding (DRE) architecture reliably predicts MEG\nresponses to words with a three-fold improvement over classic linear methods.\nTo overcome the notorious issue of interpretability of deep learning, we\ndescribe a simple variable importance analysis. When applied to DRE, this\nmethod recovers the expected evoked responses to word length and word\nfrequency. The quantitative improvement of the present deep learning approach\npaves the way to better understand the nonlinear dynamics of brain activity\nfrom large datasets.", "published": "2021-03-03T11:39:17Z", "version": 3}, {"aid": "2103.02503", "authors": ["Kaiyang Zhou", "Ziwei Liu", "Yu Qiao", "Tao Xiang", "Chen Change Loy"], "title": "Domain Generalization: A Survey", "url": "http://arxiv.org/pdf/2103.02503v7", "summary": "Generalization to out-of-distribution (OOD) data is a capability natural to\nhumans yet challenging for machines to reproduce. This is because most learning\nalgorithms strongly rely on the i.i.d.~assumption on source/target data, which\nis often violated in practice due to domain shift. Domain generalization (DG)\naims to achieve OOD generalization by using only source data for model\nlearning. Over the last ten years, research in DG has made great progress,\nleading to a broad spectrum of methodologies, e.g., those based on domain\nalignment, meta-learning, data augmentation, or ensemble learning, to name a\nfew; DG has also been studied in various application areas including computer\nvision, speech recognition, natural language processing, medical imaging, and\nreinforcement learning. In this paper, for the first time a comprehensive\nliterature review in DG is provided to summarize the developments over the past\ndecade. Specifically, we first cover the background by formally defining DG and\nrelating it to other relevant fields like domain adaptation and transfer\nlearning. Then, we conduct a thorough review into existing methods and\ntheories. Finally, we conclude this survey with insights and discussions on\nfuture research directions.", "published": "2021-03-03T16:12:22Z", "version": 7}, {"aid": "2103.06132", "authors": ["Alexandre Rame", "Remy Sun", "Matthieu Cord"], "title": "MixMo: Mixing Multiple Inputs for Multiple Outputs via Deep Subnetworks", "url": "http://arxiv.org/pdf/2103.06132v3", "summary": "Recent strategies achieved ensembling \"for free\" by fitting concurrently\ndiverse subnetworks inside a single base network. The main idea during training\nis that each subnetwork learns to classify only one of the multiple inputs\nsimultaneously provided. However, the question of how to best mix these\nmultiple inputs has not been studied so far. In this paper, we introduce MixMo,\na new generalized framework for learning multi-input multi-output deep\nsubnetworks. Our key motivation is to replace the suboptimal summing operation\nhidden in previous approaches by a more appropriate mixing mechanism. For that\npurpose, we draw inspiration from successful mixed sample data augmentations.\nWe show that binary mixing in features - particularly with rectangular patches\nfrom CutMix - enhances results by making subnetworks stronger and more diverse.\nWe improve state of the art for image classification on CIFAR-100 and Tiny\nImageNet datasets. Our easy to implement models notably outperform data\naugmented deep ensembles, without the inference and memory overheads. As we\noperate in features and simply better leverage the expressiveness of large\nnetworks, we open a new line of research complementary to previous works.", "published": "2021-03-10T15:31:02Z", "version": 3}, {"aid": "2103.13870", "authors": ["Tianxiang Zhan", "Fuyuan Xiao"], "title": "A novel weighted approach for time series forecasting based on visibility graph", "url": "http://arxiv.org/pdf/2103.13870v6", "summary": "Time series has attracted a lot of attention in many fields today. Time\nseries forecasting algorithm based on complex network analysis is a research\nhotspot. How to use time series information to achieve more accurate\nforecasting is a problem. To solve this problem, this paper proposes a weighted\nnetwork forecasting method to improve the forecasting accuracy. Firstly, the\ntime series will be transformed into a complex network, and the similarity\nbetween nodes will be found. Then, the similarity will be used as a weight to\nmake weighted forecasting on the predicted values produced by different nodes.\nCompared with the previous method, the proposed method is more accurate. In\norder to verify the effect of the proposed method, the experimental part is\ntested on M1, M3 datasets and Construction Cost Index (CCI) dataset, which\nshows that the proposed method has more accurate forecasting performance.", "published": "2021-03-14T01:01:41Z", "version": 6}, {"aid": "2103.09656", "authors": ["Mateusz Jurewicz", "Leon Str\u00f8mberg-Derczynski"], "title": "Set-to-Sequence Methods in Machine Learning: a Review", "url": "http://arxiv.org/pdf/2103.09656v2", "summary": "Machine learning on sets towards sequential output is an important and\nubiquitous task, with applications ranging from language modeling and\nmeta-learning to multi-agent strategy games and power grid optimization.\nCombining elements of representation learning and structured prediction, its\ntwo primary challenges include obtaining a meaningful, permutation invariant\nset representation and subsequently utilizing this representation to output a\ncomplex target permutation. This paper provides a comprehensive introduction to\nthe field as well as an overview of important machine learning methods tackling\nboth of these key challenges, with a detailed qualitative comparison of\nselected model architectures.", "published": "2021-03-17T13:52:33Z", "version": 2}, {"aid": "2103.13630", "authors": ["Amir Gholami", "Sehoon Kim", "Zhen Dong", "Zhewei Yao", "Michael W. Mahoney", "Kurt Keutzer"], "title": "A Survey of Quantization Methods for Efficient Neural Network Inference", "url": "http://arxiv.org/pdf/2103.13630v3", "summary": "As soon as abstract mathematical computations were adapted to computation on\ndigital computers, the problem of efficient representation, manipulation, and\ncommunication of the numerical values in those computations arose. Strongly\nrelated to the problem of numerical representation is the problem of\nquantization: in what manner should a set of continuous real-valued numbers be\ndistributed over a fixed discrete set of numbers to minimize the number of bits\nrequired and also to maximize the accuracy of the attendant computations? This\nperennial problem of quantization is particularly relevant whenever memory\nand/or computational resources are severely restricted, and it has come to the\nforefront in recent years due to the remarkable performance of Neural Network\nmodels in computer vision, natural language processing, and related areas.\nMoving from floating-point representations to low-precision fixed integer\nvalues represented in four bits or less holds the potential to reduce the\nmemory footprint and latency by a factor of 16x; and, in fact, reductions of 4x\nto 8x are often realized in practice in these applications. Thus, it is not\nsurprising that quantization has emerged recently as an important and very\nactive sub-area of research in the efficient implementation of computations\nassociated with Neural Networks. In this article, we survey approaches to the\nproblem of quantizing the numerical values in deep Neural Network computations,\ncovering the advantages/disadvantages of current methods. With this survey and\nits organization, we hope to have presented a useful snapshot of the current\nresearch in quantization for Neural Networks and to have given an intelligent\norganization to ease the evaluation of future research in this area.", "published": "2021-03-25T06:57:11Z", "version": 3}, {"aid": "2103.14005", "authors": ["Klemen Kotar", "Gabriel Ilharco", "Ludwig Schmidt", "Kiana Ehsani", "Roozbeh Mottaghi"], "title": "Contrasting Contrastive Self-Supervised Representation Learning Pipelines", "url": "http://arxiv.org/pdf/2103.14005v2", "summary": "In the past few years, we have witnessed remarkable breakthroughs in\nself-supervised representation learning. Despite the success and adoption of\nrepresentations learned through this paradigm, much is yet to be understood\nabout how different training methods and datasets influence performance on\ndownstream tasks. In this paper, we analyze contrastive approaches as one of\nthe most successful and popular variants of self-supervised representation\nlearning. We perform this analysis from the perspective of the training\nalgorithms, pre-training datasets and end tasks. We examine over 700 training\nexperiments including 30 encoders, 4 pre-training datasets and 20 diverse\ndownstream tasks. Our experiments address various questions regarding the\nperformance of self-supervised models compared to their supervised\ncounterparts, current benchmarks used for evaluation, and the effect of the\npre-training data on end task performance. Our Visual Representation Benchmark\n(ViRB) is available at: https://github.com/allenai/virb.", "published": "2021-03-25T17:40:38Z", "version": 2}, {"aid": "2103.14030", "authors": ["Ze Liu", "Yutong Lin", "Yue Cao", "Han Hu", "Yixuan Wei", "Zheng Zhang", "Stephen Lin", "Baining Guo"], "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", "url": "http://arxiv.org/pdf/2103.14030v2", "summary": "This paper presents a new vision Transformer, called Swin Transformer, that\ncapably serves as a general-purpose backbone for computer vision. Challenges in\nadapting Transformer from language to vision arise from differences between the\ntwo domains, such as large variations in the scale of visual entities and the\nhigh resolution of pixels in images compared to words in text. To address these\ndifferences, we propose a hierarchical Transformer whose representation is\ncomputed with \\textbf{S}hifted \\textbf{win}dows. The shifted windowing scheme\nbrings greater efficiency by limiting self-attention computation to\nnon-overlapping local windows while also allowing for cross-window connection.\nThis hierarchical architecture has the flexibility to model at various scales\nand has linear computational complexity with respect to image size. These\nqualities of Swin Transformer make it compatible with a broad range of vision\ntasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and\ndense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP\non COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its\nperformance surpasses the previous state-of-the-art by a large margin of +2.7\nbox AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the\npotential of Transformer-based models as vision backbones. The hierarchical\ndesign and the shifted window approach also prove beneficial for all-MLP\narchitectures. The code and models are publicly available\nat~\\url{https://github.com/microsoft/Swin-Transformer}.", "published": "2021-03-25T17:59:31Z", "version": 2}, {"aid": "2103.14545", "authors": ["Zirui Liu", "Haifeng Jin", "Ting-Hsiang Wang", "Kaixiong Zhou", "Xia Hu"], "title": "DivAug: Plug-in Automated Data Augmentation with Explicit Diversity Maximization", "url": "http://arxiv.org/pdf/2103.14545v2", "summary": "Human-designed data augmentation strategies have been replaced by\nautomatically learned augmentation policy in the past two years. Specifically,\nrecent work has empirically shown that the superior performance of the\nautomated data augmentation methods stems from increasing the diversity of\naugmented data \\cite{autoaug, randaug}. However, two factors regarding the\ndiversity of augmented data are still missing: 1) the explicit definition (and\nthus measurement) of diversity and 2) the quantifiable relationship between\ndiversity and its regularization effects. To bridge this gap, we propose a\ndiversity measure called Variance Diversity and theoretically show that the\nregularization effect of data augmentation is promised by Variance Diversity.\nWe validate in experiments that the relative gain from automated data\naugmentation in test accuracy is highly correlated to Variance Diversity. An\nunsupervised sampling-based framework, \\textbf{DivAug}, is designed to directly\nmaximize Variance Diversity and hence strengthen the regularization effect.\nWithout requiring a separate search process, the performance gain from DivAug\nis comparable with the state-of-the-art method with better efficiency.\nMoreover, under the semi-supervised setting, our framework can further improve\nthe performance of semi-supervised learning algorithms compared to RandAugment,\nmaking it highly applicable to real-world problems, where labeled data is\nscarce. The code is available at\n\\texttt{\\url{https://github.com/warai-0toko/DivAug}}.", "published": "2021-03-26T16:00:01Z", "version": 2}, {"aid": "2103.17249", "authors": ["Or Patashnik", "Zongze Wu", "Eli Shechtman", "Daniel Cohen-Or", "Dani Lischinski"], "title": "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery", "url": "http://arxiv.org/pdf/2103.17249v1", "summary": "Inspired by the ability of StyleGAN to generate highly realistic images in a\nvariety of domains, much recent work has focused on understanding how to use\nthe latent spaces of StyleGAN to manipulate generated and real images. However,\ndiscovering semantically meaningful latent manipulations typically involves\npainstaking human examination of the many degrees of freedom, or an annotated\ncollection of images for each desired manipulation. In this work, we explore\nleveraging the power of recently introduced Contrastive Language-Image\nPre-training (CLIP) models in order to develop a text-based interface for\nStyleGAN image manipulation that does not require such manual effort. We first\nintroduce an optimization scheme that utilizes a CLIP-based loss to modify an\ninput latent vector in response to a user-provided text prompt. Next, we\ndescribe a latent mapper that infers a text-guided latent manipulation step for\na given input image, allowing faster and more stable text-based manipulation.\nFinally, we present a method for mapping a text prompts to input-agnostic\ndirections in StyleGAN's style space, enabling interactive text-driven image\nmanipulation. Extensive results and comparisons demonstrate the effectiveness\nof our approaches.", "published": "2021-03-31T17:51:25Z", "version": 1}, {"aid": "2104.00272", "authors": ["Kevin Lin", "Lijuan Wang", "Zicheng Liu"], "title": "Mesh Graphormer", "url": "http://arxiv.org/pdf/2104.00272v2", "summary": "We present a graph-convolution-reinforced transformer, named Mesh Graphormer,\nfor 3D human pose and mesh reconstruction from a single image. Recently both\ntransformers and graph convolutional neural networks (GCNNs) have shown\npromising progress in human mesh reconstruction. Transformer-based approaches\nare effective in modeling non-local interactions among 3D mesh vertices and\nbody joints, whereas GCNNs are good at exploiting neighborhood vertex\ninteractions based on a pre-specified mesh topology. In this paper, we study\nhow to combine graph convolutions and self-attentions in a transformer to model\nboth local and global interactions. Experimental results show that our proposed\nmethod, Mesh Graphormer, significantly outperforms the previous\nstate-of-the-art methods on multiple benchmarks, including Human3.6M, 3DPW, and\nFreiHAND datasets. Code and pre-trained models are available at\nhttps://github.com/microsoft/MeshGraphormer", "published": "2021-04-01T06:16:36Z", "version": 2}, {"aid": "2104.00466", "authors": ["Zhisheng Zhong", "Jiequan Cui", "Shu Liu", "Jiaya Jia"], "title": "Improving Calibration for Long-Tailed Recognition", "url": "http://arxiv.org/pdf/2104.00466v1", "summary": "Deep neural networks may perform poorly when training datasets are heavily\nclass-imbalanced. Recently, two-stage methods decouple representation learning\nand classifier learning to improve performance. But there is still the vital\nissue of miscalibration. To address it, we design two methods to improve\ncalibration and performance in such scenarios. Motivated by the fact that\npredicted probability distributions of classes are highly related to the\nnumbers of class instances, we propose label-aware smoothing to deal with\ndifferent degrees of over-confidence for classes and improve classifier\nlearning. For dataset bias between these two stages due to different samplers,\nwe further propose shifted batch normalization in the decoupling framework. Our\nproposed methods set new records on multiple popular long-tailed recognition\nbenchmark datasets, including CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT,\nPlaces-LT, and iNaturalist 2018. Code will be available at\nhttps://github.com/Jia-Research-Lab/MiSLAS.", "published": "2021-04-01T13:55:21Z", "version": 1}, {"aid": "2104.04162", "authors": ["Ademola Okerinde", "Lior Shamir", "William Hsu", "Tom Theis", "Nasik Nafi"], "title": "eGAN: Unsupervised approach to class imbalance using transfer learning", "url": "http://arxiv.org/pdf/2104.04162v2", "summary": "Class imbalance is an inherent problem in many machine learning\nclassification tasks. This often leads to trained models that are unusable for\nany practical purpose. In this study we explore an unsupervised approach to\naddress these imbalances by leveraging transfer learning from pre-trained image\nclassification models to encoder-based Generative Adversarial Network (eGAN).\nTo the best of our knowledge, this is the first work to tackle this problem\nusing GAN without needing to augment with synthesized fake images.\n  In the proposed approach we use the discriminator network to output a\nnegative or positive score. We classify as minority, test samples with negative\nscores and as majority those with positive scores. Our approach eliminates\nepistemic uncertainty in model predictions, as the P(minority) + P(majority)\nneed not sum up to 1. The impact of transfer learning and combinations of\ndifferent pre-trained image classification models at the generator and\ndiscriminator is also explored. Best result of 0.69 F1-score was obtained on\nCIFAR-10 classification task with imbalance ratio of 1:2500.\n  Our approach also provides a mechanism of thresholding the specificity or\nsensitivity of our machine learning system. Keywords: Class imbalance, Transfer\nLearning, GAN, nash equilibrium", "published": "2021-04-09T02:37:55Z", "version": 2}, {"aid": "2104.05704", "authors": ["Ali Hassani", "Steven Walton", "Nikhil Shah", "Abulikemu Abuduweili", "Jiachen Li", "Humphrey Shi"], "title": "Escaping the Big Data Paradigm with Compact Transformers", "url": "http://arxiv.org/pdf/2104.05704v4", "summary": "With the rise of Transformers as the standard for language processing, and\ntheir advancements in computer vision, there has been a corresponding growth in\nparameter size and amounts of training data. Many have come to believe that\nbecause of this, transformers are not suitable for small sets of data. This\ntrend leads to concerns such as: limited availability of data in certain\nscientific domains and the exclusion of those with limited resource from\nresearch in the field. In this paper, we aim to present an approach for\nsmall-scale learning by introducing Compact Transformers. We show for the first\ntime that with the right size, convolutional tokenization, transformers can\navoid overfitting and outperform state-of-the-art CNNs on small datasets. Our\nmodels are flexible in terms of model size, and can have as little as 0.28M\nparameters while achieving competitive results. Our best model can reach 98%\naccuracy when training from scratch on CIFAR-10 with only 3.7M parameters,\nwhich is a significant improvement in data-efficiency over previous Transformer\nbased models being over 10x smaller than other transformers and is 15% the size\nof ResNet50 while achieving similar performance. CCT also outperforms many\nmodern CNN based approaches, and even some recent NAS-based approaches.\nAdditionally, we obtain a new SOTA result on Flowers-102 with 99.76% top-1\naccuracy, and improve upon the existing baseline on ImageNet (82.71% accuracy\nwith 29% as many parameters as ViT), as well as NLP tasks. Our simple and\ncompact design for transformers makes them more feasible to study for those\nwith limited computing resources and/or dealing with small datasets, while\nextending existing research efforts in data efficient transformers. Our code\nand pre-trained models are publicly available at\nhttps://github.com/SHI-Labs/Compact-Transformers.", "published": "2021-04-12T17:58:56Z", "version": 4}, {"aid": "2104.05988", "authors": ["Marcel C. B\u00fchler", "Abhimitra Meka", "Gengyan Li", "Thabo Beeler", "Otmar Hilliges"], "title": "VariTex: Variational Neural Face Textures", "url": "http://arxiv.org/pdf/2104.05988v3", "summary": "Deep generative models can synthesize photorealistic images of human faces\nwith novel identities. However, a key challenge to the wide applicability of\nsuch techniques is to provide independent control over semantically meaningful\nparameters: appearance, head pose, face shape, and facial expressions. In this\npaper, we propose VariTex - to the best of our knowledge the first method that\nlearns a variational latent feature space of neural face textures, which allows\nsampling of novel identities. We combine this generative model with a\nparametric face model and gain explicit control over head pose and facial\nexpressions. To generate complete images of human heads, we propose an additive\ndecoder that adds plausible details such as hair. A novel training scheme\nenforces a pose-independent latent space and in consequence, allows learning a\none-to-many mapping between latent codes and pose-conditioned exterior regions.\nThe resulting method can generate geometrically consistent images of novel\nidentities under fine-grained control over head pose, face shape, and facial\nexpressions. This facilitates a broad range of downstream tasks, like sampling\nnovel identities, changing the head pose, expression transfer, and more. Code\nand models are available for research on https://mcbuehler.github.io/VariTex.", "published": "2021-04-13T07:47:53Z", "version": 3}, {"aid": "2104.07658", "authors": ["Charig Yang", "Hala Lamdouar", "Erika Lu", "Andrew Zisserman", "Weidi Xie"], "title": "Self-supervised Video Object Segmentation by Motion Grouping", "url": "http://arxiv.org/pdf/2104.07658v2", "summary": "Animals have evolved highly functional visual systems to understand motion,\nassisting perception even under complex environments. In this paper, we work\ntowards developing a computer vision system able to segment objects by\nexploiting motion cues, i.e. motion segmentation. We make the following\ncontributions: First, we introduce a simple variant of the Transformer to\nsegment optical flow frames into primary objects and the background. Second, we\ntrain the architecture in a self-supervised manner, i.e. without using any\nmanual annotations. Third, we analyze several critical components of our method\nand conduct thorough ablation studies to validate their necessity. Fourth, we\nevaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2,\nand FBMS59). Despite using only optical flow as input, our approach achieves\nsuperior or comparable results to previous state-of-the-art self-supervised\nmethods, while being an order of magnitude faster. We additionally evaluate on\na challenging camouflage dataset (MoCA), significantly outperforming the other\nself-supervised approaches, and comparing favourably to the top supervised\napproach, highlighting the importance of motion cues, and the potential bias\ntowards visual appearance in existing video segmentation models.", "published": "2021-04-15T17:59:32Z", "version": 2}, {"aid": "2104.09493", "authors": ["Megh Shukla"], "title": "Bayesian Uncertainty and Expected Gradient Length -- Regression: Two Sides Of The Same Coin?", "url": "http://arxiv.org/pdf/2104.09493v3", "summary": "Active learning algorithms select a subset of data for annotation to maximize\nthe model performance on a budget. One such algorithm is Expected Gradient\nLength, which as the name suggests uses the approximate gradient induced per\nexample in the sampling process. While Expected Gradient Length has been\nsuccessfully used for classification and regression, the formulation for\nregression remains intuitively driven. Hence, our theoretical contribution\ninvolves deriving this formulation, thereby supporting the experimental\nevidence. Subsequently, we show that expected gradient length in regression is\nequivalent to Bayesian uncertainty. If certain assumptions are infeasible, our\nalgorithmic contribution (EGL++) approximates the effect of ensembles with a\nsingle deterministic network. Instead of computing multiple possible inferences\nper input, we leverage previously annotated samples to quantify the probability\nof previous labels being the true label. Such an approach allows us to extend\nexpected gradient length to a new task: human pose estimation. We perform\nexperimental validation on two human pose datasets (MPII and LSP/LSPET),\nhighlighting the interpretability and competitiveness of EGL++ with different\nactive learning algorithms for human pose estimation.", "published": "2021-04-19T17:56:59Z", "version": 3}, {"aid": "2104.10729", "authors": ["Chongyi Li", "Chunle Guo", "Linghao Han", "Jun Jiang", "Ming-Ming Cheng", "Jinwei Gu", "Chen Change Loy"], "title": "Low-Light Image and Video Enhancement Using Deep Learning: A Survey", "url": "http://arxiv.org/pdf/2104.10729v3", "summary": "Low-light image enhancement (LLIE) aims at improving the perception or\ninterpretability of an image captured in an environment with poor illumination.\nRecent advances in this area are dominated by deep learning-based solutions,\nwhere many learning strategies, network structures, loss functions, training\ndata, etc. have been employed. In this paper, we provide a comprehensive survey\nto cover various aspects ranging from algorithm taxonomy to open issues. To\nexamine the generalization of existing methods, we propose a low-light image\nand video dataset, in which the images and videos are taken by different mobile\nphones' cameras under diverse illumination conditions. Besides, for the first\ntime, we provide a unified online platform that covers many popular LLIE\nmethods, of which the results can be produced through a user-friendly web\ninterface. In addition to qualitative and quantitative evaluation of existing\nmethods on publicly available and our proposed datasets, we also validate their\nperformance in face detection in the dark.This survey together with the\nproposed dataset and online platform could serve as a reference source for\nfuture study and promote the development of this research field. The proposed\nplatform and dataset as well as the collected methods, datasets, and evaluation\nmetrics are publicly available and will be regularly updated.", "published": "2021-04-21T19:12:19Z", "version": 3}, {"aid": "2104.11178", "authors": ["Hassan Akbari", "Liangzhe Yuan", "Rui Qian", "Wei-Hong Chuang", "Shih-Fu Chang", "Yin Cui", "Boqing Gong"], "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text", "url": "http://arxiv.org/pdf/2104.11178v3", "summary": "We present a framework for learning multimodal representations from unlabeled\ndata using convolution-free Transformer architectures. Specifically, our\nVideo-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts\nmultimodal representations that are rich enough to benefit a variety of\ndownstream tasks. We train VATT end-to-end from scratch using multimodal\ncontrastive losses and evaluate its performance by the downstream tasks of\nvideo action recognition, audio event classification, image classification, and\ntext-to-video retrieval. Furthermore, we study a modality-agnostic,\nsingle-backbone Transformer by sharing weights among the three modalities. We\nshow that the convolution-free VATT outperforms state-of-the-art ConvNet-based\narchitectures in the downstream tasks. Especially, VATT's vision Transformer\nachieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600,\n72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding\nsupervised pre-training. Transferring to image classification leads to 78.7%\ntop-1 accuracy on ImageNet compared to 64.7% by training the same Transformer\nfrom scratch, showing the generalizability of our model despite the domain gap\nbetween videos and images. VATT's audio Transformer also sets a new record on\nwaveform-based audio event recognition by achieving the mAP of 39.4% on\nAudioSet without any supervised pre-training. VATT's source code is publicly\navailable.", "published": "2021-04-22T17:07:41Z", "version": 3}, {"aid": "2104.13478", "authors": ["Michael M. Bronstein", "Joan Bruna", "Taco Cohen", "Petar Veli\u010dkovi\u0107"], "title": "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges", "url": "http://arxiv.org/pdf/2104.13478v2", "summary": "The last decade has witnessed an experimental revolution in data science and\nmachine learning, epitomised by deep learning methods. Indeed, many\nhigh-dimensional learning tasks previously thought to be beyond reach -- such\nas computer vision, playing Go, or protein folding -- are in fact feasible with\nappropriate computational scale. Remarkably, the essence of deep learning is\nbuilt from two simple algorithmic principles: first, the notion of\nrepresentation or feature learning, whereby adapted, often hierarchical,\nfeatures capture the appropriate notion of regularity for each task, and\nsecond, learning by local gradient-descent type methods, typically implemented\nas backpropagation.\n  While learning generic functions in high dimensions is a cursed estimation\nproblem, most tasks of interest are not generic, and come with essential\npre-defined regularities arising from the underlying low-dimensionality and\nstructure of the physical world. This text is concerned with exposing these\nregularities through unified geometric principles that can be applied\nthroughout a wide spectrum of applications.\n  Such a 'geometric unification' endeavour, in the spirit of Felix Klein's\nErlangen Program, serves a dual purpose: on one hand, it provides a common\nmathematical framework to study the most successful neural network\narchitectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand,\nit gives a constructive procedure to incorporate prior physical knowledge into\nneural architectures and provide principled way to build future architectures\nyet to be invented.", "published": "2021-04-27T21:09:51Z", "version": 2}, {"aid": "2105.02738", "authors": ["Marija Slavkovik", "Clemens Stachl", "Caroline Pitman", "Jonathan Askonas"], "title": "Digital Voodoo Dolls", "url": "http://arxiv.org/pdf/2105.02738v2", "summary": "An institution, be it a body of government, commercial enterprise, or a\nservice, cannot interact directly with a person. Instead, a model is created to\nrepresent us. We argue the existence of a new high-fidelity type of person\nmodel which we call a digital voodoo doll. We conceptualize it and compare its\nfeatures with existing models of persons. Digital voodoo dolls are\ndistinguished by existing completely beyond the influence and control of the\nperson they represent. We discuss the ethical issues that such a lack of\naccountability creates and argue how these concerns can be mitigated.", "published": "2021-05-06T14:56:54Z", "version": 2}, {"aid": "2105.07674", "authors": ["Andrea Cossu", "Davide Bacciu", "Antonio Carta", "Claudio Gallicchio", "Vincenzo Lomonaco"], "title": "Continual Learning with Echo State Networks", "url": "http://arxiv.org/pdf/2105.07674v3", "summary": "Continual Learning (CL) refers to a learning setup where data is non\nstationary and the model has to learn without forgetting existing knowledge.\nThe study of CL for sequential patterns revolves around trained recurrent\nnetworks. In this work, instead, we introduce CL in the context of Echo State\nNetworks (ESNs), where the recurrent component is kept fixed. We provide the\nfirst evaluation of catastrophic forgetting in ESNs and we highlight the\nbenefits in using CL strategies which are not applicable to trained recurrent\nmodels. Our results confirm the ESN as a promising model for CL and open to its\nuse in streaming scenarios.", "published": "2021-05-17T08:49:01Z", "version": 3}, {"aid": "2105.10404", "authors": ["Michael Rosenblum", "Arkady Pikovsky", "Andrea A. K\u00fchn", "Johannes L. Busch"], "title": "Real-time estimation of phase and amplitude with application to neural data", "url": "http://arxiv.org/pdf/2105.10404v1", "summary": "Computation of the instantaneous phase and amplitude via the Hilbert\nTransform is a powerful tool of data analysis. This approach finds many\napplications in various science and engineering branches but is not proper for\ncausal estimation because it requires knowledge of the signal's past and\nfuture. However, several problems require real-time estimation of phase and\namplitude; an illustrative example is phase-locked or amplitude-dependent\nstimulation in neuroscience. In this paper, we discuss and compare three causal\nalgorithms that do not rely on the Hilbert Transform but exploit well-known\nphysical phenomena, the synchronization and the resonance. After testing the\nalgorithms on a synthetic data set, we illustrate their performance computing\nphase and amplitude for the accelerometer tremor measurements and a\nParkinsonian patient's beta-band brain activity.", "published": "2021-05-20T12:21:33Z", "version": 1}, {"aid": "2105.10461", "authors": ["Jeffrey L. Krichmar"], "title": "Edelman's Steps Toward a Conscious Artifact", "url": "http://arxiv.org/pdf/2105.10461v2", "summary": "In 2006, during a meeting of a working group of scientists in La Jolla,\nCalifornia at The Neurosciences Institute (NSI), Gerald Edelman described a\nroadmap towards the creation of a Conscious Artifact. As far as I know, this\nroadmap was not published. However, it did shape my thinking and that of many\nothers in the years since that meeting. This short paper, which is based on my\nnotes taken during the meeting, describes the key steps in this roadmap. I\nbelieve it is as groundbreaking today as it was more than 15 years ago.", "published": "2021-05-22T00:13:06Z", "version": 2}, {"aid": "2105.14257", "authors": ["Sarthak Mittal", "Korbinian Abstreiter", "Stefan Bauer", "Bernhard Sch\u00f6lkopf", "Arash Mehrjou"], "title": "Diffusion-Based Representation Learning", "url": "http://arxiv.org/pdf/2105.14257v4", "summary": "Diffusion-based methods represented as stochastic differential equations on a\ncontinuous-time domain have recently proven successful as a non-adversarial\ngenerative model. Training such models relies on denoising score matching,\nwhich can be seen as multi-scale denoising autoencoders. Here, we augment the\ndenoising score matching framework to enable representation learning without\nany supervised signal. GANs and VAEs learn representations by directly\ntransforming latent codes to data samples. In contrast, the introduced\ndiffusion-based representation learning relies on a new formulation of the\ndenoising score matching objective and thus encodes the information needed for\ndenoising. We illustrate how this difference allows for manual control of the\nlevel of details encoded in the representation. Using the same approach, we\npropose to learn an infinite-dimensional latent code that achieves improvements\nof state-of-the-art models on semi-supervised image classification. We also\ncompare the quality of learned representations of diffusion score matching with\nother methods like autoencoder and contrastively trained systems through their\nperformances on downstream tasks.", "published": "2021-05-29T09:26:02Z", "version": 4}, {"aid": "2107.09507", "authors": ["Jian Cui", "Zirui Lan", "Olga Sourina", "Wolfgang M\u00fcller-Wittig"], "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with an Interpretable Convolutional Neural Network", "url": "http://arxiv.org/pdf/2107.09507v4", "summary": "In the context of electroencephalogram (EEG)-based driver drowsiness\nrecognition, it is still challenging to design a calibration-free system, since\nEEG signals vary significantly among different subjects and recording sessions.\nMany efforts have been made to use deep learning methods for mental state\nrecognition from EEG signals. However, existing work mostly treats deep\nlearning models as black-box classifiers, while what have been learned by the\nmodels and to which extent they are affected by the noise in EEG data are still\nunderexplored. In this paper, we develop a novel convolutional neural network\ncombined with an interpretation technique that allows sample-wise analysis of\nimportant features for classification. The network has a compact structure and\ntakes advantage of separable convolutions to process the EEG signals in a\nspatial-temporal sequence. Results show that the model achieves an average\naccuracy of 78.35% on 11 subjects for leave-one-out cross-subject drowsiness\nrecognition, which is higher than the conventional baseline methods of\n53.40%-72.68% and state-of-the-art deep learning methods of 71.75%-75.19%.\nInterpretation results indicate the model has learned to recognize biologically\nmeaningful features from EEG signals, e.g., Alpha spindles, as strong\nindicators of drowsiness across different subjects. In addition, we also\nexplore reasons behind some wrongly classified samples with the interpretation\ntechnique and discuss potential ways to improve the recognition accuracy. Our\nwork illustrates a promising direction on using interpretable deep learning\nmodels to discover meaningful patterns related to different mental states from\ncomplex EEG signals.", "published": "2021-05-30T14:47:20Z", "version": 4}, {"aid": "2106.01345", "authors": ["Lili Chen", "Kevin Lu", "Aravind Rajeswaran", "Kimin Lee", "Aditya Grover", "Michael Laskin", "Pieter Abbeel", "Aravind Srinivas", "Igor Mordatch"], "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling", "url": "http://arxiv.org/pdf/2106.01345v2", "summary": "We introduce a framework that abstracts Reinforcement Learning (RL) as a\nsequence modeling problem. This allows us to draw upon the simplicity and\nscalability of the Transformer architecture, and associated advances in\nlanguage modeling such as GPT-x and BERT. In particular, we present Decision\nTransformer, an architecture that casts the problem of RL as conditional\nsequence modeling. Unlike prior approaches to RL that fit value functions or\ncompute policy gradients, Decision Transformer simply outputs the optimal\nactions by leveraging a causally masked Transformer. By conditioning an\nautoregressive model on the desired return (reward), past states, and actions,\nour Decision Transformer model can generate future actions that achieve the\ndesired return. Despite its simplicity, Decision Transformer matches or exceeds\nthe performance of state-of-the-art model-free offline RL baselines on Atari,\nOpenAI Gym, and Key-to-Door tasks.", "published": "2021-06-02T17:53:39Z", "version": 2}, {"aid": "2106.02022", "authors": ["Micha\u00ebl Ramamonjisoa", "Michael Firman", "Jamie Watson", "Vincent Lepetit", "Daniyar Turmukhambetov"], "title": "Single Image Depth Prediction with Wavelet Decomposition", "url": "http://arxiv.org/pdf/2106.02022v2", "summary": "We present a novel method for predicting accurate depths from monocular\nimages with high efficiency. This optimal efficiency is achieved by exploiting\nwavelet decomposition, which is integrated in a fully differentiable\nencoder-decoder architecture. We demonstrate that we can reconstruct\nhigh-fidelity depth maps by predicting sparse wavelet coefficients. In contrast\nwith previous works, we show that wavelet coefficients can be learned without\ndirect supervision on coefficients. Instead we supervise only the final depth\nimage that is reconstructed through the inverse wavelet transform. We\nadditionally show that wavelet coefficients can be learned in fully\nself-supervised scenarios, without access to ground-truth depth. Finally, we\napply our method to different state-of-the-art monocular depth estimation\nmodels, in each case giving similar or better results compared to the original\nmodel, while requiring less than half the multiply-adds in the decoder network.\nCode at https://github.com/nianticlabs/wavelet-monodepth", "published": "2021-06-03T17:42:25Z", "version": 2}, {"aid": "2106.02299", "authors": ["Liying Lu", "Wenbo Li", "Xin Tao", "Jiangbo Lu", "Jiaya Jia"], "title": "MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution", "url": "http://arxiv.org/pdf/2106.02299v1", "summary": "Reference-based image super-resolution (RefSR) has shown promising success in\nrecovering high-frequency details by utilizing an external reference image\n(Ref). In this task, texture details are transferred from the Ref image to the\nlow-resolution (LR) image according to their point- or patch-wise\ncorrespondence. Therefore, high-quality correspondence matching is critical. It\nis also desired to be computationally efficient. Besides, existing RefSR\nmethods tend to ignore the potential large disparity in distributions between\nthe LR and Ref images, which hurts the effectiveness of the information\nutilization. In this paper, we propose the MASA network for RefSR, where two\nnovel modules are designed to address these problems. The proposed Match &\nExtraction Module significantly reduces the computational cost by a\ncoarse-to-fine correspondence matching scheme. The Spatial Adaptation Module\nlearns the difference of distribution between the LR and Ref images, and remaps\nthe distribution of Ref features to that of LR features in a spatially adaptive\nway. This scheme makes the network robust to handle different reference images.\nExtensive quantitative and qualitative experiments validate the effectiveness\nof our proposed model.", "published": "2021-06-04T07:15:32Z", "version": 1}, {"aid": "2106.02994", "authors": ["Alex Wong", "Safa Cicek", "Stefano Soatto"], "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion", "url": "http://arxiv.org/pdf/2106.02994v3", "summary": "We present a method for inferring dense depth maps from images and sparse\ndepth measurements by leveraging synthetic data to learn the association of\nsparse point clouds with dense natural shapes, and using the image as evidence\nto validate the predicted depth map. Our learned prior for natural shapes uses\nonly sparse depth as input, not images, so the method is not affected by the\ncovariate shift when attempting to transfer learned models from synthetic data\nto real ones. This allows us to use abundant synthetic data with ground truth\nto learn the most difficult component of the reconstruction process, which is\ntopology estimation, and use the image to refine the prediction based on\nphotometric evidence. Our approach uses fewer parameters than previous methods,\nyet, achieves the state of the art on both indoor and outdoor benchmark\ndatasets. Code available at:\nhttps://github.com/alexklwong/learning-topology-synthetic-data.", "published": "2021-06-06T00:21:12Z", "version": 3}, {"aid": "2106.03761", "authors": ["Tiago Salvador", "Stephanie Cairns", "Vikram Voleti", "Noah Marshall", "Adam Oberman"], "title": "FairCal: Fairness Calibration for Face Verification", "url": "http://arxiv.org/pdf/2106.03761v4", "summary": "Despite being widely used, face recognition models suffer from bias: the\nprobability of a false positive (incorrect face match) strongly depends on\nsensitive attributes such as the ethnicity of the face. As a result, these\nmodels can disproportionately and negatively impact minority groups,\nparticularly when used by law enforcement. The majority of bias reduction\nmethods have several drawbacks: they use an end-to-end retraining approach, may\nnot be feasible due to privacy issues, and often reduce accuracy. An\nalternative approach is post-processing methods that build fairer decision\nclassifiers using the features of pre-trained models, thus avoiding the cost of\nretraining. However, they still have drawbacks: they reduce accuracy (AGENDA,\nPASS, FTC), or require retuning for different false positive rates (FSN). In\nthis work, we introduce the Fairness Calibration (FairCal) method, a\npost-training approach that simultaneously: (i) increases model accuracy\n(improving the state-of-the-art), (ii) produces fairly-calibrated\nprobabilities, (iii) significantly reduces the gap in the false positive rates,\n(iv) does not require knowledge of the sensitive attribute, and (v) does not\nrequire retraining, training an additional model, or retuning. We apply it to\nthe task of Face Verification, and obtain state-of-the-art results with all the\nabove advantages.", "published": "2021-06-07T16:26:26Z", "version": 4}, {"aid": "2106.04026", "authors": ["Dae-Hyeok Lee", "Dong-Kyun Han", "Sung-Jin Kim", "Ji-Hoon Jeong", "Seong-Whan Lee"], "title": "Subject-Independent Brain-Computer Interface for Decoding High-Level Visual Imagery Tasks", "url": "http://arxiv.org/pdf/2106.04026v2", "summary": "Brain-computer interface (BCI) is used for communication between humans and\ndevices by recognizing status and intention of humans. Communication between\nhumans and a drone using electroencephalogram (EEG) signals is one of the most\nchallenging issues in the BCI domain. In particular, the control of drone\nswarms (the direction and formation) has more advantages compared to the\ncontrol of a drone. The visual imagery (VI) paradigm is that subjects visually\nimagine specific objects or scenes. Reduction of the variability among EEG\nsignals of subjects is essential for practical BCI-based systems. In this\nstudy, we proposed the subepoch-wise feature encoder (SEFE) to improve the\nperformances in the subject-independent tasks by using the VI dataset. This\nstudy is the first attempt to demonstrate the possibility of generalization\namong subjects in the VI-based BCI. We used the leave-one-subject-out\ncross-validation for evaluating the performances. We obtained higher\nperformances when including our proposed module than excluding our proposed\nmodule. The DeepConvNet with SEFE showed the highest performance of 0.72 among\nsix different decoding models. Hence, we demonstrated the feasibility of\ndecoding the VI dataset in the subject-independent task with robust\nperformances by using our proposed module.", "published": "2021-06-08T00:39:31Z", "version": 2}, {"aid": "2106.05238", "authors": ["Matthew Willetts", "Brooks Paige"], "title": "I Don't Need u: Identifiable Non-Linear ICA Without Side Information", "url": "http://arxiv.org/pdf/2106.05238v4", "summary": "In this paper, we investigate the algorithmic stability of unsupervised\nrepresentation learning with deep generative models, as a function of repeated\nre-training on the same input data. Algorithms for learning low dimensional\nlinear representations -- for example principal components analysis (PCA), or\nlinear independent components analysis (ICA) -- come with guarantees that they\nwill always reveal the same latent representations (perhaps up to an arbitrary\nrotation or permutation). Unfortunately, for non-linear representation\nlearning, such as in a variational auto-encoder (VAE) model trained by\nstochastic gradient descent, we have no such guarantees. Recent work on\nidentifiability in non-linear ICA have introduced a family of deep generative\nmodels that have identifiable latent representations, achieved by conditioning\non side information (e.g. informative labels). We empirically evaluate the\nstability of these models under repeated re-estimation of parameters, and\ncompare them to both standard VAEs and deep generative models which learn to\ncluster in their latent space. Surprisingly, we discover side information is\nnot necessary for algorithmic stability: using standard quantitative measures\nof identifiability, we find deep generative models with latent clusterings are\nempirically identifiable to the same degree as models which rely on auxiliary\nlabels. We relate these results to the possibility of identifiable non-linear\nICA.", "published": "2021-06-09T17:22:08Z", "version": 4}, {"aid": "2106.06112", "authors": ["Jingyi Zhang", "Jiaxing Huang", "Zichen Tian", "Shijian Lu"], "title": "Spectral Unsupervised Domain Adaptation for Visual Recognition", "url": "http://arxiv.org/pdf/2106.06112v3", "summary": "Though unsupervised domain adaptation (UDA) has achieved very impressive\nprogress recently, it remains a great challenge due to missing target\nannotations and the rich discrepancy between source and target distributions.\nWe propose Spectral UDA (SUDA), an effective and efficient UDA technique that\nworks in the spectral space and can generalize across different visual\nrecognition tasks. SUDA addresses the UDA challenges from two perspectives.\nFirst, it introduces a spectrum transformer (ST) that mitigates inter-domain\ndiscrepancies by enhancing domain-invariant spectra while suppressing\ndomain-variant spectra of source and target samples simultaneously. Second, it\nintroduces multi-view spectral learning that learns useful unsupervised\nrepresentations by maximizing mutual information among multiple ST-generated\nspectral views of each target sample. Extensive experiments show that SUDA\nachieves superior accuracy consistently across different visual tasks in object\ndetection, semantic segmentation and image classification. Additionally, SUDA\nalso works with the transformer-based network and achieves state-of-the-art\nperformance on object detection.", "published": "2021-06-11T01:31:52Z", "version": 3}, {"aid": "2106.08208", "authors": ["Feihu Huang", "Junyi Li", "Heng Huang"], "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients", "url": "http://arxiv.org/pdf/2106.08208v10", "summary": "Adaptive gradient methods have shown excellent performances for solving many\nmachine learning problems. Although multiple adaptive gradient methods were\nrecently studied, they mainly focus on either empirical or theoretical aspects\nand also only work for specific problems by using some specific adaptive\nlearning rates. Thus, it is desired to design a universal framework for\npractical algorithms of adaptive gradients with theoretical guarantee to solve\ngeneral problems. To fill this gap, we propose a faster and universal framework\nof adaptive gradients (i.e., SUPER-ADAM) by introducing a universal adaptive\nmatrix that includes most existing adaptive gradient forms. Moreover, our\nframework can flexibly integrate the momentum and variance reduced techniques.\nIn particular, our novel framework provides the convergence analysis support\nfor adaptive gradient methods under the nonconvex setting. In theoretical\nanalysis, we prove that our SUPER-ADAM algorithm can achieve the best known\ngradient (i.e., stochastic first-order oracle (SFO)) complexity of\n$\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point of\nnonconvex optimization, which matches the lower bound for stochastic smooth\nnonconvex optimization. In numerical experiments, we employ various deep\nlearning tasks to validate that our algorithm consistently outperforms the\nexisting adaptive algorithms. Code is available at\nhttps://github.com/LIJUNYI95/SuperAdam", "published": "2021-06-15T15:16:28Z", "version": 10}, {"aid": "2106.08693", "authors": ["Alexander Tsaregorodtsev", "Vasileios Belagiannis"], "title": "ParticleAugment: Sampling-Based Data Augmentation", "url": "http://arxiv.org/pdf/2106.08693v3", "summary": "We present an automated data augmentation approach for image classification.\nWe formulate the problem as Monte Carlo sampling where our goal is to\napproximate the optimal augmentation policies. We propose a particle filtering\nscheme for the policy search where the probability of applying a set of\naugmentation operations forms the state of the filter. We measure the policy\nperformance based on the loss function difference between a reference and the\nactual model, which we afterwards use to re-weight the particles and finally\nupdate the policy. In our experiments, we show that our formulation for\nautomated augmentation reaches promising results on CIFAR-10, CIFAR-100, and\nImageNet datasets using the standard network architectures for this problem. By\ncomparing with the related work, our method reaches a balance between the\ncomputational cost of policy search and the model performance. Our code will be\nmade publicly available.", "published": "2021-06-16T10:56:02Z", "version": 3}, {"aid": "2106.09563", "authors": ["Lucas Caccia", "Jing Xu", "Myle Ott", "Marc'Aurelio Ranzato", "Ludovic Denoyer"], "title": "On Anytime Learning at Macroscale", "url": "http://arxiv.org/pdf/2106.09563v5", "summary": "In many practical applications of machine learning data arrives sequentially\nover time in large chunks. Practitioners have then to decide how to allocate\ntheir computational budget in order to obtain the best performance at any point\nin time. Online learning theory for convex optimization suggests that the best\nstrategy is to use data as soon as it arrives. However, this might not be the\nbest strategy when using deep non-linear networks, particularly when these\nperform multiple passes over each chunk of data rendering the overall\ndistribution non i.i.d.. In this paper, we formalize this learning setting in\nthe simplest scenario in which each data chunk is drawn from the same\nunderlying distribution, and make a first attempt at empirically answering the\nfollowing questions: How long should the learner wait before training on the\nnewly arrived chunks? What architecture should the learner adopt? Should the\nlearner increase capacity over time as more data is observed? We probe this\nlearning setting using convolutional neural networks trained on classic\ncomputer vision benchmarks as well as a large transformer model trained on a\nlarge-scale language modeling task. Code is available at\n\\url{www.github.com/facebookresearch/ALMA}.", "published": "2021-06-17T14:45:22Z", "version": 5}, {"aid": "2106.09701", "authors": ["James Smith", "Yen-Chang Hsu", "Jonathan Balloch", "Yilin Shen", "Hongxia Jin", "Zsolt Kira"], "title": "Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning", "url": "http://arxiv.org/pdf/2106.09701v2", "summary": "Modern computer vision applications suffer from catastrophic forgetting when\nincrementally learning new concepts over time. The most successful approaches\nto alleviate this forgetting require extensive replay of previously seen data,\nwhich is problematic when memory constraints or data legality concerns exist.\nIn this work, we consider the high-impact problem of Data-Free\nClass-Incremental Learning (DFCIL), where an incremental learning agent must\nlearn new concepts over time without storing generators or training data from\npast tasks. One approach for DFCIL is to replay synthetic images produced by\ninverting a frozen copy of the learner's classification model, but we show this\napproach fails for common class-incremental benchmarks when using standard\ndistillation strategies. We diagnose the cause of this failure and propose a\nnovel incremental distillation strategy for DFCIL, contributing a modified\ncross-entropy training and importance-weighted feature distillation, and show\nthat our method results in up to a 25.1% increase in final task accuracy\n(absolute difference) compared to SOTA DFCIL methods for common\nclass-incremental benchmarks. Our method even outperforms several standard\nreplay based methods which store a coreset of images.", "published": "2021-06-17T17:56:08Z", "version": 2}, {"aid": "2106.10163", "authors": ["Erik Jenner", "Maurice Weiler"], "title": "Steerable Partial Differential Operators for Equivariant Neural Networks", "url": "http://arxiv.org/pdf/2106.10163v3", "summary": "Recent work in equivariant deep learning bears strong similarities to\nphysics. Fields over a base space are fundamental entities in both subjects, as\nare equivariant maps between these fields. In deep learning, however, these\nmaps are usually defined by convolutions with a kernel, whereas they are\npartial differential operators (PDOs) in physics. Developing the theory of\nequivariant PDOs in the context of deep learning could bring these subjects\neven closer together and lead to a stronger flow of ideas. In this work, we\nderive a $G$-steerability constraint that completely characterizes when a PDO\nbetween feature vector fields is equivariant, for arbitrary symmetry groups\n$G$. We then fully solve this constraint for several important groups. We use\nour solutions as equivariant drop-in replacements for convolutional layers and\nbenchmark them in that role. Finally, we develop a framework for equivariant\nmaps based on Schwartz distributions that unifies classical convolutions and\ndifferential operators and gives insight about the relation between the two.", "published": "2021-06-18T14:58:19Z", "version": 3}, {"aid": "2106.10165", "authors": ["Daniel A. Roberts", "Sho Yaida", "Boris Hanin"], "title": "The Principles of Deep Learning Theory", "url": "http://arxiv.org/pdf/2106.10165v2", "summary": "This book develops an effective theory approach to understanding deep neural\nnetworks of practical relevance. Beginning from a first-principles\ncomponent-level picture of networks, we explain how to determine an accurate\ndescription of the output of trained networks by solving layer-to-layer\niteration equations and nonlinear learning dynamics. A main result is that the\npredictions of networks are described by nearly-Gaussian distributions, with\nthe depth-to-width aspect ratio of the network controlling the deviations from\nthe infinite-width Gaussian description. We explain how these effectively-deep\nnetworks learn nontrivial representations from training and more broadly\nanalyze the mechanism of representation learning for nonlinear models. From a\nnearly-kernel-methods perspective, we find that the dependence of such models'\npredictions on the underlying learning algorithm can be expressed in a simple\nand universal way. To obtain these results, we develop the notion of\nrepresentation group flow (RG flow) to characterize the propagation of signals\nthrough the network. By tuning networks to criticality, we give a practical\nsolution to the exploding and vanishing gradient problem. We further explain\nhow RG flow leads to near-universal behavior and lets us categorize networks\nbuilt from different activation functions into universality classes.\nAltogether, we show that the depth-to-width ratio governs the effective model\ncomplexity of the ensemble of trained networks. By using information-theoretic\ntechniques, we estimate the optimal aspect ratio at which we expect the network\nto be practically most useful and show how residual connections can be used to\npush this scale to arbitrary depths. With these tools, we can learn in detail\nabout the inductive bias of architectures, hyperparameters, and optimizers.", "published": "2021-06-18T15:00:00Z", "version": 2}, {"aid": "2106.11342", "authors": ["Aston Zhang", "Zachary C. Lipton", "Mu Li", "Alexander J. Smola"], "title": "Dive into Deep Learning", "url": "http://arxiv.org/pdf/2106.11342v5", "summary": "This open-source book represents our attempt to make deep learning\napproachable, teaching readers the concepts, the context, and the code. The\nentire book is drafted in Jupyter notebooks, seamlessly integrating exposition\nfigures, math, and interactive examples with self-contained code. Our goal is\nto offer a resource that could (i) be freely available for everyone; (ii) offer\nsufficient technical depth to provide a starting point on the path to actually\nbecoming an applied machine learning scientist; (iii) include runnable code,\nshowing readers how to solve problems in practice; (iv) allow for rapid\nupdates, both by us and also by the community at large; (v) be complemented by\na forum for interactive discussion of technical details and to answer\nquestions.", "published": "2021-06-21T18:19:46Z", "version": 5}, {"aid": "2106.12423", "authors": ["Tero Karras", "Miika Aittala", "Samuli Laine", "Erik H\u00e4rk\u00f6nen", "Janne Hellsten", "Jaakko Lehtinen", "Timo Aila"], "title": "Alias-Free Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2106.12423v4", "summary": "We observe that despite their hierarchical convolutional nature, the\nsynthesis process of typical generative adversarial networks depends on\nabsolute pixel coordinates in an unhealthy manner. This manifests itself as,\ne.g., detail appearing to be glued to image coordinates instead of the surfaces\nof depicted objects. We trace the root cause to careless signal processing that\ncauses aliasing in the generator network. Interpreting all signals in the\nnetwork as continuous, we derive generally applicable, small architectural\nchanges that guarantee that unwanted information cannot leak into the\nhierarchical synthesis process. The resulting networks match the FID of\nStyleGAN2 but differ dramatically in their internal representations, and they\nare fully equivariant to translation and rotation even at subpixel scales. Our\nresults pave the way for generative models better suited for video and\nanimation.", "published": "2021-06-23T14:20:01Z", "version": 4}, {"aid": "2106.13799", "authors": ["Yiding Jiang", "Vaishnavh Nagarajan", "Christina Baek", "J. Zico Kolter"], "title": "Assessing Generalization of SGD via Disagreement", "url": "http://arxiv.org/pdf/2106.13799v2", "summary": "We empirically show that the test error of deep networks can be estimated by\nsimply training the same architecture on the same training set but with a\ndifferent run of Stochastic Gradient Descent (SGD), and measuring the\ndisagreement rate between the two networks on unlabeled test data. This builds\non -- and is a stronger version of -- the observation in Nakkiran & Bansal '20,\nwhich requires the second run to be on an altogether fresh training set. We\nfurther theoretically show that this peculiar phenomenon arises from the\n\\emph{well-calibrated} nature of \\emph{ensembles} of SGD-trained models. This\nfinding not only provides a simple empirical measure to directly predict the\ntest error using unlabeled test data, but also establishes a new conceptual\nconnection between generalization and calibration.", "published": "2021-06-25T17:53:09Z", "version": 2}, {"aid": "2106.14501", "authors": ["Jiang Hai", "Zhu Xuan", "Songchen Han", "Ren Yang", "Yutong Hao", "Fengzhu Zou", "Fang Lin"], "title": "R2RNet: Low-light Image Enhancement via Real-low to Real-normal Network", "url": "http://arxiv.org/pdf/2106.14501v2", "summary": "Images captured in weak illumination conditions could seriously degrade the\nimage quality. Solving a series of degradation of low-light images can\neffectively improve the visual quality of images and the performance of\nhigh-level visual tasks. In this study, a novel Retinex-based Real-low to\nReal-normal Network (R2RNet) is proposed for low-light image enhancement, which\nincludes three subnets: a Decom-Net, a Denoise-Net, and a Relight-Net. These\nthree subnets are used for decomposing, denoising, contrast enhancement and\ndetail preservation, respectively. Our R2RNet not only uses the spatial\ninformation of the image to improve the contrast but also uses the frequency\ninformation to preserve the details. Therefore, our model acheived more robust\nresults for all degraded images. Unlike most previous methods that were trained\non synthetic images, we collected the first Large-Scale Real-World paired\nlow/normal-light images dataset (LSRW dataset) to satisfy the training\nrequirements and make our model have better generalization performance in\nreal-world scenes. Extensive experiments on publicly available datasets\ndemonstrated that our method outperforms the existing state-of-the-art methods\nboth quantitatively and visually. In addition, our results showed that the\nperformance of the high-level visual task (i.e. face detection) can be\neffectively improved by using the enhanced results obtained by our method in\nlow-light conditions. Our codes and the LSRW dataset are available at:\nhttps://github.com/abcdef2000/R2RNet.", "published": "2021-06-28T09:33:13Z", "version": 2}, {"aid": "2106.15419", "authors": ["Zhikang T. Wang", "Masahito Ueda"], "title": "Convergent and Efficient Deep Q Network Algorithm", "url": "http://arxiv.org/pdf/2106.15419v3", "summary": "Despite the empirical success of the deep Q network (DQN) reinforcement\nlearning algorithm and its variants, DQN is still not well understood and it\ndoes not guarantee convergence. In this work, we show that DQN can indeed\ndiverge and cease to operate in realistic settings. Although there exist\ngradient-based convergent methods, we show that they actually have inherent\nproblems in learning dynamics which cause them to fail even in simple tasks. To\novercome these problems, we propose a convergent DQN algorithm (C-DQN) that is\nguaranteed to converge and can work with large discount factors (0.9998). It\nlearns robustly in difficult settings and can learn several difficult games in\nthe Atari 2600 benchmark that DQN fails to solve. Our codes have been publicly\nreleased and can be used to reproduce our results.", "published": "2021-06-29T13:38:59Z", "version": 3}, {"aid": "2107.04261", "authors": ["Jin Li", "Wanyun Li", "Zichen Xu", "Yuhao Wang", "Qiegen Liu"], "title": "Wavelet Transform-assisted Adaptive Generative Modeling for Colorization", "url": "http://arxiv.org/pdf/2107.04261v2", "summary": "Unsupervised deep learning has recently demonstrated the promise of producing\nhigh-quality samples. While it has tremendous potential to promote the image\ncolorization task, the performance is limited owing to the high-dimension of\ndata manifold and model capability. This study presents a novel scheme that\nexploits the score-based generative model in wavelet domain to address the\nissues. By taking advantage of the multi-scale and multi-channel representation\nvia wavelet transform, the proposed model learns the richer priors from stacked\ncoarse and detailed wavelet coefficient components jointly and effectively.\nThis strategy also reduces the dimension of the original manifold and\nalleviates the curse of dimensionality, which is beneficial for estimation and\nsampling. Moreover, dual consistency terms in the wavelet domain, namely\ndata-consistency and structure-consistency are devised to leverage colorization\ntask better. Specifically, in the training phase, a set of multi-channel\ntensors consisting of wavelet coefficients is used as the input to train the\nnetwork with denoising score matching. In the inference phase, samples are\niteratively generated via annealed Langevin dynamics with data and structure\nconsistencies. Experiments demonstrated remarkable improvements of the proposed\nmethod on both generation and colorization quality, particularly in\ncolorization robustness and diversity.", "published": "2021-07-09T07:12:39Z", "version": 2}, {"aid": "2107.06154", "authors": ["Shuhao Cui", "Shuhui Wang", "Junbao Zhuo", "Liang Li", "Qingming Huang", "Qi Tian"], "title": "Fast Batch Nuclear-norm Maximization and Minimization for Robust Domain Adaptation", "url": "http://arxiv.org/pdf/2107.06154v4", "summary": "Due to the domain discrepancy in visual domain adaptation, the performance of\nsource model degrades when bumping into the high data density near decision\nboundary in target domain. A common solution is to minimize the Shannon Entropy\nto push the decision boundary away from the high density area. However, entropy\nminimization also leads to severe reduction of prediction diversity, and\nunfortunately brings harm to the domain adaptation. In this paper, we\ninvestigate the prediction discriminability and diversity by studying the\nstructure of the classification output matrix of a randomly selected data\nbatch. We find by theoretical analysis that the prediction discriminability and\ndiversity could be separately measured by the Frobenius-norm and rank of the\nbatch output matrix. The nuclear-norm is an upperbound of the former, and a\nconvex approximation of the latter. Accordingly, we propose Batch Nuclear-norm\nMaximization and Minimization, which performs nuclear-norm maximization on the\ntarget output matrix to enhance the target prediction ability, and nuclear-norm\nminimization on the source batch output matrix to increase applicability of the\nsource domain knowledge. We further approximate the nuclear-norm by\nL_{1,2}-norm, and design multi-batch optimization for stable solution on large\nnumber of categories. The fast approximation method achieves O(n^2)\ncomputational complexity and better convergence property. Experiments show that\nour method could boost the adaptation accuracy and robustness under three\ntypical domain adaptation scenarios. The code is available at\nhttps://github.com/cuishuhao/BNM.", "published": "2021-07-13T15:08:32Z", "version": 4}, {"aid": "2107.07110", "authors": ["Jiayun Wang", "Yubei Chen", "Stella X. Yu", "Brian Cheung", "Yann LeCun"], "title": "Compact and Optimal Deep Learning with Recurrent Parameter Generators", "url": "http://arxiv.org/pdf/2107.07110v3", "summary": "Deep learning has achieved tremendous success by training increasingly large\nmodels, which are then compressed for practical deployment. We propose a\ndrastically different approach to compact and optimal deep learning: We\ndecouple the Degrees of freedom (DoF) and the actual number of parameters of a\nmodel, optimize a small DoF with predefined random linear constraints for a\nlarge model of arbitrary architecture, in one-stage end-to-end learning.\nSpecifically, we create a recurrent parameter generator (RPG), which repeatedly\nfetches parameters from a ring and unpacks them onto a large model with random\npermutation and sign flipping to promote parameter decorrelation. We show that\ngradient descent can automatically find the best model under constraints with\nfaster convergence. Our extensive experimentation reveals a log-linear\nrelationship between model DoF and accuracy. Our RPG demonstrates remarkable\nDoF reduction and can be further pruned and quantized for additional run-time\nperformance gain. For example, in terms of top-1 accuracy on ImageNet, RPG\nachieves $96\\%$ of ResNet18's performance with only $18\\%$ DoF (the equivalent\nof one convolutional layer) and $52\\%$ of ResNet34's performance with only\n$0.25\\%$ DoF! Our work shows a significant potential of constrained neural\noptimization in compact and optimal deep learning.", "published": "2021-07-15T04:23:59Z", "version": 3}, {"aid": "2107.08430", "authors": ["Zheng Ge", "Songtao Liu", "Feng Wang", "Zeming Li", "Jian Sun"], "title": "YOLOX: Exceeding YOLO Series in 2021", "url": "http://arxiv.org/pdf/2107.08430v2", "summary": "In this report, we present some experienced improvements to YOLO series,\nforming a new high-performance detector -- YOLOX. We switch the YOLO detector\nto an anchor-free manner and conduct other advanced detection techniques, i.e.,\na decoupled head and the leading label assignment strategy SimOTA to achieve\nstate-of-the-art results across a large scale range of models: For YOLO-Nano\nwith only 0.91M parameters and 1.08G FLOPs, we get 25.3% AP on COCO, surpassing\nNanoDet by 1.8% AP; for YOLOv3, one of the most widely used detectors in\nindustry, we boost it to 47.3% AP on COCO, outperforming the current best\npractice by 3.0% AP; for YOLOX-L with roughly the same amount of parameters as\nYOLOv4-CSP, YOLOv5-L, we achieve 50.0% AP on COCO at a speed of 68.9 FPS on\nTesla V100, exceeding YOLOv5-L by 1.8% AP. Further, we won the 1st Place on\nStreaming Perception Challenge (Workshop on Autonomous Driving at CVPR 2021)\nusing a single YOLOX-L model. We hope this report can provide useful experience\nfor developers and researchers in practical scenes, and we also provide deploy\nversions with ONNX, TensorRT, NCNN, and Openvino supported. Source code is at\nhttps://github.com/Megvii-BaseDetection/YOLOX.", "published": "2021-07-18T12:55:11Z", "version": 2}, {"aid": "2107.12026", "authors": ["Eneko Uru\u00f1uela", "Thomas A. W. Bolton", "Dimitri Van De Ville", "C\u00e9sar Caballero-Gaudes"], "title": "Hemodynamic Deconvolution Demystified: Sparsity-Driven Regularization at Work", "url": "http://arxiv.org/pdf/2107.12026v4", "summary": "Deconvolution of the hemodynamic response is an important step to access\nshort timescales of brain activity recorded by functional magnetic resonance\nimaging (fMRI). Albeit conventional deconvolution algorithms have been around\nfor a long time (e.g., Wiener deconvolution), recent state-of-the-art methods\nbased on sparsity-pursuing regularization are attracting increasing interest to\ninvestigate brain dynamics and connectivity with fMRI. This technical note\nrevisits the main concepts underlying two main methods, Paradigm Free Mapping\nand Total Activation, in the most accessible way. Despite their apparent\ndifferences in the formulation, these methods are theoretically equivalent as\nthey represent the synthesis and analysis sides of the same problem,\nrespectively. We demonstrate this equivalence in practice with their\nbest-available implementations using both simulations, with different\nsignal-to-noise ratios, and experimental fMRI data acquired during a motor task\nand resting-state. We evaluate the parameter settings that lead to equivalent\nresults, and showcase the potential of these algorithms compared to other\ncommon approaches. This note is useful for practitioners interested in gaining\na better understanding of state-of-the-art hemodynamic deconvolution, and aims\nto answer questions that practitioners often have regarding the differences\nbetween the two methods.", "published": "2021-07-26T08:30:18Z", "version": 4}, {"aid": "2107.12028", "authors": ["Jiequan Cui", "Zhisheng Zhong", "Shu Liu", "Bei Yu", "Jiaya Jia"], "title": "Parametric Contrastive Learning", "url": "http://arxiv.org/pdf/2107.12028v2", "summary": "In this paper, we propose Parametric Contrastive Learning (PaCo) to tackle\nlong-tailed recognition. Based on theoretical analysis, we observe supervised\ncontrastive loss tends to bias on high-frequency classes and thus increases the\ndifficulty of imbalanced learning. We introduce a set of parametric class-wise\nlearnable centers to rebalance from an optimization perspective. Further, we\nanalyze our PaCo loss under a balanced setting. Our analysis demonstrates that\nPaCo can adaptively enhance the intensity of pushing samples of the same class\nclose as more samples are pulled together with their corresponding centers and\nbenefit hard example learning. Experiments on long-tailed CIFAR, ImageNet,\nPlaces, and iNaturalist 2018 manifest the new state-of-the-art for long-tailed\nrecognition. On full ImageNet, models trained with PaCo loss surpass supervised\ncontrastive learning across various ResNet backbones, e.g., our ResNet-200\nachieves 81.8% top-1 accuracy. Our code is available at\nhttps://github.com/dvlab-research/Parametric-Contrastive-Learning.", "published": "2021-07-26T08:37:23Z", "version": 2}, {"aid": "2107.12979", "authors": ["Beren Millidge", "Anil Seth", "Christopher L Buckley"], "title": "Predictive Coding: a Theoretical and Experimental Review", "url": "http://arxiv.org/pdf/2107.12979v4", "summary": "Predictive coding offers a potentially unifying account of cortical function\n-- postulating that the core function of the brain is to minimize prediction\nerrors with respect to a generative model of the world. The theory is closely\nrelated to the Bayesian brain framework and, over the last two decades, has\ngained substantial influence in the fields of theoretical and cognitive\nneuroscience. A large body of research has arisen based on both empirically\ntesting improved and extended theoretical and mathematical models of predictive\ncoding, as well as in evaluating their potential biological plausibility for\nimplementation in the brain and the concrete neurophysiological and\npsychological predictions made by the theory. Despite this enduring popularity,\nhowever, no comprehensive review of predictive coding theory, and especially of\nrecent developments in this field, exists. Here, we provide a comprehensive\nreview both of the core mathematical structure and logic of predictive coding,\nthus complementing recent tutorials in the literature. We also review a wide\nrange of classic and recent work within the framework, ranging from the\nneurobiologically realistic microcircuits that could implement predictive\ncoding, to the close relationship between predictive coding and the widely-used\nbackpropagation of error algorithm, as well as surveying the close\nrelationships between predictive coding and modern machine learning techniques.", "published": "2021-07-27T17:44:21Z", "version": 4}, {"aid": "2107.13473", "authors": ["Nicolas Valenchon", "Yann Bouteiller", "Hugo R. Jourde", "Xavier L'Heureux", "Milo Sobral", "Emily B. J. Coffey", "Giovanni Beltrame"], "title": "The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation", "url": "http://arxiv.org/pdf/2107.13473v3", "summary": "Closed-loop brain stimulation refers to capturing neurophysiological measures\nsuch as electroencephalography (EEG), quickly identifying neural events of\ninterest, and producing auditory, magnetic or electrical stimulation so as to\ninteract with brain processes precisely. It is a promising new method for\nfundamental neuroscience and perhaps for clinical applications such as\nrestoring degraded memory function; however, existing tools are expensive,\ncumbersome, and offer limited experimental flexibility. In this article, we\npropose the Portiloop, a deep learning-based, portable and low-cost closed-loop\nstimulation system able to target specific brain oscillations. We first\ndocument open-hardware implementations that can be constructed from\ncommercially available components. We also provide a fast, lightweight neural\nnetwork model and an exploration algorithm that automatically optimizes the\nmodel hyperparameters to the desired brain oscillation. Finally, we validate\nthe technology on a challenging test case of real-time sleep spindle detection,\nwith results comparable to off-line expert performance on the Massive Online\nData Annotation spindle dataset (MODA; group consensus). Software and plans are\navailable to the community as an open science initiative to encourage further\ndevelopment and advance closed-loop neuroscience research.", "published": "2021-07-28T16:29:58Z", "version": 3}, {"aid": "2107.13704", "authors": ["Lenore Blum", "Manuel Blum"], "title": "A Theory of Consciousness from a Theoretical Computer Science Perspective: Insights from the Conscious Turing Machine", "url": "http://arxiv.org/pdf/2107.13704v10", "summary": "The quest to understand consciousness, once the purview of philosophers and\ntheologians, is now actively pursued by scientists of many stripes. We examine\nconsciousness from the perspective of theoretical computer science (TCS), a\nbranch of mathematics concerned with understanding the underlying principles of\ncomputation and complexity, including the implications and surprising\nconsequences of resource limitations. In the spirit of Alan Turing's simple yet\npowerful definition of a computer, the Turing Machine (TM), and perspective of\ncomputational complexity theory, we formalize a modified version of the Global\nWorkspace Theory (GWT) of consciousness originated by cognitive neuroscientist\nBernard Baars and further developed by him, Stanislas Dehaene, Jean-Pierre\nChangeaux and others. We are not looking for a complex model of the brain nor\nof cognition, but for a simple computational model of (the admittedly complex\nconcept of) consciousness. We do this by defining the Conscious Turing Machine\n(CTM), also called a conscious AI, and then we define consciousness and related\nnotions in the CTM. While these are only mathematical (TCS) definitions, we\nsuggest why the CTM has the feeling of consciousness. The TCS perspective\nprovides a simple formal framework to employ tools from computational\ncomplexity theory and machine learning to help us understand consciousness and\nrelated concepts. Previously we explored high level explanations for the\nfeelings of pain and pleasure in the CTM. Here we consider three examples\nrelated to vision (blindsight, inattentional blindness, and change blindness),\nfollowed by discussions of dreams, free will, and altered states of\nconsciousness.", "published": "2021-07-29T01:47:52Z", "version": 10}, {"aid": "2108.00298", "authors": ["Andrea Cini", "Ivan Marisca", "Cesare Alippi"], "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks", "url": "http://arxiv.org/pdf/2108.00298v3", "summary": "Dealing with missing values and incomplete time series is a labor-intensive,\ntedious, inevitable task when handling data coming from real-world\napplications. Effective spatio-temporal representations would allow imputation\nmethods to reconstruct missing temporal data by exploiting information coming\nfrom sensors at different locations. However, standard methods fall short in\ncapturing the nonlinear time and space dependencies existing within networks of\ninterconnected sensors and do not take full advantage of the available - and\noften strong - relational information. Notably, most state-of-the-art\nimputation methods based on deep learning do not explicitly model relational\naspects and, in any case, do not exploit processing frameworks able to\nadequately represent structured spatio-temporal data. Conversely, graph neural\nnetworks have recently surged in popularity as both expressive and scalable\ntools for processing sequential data with relational inductive biases. In this\nwork, we present the first assessment of graph neural networks in the context\nof multivariate time series imputation. In particular, we introduce a novel\ngraph neural network architecture, named GRIN, which aims at reconstructing\nmissing data in the different channels of a multivariate time series by\nlearning spatio-temporal representations through message passing. Empirical\nresults show that our model outperforms state-of-the-art methods in the\nimputation task on relevant real-world benchmarks with mean absolute error\nimprovements often higher than 20%.", "published": "2021-07-31T17:47:10Z", "version": 3}, {"aid": "2108.00996", "authors": ["Pedro C. Neto", "Fadi Boutros", "Jo\u00e3o Ribeiro Pinto", "Mohsen Saffari", "Naser Damer", "Ana F. Sequeira", "Jaime S. Cardoso"], "title": "My Eyes Are Up Here: Promoting Focus on Uncovered Regions in Masked Face Recognition", "url": "http://arxiv.org/pdf/2108.00996v3", "summary": "The recent Covid-19 pandemic and the fact that wearing masks in public is now\nmandatory in several countries, created challenges in the use of face\nrecognition systems (FRS). In this work, we address the challenge of masked\nface recognition (MFR) and focus on evaluating the verification performance in\nFRS when verifying masked vs unmasked faces compared to verifying only unmasked\nfaces. We propose a methodology that combines the traditional triplet loss and\nthe mean squared error (MSE) intending to improve the robustness of an MFR\nsystem in the masked-unmasked comparison mode. The results obtained by our\nproposed method show improvements in a detailed step-wise ablation study. The\nconducted study showed significant performance gains induced by our proposed\ntraining paradigm and modified triplet loss on two evaluation databases.", "published": "2021-08-02T15:51:15Z", "version": 3}, {"aid": "2108.01073", "authors": ["Chenlin Meng", "Yutong He", "Yang Song", "Jiaming Song", "Jiajun Wu", "Jun-Yan Zhu", "Stefano Ermon"], "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations", "url": "http://arxiv.org/pdf/2108.01073v2", "summary": "Guided image synthesis enables everyday users to create and edit\nphoto-realistic images with minimum effort. The key challenge is balancing\nfaithfulness to the user input (e.g., hand-drawn colored strokes) and realism\nof the synthesized image. Existing GAN-based methods attempt to achieve such\nbalance using either conditional GANs or GAN inversions, which are challenging\nand often require additional training data or loss functions for individual\napplications. To address these issues, we introduce a new image synthesis and\nediting method, Stochastic Differential Editing (SDEdit), based on a diffusion\nmodel generative prior, which synthesizes realistic images by iteratively\ndenoising through a stochastic differential equation (SDE). Given an input\nimage with user guide of any type, SDEdit first adds noise to the input, then\nsubsequently denoises the resulting image through the SDE prior to increase its\nrealism. SDEdit does not require task-specific training or inversions and can\nnaturally achieve the balance between realism and faithfulness. SDEdit\nsignificantly outperforms state-of-the-art GAN-based methods by up to 98.09% on\nrealism and 91.72% on overall satisfaction scores, according to a human\nperception study, on multiple tasks, including stroke-based image synthesis and\nediting as well as image compositing.", "published": "2021-08-02T17:59:47Z", "version": 2}, {"aid": "2108.02110", "authors": ["Minyi Zhao", "Yi Xu", "Shuigeng Zhou"], "title": "Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction", "url": "http://arxiv.org/pdf/2108.02110v2", "summary": "A number of deep learning based algorithms have been proposed to recover\nhigh-quality videos from low-quality compressed ones. Among them, some restore\nthe missing details of each frame via exploring the spatiotemporal information\nof neighboring frames. However, these methods usually suffer from a narrow\ntemporal scope, thus may miss some useful details from some frames outside the\nneighboring ones. In this paper, to boost artifact removal, on the one hand, we\npropose a Recursive Fusion (RF) module to model the temporal dependency within\na long temporal range. Specifically, RF utilizes both the current reference\nframes and the preceding hidden state to conduct better spatiotemporal\ncompensation. On the other hand, we design an efficient and effective\nDeformable Spatiotemporal Attention (DSTA) module such that the model can pay\nmore effort on restoring the artifact-rich areas like the boundary area of a\nmoving object. Extensive experiments show that our method outperforms the\nexisting ones on the MFQE 2.0 dataset in terms of both fidelity and perceptual\neffect. Code is available at https://github.com/zhaominyiz/RFDA-PyTorch.", "published": "2021-08-04T15:25:27Z", "version": 2}, {"aid": "2108.02451", "authors": ["Lei Zhu", "Qi She", "Duo Li", "Yanye Lu", "Xuejing Kang", "Jie Hu", "Changhu Wang"], "title": "Unifying Nonlocal Blocks for Neural Networks", "url": "http://arxiv.org/pdf/2108.02451v3", "summary": "The nonlocal-based blocks are designed for capturing long-range\nspatial-temporal dependencies in computer vision tasks. Although having shown\nexcellent performance, they still lack the mechanism to encode the rich,\nstructured information among elements in an image or video. In this paper, to\ntheoretically analyze the property of these nonlocal-based blocks, we provide a\nnew perspective to interpret them, where we view them as a set of graph filters\ngenerated on a fully-connected graph. Specifically, when choosing the Chebyshev\ngraph filter, a unified formulation can be derived for explaining and analyzing\nthe existing nonlocal-based blocks (e.g., nonlocal block, nonlocal stage,\ndouble attention block). Furthermore, by concerning the property of spectral,\nwe propose an efficient and robust spectral nonlocal block, which can be more\nrobust and flexible to catch long-range dependencies when inserted into deep\nneural networks than the existing nonlocal blocks. Experimental results\ndemonstrate the clear-cut improvements and practical applicabilities of our\nmethod on image classification, action recognition, semantic segmentation, and\nperson re-identification tasks.", "published": "2021-08-05T08:34:12Z", "version": 3}, {"aid": "2108.02456", "authors": ["Ke Zhu", "Jianxin Wu"], "title": "Residual Attention: A Simple but Effective Method for Multi-Label Recognition", "url": "http://arxiv.org/pdf/2108.02456v2", "summary": "Multi-label image recognition is a challenging computer vision task of\npractical use. Progresses in this area, however, are often characterized by\ncomplicated methods, heavy computations, and lack of intuitive explanations. To\neffectively capture different spatial regions occupied by objects from\ndifferent categories, we propose an embarrassingly simple module, named\nclass-specific residual attention (CSRA). CSRA generates class-specific\nfeatures for every category by proposing a simple spatial attention score, and\nthen combines it with the class-agnostic average pooling feature. CSRA achieves\nstate-of-the-art results on multilabel recognition, and at the same time is\nmuch simpler than them. Furthermore, with only 4 lines of code, CSRA also leads\nto consistent improvement across many diverse pretrained models and datasets\nwithout any extra training. CSRA is both easy to implement and light in\ncomputations, which also enjoys intuitive explanations and visualizations.", "published": "2021-08-05T08:45:57Z", "version": 2}, {"aid": "2108.06396", "authors": ["Eric Sanchis"], "title": "Free Will: A New Formulation", "url": "http://arxiv.org/pdf/2108.06396v1", "summary": "Free will is sometimes summarised in the philosophical literature as the\nsubjective impression felt by an individual that he or she is the ultimate\nsource or cause of his or her own choices. The two most common arguments for\ndenying the existence of free will come from philosophy and neuroscience. The\nfirst argument is the Consequence Argument. The second asserts that our\ndecisions are first made by the brain and only then become conscious to the\nsubject, taking away the control of the decision. The purpose of these two\narguments is to demonstrate that an individual cannot be the source or primary\ncause of his or her choices. It is shown in this work that the concepts of\nprimary cause and primary source are not adequate to state a solid\ncharacterisation of free will. A new formulation of this property is proposed\nin which it is seen as a three-stage decision-making process implemented by an\nindividual to escape his or her own real or supposed alienation. This\ndecision-making process is represented in the form of a computer model called\nthe PSU (Predictability - Suspension - Unpredictability) model. The\ncompatibility of this new formulation of free will with the feeling it provides\nand the analysis of various situations are then discussed.", "published": "2021-08-05T16:12:24Z", "version": 1}, {"aid": "2108.02874", "authors": ["Sen He", "Wentong Liao", "Michael Ying Yang", "Yi-Zhe Song", "Bodo Rosenhahn", "Tao Xiang"], "title": "Disentangled Lifespan Face Synthesis", "url": "http://arxiv.org/pdf/2108.02874v2", "summary": "A lifespan face synthesis (LFS) model aims to generate a set of\nphoto-realistic face images of a person's whole life, given only one snapshot\nas reference. The generated face image given a target age code is expected to\nbe age-sensitive reflected by bio-plausible transformations of shape and\ntexture, while being identity preserving. This is extremely challenging because\nthe shape and texture characteristics of a face undergo separate and highly\nnonlinear transformations w.r.t. age. Most recent LFS models are based on\ngenerative adversarial networks (GANs) whereby age code conditional\ntransformations are applied to a latent face representation. They benefit\ngreatly from the recent advancements of GANs. However, without explicitly\ndisentangling their latent representations into the texture, shape and identity\nfactors, they are fundamentally limited in modeling the nonlinear age-related\ntransformation on texture and shape whilst preserving identity. In this work, a\nnovel LFS model is proposed to disentangle the key face characteristics\nincluding shape, texture and identity so that the unique shape and texture age\ntransformations can be modeled effectively. This is achieved by extracting\nshape, texture and identity features separately from an encoder. Critically,\ntwo transformation modules, one conditional convolution based and the other\nchannel attention based, are designed for modeling the nonlinear shape and\ntexture feature transformations respectively. This is to accommodate their\nrather distinct aging processes and ensure that our synthesized images are both\nage-sensitive and identity preserving. Extensive experiments show that our LFS\nmodel is clearly superior to the state-of-the-art alternatives. Codes and demo\nare available on our project website:\n\\url{https://senhe.github.io/projects/iccv_2021_lifespan_face}.", "published": "2021-08-05T22:33:14Z", "version": 2}, {"aid": "2108.02924", "authors": ["Xuejiao Tang", "Wenbin Zhang", "Yi Yu", "Kea Turner", "Tyler Derr", "Mengyu Wang", "Eirini Ntoutsi"], "title": "Interpretable Visual Understanding with Cognitive Attention Network", "url": "http://arxiv.org/pdf/2108.02924v3", "summary": "While image understanding on recognition-level has achieved remarkable\nadvancements, reliable visual scene understanding requires comprehensive image\nunderstanding on recognition-level but also cognition-level, which calls for\nexploiting the multi-source information as well as learning different levels of\nunderstanding and extensive commonsense knowledge. In this paper, we propose a\nnovel Cognitive Attention Network (CAN) for visual commonsense reasoning to\nachieve interpretable visual understanding. Specifically, we first introduce an\nimage-text fusion module to fuse information from images and text collectively.\nSecond, a novel inference module is designed to encode commonsense among image,\nquery and response. Extensive experiments on large-scale Visual Commonsense\nReasoning (VCR) benchmark dataset demonstrate the effectiveness of our\napproach. The implementation is publicly available at\nhttps://github.com/tanjatang/CAN", "published": "2021-08-06T02:57:43Z", "version": 3}, {"aid": "2108.03002", "authors": ["Hongbing Zhang", "Xinyi Liu", "Hongtao Fan", "Yajing Li", "Yinlin Ye"], "title": "Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm", "url": "http://arxiv.org/pdf/2108.03002v4", "summary": "The low rank tensor completion (LRTC) problem has attracted great attention\nin computer vision and signal processing. How to acquire high quality image\nrecovery effect is still an urgent task to be solved at present. This paper\nproposes a new tensor $L_{2,1}$ norm minimization model (TLNM) that integrates\nsum nuclear norm (SNN) method, differing from the classical tensor nuclear norm\n(TNN)-based tensor completion method, with $L_{2,1}$ norm and Qatar Riyal\ndecomposition for solving the LRTC problem. To improve the utilization rate of\nthe local prior information of the image, a total variation (TV) regularization\nterm is introduced, resulting in a new class of tensor $L_{2,1}$ norm\nminimization with total variation model (TLNMTV). Both proposed models are\nconvex and therefore have global optimal solutions. Moreover, we adopt the\nAlternating Direction Multiplier Method (ADMM) to obtain the closed-form\nsolution of each variable, thus ensuring the feasibility of the algorithm.\nNumerical experiments show that the two proposed algorithms are convergent and\noutperform compared methods. In particular, our method significantly\noutperforms the contrastive methods when the sampling rate of hyperspectral\nimages is 2.5\\%.", "published": "2021-08-06T08:35:33Z", "version": 4}, {"aid": "2108.05713", "authors": ["Shu Ishida", "Jo\u00e3o F. Henriques"], "title": "Towards real-world navigation with deep differentiable planners", "url": "http://arxiv.org/pdf/2108.05713v2", "summary": "We train embodied neural networks to plan and navigate unseen complex 3D\nenvironments, emphasising real-world deployment. Rather than requiring prior\nknowledge of the agent or environment, the planner learns to model the state\ntransitions and rewards. To avoid the potentially hazardous trial-and-error of\nreinforcement learning, we focus on differentiable planners such as Value\nIteration Networks (VIN), which are trained offline from safe expert\ndemonstrations. Although they work well in small simulations, we address two\nmajor limitations that hinder their deployment. First, we observed that current\ndifferentiable planners struggle to plan long-term in environments with a high\nbranching complexity. While they should ideally learn to assign low rewards to\nobstacles to avoid collisions, we posit that the constraints imposed on the\nnetwork are not strong enough to guarantee the network to learn sufficiently\nlarge penalties for every possible collision. We thus impose a structural\nconstraint on the value iteration, which explicitly learns to model any\nimpossible actions. Secondly, we extend the model to work with a limited\nperspective camera under translation and rotation, which is crucial for real\nrobot deployment. Many VIN-like planners assume a 360 degrees or overhead view\nwithout rotation. In contrast, our method uses a memory-efficient lattice map\nto aggregate CNN embeddings of partial observations, and models the rotational\ndynamics explicitly using a 3D state-space grid (translation and rotation). Our\nproposals significantly improve semantic navigation and exploration on several\n2D and 3D environments, succeeding in settings that are otherwise challenging\nfor this class of methods. As far as we know, we are the first to successfully\nperform differentiable planning on the difficult Active Vision Dataset,\nconsisting of real images captured from a robot.", "published": "2021-08-08T11:29:16Z", "version": 2}, {"aid": "2108.03830", "authors": ["Kun Wang", "Zhenyu Zhang", "Zhiqiang Yan", "Xiang Li", "Baobei Xu", "Jun Li", "Jian Yang"], "title": "Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark", "url": "http://arxiv.org/pdf/2108.03830v2", "summary": "Monocular depth estimation aims at predicting depth from a single image or\nvideo. Recently, self-supervised methods draw much attention since they are\nfree of depth annotations and achieve impressive performance on several daytime\nbenchmarks. However, they produce weird outputs in more challenging nighttime\nscenarios because of low visibility and varying illuminations, which bring weak\ntextures and break brightness-consistency assumption, respectively. To address\nthese problems, in this paper we propose a novel framework with several\nimprovements: (1) we introduce Priors-Based Regularization to learn\ndistribution knowledge from unpaired depth maps and prevent model from being\nincorrectly trained; (2) we leverage Mapping-Consistent Image Enhancement\nmodule to enhance image visibility and contrast while maintaining brightness\nconsistency; and (3) we present Statistics-Based Mask strategy to tune the\nnumber of removed pixels within textureless regions, using dynamic statistics.\nExperimental results demonstrate the effectiveness of each component.\nMeanwhile, our framework achieves remarkable improvements and state-of-the-art\nresults on two nighttime datasets.", "published": "2021-08-09T06:24:35Z", "version": 2}, {"aid": "2108.04316", "authors": ["Ricardo Andres Diaz Rincon"], "title": "Generating Music and Generative Art from Brain activity", "url": "http://arxiv.org/pdf/2108.04316v2", "summary": "Nowadays, technological advances have influenced all human activities,\ncreating new dynamics and ways of communication. In this context, some artists\nhave incorporated these advances in their creative process, giving rise to\nunique aesthetic expressions referred to in the literature as Generative Art,\nwhich is characterized by assigning part of the creative process to a system\nthat acts with certain autonomy (Galanter, 2003).\n  This research work introduces a computational system for creating generative\nart using a Brain-Computer Interface (BCI) which portrays the user's brain\nactivity in a digital artwork. In this way, the user takes an active role in\nthe creative process. In aims of showing that the proposed system materializes\nin an artistic piece the user's mental states by means of a visual and sound\nrepresentation, several tests are carried out to ensure the reliability of the\nBCI device sent data.\n  The generated artwork uses brain signals and concepts of geometry, color and\nspatial location to give complexity to the autonomous construction. As an added\nvalue, the visual and auditory production is accompanied by an olfactory and\nkinesthetic component which complements the art pieces providing a multimodal\ncommunication character.", "published": "2021-08-09T19:33:45Z", "version": 2}, {"aid": "2108.04526", "authors": ["Qingpeng Cai", "Can Cui", "Yiyuan Xiong", "Wei Wang", "Zhongle Xie", "Meihui Zhang"], "title": "A Survey on Deep Reinforcement Learning for Data Processing and Analytics", "url": "http://arxiv.org/pdf/2108.04526v3", "summary": "Data processing and analytics are fundamental and pervasive. Algorithms play\na vital role in data processing and analytics where many algorithm designs have\nincorporated heuristics and general rules from human knowledge and experience\nto improve their effectiveness. Recently, reinforcement learning, deep\nreinforcement learning (DRL) in particular, is increasingly explored and\nexploited in many areas because it can learn better strategies in complicated\nenvironments it is interacting with than statically designed algorithms.\nMotivated by this trend, we provide a comprehensive review of recent works\nfocusing on utilizing DRL to improve data processing and analytics. First, we\npresent an introduction to key concepts, theories, and methods in DRL. Next, we\ndiscuss DRL deployment on database systems, facilitating data processing and\nanalytics in various aspects, including data organization, scheduling, tuning,\nand indexing. Then, we survey the application of DRL in data processing and\nanalytics, ranging from data preparation, natural language processing to\nhealthcare, fintech, etc. Finally, we discuss important open challenges and\nfuture research directions of using DRL in data processing and analytics.", "published": "2021-08-10T09:14:03Z", "version": 3}, {"aid": "2108.04893", "authors": ["Mahdi Pourmirzaei", "Farzaneh Esmaili", "Ebrahim Mousavi", "Sasan Karamizadeh", "Seyedehsamaneh Shojaeilangari"], "title": "How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?", "url": "http://arxiv.org/pdf/2108.04893v6", "summary": "The cost of head pose labeling is the main challenge of improving the\nfine-grained Head Pose Estimation (HPE). Although Self-Supervised Learning\n(SSL) can be a solution to the lack of huge amounts of labeled data, its\nefficacy for fine-grained HPE is not yet fully explored. This study aims to\nassess the usage of SSL in fine-grained HPE based on two scenarios: (1) using\nSSL for weights pre-training procedure, and (2) leveraging auxiliary SSL losses\nbesides HPE. We design a Hybrid Multi-Task Learning (HMTL) architecture based\non the ResNet50 backbone in which both strategies are applied. Our experimental\nresults reveal that the combination of both scenarios is the best for HPE.\nTogether, the average error rate is reduced up to 23.1% for AFLW2000 and 14.2%\nfor BIWI benchmark compared to the baseline. Moreover, it is found that some\nSSL methods are more suitable for transfer learning, while others may be\neffective when they are considered as auxiliary tasks incorporated into\nsupervised learning. Finally, it is shown that by using the proposed HMTL\narchitecture, the average error is reduced with different types of initial\nweights: random, ImageNet and SSL pre-trained weights.", "published": "2021-08-10T19:34:45Z", "version": 6}, {"aid": "2108.04936", "authors": ["James V Stone"], "title": "Using Information Theory to Measure Psychophysical Performance", "url": "http://arxiv.org/pdf/2108.04936v3", "summary": "Most psychophysical experiments discard half the data collected.\nSpecifically, experiments discard reaction time data, and use binary responses\n(e.g. yes/no) to measure performance. Here, Shannon's information theory is\nused to define Shannon competence $s'$, which depends on the mutual information\nbetween stimulus strength (e.g. luminance) and a combination of reaction times\nand binary responses. Mutual information is the entropy of the joint\ndistribution of responses minus the residual entropy after a model has been\nfitted to these responses. Here, this model is instantiated as a proportional\nrate diffusion model, with the additional innovation that the full covariance\nstructure of responses is taken into account. Results suggest information\nassociated with reaction times is independent of (i.e. additional to)\ninformation associated with binary responses, and that reaction time and binary\nresponses together provide substantially more than the sum of their individual\ncontributions (i.e. they act synergistically). Consequently, the additional\ninformation supplied by reaction times suggests that using combined reaction\ntime and binary responses requires fewer stimulus presentations, without loss\nof precision in psychophysical parameters. Finally, because s' takes account of\nboth reaction time and binary responses, (and in contrast to d') $s'$ is immune\nto speed-accuracy trade-offs, which vary between observers and experimental\ndesigns.", "published": "2021-08-10T21:47:57Z", "version": 3}, {"aid": "2108.05061", "authors": ["Guangyi Xiao", "Weiwei Xiang", "Huan Liu", "Hao Chen", "Shun Peng", "Jingzhi Guo", "Zhiguo Gong"], "title": "NI-UDA: Graph Adversarial Domain Adaptation from Non-shared-and-Imbalanced Big Data to Small Imbalanced Applications", "url": "http://arxiv.org/pdf/2108.05061v2", "summary": "We propose a new general Graph Adversarial Domain Adaptation (GADA) based on\nsemantic knowledge reasoning of class structure for solving the problem of\nunsupervised domain adaptation (UDA) from the big data with non-shared and\nimbalanced classes to specified small and imbalanced applications (NI-UDA),\nwhere non-shared classes mean the label space out of the target domain. Our\ngoal is to leverage priori hierarchy knowledge to enhance domain adversarial\naligned feature representation with graph reasoning. In this paper, to address\ntwo challenges in NI-UDA, we equip adversarial domain adaptation with Hierarchy\nGraph Reasoning (HGR) layer and the Source Classifier Filter (SCF). For sparse\nclasses transfer challenge, our HGR layer can aggregate local feature to\nhierarchy graph nodes by node prediction and enhance domain adversarial aligned\nfeature with hierarchy graph reasoning for sparse classes. Our HGR contributes\nto learn direct semantic patterns for sparse classes by hierarchy attention in\nself-attention, non-linear mapping and graph normalization. our SCF is proposed\nfor the challenge of knowledge sharing from non-shared data without negative\ntransfer effect by filtering low-confidence non-shared data in HGR layer.\nExperiments on two benchmark datasets show our GADA methods consistently\nimprove the state-of-the-art adversarial UDA algorithms, e.g. GADA(HGR) can\ngreatly improve f1 of the MDD by \\textbf{7.19\\%} and GVB-GD by \\textbf{7.89\\%}\nrespectively on imbalanced source task in Meal300 dataset. The code is\navailable at https://gadatransfer.wixsite.com/gada.", "published": "2021-08-11T07:01:13Z", "version": 2}, {"aid": "2108.05080", "authors": ["Hasam Khalid", "Shahroz Tariq", "Minha Kim", "Simon S. Woo"], "title": "FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset", "url": "http://arxiv.org/pdf/2108.05080v4", "summary": "While the significant advancements have made in the generation of deepfakes\nusing deep learning technologies, its misuse is a well-known issue now.\nDeepfakes can cause severe security and privacy issues as they can be used to\nimpersonate a person's identity in a video by replacing his/her face with\nanother person's face. Recently, a new problem of generating synthesized human\nvoice of a person is emerging, where AI-based deep learning models can\nsynthesize any person's voice requiring just a few seconds of audio. With the\nemerging threat of impersonation attacks using deepfake audios and videos, a\nnew generation of deepfake detectors is needed to focus on both video and audio\ncollectively. To develop a competent deepfake detector, a large amount of\nhigh-quality data is typically required to capture real-world (or practical)\nscenarios. Existing deepfake datasets either contain deepfake videos or audios,\nwhich are racially biased as well. As a result, it is critical to develop a\nhigh-quality video and audio deepfake dataset that can be used to detect both\naudio and video deepfakes simultaneously. To fill this gap, we propose a novel\nAudio-Video Deepfake dataset, FakeAVCeleb, which contains not only deepfake\nvideos but also respective synthesized lip-synced fake audios. We generate this\ndataset using the most popular deepfake generation methods. We selected real\nYouTube videos of celebrities with four ethnic backgrounds to develop a more\nrealistic multimodal dataset that addresses racial bias, and further help\ndevelop multimodal deepfake detectors. We performed several experiments using\nstate-of-the-art detection methods to evaluate our deepfake dataset and\ndemonstrate the challenges and usefulness of our multimodal Audio-Video\ndeepfake dataset.", "published": "2021-08-11T07:49:36Z", "version": 4}, {"aid": "2108.05278", "authors": ["Xin Mao", "Wenting Wang", "Yuanbin Wu", "Man Lan"], "title": "Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness", "url": "http://arxiv.org/pdf/2108.05278v2", "summary": "Entity alignment (EA) aims to find the equivalent entities in different KGs,\nwhich is a crucial step in integrating multiple KGs. However, most existing EA\nmethods have poor scalability and are unable to cope with large-scale datasets.\nWe summarize three issues leading to such high time-space complexity in\nexisting EA methods: (1) Inefficient graph encoders, (2) Dilemma of negative\nsampling, and (3) \"Catastrophic forgetting\" in semi-supervised learning. To\naddress these challenges, we propose a novel EA method with three new\ncomponents to enable high Performance, high Scalability, and high Robustness\n(PSR): (1) Simplified graph encoder with relational graph sampling, (2)\nSymmetric negative-free alignment loss, and (3) Incremental semi-supervised\nlearning. Furthermore, we conduct detailed experiments on several public\ndatasets to examine the effectiveness and efficiency of our proposed method.\nThe experimental results show that PSR not only surpasses the previous SOTA in\nperformance but also has impressive scalability and robustness.", "published": "2021-08-11T15:20:41Z", "version": 2}, {"aid": "2108.05305", "authors": ["Hong-Yu Zhou", "Chixiang Lu", "Sibei Yang", "Yizhou Yu"], "title": "ConvNets vs. Transformers: Whose Visual Representations are More Transferable?", "url": "http://arxiv.org/pdf/2108.05305v2", "summary": "Vision transformers have attracted much attention from computer vision\nresearchers as they are not restricted to the spatial inductive bias of\nConvNets. However, although Transformer-based backbones have achieved much\nprogress on ImageNet classification, it is still unclear whether the learned\nrepresentations are as transferable as or even more transferable than ConvNets'\nfeatures. To address this point, we systematically investigate the transfer\nlearning ability of ConvNets and vision transformers in 15 single-task and\nmulti-task performance evaluations. Given the strong correlation between the\nperformance of pre-trained models and transfer learning, we include 2 residual\nConvNets (i.e., R-101x3 and R-152x4) and 3 Transformer-based visual backbones\n(i.e., ViT-B, ViT-L and Swin-B), which have close error rates on ImageNet, that\nindicate similar transfer learning performance on downstream datasets.\n  We observe consistent advantages of Transformer-based backbones on 13\ndownstream tasks (out of 15), including but not limited to fine-grained\nclassification, scene recognition (classification, segmentation and depth\nestimation), open-domain classification, face recognition, etc. More\nspecifically, we find that two ViT models heavily rely on whole network\nfine-tuning to achieve performance gains while Swin Transformer does not have\nsuch a requirement. Moreover, vision transformers behave more robustly in\nmulti-task learning, i.e., bringing more improvements when managing mutually\nbeneficial tasks and reducing performance losses when tackling irrelevant\ntasks. We hope our discoveries can facilitate the exploration and exploitation\nof vision transformers in the future.", "published": "2021-08-11T16:20:38Z", "version": 2}, {"aid": "2108.05390", "authors": ["Jiahao Chen", "Victor Storchan"], "title": "Seven challenges for harmonizing explainability requirements", "url": "http://arxiv.org/pdf/2108.05390v1", "summary": "Regulators have signalled an interest in adopting explainable AI(XAI)\ntechniques to handle the diverse needs for model governance, operational\nservicing, and compliance in the financial services industry. In this short\noverview, we review the recent technical literature in XAI and argue that based\non our current understanding of the field, the use of XAI techniques in\npractice necessitate a highly contextualized approach considering the specific\nneeds of stakeholders for particular business applications.", "published": "2021-08-11T18:10:24Z", "version": 1}, {"aid": "2108.05449", "authors": ["Wei Zhu", "Haitian Zheng", "Haofu Liao", "Weijian Li", "Jiebo Luo"], "title": "Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization", "url": "http://arxiv.org/pdf/2108.05449v2", "summary": "Deep learning algorithms mine knowledge from the training data and thus would\nlikely inherit the dataset's bias information. As a result, the obtained model\nwould generalize poorly and even mislead the decision process in real-life\napplications. We propose to remove the bias information misused by the target\ntask with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly\nextracts target and bias features disentangled from the latent representation\ngenerated by a feature extractor and then learns to discover and remove the\ncorrelation between the target and bias features. The correlation measurement\nplays a critical role in adversarial debiasing and is conducted by a\ncross-sample neural mutual information estimator. Moreover, we propose joint\ncontent and local structural representation learning to boost mutual\ninformation estimation for better performance. We conduct thorough experiments\non publicly available datasets to validate the advantages of the proposed\nmethod over state-of-the-art approaches.", "published": "2021-08-11T21:17:02Z", "version": 2}, {"aid": "2108.05479", "authors": ["Shreya Ghosh", "Abhinav Dhall", "Munawar Hayat", "Jarrod Knibbe", "Qiang Ji"], "title": "Automatic Gaze Analysis: A Survey of Deep Learning based Approaches", "url": "http://arxiv.org/pdf/2108.05479v3", "summary": "Eye gaze analysis is an important research problem in the field of Computer\nVision and Human-Computer Interaction. Even with notable progress in the last\n10 years, automatic gaze analysis still remains challenging due to the\nuniqueness of eye appearance, eye-head interplay, occlusion, image quality, and\nillumination conditions. There are several open questions, including what are\nthe important cues to interpret gaze direction in an unconstrained environment\nwithout prior knowledge and how to encode them in real-time. We review the\nprogress across a range of gaze analysis tasks and applications to elucidate\nthese fundamental questions, identify effective methods in gaze analysis, and\nprovide possible future directions. We analyze recent gaze estimation and\nsegmentation methods, especially in the unsupervised and weakly supervised\ndomain, based on their advantages and reported evaluation metrics. Our analysis\nshows that the development of a robust and generic gaze analysis method still\nneeds to address real-world challenges such as unconstrained setup and learning\nwith less supervision. We conclude by discussing future research directions for\ndesigning a real-world gaze analysis system that can propagate to other domains\nincluding Computer Vision, Augmented Reality (AR), Virtual Reality (VR), and\nHuman Computer Interaction (HCI). Project Page:\nhttps://github.com/i-am-shreya/EyeGazeSurvey}{https://github.com/i-am-shreya/EyeGazeSurvey", "published": "2021-08-12T00:30:39Z", "version": 3}, {"aid": "2108.05494", "authors": ["Ananta Nair"], "title": "A Mathematical Approach to Constraining Neural Abstraction and the Mechanisms Needed to Scale to Higher-Order Cognition", "url": "http://arxiv.org/pdf/2108.05494v1", "summary": "Artificial intelligence has made great strides in the last decade but still\nfalls short of the human brain, the best-known example of intelligence. Not\nmuch is known of the neural processes that allow the brain to make the leap to\nachieve so much from so little beyond its ability to create knowledge\nstructures that can be flexibly and dynamically combined, recombined, and\napplied in new and novel ways. This paper proposes a mathematical approach\nusing graph theory and spectral graph theory, to hypothesize how to constrain\nthese neural clusters of information based on eigen-relationships. This same\nhypothesis is hierarchically applied to scale up from the smallest to the\nlargest clusters of knowledge that eventually lead to model building and\nreasoning.", "published": "2021-08-12T02:13:22Z", "version": 1}, {"aid": "2108.05580", "authors": ["Aditya Rajagopal", "Christos-Savvas Bouganis"], "title": "perf4sight: A toolflow to model CNN training performance on Edge GPUs", "url": "http://arxiv.org/pdf/2108.05580v1", "summary": "The increased memory and processing capabilities of today's edge devices\ncreate opportunities for greater edge intelligence. In the domain of vision,\nthe ability to adapt a Convolutional Neural Network's (CNN) structure and\nparameters to the input data distribution leads to systems with lower memory\nfootprint, latency and power consumption. However, due to the limited compute\nresources and memory budget on edge devices, it is necessary for the system to\nbe able to predict the latency and memory footprint of the training process in\norder to identify favourable training configurations of the network topology\nand device combination for efficient network adaptation. This work proposes\nperf4sight, an automated methodology for developing accurate models that\npredict CNN training memory footprint and latency given a target device and\nnetwork. This enables rapid identification of network topologies that can be\nretrained on the edge device with low resource consumption. With PyTorch as the\nframework and NVIDIA Jetson TX2 as the target device, the developed models\npredict training memory footprint and latency with 95% and 91% accuracy\nrespectively for a wide range of networks, opening the path towards efficient\nnetwork adaptation on edge GPUs.", "published": "2021-08-12T07:55:37Z", "version": 1}, {"aid": "2108.05623", "authors": ["El Mehdi Achour", "Fran\u00e7ois Malgouyres", "Franck Mamalet"], "title": "Existence, Stability and Scalability of Orthogonal Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2108.05623v3", "summary": "Imposing orthogonality on the layers of neural networks is known to\nfacilitate the learning by limiting the exploding/vanishing of the gradient;\ndecorrelate the features; improve the robustness. This paper studies the\ntheoretical properties of orthogonal convolutional layers.We establish\nnecessary and sufficient conditions on the layer architecture guaranteeing the\nexistence of an orthogonal convolutional transform. The conditions prove that\northogonal convolutional transforms exist for almost all architectures used in\npractice for 'circular' padding.We also exhibit limitations with 'valid'\nboundary conditions and 'same' boundary conditions with zero-padding.Recently,\na regularization term imposing the orthogonality of convolutional layers has\nbeen proposed, and impressive empirical results have been obtained in different\napplications (Wang et al. 2020).The second motivation of the present paper is\nto specify the theory behind this.We make the link between this regularization\nterm and orthogonality measures. In doing so, we show that this regularization\nstrategy is stable with respect to numerical and optimization errors and that,\nin the presence of small errors and when the size of the signal/image is large,\nthe convolutional layers remain close to isometric.The theoretical results are\nconfirmed with experiments and the landscape of the regularization term is\nstudied. Experiments on real data sets show that when orthogonality is used to\nenforce robustness, the parameter multiplying the regularization termcan be\nused to tune a tradeoff between accuracy and orthogonality, for the benefit of\nboth accuracy and robustness.Altogether, the study guarantees that the\nregularization proposed in Wang et al. (2020) is an efficient, flexible and\nstable numerical strategy to learn orthogonal convolutional layers.", "published": "2021-08-12T09:30:53Z", "version": 3}, {"aid": "2108.05839", "authors": ["Aman Gupta", "Rohan Ramanath", "Jun Shi", "Anika Ramachandran", "Sirou Zhou", "Mingzhou Zhou", "S. Sathiya Keerthi"], "title": "Logit Attenuating Weight Normalization", "url": "http://arxiv.org/pdf/2108.05839v1", "summary": "Over-parameterized deep networks trained using gradient-based optimizers are\na popular choice for solving classification and ranking problems. Without\nappropriately tuned $\\ell_2$ regularization or weight decay, such networks have\nthe tendency to make output scores (logits) and network weights large, causing\ntraining loss to become too small and the network to lose its adaptivity\n(ability to move around) in the parameter space. Although regularization is\ntypically understood from an overfitting perspective, we highlight its role in\nmaking the network more adaptive and enabling it to escape more easily from\nweights that generalize poorly. To provide such a capability, we propose a\nmethod called Logit Attenuating Weight Normalization (LAWN), that can be\nstacked onto any gradient-based optimizer. LAWN controls the logits by\nconstraining the weight norms of layers in the final homogeneous sub-network.\nEmpirically, we show that the resulting LAWN variant of the optimizer makes a\ndeep network more adaptive to finding minimas with superior generalization\nperformance on large-scale image classification and recommender systems. While\nLAWN is particularly impressive in improving Adam, it greatly improves all\noptimizers when used with large batch sizes", "published": "2021-08-12T16:44:24Z", "version": 1}, {"aid": "2108.05862", "authors": ["Duo Li", "Shang-Hua Gao"], "title": "m-RevNet: Deep Reversible Neural Networks with Momentum", "url": "http://arxiv.org/pdf/2108.05862v2", "summary": "In recent years, the connections between deep residual networks and\nfirst-order Ordinary Differential Equations (ODEs) have been disclosed. In this\nwork, we further bridge the deep neural architecture design with the\nsecond-order ODEs and propose a novel reversible neural network, termed as\nm-RevNet, that is characterized by inserting momentum update to residual\nblocks. The reversible property allows us to perform backward pass without\naccess to activation values of the forward pass, greatly relieving the storage\nburden during training. Furthermore, the theoretical foundation based on\nsecond-order ODEs grants m-RevNet with stronger representational power than\nvanilla residual networks, which potentially explains its performance gains.\nFor certain learning scenarios, we analytically and empirically reveal that our\nm-RevNet succeeds while standard ResNet fails. Comprehensive experiments on\nvarious image classification and semantic segmentation benchmarks demonstrate\nthe superiority of our m-RevNet over ResNet, concerning both memory efficiency\nand recognition performance.", "published": "2021-08-12T17:14:32Z", "version": 2}, {"aid": "2108.05889", "authors": ["Wenliang Zhao", "Yongming Rao", "Ziyi Wang", "Jiwen Lu", "Jie Zhou"], "title": "Towards Interpretable Deep Metric Learning with Structural Matching", "url": "http://arxiv.org/pdf/2108.05889v1", "summary": "How do the neural networks distinguish two images? It is of critical\nimportance to understand the matching mechanism of deep models for developing\nreliable intelligent systems for many risky visual applications such as\nsurveillance and access control. However, most existing deep metric learning\nmethods match the images by comparing feature vectors, which ignores the\nspatial structure of images and thus lacks interpretability. In this paper, we\npresent a deep interpretable metric learning (DIML) method for more transparent\nembedding learning. Unlike conventional metric learning methods based on\nfeature vector comparison, we propose a structural matching strategy that\nexplicitly aligns the spatial embeddings by computing an optimal matching flow\nbetween feature maps of the two images. Our method enables deep models to learn\nmetrics in a more human-friendly way, where the similarity of two images can be\ndecomposed to several part-wise similarities and their contributions to the\noverall similarity. Our method is model-agnostic, which can be applied to\noff-the-shelf backbone networks and metric learning methods. We evaluate our\nmethod on three major benchmarks of deep metric learning including CUB200-2011,\nCars196, and Stanford Online Products, and achieve substantial improvements\nover popular metric learning methods with better interpretability. Code is\navailable at https://github.com/wl-zhao/DIML", "published": "2021-08-12T17:59:09Z", "version": 1}, {"aid": "2108.05892", "authors": ["Chris Rockwell", "David F. Fouhey", "Justin Johnson"], "title": "PixelSynth: Generating a 3D-Consistent Experience from a Single Image", "url": "http://arxiv.org/pdf/2108.05892v1", "summary": "Recent advancements in differentiable rendering and 3D reasoning have driven\nexciting results in novel view synthesis from a single image. Despite realistic\nresults, methods are limited to relatively small view change. In order to\nsynthesize immersive scenes, models must also be able to extrapolate. We\npresent an approach that fuses 3D reasoning with autoregressive modeling to\noutpaint large view changes in a 3D-consistent manner, enabling scene\nsynthesis. We demonstrate considerable improvement in single image large-angle\nview synthesis results compared to a variety of methods and possible variants\nacross simulated and real datasets. In addition, we show increased 3D\nconsistency compared to alternative accumulation methods. Project website:\nhttps://crockwell.github.io/pixelsynth/", "published": "2021-08-12T17:59:31Z", "version": 1}, {"aid": "2108.05894", "authors": ["Yunsheng Li", "Yinpeng Chen", "Xiyang Dai", "Dongdong Chen", "Mengchen Liu", "Lu Yuan", "Zicheng Liu", "Lei Zhang", "Nuno Vasconcelos"], "title": "MicroNet: Improving Image Recognition with Extremely Low FLOPs", "url": "http://arxiv.org/pdf/2108.05894v1", "summary": "This paper aims at addressing the problem of substantial performance\ndegradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet\nclassification). We found that two factors, sparse connectivity and dynamic\nactivation function, are effective to improve the accuracy. The former avoids\nthe significant reduction of network width, while the latter mitigates the\ndetriment of reduction in network depth. Technically, we propose\nmicro-factorized convolution, which factorizes a convolution matrix into low\nrank matrices, to integrate sparse connectivity into convolution. We also\npresent a new dynamic activation function, named Dynamic Shift Max, to improve\nthe non-linearity via maxing out multiple dynamic fusions between an input\nfeature map and its circular channel shift. Building upon these two new\noperators, we arrive at a family of networks, named MicroNet, that achieves\nsignificant performance gains over the state of the art in the low FLOP regime.\nFor instance, under the constraint of 12M FLOPs, MicroNet achieves 59.4\\% top-1\naccuracy on ImageNet classification, outperforming MobileNetV3 by 9.6\\%. Source\ncode is at\n\\href{https://github.com/liyunsheng13/micronet}{https://github.com/liyunsheng13/micronet}.", "published": "2021-08-12T17:59:41Z", "version": 1}, {"aid": "2108.05895", "authors": ["Yinpeng Chen", "Xiyang Dai", "Dongdong Chen", "Mengchen Liu", "Xiaoyi Dong", "Lu Yuan", "Zicheng Liu"], "title": "Mobile-Former: Bridging MobileNet and Transformer", "url": "http://arxiv.org/pdf/2108.05895v3", "summary": "We present Mobile-Former, a parallel design of MobileNet and transformer with\na two-way bridge in between. This structure leverages the advantages of\nMobileNet at local processing and transformer at global interaction. And the\nbridge enables bidirectional fusion of local and global features. Different\nfrom recent works on vision transformer, the transformer in Mobile-Former\ncontains very few tokens (e.g. 6 or fewer tokens) that are randomly initialized\nto learn global priors, resulting in low computational cost. Combining with the\nproposed light-weight cross attention to model the bridge, Mobile-Former is not\nonly computationally efficient, but also has more representation power. It\noutperforms MobileNetV3 at low FLOP regime from 25M to 500M FLOPs on ImageNet\nclassification. For instance, Mobile-Former achieves 77.9\\% top-1 accuracy at\n294M FLOPs, gaining 1.3\\% over MobileNetV3 but saving 17\\% of computations.\nWhen transferring to object detection, Mobile-Former outperforms MobileNetV3 by\n8.6 AP in RetinaNet framework. Furthermore, we build an efficient end-to-end\ndetector by replacing backbone, encoder and decoder in DETR with Mobile-Former,\nwhich outperforms DETR by 1.1 AP but saves 52\\% of computational cost and 36\\%\nof parameters.", "published": "2021-08-12T17:59:55Z", "version": 3}, {"aid": "2108.06065", "authors": ["John Rohrlich", "Randall C. O'Reilly"], "title": "Statistical Learning in Speech: A Biologically Based Predictive Learning Model", "url": "http://arxiv.org/pdf/2108.06065v1", "summary": "Infants, adults, non-human primates and non-primates all learn patterns\nimplicitly, and they do so across modalities. The biological evidence supports\nthe hypothesis that the mechanism for this learning is general but\ncomputationally local. We hypothesize that the mechanism itself is predictive\nerror-driven learning. We build on recent work that advanced a biologically\nplausible model of error backpropagation learning which proposes that higher\norder thalamic nuclei provide a locale for a temporal difference between\ntop-down predictions and an actual event outcome. Our neural network based on\nthat work also models the auditory cortex hierarchy of core, belt and parabelt\nand the caudal-rostral axis within regions. We simulated two studies showing\nstatistical learning in infants, a seminal study using synthesized speech and a\nmore recent study using human speech. Before simulating these studies the\nnetwork was trained on spoken sentences from the TIMIT corpus to emulate\ninfant's experience listening to random speech. The implemented neural network,\nlearning only by predicting the next brief speech segment, learned in both\nsimulations to predict in-word syllables better than next-word syllables\nshowing that prediction could be the basis for word segmentation and thus\nstatistical learning.", "published": "2021-08-13T05:14:49Z", "version": 1}, {"aid": "2108.06128", "authors": ["Md Mohaimenuzzaman", "Christoph Bergmeir", "Bernd Meyer"], "title": "Pruning vs XNOR-Net: A Comprehensive Study of Deep Learning for Audio Classification on Edge-devices", "url": "http://arxiv.org/pdf/2108.06128v3", "summary": "Deep learning has celebrated resounding successes in many application areas\nof relevance to the Internet of Things (IoT), such as computer vision and\nmachine listening. These technologies must ultimately be brought directly to\nthe edge to fully harness the power of deep learning for the IoT. The obvious\nchallenge is that deep learning techniques can only be implemented on strictly\nresource-constrained edge devices if the models are radically downsized. This\ntask relies on different model compression techniques, such as network pruning,\nquantization, and the recent advancement of XNOR-Net. This study examines the\nsuitability of these techniques for audio classification on microcontrollers.\nWe present an application of XNOR-Net for end-to-end raw audio classification\nand a comprehensive empirical study comparing this approach with\npruning-and-quantization methods. We show that raw audio classification with\nXNOR yields comparable performance to regular full precision networks for small\nnumbers of classes while reducing memory requirements 32-fold and computation\nrequirements 58-fold. However, as the number of classes increases\nsignificantly, performance degrades, and pruning-and-quantization based\ncompression techniques take over as the preferred technique being able to\nsatisfy the same space constraints but requiring approximately 8x more\ncomputation. We show that these insights are consistent between raw audio\nclassification and image classification using standard benchmark sets. To the\nbest of our knowledge, this is the first study to apply XNOR to end-to-end\naudio classification and evaluate it in the context of alternative techniques.\nAll codes are publicly available on GitHub.", "published": "2021-08-13T09:07:45Z", "version": 3}, {"aid": "2108.06129", "authors": ["Zhongyi Han", "Haoliang Sun", "Yilong Yin"], "title": "Learning Transferable Parameters for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/2108.06129v1", "summary": "Unsupervised domain adaptation (UDA) enables a learning machine to adapt from\na labeled source domain to an unlabeled domain under the distribution shift.\nThanks to the strong representation ability of deep neural networks, recent\nremarkable achievements in UDA resort to learning domain-invariant features.\nIntuitively, the hope is that a good feature representation, together with the\nhypothesis learned from the source domain, can generalize well to the target\ndomain. However, the learning processes of domain-invariant features and source\nhypothesis inevitably involve domain-specific information that would degrade\nthe generalizability of UDA models on the target domain. In this paper,\nmotivated by the lottery ticket hypothesis that only partial parameters are\nessential for generalization, we find that only partial parameters are\nessential for learning domain-invariant information and generalizing well in\nUDA. Such parameters are termed transferable parameters. In contrast, the other\nparameters tend to fit domain-specific details and often fail to generalize,\nwhich we term as untransferable parameters. Driven by this insight, we propose\nTransferable Parameter Learning (TransPar) to reduce the side effect brought by\ndomain-specific information in the learning process and thus enhance the\nmemorization of domain-invariant information. Specifically, according to the\ndistribution discrepancy degree, we divide all parameters into transferable and\nuntransferable ones in each training iteration. We then perform separate\nupdates rules for the two types of parameters. Extensive experiments on image\nclassification and regression tasks (keypoint detection) show that TransPar\noutperforms prior arts by non-trivial margins. Moreover, experiments\ndemonstrate that TransPar can be integrated into the most popular deep UDA\nnetworks and be easily extended to handle any data distribution shift\nscenarios.", "published": "2021-08-13T09:09:15Z", "version": 1}, {"aid": "2108.06467", "authors": ["Khay Boon Hong"], "title": "Optimal Approximation with Sparse Neural Networks and Applications", "url": "http://arxiv.org/pdf/2108.06467v1", "summary": "We use deep sparsely connected neural networks to measure the complexity of a\nfunction class in $L^2(\\mathbb R^d)$ by restricting connectivity and memory\nrequirement for storing the neural networks. We also introduce representation\nsystem - a countable collection of functions to guide neural networks, since\napproximation theory with representation system has been well developed in\nMathematics. We then prove the fundamental bound theorem, implying a quantity\nintrinsic to the function class itself can give information about the\napproximation ability of neural networks and representation system. We also\nprovides a method for transferring existing theories about approximation by\nrepresentation systems to that of neural networks, greatly amplifying the\npractical values of neural networks. Finally, we use neural networks to\napproximate B-spline functions, which are used to generate the B-spline curves.\nThen, we analyse the complexity of a class called $\\beta$ cartoon-like\nfunctions using rate-distortion theory and wedgelets construction.", "published": "2021-08-14T05:14:13Z", "version": 1}, {"aid": "2108.06581", "authors": ["Puspita Majumdar", "Surbhi Mittal", "Richa Singh", "Mayank Vatsa"], "title": "Unravelling the Effect of Image Distortions for Biased Prediction of Pre-trained Face Recognition Models", "url": "http://arxiv.org/pdf/2108.06581v1", "summary": "Identifying and mitigating bias in deep learning algorithms has gained\nsignificant popularity in the past few years due to its impact on the society.\nResearchers argue that models trained on balanced datasets with good\nrepresentation provide equal and unbiased performance across subgroups.\nHowever, \\textit{can seemingly unbiased pre-trained model become biased when\ninput data undergoes certain distortions?} For the first time, we attempt to\nanswer this question in the context of face recognition. We provide a\nsystematic analysis to evaluate the performance of four state-of-the-art deep\nface recognition models in the presence of image distortions across different\n\\textit{gender} and \\textit{race} subgroups. We have observed that image\ndistortions have a relationship with the performance gap of the model across\ndifferent subgroups.", "published": "2021-08-14T16:49:05Z", "version": 1}, {"aid": "2108.06613", "authors": ["Andrea Burns", "Aaron Sarna", "Dilip Krishnan", "Aaron Maschinot"], "title": "Unsupervised Disentanglement without Autoencoding: Pitfalls and Future Directions", "url": "http://arxiv.org/pdf/2108.06613v1", "summary": "Disentangled visual representations have largely been studied with generative\nmodels such as Variational AutoEncoders (VAEs). While prior work has focused on\ngenerative methods for disentangled representation learning, these approaches\ndo not scale to large datasets due to current limitations of generative models.\nInstead, we explore regularization methods with contrastive learning, which\ncould result in disentangled representations that are powerful enough for large\nscale datasets and downstream applications. However, we find that unsupervised\ndisentanglement is difficult to achieve due to optimization and initialization\nsensitivity, with trade-offs in task performance. We evaluate disentanglement\nwith downstream tasks, analyze the benefits and disadvantages of each\nregularization used, and discuss future directions.", "published": "2021-08-14T21:06:42Z", "version": 1}, {"aid": "2108.06626", "authors": ["Dina Tantawy", "Mohamed Zahran", "Amr Wassal"], "title": "A Survey on GAN Acceleration Using Memory Compression Technique", "url": "http://arxiv.org/pdf/2108.06626v1", "summary": "Since its invention, Generative adversarial networks (GANs) have shown\noutstanding results in many applications. Generative Adversarial Networks are\npowerful yet, resource-hungry deep-learning models. Their main difference from\nordinary deep learning models is the nature of their output. For example, GAN\noutput can be a whole image versus other models detecting objects or\nclassifying images. Thus, the architecture and numeric precision of the network\naffect the quality and speed of the solution. Hence, accelerating GANs is\npivotal. Accelerating GANs can be classified into three main tracks: (1) Memory\ncompression, (2) Computation optimization, and (3) Data-flow optimization.\nBecause data transfer is the main source of energy usage, memory compression\nleads to the most savings. Thus, in this paper, we survey memory compression\ntechniques for CNN-Based GANs. Additionally, the paper summarizes opportunities\nand challenges in GANs acceleration and suggests open research problems to be\nfurther investigated.", "published": "2021-08-14T23:03:14Z", "version": 1}, {"aid": "2108.06637", "authors": ["Yuelong Li", "Or Bar-Shira", "Vishal Monga", "Yonina C. Eldar"], "title": "Deep Algorithm Unrolling for Biomedical Imaging", "url": "http://arxiv.org/pdf/2108.06637v1", "summary": "In this chapter, we review biomedical applications and breakthroughs via\nleveraging algorithm unrolling, an important technique that bridges between\ntraditional iterative algorithms and modern deep learning techniques. To\nprovide context, we start by tracing the origin of algorithm unrolling and\nproviding a comprehensive tutorial on how to unroll iterative algorithms into\ndeep networks. We then extensively cover algorithm unrolling in a wide variety\nof biomedical imaging modalities and delve into several representative recent\nworks in detail. Indeed, there is a rich history of iterative algorithms for\nbiomedical image synthesis, which makes the field ripe for unrolling\ntechniques. In addition, we put algorithm unrolling into a broad perspective,\nin order to understand why it is particularly effective and discuss recent\ntrends. Finally, we conclude the chapter by discussing open challenges, and\nsuggesting future research directions.", "published": "2021-08-15T01:06:26Z", "version": 1}, {"aid": "2108.06695", "authors": ["Benjamin Groisser", "Alon Wolf", "Ron Kimmel"], "title": "U-mesh: Human Correspondence Matching with Mesh Convolutional Networks", "url": "http://arxiv.org/pdf/2108.06695v2", "summary": "The proliferation of 3D scanning technology has driven a need for methods to\ninterpret geometric data, particularly for human subjects. In this paper we\npropose an elegant fusion of regression (bottom-up) and generative (top-down)\nmethods to fit a parametric template model to raw scan meshes.\n  Our first major contribution is an intrinsic convolutional mesh U-net\narchitecture that predicts pointwise correspondence to a template surface.\nSoft-correspondence is formulated as coordinates in a newly-constructed\nCartesian space. Modeling correspondence as Euclidean proximity enables\nefficient optimization, both for network training and for the next step of the\nalgorithm.\n  Our second contribution is a generative optimization algorithm that uses the\nU-net correspondence predictions to guide a parametric Iterative Closest Point\nregistration. By employing pre-trained human surface parametric models we\nmaximally leverage domain-specific prior knowledge.\n  The pairing of a mesh-convolutional network with generative model fitting\nenables us to predict correspondence for real human surface scans including\nocclusions, partialities, and varying genus (e.g. from self-contact). We\nevaluate the proposed method on the FAUST correspondence challenge where we\nachieve 20% (33%) improvement over state of the art methods for inter- (intra-)\nsubject correspondence.", "published": "2021-08-15T08:58:45Z", "version": 2}, {"aid": "2108.06797", "authors": ["Ren Wang", "Tianqi Chen", "Alfred Hero"], "title": "Deep Adversarially-Enhanced k-Nearest Neighbors", "url": "http://arxiv.org/pdf/2108.06797v2", "summary": "Recent works have theoretically and empirically shown that deep neural\nnetworks (DNNs) have an inherent vulnerability to small perturbations. Applying\nthe Deep k-Nearest Neighbors (DkNN) classifier, we observe a dramatically\nincreasing robustness-accuracy trade-off as the layer goes deeper. In this\nwork, we propose a Deep Adversarially-Enhanced k-Nearest Neighbors (DAEkNN)\nmethod which achieves higher robustness than DkNN and mitigates the\nrobustness-accuracy trade-off in deep layers through two key elements. First,\nDAEkNN is based on an adversarially trained model. Second, DAEkNN makes\npredictions by leveraging a weighted combination of benign and adversarial\ntraining data. Empirically, we find that DAEkNN improves both the robustness\nand the robustness-accuracy trade-off on MNIST and CIFAR-10 datasets.", "published": "2021-08-15T19:18:53Z", "version": 2}, {"aid": "2108.06858", "authors": ["S. Alireza Golestaneh", "Saba Dadsetan", "Kris M. Kitani"], "title": "No-Reference Image Quality Assessment via Transformers, Relative Ranking, and Self-Consistency", "url": "http://arxiv.org/pdf/2108.06858v2", "summary": "The goal of No-Reference Image Quality Assessment (NR-IQA) is to estimate the\nperceptual image quality in accordance with subjective evaluations, it is a\ncomplex and unsolved problem due to the absence of the pristine reference\nimage. In this paper, we propose a novel model to address the NR-IQA task by\nleveraging a hybrid approach that benefits from Convolutional Neural Networks\n(CNNs) and self-attention mechanism in Transformers to extract both local and\nnon-local features from the input image. We capture local structure information\nof the image via CNNs, then to circumvent the locality bias among the extracted\nCNNs features and obtain a non-local representation of the image, we utilize\nTransformers on the extracted features where we model them as a sequential\ninput to the Transformer model. Furthermore, to improve the monotonicity\ncorrelation between the subjective and objective scores, we utilize the\nrelative distance information among the images within each batch and enforce\nthe relative ranking among them. Last but not least, we observe that the\nperformance of NR-IQA models degrades when we apply equivariant transformations\n(e.g. horizontal flipping) to the inputs. Therefore, we propose a method that\nleverages self-consistency as a source of self-supervision to improve the\nrobustness of NRIQA models. Specifically, we enforce self-consistency between\nthe outputs of our quality assessment model for each image and its\ntransformation (horizontally flipped) to utilize the rich self-supervisory\ninformation and reduce the uncertainty of the model. To demonstrate the\neffectiveness of our work, we evaluate it on seven standard IQA datasets (both\nsynthetic and authentic) and show that our model achieves state-of-the-art\nresults on various datasets.", "published": "2021-08-16T02:07:08Z", "version": 2}, {"aid": "2108.06885", "authors": ["Yanxi Li", "Zhaohui Yang", "Yunhe Wang", "Chang Xu"], "title": "Neural Architecture Dilation for Adversarial Robustness", "url": "http://arxiv.org/pdf/2108.06885v1", "summary": "With the tremendous advances in the architecture and scale of convolutional\nneural networks (CNNs) over the past few decades, they can easily reach or even\nexceed the performance of humans in certain tasks. However, a recently\ndiscovered shortcoming of CNNs is that they are vulnerable to adversarial\nattacks. Although the adversarial robustness of CNNs can be improved by\nadversarial training, there is a trade-off between standard accuracy and\nadversarial robustness. From the neural architecture perspective, this paper\naims to improve the adversarial robustness of the backbone CNNs that have a\nsatisfactory accuracy. Under a minimal computational overhead, the introduction\nof a dilation architecture is expected to be friendly with the standard\nperformance of the backbone CNN while pursuing adversarial robustness.\nTheoretical analyses on the standard and adversarial error bounds naturally\nmotivate the proposed neural architecture dilation algorithm. Experimental\nresults on real-world datasets and benchmark neural networks demonstrate the\neffectiveness of the proposed algorithm to balance the accuracy and adversarial\nrobustness.", "published": "2021-08-16T03:58:00Z", "version": 1}, {"aid": "2108.06889", "authors": ["Sihao Ding", "Fuli Feng", "Xiangnan He", "Yong Liao", "Jun Shi", "Yongdong Zhang"], "title": "Causal Incremental Graph Convolution for Recommender System Retraining", "url": "http://arxiv.org/pdf/2108.06889v2", "summary": "Real-world recommender system needs to be regularly retrained to keep with\nthe new data. In this work, we consider how to efficiently retrain graph\nconvolution network (GCN) based recommender models, which are state-of-the-art\ntechniques for collaborative recommendation. To pursue high efficiency, we set\nthe target as using only new data for model updating, meanwhile not sacrificing\nthe recommendation accuracy compared with full model retraining. This is\nnon-trivial to achieve, since the interaction data participates in both the\ngraph structure for model construction and the loss function for model\nlearning, whereas the old graph structure is not allowed to use in model\nupdating. Towards the goal, we propose a \\textit{Causal Incremental Graph\nConvolution} approach, which consists of two new operators named\n\\textit{Incremental Graph Convolution} (IGC) and \\textit{Colliding Effect\nDistillation} (CED) to estimate the output of full graph convolution. In\nparticular, we devise simple and effective modules for IGC to ingeniously\ncombine the old representations and the incremental graph and effectively fuse\nthe long-term and short-term preference signals. CED aims to avoid the\nout-of-date issue of inactive nodes that are not in the incremental graph,\nwhich connects the new data with inactive nodes through causal inference. In\nparticular, CED estimates the causal effect of new data on the representation\nof inactive nodes through the control of their collider. Extensive experiments\non three real-world datasets demonstrate both accuracy gains and significant\nspeed-ups over the existing retraining mechanism.", "published": "2021-08-16T04:20:09Z", "version": 2}, {"aid": "2108.06912", "authors": ["Sin Kit Lo", "Yue Liu", "Qinghua Lu", "Chen Wang", "Xiwei Xu", "Hye-Young Paik", "Liming Zhu"], "title": "Blockchain-based Trustworthy Federated Learning Architecture", "url": "http://arxiv.org/pdf/2108.06912v2", "summary": "Federated learning is an emerging privacy-preserving AI technique where\nclients (i.e., organisations or devices) train models locally and formulate a\nglobal model based on the local model updates without transferring local data\nexternally. However, federated learning systems struggle to achieve\ntrustworthiness and embody responsible AI principles. In particular, federated\nlearning systems face accountability and fairness challenges due to\nmulti-stakeholder involvement and heterogeneity in client data distribution. To\nenhance the accountability and fairness of federated learning systems, we\npresent a blockchain-based trustworthy federated learning architecture. We\nfirst design a smart contract-based data-model provenance registry to enable\naccountability. Additionally, we propose a weighted fair data sampler algorithm\nto enhance fairness in training data. We evaluate the proposed approach using a\nCOVID-19 X-ray detection use case. The evaluation results show that the\napproach is feasible to enable accountability and improve fairness. The\nproposed algorithm can achieve better performance than the default federated\nlearning setting in terms of the model's generalisation and accuracy.", "published": "2021-08-16T06:13:58Z", "version": 2}, {"aid": "2108.08296", "authors": ["Mengqi Zhang", "Yanqiao Zhu", "Qiang Liu", "Shu Wu", "Liang Wang"], "title": "Deep Contrastive Multiview Network Embedding", "url": "http://arxiv.org/pdf/2108.08296v2", "summary": "Multiview network embedding aims at projecting nodes in the network to\nlow-dimensional vectors, while preserving their multiple relations and\nattribute information. Contrastive learning approaches have shown promising\nperformance in this task. However, they neglect the semantic consistency\nbetween fused and view representations and have difficulty in modeling\ncomplementary information between different views. To deal with these\ndeficiencies, this work presents a novel Contrastive leaRning framEwork for\nMultiview network Embedding (CREME). In our work, different views can be\nobtained based on the various relations among nodes. Then, we generate view\nembeddings via proper view encoders and utilize an attentive multiview\naggregator to fuse these representations. Particularly, we design two\ncollaborative contrastive objectives, view fusion InfoMax and inter-view\nInfoMin, to train the model in a self-supervised manner. The former objective\ndistills information from embeddings generated from different views, while the\nlatter captures complementary information among views to promote distinctive\nview embeddings. We also show that the two objectives can be unified into one\nobjective for model training. Extensive experiments on three real-world\ndatasets demonstrate that our proposed CREME is able to consistently outperform\nstate-of-the-art methods.", "published": "2021-08-16T06:29:18Z", "version": 2}, {"aid": "2108.06925", "authors": ["Yu-Qi Yang", "Peng-Shuai Wang", "Yang Liu"], "title": "Interpolation-Aware Padding for 3D Sparse Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2108.06925v1", "summary": "Sparse voxel-based 3D convolutional neural networks (CNNs) are widely used\nfor various 3D vision tasks. Sparse voxel-based 3D CNNs create sparse non-empty\nvoxels from the 3D input and perform 3D convolution operations on them only. We\npropose a simple yet effective padding scheme --- interpolation-aware padding\nto pad a few empty voxels adjacent to the non-empty voxels and involve them in\nthe 3D CNN computation so that all neighboring voxels exist when computing\npoint-wise features via the trilinear interpolation. For fine-grained 3D vision\ntasks where point-wise features are essential, like semantic segmentation and\n3D detection, our network achieves higher prediction accuracy than the existing\nnetworks using the nearest neighbor interpolation or the normalized trilinear\ninterpolation with the zero-padding or the octree-padding scheme. Through\nextensive comparisons on various 3D segmentation and detection tasks, we\ndemonstrate the superiority of 3D sparse CNNs with our padding scheme in\nconjunction with feature interpolation.", "published": "2021-08-16T07:00:42Z", "version": 1}, {"aid": "2108.06968", "authors": ["Ajian Liu", "Chenxu Zhao", "Zitong Yu", "Anyang Su", "Xing Liu", "Zijian Kong", "Jun Wan", "Sergio Escalera", "Hugo Jair Escalante", "Zhen Lei", "Guodong Guo"], "title": "3D High-Fidelity Mask Face Presentation Attack Detection Challenge", "url": "http://arxiv.org/pdf/2108.06968v1", "summary": "The threat of 3D masks to face recognition systems is increasingly serious\nand has been widely concerned by researchers. To facilitate the study of the\nalgorithms, a large-scale High-Fidelity Mask dataset, namely CASIA-SURF\nHiFiMask (briefly HiFiMask) has been collected. Specifically, it consists of a\ntotal amount of 54, 600 videos which are recorded from 75 subjects with 225\nrealistic masks under 7 new kinds of sensors. Based on this dataset and\nProtocol 3 which evaluates both the discrimination and generalization ability\nof the algorithm under the open set scenarios, we organized a 3D High-Fidelity\nMask Face Presentation Attack Detection Challenge to boost the research of 3D\nmask-based attack detection. It attracted 195 teams for the development phase\nwith a total of 18 teams qualifying for the final round. All the results were\nverified and re-run by the organizing team, and the results were used for the\nfinal ranking. This paper presents an overview of the challenge, including the\nintroduction of the dataset used, the definition of the protocol, the\ncalculation of the evaluation criteria, and the summary and publication of the\ncompetition results. Finally, we focus on introducing and analyzing the top\nranking algorithms, the conclusion summary, and the research ideas for mask\nattack detection provided by this competition.", "published": "2021-08-16T08:40:12Z", "version": 1}, {"aid": "2108.06983", "authors": ["Dohyung kim", "Junghyup Lee", "Bumsub Ham"], "title": "Distance-aware Quantization", "url": "http://arxiv.org/pdf/2108.06983v1", "summary": "We address the problem of network quantization, that is, reducing bit-widths\nof weights and/or activations to lighten network architectures. Quantization\nmethods use a rounding function to map full-precision values to the nearest\nquantized ones, but this operation is not differentiable. There are mainly two\napproaches to training quantized networks with gradient-based optimizers.\nFirst, a straight-through estimator (STE) replaces the zero derivative of the\nrounding with that of an identity function, which causes a gradient mismatch\nproblem. Second, soft quantizers approximate the rounding with continuous\nfunctions at training time, and exploit the rounding for quantization at test\ntime. This alleviates the gradient mismatch, but causes a quantizer gap\nproblem. We alleviate both problems in a unified framework. To this end, we\nintroduce a novel quantizer, dubbed a distance-aware quantizer (DAQ), that\nmainly consists of a distance-aware soft rounding (DASR) and a temperature\ncontroller. To alleviate the gradient mismatch problem, DASR approximates the\ndiscrete rounding with the kernel soft argmax, which is based on our insight\nthat the quantization can be formulated as a distance-based assignment problem\nbetween full-precision values and quantized ones. The controller adjusts the\ntemperature parameter in DASR adaptively according to the input, addressing the\nquantizer gap problem. Experimental results on standard benchmarks show that\nDAQ outperforms the state of the art significantly for various bit-widths\nwithout bells and whistles.", "published": "2021-08-16T09:25:22Z", "version": 1}, {"aid": "2108.07049", "authors": ["Kirill Prokofiev", "Vladislav Sovrasov"], "title": "Towards Efficient and Data Agnostic Image Classification Training Pipeline for Embedded Systems", "url": "http://arxiv.org/pdf/2108.07049v1", "summary": "Nowadays deep learning-based methods have achieved a remarkable progress at\nthe image classification task among a wide range of commonly used datasets\n(ImageNet, CIFAR, SVHN, Caltech 101, SUN397, etc.). SOTA performance on each of\nthe mentioned datasets is obtained by careful tuning of the model architecture\nand training tricks according to the properties of the target data. Although\nthis approach allows setting academic records, it is unrealistic that an\naverage data scientist would have enough resources to build a sophisticated\ntraining pipeline for every image classification task he meets in practice.\nThis work is focusing on reviewing the latest augmentation and regularization\nmethods for the image classification and exploring ways to automatically choose\nsome of the most important hyperparameters: total number of epochs, initial\nlearning rate value and it's schedule. Having a training procedure equipped\nwith a lightweight modern CNN architecture (like bileNetV3 or EfficientNet),\nsufficient level of regularization and adaptive to data learning rate schedule,\nwe can achieve a reasonable performance on a variety of downstream image\nclassification tasks without manual tuning of parameters to each particular\ntask. Resulting models are computationally efficient and can be deployed to CPU\nusing the OpenVINO toolkit. Source code is available as a part of the OpenVINO\nTraining Extensions (https://github.com/openvinotoolkit/training_extensions).", "published": "2021-08-16T12:38:05Z", "version": 1}, {"aid": "2108.07380", "authors": ["Subhadeep Mukhopadhyay"], "title": "InfoGram and Admissible Machine Learning", "url": "http://arxiv.org/pdf/2108.07380v2", "summary": "We have entered a new era of machine learning (ML), where the most accurate\nalgorithm with superior predictive power may not even be deployable, unless it\nis admissible under the regulatory constraints. This has led to great interest\nin developing fair, transparent and trustworthy ML methods. The purpose of this\narticle is to introduce a new information-theoretic learning framework\n(admissible machine learning) and algorithmic risk-management tools (InfoGram,\nL-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf\nML methods to be regulatory compliant, while maintaining good prediction\naccuracy. We have illustrated our approach using several real-data examples\nfrom financial sectors, biomedical research, marketing campaigns, and the\ncriminal justice system.", "published": "2021-08-17T00:04:38Z", "version": 2}, {"aid": "2108.07387", "authors": ["Ionut Cosmin Duta", "Mariana Iuliana Georgescu", "Radu Tudor Ionescu"], "title": "Contextual Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2108.07387v1", "summary": "We propose contextual convolution (CoConv) for visual recognition. CoConv is\na direct replacement of the standard convolution, which is the core component\nof convolutional neural networks. CoConv is implicitly equipped with the\ncapability of incorporating contextual information while maintaining a similar\nnumber of parameters and computational cost compared to the standard\nconvolution. CoConv is inspired by neuroscience studies indicating that (i)\nneurons, even from the primary visual cortex (V1 area), are involved in\ndetection of contextual cues and that (ii) the activity of a visual neuron can\nbe influenced by the stimuli placed entirely outside of its theoretical\nreceptive field. On the one hand, we integrate CoConv in the widely-used\nresidual networks and show improved recognition performance over baselines on\nthe core tasks and benchmarks for visual recognition, namely image\nclassification on the ImageNet data set and object detection on the MS COCO\ndata set. On the other hand, we introduce CoConv in the generator of a\nstate-of-the-art Generative Adversarial Network, showing improved generative\nresults on CIFAR-10 and CelebA. Our code is available at\nhttps://github.com/iduta/coconv.", "published": "2021-08-17T00:42:11Z", "version": 1}, {"aid": "2108.07639", "authors": ["Jordi Armengol-Estap\u00e9", "Michael F. P. O'Boyle"], "title": "Learning C to x86 Translation: An Experiment in Neural Compilation", "url": "http://arxiv.org/pdf/2108.07639v2", "summary": "Deep learning has had a significant impact on many fields. Recently,\ncode-to-code neural models have been used in code translation, code refinement\nand decompilation. However, the question of whether these models can automate\ncompilation has yet to be investigated. In this work, we explore neural\ncompilation, building and evaluating Transformer models that learn how to\nproduce x86 assembler from C code. Although preliminary results are relatively\nweak, we make our data, models and code publicly available to encourage further\nresearch in this area.", "published": "2021-08-17T14:11:15Z", "version": 2}, {"aid": "2108.07839", "authors": ["Stefano Fusi"], "title": "Memory capacity of neural network models", "url": "http://arxiv.org/pdf/2108.07839v2", "summary": "Memory is a complex phenomenon that involves several distinct mechanisms.\nThese mechanisms operate at different spatial and temporal levels. This chapter\nfocuses on the theoretical framework and the mathematical models that have been\ndeveloped to understand how these mechanisms are orchestrated to store,\npreserve and retrieve a large number of memories. In particular, this chapter\nreviews the theoretical studies on memory capacity, in which the investigators\nestimated how the number of storable memories scales with the number of neurons\nand synapses in the neural circuitry. The memory capacity depends on the\ncomplexity of the synapses, the sparseness of the representations, the spatial\nand temporal correlations between memories and the specific way memories are\nretrieved. Complexity is important when the synapses can only be modified with\na limited precision, as in the case of biological synapses, and sparseness can\ngreatly increase memory capacity and be particularly beneficial when memories\nare structured (correlated to each other). The theoretical tools discussed by\nthis chapter can be harnessed to identify the important computational\nprinciples that underlie memory storage, preservation and retrieval and provide\nguidance in designing and interpreting memory experiments.", "published": "2021-08-17T19:08:25Z", "version": 2}, {"aid": "2108.07846", "authors": ["Xianyuan Liu", "Shuo Zhou", "Tao Lei", "Haiping Lu"], "title": "Channel-Temporal Attention for First-Person Video Domain Adaptation", "url": "http://arxiv.org/pdf/2108.07846v2", "summary": "Unsupervised Domain Adaptation (UDA) can transfer knowledge from labeled\nsource data to unlabeled target data of the same categories. However, UDA for\nfirst-person action recognition is an under-explored problem, with lack of\ndatasets and limited consideration of first-person video characteristics. This\npaper focuses on addressing this problem. Firstly, we propose two small-scale\nfirst-person video domain adaptation datasets: ADL$_{small}$ and GTEA-KITCHEN.\nSecondly, we introduce channel-temporal attention blocks to capture the\nchannel-wise and temporal-wise relationships and model their inter-dependencies\nimportant to first-person vision. Finally, we propose a Channel-Temporal\nAttention Network (CTAN) to integrate these blocks into existing architectures.\nCTAN outperforms baselines on the two proposed datasets and one existing\ndataset EPIC$_{cvpr20}$.", "published": "2021-08-17T19:30:42Z", "version": 2}, {"aid": "2108.07908", "authors": ["Luca Parisi"], "title": "M-ar-K-Fast Independent Component Analysis", "url": "http://arxiv.org/pdf/2108.07908v1", "summary": "This study presents the m-arcsinh Kernel ('m-ar-K') Fast Independent\nComponent Analysis ('FastICA') method ('m-ar-K-FastICA') for feature\nextraction. The kernel trick has enabled dimensionality reduction techniques to\ncapture a higher extent of non-linearity in the data; however, reproducible,\nopen-source kernels to aid with feature extraction are still limited and may\nnot be reliable when projecting features from entropic data. The m-ar-K\nfunction, freely available in Python and compatible with its open-source\nlibrary 'scikit-learn', is hereby coupled with FastICA to achieve more reliable\nfeature extraction in presence of a high extent of randomness in the data,\nreducing the need for pre-whitening. Different classification tasks were\nconsidered, as related to five (N = 5) open access datasets of various degrees\nof information entropy, available from scikit-learn and the University\nCalifornia Irvine (UCI) Machine Learning repository. Experimental results\ndemonstrate improvements in the classification performance brought by the\nproposed feature extraction. The novel m-ar-K-FastICA dimensionality reduction\napproach is compared to the 'FastICA' gold standard method, supporting its\nhigher reliability and computational efficiency, regardless of the underlying\nuncertainty in the data.", "published": "2021-08-17T23:53:12Z", "version": 1}, {"aid": "2108.08000", "authors": ["Matthew L. Olson", "Thuy-Vy Nguyen", "Gaurav Dixit", "Neale Ratzlaff", "Weng-Keen Wong", "Minsuk Kahng"], "title": "Contrastive Identification of Covariate Shift in Image Data", "url": "http://arxiv.org/pdf/2108.08000v2", "summary": "Identifying covariate shift is crucial for making machine learning systems\nrobust in the real world and for detecting training data biases that are not\nreflected in test data. However, detecting covariate shift is challenging,\nespecially when the data consists of high-dimensional images, and when multiple\ntypes of localized covariate shift affect different subspaces of the data.\nAlthough automated techniques can be used to detect the existence of covariate\nshift, our goal is to help human users characterize the extent of covariate\nshift in large image datasets with interfaces that seamlessly integrate\ninformation obtained from the detection algorithms. In this paper, we design\nand evaluate a new visual interface that facilitates the comparison of the\nlocal distributions of training and test data. We conduct a quantitative user\nstudy on multi-attribute facial data to compare two different learned\nlow-dimensional latent representations (pretrained ImageNet CNN vs. density\nratio) and two user analytic workflows (nearest-neighbor vs.\ncluster-to-cluster). Our results indicate that the latent representation of our\ndensity ratio model, combined with a nearest-neighbor comparison, is the most\neffective at helping humans identify covariate shift.", "published": "2021-08-18T06:58:29Z", "version": 2}, {"aid": "2108.08046", "authors": ["Seong Jin Ahn", "Myoung Ho Kim"], "title": "Variational Graph Normalized Auto-Encoders", "url": "http://arxiv.org/pdf/2108.08046v2", "summary": "Link prediction is one of the key problems for graph-structured data. With\nthe advancement of graph neural networks, graph autoencoders (GAEs) and\nvariational graph autoencoders (VGAEs) have been proposed to learn graph\nembeddings in an unsupervised way. It has been shown that these methods are\neffective for link prediction tasks. However, they do not work well in link\npredictions when a node whose degree is zero (i.g., isolated node) is involved.\nWe have found that GAEs/VGAEs make embeddings of isolated nodes close to zero\nregardless of their content features. In this paper, we propose a novel\nVariational Graph Normalized AutoEncoder (VGNAE) that utilize L2-normalization\nto derive better embeddings for isolated nodes. We show that our VGNAEs\noutperform the existing state-of-the-art models for link prediction tasks. The\ncode is available at https://github.com/SeongJinAhn/VGNAE.", "published": "2021-08-18T08:56:04Z", "version": 2}, {"aid": "2108.08782", "authors": ["Tan Wang", "Chang Zhou", "Qianru Sun", "Hanwang Zhang"], "title": "Causal Attention for Unbiased Visual Recognition", "url": "http://arxiv.org/pdf/2108.08782v1", "summary": "Attention module does not always help deep models learn causal features that\nare robust in any confounding context, e.g., a foreground object feature is\ninvariant to different backgrounds. This is because the confounders trick the\nattention to capture spurious correlations that benefit the prediction when the\ntraining and testing data are IID (identical & independent distribution); while\nharm the prediction when the data are OOD (out-of-distribution). The sole\nfundamental solution to learn causal attention is by causal intervention, which\nrequires additional annotations of the confounders, e.g., a \"dog\" model is\nlearned within \"grass+dog\" and \"road+dog\" respectively, so the \"grass\" and\n\"road\" contexts will no longer confound the \"dog\" recognition. However, such\nannotation is not only prohibitively expensive, but also inherently\nproblematic, as the confounders are elusive in nature. In this paper, we\npropose a causal attention module (CaaM) that self-annotates the confounders in\nunsupervised fashion. In particular, multiple CaaMs can be stacked and\nintegrated in conventional attention CNN and self-attention Vision Transformer.\nIn OOD settings, deep models with CaaM outperform those without it\nsignificantly; even in IID settings, the attention localization is also\nimproved by CaaM, showing a great potential in applications that require robust\nvisual saliency. Codes are available at \\url{https://github.com/Wangt-CN/CaaM}.", "published": "2021-08-19T16:45:51Z", "version": 1}, {"aid": "2108.09598", "authors": ["Sayan Nag", "Mayukh Bhattacharyya"], "title": "SERF: Towards better training of deep neural networks using log-Softplus ERror activation Function", "url": "http://arxiv.org/pdf/2108.09598v3", "summary": "Activation functions play a pivotal role in determining the training dynamics\nand neural network performance. The widely adopted activation function ReLU\ndespite being simple and effective has few disadvantages including the Dying\nReLU problem. In order to tackle such problems, we propose a novel activation\nfunction called Serf which is self-regularized and nonmonotonic in nature. Like\nMish, Serf also belongs to the Swish family of functions. Based on several\nexperiments on computer vision (image classification and object detection) and\nnatural language processing (machine translation, sentiment classification and\nmultimodal entailment) tasks with different state-of-the-art architectures, it\nis observed that Serf vastly outperforms ReLU (baseline) and other activation\nfunctions including both Swish and Mish, with a markedly bigger margin on\ndeeper architectures. Ablation studies further demonstrate that Serf based\narchitectures perform better than those of Swish and Mish in varying scenarios,\nvalidating the effectiveness and compatibility of Serf with varying depth,\ncomplexity, optimizers, learning rates, batch sizes, initializers and dropout\nrates. Finally, we investigate the mathematical relation between Swish and\nSerf, thereby showing the impact of preconditioner function ingrained in the\nfirst derivative of Serf which provides a regularization effect making\ngradients smoother and optimization faster.", "published": "2021-08-21T23:33:57Z", "version": 3}, {"aid": "2108.10751", "authors": ["Ljubisa Stankovic", "Danilo Mandic"], "title": "Understanding the Basis of Graph Convolutional Neural Networks via an Intuitive Matched Filtering Approach", "url": "http://arxiv.org/pdf/2108.10751v1", "summary": "Graph Convolutional Neural Networks (GCNN) are becoming a preferred model for\ndata processing on irregular domains, yet their analysis and principles of\noperation are rarely examined due to the black box nature of NNs. To this end,\nwe revisit the operation of GCNNs and show that their convolution layers\neffectively perform matched filtering of input data with the chosen patterns\n(features). This allows us to provide a unifying account of GCNNs through a\nmatched filter perspective, whereby the nonlinear ReLU and max-pooling layers\nare also discussed within the matched filtering framework. This is followed by\na step-by-step guide on information propagation and learning in GCNNs. It is\nalso shown that standard CNNs and fully connected NNs can be obtained as a\nspecial case of GCNNs. A carefully chosen numerical example guides the reader\nthrough the various steps of GCNN operation and learning both visually and\nnumerically.", "published": "2021-08-23T12:41:06Z", "version": 1}, {"aid": "2108.10430", "authors": ["Yixin Hu", "Xingyu Li"], "title": "CoverTheFace: face covering monitoring and demonstrating using deep learning and statistical shape analysis", "url": "http://arxiv.org/pdf/2108.10430v1", "summary": "Wearing a mask is a strong protection against the COVID-19 pandemic, even\nthough the vaccine has been successfully developed and is widely available.\nHowever, many people wear them incorrectly. This observation prompts us to\ndevise an automated approach to monitor the condition of people wearing masks.\nUnlike previous studies, our work goes beyond mask detection; it focuses on\ngenerating a personalized demonstration on proper mask-wearing, which helps\npeople use masks better through visual demonstration rather than text\nexplanation. The pipeline starts from the detection of face covering. For\nimages where faces are improperly covered, our mask overlay module incorporates\nstatistical shape analysis (SSA) and dense landmark alignment to approximate\nthe geometry of a face and generates corresponding face-covering examples. Our\nresults show that the proposed system successfully identifies images with faces\ncovered properly. Our ablation study on mask overlay suggests that the SSA\nmodel helps to address variations in face shapes, orientations, and scales. The\nfinal face-covering examples, especially half profile face images, surpass\nprevious arts by a noticeable margin.", "published": "2021-08-23T22:11:07Z", "version": 1}, {"aid": "2108.10521", "authors": ["Tianlong Chen", "Kaixiong Zhou", "Keyu Duan", "Wenqing Zheng", "Peihao Wang", "Xia Hu", "Zhangyang Wang"], "title": "Bag of Tricks for Training Deeper Graph Neural Networks: A Comprehensive Benchmark Study", "url": "http://arxiv.org/pdf/2108.10521v2", "summary": "Training deep graph neural networks (GNNs) is notoriously hard. Besides the\nstandard plights in training deep architectures such as vanishing gradients and\noverfitting, it also uniquely suffers from over-smoothing, information\nsquashing, and so on, which limits their potential power for encoding the\nhigh-order neighbor structure in large-scale graphs. Although numerous efforts\nare proposed to address these limitations, such as various forms of skip\nconnections, graph normalization, and random dropping, it is difficult to\ndisentangle the advantages brought by a deep GNN architecture from those\n\"tricks\" necessary to train such an architecture. Moreover, the lack of a\nstandardized benchmark with fair and consistent experimental settings poses an\nalmost insurmountable obstacle to gauge the effectiveness of new mechanisms. In\nview of those, we present the first fair and reproducible benchmark dedicated\nto assessing the \"tricks\" of training deep GNNs. We categorize existing\napproaches, investigate their hyperparameter sensitivity, and unify the basic\nconfiguration. Comprehensive evaluations are then conducted on tens of\nrepresentative graph datasets including the recent large-scale Open Graph\nBenchmark, with diverse deep GNN backbones. We demonstrate that an organic\ncombo of initial connection, identity mapping, group and batch normalization\nattains the new state-of-the-art results for deep GNNs on large datasets. Codes\nare available: https://github.com/VITA-Group/Deep_GCN_Benchmarking.", "published": "2021-08-24T05:00:37Z", "version": 2}, {"aid": "2108.10612", "authors": ["Dawid Rymarczyk", "Adam Pardyl", "Jaros\u0142aw Kraus", "Aneta Kaczy\u0144ska", "Marek Skomorowski", "Bartosz Zieli\u0144ski"], "title": "ProtoMIL: Multiple Instance Learning with Prototypical Parts for Whole-Slide Image Classification", "url": "http://arxiv.org/pdf/2108.10612v2", "summary": "Multiple Instance Learning (MIL) gains popularity in many real-life machine\nlearning applications due to its weakly supervised nature. However, the\ncorresponding effort on explaining MIL lags behind, and it is usually limited\nto presenting instances of a bag that are crucial for a particular prediction.\nIn this paper, we fill this gap by introducing ProtoMIL, a novel\nself-explainable MIL method inspired by the case-based reasoning process that\noperates on visual prototypes. Thanks to incorporating prototypical features\ninto objects description, ProtoMIL unprecedentedly joins the model accuracy and\nfine-grained interpretability, which we present with the experiments on five\nrecognized MIL datasets.", "published": "2021-08-24T10:02:31Z", "version": 2}, {"aid": "2108.10710", "authors": ["Fadi Boutros", "Patrick Siebke", "Marcel Klemt", "Naser Damer", "Florian Kirchbuchner", "Arjan Kuijper"], "title": "PocketNet: Extreme Lightweight Face Recognition Network using Neural Architecture Search and Multi-Step Knowledge Distillation", "url": "http://arxiv.org/pdf/2108.10710v2", "summary": "Deep neural networks have rapidly become the mainstream method for face\nrecognition (FR). However, this limits the deployment of such models that\ncontain an extremely large number of parameters to embedded and low-end\ndevices. In this work, we present an extremely lightweight and accurate FR\nsolution, namely PocketNet. We utilize neural architecture search to develop a\nnew family of lightweight face-specific architectures. We additionally propose\na novel training paradigm based on knowledge distillation (KD), the multi-step\nKD, where the knowledge is distilled from the teacher model to the student\nmodel at different stages of the training maturity. We conduct a detailed\nablation study proving both, the sanity of using NAS for the specific task of\nFR rather than general object classification, and the benefits of our proposed\nmulti-step KD. We present an extensive experimental evaluation and comparisons\nwith the state-of-the-art (SOTA) compact FR models on nine different benchmarks\nincluding large-scale evaluation benchmarks such as IJB-B, IJB-C, and MegaFace.\nPocketNets have consistently advanced the SOTA FR performance on nine\nmainstream benchmarks when considering the same level of model compactness.\nWith 0.92M parameters, our smallest network PocketNetS-128 achieved very\ncompetitive results to recent SOTA compacted models that contain up to 4M\nparameters.", "published": "2021-08-24T13:19:08Z", "version": 2}, {"aid": "2108.10733", "authors": ["Lilapati Waikhom", "Ripon Patgiri"], "title": "Graph Neural Networks: Methods, Applications, and Opportunities", "url": "http://arxiv.org/pdf/2108.10733v2", "summary": "In the last decade or so, we have witnessed deep learning reinvigorating the\nmachine learning field. It has solved many problems in the domains of computer\nvision, speech recognition, natural language processing, and various other\ntasks with state-of-the-art performance. The data is generally represented in\nthe Euclidean space in these domains. Various other domains conform to\nnon-Euclidean space, for which graph is an ideal representation. Graphs are\nsuitable for representing the dependencies and interrelationships between\nvarious entities. Traditionally, handcrafted features for graphs are incapable\nof providing the necessary inference for various tasks from this complex data\nrepresentation. Recently, there is an emergence of employing various advances\nin deep learning to graph data-based tasks. This article provides a\ncomprehensive survey of graph neural networks (GNNs) in each learning setting:\nsupervised, unsupervised, semi-supervised, and self-supervised learning.\nTaxonomy of each graph based learning setting is provided with logical\ndivisions of methods falling in the given learning setting. The approaches for\neach learning task are analyzed from both theoretical as well as empirical\nstandpoints. Further, we provide general architecture guidelines for building\nGNNs. Various applications and benchmark datasets are also provided, along with\nopen challenges still plaguing the general applicability of GNNs.", "published": "2021-08-24T13:46:19Z", "version": 2}, {"aid": "2108.10840", "authors": ["Shuhao Qiu", "Chuang Zhu", "Wenli Zhou"], "title": "Meta Self-Learning for Multi-Source Domain Adaptation: A Benchmark", "url": "http://arxiv.org/pdf/2108.10840v1", "summary": "In recent years, deep learning-based methods have shown promising results in\ncomputer vision area. However, a common deep learning model requires a large\namount of labeled data, which is labor-intensive to collect and label. What's\nmore, the model can be ruined due to the domain shift between training data and\ntesting data. Text recognition is a broadly studied field in computer vision\nand suffers from the same problems noted above due to the diversity of fonts\nand complicated backgrounds. In this paper, we focus on the text recognition\nproblem and mainly make three contributions toward these problems. First, we\ncollect a multi-source domain adaptation dataset for text recognition,\nincluding five different domains with over five million images, which is the\nfirst multi-domain text recognition dataset to our best knowledge. Secondly, we\npropose a new method called Meta Self-Learning, which combines the\nself-learning method with the meta-learning paradigm and achieves a better\nrecognition result under the scene of multi-domain adaptation. Thirdly,\nextensive experiments are conducted on the dataset to provide a benchmark and\nalso show the effectiveness of our method. The code of our work and dataset are\navailable soon at https://bupt-ai-cz.github.io/Meta-SelfLearning/.", "published": "2021-08-24T17:07:34Z", "version": 1}, {"aid": "2108.12043", "authors": ["Xiao Liu", "Pedro Sanchez", "Spyridon Thermos", "Alison Q. O'Neil", "Sotirios A. Tsaftaris"], "title": "Learning Disentangled Representations in the Imaging Domain", "url": "http://arxiv.org/pdf/2108.12043v6", "summary": "Disentangled representation learning has been proposed as an approach to\nlearning general representations even in the absence of, or with limited,\nsupervision. A good general representation can be fine-tuned for new target\ntasks using modest amounts of data, or used directly in unseen domains\nachieving remarkable performance in the corresponding task. This alleviation of\nthe data and annotation requirements offers tantalising prospects for\napplications in computer vision and healthcare. In this tutorial paper, we\nmotivate the need for disentangled representations, revisit key concepts, and\ndescribe practical building blocks and criteria for learning such\nrepresentations. We survey applications in medical imaging emphasising choices\nmade in exemplar key works, and then discuss links to computer vision\napplications. We conclude by presenting limitations, challenges, and\nopportunities.", "published": "2021-08-26T21:44:10Z", "version": 6}, {"aid": "2109.07161", "authors": ["Roman Suvorov", "Elizaveta Logacheva", "Anton Mashikhin", "Anastasia Remizova", "Arsenii Ashukha", "Aleksei Silvestrov", "Naejin Kong", "Harshith Goka", "Kiwoong Park", "Victor Lempitsky"], "title": "Resolution-robust Large Mask Inpainting with Fourier Convolutions", "url": "http://arxiv.org/pdf/2109.07161v2", "summary": "Modern image inpainting systems, despite the significant progress, often\nstruggle with large missing areas, complex geometric structures, and\nhigh-resolution images. We find that one of the main reasons for that is the\nlack of an effective receptive field in both the inpainting network and the\nloss function. To alleviate this issue, we propose a new method called large\nmask inpainting (LaMa). LaMa is based on i) a new inpainting network\narchitecture that uses fast Fourier convolutions (FFCs), which have the\nimage-wide receptive field; ii) a high receptive field perceptual loss; iii)\nlarge training masks, which unlocks the potential of the first two components.\nOur inpainting network improves the state-of-the-art across a range of datasets\nand achieves excellent performance even in challenging scenarios, e.g.\ncompletion of periodic structures. Our model generalizes surprisingly well to\nresolutions that are higher than those seen at train time, and achieves this at\nlower parameter&time costs than the competitive baselines. The code is\navailable at \\url{https://github.com/saic-mdal/lama}.", "published": "2021-09-15T08:54:29Z", "version": 2}, {"aid": "2109.08203", "authors": ["David Picard"], "title": "Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision", "url": "http://arxiv.org/pdf/2109.08203v2", "summary": "In this paper I investigate the effect of random seed selection on the\naccuracy when using popular deep learning architectures for computer vision. I\nscan a large amount of seeds (up to $10^4$) on CIFAR 10 and I also scan fewer\nseeds on Imagenet using pre-trained models to investigate large scale datasets.\nThe conclusions are that even if the variance is not very large, it is\nsurprisingly easy to find an outlier that performs much better or much worse\nthan the average.", "published": "2021-09-16T20:10:12Z", "version": 2}, {"aid": "2109.09265", "authors": ["Aadyot Bhatnagar", "Paul Kassianik", "Chenghao Liu", "Tian Lan", "Wenzhuo Yang", "Rowan Cassius", "Doyen Sahoo", "Devansh Arpit", "Sri Subramanian", "Gerald Woo", "Amrita Saha", "Arun Kumar Jagota", "Gokulakrishnan Gopalakrishnan", "Manpreet Singh", "K C Krithika", "Sukumar Maddineni", "Daeki Cho", "Bo Zong", "Yingbo Zhou", "Caiming Xiong", "Silvio Savarese", "Steven Hoi", "Huan Wang"], "title": "Merlion: A Machine Learning Library for Time Series", "url": "http://arxiv.org/pdf/2109.09265v1", "summary": "We introduce Merlion, an open-source machine learning library for time\nseries. It features a unified interface for many commonly used models and\ndatasets for anomaly detection and forecasting on both univariate and\nmultivariate time series, along with standard pre/post-processing layers. It\nhas several modules to improve ease-of-use, including visualization, anomaly\nscore calibration to improve interpetability, AutoML for hyperparameter tuning\nand model selection, and model ensembling. Merlion also provides a unique\nevaluation framework that simulates the live deployment and re-training of a\nmodel in production. This library aims to provide engineers and researchers a\none-stop solution to rapidly develop models for their specific time series\nneeds and benchmark them across multiple time series datasets. In this\ntechnical report, we highlight Merlion's architecture and major\nfunctionalities, and we report benchmark numbers across different baseline\nmodels and ensembles.", "published": "2021-09-20T02:03:43Z", "version": 1}, {"aid": "2109.10817", "authors": ["Wasim Ahmad", "Maha Shadaydeh", "Joachim Denzler"], "title": "Causal Inference in Non-linear Time-series using Deep Networks and Knockoff Counterfactuals", "url": "http://arxiv.org/pdf/2109.10817v3", "summary": "Estimating causal relations is vital in understanding the complex\ninteractions in multivariate time series. Non-linear coupling of variables is\none of the major challenges inaccurate estimation of cause-effect relations. In\nthis paper, we propose to use deep autoregressive networks (DeepAR) in tandem\nwith counterfactual analysis to infer nonlinear causal relations in\nmultivariate time series. We extend the concept of Granger causality using\nprobabilistic forecasting with DeepAR. Since deep networks can neither handle\nmissing input nor out-of-distribution intervention, we propose to use the\nKnockoffs framework (Barberand Cand`es, 2015) for generating intervention\nvariables and consequently counterfactual probabilistic forecasting. Knockoff\nsamples are independent of their output given the observed variables and\nexchangeable with their counterpart variables without changing the underlying\ndistribution of the data. We test our method on synthetic as well as real-world\ntime series datasets. Overall our method outperforms the widely used vector\nautoregressive Granger causality and PCMCI in detecting nonlinear causal\ndependency in multivariate time series.", "published": "2021-09-22T16:07:27Z", "version": 3}, {"aid": "2109.10951", "authors": ["Morgan Schaefer", "Lauren Michelin", "Jeremy Kepner"], "title": "Naming Schema for a Human Brain-Scale Neural Network", "url": "http://arxiv.org/pdf/2109.10951v1", "summary": "Deep neural networks have become increasingly large and sparse, allowing for\nthe storage of large-scale neural networks with decreased costs of storage and\ncomputation. Storage of a neural network with as many connections as the human\nbrain is possible with current versions of the high-performance Apache Accumulo\ndatabase and the Distributed Dimensional Data Model (D4M) software. Neural\nnetworks of such large scale may be of particular interest to scientists within\nthe human brain Connectome community. To aid in research and understanding of\nartificial neural networks that parallel existing neural networks like the\nbrain, a naming schema can be developed to label groups of neurons in the\nartificial network that parallel those in the brain. Groups of artificial\nneurons are able to be specifically labeled in small regions for future study.", "published": "2021-09-22T18:14:47Z", "version": 1}, {"aid": "2109.11358", "authors": ["Jari Pronold", "Jakob Jordan", "Brian J. N. Wylie", "Itaru Kitayama", "Markus Diesmann", "Susanne Kunkel"], "title": "Routing brain traffic through the von Neumann bottleneck: Parallel sorting and refactoring", "url": "http://arxiv.org/pdf/2109.11358v3", "summary": "Generic simulation code for spiking neuronal networks spends the major part\nof time in the phase where spikes have arrived at a compute node and need to be\ndelivered to their target neurons. These spikes were emitted over the last\ninterval between communication steps by source neurons distributed across many\ncompute nodes and are inherently irregular with respect to their targets. For\nfinding the targets, the spikes need to be dispatched to a three-dimensional\ndata structure with decisions on target thread and synapse type to be made on\nthe way. With growing network size a compute node receives spikes from an\nincreasing number of different source neurons until in the limit each synapse\non the compute node has a unique source. Here we show analytically how this\nsparsity emerges over the practically relevant range of network sizes from a\nhundred thousand to a billion neurons. By profiling a production code we\ninvestigate opportunities for algorithmic changes to avoid indirections and\nbranching. Every thread hosts an equal share of the neurons on a compute node.\nIn the original algorithm all threads search through all spikes to pick out the\nrelevant ones. With increasing network size the fraction of hits remains\ninvariant but the absolute number of rejections grows. An alternative algorithm\nequally divides the spikes among the threads and sorts them in parallel\naccording to target thread and synapse type. After this every thread completes\ndelivery solely of the section of spikes for its own neurons. The new algorithm\nhalves the number of instructions in spike delivery which leads to a reduction\nof simulation time of up to 40 %. Thus, spike delivery is a fully\nparallelizable process with a single synchronization point and thereby well\nsuited for many-core systems. Our analysis indicates that further progress\nrequires a reduction of the latency instructions experience in accessing\nmemory.", "published": "2021-09-23T13:15:34Z", "version": 3}, {"aid": "2109.11439", "authors": ["Phutphalla Kong", "Matei Mancas", "Bernard Gosselin", "Kimtho Po"], "title": "DeepRare: Generic Unsupervised Visual Attention Models", "url": "http://arxiv.org/pdf/2109.11439v1", "summary": "Human visual system is modeled in engineering field providing\nfeature-engineered methods which detect contrasted/surprising/unusual data into\nimages. This data is \"interesting\" for humans and leads to numerous\napplications. Deep learning (DNNs) drastically improved the algorithms\nefficiency on the main benchmark datasets. However, DNN-based models are\ncounter-intuitive: surprising or unusual data is by definition difficult to\nlearn because of its low occurrence probability. In reality, DNN-based models\nmainly learn top-down features such as faces, text, people, or animals which\nusually attract human attention, but they have low efficiency in extracting\nsurprising or unusual data in the images. In this paper, we propose a new\nvisual attention model called DeepRare2021 (DR21) which uses the power of DNNs\nfeature extraction and the genericity of feature-engineered algorithms. This\nalgorithm is an evolution of a previous version called DeepRare2019 (DR19)\nbased on a common framework. DR21 1) does not need any training and uses the\ndefault ImageNet training, 2) is fast even on CPU, 3) is tested on four very\ndifferent eye-tracking datasets showing that the DR21 is generic and is always\nin the within the top models on all datasets and metrics while no other model\nexhibits such a regularity and genericity. Finally DR21 4) is tested with\nseveral network architectures such as VGG16 (V16), VGG19 (V19) and MobileNetV2\n(MN2) and 5) it provides explanation and transparency on which parts of the\nimage are the most surprising at different levels despite the use of a\nDNN-based feature extractor. DeepRare2021 code can be found at\nhttps://github.com/numediart/VisualAttention-RareFamil}.", "published": "2021-09-23T15:28:43Z", "version": 1}, {"aid": "2109.12813", "authors": ["Yeshwanth Bethi", "Ying Xu", "Gregory Cohen", "Andre van Schaik", "Saeed Afshar"], "title": "An optimised deep spiking neural network architecture without gradients", "url": "http://arxiv.org/pdf/2109.12813v3", "summary": "We present an end-to-end trainable modular event-driven neural architecture\nthat uses local synaptic and threshold adaptation rules to perform\ntransformations between arbitrary spatio-temporal spike patterns. The\narchitecture represents a highly abstracted model of existing Spiking Neural\nNetwork (SNN) architectures. The proposed Optimized Deep Event-driven Spiking\nneural network Architecture (ODESA) can simultaneously learn hierarchical\nspatio-temporal features at multiple arbitrary time scales. ODESA performs\nonline learning without the use of error back-propagation or the calculation of\ngradients. Through the use of simple local adaptive selection thresholds at\neach node, the network rapidly learns to appropriately allocate its neuronal\nresources at each layer for any given problem without using a real-valued error\nmeasure. These adaptive selection thresholds are the central feature of ODESA,\nensuring network stability and remarkable robustness to noise as well as to the\nselection of initial system parameters. Network activations are inherently\nsparse due to a hard Winner-Take-All (WTA) constraint at each layer. We\nevaluate the architecture on existing spatio-temporal datasets, including the\nspike-encoded IRIS and TIDIGITS datasets, as well as a novel set of tasks based\non International Morse Code that we created. These tests demonstrate the\nhierarchical spatio-temporal learning capabilities of ODESA. Through these\ntests, we demonstrate ODESA can optimally solve practical and highly\nchallenging hierarchical spatio-temporal learning tasks with the minimum\npossible number of computing nodes.", "published": "2021-09-27T05:59:12Z", "version": 3}, {"aid": "2109.13208", "authors": ["Saeed Reza Kheradpisheh", "Maryam Mirsadeghi", "Timoth\u00e9e Masquelier"], "title": "Spiking neural networks trained via proxy", "url": "http://arxiv.org/pdf/2109.13208v3", "summary": "We propose a new learning algorithm to train spiking neural networks (SNN)\nusing conventional artificial neural networks (ANN) as proxy. We couple two SNN\nand ANN networks, respectively, made of integrate-and-fire (IF) and ReLU\nneurons with the same network architectures and shared synaptic weights. The\nforward passes of the two networks are totally independent. By assuming IF\nneuron with rate-coding as an approximation of ReLU, we backpropagate the error\nof the SNN in the proxy ANN to update the shared weights, simply by replacing\nthe ANN final output with that of the SNN. We applied the proposed proxy\nlearning to deep convolutional SNNs and evaluated it on two benchmarked\ndatasets of Fashion-MNIST and Cifar10 with 94.56% and 93.11% classification\naccuracy, respectively. The proposed networks could outperform other deep SNNs\ntrained with tandem learning, surrogate gradient learning, or converted from\ndeep ANNs. Converted SNNs require long simulation times to reach reasonable\naccuracies while our proxy learning leads to efficient SNNs with much smaller\nsimulation times. The source codes of the proposed method are publicly\navailable at https://github.com/SRKH/ProxyLearning.", "published": "2021-09-27T17:29:51Z", "version": 3}, {"aid": "2109.13392", "authors": ["Volker Tresp", "Sahand Sharifzadeh", "Hang Li", "Dario Konopatzki", "Yunpu Ma"], "title": "The Tensor Brain: A Unified Theory of Perception, Memory and Semantic Decoding", "url": "http://arxiv.org/pdf/2109.13392v6", "summary": "We present a unified computational theory of an agent's perception and\nmemory. In our model, perception, episodic memory, and semantic memory are\nrealized by different operational modes of the oscillating interactions between\na symbolic index layer and a subsymbolic representation layer. The two layers\nform a bilayer tensor network (BTN). Although memory appears to be about the\npast, its main purpose is to support the agent in the present and the future.\nRecent episodic memory provides the agent with a sense of the here and now.\nRemote episodic memory retrieves relevant past experiences to provide\ninformation about possible future scenarios. This aids the agent in\ndecision-making. \"Future\" episodic memory, based on expected future events,\nguides planning and action. Semantic memory retrieves specific information,\nwhich is not delivered by current perception, and defines priors for future\nobservations. We argue that it is important for the agent to encode individual\nentities, not just classes and attributes. We demonstrate that a form of\nself-supervised learning can acquire new concepts and refine existing ones. We\ntest our model on a standard benchmark data set, which we expanded to contain\nricher representations for attributes, classes, and individuals. Our key\nhypothesis is that obtaining a better understanding of perception and memory is\na crucial prerequisite to comprehending human-level intelligence.", "published": "2021-09-27T23:32:44Z", "version": 6}, {"aid": "2109.15089", "authors": ["Mufeng Tang", "Yibo Yang", "Yali Amit"], "title": "Biologically Plausible Training Mechanisms for Self-Supervised Learning in Deep Networks", "url": "http://arxiv.org/pdf/2109.15089v4", "summary": "We develop biologically plausible training mechanisms for self-supervised\nlearning (SSL) in deep networks. Specifically, by biological plausible training\nwe mean (i) All updates of weights are based on current activities of\npre-synaptic units and current, or activity retrieved from short term memory of\npost synaptic units, including at the top-most error computing layer, (ii)\nComplex computations such as normalization, inner products and division are\navoided (iii) Asymmetric connections between units, (iv) Most learning is\ncarried out in an unsupervised manner. SSL with a contrastive loss satisfies\nthe third condition as it does not require labelled data and it introduces\nrobustness to observed perturbations of objects, which occur naturally as\nobjects or observer move in 3d and with variable lighting over time. We propose\na contrastive hinge based loss whose error involves simple local computations\nsatisfying (ii), as opposed to the standard contrastive losses employed in the\nliterature, which do not lend themselves easily to implementation in a network\narchitecture due to complex computations involving ratios and inner products.\nFurthermore we show that learning can be performed with one of two more\nplausible alternatives to backpropagation that satisfy conditions (i) and (ii).\nThe first is difference target propagation (DTP) and the second is layer-wise\nlearning (LL), where each layer is directly connected to a layer computing the\nloss error. Both methods represent alternatives to the symmetric weight issue\nof backpropagation. By training convolutional neural networks (CNNs) with SSL\nand DTP, LL, we find that our proposed framework achieves comparable\nperformance to standard BP learning downstream linear classifier evaluation of\nthe learned embeddings.", "published": "2021-09-30T12:56:57Z", "version": 4}, {"aid": "2110.01640", "authors": ["Sreeraj Ramachandran", "Aakash Varma Nadimpalli", "Ajita Rattani"], "title": "An Experimental Evaluation on Deepfake Detection using Deep Face Recognition", "url": "http://arxiv.org/pdf/2110.01640v1", "summary": "Significant advances in deep learning have obtained hallmark accuracy rates\nfor various computer vision applications. However, advances in deep generative\nmodels have also led to the generation of very realistic fake content, also\nknown as deepfakes, causing a threat to privacy, democracy, and national\nsecurity. Most of the current deepfake detection methods are deemed as a binary\nclassification problem in distinguishing authentic images or videos from fake\nones using two-class convolutional neural networks (CNNs). These methods are\nbased on detecting visual artifacts, temporal or color inconsistencies produced\nby deep generative models. However, these methods require a large amount of\nreal and fake data for model training and their performance drops significantly\nin cross dataset evaluation with samples generated using advanced deepfake\ngeneration techniques. In this paper, we thoroughly evaluate the efficacy of\ndeep face recognition in identifying deepfakes, using different loss functions\nand deepfake generation techniques. Experimental investigations on challenging\nCeleb-DF and FaceForensics++ deepfake datasets suggest the efficacy of deep\nface recognition in identifying deepfakes over two-class CNNs and the ocular\nmodality. Reported results suggest a maximum Area Under Curve (AUC) of 0.98 and\nan Equal Error Rate (EER) of 7.1% in detecting deepfakes using face recognition\non the Celeb-DF dataset. This EER is lower by 16.6% compared to the EER\nobtained for the two-class CNN and the ocular modality on the Celeb-DF dataset.\nFurther on the FaceForensics++ dataset, an AUC of 0.99 and EER of 2.04% were\nobtained. The use of biometric facial recognition technology has the advantage\nof bypassing the need for a large amount of fake data for model training and\nobtaining better generalizability to evolving deepfake creation techniques.", "published": "2021-10-04T18:02:56Z", "version": 1}, {"aid": "2110.01765", "authors": ["James Martens", "Andy Ballard", "Guillaume Desjardins", "Grzegorz Swirszcz", "Valentin Dalibard", "Jascha Sohl-Dickstein", "Samuel S. Schoenholz"], "title": "Rapid training of deep neural networks without skip connections or normalization layers using Deep Kernel Shaping", "url": "http://arxiv.org/pdf/2110.01765v1", "summary": "Using an extended and formalized version of the Q/C map analysis of Poole et\nal. (2016), along with Neural Tangent Kernel theory, we identify the main\npathologies present in deep networks that prevent them from training fast and\ngeneralizing to unseen data, and show how these can be avoided by carefully\ncontrolling the \"shape\" of the network's initialization-time kernel function.\nWe then develop a method called Deep Kernel Shaping (DKS), which accomplishes\nthis using a combination of precise parameter initialization, activation\nfunction transformations, and small architectural tweaks, all of which preserve\nthe model class. In our experiments we show that DKS enables SGD training of\nresidual networks without normalization layers on Imagenet and CIFAR-10\nclassification tasks at speeds comparable to standard ResNetV2 and Wide-ResNet\nmodels, with only a small decrease in generalization performance. And when\nusing K-FAC as the optimizer, we achieve similar results for networks without\nskip connections. Our results apply for a large variety of activation\nfunctions, including those which traditionally perform very badly, such as the\nlogistic sigmoid. In addition to DKS, we contribute a detailed analysis of skip\nconnections, normalization layers, special activation functions like RELU and\nSELU, and various initialization schemes, explaining their effectiveness as\nalternative (and ultimately incomplete) ways of \"shaping\" the network's\ninitialization-time kernel.", "published": "2021-10-05T00:49:36Z", "version": 1}, {"aid": "2110.02861", "authors": ["Tim Dettmers", "Mike Lewis", "Sam Shleifer", "Luke Zettlemoyer"], "title": "8-bit Optimizers via Block-wise Quantization", "url": "http://arxiv.org/pdf/2110.02861v2", "summary": "Stateful optimizers maintain gradient statistics over time, e.g., the\nexponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past\ngradient values. This state can be used to accelerate optimization compared to\nplain stochastic gradient descent but uses memory that might otherwise be\nallocated to model parameters, thereby limiting the maximum size of models\ntrained in practice. In this paper, we develop the first optimizers that use\n8-bit statistics while maintaining the performance levels of using 32-bit\noptimizer states. To overcome the resulting computational, quantization, and\nstability challenges, we develop block-wise dynamic quantization. Block-wise\nquantization divides input tensors into smaller blocks that are independently\nquantized. Each block is processed in parallel across cores, yielding faster\noptimization and high precision quantization. To maintain stability and\nperformance, we combine block-wise quantization with two additional changes:\n(1) dynamic quantization, a form of non-linear optimization that is precise for\nboth large and small magnitude values, and (2) a stable embedding layer to\nreduce gradient variance that comes from the highly non-uniform distribution of\ninput tokens in language models. As a result, our 8-bit optimizers maintain\n32-bit performance with a small fraction of the memory footprint on a range of\ntasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet\nclassification, WMT'14 machine translation, MoCo v2 contrastive ImageNet\npretraining+finetuning, and RoBERTa pretraining, without changes to the\noriginal optimizer hyperparameters. We open-source our 8-bit optimizers as a\ndrop-in replacement that only requires a two-line code change.", "published": "2021-10-06T15:43:20Z", "version": 2}, {"aid": "2110.04181", "authors": ["Bo Zhao", "Hakan Bilen"], "title": "Dataset Condensation with Distribution Matching", "url": "http://arxiv.org/pdf/2110.04181v3", "summary": "Computational cost of training state-of-the-art deep models in many learning\nproblems is rapidly increasing due to more sophisticated models and larger\ndatasets. A recent promising direction for reducing training cost is dataset\ncondensation that aims to replace the original large training set with a\nsignificantly smaller learned synthetic set while preserving the original\ninformation. While training deep models on the small set of condensed images\ncan be extremely fast, their synthesis remains computationally expensive due to\nthe complex bi-level optimization and second-order derivative computation. In\nthis work, we propose a simple yet effective method that synthesizes condensed\nimages by matching feature distributions of the synthetic and original training\nimages in many sampled embedding spaces. Our method significantly reduces the\nsynthesis cost while achieving comparable or better performance. Thanks to its\nefficiency, we apply our method to more realistic and larger datasets with\nsophisticated neural architectures and obtain a significant performance boost.\nWe also show promising practical benefits of our method in continual learning\nand neural architecture search.", "published": "2021-10-08T15:02:30Z", "version": 3}, {"aid": "2110.05651", "authors": ["Felix Petersen", "Christian Borgelt", "Hilde Kuehne", "Oliver Deussen"], "title": "Learning with Algorithmic Supervision via Continuous Relaxations", "url": "http://arxiv.org/pdf/2110.05651v2", "summary": "The integration of algorithmic components into neural architectures has\ngained increased attention recently, as it allows training neural networks with\nnew forms of supervision such as ordering constraints or silhouettes instead of\nusing ground truth labels. Many approaches in the field focus on the continuous\nrelaxation of a specific task and show promising results in this context. But\nthe focus on single tasks also limits the applicability of the proposed\nconcepts to a narrow range of applications. In this work, we build on those\nideas to propose an approach that allows to integrate algorithms into\nend-to-end trainable neural network architectures based on a general\napproximation of discrete conditions. To this end, we relax these conditions in\ncontrol structures such as conditional statements, loops, and indexing, so that\nresulting algorithms are smoothly differentiable. To obtain meaningful\ngradients, each relevant variable is perturbed via logistic distributions and\nthe expectation value under this perturbation is approximated. We evaluate the\nproposed continuous relaxation model on four challenging tasks and show that it\ncan keep up with relaxations specifically designed for each individual task.", "published": "2021-10-11T23:52:42Z", "version": 2}, {"aid": "2110.08649", "authors": ["Avishek Joey Bose", "Marcus Brubaker", "Ivan Kobyzev"], "title": "Equivariant Finite Normalizing Flows", "url": "http://arxiv.org/pdf/2110.08649v2", "summary": "Generative modeling seeks to uncover the underlying factors that give rise to\nobserved data that can often be modeled as the natural symmetries that manifest\nthemselves through invariances and equivariances to certain transformation\nlaws. However, current approaches to representing these symmetries are couched\nin the formalism of continuous normalizing flows that require the construction\nof equivariant vector fields -- inhibiting their simple application to\nconventional higher dimensional generative modelling domains like natural\nimages. In this paper, we focus on building equivariant normalizing flows using\ndiscrete layers. We first theoretically prove the existence of an equivariant\nmap for compact groups whose actions are on compact spaces. We further\nintroduce three new equivariant flows: $G$-Residual Flows, $G$-Coupling Flows,\nand $G$-Inverse Autoregressive Flows that elevate classical Residual, Coupling,\nand Inverse Autoregressive Flows with equivariant maps to a prescribed group\n$G$. Our construction of $G$-Residual Flows are also universal, in the sense\nthat we prove an $G$-equivariant diffeomorphism can be exactly mapped by a\n$G$-residual flow. Finally, we complement our theoretical insights with\ndemonstrative experiments -- for the first time -- on image datasets like\nCIFAR-10 and show $G$-Equivariant Finite Normalizing flows lead to increased\ndata efficiency, faster convergence, and improved likelihood estimates.", "published": "2021-10-16T20:16:00Z", "version": 2}, {"aid": "2110.08890", "authors": ["Han Cai", "Chuang Gan", "Ji Lin", "Song Han"], "title": "Network Augmentation for Tiny Deep Learning", "url": "http://arxiv.org/pdf/2110.08890v2", "summary": "We introduce Network Augmentation (NetAug), a new training method for\nimproving the performance of tiny neural networks. Existing regularization\ntechniques (e.g., data augmentation, dropout) have shown much success on large\nneural networks by adding noise to overcome over-fitting. However, we found\nthese techniques hurt the performance of tiny neural networks. We argue that\ntraining tiny models are different from large models: rather than augmenting\nthe data, we should augment the model, since tiny models tend to suffer from\nunder-fitting rather than over-fitting due to limited capacity. To alleviate\nthis issue, NetAug augments the network (reverse dropout) instead of inserting\nnoise into the dataset or the network. It puts the tiny model into larger\nmodels and encourages it to work as a sub-model of larger models to get extra\nsupervision, in addition to functioning as an independent model. At test time,\nonly the tiny model is used for inference, incurring zero inference overhead.\nWe demonstrate the effectiveness of NetAug on image classification and object\ndetection. NetAug consistently improves the performance of tiny models,\nachieving up to 2.2% accuracy improvement on ImageNet. On object detection,\nachieving the same level of performance, NetAug requires 41% fewer MACs on\nPascal VOC and 38% fewer MACs on COCO than the baseline.", "published": "2021-10-17T18:48:41Z", "version": 2}, {"aid": "2110.11334", "authors": ["Jingkang Yang", "Kaiyang Zhou", "Yixuan Li", "Ziwei Liu"], "title": "Generalized Out-of-Distribution Detection: A Survey", "url": "http://arxiv.org/pdf/2110.11334v3", "summary": "Out-of-distribution (OOD) detection is critical to ensuring the reliability\nand safety of machine learning systems. For instance, in autonomous driving, we\nwould like the driving system to issue an alert and hand over the control to\nhumans when it detects unusual scenes or objects that it has never seen during\ntraining time and cannot make a safe decision. The term, OOD detection, first\nemerged in 2017 and since then has received increasing attention from the\nresearch community, leading to a plethora of methods developed, ranging from\nclassification-based to density-based to distance-based ones. Meanwhile,\nseveral other problems, including anomaly detection (AD), novelty detection\n(ND), open set recognition (OSR), and outlier detection (OD), are closely\nrelated to OOD detection in terms of motivation and methodology. Despite common\ngoals, these topics develop in isolation, and their subtle differences in\ndefinition and problem setting often confuse readers and practitioners. In this\nsurvey, we first present a unified framework called generalized OOD detection,\nwhich encompasses the five aforementioned problems, i.e., AD, ND, OSR, OOD\ndetection, and OD. Under our framework, these five problems can be seen as\nspecial cases or sub-tasks, and are easier to distinguish. We then review each\nof these five areas by summarizing their recent technical developments, with a\nspecial focus on OOD detection methodologies. We conclude this survey with open\nchallenges and potential research directions.", "published": "2021-10-21T17:59:41Z", "version": 3}, {"aid": "2110.11940", "authors": ["Scott C. Lowe", "Robert Earle", "Jason d'Eon", "Thomas Trappenberg", "Sageev Oore"], "title": "Logical Activation Functions: Logit-space equivalents of Probabilistic Boolean Operators", "url": "http://arxiv.org/pdf/2110.11940v2", "summary": "The choice of activation functions and their motivation is a long-standing\nissue within the neural network community. Neuronal representations within\nartificial neural networks are commonly understood as logits, representing the\nlog-odds score of presence of features within the stimulus. We derive\nlogit-space operators equivalent to probabilistic Boolean logic-gates AND, OR,\nand XNOR for independent probabilities. Such theories are important to\nformalize more complex dendritic operations in real neurons, and these\noperations can be used as activation functions within a neural network,\nintroducing probabilistic Boolean-logic as the core operation of the neural\nnetwork. Since these functions involve taking multiple exponents and\nlogarithms, they are computationally expensive and not well suited to be\ndirectly used within neural networks. Consequently, we construct efficient\napproximations named $\\text{AND}_\\text{AIL}$ (the AND operator Approximate for\nIndependent Logits), $\\text{OR}_\\text{AIL}$, and $\\text{XNOR}_\\text{AIL}$,\nwhich utilize only comparison and addition operations, have well-behaved\ngradients, and can be deployed as activation functions in neural networks. Like\nMaxOut, $\\text{AND}_\\text{AIL}$ and $\\text{OR}_\\text{AIL}$ are generalizations\nof ReLU to two-dimensions. While our primary aim is to formalize dendritic\ncomputations within a logit-space probabilistic-Boolean framework, we deploy\nthese new activation functions, both in isolation and in conjunction to\ndemonstrate their effectiveness on a variety of tasks including image\nclassification, transfer learning, abstract reasoning, and compositional\nzero-shot learning.", "published": "2021-10-22T17:49:42Z", "version": 2}, {"aid": "2110.12661", "authors": ["Jiawei Zhao", "Florian Sch\u00e4fer", "Anima Anandkumar"], "title": "ZerO Initialization: Initializing Neural Networks with only Zeros and Ones", "url": "http://arxiv.org/pdf/2110.12661v3", "summary": "Deep neural networks are usually initialized with random weights, with\nadequately selected initial variance to ensure stable signal propagation during\ntraining. However, selecting the appropriate variance becomes challenging\nespecially as the number of layers grows. In this work, we replace random\nweight initialization with a fully deterministic initialization scheme, viz.,\nZerO, which initializes the weights of networks with only zeros and ones (up to\na normalization factor), based on identity and Hadamard transforms. Through\nboth theoretical and empirical studies, we demonstrate that ZerO is able to\ntrain networks without damaging their expressivity. Applying ZerO on ResNet\nachieves state-of-the-art performance on various datasets, including ImageNet,\nwhich suggests random weights may be unnecessary for network initialization. In\naddition, ZerO has many benefits, such as training ultra deep networks (without\nbatch-normalization), exhibiting low-rank learning trajectories that result in\nlow-rank and sparse solutions, and improving training reproducibility.", "published": "2021-10-25T06:17:33Z", "version": 3}, {"aid": "2111.00070", "authors": ["Feng Zhu", "Andrew R. Sedler", "Harrison A. Grier", "Nauman Ahad", "Mark A. Davenport", "Matthew T. Kaufman", "Andrea Giovannucci", "Chethan Pandarinath"], "title": "Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time", "url": "http://arxiv.org/pdf/2111.00070v1", "summary": "Modern neural interfaces allow access to the activity of up to a million\nneurons within brain circuits. However, bandwidth limits often create a\ntrade-off between greater spatial sampling (more channels or pixels) and the\ntemporal frequency of sampling. Here we demonstrate that it is possible to\nobtain spatio-temporal super-resolution in neuronal time series by exploiting\nrelationships among neurons, embedded in latent low-dimensional population\ndynamics. Our novel neural network training strategy, selective backpropagation\nthrough time (SBTT), enables learning of deep generative models of latent\ndynamics from data in which the set of observed variables changes at each time\nstep. The resulting models are able to infer activity for missing samples by\ncombining observations with learned latent dynamics. We test SBTT applied to\nsequential autoencoders and demonstrate more efficient and higher-fidelity\ncharacterization of neural population dynamics in electrophysiological and\ncalcium imaging data. In electrophysiology, SBTT enables accurate inference of\nneuronal population dynamics with lower interface bandwidths, providing an\navenue to significant power savings for implanted neuroelectronic interfaces.\nIn applications to two-photon calcium imaging, SBTT accurately uncovers\nhigh-frequency temporal structure underlying neural population activity,\nsubstantially outperforming the current state-of-the-art. Finally, we\ndemonstrate that performance could be further improved by using limited,\nhigh-bandwidth sampling to pretrain dynamics models, and then using SBTT to\nadapt these models for sparsely-sampled data.", "published": "2021-10-29T20:18:29Z", "version": 1}, {"aid": "2111.00599", "authors": ["Armin Hadzic", "Grace M. Hwang", "Kechen Zhang", "Kevin M. Schultz", "Joseph D. Monaco"], "title": "Bayesian optimization of distributed neurodynamical controller models for spatial navigation", "url": "http://arxiv.org/pdf/2111.00599v1", "summary": "Dynamical systems models for controlling multi-agent swarms have demonstrated\nadvances toward resilient, decentralized navigation algorithms. We previously\nintroduced the NeuroSwarms controller, in which agent-based interactions were\nmodeled by analogy to neuronal network interactions, including attractor\ndynamics and phase synchrony, that have been theorized to operate within\nhippocampal place-cell circuits in navigating rodents. This complexity\nprecludes linear analyses of stability, controllability, and performance\ntypically used to study conventional swarm models. Further, tuning dynamical\ncontrollers by hand or grid search is often inadequate due to the complexity of\nobjectives, dimensionality of model parameters, and computational costs of\nsimulation-based sampling. Here, we present a framework for tuning dynamical\ncontroller models of autonomous multi-agent systems based on Bayesian\nOptimization (BayesOpt). Our approach utilizes a task-dependent objective\nfunction to train Gaussian Processes (GPs) as surrogate models to achieve\nadaptive and efficient exploration of a dynamical controller model's parameter\nspace. We demonstrate this approach by studying an objective function selecting\nfor NeuroSwarms behaviors that cooperatively localize and capture spatially\ndistributed rewards under time pressure. We generalized task performance across\nenvironments by combining scores for simulations in distinct geometries. To\nvalidate search performance, we compared high-dimensional clustering for high-\nvs. low-likelihood parameter points by visualizing sample trajectories in\nUniform Manifold Approximation and Projection (UMAP) embeddings. Our findings\nshow that adaptive, sample-efficient evaluation of the self-organizing\nbehavioral capacities of complex systems, including dynamical swarm\ncontrollers, can accelerate the translation of neuroscientific theory to\napplied domains.", "published": "2021-10-31T21:43:06Z", "version": 1}, {"aid": "2111.00737", "authors": ["Roman Mikhailov"], "title": "Homotopy patterns in group theory", "url": "http://arxiv.org/pdf/2111.00737v1", "summary": "This is a survey. The main subject of this survey is the homotopical or\nhomological nature of certain structures which appear in classical problems\nabout groups, Lie rings and group rings. It is well known that the\n(generalized) dimension subgroups have complicated combinatorial theories. In\nthis paper we show that, in certain cases, the complexity of these theories is\nbased on homotopy theory. The derived functors of non-additive functors,\nhomotopy groups of spheres, group homology etc appear naturally in problems\nformulated in purely group-theoretical terms. The variety of structures\nappearing in the considered context is very rich. In order to illustrate it, we\npresent this survey as a trip passing through examples having a similar nature.", "published": "2021-11-01T07:22:17Z", "version": 1}, {"aid": "2111.00772", "authors": ["Alexandros Stergiou", "Ronald Poppe"], "title": "AdaPool: Exponential Adaptive Pooling for Information-Retaining Downsampling", "url": "http://arxiv.org/pdf/2111.00772v3", "summary": "Pooling layers are essential building blocks of convolutional neural networks\n(CNNs), to reduce computational overhead and increase the receptive fields of\nproceeding convolutional operations. Their goal is to produce downsampled\nvolumes that closely resemble the input volume while, ideally, also being\ncomputationally and memory efficient. Meeting both these requirements remains a\nchallenge. To this end, we propose an adaptive and exponentially weighted\npooling method: adaPool. Our method learns a regional-specific fusion of two\nsets of pooling kernels that are based on the exponent of the Dice-Sorensen\ncoefficient and the exponential maximum, respectively. AdaPool improves the\npreservation of detail on a range of tasks including image and video\nclassification and object detection. A key property of adaPool is its\nbidirectional nature. In contrast to common pooling methods, the learned\nweights can also be used to upsample activation maps. We term this method\nadaUnPool. We evaluate adaUnPool on image and video super-resolution and frame\ninterpolation. For benchmarking, we introduce Inter4K, a novel high-quality,\nhigh frame-rate video dataset. Our experiments demonstrate that adaPool\nsystematically achieves better results across tasks and backbones, while\nintroducing a minor additional computational and memory overhead.", "published": "2021-11-01T08:50:37Z", "version": 3}, {"aid": "2111.03122", "authors": ["Marie-Constance Corsi", "Sylvain Chevallier", "Fabrizio De Vico Fallani", "Florian Yger"], "title": "Functional connectivity ensemble method to enhance BCI performance (FUCONE)", "url": "http://arxiv.org/pdf/2111.03122v2", "summary": "Functional connectivity is a key approach to investigate oscillatory\nactivities of the brain that provides important insights on the underlying\ndynamic of neuronal interactions and that is mostly applied for brain activity\nanalysis. Building on the advances in information geometry for brain-computer\ninterface, we propose a novel framework that combines functional connectivity\nestimators and covariance-based pipelines to classify mental states, such as\nmotor imagery. A Riemannian classifier is trained for each estimator and an\nensemble classifier combines the decisions in each feature space. A thorough\nassessment of the functional connectivity estimators is provided and the best\nperforming pipeline, called FUCONE, is evaluated on different conditions and\ndatasets. Using a meta-analysis to aggregate results across datasets, FUCONE\nperformed significantly better than all state-of-the-art methods. The\nperformance gain is mostly imputable to the improved diversity of the feature\nspaces, increasing the robustness of the ensemble classifier with respect to\nthe inter- and intra-subject variability.", "published": "2021-11-04T19:40:08Z", "version": 2}, {"aid": "2111.03270", "authors": ["Virender Ranga", "Shivam Gupta", "Jyoti Meena", "Priyansh Agrawal"], "title": "Automated Human Mind Reading Using EEG Signals for Seizure Detection", "url": "http://arxiv.org/pdf/2111.03270v1", "summary": "Epilepsy is one of the most occurring neurological disease globally emerged\nback in 4000 BC. It is affecting around 50 million people of all ages these\ndays. The trait of this disease is recurrent seizures. In the past few decades,\nthe treatments available for seizure control have improved a lot with the\nadvancements in the field of medical science and technology.\nElectroencephalogram (EEG) is a widely used technique for monitoring the brain\nactivity and widely popular for seizure region detection. It is performed\nbefore surgery and also to predict seizure at the time operation which is\nuseful in neuro stimulation device. But in most of cases visual examination is\ndone by neurologist in order to detect and classify patterns of the disease but\nthis requires a lot of pre-domain knowledge and experience. This all in turns\nput a pressure on neurosurgeons and leads to time wastage and also reduce their\naccuracy and efficiency. There is a need of some automated systems in arena of\ninformation technology like use of neural networks in deep learning which can\nassist neurologists. In the present paper, a model is proposed to give an\naccuracy of 98.33% which can be used for development of automated systems. The\ndeveloped system will significantly help neurologists in their performance.", "published": "2021-11-05T05:31:33Z", "version": 1}, {"aid": "2111.05826", "authors": ["Chitwan Saharia", "William Chan", "Huiwen Chang", "Chris A. Lee", "Jonathan Ho", "Tim Salimans", "David J. Fleet", "Mohammad Norouzi"], "title": "Palette: Image-to-Image Diffusion Models", "url": "http://arxiv.org/pdf/2111.05826v2", "summary": "This paper develops a unified framework for image-to-image translation based\non conditional diffusion models and evaluates this framework on four\nchallenging image-to-image translation tasks, namely colorization, inpainting,\nuncropping, and JPEG restoration. Our simple implementation of image-to-image\ndiffusion models outperforms strong GAN and regression baselines on all tasks,\nwithout task-specific hyper-parameter tuning, architecture customization, or\nany auxiliary loss or sophisticated new techniques needed. We uncover the\nimpact of an L2 vs. L1 loss in the denoising diffusion objective on sample\ndiversity, and demonstrate the importance of self-attention in the neural\narchitecture through empirical studies. Importantly, we advocate a unified\nevaluation protocol based on ImageNet, with human evaluation and sample quality\nscores (FID, Inception Score, Classification Accuracy of a pre-trained\nResNet-50, and Perceptual Distance against original images). We expect this\nstandardized evaluation protocol to play a role in advancing image-to-image\ntranslation research. Finally, we show that a generalist, multi-task diffusion\nmodel performs as well or better than task-specific specialist counterparts.\nCheck out https://diffusion-palette.github.io for an overview of the results.", "published": "2021-11-10T17:49:29Z", "version": 2}, {"aid": "2111.06021", "authors": ["Junjie Li", "Yixin Zhang", "Zilei Wang", "Saihui Hou", "Keyu Tu", "Man Zhang"], "title": "Probabilistic Contrastive Learning for Domain Adaptation", "url": "http://arxiv.org/pdf/2111.06021v6", "summary": "Contrastive learning has shown impressive success in enhancing feature\ndiscriminability for various visual tasks in a self-supervised manner, but the\nstandard contrastive paradigm (features+$\\ell_{2}$ normalization) has limited\nbenefits when applied in domain adaptation. We find that this is mainly because\nthe class weights (weights of the final fully connected layer) are ignored in\nthe domain adaptation optimization process, which makes it difficult for\nfeatures to cluster around the corresponding class weights. To solve this\nproblem, we propose the \\emph{simple but powerful} Probabilistic Contrastive\nLearning (PCL), which moves beyond the standard paradigm by removing $\\ell_{2}$\nnormalization and replacing the features with probabilities. PCL can guide the\nprobability distribution towards a one-hot configuration, thus minimizing the\ndiscrepancy between features and class weights. We conduct extensive\nexperiments to validate the effectiveness of PCL and observe consistent\nperformance gains on five tasks, i.e., Unsupervised/Semi-Supervised Domain\nAdaptation (UDA/SSDA), Semi-Supervised Learning (SSL), UDA Detection and\nSemantic Segmentation. Notably, for UDA Semantic Segmentation on SYNTHIA, PCL\nsurpasses the sophisticated CPSL-D by $>\\!2\\%$ in terms of mean IoU with a much\nlower training cost (PCL: 1*3090, 5 days v.s. CPSL-D: 4*V100, 11 days). Code is\navailable at https://github.com/ljjcoder/Probabilistic-Contrastive-Learning.", "published": "2021-11-11T02:08:07Z", "version": 6}, {"aid": "2111.09266", "authors": ["Yoshua Bengio", "Salem Lahlou", "Tristan Deleu", "Edward J. Hu", "Mo Tiwari", "Emmanuel Bengio"], "title": "GFlowNet Foundations", "url": "http://arxiv.org/pdf/2111.09266v4", "summary": "Generative Flow Networks (GFlowNets) have been introduced as a method to\nsample a diverse set of candidates in an active learning context, with a\ntraining objective that makes them approximately sample in proportion to a\ngiven reward function. In this paper, we show a number of additional\ntheoretical properties of GFlowNets. They can be used to estimate joint\nprobability distributions and the corresponding marginal distributions where\nsome variables are unspecified and, of particular interest, can represent\ndistributions over composite objects like sets and graphs. GFlowNets amortize\nthe work typically done by computationally expensive MCMC methods in a single\nbut trained generative pass. They could also be used to estimate partition\nfunctions and free energies, conditional probabilities of supersets\n(supergraphs) given a subset (subgraph), as well as marginal distributions over\nall supersets (supergraphs) of a given set (graph). We introduce variations\nenabling the estimation of entropy and mutual information, sampling from a\nPareto frontier, connections to reward-maximizing policies, and extensions to\nstochastic environments, continuous actions and modular energy functions.", "published": "2021-11-17T17:59:54Z", "version": 4}, {"aid": "2111.09953", "authors": ["Mark A. Kramer"], "title": "Golden rhythms as a theoretical framework for cross-frequency organization", "url": "http://arxiv.org/pdf/2111.09953v6", "summary": "While brain rhythms appear fundamental to brain function, why brain rhythms\nconsistently organize into the small set of discrete frequency bands observed\nremains unknown. Here we propose that rhythms separated by factors of the\ngolden ratio ($\\phi=(1+ \\sqrt{5})/2$) optimally support segregation and\ncross-frequency integration of information transmission in the brain. Organized\nby the golden ratio, pairs of transient rhythms support multiplexing by\nreducing interference between separate communication channels, and triplets of\ntransient rhythms support integration of signals to establish a hierarchy of\ncross-frequency interactions. We illustrate this framework in simulation and\napply this framework to propose four hypotheses.", "published": "2021-11-18T21:50:54Z", "version": 6}, {"aid": "2111.09996", "authors": ["Daniel Rebain", "Mark Matthews", "Kwang Moo Yi", "Dmitry Lagun", "Andrea Tagliasacchi"], "title": "LOLNeRF: Learn from One Look", "url": "http://arxiv.org/pdf/2111.09996v2", "summary": "We present a method for learning a generative 3D model based on neural\nradiance fields, trained solely from data with only single views of each\nobject. While generating realistic images is no longer a difficult task,\nproducing the corresponding 3D structure such that they can be rendered from\ndifferent views is non-trivial. We show that, unlike existing methods, one does\nnot need multi-view data to achieve this goal. Specifically, we show that by\nreconstructing many images aligned to an approximate canonical pose with a\nsingle network conditioned on a shared latent space, you can learn a space of\nradiance fields that models shape and appearance for a class of objects. We\ndemonstrate this by training models to reconstruct object categories using\ndatasets that contain only one view of each subject without depth or geometry\ninformation. Our experiments show that we achieve state-of-the-art results in\nnovel view synthesis and high-quality results for monocular depth prediction.", "published": "2021-11-19T01:20:01Z", "version": 2}, {"aid": "2111.10694", "authors": ["Sergei O. Ivanov"], "title": "An overview of rationalization theories of non-simply connected spaces and non-nilpotent groups", "url": "http://arxiv.org/pdf/2111.10694v3", "summary": "We give an overview of five rationalization theories for spaces\n(Bousfield-Kan's $\\mathbb Q$-completion; Sullivan's rationalization;\nBousfield's homology rationalization; Casacuberta-Peschke's\n$\\Omega$-rationalization; G\\'{o}mez-Tato-Halperin-Tanr\\'{e}'s $\\pi_1$-fiberwise\nrationalization) that extend the classical rationalization of simply connected\nspaces. We also give an overview of the corresponding rationalization theories\nfor groups ($\\mathbb Q$-completion; $H\\mathbb Q$-localization; Baumslag\nrationalization) that extend the classical Malcev completion.", "published": "2021-11-20T22:35:57Z", "version": 3}, {"aid": "2111.10734", "authors": ["Sheng Liu", "Aakash Kaku", "Weicheng Zhu", "Matan Leibovich", "Sreyas Mohan", "Boyang Yu", "Haoxiang Huang", "Laure Zanna", "Narges Razavian", "Jonathan Niles-Weed", "Carlos Fernandez-Granda"], "title": "Deep Probability Estimation", "url": "http://arxiv.org/pdf/2111.10734v4", "summary": "Reliable probability estimation is of crucial importance in many real-world\napplications where there is inherent (aleatoric) uncertainty.\nProbability-estimation models are trained on observed outcomes (e.g. whether it\nhas rained or not, or whether a patient has died or not), because the\nground-truth probabilities of the events of interest are typically unknown. The\nproblem is therefore analogous to binary classification, with the difference\nthat the objective is to estimate probabilities rather than predicting the\nspecific outcome. This work investigates probability estimation from\nhigh-dimensional data using deep neural networks. There exist several methods\nto improve the probabilities generated by these models but they mostly focus on\nmodel (epistemic) uncertainty. For problems with inherent uncertainty, it is\nchallenging to evaluate performance without access to ground-truth\nprobabilities. To address this, we build a synthetic dataset to study and\ncompare different computable metrics. We evaluate existing methods on the\nsynthetic data as well as on three real-world probability estimation tasks, all\nof which involve inherent uncertainty: precipitation forecasting from radar\nimages, predicting cancer patient survival from histopathology images, and\npredicting car crashes from dashcam videos. We also give a theoretical analysis\nof a model for high-dimensional probability estimation which reproduces several\nof the phenomena evinced in our experiments. Finally, we propose a new method\nfor probability estimation using neural networks, which modifies the training\nprocess to promote output probabilities that are consistent with empirical\nprobabilities computed from the data. The method outperforms existing\napproaches on most metrics on the simulated as well as real-world data.", "published": "2021-11-21T03:55:50Z", "version": 4}, {"aid": "2111.12417", "authors": ["Chenfei Wu", "Jian Liang", "Lei Ji", "Fan Yang", "Yuejian Fang", "Daxin Jiang", "Nan Duan"], "title": "N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion", "url": "http://arxiv.org/pdf/2111.12417v1", "summary": "This paper presents a unified multimodal pre-trained model called N\\\"UWA that\ncan generate new or manipulate existing visual data (i.e., images and videos)\nfor various visual synthesis tasks. To cover language, image, and video at the\nsame time for different scenarios, a 3D transformer encoder-decoder framework\nis designed, which can not only deal with videos as 3D data but also adapt to\ntexts and images as 1D and 2D data, respectively. A 3D Nearby Attention (3DNA)\nmechanism is also proposed to consider the nature of the visual data and reduce\nthe computational complexity. We evaluate N\\\"UWA on 8 downstream tasks.\nCompared to several strong baselines, N\\\"UWA achieves state-of-the-art results\non text-to-image generation, text-to-video generation, video prediction, etc.\nFurthermore, it also shows surprisingly good zero-shot capabilities on\ntext-guided image and video manipulation tasks. Project repo is\nhttps://github.com/microsoft/NUWA.", "published": "2021-11-24T11:02:12Z", "version": 1}, {"aid": "2111.12933", "authors": ["Tal Ridnik", "Gilad Sharir", "Avi Ben-Cohen", "Emanuel Ben-Baruch", "Asaf Noy"], "title": "ML-Decoder: Scalable and Versatile Classification Head", "url": "http://arxiv.org/pdf/2111.12933v2", "summary": "In this paper, we introduce ML-Decoder, a new attention-based classification\nhead. ML-Decoder predicts the existence of class labels via queries, and\nenables better utilization of spatial data compared to global average pooling.\nBy redesigning the decoder architecture, and using a novel group-decoding\nscheme, ML-Decoder is highly efficient, and can scale well to thousands of\nclasses. Compared to using a larger backbone, ML-Decoder consistently provides\na better speed-accuracy trade-off. ML-Decoder is also versatile - it can be\nused as a drop-in replacement for various classification heads, and generalize\nto unseen classes when operated with word queries. Novel query augmentations\nfurther improve its generalization ability. Using ML-Decoder, we achieve\nstate-of-the-art results on several classification tasks: on MS-COCO\nmulti-label, we reach 91.4% mAP; on NUS-WIDE zero-shot, we reach 31.1% ZSL mAP;\nand on ImageNet single-label, we reach with vanilla ResNet50 backbone a new top\nscore of 80.7%, without extra data or distillation. Public code is available\nat: https://github.com/Alibaba-MIIL/ML_Decoder", "published": "2021-11-25T06:25:30Z", "version": 2}, {"aid": "2111.13470", "authors": ["Shantanu Jaiswal", "Basura Fernando", "Cheston Tan"], "title": "TDAM: Top-Down Attention Module for Contextually Guided Feature Selection in CNNs", "url": "http://arxiv.org/pdf/2111.13470v3", "summary": "Attention modules for Convolutional Neural Networks (CNNs) are an effective\nmethod to enhance performance on multiple computer-vision tasks. While existing\nmethods appropriately model channel-, spatial- and self-attention, they\nprimarily operate in a feedforward bottom-up manner. Consequently, the\nattention mechanism strongly depends on the local information of a single input\nfeature map and does not incorporate relatively semantically-richer contextual\ninformation available at higher layers that can specify \"what and where to\nlook\" in lower-level feature maps through top-down information flow.\n  Accordingly, in this work, we propose a lightweight top-down attention module\n(TDAM) that iteratively generates a \"visual searchlight\" to perform channel and\nspatial modulation of its inputs and outputs more contextually-relevant feature\nmaps at each computation step. Our experiments indicate that TDAM enhances the\nperformance of CNNs across multiple object-recognition benchmarks and\noutperforms prominent attention modules while being more parameter and memory\nefficient. Further, TDAM-based models learn to \"shift attention\" by localizing\nindividual objects or features at each computation step without any explicit\nsupervision resulting in a 5% improvement for ResNet50 on weakly-supervised\nobject localization. Source code and models are publicly available at:\nhttps://github.com/shantanuj/TDAM_Top_down_attention_module .", "published": "2021-11-26T12:35:17Z", "version": 3}, {"aid": "2112.00390", "authors": ["Tomer Amit", "Tal Shaharbany", "Eliya Nachmani", "Lior Wolf"], "title": "SegDiff: Image Segmentation with Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2112.00390v3", "summary": "Diffusion Probabilistic Methods are employed for state-of-the-art image\ngeneration. In this work, we present a method for extending such models for\nperforming image segmentation. The method learns end-to-end, without relying on\na pre-trained backbone. The information in the input image and in the current\nestimation of the segmentation map is merged by summing the output of two\nencoders. Additional encoding layers and a decoder are then used to iteratively\nrefine the segmentation map, using a diffusion model. Since the diffusion model\nis probabilistic, it is applied multiple times, and the results are merged into\na final segmentation map. The new method produces state-of-the-art results on\nthe Cityscapes validation set, the Vaihingen building segmentation benchmark,\nand the MoNuSeg dataset.", "published": "2021-12-01T10:17:25Z", "version": 3}, {"aid": "2112.01526", "authors": ["Yanghao Li", "Chao-Yuan Wu", "Haoqi Fan", "Karttikeya Mangalam", "Bo Xiong", "Jitendra Malik", "Christoph Feichtenhofer"], "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection", "url": "http://arxiv.org/pdf/2112.01526v2", "summary": "In this paper, we study Multiscale Vision Transformers (MViTv2) as a unified\narchitecture for image and video classification, as well as object detection.\nWe present an improved version of MViT that incorporates decomposed relative\npositional embeddings and residual pooling connections. We instantiate this\narchitecture in five sizes and evaluate it for ImageNet classification, COCO\ndetection and Kinetics video recognition where it outperforms prior work. We\nfurther compare MViTv2s' pooling attention to window attention mechanisms where\nit outperforms the latter in accuracy/compute. Without bells-and-whistles,\nMViTv2 has state-of-the-art performance in 3 domains: 88.8% accuracy on\nImageNet classification, 58.7 boxAP on COCO object detection as well as 86.1%\non Kinetics-400 video classification. Code and models are available at\nhttps://github.com/facebookresearch/mvit.", "published": "2021-12-02T18:59:57Z", "version": 2}, {"aid": "2112.02902", "authors": ["Dawid Rymarczyk", "\u0141ukasz Struski", "Micha\u0142 G\u00f3rszczak", "Koryna Lewandowska", "Jacek Tabor", "Bartosz Zieli\u0144ski"], "title": "Interpretable Image Classification with Differentiable Prototypes Assignment", "url": "http://arxiv.org/pdf/2112.02902v2", "summary": "We introduce ProtoPool, an interpretable image classification model with a\npool of prototypes shared by the classes. The training is more straightforward\nthan in the existing methods because it does not require the pruning stage. It\nis obtained by introducing a fully differentiable assignment of prototypes to\nparticular classes. Moreover, we introduce a novel focal similarity function to\nfocus the model on the rare foreground features. We show that ProtoPool obtains\nstate-of-the-art accuracy on the CUB-200-2011 and the Stanford Cars datasets,\nsubstantially reducing the number of prototypes. We provide a theoretical\nanalysis of the method and a user study to show that our prototypes are more\ndistinctive than those obtained with competitive methods.", "published": "2021-12-06T10:03:32Z", "version": 2}, {"aid": "2112.03860", "authors": ["Dongzhuo Li"], "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models", "url": "http://arxiv.org/pdf/2112.03860v5", "summary": "Deep generative models such as GANs, normalizing flows, and diffusion models\nare powerful regularizers for inverse problems. They exhibit great potential\nfor helping reduce ill-posedness and attain high-quality results. However, the\nlatent tensors of such deep generative models can fall out of the desired\nhigh-dimensional standard Gaussian distribution during inversion, particularly\nin the presence of data noise and inaccurate forward models, leading to\nlow-fidelity solutions. To address this issue, we propose to reparameterize and\nGaussianize the latent tensors using novel differentiable data-dependent layers\nwherein custom operators are defined by solving optimization problems. These\nproposed layers constrain inverse problems to obtain high-fidelity\nin-distribution solutions. We validate our technique on three inversion tasks:\ncompressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear\nPDE-constrained inverse problem) using two representative deep generative\nmodels: StyleGAN2 and Glow. Our approach achieves state-of-the-art performance\nin terms of accuracy and consistency.", "published": "2021-12-07T17:53:09Z", "version": 5}, {"aid": "2112.05149", "authors": ["Boah Kim", "Inhwa Han", "Jong Chul Ye"], "title": "DiffuseMorph: Unsupervised Deformable Image Registration Using Diffusion Model", "url": "http://arxiv.org/pdf/2112.05149v2", "summary": "Deformable image registration is one of the fundamental tasks in medical\nimaging. Classical registration algorithms usually require a high computational\ncost for iterative optimizations. Although deep-learning-based methods have\nbeen developed for fast image registration, it is still challenging to obtain\nrealistic continuous deformations from a moving image to a fixed image with\nless topological folding problem. To address this, here we present a novel\ndiffusion-model-based image registration method, called DiffuseMorph.\nDiffuseMorph not only generates synthetic deformed images through reverse\ndiffusion but also allows image registration by deformation fields.\nSpecifically, the deformation fields are generated by the conditional score\nfunction of the deformation between the moving and fixed images, so that the\nregistration can be performed from continuous deformation by simply scaling the\nlatent feature of the score. Experimental results on 2D facial and 3D medical\nimage registration tasks demonstrate that our method provides flexible\ndeformations with topology preservation capability.", "published": "2021-12-09T08:41:23Z", "version": 2}, {"aid": "2201.00308", "authors": ["Kushagra Pandey", "Avideep Mukherjee", "Piyush Rai", "Abhishek Kumar"], "title": "DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents", "url": "http://arxiv.org/pdf/2201.00308v3", "summary": "Diffusion probabilistic models have been shown to generate state-of-the-art\nresults on several competitive image synthesis benchmarks but lack a\nlow-dimensional, interpretable latent space, and are slow at generation. On the\nother hand, standard Variational Autoencoders (VAEs) typically have access to a\nlow-dimensional latent space but exhibit poor sample quality. We present\nDiffuseVAE, a novel generative framework that integrates VAE within a diffusion\nmodel framework, and leverage this to design novel conditional\nparameterizations for diffusion models. We show that the resulting model equips\ndiffusion models with a low-dimensional VAE inferred latent code which can be\nused for downstream tasks like controllable synthesis. The proposed method also\nimproves upon the speed vs quality tradeoff exhibited in standard unconditional\nDDPM/DDIM models (for instance, FID of 16.47 vs 34.36 using a standard DDIM on\nthe CelebA-HQ-128 benchmark using T=10 reverse process steps) without having\nexplicitly trained for such an objective. Furthermore, the proposed model\nexhibits synthesis quality comparable to state-of-the-art models on standard\nimage synthesis benchmarks like CIFAR-10 and CelebA-64 while outperforming most\nexisting VAE-based methods. Lastly, we show that the proposed method exhibits\ninherent generalization to different types of noise in the conditioning signal.\nFor reproducibility, our source code is publicly available at\nhttps://github.com/kpandey008/DiffuseVAE.", "published": "2022-01-02T06:44:23Z", "version": 3}, {"aid": "2201.02233", "authors": ["Xuan Luo", "Zhen Han", "Lingkang Yang", "Lingling Zhang"], "title": "Consistent Style Transfer", "url": "http://arxiv.org/pdf/2201.02233v1", "summary": "Recently, attentional arbitrary style transfer methods have been proposed to\nachieve fine-grained results, which manipulates the point-wise similarity\nbetween content and style features for stylization. However, the attention\nmechanism based on feature points ignores the feature multi-manifold\ndistribution, where each feature manifold corresponds to a semantic region in\nthe image. Consequently, a uniform content semantic region is rendered by\nhighly different patterns from various style semantic regions, producing\ninconsistent stylization results with visual artifacts. We proposed the\nprogressive attentional manifold alignment (PAMA) to alleviate this problem,\nwhich repeatedly applies attention operations and space-aware interpolations.\nThe attention operation rearranges style features dynamically according to the\nspatial distribution of content features. This makes the content and style\nmanifolds correspond on the feature map. Then the space-aware interpolation\nadaptively interpolates between the corresponding content and style manifolds\nto increase their similarity. By gradually aligning the content manifolds to\nstyle manifolds, the proposed PAMA achieves state-of-the-art performance while\navoiding the inconsistency of semantic regions. Codes are available at\nhttps://github.com/computer-vision2022/PAMA.", "published": "2022-01-06T20:19:35Z", "version": 1}, {"aid": "2201.02863", "authors": ["Jaewoo Song", "Fangzhen Lin"], "title": "PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++", "url": "http://arxiv.org/pdf/2201.02863v6", "summary": "Standard deep learning algorithms are implemented using floating-point real\nnumbers. This presents an obstacle for implementing them on low-end devices\nwhich may not have dedicated floating-point units (FPUs). As a result,\nresearchers in tinyML have considered machine learning algorithms that can\ntrain and run a deep neural network (DNN) on a low-end device using integer\noperations only. In this paper we propose PocketNN, a light and self-contained\nproof-of-concept framework in pure C++ for the training and inference of DNNs\nusing only integers. Unlike other approaches, PocketNN directly operates on\nintegers without requiring any explicit quantization algorithms or customized\nfixed-point formats. This was made possible by pocket activations, which are a\nfamily of activation functions devised for integer-only DNNs, and an emerging\nDNN training algorithm called direct feedback alignment (DFA). Unlike the\nstandard backpropagation (BP), DFA trains each layer independently, thus\navoiding integer overflow which is a key problem when using BP with\ninteger-only operations. We used PocketNN to train some DNNs on two well-known\ndatasets, MNIST and Fashion-MNIST. Our experiments show that the DNNs trained\nwith our PocketNN achieved 96.98% and 87.7% accuracies on MNIST and\nFashion-MNIST datasets, respectively. The accuracies are very close to the\nequivalent DNNs trained using BP with floating-point real number operations,\nsuch that accuracy degradations were just 1.02%p and 2.09%p, respectively.\nFinally, our PocketNN has high compatibility and portability for low-end\ndevices as it is open source and implemented in pure C++ without any\ndependencies.", "published": "2022-01-08T16:52:34Z", "version": 6}, {"aid": "2201.03529", "authors": ["Utku Evci", "Vincent Dumoulin", "Hugo Larochelle", "Michael C. Mozer"], "title": "Head2Toe: Utilizing Intermediate Representations for Better Transfer Learning", "url": "http://arxiv.org/pdf/2201.03529v2", "summary": "Transfer-learning methods aim to improve performance in a data-scarce target\ndomain using a model pretrained on a data-rich source domain. A cost-efficient\nstrategy, linear probing, involves freezing the source model and training a new\nclassification head for the target domain. This strategy is outperformed by a\nmore costly but state-of-the-art method -- fine-tuning all parameters of the\nsource model to the target domain -- possibly because fine-tuning allows the\nmodel to leverage useful information from intermediate layers which is\notherwise discarded by the later pretrained layers. We explore the hypothesis\nthat these intermediate layers might be directly exploited. We propose a\nmethod, Head-to-Toe probing (Head2Toe), that selects features from all layers\nof the source model to train a classification head for the target-domain. In\nevaluations on the VTAB-1k, Head2Toe matches performance obtained with\nfine-tuning on average while reducing training and storage cost hundred folds\nor more, but critically, for out-of-distribution transfer, Head2Toe outperforms\nfine-tuning.", "published": "2022-01-10T18:40:07Z", "version": 2}, {"aid": "2201.03545", "authors": ["Zhuang Liu", "Hanzi Mao", "Chao-Yuan Wu", "Christoph Feichtenhofer", "Trevor Darrell", "Saining Xie"], "title": "A ConvNet for the 2020s", "url": "http://arxiv.org/pdf/2201.03545v2", "summary": "The \"Roaring 20s\" of visual recognition began with the introduction of Vision\nTransformers (ViTs), which quickly superseded ConvNets as the state-of-the-art\nimage classification model. A vanilla ViT, on the other hand, faces\ndifficulties when applied to general computer vision tasks such as object\ndetection and semantic segmentation. It is the hierarchical Transformers (e.g.,\nSwin Transformers) that reintroduced several ConvNet priors, making\nTransformers practically viable as a generic vision backbone and demonstrating\nremarkable performance on a wide variety of vision tasks. However, the\neffectiveness of such hybrid approaches is still largely credited to the\nintrinsic superiority of Transformers, rather than the inherent inductive\nbiases of convolutions. In this work, we reexamine the design spaces and test\nthe limits of what a pure ConvNet can achieve. We gradually \"modernize\" a\nstandard ResNet toward the design of a vision Transformer, and discover several\nkey components that contribute to the performance difference along the way. The\noutcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt.\nConstructed entirely from standard ConvNet modules, ConvNeXts compete favorably\nwith Transformers in terms of accuracy and scalability, achieving 87.8%\nImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection\nand ADE20K segmentation, while maintaining the simplicity and efficiency of\nstandard ConvNets.", "published": "2022-01-10T18:59:10Z", "version": 2}, {"aid": "2201.03904", "authors": ["Conor Heins", "Beren Millidge", "Daphne Demekas", "Brennan Klein", "Karl Friston", "Iain Couzin", "Alexander Tschantz"], "title": "pymdp: A Python library for active inference in discrete state spaces", "url": "http://arxiv.org/pdf/2201.03904v2", "summary": "Active inference is an account of cognition and behavior in complex systems\nwhich brings together action, perception, and learning under the theoretical\nmantle of Bayesian inference. Active inference has seen growing applications in\nacademic research, especially in fields that seek to model human or animal\nbehavior. While in recent years, some of the code arising from the active\ninference literature has been written in open source languages like Python and\nJulia, to-date, the most popular software for simulating active inference\nagents is the DEM toolbox of SPM, a MATLAB library originally developed for the\nstatistical analysis and modelling of neuroimaging data. Increasing interest in\nactive inference, manifested both in terms of sheer number as well as\ndiversifying applications across scientific disciplines, has thus created a\nneed for generic, widely-available, and user-friendly code for simulating\nactive inference in open-source scientific computing languages like Python. The\nPython package we present here, pymdp (see\nhttps://github.com/infer-actively/pymdp), represents a significant step in this\ndirection: namely, we provide the first open-source package for simulating\nactive inference with partially-observable Markov Decision Processes or POMDPs.\nWe review the package's structure and explain its advantages like modular\ndesign and customizability, while providing in-text code blocks along the way\nto demonstrate how it can be used to build and run active inference processes\nwith ease. We developed pymdp to increase the accessibility and exposure of the\nactive inference framework to researchers, engineers, and developers with\ndiverse disciplinary backgrounds. In the spirit of open-source software, we\nalso hope that it spurs new innovation, development, and collaboration in the\ngrowing active inference community.", "published": "2022-01-11T12:18:44Z", "version": 2}, {"aid": "2201.05624", "authors": ["Salvatore Cuomo", "Vincenzo Schiano di Cola", "Fabio Giampaolo", "Gianluigi Rozza", "Maziar Raissi", "Francesco Piccialli"], "title": "Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next", "url": "http://arxiv.org/pdf/2201.05624v4", "summary": "Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode\nmodel equations, like Partial Differential Equations (PDE), as a component of\nthe neural network itself. PINNs are nowadays used to solve PDEs, fractional\nequations, integral-differential equations, and stochastic PDEs. This novel\nmethodology has arisen as a multi-task learning framework in which a NN must\nfit observed data while reducing a PDE residual. This article provides a\ncomprehensive review of the literature on PINNs: while the primary goal of the\nstudy was to characterize these networks and their related advantages and\ndisadvantages. The review also attempts to incorporate publications on a\nbroader range of collocation-based physics informed neural networks, which\nstars form the vanilla PINN, as well as many other variants, such as\nphysics-constrained neural networks (PCNN), variational hp-VPINN, and\nconservative PINN (CPINN). The study indicates that most research has focused\non customizing the PINN through different activation functions, gradient\noptimization techniques, neural network structures, and loss function\nstructures. Despite the wide range of applications for which PINNs have been\nused, by demonstrating their ability to be more feasible in some contexts than\nclassical numerical techniques like Finite Element Method (FEM), advancements\nare still possible, most notably theoretical issues that remain unresolved.", "published": "2022-01-14T19:05:44Z", "version": 4}, {"aid": "2201.10801", "authors": ["Guangting Wang", "Yucheng Zhao", "Chuanxin Tang", "Chong Luo", "Wenjun Zeng"], "title": "When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism", "url": "http://arxiv.org/pdf/2201.10801v1", "summary": "Attention mechanism has been widely believed as the key to success of vision\ntransformers (ViTs), since it provides a flexible and powerful way to model\nspatial relationships. However, is the attention mechanism truly an\nindispensable part of ViT? Can it be replaced by some other alternatives? To\ndemystify the role of attention mechanism, we simplify it into an extremely\nsimple case: ZERO FLOP and ZERO parameter. Concretely, we revisit the shift\noperation. It does not contain any parameter or arithmetic calculation. The\nonly operation is to exchange a small portion of the channels between\nneighboring features. Based on this simple operation, we construct a new\nbackbone network, namely ShiftViT, where the attention layers in ViT are\nsubstituted by shift operations. Surprisingly, ShiftViT works quite well in\nseveral mainstream tasks, e.g., classification, detection, and segmentation.\nThe performance is on par with or even better than the strong baseline Swin\nTransformer. These results suggest that the attention mechanism might not be\nthe vital factor that makes ViT successful. It can be even replaced by a\nzero-parameter operation. We should pay more attentions to the remaining parts\nof ViT in the future work. Code is available at github.com/microsoft/SPACH.", "published": "2022-01-26T08:17:06Z", "version": 1}, {"aid": "2201.11793", "authors": ["Bahjat Kawar", "Michael Elad", "Stefano Ermon", "Jiaming Song"], "title": "Denoising Diffusion Restoration Models", "url": "http://arxiv.org/pdf/2201.11793v3", "summary": "Many interesting tasks in image restoration can be cast as linear inverse\nproblems. A recent family of approaches for solving these problems uses\nstochastic algorithms that sample from the posterior distribution of natural\nimages given the measurements. However, efficient solutions often require\nproblem-specific supervised training to model the posterior, whereas\nunsupervised methods that are not problem-specific typically rely on\ninefficient iterative methods. This work addresses these issues by introducing\nDenoising Diffusion Restoration Models (DDRM), an efficient, unsupervised\nposterior sampling method. Motivated by variational inference, DDRM takes\nadvantage of a pre-trained denoising diffusion generative model for solving any\nlinear inverse problem. We demonstrate DDRM's versatility on several image\ndatasets for super-resolution, deblurring, inpainting, and colorization under\nvarious amounts of measurement noise. DDRM outperforms the current leading\nunsupervised methods on the diverse ImageNet dataset in reconstruction quality,\nperceptual quality, and runtime, being 5x faster than the nearest competitor.\nDDRM also generalizes well for natural images out of the distribution of the\nobserved ImageNet training set.", "published": "2022-01-27T20:19:07Z", "version": 3}, {"aid": "2201.12680", "authors": ["Yuandong Tian"], "title": "Understanding Deep Contrastive Learning via Coordinate-wise Optimization", "url": "http://arxiv.org/pdf/2201.12680v7", "summary": "We show that Contrastive Learning (CL) under a broad family of loss functions\n(including InfoNCE) has a unified formulation of coordinate-wise optimization\non the network parameter $\\boldsymbol{\\theta}$ and pairwise importance\n$\\alpha$, where the \\emph{max player} $\\boldsymbol{\\theta}$ learns\nrepresentation for contrastiveness, and the \\emph{min player} $\\alpha$ puts\nmore weights on pairs of distinct samples that share similar representations.\nThe resulting formulation, called $\\alpha$-CL, unifies not only various\nexisting contrastive losses, which differ by how sample-pair importance\n$\\alpha$ is constructed, but also is able to extrapolate to give novel\ncontrastive losses beyond popular ones, opening a new avenue of contrastive\nloss design. These novel losses yield comparable (or better) performance on\nCIFAR10, STL-10 and CIFAR-100 than classic InfoNCE. Furthermore, we also\nanalyze the max player in detail: we prove that with fixed $\\alpha$, max player\nis equivalent to Principal Component Analysis (PCA) for deep linear network,\nand almost all local minima are global and rank-1, recovering optimal PCA\nsolutions. Finally, we extend our analysis on max player to 2-layer ReLU\nnetworks, showing that its fixed points can have higher ranks.", "published": "2022-01-29T23:08:34Z", "version": 7}, {"aid": "2202.00512", "authors": ["Tim Salimans", "Jonathan Ho"], "title": "Progressive Distillation for Fast Sampling of Diffusion Models", "url": "http://arxiv.org/pdf/2202.00512v2", "summary": "Diffusion models have recently shown great promise for generative modeling,\noutperforming GANs on perceptual quality and autoregressive models at density\nestimation. A remaining downside is their slow sampling time: generating high\nquality samples takes many hundreds or thousands of model evaluations. Here we\nmake two contributions to help eliminate this downside: First, we present new\nparameterizations of diffusion models that provide increased stability when\nusing few sampling steps. Second, we present a method to distill a trained\ndeterministic diffusion sampler, using many steps, into a new diffusion model\nthat takes half as many sampling steps. We then keep progressively applying\nthis distillation procedure to our model, halving the number of required\nsampling steps each time. On standard image generation benchmarks like\nCIFAR-10, ImageNet, and LSUN, we start out with state-of-the-art samplers\ntaking as many as 8192 steps, and are able to distill down to models taking as\nfew as 4 steps without losing much perceptual quality; achieving, for example,\na FID of 3.0 on CIFAR-10 in 4 steps. Finally, we show that the full progressive\ndistillation procedure does not take more time than it takes to train the\noriginal model, thus representing an efficient solution for generative modeling\nusing diffusion at both train and test time.", "published": "2022-02-01T16:07:25Z", "version": 2}, {"aid": "2202.04324", "authors": ["Edgar Y Walker", "Stephan Pohl", "Rachel N Denison", "David L Barack", "Jennifer Lee", "Ned Block", "Wei Ji Ma", "Florent Meyniel"], "title": "Studying the neural representations of uncertainty", "url": "http://arxiv.org/pdf/2202.04324v4", "summary": "The study of the brain's representations of uncertainty is a central topic in\nneuroscience. Unlike most quantities of which the neural representation is\nstudied, uncertainty is a property of an observer's beliefs about the world,\nwhich poses specific methodological challenges. We analyze how the literature\non the neural representations of uncertainty addresses those challenges and\ndistinguish between \"code-driven\" and \"correlational\" approaches. Code-driven\napproaches make assumptions about the neural code for representing world states\nand the associated uncertainty. By contrast, correlational approaches search\nfor relationships between uncertainty and neural activity without constraints\non the neural representation of the world state that this uncertainty\naccompanies. To compare these two approaches, we apply several criteria for\nneural representations: sensitivity, specificity, invariance, functionality.\nOur analysis reveals that the two approaches lead to different, but\ncomplementary findings, shaping new research questions and guiding future\nexperiments.", "published": "2022-02-09T08:13:36Z", "version": 4}, {"aid": "2202.06709", "authors": ["Namuk Park", "Songkuk Kim"], "title": "How Do Vision Transformers Work?", "url": "http://arxiv.org/pdf/2202.06709v4", "summary": "The success of multi-head self-attentions (MSAs) for computer vision is now\nindisputable. However, little is known about how MSAs work. We present\nfundamental explanations to help better understand the nature of MSAs. In\nparticular, we demonstrate the following properties of MSAs and Vision\nTransformers (ViTs): (1) MSAs improve not only accuracy but also generalization\nby flattening the loss landscapes. Such improvement is primarily attributable\nto their data specificity, not long-range dependency. On the other hand, ViTs\nsuffer from non-convex losses. Large datasets and loss landscape smoothing\nmethods alleviate this problem; (2) MSAs and Convs exhibit opposite behaviors.\nFor example, MSAs are low-pass filters, but Convs are high-pass filters.\nTherefore, MSAs and Convs are complementary; (3) Multi-stage neural networks\nbehave like a series connection of small individual models. In addition, MSAs\nat the end of a stage play a key role in prediction. Based on these insights,\nwe propose AlterNet, a model in which Conv blocks at the end of a stage are\nreplaced with MSA blocks. AlterNet outperforms CNNs not only in large data\nregimes but also in small data regimes. The code is available at\nhttps://github.com/xxxnell/how-do-vits-work.", "published": "2022-02-14T13:58:43Z", "version": 4}, {"aid": "2202.06768", "authors": ["Ivan Karpukhin", "Stanislav Dereka", "Sergey Kolesnikov"], "title": "Probabilistic Embeddings Revisited", "url": "http://arxiv.org/pdf/2202.06768v2", "summary": "In recent years, deep metric learning and its probabilistic extensions\nclaimed state-of-the-art results in the face verification task. Despite\nimprovements in face verification, probabilistic methods received little\nattention in the research community and practical applications. In this paper,\nwe, for the first time, perform an in-depth analysis of known probabilistic\nmethods in verification and retrieval tasks. We study different design choices\nand propose a simple extension, achieving new state-of-the-art results among\nprobabilistic methods. Finally, we study confidence prediction and show that it\ncorrelates with data quality, but contains little information about prediction\nerror probability. We thus provide a new confidence evaluation benchmark and\nestablish a baseline for future confidence prediction research. PyTorch\nimplementation is publicly released.", "published": "2022-02-14T14:37:54Z", "version": 2}, {"aid": "2202.06997", "authors": ["Guoyang Xie", "Yawen Huang", "Jinbao Wang", "Jiayi Lyu", "Feng Zheng", "Yefeng Zheng", "Yaochu Jin"], "title": "Cross-Modality Neuroimage Synthesis: A Survey", "url": "http://arxiv.org/pdf/2202.06997v7", "summary": "Multi-modality imaging improves disease diagnosis and reveals distinct\ndeviations in tissues with anatomical properties. The existence of completely\naligned and paired multi-modality neuroimaging data has proved its\neffectiveness in brain research. However, collecting fully aligned and paired\ndata is expensive or even impractical, since it faces many difficulties,\nincluding high cost, long acquisition time, image corruption, and privacy\nissues. An alternative solution is to explore unsupervised or weakly supervised\nlearning methods to synthesize the absent neuroimaging data. In this paper, we\nprovide a comprehensive review of cross-modality synthesis for neuroimages,\nfrom the perspectives of weakly supervised and unsupervised settings, loss\nfunctions, evaluation metrics, imaging modalities, datasets, and downstream\napplications based on synthesis. We begin by highlighting several opening\nchallenges for cross-modality neuroimage synthesis. Then, we discuss\nrepresentative architectures of cross-modality synthesis methods under\ndifferent supervisions. This is followed by a stepwise in-depth analysis to\nevaluate how cross-modality neuroimage synthesis improves the performance of\nits downstream tasks. Finally, we summarize the existing research findings and\npoint out future research directions. All resources are available at\nhttps://github.com/M-3LAB/awesome-multimodal-brain-image-systhesis", "published": "2022-02-14T19:29:08Z", "version": 7}, {"aid": "2202.07643", "authors": ["Johannes Brandstetter", "Max Welling", "Daniel E. Worrall"], "title": "Lie Point Symmetry Data Augmentation for Neural PDE Solvers", "url": "http://arxiv.org/pdf/2202.07643v2", "summary": "Neural networks are increasingly being used to solve partial differential\nequations (PDEs), replacing slower numerical solvers. However, a critical issue\nis that neural PDE solvers require high-quality ground truth data, which\nusually must come from the very solvers they are designed to replace. Thus, we\nare presented with a proverbial chicken-and-egg problem. In this paper, we\npresent a method, which can partially alleviate this problem, by improving\nneural PDE solver sample complexity -- Lie point symmetry data augmentation\n(LPSDA). In the context of PDEs, it turns out that we are able to\nquantitatively derive an exhaustive list of data transformations, based on the\nLie point symmetry group of the PDEs in question, something not possible in\nother application areas. We present this framework and demonstrate how it can\neasily be deployed to improve neural PDE solver sample complexity by an order\nof magnitude.", "published": "2022-02-15T18:43:17Z", "version": 2}, {"aid": "2202.08345", "authors": ["Hsueh-Ti Derek Liu", "Francis Williams", "Alec Jacobson", "Sanja Fidler", "Or Litany"], "title": "Learning Smooth Neural Functions via Lipschitz Regularization", "url": "http://arxiv.org/pdf/2202.08345v2", "summary": "Neural implicit fields have recently emerged as a useful representation for\n3D shapes. These fields are commonly represented as neural networks which map\nlatent descriptors and 3D coordinates to implicit function values. The latent\ndescriptor of a neural field acts as a deformation handle for the 3D shape it\nrepresents. Thus, smoothness with respect to this descriptor is paramount for\nperforming shape-editing operations. In this work, we introduce a novel\nregularization designed to encourage smooth latent spaces in neural fields by\npenalizing the upper bound on the field's Lipschitz constant. Compared with\nprior Lipschitz regularized networks, ours is computationally fast, can be\nimplemented in four lines of code, and requires minimal hyperparameter tuning\nfor geometric applications. We demonstrate the effectiveness of our approach on\nshape interpolation and extrapolation as well as partial shape reconstruction\nfrom 3D point clouds, showing both qualitative and quantitative improvements\nover existing state-of-the-art and non-regularized baselines.", "published": "2022-02-16T21:24:54Z", "version": 2}, {"aid": "2202.10688", "authors": ["Falih Gozi Febrinanto", "Feng Xia", "Kristen Moore", "Chandra Thapa", "Charu Aggarwal"], "title": "Graph Lifelong Learning: A Survey", "url": "http://arxiv.org/pdf/2202.10688v2", "summary": "Graph learning is a popular approach for performing machine learning on\ngraph-structured data. It has revolutionized the machine learning ability to\nmodel graph data to address downstream tasks. Its application is wide due to\nthe availability of graph data ranging from all types of networks to\ninformation systems. Most graph learning methods assume that the graph is\nstatic and its complete structure is known during training. This limits their\napplicability since they cannot be applied to problems where the underlying\ngraph grows over time and/or new tasks emerge incrementally. Such applications\nrequire a lifelong learning approach that can learn the graph continuously and\naccommodate new information whilst retaining previously learned knowledge.\nLifelong learning methods that enable continuous learning in regular domains\nlike images and text cannot be directly applied to continuously evolving graph\ndata, due to its irregular structure. As a result, graph lifelong learning is\ngaining attention from the research community. This survey paper provides a\ncomprehensive overview of recent advancements in graph lifelong learning,\nincluding the categorization of existing methods, and the discussions of\npotential applications and open research problems.", "published": "2022-02-22T06:14:07Z", "version": 2}, {"aid": "2202.10793", "authors": ["Yixuan He", "Xitong Zhang", "Junjie Huang", "Benedek Rozemberczki", "Mihai Cucuringu", "Gesine Reinert"], "title": "PyTorch Geometric Signed Directed: A Software Package on Graph Neural Networks for Signed and Directed Graphs", "url": "http://arxiv.org/pdf/2202.10793v6", "summary": "Networks are ubiquitous in many real-world applications (e.g., social\nnetworks encoding trust/distrust relationships, correlation networks arising\nfrom time series data). While many networks are signed or directed, or both,\nthere is a lack of unified software packages on graph neural networks (GNNs)\nspecially designed for signed and directed networks. In this paper, we present\nPyTorch Geometric Signed Directed (PyGSD), a software package which fills this\ngap. Along the way, we evaluate the implemented methods with experiments with a\nview to providing insights into which method to choose for a given task. The\ndeep learning framework consists of easy-to-use GNN models, synthetic and\nreal-world data, as well as task-specific evaluation metrics and loss functions\nfor signed and directed networks. As an extension library for PyG, our proposed\nsoftware is maintained with open-source releases, detailed documentation,\ncontinuous integration, unit tests and code coverage checks. The GitHub\nrepository of the library is\nhttps://github.com/SherylHYX/pytorch_geometric_signed_directed.", "published": "2022-02-22T10:25:59Z", "version": 6}, {"aid": "2202.12387", "authors": ["Zhuoning Yuan", "Yuexin Wu", "Zi-Hao Qiu", "Xianzhi Du", "Lijun Zhang", "Denny Zhou", "Tianbao Yang"], "title": "Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance", "url": "http://arxiv.org/pdf/2202.12387v4", "summary": "In this paper, we study contrastive learning from an optimization\nperspective, aiming to analyze and address a fundamental issue of existing\ncontrastive learning methods that either rely on a large batch size or a large\ndictionary of feature vectors. We consider a global objective for contrastive\nlearning, which contrasts each positive pair with all negative pairs for an\nanchor point. From the optimization perspective, we explain why existing\nmethods such as SimCLR require a large batch size in order to achieve a\nsatisfactory result. In order to remove such requirement, we propose a\nmemory-efficient Stochastic Optimization algorithm for solving the Global\nobjective of Contrastive Learning of Representations, named SogCLR. We show\nthat its optimization error is negligible under a reasonable condition after a\nsufficient number of iterations or is diminishing for a slightly different\nglobal contrastive objective. Empirically, we demonstrate that SogCLR with\nsmall batch size (e.g., 256) can achieve similar performance as SimCLR with\nlarge batch size (e.g., 8192) on self-supervised learning task on ImageNet-1K.\nWe also attempt to show that the proposed optimization technique is generic and\ncan be applied to solving other contrastive losses, e.g., two-way contrastive\nlosses for bimodal contrastive learning. The proposed method is implemented in\nour open-sourced library LibAUC (www.libauc.org).", "published": "2022-02-24T22:16:53Z", "version": 4}, {"aid": "2202.12498", "authors": ["Kun Han", "Shanlin sun", "Xiangyi Yan", "Chenyu You", "Hao Tang", "Junayed Naushad", "Haoyu Ma", "Deying Kong", "Xiaohui Xie"], "title": "Diffeomorphic Image Registration with Neural Velocity Field", "url": "http://arxiv.org/pdf/2202.12498v5", "summary": "Diffeomorphic image registration, offering smooth transformation and topology\npreservation, is required in many medical image analysis tasks.Traditional\nmethods impose certain modeling constraints on the space of admissible\ntransformations and use optimization to find the optimal transformation between\ntwo images. Specifying the right space of admissible transformations is\nchallenging: the registration quality can be poor if the space is too\nrestrictive, while the optimization can be hard to solve if the space is too\ngeneral. Recent learning-based methods, utilizing deep neural networks to learn\nthe transformation directly, achieve fast inference, but face challenges in\naccuracy due to the difficulties in capturing the small local deformations and\ngeneralization ability. Here we propose a new optimization-based method named\nDNVF (Diffeomorphic Image Registration with Neural Velocity Field) which\nutilizes deep neural network to model the space of admissible transformations.\nA multilayer perceptron (MLP) with sinusoidal activation function is used to\nrepresent the continuous velocity field and assigns a velocity vector to every\npoint in space, providing the flexibility of modeling complex deformations as\nwell as the convenience of optimization. Moreover, we propose a cascaded image\nregistration framework (Cas-DNVF) by combining the benefits of both\noptimization and learning based methods, where a fully convolutional neural\nnetwork (FCN) is trained to predict the initial deformation, followed by DNVF\nfor further refinement. Experiments on two large-scale 3D MR brain scan\ndatasets demonstrate that our proposed methods significantly outperform the\nstate-of-the-art registration methods.", "published": "2022-02-25T05:04:29Z", "version": 5}, {"aid": "2203.04946", "authors": ["Manoj Kumar", "Neil Houlsby", "Nal Kalchbrenner", "Ekin D. Cubuk"], "title": "Do better ImageNet classifiers assess perceptual similarity better?", "url": "http://arxiv.org/pdf/2203.04946v3", "summary": "Perceptual distances between images, as measured in the space of pre-trained\ndeep features, have outperformed prior low-level, pixel-based metrics on\nassessing perceptual similarity. While the capabilities of older and less\naccurate models such as AlexNet and VGG to capture perceptual similarity are\nwell known, modern and more accurate models are less studied. In this paper, we\npresent a large-scale empirical study to assess how well ImageNet classifiers\nperform on perceptual similarity. First, we observe a inverse correlation\nbetween ImageNet accuracy and Perceptual Scores of modern networks such as\nResNets, EfficientNets, and Vision Transformers: that is better classifiers\nachieve worse Perceptual Scores. Then, we examine the ImageNet\naccuracy/Perceptual Score relationship on varying the depth, width, number of\ntraining steps, weight decay, label smoothing, and dropout. Higher accuracy\nimproves Perceptual Score up to a certain point, but we uncover a Pareto\nfrontier between accuracies and Perceptual Score in the mid-to-high accuracy\nregime. We explore this relationship further using a number of plausible\nhypotheses such as distortion invariance, spatial frequency sensitivity, and\nalternative perceptual functions. Interestingly we discover shallow ResNets and\nResNets trained for less than 5 epochs only on ImageNet, whose emergent\nPerceptual Score matches the prior best networks trained directly on supervised\nhuman perceptual judgements. The checkpoints for the models in our study are\navailable at\nhttps://console.cloud.google.com/storage/browser/gresearch/perceptual_similarity.", "published": "2022-03-09T18:45:41Z", "version": 3}, {"aid": "2203.05328", "authors": ["Boyu Chen", "Peixia Li", "Lei Bai", "Lei Qiao", "Qiuhong Shen", "Bo Li", "Weihao Gan", "Wei Wu", "Wanli Ouyang"], "title": "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking", "url": "http://arxiv.org/pdf/2203.05328v2", "summary": "Exploiting a general-purpose neural architecture to replace hand-wired\ndesigns or inductive biases has recently drawn extensive interest. However,\nexisting tracking approaches rely on customized sub-modules and need prior\nknowledge for architecture selection, hindering the tracking development in a\nmore general system. This paper presents a Simplified Tracking architecture\n(SimTrack) by leveraging a transformer backbone for joint feature extraction\nand interaction. Unlike existing Siamese trackers, we serialize the input\nimages and concatenate them directly before the one-branch backbone. Feature\ninteraction in the backbone helps to remove well-designed interaction modules\nand produce a more efficient and effective framework. To reduce the information\nloss from down-sampling in vision transformers, we further propose a foveal\nwindow strategy, providing more diverse input patches with acceptable\ncomputational costs. Our SimTrack improves the baseline with 2.5%/2.6% AUC\ngains on LaSOT/TNL2K and gets results competitive with other specialized\ntracking algorithms without bells and whistles.", "published": "2022-03-10T12:20:58Z", "version": 2}, {"aid": "2203.05483", "authors": ["Bobak Kiani", "Randall Balestriero", "Yann LeCun", "Seth Lloyd"], "title": "projUNN: efficient method for training deep networks with unitary matrices", "url": "http://arxiv.org/pdf/2203.05483v3", "summary": "In learning with recurrent or very deep feed-forward networks, employing\nunitary matrices in each layer can be very effective at maintaining long-range\nstability. However, restricting network parameters to be unitary typically\ncomes at the cost of expensive parameterizations or increased training runtime.\nWe propose instead an efficient method based on rank-$k$ updates -- or their\nrank-$k$ approximation -- that maintains performance at a nearly optimal\ntraining runtime. We introduce two variants of this method, named Direct\n(projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can\nparameterize full $N$-dimensional unitary or orthogonal matrices with a\ntraining runtime scaling as $O(kN^2)$. Our method either projects low-rank\ngradients onto the closest unitary matrix (projUNN-T) or transports unitary\nmatrices in the direction of the low-rank gradient (projUNN-D). Even in the\nfastest setting ($k=1$), projUNN is able to train a model's unitary parameters\nto reach comparable performances against baseline implementations. In recurrent\nneural network settings, projUNN closely matches or exceeds benchmarked results\nfrom prior unitary neural networks. Finally, we preliminarily explore projUNN\nin training orthogonal convolutional neural networks, which are currently\nunable to outperform state of the art models but can potentially enhance\nstability and robustness at large depth.", "published": "2022-03-10T17:04:41Z", "version": 3}, {"aid": "2203.08207", "authors": ["Pei Xu", "Jean-Bernard Hayet", "Ioannis Karamouzas"], "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents", "url": "http://arxiv.org/pdf/2203.08207v4", "summary": "Predicting pedestrian movement is critical for human behavior analysis and\nalso for safe and efficient human-agent interactions. However, despite\nsignificant advancements, it is still challenging for existing approaches to\ncapture the uncertainty and multimodality of human navigation decision making.\nIn this paper, we propose SocialVAE, a novel approach for human trajectory\nprediction. The core of SocialVAE is a timewise variational autoencoder\narchitecture that exploits stochastic recurrent neural networks to perform\nprediction, combined with a social attention mechanism and a backward posterior\napproximation to allow for better extraction of pedestrian navigation\nstrategies. We show that SocialVAE improves current state-of-the-art\nperformance on several pedestrian trajectory prediction benchmarks, including\nthe ETH/UCY benchmark, Stanford Drone Dataset, and SportVU NBA movement\ndataset. Code is available at: https://github.com/xupei0610/SocialVAE.", "published": "2022-03-15T19:14:33Z", "version": 4}, {"aid": "2203.09081", "authors": ["Yibo Yang", "Shixiang Chen", "Xiangtai Li", "Liang Xie", "Zhouchen Lin", "Dacheng Tao"], "title": "Inducing Neural Collapse in Imbalanced Learning: Do We Really Need a Learnable Classifier at the End of Deep Neural Network?", "url": "http://arxiv.org/pdf/2203.09081v3", "summary": "Modern deep neural networks for classification usually jointly learn a\nbackbone for representation and a linear classifier to output the logit of each\nclass. A recent study has shown a phenomenon called neural collapse that the\nwithin-class means of features and the classifier vectors converge to the\nvertices of a simplex equiangular tight frame (ETF) at the terminal phase of\ntraining on a balanced dataset. Since the ETF geometric structure maximally\nseparates the pair-wise angles of all classes in the classifier, it is natural\nto raise the question, why do we spend an effort to learn a classifier when we\nknow its optimal geometric structure? In this paper, we study the potential of\nlearning a neural network for classification with the classifier randomly\ninitialized as an ETF and fixed during training. Our analytical work based on\nthe layer-peeled model indicates that the feature learning with a fixed ETF\nclassifier naturally leads to the neural collapse state even when the dataset\nis imbalanced among classes. We further show that in this case the cross\nentropy (CE) loss is not necessary and can be replaced by a simple squared loss\nthat shares the same global optimality but enjoys a better convergence\nproperty. Our experimental results show that our method is able to bring\nsignificant improvements with faster convergence on multiple imbalanced\ndatasets.", "published": "2022-03-17T04:34:28Z", "version": 3}, {"aid": "2203.10761", "authors": ["Zicheng Liu", "Siyuan Li", "Ge Wang", "Cheng Tan", "Lirong Wu", "Stan Z. Li"], "title": "Harnessing Hard Mixed Samples with Decoupled Regularizer", "url": "http://arxiv.org/pdf/2203.10761v3", "summary": "Mixup is an efficient data augmentation approach that improves the\ngeneralization of neural networks by smoothing the decision boundary with mixed\ndata. Recently, dynamic mixup methods have improved previous static policies\neffectively (e.g., linear interpolation) by maximizing target-related salient\nregions in mixed samples, but excessive additional time costs are not\nacceptable. These additional computational overheads mainly come from\noptimizing the mixed samples according to the mixed labels. However, we found\nthat the extra optimizing step may be redundant because label-mismatched mixed\nsamples are informative hard mixed samples for deep models to localize\ndiscriminative features. In this paper, we thus are not trying to propose a\nmore complicated dynamic mixup policy but rather an efficient mixup objective\nfunction with a decoupled regularizer named Decoupled Mixup (DM). The primary\neffect is that DM can adaptively utilize those hard mixed samples to mine\ndiscriminative features without losing the original smoothness of mixup. As a\nresult, DM enables static mixup methods to achieve comparable or even exceed\nthe performance of dynamic methods without any extra computation. This also\nleads to an interesting objective design problem for mixup training that we\nneed to focus on both smoothing the decision boundaries and identifying\ndiscriminative features. Extensive experiments on supervised and\nsemi-supervised learning benchmarks across seven datasets validate the\neffectiveness of DM as a plug-and-play module. Source code and models are\navailable at https://github.com/Westlake-AI/openmixup", "published": "2022-03-21T07:12:18Z", "version": 3}, {"aid": "2203.10810", "authors": ["Patricia Wollstadt", "Daniel L. Rathbun", "W. Martin Usrey and", "Andr\u00e9 Moraes Bastos", "Michael Lindner", "Viola Priesemann", "Michael Wibral"], "title": "Information-theoretic analyses of neural data to minimize the effect of researchers' assumptions in predictive coding studies", "url": "http://arxiv.org/pdf/2203.10810v3", "summary": "Studies investigating neural information processing often implicitly ask\nboth, which processing strategy out of several alternatives is used and how\nthis strategy is implemented in neural dynamics. A prime example are studies on\npredictive coding. These often ask if confirmed predictions about inputs or\npredictions errors between internal predictions and inputs are passed on in a\nhierarchical neural system--while at the same time looking for the neural\ncorrelates of coding for errors and predictions. If we do not know exactly what\na neural system predicts at any given moment, this results in a circular\nanalysis--as has been criticized correctly. To circumvent such circular\nanalysis, we propose to express information processing strategies (such as\npredictive coding) by local information-theoretic quantities, such that they\ncan be estimated directly from neural data. We demonstrate our approach by\ninvestigating two opposing accounts of predictive coding-like processing\nstrategies, where we quantify the building blocks of predictive coding, namely\npredictability of inputs and transfer of information, by local active\ninformation storage and local transfer entropy. We define testable hypotheses\non the relationship of both quantities to identify which of the assumed\nstrategies was used. We demonstrate our approach on spiking data from the\nretinogeniculate synapse of the cat. Applying our local information dynamics\nframework, we are able to show that the synapse codes for predictable rather\nthan surprising input. To support our findings, we apply measures from partial\ninformation decomposition, which allow to differentiate if the transferred\ninformation is primarily bottom-up sensory input or information transferred\nconditionally on the current state of the synapse. Supporting our local\ninformation-theoretic results, we find that the synapse preferentially\ntransfers bottom-up information.", "published": "2022-03-21T09:03:53Z", "version": 3}, {"aid": "2203.11156", "authors": ["Junqi Tang", "Subhadip Mukherjee", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Operator Sketching for Deep Unrolling Networks", "url": "http://arxiv.org/pdf/2203.11156v3", "summary": "In this work we propose a new paradigm for designing efficient deep unrolling\nnetworks using operator sketching. The deep unrolling networks are currently\nthe state-of-the-art solutions for imaging inverse problems. However, for\nhigh-dimensional imaging tasks, especially the 3D cone-beam X-ray CT and 4D MRI\nimaging, the deep unrolling schemes typically become inefficient both in terms\nof memory and computation, due to the need of computing multiple times the\nhigh-dimensional forward and adjoint operators. Recently researchers have found\nthat such limitations can be partially addressed by stochastic unrolling with\nsubsets of operators, inspired by the success of stochastic first-order\noptimization. In this work, we propose a further acceleration upon stochastic\nunrolling, using sketching techniques to approximate products in the\nhigh-dimensional image space. The operator sketching can be jointly applied\nwith stochastic unrolling for the best acceleration and compression\nperformance. Our numerical experiments on X-ray CT image reconstruction\ndemonstrate the remarkable effectiveness of our sketched unrolling schemes.", "published": "2022-03-21T17:34:18Z", "version": 3}, {"aid": "2203.11862", "authors": ["Ariel Elnekave", "Yair Weiss"], "title": "Generating natural images with direct Patch Distributions Matching", "url": "http://arxiv.org/pdf/2203.11862v3", "summary": "Many traditional computer vision algorithms generate realistic images by\nrequiring that each patch in the generated image be similar to a patch in a\ntraining image and vice versa. Recently, this classical approach has been\nreplaced by adversarial training with a patch discriminator. The adversarial\napproach avoids the computational burden of finding nearest neighbors of\npatches but often requires very long training times and may fail to match the\ndistribution of patches. In this paper we leverage the recently developed\nSliced Wasserstein Distance and develop an algorithm that explicitly and\nefficiently minimizes the distance between patch distributions in two images.\nOur method is conceptually simple, requires no training and can be implemented\nin a few lines of codes. On a number of image generation tasks we show that our\nresults are often superior to single-image-GANs, require no training, and can\ngenerate high quality images in a few seconds. Our implementation is available\nat https://github.com/ariel415el/GPDM", "published": "2022-03-22T16:38:52Z", "version": 3}, {"aid": "2204.05133", "authors": ["Arthur Juliani", "Kai Arulkumaran", "Shuntaro Sasai", "Ryota Kanai"], "title": "On the link between conscious function and general intelligence in humans and machines", "url": "http://arxiv.org/pdf/2204.05133v2", "summary": "In popular media, there is often a connection drawn between the advent of\nawareness in artificial agents and those same agents simultaneously achieving\nhuman or superhuman level intelligence. In this work, we explore the validity\nand potential application of this seemingly intuitive link between\nconsciousness and intelligence. We do so by examining the cognitive abilities\nassociated with three contemporary theories of conscious function: Global\nWorkspace Theory (GWT), Information Generation Theory (IGT), and Attention\nSchema Theory (AST). We find that all three theories specifically relate\nconscious function to some aspect of domain-general intelligence in humans.\nWith this insight, we turn to the field of Artificial Intelligence (AI) and\nfind that, while still far from demonstrating general intelligence, many\nstate-of-the-art deep learning methods have begun to incorporate key aspects of\neach of the three functional theories. Having identified this trend, we use the\nmotivating example of mental time travel in humans to propose ways in which\ninsights from each of the three theories may be combined into a single unified\nand implementable model. Given that it is made possible by cognitive abilities\nunderlying each of the three functional theories, artificial agents capable of\nmental time travel would not only possess greater general intelligence than\ncurrent approaches, but also be more consistent with our current understanding\nof the functional role of consciousness in humans, thus making it a promising\nnear-term goal for AI research.", "published": "2022-03-24T02:22:23Z", "version": 2}, {"aid": "2203.14194", "authors": ["Chang Sub Kim"], "title": "Free energy and inference in living systems", "url": "http://arxiv.org/pdf/2203.14194v2", "summary": "Organisms are nonequilibrium, stationary systems self-organized via\nspontaneous symmetry breaking and undergoing metabolic cycles with broken\ndetailed balance in the environment. The thermodynamic free-energy principle\ndescribes an organism's homeostasis as the regulation of biochemical work\nconstrained by the physical free-energy cost. In contrast, recent research in\nneuroscience and theoretical biology explains a higher organism's homeostasis\nand allostasis as Bayesian inference facilitated by the informational free\nenergy. As an integrated approach to living systems, this study presents a\nfree-energy minimization theory overarching the essential features of both the\nthermodynamic and neuroscientific free-energy principles. Our results reveal\nthat the perception and action of animals result from active inference entailed\nby free-energy minimization in the brain, and the brain operates as\nSchr{\\\"o}dinger's machine conducting the neural mechanics of minimizing sensory\nuncertainty. A parsimonious model suggests that the Bayesian brain develops the\noptimal trajectories in neural manifolds and induces a dynamic bifurcation\nbetween neural attractors in the process of active inference.", "published": "2022-03-27T03:16:06Z", "version": 2}, {"aid": "2203.15544", "authors": ["Andrew Dudzik", "Petar Veli\u010dkovi\u0107"], "title": "Graph Neural Networks are Dynamic Programmers", "url": "http://arxiv.org/pdf/2203.15544v3", "summary": "Recent advances in neural algorithmic reasoning with graph neural networks\n(GNNs) are propped up by the notion of algorithmic alignment. Broadly, a neural\nnetwork will be better at learning to execute a reasoning task (in terms of\nsample complexity) if its individual components align well with the target\nalgorithm. Specifically, GNNs are claimed to align with dynamic programming\n(DP), a general problem-solving strategy which expresses many polynomial-time\nalgorithms. However, has this alignment truly been demonstrated and\ntheoretically quantified? Here we show, using methods from category theory and\nabstract algebra, that there exists an intricate connection between GNNs and\nDP, going well beyond the initial observations over individual algorithms such\nas Bellman-Ford. Exposing this connection, we easily verify several prior\nfindings in the literature, produce better-grounded GNN architectures for\nedge-centric tasks, and demonstrate empirical results on the CLRS algorithmic\nreasoning benchmark. We hope our exposition will serve as a foundation for\nbuilding stronger algorithmically aligned GNNs.", "published": "2022-03-29T13:27:28Z", "version": 3}, {"aid": "2204.01723", "authors": ["Adam Kohan", "Edward A. Rietman", "Hava T. Siegelmann"], "title": "Signal Propagation: A Framework for Learning and Inference In a Forward Pass", "url": "http://arxiv.org/pdf/2204.01723v2", "summary": "We propose a new learning framework, signal propagation (sigprop), for\npropagating a learning signal and updating neural network parameters via a\nforward pass, as an alternative to backpropagation. In sigprop, there is only\nthe forward path for inference and learning. So, there are no structural or\ncomputational constraints necessary for learning to take place, beyond the\ninference model itself, such as feedback connectivity, weight transport, or a\nbackward pass, which exist under backpropagation based approaches. That is,\nsigprop enables global supervised learning with only a forward path. This is\nideal for parallel training of layers or modules. In biology, this explains how\nneurons without feedback connections can still receive a global learning\nsignal. In hardware, this provides an approach for global supervised learning\nwithout backward connectivity. Sigprop by construction has compatibility with\nmodels of learning in the brain and in hardware than backpropagation, including\nalternative approaches relaxing learning constraints. We also demonstrate that\nsigprop is more efficient in time and memory than they are. To further explain\nthe behavior of sigprop, we provide evidence that sigprop provides useful\nlearning signals in context to backpropagation. To further support relevance to\nbiological and hardware learning, we use sigprop to train continuous time\nneural networks with Hebbian updates, and train spiking neural networks with\nonly the voltage or with biologically and hardware compatible surrogate\nfunctions.", "published": "2022-04-04T04:41:59Z", "version": 2}, {"aid": "2204.03740", "authors": ["Federico Adolfi", "Jeffrey S. Bowers", "David Poeppel"], "title": "Successes and critical failures of neural networks in capturing human-like speech recognition", "url": "http://arxiv.org/pdf/2204.03740v4", "summary": "Natural and artificial audition can in principle acquire different solutions\nto a given problem. The constraints of the task, however, can nudge the\ncognitive science and engineering of audition to qualitatively converge,\nsuggesting that a closer mutual examination would potentially enrich artificial\nhearing systems and process models of the mind and brain. Speech recognition -\nan area ripe for such exploration - is inherently robust in humans to a number\ntransformations at various spectrotemporal granularities. To what extent are\nthese robustness profiles accounted for by high-performing neural network\nsystems? We bring together experiments in speech recognition under a single\nsynthesis framework to evaluate state-of-the-art neural networks as\nstimulus-computable, optimized observers. In a series of experiments, we (1)\nclarify how influential speech manipulations in the literature relate to each\nother and to natural speech, (2) show the granularities at which machines\nexhibit out-of-distribution robustness, reproducing classical perceptual\nphenomena in humans, (3) identify the specific conditions where model\npredictions of human performance differ, and (4) demonstrate a crucial failure\nof all artificial systems to perceptually recover where humans do, suggesting\nalternative directions for theory and model building. These findings encourage\na tighter synergy between the cognitive science and engineering of audition.", "published": "2022-04-06T06:35:10Z", "version": 4}, {"aid": "2204.02849", "authors": ["Shelly Sheynin", "Oron Ashual", "Adam Polyak", "Uriel Singer", "Oran Gafni", "Eliya Nachmani", "Yaniv Taigman"], "title": "KNN-Diffusion: Image Generation via Large-Scale Retrieval", "url": "http://arxiv.org/pdf/2204.02849v2", "summary": "Recent text-to-image models have achieved impressive results. However, since\nthey require large-scale datasets of text-image pairs, it is impractical to\ntrain them on new domains where data is scarce or not labeled. In this work, we\npropose using large-scale retrieval methods, in particular, efficient\nk-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a\nsubstantially small and efficient text-to-image diffusion model without any\ntext, (2) generating out-of-distribution images by simply swapping the\nretrieval database at inference time, and (3) performing text-driven local\nsemantic manipulations while preserving object identity. To demonstrate the\nrobustness of our method, we apply our kNN approach on two state-of-the-art\ndiffusion backbones, and show results on several different datasets. As\nevaluated by human studies and automatic metrics, our method achieves\nstate-of-the-art results compared to existing approaches that train\ntext-to-image generation models using images only (without paired text data)", "published": "2022-04-06T14:13:35Z", "version": 2}, {"aid": "2204.03354", "authors": ["Achim Schilling", "William Sedley", "Richard Gerum", "Claus Metzner", "Konstantin Tziridis", "Andreas Maier", "Holger Schulze", "Fan-Gang Zeng", "Karl J. Friston", "Patrick Krauss"], "title": "Predictive coding and stochastic resonance as fundamental principles of auditory perception", "url": "http://arxiv.org/pdf/2204.03354v2", "summary": "How is information processed in the brain during perception? Mechanistic\ninsight is achieved only when experiments are employed to test formal or\ncomputational models. In analogy to lesion studies, phantom perception may\nserve as a vehicle to understand the fundamental processing principles\nunderlying auditory perception. With a special focus on tinnitus -- as the\nprime example of auditory phantom perception -- we review recent work at the\nintersection of artificial intelligence, psychology, and neuroscience. In\nparticular, we discuss why everyone with tinnitus suffers from hearing loss,\nbut not everyone with hearing loss suffers from tinnitus. We argue that the\nincrease of sensory precision due to Bayesian inference could be caused by\nintrinsic neural noise and lead to a prediction error in the cerebral cortex.\nHence, two fundamental processing principles - being ubiquitous in the brain -\nprovide the most explanatory power for the emergence of tinnitus: predictive\ncoding as a top-down, and stochastic resonance as a complementary bottom-up\nmechanism. We conclude that both principles play a crucial role in healthy\nauditory perception.", "published": "2022-04-07T10:47:58Z", "version": 2}, {"aid": "2204.03475", "authors": ["Tal Ridnik", "Hussam Lawen", "Emanuel Ben-Baruch", "Asaf Noy"], "title": "Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results", "url": "http://arxiv.org/pdf/2204.03475v2", "summary": "ImageNet serves as the primary dataset for evaluating the quality of\ncomputer-vision models. The common practice today is training each architecture\nwith a tailor-made scheme, designed and tuned by an expert. In this paper, we\npresent a unified scheme for training any backbone on ImageNet. The scheme,\nnamed USI (Unified Scheme for ImageNet), is based on knowledge distillation and\nmodern tricks. It requires no adjustments or hyper-parameters tuning between\ndifferent models, and is efficient in terms of training times. We test USI on a\nwide variety of architectures, including CNNs, Transformers, Mobile-oriented\nand MLP-only. On all models tested, USI outperforms previous state-of-the-art\nresults. Hence, we are able to transform training on ImageNet from an\nexpert-oriented task to an automatic seamless routine. Since USI accepts any\nbackbone and trains it to top results, it also enables to perform methodical\ncomparisons, and identify the most efficient backbones along the speed-accuracy\nPareto curve. Implementation is available\nat:https://github.com/Alibaba-MIIL/Solving_ImageNet", "published": "2022-04-07T14:43:58Z", "version": 2}, {"aid": "2204.03638", "authors": ["Songwei Ge", "Thomas Hayes", "Harry Yang", "Xi Yin", "Guan Pang", "David Jacobs", "Jia-Bin Huang", "Devi Parikh"], "title": "Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer", "url": "http://arxiv.org/pdf/2204.03638v4", "summary": "Videos are created to express emotion, exchange information, and share\nexperiences. Video synthesis has intrigued researchers for a long time. Despite\nthe rapid progress driven by advances in visual synthesis, most existing\nstudies focus on improving the frames' quality and the transitions between\nthem, while little progress has been made in generating longer videos. In this\npaper, we present a method that builds on 3D-VQGAN and transformers to generate\nvideos with thousands of frames. Our evaluation shows that our model trained on\n16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse,\nand Taichi-HD datasets can generate diverse, coherent, and high-quality long\nvideos. We also showcase conditional extensions of our approach for generating\nmeaningful long videos by incorporating temporal information with text and\naudio. Videos and code can be found at\nhttps://songweige.github.io/projects/tats/index.html.", "published": "2022-04-07T17:59:02Z", "version": 4}, {"aid": "2204.06718", "authors": ["Hengyue Pan", "Yixin Chen", "Xin Niu", "Wenbo Zhou", "Dongsheng Li"], "title": "Learning Convolutional Neural Networks in the Frequency Domain", "url": "http://arxiv.org/pdf/2204.06718v10", "summary": "Convolutional neural network (CNN) has achieved impressive success in\ncomputer vision during the past few decades. The image convolution operation\nhelps CNNs to get good performance on image-related tasks. However, the image\nconvolution has high computation complexity and hard to be implemented. This\npaper proposes the CEMNet, which can be trained in the frequency domain. The\nmost important motivation of this research is that we can use the\nstraightforward element-wise multiplication operation to replace the image\nconvolution in the frequency domain based on the Cross-Correlation Theorem,\nwhich obviously reduces the computation complexity. We further introduce a\nWeight Fixation mechanism to alleviate the problem of over-fitting, and analyze\nthe working behavior of Batch Normalization, Leaky ReLU, and Dropout in the\nfrequency domain to design their counterparts for CEMNet. Also, to deal with\ncomplex inputs brought by Discrete Fourier Transform, we design a two-branches\nnetwork structure for CEMNet. Experimental results imply that CEMNet achieves\ngood performance on MNIST and CIFAR-10 databases.", "published": "2022-04-14T03:08:40Z", "version": 10}, {"aid": "2204.07156", "authors": ["Lucy Chai", "Michael Gharbi", "Eli Shechtman", "Phillip Isola", "Richard Zhang"], "title": "Any-resolution Training for High-resolution Image Synthesis", "url": "http://arxiv.org/pdf/2204.07156v2", "summary": "Generative models operate at fixed resolution, even though natural images\ncome in a variety of sizes. As high-resolution details are downsampled away and\nlow-resolution images are discarded altogether, precious supervision is lost.\nWe argue that every pixel matters and create datasets with variable-size\nimages, collected at their native resolutions. To take advantage of varied-size\ndata, we introduce continuous-scale training, a process that samples patches at\nrandom scales to train a new generator with variable output resolutions. First,\nconditioning the generator on a target scale allows us to generate higher\nresolution images than previously possible, without adding layers to the model.\nSecond, by conditioning on continuous coordinates, we can sample patches that\nstill obey a consistent global layout, which also allows for scalable training\nat higher resolutions. Controlled FFHQ experiments show that our method can\ntake advantage of multi-resolution training data better than discrete\nmulti-scale approaches, achieving better FID scores and cleaner high-frequency\ndetails. We also train on other natural image domains including churches,\nmountains, and birds, and demonstrate arbitrary scale synthesis with both\ncoherent global layouts and realistic local details, going beyond 2K resolution\nin our experiments. Our project page is available at:\nhttps://chail.github.io/anyres-gan/.", "published": "2022-04-14T17:59:31Z", "version": 2}, {"aid": "2204.07356", "authors": ["Siqu Long", "Feiqi Cao", "Soyeon Caren Han", "Haiqin Yang"], "title": "Vision-and-Language Pretrained Models: A Survey", "url": "http://arxiv.org/pdf/2204.07356v5", "summary": "Pretrained models have produced great success in both Computer Vision (CV)\nand Natural Language Processing (NLP). This progress leads to learning joint\nrepresentations of vision and language pretraining by feeding visual and\nlinguistic contents into a multi-layer transformer, Visual-Language Pretrained\nModels (VLPMs). In this paper, we present an overview of the major advances\nachieved in VLPMs for producing joint representations of vision and language.\nAs the preliminaries, we briefly describe the general task definition and\ngenetic architecture of VLPMs. We first discuss the language and vision data\nencoding methods and then present the mainstream VLPM structure as the core\ncontent. We further summarise several essential pretraining and fine-tuning\nstrategies. Finally, we highlight three future directions for both CV and NLP\nresearchers to provide insightful guidance.", "published": "2022-04-15T07:33:06Z", "version": 5}, {"aid": "2204.08583", "authors": ["Katherine Crowson", "Stella Biderman", "Daniel Kornis", "Dashiell Stander", "Eric Hallahan", "Louis Castricato", "Edward Raff"], "title": "VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance", "url": "http://arxiv.org/pdf/2204.08583v2", "summary": "Generating and editing images from open domain text prompts is a challenging\ntask that heretofore has required expensive and specially trained models. We\ndemonstrate a novel methodology for both tasks which is capable of producing\nimages of high visual quality from text prompts of significant semantic\ncomplexity without any training by using a multimodal encoder to guide image\ngenerations. We demonstrate on a variety of tasks how using CLIP [37] to guide\nVQGAN [11] produces higher visual quality outputs than prior, less flexible\napproaches like DALL-E [38], GLIDE [33] and Open-Edit [24], despite not being\ntrained for the tasks presented. Our code is available in a public repository.", "published": "2022-04-18T22:57:29Z", "version": 2}, {"aid": "2204.10105", "authors": ["Binjie Qin", "Haohao Mao", "Ruipeng Zhang", "Yueqi Zhu", "Song Ding", "Xu Chen"], "title": "Working memory inspired hierarchical video decomposition with transformative representations", "url": "http://arxiv.org/pdf/2204.10105v3", "summary": "Video decomposition is very important to extract moving foreground objects\nfrom complex backgrounds in computer vision, machine learning, and medical\nimaging, e.g., extracting moving contrast-filled vessels from the complex and\nnoisy backgrounds of X-ray coronary angiography (XCA). However, the challenges\ncaused by dynamic backgrounds, overlapping heterogeneous environments and\ncomplex noises still exist in video decomposition. To solve these problems,\nthis study is the first to introduce a flexible visual working memory model in\nvideo decomposition tasks to provide interpretable and high-performance\nhierarchical deep architecture, integrating the transformative representations\nbetween sensory and control layers from the perspective of visual and cognitive\nneuroscience. Specifically, robust PCA unrolling networks acting as a\nstructure-regularized sensor layer decompose XCA into sparse/low-rank\nstructured representations to separate moving contrast-filled vessels from\nnoisy and complex backgrounds. Then, patch recurrent convolutional LSTM\nnetworks with a backprojection module embody unstructured random\nrepresentations of the control layer in working memory, recurrently projecting\nspatiotemporally decomposed nonlocal patches into orthogonal subspaces for\nheterogeneous vessel retrieval and interference suppression. This video\ndecomposition deep architecture effectively restores the heterogeneous profiles\nof intensity and the geometries of moving objects against the complex\nbackground interferences. Experiments show that the proposed method\nsignificantly outperforms state-of-the-art methods in accurate moving\ncontrast-filled vessel extraction with excellent flexibility and computational\nefficiency.", "published": "2022-04-21T13:49:43Z", "version": 3}, {"aid": "2204.11795", "authors": ["Ella Lan"], "title": "Performer: A Novel PPG-to-ECG Reconstruction Transformer for a Digital Biomarker of Cardiovascular Disease Detection", "url": "http://arxiv.org/pdf/2204.11795v3", "summary": "Electrocardiography (ECG), an electrical measurement which captures cardiac\nactivities, is the gold standard for diagnosing cardiovascular disease (CVD).\nHowever, ECG is infeasible for continuous cardiac monitoring due to its\nrequirement for user participation. By contrast, photoplethysmography (PPG)\nprovides easy-to-collect data, but its limited accuracy constrains its clinical\nusage. To combine the advantages of both signals, recent studies incorporate\nvarious deep learning techniques for the reconstruction of PPG signals to ECG;\nhowever, the lack of contextual information as well as the limited abilities to\ndenoise biomedical signals ultimately constrain model performance. In this\nresearch, we propose Performer, a novel Transformer-based architecture that\nreconstructs ECG from PPG and combines the PPG and reconstructed ECG as\nmultiple modalities for CVD detection. This method is the first time that\nTransformer sequence-to-sequence translation has been performed on biomedical\nwaveform reconstruction, combining the advantages of both PPG and ECG. We also\ncreate Shifted Patch-based Attention (SPA), an effective method to\nencode/decode the biomedical waveforms. Through fetching the various sequence\nlengths and capturing cross-patch connections, SPA maximizes the signal\nprocessing for both local features and global contextual representations. The\nproposed architecture generates a state-of-the-art performance of 0.29 RMSE for\nthe reconstruction of PPG to ECG on the BIDMC database, surpassing prior\nstudies. We also evaluated this model on the MIMIC-III dataset, achieving a\n95.9% accuracy in CVD detection, and on the PPG-BP dataset, achieving 75.9%\naccuracy in related CVD diabetes detection, indicating its generalizability. As\na proof of concept, an earring wearable named PEARL (prototype), was designed\nto scale up the point-of-care (POC) healthcare system.", "published": "2022-04-25T17:10:13Z", "version": 3}, {"aid": "2204.11824", "authors": ["Andreas Blattmann", "Robin Rombach", "Kaan Oktay", "Jonas M\u00fcller", "Bj\u00f6rn Ommer"], "title": "Semi-Parametric Neural Image Synthesis", "url": "http://arxiv.org/pdf/2204.11824v3", "summary": "Novel architectures have recently improved generative image synthesis leading\nto excellent visual quality in various tasks. Much of this success is due to\nthe scalability of these architectures and hence caused by a dramatic increase\nin model complexity and in the computational resources invested in training\nthese models. Our work questions the underlying paradigm of compressing large\ntraining data into ever growing parametric representations. We rather present\nan orthogonal, semi-parametric approach. We complement comparably small\ndiffusion or autoregressive models with a separate image database and a\nretrieval strategy. During training we retrieve a set of nearest neighbors from\nthis external database for each training instance and condition the generative\nmodel on these informative samples. While the retrieval approach is providing\nthe (local) content, the model is focusing on learning the composition of\nscenes based on this content. As demonstrated by our experiments, simply\nswapping the database for one with different contents transfers a trained model\npost-hoc to a novel domain. The evaluation shows competitive performance on\ntasks which the generative model has not been trained on, such as\nclass-conditional synthesis, zero-shot stylization or text-to-image synthesis\nwithout requiring paired text-image data. With negligible memory and\ncomputational overhead for the external database and retrieval we can\nsignificantly reduce the parameter count of the generative model and still\noutperform the state-of-the-art.", "published": "2022-04-25T17:55:26Z", "version": 3}, {"aid": "2204.11830", "authors": ["Monish Keswani", "Sriranjani Ramakrishnan", "Nishant Reddy", "Vineeth N Balasubramanian"], "title": "Proto2Proto: Can you recognize the car, the way I do?", "url": "http://arxiv.org/pdf/2204.11830v2", "summary": "Prototypical methods have recently gained a lot of attention due to their\nintrinsic interpretable nature, which is obtained through the prototypes. With\ngrowing use cases of model reuse and distillation, there is a need to also\nstudy transfer of interpretability from one model to another. We present\nProto2Proto, a novel method to transfer interpretability of one prototypical\npart network to another via knowledge distillation. Our approach aims to add\ninterpretability to the \"dark\" knowledge transferred from the teacher to the\nshallower student model. We propose two novel losses: \"Global Explanation\" loss\nand \"Patch-Prototype Correspondence\" loss to facilitate such a transfer. Global\nExplanation loss forces the student prototypes to be close to teacher\nprototypes, and Patch-Prototype Correspondence loss enforces the local\nrepresentations of the student to be similar to that of the teacher. Further,\nwe propose three novel metrics to evaluate the student's proximity to the\nteacher as measures of interpretability transfer in our settings. We\nqualitatively and quantitatively demonstrate the effectiveness of our method on\nCUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed\nmethod indeed achieves interpretability transfer from teacher to student while\nsimultaneously exhibiting competitive performance.", "published": "2022-04-25T17:59:30Z", "version": 2}, {"aid": "2204.13620", "authors": ["Chunwei Tian", "Xuanyu Zhang", "Qi Zhu", "Bob Zhang", "Jerry Chun-Wei Lin"], "title": "Generative Adversarial Networks for Image Super-Resolution: A Survey", "url": "http://arxiv.org/pdf/2204.13620v4", "summary": "Single image super-resolution (SISR) has played an important role in the\nfield of image processing. Recent generative adversarial networks (GANs) can\nachieve excellent results on low-resolution images with small samples. However,\nthere are little literatures summarizing different GANs in SISR. In this paper,\nwe conduct a comparative study of GANs from different perspectives. We first\ntake a look at developments of GANs. Second, we present popular architectures\nfor GANs in big and small samples for image applications. Then, we analyze\nmotivations, implementations and differences of GANs based optimization methods\nand discriminative learning for image super-resolution in terms of supervised,\nsemi-supervised and unsupervised manners, where these GANs are analyzed via\nintegrating different network architectures, prior knowledge, loss functions\nand multiple tasks. Next, we compare performance of these popular GANs on\npublic datasets via quantitative and qualitative analysis in SISR. Finally, we\nhighlight challenges of GANs and potential research points for SISR.", "published": "2022-04-28T16:35:04Z", "version": 4}, {"aid": "2205.01490", "authors": ["Bowen Jing", "Gabriele Corso", "Renato Berlinghieri", "Tommi Jaakkola"], "title": "Subspace Diffusion Generative Models", "url": "http://arxiv.org/pdf/2205.01490v2", "summary": "Score-based models generate samples by mapping noise to data (and vice versa)\nvia a high-dimensional diffusion process. We question whether it is necessary\nto run this entire process at high dimensionality and incur all the\ninconveniences thereof. Instead, we restrict the diffusion via projections onto\nsubspaces as the data distribution evolves toward noise. When applied to\nstate-of-the-art models, our framework simultaneously improves sample quality\n-- reaching an FID of 2.17 on unconditional CIFAR-10 -- and reduces the\ncomputational cost of inference for the same number of denoising steps. Our\nframework is fully compatible with continuous-time diffusion and retains its\nflexible capabilities, including exact log-likelihoods and controllable\ngeneration. Code is available at\nhttps://github.com/bjing2016/subspace-diffusion.", "published": "2022-05-03T13:43:47Z", "version": 2}, {"aid": "2205.01491", "authors": ["Mingle Xu", "Sook Yoon", "Alvaro Fuentes", "Dong Sun Park"], "title": "A Comprehensive Survey of Image Augmentation Techniques for Deep Learning", "url": "http://arxiv.org/pdf/2205.01491v2", "summary": "Deep learning has been achieving decent performance in computer vision\nrequiring a large volume of images, however, collecting images is expensive and\ndifficult in many scenarios. To alleviate this issue, many image augmentation\nalgorithms have been proposed as effective and efficient strategies.\nUnderstanding current algorithms is essential to find suitable methods or\ndevelop novel techniques for given tasks. In this paper, we perform a\ncomprehensive survey on image augmentation for deep learning with a novel\ninformative taxonomy. To get the basic idea why we need image augmentation, we\nintroduce the challenges in computer vision tasks and vicinity distribution.\nThen, the algorithms are split into three categories; model-free, model-based,\nand optimizing policy-based. The model-free category employs image processing\nmethods while the model-based method leverages trainable image generation\nmodels. In contrast, the optimizing policy-based approach aims to find the\noptimal operations or their combinations. Furthermore, we discuss the current\ntrend of common applications with two more active topics, leveraging different\nways to understand image augmentation, such as group and kernel theory, and\ndeploying image augmentation for unsupervised learning. Based on the analysis,\nwe believe that our survey gives a better understanding helpful to choose\nsuitable methods or design novel algorithms for practical applications.", "published": "2022-05-03T13:45:04Z", "version": 2}, {"aid": "2205.01508", "authors": ["Weichao Lan", "Yiu-ming Cheung", "Juyong Jiang"], "title": "Compact Neural Networks via Stacking Designed Basic Units", "url": "http://arxiv.org/pdf/2205.01508v1", "summary": "Unstructured pruning has the limitation of dealing with the sparse and\nirregular weights. By contrast, structured pruning can help eliminate this\ndrawback but it requires complex criterion to determine which components to be\npruned. To this end, this paper presents a new method termed TissueNet, which\ndirectly constructs compact neural networks with fewer weight parameters by\nindependently stacking designed basic units, without requiring additional\njudgement criteria anymore. Given the basic units of various architectures,\nthey are combined and stacked in a certain form to build up compact neural\nnetworks. We formulate TissueNet in diverse popular backbones for comparison\nwith the state-of-the-art pruning methods on different benchmark datasets.\nMoreover, two new metrics are proposed to evaluate compression performance.\nExperiment results show that TissueNet can achieve comparable classification\naccuracy while saving up to around 80% FLOPs and 89.7% parameters. That is,\nstacking basic units provides a new promising way for network compression.", "published": "2022-05-03T14:04:49Z", "version": 1}, {"aid": "2205.01586", "authors": ["Francesco Pelosin"], "title": "Simpler is Better: off-the-shelf Continual Learning Through Pretrained Backbones", "url": "http://arxiv.org/pdf/2205.01586v2", "summary": "In this short paper, we propose a baseline (off-the-shelf) for Continual\nLearning of Computer Vision problems, by leveraging the power of pretrained\nmodels. By doing so, we devise a simple approach achieving strong performance\nfor most of the common benchmarks. Our approach is fast since requires no\nparameters updates and has minimal memory requirements (order of KBytes). In\nparticular, the \"training\" phase reorders data and exploit the power of\npretrained models to compute a class prototype and fill a memory bank. At\ninference time we match the closest prototype through a knn-like approach,\nproviding us the prediction. We will see how this naive solution can act as an\noff-the-shelf continual learning system. In order to better consolidate our\nresults, we compare the devised pipeline with common CNN models and show the\nsuperiority of Vision Transformers, suggesting that such architectures have the\nability to produce features of higher quality. Moreover, this simple pipeline,\nraises the same questions raised by previous works \\cite{gdumb} on the\neffective progresses made by the CL community especially in the dataset\nconsidered and the usage of pretrained models. Code is live at\nhttps://github.com/francesco-p/off-the-shelf-cl", "published": "2022-05-03T16:03:46Z", "version": 2}, {"aid": "2205.01733", "authors": ["Ling Huang", "Su Ruan", "Thierry Denoeux"], "title": "Application of belief functions to medical image segmentation: A review", "url": "http://arxiv.org/pdf/2205.01733v4", "summary": "The investigation of uncertainty is of major importance in risk-critical\napplications, such as medical image segmentation. Belief function theory, a\nformal framework for uncertainty analysis and multiple evidence fusion, has\nmade significant contributions to medical image segmentation, especially since\nthe development of deep learning. In this paper, we provide an introduction to\nthe topic of medical image segmentation methods using belief function theory.\nWe classify the methods according to the fusion step and explain how\ninformation with uncertainty or imprecision is modeled and fused with belief\nfunction theory. In addition, we discuss the challenges and limitations of\npresent belief function-based medical image segmentation and propose\norientations for future research. Future research could investigate both belief\nfunction theory and deep learning to achieve more promising and reliable\nsegmentation results.", "published": "2022-05-03T19:06:45Z", "version": 4}, {"aid": "2205.01818", "authors": ["Ziyi Yang", "Yuwei Fang", "Chenguang Zhu", "Reid Pryzant", "Dongdong Chen", "Yu Shi", "Yichong Xu", "Yao Qian", "Mei Gao", "Yi-Ling Chen", "Liyang Lu", "Yujia Xie", "Robert Gmyr", "Noel Codella", "Naoyuki Kanda", "Bin Xiao", "Lu Yuan", "Takuya Yoshioka", "Michael Zeng", "Xuedong Huang"], "title": "i-Code: An Integrative and Composable Multimodal Learning Framework", "url": "http://arxiv.org/pdf/2205.01818v2", "summary": "Human intelligence is multimodal; we integrate visual, linguistic, and\nacoustic signals to maintain a holistic worldview. Most current pretraining\nmethods, however, are limited to one or two modalities. We present i-Code, a\nself-supervised pretraining framework where users may flexibly combine the\nmodalities of vision, speech, and language into unified and general-purpose\nvector representations. In this framework, data from each modality are first\ngiven to pretrained single-modality encoders. The encoder outputs are then\nintegrated with a multimodal fusion network, which uses novel attention\nmechanisms and other architectural innovations to effectively combine\ninformation from the different modalities. The entire system is pretrained\nend-to-end with new objectives including masked modality unit modeling and\ncross-modality contrastive learning. Unlike previous research using only video\nfor pretraining, the i-Code framework can dynamically process single, dual, and\ntriple-modality data during training and inference, flexibly projecting\ndifferent combinations of modalities into a single representation space.\nExperimental results demonstrate how i-Code can outperform state-of-the-art\ntechniques on five video understanding tasks and the GLUE NLP benchmark,\nimproving by as much as 11% and demonstrating the power of integrative\nmultimodal pretraining.", "published": "2022-05-03T23:38:50Z", "version": 2}, {"aid": "2205.01903", "authors": ["Sungyeon Kim", "Dongwon Kim", "Minsu Cho", "Suha Kwak"], "title": "Self-Taught Metric Learning without Labels", "url": "http://arxiv.org/pdf/2205.01903v1", "summary": "We present a novel self-taught framework for unsupervised metric learning,\nwhich alternates between predicting class-equivalence relations between data\nthrough a moving average of an embedding model and learning the model with the\npredicted relations as pseudo labels. At the heart of our framework lies an\nalgorithm that investigates contexts of data on the embedding space to predict\ntheir class-equivalence relations as pseudo labels. The algorithm enables\nefficient end-to-end training since it demands no off-the-shelf module for\npseudo labeling. Also, the class-equivalence relations provide rich supervisory\nsignals for learning an embedding space. On standard benchmarks for metric\nlearning, it clearly outperforms existing unsupervised learning methods and\nsometimes even beats supervised learning models using the same backbone\nnetwork. It is also applied to semi-supervised metric learning as a way of\nexploiting additional unlabeled data, and achieves the state of the art by\nboosting performance of supervised learning substantially.", "published": "2022-05-04T05:48:40Z", "version": 1}, {"aid": "2205.02084", "authors": ["Yunzhi Zhang", "Jiajun Wu"], "title": "Video Extrapolation in Space and Time", "url": "http://arxiv.org/pdf/2205.02084v3", "summary": "Novel view synthesis (NVS) and video prediction (VP) are typically considered\ndisjoint tasks in computer vision. However, they can both be seen as ways to\nobserve the spatial-temporal world: NVS aims to synthesize a scene from a new\npoint of view, while VP aims to see a scene from a new point of time. These two\ntasks provide complementary signals to obtain a scene representation, as\nviewpoint changes from spatial observations inform depth, and temporal\nobservations inform the motion of cameras and individual objects. Inspired by\nthese observations, we propose to study the problem of Video Extrapolation in\nSpace and Time (VEST). We propose a model that leverages the self-supervision\nand the complementary cues from both tasks, while existing methods can only\nsolve one of them. Experiments show that our method achieves performance better\nthan or comparable to several state-of-the-art NVS and VP methods on indoor and\noutdoor real-world datasets.", "published": "2022-05-04T14:25:08Z", "version": 3}, {"aid": "2205.02131", "authors": ["Kaveena Persand", "Andrew Anderson", "David Gregg"], "title": "Domino Saliency Metrics: Improving Existing Channel Saliency Metrics with Structural Information", "url": "http://arxiv.org/pdf/2205.02131v2", "summary": "Channel pruning is used to reduce the number of weights in a Convolutional\nNeural Network (CNN). Channel pruning removes slices of the weight tensor so\nthat the convolution layer remains dense. The removal of these weight slices\nfrom a single layer causes mismatching number of feature maps between layers of\nthe network. A simple solution is to force the number of feature map between\nlayers to match through the removal of weight slices from subsequent layers.\nThis additional constraint becomes more apparent in DNNs with branches where\nmultiple channels need to be pruned together to keep the network dense. Popular\npruning saliency metrics do not factor in the structural dependencies that\narise in DNNs with branches. We propose Domino metrics (built on existing\nchannel saliency metrics) to reflect these structural constraints. We test\nDomino saliency metrics against the baseline channel saliency metrics on\nmultiple networks with branches. Domino saliency metrics improved pruning rates\nin most tested networks and up to 25% in AlexNet on CIFAR-10.", "published": "2022-05-04T15:37:51Z", "version": 2}, {"aid": "2205.02698", "authors": ["Konstantin Kobs", "Michael Steininger", "Andrzej Dulny", "Andreas Hotho"], "title": "Do Different Deep Metric Learning Losses Lead to Similar Learned Features?", "url": "http://arxiv.org/pdf/2205.02698v1", "summary": "Recent studies have shown that many deep metric learning loss functions\nperform very similarly under the same experimental conditions. One potential\nreason for this unexpected result is that all losses let the network focus on\nsimilar image regions or properties. In this paper, we investigate this by\nconducting a two-step analysis to extract and compare the learned visual\nfeatures of the same model architecture trained with different loss functions:\nFirst, we compare the learned features on the pixel level by correlating\nsaliency maps of the same input images. Second, we compare the clustering of\nembeddings for several image properties, e.g. object color or illumination. To\nprovide independent control over these properties, photo-realistic 3D car\nrenders similar to images in the Cars196 dataset are generated. In our\nanalysis, we compare 14 pretrained models from a recent study and find that,\neven though all models perform similarly, different loss functions can guide\nthe model to learn different features. We especially find differences between\nclassification and ranking based losses. Our analysis also shows that some\nseemingly irrelevant properties can have significant influence on the resulting\nembedding. We encourage researchers from the deep metric learning community to\nuse our methods to get insights into the features learned by their proposed\nmethods.", "published": "2022-05-05T15:07:19Z", "version": 1}, {"aid": "2205.02767", "authors": ["Zulun Zhu", "Jiaying Peng", "Jintang Li", "Liang Chen", "Qi Yu", "Siqiang Luo"], "title": "Spiking Graph Convolutional Networks", "url": "http://arxiv.org/pdf/2205.02767v2", "summary": "Graph Convolutional Networks (GCNs) achieve an impressive performance due to\nthe remarkable representation ability in learning the graph information.\nHowever, GCNs, when implemented on a deep network, require expensive\ncomputation power, making them difficult to be deployed on battery-powered\ndevices. In contrast, Spiking Neural Networks (SNNs), which perform a\nbio-fidelity inference process, offer an energy-efficient neural architecture.\nIn this work, we propose SpikingGCN, an end-to-end framework that aims to\nintegrate the embedding of GCNs with the biofidelity characteristics of SNNs.\nThe original graph data are encoded into spike trains based on the\nincorporation of graph convolution. We further model biological information\nprocessing by utilizing a fully connected layer combined with neuron nodes. In\na wide range of scenarios (e.g. citation networks, image graph classification,\nand recommender systems), our experimental results show that the proposed\nmethod could gain competitive performance against state-of-the-art approaches.\nFurthermore, we show that SpikingGCN on a neuromorphic chip can bring a clear\nadvantage of energy efficiency into graph data analysis, which demonstrates its\ngreat potential to construct environment-friendly machine learning models.", "published": "2022-05-05T16:44:36Z", "version": 2}, {"aid": "2205.04545", "authors": ["Eli Sennesh", "Tom Xu", "Yoshihiro Maruyama"], "title": "A Probabilistic Generative Model of Free Categories", "url": "http://arxiv.org/pdf/2205.04545v2", "summary": "Applied category theory has recently developed libraries for computing with\nmorphisms in interesting categories, while machine learning has developed ways\nof learning programs in interesting languages. Taking the analogy between\ncategories and languages seriously, this paper defines a probabilistic\ngenerative model of morphisms in free monoidal categories over domain-specific\ngenerating objects and morphisms. The paper shows how acyclic directed wiring\ndiagrams can model specifications for morphisms, which the model can use to\ngenerate morphisms. Amortized variational inference in the generative model\nthen enables learning of parameters (by maximum likelihood) and inference of\nlatent variables (by Bayesian inversion). A concrete experiment shows that the\nfree category prior achieves competitive reconstruction performance on the\nOmniglot dataset.", "published": "2022-05-09T20:35:08Z", "version": 2}, {"aid": "2205.04596", "authors": ["Vijay Vasudevan", "Benjamin Caine", "Raphael Gontijo-Lopes", "Sara Fridovich-Keil", "Rebecca Roelofs"], "title": "When does dough become a bagel? Analyzing the remaining mistakes on ImageNet", "url": "http://arxiv.org/pdf/2205.04596v2", "summary": "Image classification accuracy on the ImageNet dataset has been a barometer\nfor progress in computer vision over the last decade. Several recent papers\nhave questioned the degree to which the benchmark remains useful to the\ncommunity, yet innovations continue to contribute gains to performance, with\ntoday's largest models achieving 90%+ top-1 accuracy. To help contextualize\nprogress on ImageNet and provide a more meaningful evaluation for today's\nstate-of-the-art models, we manually review and categorize every remaining\nmistake that a few top models make in order to provide insight into the\nlong-tail of errors on one of the most benchmarked datasets in computer vision.\nWe focus on the multi-label subset evaluation of ImageNet, where today's best\nmodels achieve upwards of 97% top-1 accuracy. Our analysis reveals that nearly\nhalf of the supposed mistakes are not mistakes at all, and we uncover new valid\nmulti-labels, demonstrating that, without careful review, we are significantly\nunderestimating the performance of these models. On the other hand, we also\nfind that today's best models still make a significant number of mistakes (40%)\nthat are obviously wrong to human reviewers. To calibrate future progress on\nImageNet, we provide an updated multi-label evaluation set, and we curate\nImageNet-Major: a 68-example \"major error\" slice of the obvious mistakes made\nby today's top models -- a slice where models should achieve near perfection,\nbut today are far from doing so.", "published": "2022-05-09T23:25:45Z", "version": 2}, {"aid": "2205.05303", "authors": ["Fabian A. Mikulasch", "Lucas Rudelt", "Michael Wibral", "Viola Priesemann"], "title": "Dendritic predictive coding: A theory of cortical computation with spiking neurons", "url": "http://arxiv.org/pdf/2205.05303v1", "summary": "Top-down feedback in cortex is critical for guiding sensory processing, which\nhas prominently been formalized in the theory of hierarchical predictive coding\n(hPC). However, experimental evidence for error units, which are central to the\ntheory, is inconclusive, and it remains unclear how hPC can be implemented with\nspiking neurons. To address this, we connect hPC to existing work on efficient\ncoding in balanced networks with lateral inhibition, and predictive computation\nat apical dendrites. Together, this work points to an efficient implementation\nof hPC with spiking neurons, where prediction errors are computed not in\nseparate units, but locally in dendritic compartments. The implied model shows\na remarkable correspondence to experimentally observed cortical connectivity\npatterns, plasticity and dynamics, and at the same time can explain hallmarks\nof predictive processing, such as mismatch responses, in cortex. We thus\npropose dendritic predictive coding as one of the main organizational\nprinciples of cortex.", "published": "2022-05-11T07:08:19Z", "version": 1}, {"aid": "2205.05671", "authors": ["Xintao Wang", "Chao Dong", "Ying Shan"], "title": "RepSR: Training Efficient VGG-style Super-Resolution Networks with Structural Re-Parameterization and Batch Normalization", "url": "http://arxiv.org/pdf/2205.05671v1", "summary": "This paper explores training efficient VGG-style super-resolution (SR)\nnetworks with the structural re-parameterization technique. The general\npipeline of re-parameterization is to train networks with multi-branch topology\nfirst, and then merge them into standard 3x3 convolutions for efficient\ninference. In this work, we revisit those primary designs and investigate\nessential components for re-parameterizing SR networks. First of all, we find\nthat batch normalization (BN) is important to bring training non-linearity and\nimprove the final performance. However, BN is typically ignored in SR, as it\nusually degrades the performance and introduces unpleasant artifacts. We\ncarefully analyze the cause of BN issue and then propose a straightforward yet\neffective solution. In particular, we first train SR networks with mini-batch\nstatistics as usual, and then switch to using population statistics at the\nlater training period. While we have successfully re-introduced BN into SR, we\nfurther design a new re-parameterizable block tailored for SR, namely RepSR. It\nconsists of a clean residual path and two expand-and-squeeze convolution paths\nwith the modified BN. Extensive experiments demonstrate that our simple RepSR\nis capable of achieving superior performance to previous SR re-parameterization\nmethods among different model sizes. In addition, our RepSR can achieve a\nbetter trade-off between performance and actual running time (throughput) than\nprevious SR methods. Codes will be available at\nhttps://github.com/TencentARC/RepSR.", "published": "2022-05-11T17:55:49Z", "version": 1}, {"aid": "2205.05874", "authors": ["David Mac\u00eado", "Cleber Zanchettin", "Teresa Ludermir"], "title": "Distinction Maximization Loss: Efficiently Improving Out-of-Distribution Detection and Uncertainty Estimation by Replacing the Loss and Calibrating", "url": "http://arxiv.org/pdf/2205.05874v5", "summary": "Building robust deterministic neural networks remains a challenge. On the one\nhand, some approaches improve out-of-distribution detection at the cost of\nreducing classification accuracy in some situations. On the other hand, some\nmethods simultaneously increase classification accuracy, uncertainty\nestimation, and out-of-distribution detection at the expense of reducing the\ninference efficiency. In this paper, we propose training deterministic neural\nnetworks using our DisMax loss, which works as a drop-in replacement for the\nusual SoftMax loss (i.e., the combination of the linear output layer, the\nSoftMax activation, and the cross-entropy loss). Starting from the IsoMax+\nloss, we create each logit based on the distances to all prototypes, rather\nthan just the one associated with the correct class. We also introduce a\nmechanism to combine images to construct what we call fractional probability\nregularization. Moreover, we present a fast way to calibrate the network after\ntraining. Finally, we propose a composite score to perform out-of-distribution\ndetection. Our experiments show that DisMax usually outperforms current\napproaches simultaneously in classification accuracy, uncertainty estimation,\nand out-of-distribution detection while maintaining deterministic neural\nnetwork inference efficiency. The code to reproduce the results is available at\nhttps://github.com/dlmacedo/distinction-maximization-loss.", "published": "2022-05-12T04:37:35Z", "version": 5}, {"aid": "2205.06254", "authors": ["Enric Corona", "Gerard Pons-Moll", "Guillem Aleny\u00e0", "Francesc Moreno-Noguer"], "title": "Learned Vertex Descent: A New Direction for 3D Human Model Fitting", "url": "http://arxiv.org/pdf/2205.06254v2", "summary": "We propose a novel optimization-based paradigm for 3D human model fitting on\nimages and scans. In contrast to existing approaches that directly regress the\nparameters of a low-dimensional statistical body model (e.g. SMPL) from input\nimages, we train an ensemble of per-vertex neural fields network. The network\npredicts, in a distributed manner, the vertex descent direction towards the\nground truth, based on neural features extracted at the current vertex\nprojection. At inference, we employ this network, dubbed LVD, within a\ngradient-descent optimization pipeline until its convergence, which typically\noccurs in a fraction of a second even when initializing all vertices into a\nsingle point. An exhaustive evaluation demonstrates that our approach is able\nto capture the underlying body of clothed people with very different body\nshapes, achieving a significant improvement compared to state-of-the-art. LVD\nis also applicable to 3D model fitting of humans and hands, for which we show a\nsignificant improvement to the SOTA with a much simpler and faster method.", "published": "2022-05-12T17:55:51Z", "version": 2}, {"aid": "2205.06929", "authors": ["Mohamed R. Ibrahim", "Terry Lyons"], "title": "ImageSig: A signature transform for ultra-lightweight image recognition", "url": "http://arxiv.org/pdf/2205.06929v1", "summary": "This paper introduces a new lightweight method for image recognition.\nImageSig is based on computing signatures and does not require a convolutional\nstructure or an attention-based encoder. It is striking to the authors that it\nachieves: a) an accuracy for 64 X 64 RGB images that exceeds many of the\nstate-of-the-art methods and simultaneously b) requires orders of magnitude\nless FLOPS, power and memory footprint. The pretrained model can be as small as\n44.2 KB in size. ImageSig shows unprecedented performance on hardware such as\nRaspberry Pi and Jetson-nano. ImageSig treats images as streams with multiple\nchannels. These streams are parameterized by spatial directions. We contribute\nto the functionality of signature and rough path theory to stream-like data and\nvision tasks on static images beyond temporal streams. With very few parameters\nand small size models, the key advantage is that one could have many of these\n\"detectors\" assembled on the same chip; moreover, the feature acquisition can\nbe performed once and shared between different models of different tasks -\nfurther accelerating the process. This contributes to energy efficiency and the\nadvancements of embedded AI at the edge.", "published": "2022-05-13T23:48:32Z", "version": 1}, {"aid": "2205.06978", "authors": ["Yang Ni", "Danny Abraham", "Mariam Issa", "Yeseong Kim", "Pietro Mercati", "Mohsen Imani"], "title": "Efficient Off-Policy Reinforcement Learning via Brain-Inspired Computing", "url": "http://arxiv.org/pdf/2205.06978v3", "summary": "Reinforcement Learning (RL) has opened up new opportunities to enhance\nexisting smart systems that generally include a complex decision-making\nprocess. However, modern RL algorithms, e.g., Deep Q-Networks (DQN), are based\non deep neural networks, resulting in high computational costs. In this paper,\nwe propose QHD, an off-policy value-based Hyperdimensional Reinforcement\nLearning, that mimics brain properties toward robust and real-time learning.\nQHD relies on a lightweight brain-inspired model to learn an optimal policy in\nan unknown environment. On both desktop and power-limited embedded platforms,\nQHD achieves significantly better overall efficiency than DQN while providing\nhigher or comparable rewards. QHD is also suitable for highly-efficient\nreinforcement learning with great potential for online and real-time learning.\nOur solution supports a small experience replay batch size that provides 12.3\ntimes speedup compared to DQN while ensuring minimal quality loss. Our\nevaluation shows QHD capability for real-time learning, providing 34.6 times\nspeedup and significantly better quality of learning than DQN.", "published": "2022-05-14T05:50:54Z", "version": 3}, {"aid": "2205.07019", "authors": ["Yihao Liu", "Hengyuan Zhao", "Jinjin Gu", "Yu Qiao", "Chao Dong"], "title": "Evaluating the Generalization Ability of Super-Resolution Networks", "url": "http://arxiv.org/pdf/2205.07019v2", "summary": "Performance and generalization ability are two important aspects to evaluate\nthe deep learning models. However, research on the generalization ability of\nSuper-Resolution (SR) networks is currently absent. Assessing the\ngeneralization ability of deep models not only helps us to understand their\nintrinsic mechanisms, but also allows us to quantitatively measure their\napplicability boundaries, which is important for unrestricted real-world\napplications. To this end, we make the first attempt to propose a\nGeneralization Assessment Index for SR networks, namely SRGA. SRGA exploits the\nstatistical characteristics of the internal features of deep networks to\nmeasure the generalization ability. Specially, it is a non-parametric and\nnon-learning metric. To better validate our method, we collect a patch-based\nimage evaluation set (PIES) that includes both synthetic and real-world images,\ncovering a wide range of degradations. With SRGA and PIES dataset, we benchmark\nexisting SR models on the generalization ability. This work provides insights\nand tools for future research on model generalization in low-level vision.", "published": "2022-05-14T09:33:20Z", "version": 2}, {"aid": "2205.07060", "authors": ["Anssi Kanervisto", "Tomi Kinnunen", "Ville Hautam\u00e4ki"], "title": "GAN-Aimbots: Using Machine Learning for Cheating in First Person Shooters", "url": "http://arxiv.org/pdf/2205.07060v1", "summary": "Playing games with cheaters is not fun, and in a multi-billion-dollar video\ngame industry with hundreds of millions of players, game developers aim to\nimprove the security and, consequently, the user experience of their games by\npreventing cheating. Both traditional software-based methods and statistical\nsystems have been successful in protecting against cheating, but recent\nadvances in the automatic generation of content, such as images or speech,\nthreaten the video game industry; they could be used to generate artificial\ngameplay indistinguishable from that of legitimate human players. To better\nunderstand this threat, we begin by reviewing the current state of multiplayer\nvideo game cheating, and then proceed to build a proof-of-concept method,\nGAN-Aimbot. By gathering data from various players in a first-person shooter\ngame we show that the method improves players' performance while remaining\nhidden from automatic and manual protection mechanisms. By sharing this work we\nhope to raise awareness on this issue and encourage further research into\nprotecting the gaming communities.", "published": "2022-05-14T13:33:23Z", "version": 1}, {"aid": "2205.07384", "authors": ["Ziyang Jiang", "Tongshu Zheng", "Yiling Liu", "David Carlson"], "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel", "url": "http://arxiv.org/pdf/2205.07384v8", "summary": "It is challenging to guide neural network (NN) learning with prior knowledge.\nIn contrast, many known properties, such as spatial smoothness or seasonality,\nare straightforward to model by choosing an appropriate kernel in a Gaussian\nprocess (GP). Many deep learning applications could be enhanced by modeling\nsuch known properties. For example, convolutional neural networks (CNNs) are\nfrequently used in remote sensing, which is subject to strong seasonal effects.\nWe propose to blend the strengths of deep learning and the clear modeling\ncapabilities of GPs by using a composite kernel that combines a kernel\nimplicitly defined by a neural network with a second kernel function chosen to\nmodel known properties (e.g., seasonality). We implement this idea by combining\na deep network and an efficient mapping based on the Nystrom approximation,\nwhich we call Implicit Composite Kernel (ICK). We then adopt a\nsample-then-optimize approach to approximate the full GP posterior\ndistribution. We demonstrate that ICK has superior performance and flexibility\non both synthetic and real-world data sets. We believe that ICK framework can\nbe used to include prior information into neural networks in many applications.", "published": "2022-05-15T21:32:44Z", "version": 8}, {"aid": "2205.07467", "authors": ["Lingwei Zhu", "Zheng Chen", "Eiji Uchibe", "Takamitsu Matsubara"], "title": "$q$-Munchausen Reinforcement Learning", "url": "http://arxiv.org/pdf/2205.07467v1", "summary": "The recently successful Munchausen Reinforcement Learning (M-RL) features\nimplicit Kullback-Leibler (KL) regularization by augmenting the reward function\nwith logarithm of the current stochastic policy. Though significant improvement\nhas been shown with the Boltzmann softmax policy, when the Tsallis sparsemax\npolicy is considered, the augmentation leads to a flat learning curve for\nalmost every problem considered. We show that it is due to the mismatch between\nthe conventional logarithm and the non-logarithmic (generalized) nature of\nTsallis entropy. Drawing inspiration from the Tsallis statistics literature, we\npropose to correct the mismatch of M-RL with the help of\n$q$-logarithm/exponential functions. The proposed formulation leads to implicit\nTsallis KL regularization under the maximum Tsallis entropy framework. We show\nsuch formulation of M-RL again achieves superior performance on benchmark\nproblems and sheds light on more general M-RL with various entropic indices\n$q$.", "published": "2022-05-16T06:26:10Z", "version": 1}, {"aid": "2205.07547", "authors": ["Yuhta Takida", "Takashi Shibuya", "WeiHsiang Liao", "Chieh-Hsin Lai", "Junki Ohmura", "Toshimitsu Uesaka", "Naoki Murata", "Shusuke Takahashi", "Toshiyuki Kumakura", "Yuki Mitsufuji"], "title": "SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization", "url": "http://arxiv.org/pdf/2205.07547v2", "summary": "One noted issue of vector-quantized variational autoencoder (VQ-VAE) is that\nthe learned discrete representation uses only a fraction of the full capacity\nof the codebook, also known as codebook collapse. We hypothesize that the\ntraining scheme of VQ-VAE, which involves some carefully designed heuristics,\nunderlies this issue. In this paper, we propose a new training scheme that\nextends the standard VAE via novel stochastic dequantization and quantization,\ncalled stochastically quantized variational autoencoder (SQ-VAE). In SQ-VAE, we\nobserve a trend that the quantization is stochastic at the initial stage of the\ntraining but gradually converges toward a deterministic quantization, which we\ncall self-annealing. Our experiments show that SQ-VAE improves codebook\nutilization without using common heuristics. Furthermore, we empirically show\nthat SQ-VAE is superior to VAE and VQ-VAE in vision- and speech-related tasks.", "published": "2022-05-16T09:49:37Z", "version": 2}, {"aid": "2205.08413", "authors": ["Max Dabagia", "Konrad P Kording", "Eva L Dyer"], "title": "Comparing high-dimensional neural recordings by aligning their low-dimensional latent representations", "url": "http://arxiv.org/pdf/2205.08413v1", "summary": "Many questions in neuroscience involve understanding of the responses of\nlarge populations of neurons. However, when dealing with large-scale neural\nactivity, interpretation becomes difficult, and comparisons between two\nanimals, or across different time points becomes challenging. One major\nchallenge that we face in modern neuroscience is that of correspondence, e.g.\nwe do not record the exact same neurons at the exact same times. Without some\nway to link two or more datasets, comparing different collections of neural\nactivity patterns becomes impossible. Here, we describe approaches for\nleveraging shared latent structure across neural recordings to tackle this\ncorrespondence challenge. We review algorithms that map two datasets into a\nshared space where they can be directly compared, and argue that alignment is\nkey for comparing high-dimensional neural activities across times, subsets of\nneurons, and individuals.", "published": "2022-05-17T14:52:09Z", "version": 1}, {"aid": "2205.09801", "authors": ["Charilaos I. Kanatsoulis", "Alejandro Ribeiro"], "title": "Representation Power of Graph Neural Networks: Improved Expressivity via Algebraic Analysis", "url": "http://arxiv.org/pdf/2205.09801v3", "summary": "Despite the remarkable success of Graph Neural Networks (GNNs), the common\nbelief is that their representation power is limited and that they are at most\nas expressive as the Weisfeiler-Lehman (WL) algorithm. In this paper, we argue\nthe opposite and show that standard GNNs, with anonymous inputs, produce more\ndiscriminative representations than the WL algorithm. Our novel analysis\nemploys linear algebraic tools and characterizes the representation power of\nGNNs with respect to the eigenvalue decomposition of the graph operators. We\nprove that GNNs are able to generate distinctive outputs from white\nuninformative inputs, for, at least, all graphs that have different\neigenvalues. We also show that simple convolutional architectures with white\ninputs, produce equivariant features that count the closed paths in the graph\nand are provably more expressive than the WL representations. Thorough\nexperimental analysis on graph isomorphism and graph classification datasets\ncorroborates our theoretical results and demonstrates the effectiveness of the\nproposed approach.", "published": "2022-05-19T18:40:25Z", "version": 3}, {"aid": "2205.09821", "authors": ["Dipan Mandal", "Abhilash Jain"], "title": "Unsupervised Learning of Depth, Camera Pose and Optical Flow from Monocular Video", "url": "http://arxiv.org/pdf/2205.09821v2", "summary": "We propose DFPNet -- an unsupervised, joint learning system for monocular\nDepth, Optical Flow and egomotion (Camera Pose) estimation from monocular image\nsequences. Due to the nature of 3D scene geometry these three components are\ncoupled. We leverage this fact to jointly train all the three components in an\nend-to-end manner. A single composite loss function -- which involves image\nreconstruction-based loss for depth & optical flow, bidirectional consistency\nchecks and smoothness loss components -- is used to train the network. Using\nhyperparameter tuning, we are able to reduce the model size to less than 5%\n(8.4M parameters) of state-of-the-art DFP models. Evaluation on KITTI and\nCityscapes driving datasets reveals that our model achieves results comparable\nto state-of-the-art in all of the three tasks, even with the significantly\nsmaller model size.", "published": "2022-05-19T19:47:41Z", "version": 2}, {"aid": "2205.09875", "authors": ["James Seale Smith", "Zachary Seymour", "Han-Pang Chiu"], "title": "Incremental Learning with Differentiable Architecture and Forgetting Search", "url": "http://arxiv.org/pdf/2205.09875v1", "summary": "As progress is made on training machine learning models on incrementally\nexpanding classification tasks (i.e., incremental learning), a next step is to\ntranslate this progress to industry expectations. One technique missing from\nincremental learning is automatic architecture design via Neural Architecture\nSearch (NAS). In this paper, we show that leveraging NAS for incremental\nlearning results in strong performance gains for classification tasks.\nSpecifically, we contribute the following: first, we create a strong baseline\napproach for incremental learning based on Differentiable Architecture Search\n(DARTS) and state-of-the-art incremental learning strategies, outperforming\nmany existing strategies trained with similar-sized popular architectures;\nsecond, we extend the idea of architecture search to regularize architecture\nforgetting, boosting performance past our proposed baseline. We evaluate our\nmethod on both RF signal and image classification tasks, and demonstrate we can\nachieve up to a 10% performance increase over state-of-the-art methods. Most\nimportantly, our contribution enables learning from continuous distributions on\nreal-world application data for which the complexity of the data distribution\nis unknown, or the modality less explored (such as RF signal classification).", "published": "2022-05-19T21:47:26Z", "version": 1}, {"aid": "2205.09909", "authors": ["Michael Minyi Zhang"], "title": "Sparse Infinite Random Feature Latent Variable Modeling", "url": "http://arxiv.org/pdf/2205.09909v2", "summary": "We propose a non-linear, Bayesian non-parametric latent variable model where\nthe latent space is assumed to be sparse and infinite dimensional a priori\nusing an Indian buffet process prior. A posteriori, the number of instantiated\ndimensions in the latent space is guaranteed to be finite. The purpose of\nplacing the Indian buffet process on the latent variables is to: 1.)\nAutomatically and probabilistically select the number of latent dimensions. 2.)\nImpose sparsity in the latent space, where the Indian buffet process will\nselect which elements are exactly zero. Our proposed model allows for sparse,\nnon-linear latent variable modeling where the number of latent dimensions is\nselected automatically. Inference is made tractable using the random Fourier\napproximation and we can easily implement posterior inference through Markov\nchain Monte Carlo sampling. This approach is amenable to many observation\nmodels beyond the Gaussian setting. We demonstrate the utility of our method on\na variety of synthetic, biological and text datasets and show that we can\nobtain superior test set performance compared to previous latent variable\nmodels.", "published": "2022-05-20T00:29:28Z", "version": 2}, {"aid": "2205.09930", "authors": ["Jason Yoo", "Frank Wood"], "title": "BayesPCN: A Continually Learnable Predictive Coding Associative Memory", "url": "http://arxiv.org/pdf/2205.09930v3", "summary": "Associative memory plays an important role in human intelligence and its\nmechanisms have been linked to attention in machine learning. While the machine\nlearning community's interest in associative memories has recently been\nrekindled, most work has focused on memory recall ($read$) over memory learning\n($write$). In this paper, we present BayesPCN, a hierarchical associative\nmemory capable of performing continual one-shot memory writes without\nmeta-learning. Moreover, BayesPCN is able to gradually forget past observations\n($forget$) to free its memory. Experiments show that BayesPCN can recall\ncorrupted i.i.d. high-dimensional data observed hundreds to a thousand\n``timesteps'' ago without a large drop in recall ability compared to the\nstate-of-the-art offline-learned parametric memory models.", "published": "2022-05-20T02:28:11Z", "version": 3}, {"aid": "2205.10044", "authors": ["Cristiano Capone", "Pier Stanislao Paolucci"], "title": "Towards biologically plausible Dreaming and Planning in recurrent spiking networks", "url": "http://arxiv.org/pdf/2205.10044v3", "summary": "Humans and animals can learn new skills after practicing for a few hours,\nwhile current reinforcement learning algorithms require a large amount of data\nto achieve good performances. Recent model-based approaches show promising\nresults by reducing the number of necessary interactions with the environment\nto learn a desirable policy. However, these methods require biological\nimplausible ingredients, such as the detailed storage of older experiences, and\nlong periods of offline learning. The optimal way to learn and exploit\nword-models is still an open question. Taking inspiration from biology, we\nsuggest that dreaming might be an efficient expedient to use an inner model. We\npropose a two-module (agent and model) spiking neural network in which\n\"dreaming\" (living new experiences in a model-based simulated environment)\nsignificantly boosts learning. We also explore \"planning\", an online\nalternative to dreaming, that shows comparable performances. Importantly, our\nmodel does not require the detailed storage of experiences, and learns online\nthe world-model and the policy. Moreover, we stress that our network is\ncomposed of spiking neurons, further increasing the biological plausibility and\nimplementability in neuromorphic hardware.", "published": "2022-05-20T09:35:26Z", "version": 3}, {"aid": "2205.10089", "authors": ["Reza Nasirigerdeh", "Reihaneh Torkzadehmahani", "Daniel Rueckert", "Georgios Kaissis"], "title": "Kernel Normalized Convolutional Networks", "url": "http://arxiv.org/pdf/2205.10089v4", "summary": "Existing convolutional neural network architectures frequently rely upon\nbatch normalization (BatchNorm) to effectively train the model. BatchNorm,\nhowever, performs poorly with small batch sizes, and is inapplicable to\ndifferential privacy. To address these limitations, we propose the kernel\nnormalization (KernelNorm) and kernel normalized convolutional layers, and\nincorporate them into kernel normalized convolutional networks (KNConvNets) as\nthe main building blocks. We implement KNConvNets corresponding to the\nstate-of-the-art ResNets while forgoing the BatchNorm layers. Through extensive\nexperiments, we illustrate that KNConvNets achieve higher or competitive\nperformance compared to the BatchNorm counterparts in image classification and\nsemantic segmentation. They also significantly outperform their\nbatch-independent competitors including those based on layer and group\nnormalization in non-private and differentially private training. Given that,\nKernelNorm combines the batch-independence property of layer and group\nnormalization with the performance advantage of BatchNorm.", "published": "2022-05-20T11:18:05Z", "version": 4}, {"aid": "2205.10268", "authors": ["Moritz B\u00f6hle", "Mario Fritz", "Bernt Schiele"], "title": "B-cos Networks: Alignment is All We Need for Interpretability", "url": "http://arxiv.org/pdf/2205.10268v1", "summary": "We present a new direction for increasing the interpretability of deep neural\nnetworks (DNNs) by promoting weight-input alignment during training. For this,\nwe propose to replace the linear transforms in DNNs by our B-cos transform. As\nwe show, a sequence (network) of such transforms induces a single linear\ntransform that faithfully summarises the full model computations. Moreover, the\nB-cos transform introduces alignment pressure on the weights during\noptimisation. As a result, those induced linear transforms become highly\ninterpretable and align with task-relevant features. Importantly, the B-cos\ntransform is designed to be compatible with existing architectures and we show\nthat it can easily be integrated into common models such as VGGs, ResNets,\nInceptionNets, and DenseNets, whilst maintaining similar performance on\nImageNet. The resulting explanations are of high visual quality and perform\nwell under quantitative metrics for interpretability. Code available at\nhttps://www.github.com/moboehle/B-cos.", "published": "2022-05-20T16:03:29Z", "version": 1}, {"aid": "2205.10279", "authors": ["Ravid Shwartz-Ziv", "Micah Goldblum", "Hossein Souri", "Sanyam Kapoor", "Chen Zhu", "Yann LeCun", "Andrew Gordon Wilson"], "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors", "url": "http://arxiv.org/pdf/2205.10279v1", "summary": "Deep learning is increasingly moving towards a transfer learning paradigm\nwhereby large foundation models are fine-tuned on downstream tasks, starting\nfrom an initialization learned on the source task. But an initialization\ncontains relatively little information about the source task. Instead, we show\nthat we can learn highly informative posteriors from the source task, through\nsupervised or self-supervised approaches, which then serve as the basis for\npriors that modify the whole loss surface on the downstream task. This simple\nmodular approach enables significant performance gains and more data-efficient\nlearning on a variety of downstream classification and segmentation tasks,\nserving as a drop-in replacement for standard pre-training strategies. These\nhighly informative priors also can be saved for future use, similar to\npre-trained weights, and stand in contrast to the zero-mean isotropic\nuninformative priors that are typically used in Bayesian deep learning.", "published": "2022-05-20T16:19:30Z", "version": 1}, {"aid": "2205.10316", "authors": ["Jorge Ram\u00edrez-Ruiz", "Dmytro Grytskyy", "Chiara Mastrogiuseppe", "Yamen Habib", "Rub\u00e9n Moreno-Bote"], "title": "Complex behavior from intrinsic motivation to occupy action-state path space", "url": "http://arxiv.org/pdf/2205.10316v2", "summary": "Most theories of behavior posit that agents tend to maximize some form of\nreward or utility. However, animals very often move with curiosity and seem to\nbe motivated in a reward-free manner. Here we abandon the idea of reward\nmaximization, and propose that the goal of behavior is maximizing occupancy of\nfuture paths of actions and states. According to this maximum occupancy\nprinciple, rewards are the means to occupy path space, not the goal per se;\ngoal-directedness simply emerges as rational ways of searching for resources so\nthat movement, understood amply, never ends. We find that action-state path\nentropy is the only measure consistent with additivity and other intuitive\nproperties of expected future action-state path occupancy. We provide\nanalytical expressions that relate the optimal policy and state-value function,\nand prove convergence of our value iteration algorithm. Using discrete and\ncontinuous state tasks, including a high--dimensional controller, we show that\ncomplex behaviors such as `dancing', hide-and-seek and a basic form of\naltruistic behavior naturally result from the intrinsic motivation to occupy\npath space. All in all, we present a theory of behavior that generates both\nvariability and goal-directedness in the absence of reward maximization.", "published": "2022-05-20T17:32:41Z", "version": 2}, {"aid": "2205.10347", "authors": ["Jean Prost", "Antoine Houdard", "Andr\u00e9s Almansa", "Nicolas Papadakis"], "title": "Diverse super-resolution with pretrained deep hiererarchical VAEs", "url": "http://arxiv.org/pdf/2205.10347v4", "summary": "We investigate the problem of producing diverse solutions to an image\nsuper-resolution problem. From a probabilistic perspective, this can be done by\nsampling from the posterior distribution of an inverse problem, which requires\nthe definition of a prior distribution on the high-resolution images. In this\nwork, we propose to use a pretrained hierarchical variational autoencoder\n(HVAE) as a prior. We train a lightweight stochastic encoder to encode\nlow-resolution images in the latent space of a pretrained HVAE. At inference,\nwe combine the low-resolution encoder and the pretrained generative model to\nsuper-resolve an image. We demonstrate on the task of face super-resolution\nthat our method provides an advantageous trade-off between the computational\nefficiency of conditional normalizing flows techniques and the sample quality\nof diffusion based methods.", "published": "2022-05-20T17:57:41Z", "version": 4}, {"aid": "2205.10760", "authors": ["Vamshi C. Madala", "Shivkumar Chandrasekaran", "Jason Bunk"], "title": "CNNs Avoid Curse of Dimensionality by Learning on Patches", "url": "http://arxiv.org/pdf/2205.10760v4", "summary": "Despite the success of convolutional neural networks (CNNs) in numerous\ncomputer vision tasks and their extraordinary generalization performances,\nseveral attempts to predict the generalization errors of CNNs have only been\nlimited to a posteriori analyses thus far. A priori theories explaining the\ngeneralization performances of deep neural networks have mostly ignored the\nconvolutionality aspect and do not specify why CNNs are able to seemingly\novercome curse of dimensionality on computer vision tasks like image\nclassification where the image dimensions are in thousands. Our work attempts\nto explain the generalization performance of CNNs on image classification under\nthe hypothesis that CNNs operate on the domain of image patches. Ours is the\nfirst work we are aware of to derive an a priori error bound for the\ngeneralization error of CNNs and we present both quantitative and qualitative\nevidences in the support of our theory. Our patch-based theory also offers\nexplanation for why data augmentation techniques like Cutout, CutMix and random\ncropping are effective in improving the generalization error of CNNs.", "published": "2022-05-22T06:22:27Z", "version": 4}, {"aid": "2205.12524", "authors": ["Zhaoyang Lyu", "Xudong XU", "Ceyuan Yang", "Dahua Lin", "Bo Dai"], "title": "Accelerating Diffusion Models via Early Stop of the Diffusion Process", "url": "http://arxiv.org/pdf/2205.12524v2", "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved impressive\nperformance on various generation tasks. By modeling the reverse process of\ngradually diffusing the data distribution into a Gaussian distribution,\ngenerating a sample in DDPMs can be regarded as iteratively denoising a\nrandomly sampled Gaussian noise. However, in practice DDPMs often need hundreds\neven thousands of denoising steps to obtain a high-quality sample from the\nGaussian noise, leading to extremely low inference efficiency. In this work, we\npropose a principled acceleration strategy, referred to as Early-Stopped DDPM\n(ES-DDPM), for DDPMs. The key idea is to stop the diffusion process early where\nonly the few initial diffusing steps are considered and the reverse denoising\nprocess starts from a non-Gaussian distribution. By further adopting a powerful\npre-trained generative model, such as GAN and VAE, in ES-DDPM, sampling from\nthe target non-Gaussian distribution can be efficiently achieved by diffusing\nsamples obtained from the pre-trained generative model. In this way, the number\nof required denoising steps is significantly reduced. In the meantime, the\nsample quality of ES-DDPM also improves substantially, outperforming both the\nvanilla DDPM and the adopted pre-trained generative model. On extensive\nexperiments across CIFAR-10, CelebA, ImageNet, LSUN-Bedroom and LSUN-Cat,\nES-DDPM obtains promising acceleration effect and performance improvement over\nrepresentative baseline methods. Moreover, ES-DDPM also demonstrates several\nattractive properties, including being orthogonal to existing acceleration\nmethods, as well as simultaneously enabling both global semantic and local\npixel-level control in image generation.", "published": "2022-05-25T06:40:09Z", "version": 2}, {"aid": "2205.12533", "authors": ["James Langley", "Miguel Monteiro", "Charles Jones", "Nick Pawlowski", "Ben Glocker"], "title": "Structured Uncertainty in the Observation Space of Variational Autoencoders", "url": "http://arxiv.org/pdf/2205.12533v2", "summary": "Variational autoencoders (VAEs) are a popular class of deep generative models\nwith many variants and a wide range of applications. Improvements upon the\nstandard VAE mostly focus on the modelling of the posterior distribution over\nthe latent space and the properties of the neural network decoder. In contrast,\nimproving the model for the observational distribution is rarely considered and\ntypically defaults to a pixel-wise independent categorical or normal\ndistribution. In image synthesis, sampling from such distributions produces\nspatially-incoherent results with uncorrelated pixel noise, resulting in only\nthe sample mean being somewhat useful as an output prediction. In this paper,\nwe aim to stay true to VAE theory by improving the samples from the\nobservational distribution. We propose SOS-VAE, an alternative model for the\nobservation space, encoding spatial dependencies via a low-rank\nparameterisation. We demonstrate that this new observational distribution has\nthe ability to capture relevant covariance between pixels, resulting in\nspatially-coherent samples. In contrast to pixel-wise independent\ndistributions, our samples seem to contain semantically-meaningful variations\nfrom the mean allowing the prediction of multiple plausible outputs with a\nsingle forward pass.", "published": "2022-05-25T07:12:50Z", "version": 2}, {"aid": "2205.12956", "authors": ["Chenyang Si", "Weihao Yu", "Pan Zhou", "Yichen Zhou", "Xinchao Wang", "Shuicheng Yan"], "title": "Inception Transformer", "url": "http://arxiv.org/pdf/2205.12956v2", "summary": "Recent studies show that Transformer has strong capability of building\nlong-range dependencies, yet is incompetent in capturing high frequencies that\npredominantly convey local information. To tackle this issue, we present a\nnovel and general-purpose Inception Transformer, or iFormer for short, that\neffectively learns comprehensive features with both high- and low-frequency\ninformation in visual data. Specifically, we design an Inception mixer to\nexplicitly graft the advantages of convolution and max-pooling for capturing\nthe high-frequency information to Transformers. Different from recent hybrid\nframeworks, the Inception mixer brings greater efficiency through a channel\nsplitting mechanism to adopt parallel convolution/max-pooling path and\nself-attention path as high- and low-frequency mixers, while having the\nflexibility to model discriminative information scattered within a wide\nfrequency range. Considering that bottom layers play more roles in capturing\nhigh-frequency details while top layers more in modeling low-frequency global\ninformation, we further introduce a frequency ramp structure, i.e. gradually\ndecreasing the dimensions fed to the high-frequency mixer and increasing those\nto the low-frequency mixer, which can effectively trade-off high- and\nlow-frequency components across different layers. We benchmark the iFormer on a\nseries of vision tasks, and showcase that it achieves impressive performance on\nimage classification, COCO detection and ADE20K segmentation. For example, our\niFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than\nDeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%)\nwith only 1/4 parameters and 1/3 FLOPs. Code and models will be released at\nhttps://github.com/sail-sg/iFormer.", "published": "2022-05-25T17:59:54Z", "version": 2}, {"aid": "2205.13076", "authors": ["Amir Joudaki", "Hadi Daneshmand", "Francis Bach"], "title": "On Bridging the Gap between Mean Field and Finite Width in Deep Random Neural Networks with Batch Normalization", "url": "http://arxiv.org/pdf/2205.13076v3", "summary": "Mean field theory is widely used in the theoretical studies of neural\nnetworks. In this paper, we analyze the role of depth in the concentration of\nmean-field predictions, specifically for deep multilayer perceptron (MLP) with\nbatch normalization (BN) at initialization. By scaling the network width to\ninfinity, it is postulated that the mean-field predictions suffer from\nlayer-wise errors that amplify with depth. We demonstrate that BN stabilizes\nthe distribution of representations that avoids the error propagation of\nmean-field predictions. This stabilization, which is characterized by a\ngeometric mixing property, allows us to establish concentration bounds for mean\nfield predictions in infinitely-deep neural networks with a finite width.", "published": "2022-05-25T23:00:26Z", "version": 3}, {"aid": "2205.13147", "authors": ["Aditya Kusupati", "Gantavya Bhatt", "Aniket Rege", "Matthew Wallingford", "Aditya Sinha", "Vivek Ramanujan", "William Howard-Snyder", "Kaifeng Chen", "Sham Kakade", "Prateek Jain", "Ali Farhadi"], "title": "Matryoshka Representation Learning", "url": "http://arxiv.org/pdf/2205.13147v4", "summary": "Learned representations are a central component in modern ML systems, serving\na multitude of downstream tasks. When training such representations, it is\noften the case that computational and statistical constraints for each\ndownstream task are unknown. In this context rigid, fixed capacity\nrepresentations can be either over or under-accommodating to the task at hand.\nThis leads us to ask: can we design a flexible representation that can adapt to\nmultiple downstream tasks with varying computational resources? Our main\ncontribution is Matryoshka Representation Learning (MRL) which encodes\ninformation at different granularities and allows a single embedding to adapt\nto the computational constraints of downstream tasks. MRL minimally modifies\nexisting representation learning pipelines and imposes no additional cost\nduring inference and deployment. MRL learns coarse-to-fine representations that\nare at least as accurate and rich as independently trained low-dimensional\nrepresentations. The flexibility within the learned Matryoshka Representations\noffer: (a) up to 14x smaller embedding size for ImageNet-1K classification at\nthe same level of accuracy; (b) up to 14x real-world speed-ups for large-scale\nretrieval on ImageNet-1K and 4K; and (c) up to 2% accuracy improvements for\nlong-tail few-shot classification, all while being as robust as the original\nrepresentations. Finally, we show that MRL extends seamlessly to web-scale\ndatasets (ImageNet, JFT) across various modalities -- vision (ViT, ResNet),\nvision + language (ALIGN) and language (BERT). MRL code and pretrained models\nare open-sourced at https://github.com/RAIVNLab/MRL.", "published": "2022-05-26T04:33:56Z", "version": 4}, {"aid": "2205.13554", "authors": ["Andy Shih", "Dorsa Sadigh", "Stefano Ermon"], "title": "Training and Inference on Any-Order Autoregressive Models the Right Way", "url": "http://arxiv.org/pdf/2205.13554v2", "summary": "Conditional inference on arbitrary subsets of variables is a core problem in\nprobabilistic inference with important applications such as masked language\nmodeling and image inpainting. In recent years, the family of Any-Order\nAutoregressive Models (AO-ARMs) -- closely related to popular models such as\nBERT and XLNet -- has shown breakthrough performance in arbitrary conditional\ntasks across a sweeping range of domains. But, in spite of their success, in\nthis paper we identify significant improvements to be made to previous\nformulations of AO-ARMs. First, we show that AO-ARMs suffer from redundancy in\ntheir probabilistic model, i.e., they define the same distribution in multiple\ndifferent ways. We alleviate this redundancy by training on a smaller set of\nunivariate conditionals that still maintains support for efficient arbitrary\nconditional inference. Second, we upweight the training loss for univariate\nconditionals that are evaluated more frequently during inference. Our method\nleads to improved performance with no compromises on tractability, giving\nstate-of-the-art likelihoods in arbitrary conditional modeling on text (Text8),\nimage (CIFAR10, ImageNet32), and continuous tabular data domains.", "published": "2022-05-26T18:00:02Z", "version": 2}, {"aid": "2205.13599", "authors": ["Selena Ling", "Nicholas Sharp", "Alec Jacobson"], "title": "VectorAdam for Rotation Equivariant Geometry Optimization", "url": "http://arxiv.org/pdf/2205.13599v4", "summary": "The Adam optimization algorithm has proven remarkably effective for\noptimization problems across machine learning and even traditional tasks in\ngeometry processing. At the same time, the development of equivariant methods,\nwhich preserve their output under the action of rotation or some other\ntransformation, has proven to be important for geometry problems across these\ndomains. In this work, we observe that Adam $-$ when treated as a function that\nmaps initial conditions to optimized results $-$ is not rotation equivariant\nfor vector-valued parameters due to per-coordinate moment updates. This leads\nto significant artifacts and biases in practice. We propose to resolve this\ndeficiency with VectorAdam, a simple modification which makes Adam\nrotation-equivariant by accounting for the vector structure of optimization\nvariables. We demonstrate this approach on problems in machine learning and\ntraditional geometric optimization, showing that equivariant VectorAdam\nresolves the artifacts and biases of traditional Adam when applied to\nvector-valued data, with equivalent or even improved rates of convergence.", "published": "2022-05-26T20:11:05Z", "version": 4}, {"aid": "2205.13863", "authors": ["Binghui Li", "Jikai Jin", "Han Zhong", "John E. Hopcroft", "Liwei Wang"], "title": "Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power", "url": "http://arxiv.org/pdf/2205.13863v3", "summary": "It is well-known that modern neural networks are vulnerable to adversarial\nexamples. To mitigate this problem, a series of robust learning algorithms have\nbeen proposed. However, although the robust training error can be near zero via\nsome methods, all existing algorithms lead to a high robust generalization\nerror. In this paper, we provide a theoretical understanding of this puzzling\nphenomenon from the perspective of expressive power for deep neural networks.\nSpecifically, for binary classification problems with well-separated data, we\nshow that, for ReLU networks, while mild over-parameterization is sufficient\nfor high robust training accuracy, there exists a constant robust\ngeneralization gap unless the size of the neural network is exponential in the\ndata dimension $d$. This result holds even if the data is linear separable\n(which means achieving standard generalization is easy), and more generally for\nany parameterized function classes as long as their VC dimension is at most\npolynomial in the number of parameters. Moreover, we establish an improved\nupper bound of $\\exp({\\mathcal{O}}(k))$ for the network size to achieve low\nrobust generalization error when the data lies on a manifold with intrinsic\ndimension $k$ ($k \\ll d$). Nonetheless, we also have a lower bound that grows\nexponentially with respect to $k$ -- the curse of dimensionality is inevitable.\nBy demonstrating an exponential separation between the network size for\nachieving low robust training and generalization error, our results reveal that\nthe hardness of robust generalization may stem from the expressive power of\npractical models.", "published": "2022-05-27T09:53:04Z", "version": 3}, {"aid": "2205.13913", "authors": ["Zhishu Sun", "Zhifeng Shen", "Luojun Lin", "Yuanlong Yu", "Zhifeng Yang", "Shicai Yang", "Weijie Chen"], "title": "Dynamic Domain Generalization", "url": "http://arxiv.org/pdf/2205.13913v1", "summary": "Domain generalization (DG) is a fundamental yet very challenging research\ntopic in machine learning. The existing arts mainly focus on learning\ndomain-invariant features with limited source domains in a static model.\nUnfortunately, there is a lack of training-free mechanism to adjust the model\nwhen generalized to the agnostic target domains. To tackle this problem, we\ndevelop a brand-new DG variant, namely Dynamic Domain Generalization (DDG), in\nwhich the model learns to twist the network parameters to adapt the data from\ndifferent domains. Specifically, we leverage a meta-adjuster to twist the\nnetwork parameters based on the static model with respect to different data\nfrom different domains. In this way, the static model is optimized to learn\ndomain-shared features, while the meta-adjuster is designed to learn\ndomain-specific features. To enable this process, DomainMix is exploited to\nsimulate data from diverse domains during teaching the meta-adjuster to adapt\nto the upcoming agnostic target domains. This learning mechanism urges the\nmodel to generalize to different agnostic target domains via adjusting the\nmodel without training. Extensive experiments demonstrate the effectiveness of\nour proposed method. Code is available at: https://github.com/MetaVisionLab/DDG", "published": "2022-05-27T11:29:03Z", "version": 1}, {"aid": "2205.14540", "authors": ["Feng Liang", "Yangguang Li", "Diana Marculescu"], "title": "SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners", "url": "http://arxiv.org/pdf/2205.14540v3", "summary": "Recently, self-supervised Masked Autoencoders (MAE) have attracted\nunprecedented attention for their impressive representation learning ability.\nHowever, the pretext task, Masked Image Modeling (MIM), reconstructs the\nmissing local patches, lacking the global understanding of the image. This\npaper extends MAE to a fully supervised setting by adding a supervised\nclassification branch, thereby enabling MAE to learn global features from\ngolden labels effectively. The proposed Supervised MAE (SupMAE) only exploits a\nvisible subset of image patches for classification, unlike the standard\nsupervised pre-training where all image patches are used. Through experiments,\nwe demonstrate that SupMAE is not only more training efficient but it also\nlearns more robust and transferable features. Specifically, SupMAE achieves\ncomparable performance with MAE using only 30% of compute when evaluated on\nImageNet with the ViT-B/16 model. SupMAE's robustness on ImageNet variants and\ntransfer learning performance outperforms MAE and standard supervised\npre-training counterparts. Codes are available at\nhttps://github.com/enyac-group/supmae.", "published": "2022-05-28T23:05:03Z", "version": 3}, {"aid": "2205.14871", "authors": ["Ziteng Cui", "Kunchang Li", "Lin Gu", "Shenghan Su", "Peng Gao", "Zhengkai Jiang", "Yu Qiao", "Tatsuya Harada"], "title": "You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image Enhancement and Exposure Correction", "url": "http://arxiv.org/pdf/2205.14871v4", "summary": "Challenging illumination conditions (low-light, under-exposure and\nover-exposure) in the real world not only cast an unpleasant visual appearance\nbut also taint the computer vision tasks. After camera captures the raw-RGB\ndata, it renders standard sRGB images with image signal processor (ISP). By\ndecomposing ISP pipeline into local and global image components, we propose a\nlightweight fast Illumination Adaptive Transformer (IAT) to restore the normal\nlit sRGB image from either low-light or under/over-exposure conditions.\nSpecifically, IAT uses attention queries to represent and adjust the\nISP-related parameters such as colour correction, gamma correction. With only\n~90k parameters and ~0.004s processing speed, our IAT consistently achieves\nsuperior performance over SOTA on the current benchmark low-light enhancement\nand exposure correction datasets. Competitive experimental performance also\ndemonstrates that our IAT significantly enhances object detection and semantic\nsegmentation tasks under various light conditions. Training code and pretrained\nmodel is available at\nhttps://github.com/cuiziteng/Illumination-Adaptive-Transformer.", "published": "2022-05-30T06:21:52Z", "version": 4}, {"aid": "2205.15146", "authors": ["Zhanpeng Zhou", "Wen Shen", "Huixin Chen", "Ling Tang", "Quanshi Zhang"], "title": "Batch Normalization Is Blind to the First and Second Derivatives of the Loss", "url": "http://arxiv.org/pdf/2205.15146v2", "summary": "In this paper, we prove the effects of the BN operation on the\nback-propagation of the first and second derivatives of the loss. When we do\nthe Taylor series expansion of the loss function, we prove that the BN\noperation will block the influence of the first-order term and most influence\nof the second-order term of the loss. We also find that such a problem is\ncaused by the standardization phase of the BN operation. Experimental results\nhave verified our theoretical conclusions, and we have found that the BN\noperation significantly affects feature representations in specific tasks,\nwhere losses of different samples share similar analytic formulas.", "published": "2022-05-30T14:43:51Z", "version": 2}, {"aid": "2205.15242", "authors": ["Xiaohan Ding", "Honghao Chen", "Xiangyu Zhang", "Kaiqi Huang", "Jungong Han", "Guiguang Ding"], "title": "Re-parameterizing Your Optimizers rather than Architectures", "url": "http://arxiv.org/pdf/2205.15242v4", "summary": "The well-designed structures in neural networks reflect the prior knowledge\nincorporated into the models. However, though different models have various\npriors, we are used to training them with model-agnostic optimizers such as\nSGD. In this paper, we propose to incorporate model-specific prior knowledge\ninto optimizers by modifying the gradients according to a set of model-specific\nhyper-parameters. Such a methodology is referred to as Gradient\nRe-parameterization, and the optimizers are named RepOptimizers. For the\nextreme simplicity of model structure, we focus on a VGG-style plain model and\nshowcase that such a simple model trained with a RepOptimizer, which is\nreferred to as RepOpt-VGG, performs on par with or better than the recent\nwell-designed models. From a practical perspective, RepOpt-VGG is a favorable\nbase model because of its simple structure, high inference speed and training\nefficiency. Compared to Structural Re-parameterization, which adds priors into\nmodels via constructing extra training-time structures, RepOptimizers require\nno extra forward/backward computations and solve the problem of quantization.\nWe hope to spark further research beyond the realms of model structure design.\nCode and models \\url{https://github.com/DingXiaoH/RepOptimizers}.", "published": "2022-05-30T16:55:59Z", "version": 4}, {"aid": "2205.15894", "authors": ["Kashif Rasul", "Young-Jin Park", "Max Nihl\u00e9n Ramstr\u00f6m", "Kyung-Min Kim"], "title": "VQ-AR: Vector Quantized Autoregressive Probabilistic Time Series Forecasting", "url": "http://arxiv.org/pdf/2205.15894v1", "summary": "Time series models aim for accurate predictions of the future given the past,\nwhere the forecasts are used for important downstream tasks like business\ndecision making. In practice, deep learning based time series models come in\nmany forms, but at a high level learn some continuous representation of the\npast and use it to output point or probabilistic forecasts. In this paper, we\nintroduce a novel autoregressive architecture, VQ-AR, which instead learns a\n\\emph{discrete} set of representations that are used to predict the future.\nExtensive empirical comparison with other competitive deep learning models\nshows that surprisingly such a discrete set of representations gives\nstate-of-the-art or equivalent results on a wide variety of time series\ndatasets. We also highlight the shortcomings of this approach, explore its\nzero-shot generalization capabilities, and present an ablation study on the\nnumber of representations. The full source code of the method will be available\nat the time of publication with the hope that researchers can further\ninvestigate this important but overlooked inductive bias for the time series\ndomain.", "published": "2022-05-31T15:43:46Z", "version": 1}, {"aid": "2206.02629", "authors": ["Beren Millidge", "Yuhang Song", "Tommaso Salvatori", "Thomas Lukasiewicz", "Rafal Bogacz"], "title": "Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning", "url": "http://arxiv.org/pdf/2206.02629v3", "summary": "How the brain performs credit assignment is a fundamental unsolved problem in\nneuroscience. Many `biologically plausible' algorithms have been proposed,\nwhich compute gradients that approximate those computed by backpropagation\n(BP), and which operate in ways that more closely satisfy the constraints\nimposed by neural circuitry. Many such algorithms utilize the framework of\nenergy-based models (EBMs), in which all free variables in the model are\noptimized to minimize a global energy function. However, in the literature,\nthese algorithms exist in isolation and no unified theory exists linking them\ntogether. Here, we provide a comprehensive theory of the conditions under which\nEBMs can approximate BP, which lets us unify many of the BP approximation\nresults in the literature (namely, predictive coding, equilibrium propagation,\nand contrastive Hebbian learning) and demonstrate that their approximation to\nBP arises from a simple and general mathematical property of EBMs at free-phase\nequilibrium. This property can then be exploited in different ways with\ndifferent energy functions, and these specific choices yield a family of\nBP-approximating algorithms, which both includes the known results in the\nliterature and can be used to derive new ones.", "published": "2022-05-31T20:48:52Z", "version": 3}, {"aid": "2206.00182", "authors": ["Ali Athar", "Jonathon Luiten", "Alexander Hermans", "Deva Ramanan", "Bastian Leibe"], "title": "Differentiable Soft-Masked Attention", "url": "http://arxiv.org/pdf/2206.00182v2", "summary": "Transformers have become prevalent in computer vision due to their\nperformance and flexibility in modelling complex operations. Of particular\nsignificance is the 'cross-attention' operation, which allows a vector\nrepresentation (e.g. of an object in an image) to be learned by attending to an\narbitrarily sized set of input features. Recently, \"Masked Attention\" was\nproposed in which a given object representation only attends to those image\npixel features for which the segmentation mask of that object is active. This\nspecialization of attention proved beneficial for various image and video\nsegmentation tasks. In this paper, we propose another specialization of\nattention which enables attending over `soft-masks' (those with continuous mask\nprobabilities instead of binary values), and is also differentiable through\nthese mask probabilities, thus allowing the mask used for attention to be\nlearned within the network without requiring direct loss supervision. This can\nbe useful for several applications. Specifically, we employ our \"Differentiable\nSoft-Masked Attention\" for the task of Weakly-Supervised Video Object\nSegmentation (VOS), where we develop a transformer-based network for VOS which\nonly requires a single annotated image frame for training, but can also benefit\nfrom cycle consistency training on a video with just one annotated frame.\nAlthough there is no loss for masks in unlabeled frames, the network is still\nable to segment objects in those frames due to our novel attention formulation.\nCode:\nhttps://github.com/Ali2500/HODOR/blob/main/hodor/modelling/encoder/soft_masked_attention.py", "published": "2022-06-01T02:05:13Z", "version": 2}, {"aid": "2206.00244", "authors": ["Jiuk Hong", "Chaehyeon Lee", "Soyoun Bang", "Heechul Jung"], "title": "Fair Comparison between Efficient Attentions", "url": "http://arxiv.org/pdf/2206.00244v1", "summary": "Transformers have been successfully used in various fields and are becoming\nthe standard tools in computer vision. However, self-attention, a core\ncomponent of transformers, has a quadratic complexity problem, which limits the\nuse of transformers in various vision tasks that require dense prediction. Many\nstudies aiming at solving this problem have been reported proposed. However, no\ncomparative study of these methods using the same scale has been reported due\nto different model configurations, training schemes, and new methods. In our\npaper, we validate these efficient attention models on the ImageNet1K\nclassification task by changing only the attention operation and examining\nwhich efficient attention is better.", "published": "2022-06-01T06:00:13Z", "version": 1}, {"aid": "2206.00272", "authors": ["Kai Han", "Yunhe Wang", "Jianyuan Guo", "Yehui Tang", "Enhua Wu"], "title": "Vision GNN: An Image is Worth Graph of Nodes", "url": "http://arxiv.org/pdf/2206.00272v3", "summary": "Network architecture plays a key role in the deep learning-based computer\nvision system. The widely-used convolutional neural network and transformer\ntreat the image as a grid or sequence structure, which is not flexible to\ncapture irregular and complex objects. In this paper, we propose to represent\nthe image as a graph structure and introduce a new Vision GNN (ViG)\narchitecture to extract graph-level feature for visual tasks. We first split\nthe image to a number of patches which are viewed as nodes, and construct a\ngraph by connecting the nearest neighbors. Based on the graph representation of\nimages, we build our ViG model to transform and exchange information among all\nthe nodes. ViG consists of two basic modules: Grapher module with graph\nconvolution for aggregating and updating graph information, and FFN module with\ntwo linear layers for node feature transformation. Both isotropic and pyramid\narchitectures of ViG are built with different model sizes. Extensive\nexperiments on image recognition and object detection tasks demonstrate the\nsuperiority of our ViG architecture. We hope this pioneering study of GNN on\ngeneral visual tasks will provide useful inspiration and experience for future\nresearch. The PyTorch code is available at\nhttps://github.com/huawei-noah/Efficient-AI-Backbones and the MindSpore code is\navailable at https://gitee.com/mindspore/models.", "published": "2022-06-01T07:01:04Z", "version": 3}, {"aid": "2206.00384", "authors": ["Jaewon Kim", "Hyukjong Lee", "Jooyoung Chang", "Sang Min Park"], "title": "Generalized Supervised Contrastive Learning", "url": "http://arxiv.org/pdf/2206.00384v2", "summary": "With the recent promising results of contrastive learning in the\nself-supervised learning paradigm, supervised contrastive learning has\nsuccessfully extended these contrastive approaches to supervised contexts,\noutperforming cross-entropy on various datasets. However, supervised\ncontrastive learning inherently employs label information in a binary\nform--either positive or negative--using a one-hot target vector. This\nstructure struggles to adapt to methods that exploit label information as a\nprobability distribution, such as CutMix and knowledge distillation. In this\npaper, we introduce a generalized supervised contrastive loss, which measures\ncross-entropy between label similarity and latent similarity. This concept\nenhances the capabilities of supervised contrastive loss by fully utilizing the\nlabel distribution and enabling the adaptation of various existing techniques\nfor training modern neural networks. Leveraging this generalized supervised\ncontrastive loss, we construct a tailored framework: the Generalized Supervised\nContrastive Learning (GenSCL). Compared to existing contrastive learning\nframeworks, GenSCL incorporates additional enhancements, including advanced\nimage-based regularization techniques and an arbitrary teacher classifier. When\napplied to ResNet50 with the Momentum Contrast technique, GenSCL achieves a\ntop-1 accuracy of 77.3% on ImageNet, a 4.1% relative improvement over\ntraditional supervised contrastive learning. Moreover, our method establishes\nnew state-of-the-art accuracies of 98.2% and 87.0% on CIFAR10 and CIFAR100\nrespectively when applied to ResNet50, marking the highest reported figures for\nthis architecture.", "published": "2022-06-01T10:38:21Z", "version": 2}, {"aid": "2206.00746", "authors": ["Shayan Shekarforoush", "David B. Lindell", "David J. Fleet", "Marcus A. Brubaker"], "title": "Residual Multiplicative Filter Networks for Multiscale Reconstruction", "url": "http://arxiv.org/pdf/2206.00746v2", "summary": "Coordinate networks like Multiplicative Filter Networks (MFNs) and BACON\noffer some control over the frequency spectrum used to represent continuous\nsignals such as images or 3D volumes. Yet, they are not readily applicable to\nproblems for which coarse-to-fine estimation is required, including various\ninverse problems in which coarse-to-fine optimization plays a key role in\navoiding poor local minima. We introduce a new coordinate network architecture\nand training scheme that enables coarse-to-fine optimization with fine-grained\ncontrol over the frequency support of learned reconstructions. This is achieved\nwith two key innovations. First, we incorporate skip connections so that\nstructure at one scale is preserved when fitting finer-scale structure. Second,\nwe propose a novel initialization scheme to provide control over the model\nfrequency spectrum at each stage of optimization. We demonstrate how these\nmodifications enable multiscale optimization for coarse-to-fine fitting to\nnatural images. We then evaluate our model on synthetically generated datasets\nfor the the problem of single-particle cryo-EM reconstruction. We learn high\nresolution multiscale structures, on par with the state-of-the art.", "published": "2022-06-01T20:16:28Z", "version": 2}, {"aid": "2206.00823", "authors": ["Yuhan Helena Liu", "Arna Ghosh", "Blake A. Richards", "Eric Shea-Brown", "Guillaume Lajoie"], "title": "Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules", "url": "http://arxiv.org/pdf/2206.00823v3", "summary": "To unveil how the brain learns, ongoing work seeks biologically-plausible\napproximations of gradient descent algorithms for training recurrent neural\nnetworks (RNNs). Yet, beyond task accuracy, it is unclear if such learning\nrules converge to solutions that exhibit different levels of generalization\nthan their nonbiologically-plausible counterparts. Leveraging results from deep\nlearning theory based on loss landscape curvature, we ask: how do\nbiologically-plausible gradient approximations affect generalization? We first\ndemonstrate that state-of-the-art biologically-plausible learning rules for\ntraining RNNs exhibit worse and more variable generalization performance\ncompared to their machine learning counterparts that follow the true gradient\nmore closely. Next, we verify that such generalization performance is\ncorrelated significantly with loss landscape curvature, and we show that\nbiologically-plausible learning rules tend to approach high-curvature regions\nin synaptic weight space. Using tools from dynamical systems, we derive\ntheoretical arguments and present a theorem explaining this phenomenon. This\npredicts our numerical results, and explains why biologically-plausible rules\nlead to worse and more variable generalization properties. Finally, we suggest\npotential remedies that could be used by the brain to mitigate this effect. To\nour knowledge, our analysis is the first to identify the reason for this\ngeneralization gap between artificial and biologically-plausible learning\nrules, which can help guide future investigations into how the brain learns\nsolutions that generalize.", "published": "2022-06-02T01:39:08Z", "version": 3}, {"aid": "2206.00941", "authors": ["Hyungjin Chung", "Byeongsu Sim", "Dohoon Ryu", "Jong Chul Ye"], "title": "Improving Diffusion Models for Inverse Problems using Manifold Constraints", "url": "http://arxiv.org/pdf/2206.00941v3", "summary": "Recently, diffusion models have been used to solve various inverse problems\nin an unsupervised manner with appropriate modifications to the sampling\nprocess. However, the current solvers, which recursively apply a reverse\ndiffusion step followed by a projection-based measurement consistency step,\noften produce suboptimal results. By studying the generative sampling path,\nhere we show that current solvers throw the sample path off the data manifold,\nand hence the error accumulates. To address this, we propose an additional\ncorrection term inspired by the manifold constraint, which can be used\nsynergistically with the previous solvers to make the iterations close to the\nmanifold. The proposed manifold constraint is straightforward to implement\nwithin a few lines of code, yet boosts the performance by a surprisingly large\nmargin. With extensive experiments, we show that our method is superior to the\nprevious methods both theoretically and empirically, producing promising\nresults in many applications such as image inpainting, colorization, and\nsparse-view computed tomography. Code available\nhttps://github.com/HJ-harry/MCG_diffusion", "published": "2022-06-02T09:06:10Z", "version": 3}, {"aid": "2206.01338", "authors": ["Yuhan Helena Liu", "Stephen Smith", "Stefan Mihalas", "Eric Shea-Brown", "Uygar S\u00fcmb\u00fcl"], "title": "Biologically-plausible backpropagation through arbitrary timespans via local neuromodulators", "url": "http://arxiv.org/pdf/2206.01338v4", "summary": "The spectacular successes of recurrent neural network models where key\nparameters are adjusted via backpropagation-based gradient descent have\ninspired much thought as to how biological neuronal networks might solve the\ncorresponding synaptic credit assignment problem. There is so far little\nagreement, however, as to how biological networks could implement the necessary\nbackpropagation through time, given widely recognized constraints of biological\nsynaptic network signaling architectures. Here, we propose that extra-synaptic\ndiffusion of local neuromodulators such as neuropeptides may afford an\neffective mode of backpropagation lying within the bounds of biological\nplausibility. Going beyond existing temporal truncation-based gradient\napproximations, our approximate gradient-based update rule, ModProp, propagates\ncredit information through arbitrary time steps. ModProp suggests that\nmodulatory signals can act on receiving cells by convolving their eligibility\ntraces via causal, time-invariant and synapse-type-specific filter taps. Our\nmathematical analysis of ModProp learning, together with simulation results on\nbenchmark temporal tasks, demonstrate the advantage of ModProp over existing\nbiologically-plausible temporal credit assignment rules. These results suggest\na potential neuronal mechanism for signaling credit information related to\nrecurrent interactions over a longer time horizon. Finally, we derive an\nin-silico implementation of ModProp that could serve as a low-complexity and\ncausal alternative to backpropagation through time.", "published": "2022-06-02T23:38:10Z", "version": 4}, {"aid": "2206.01342", "authors": ["Yuandong Tian"], "title": "Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning", "url": "http://arxiv.org/pdf/2206.01342v3", "summary": "While the empirical success of self-supervised learning (SSL) heavily relies\non the usage of deep nonlinear models, existing theoretical works on SSL\nunderstanding still focus on linear ones. In this paper, we study the role of\nnonlinearity in the training dynamics of contrastive learning (CL) on one and\ntwo-layer nonlinear networks with homogeneous activation $h(x) = h'(x)x$. We\nhave two major theoretical discoveries. First, the presence of nonlinearity can\nlead to many local optima even in 1-layer setting, each corresponding to\ncertain patterns from the data distribution, while with linear activation, only\none major pattern can be learned. This suggests that models with lots of\nparameters can be regarded as a \\emph{brute-force} way to find these local\noptima induced by nonlinearity. Second, in the 2-layer case, linear activation\nis proven not capable of learning specialized weights into diverse patterns,\ndemonstrating the importance of nonlinearity. In addition, for 2-layer setting,\nwe also discover \\emph{global modulation}: those local patterns discriminative\nfrom the perspective of global-level patterns are prioritized to learn, further\ncharacterizing the learning process. Simulation verifies our theoretical\nfindings.", "published": "2022-06-02T23:52:35Z", "version": 3}, {"aid": "2206.02574", "authors": ["Quentin Garrido", "Yubei Chen", "Adrien Bardes", "Laurent Najman", "Yann Lecun"], "title": "On the duality between contrastive and non-contrastive self-supervised learning", "url": "http://arxiv.org/pdf/2206.02574v3", "summary": "Recent approaches in self-supervised learning of image representations can be\ncategorized into different families of methods and, in particular, can be\ndivided into contrastive and non-contrastive approaches. While differences\nbetween the two families have been thoroughly discussed to motivate new\napproaches, we focus more on the theoretical similarities between them. By\ndesigning contrastive and covariance based non-contrastive criteria that can be\nrelated algebraically and shown to be equivalent under limited assumptions, we\nshow how close those families can be. We further study popular methods and\nintroduce variations of them, allowing us to relate this theoretical result to\ncurrent practices and show the influence (or lack thereof) of design choices on\ndownstream performance. Motivated by our equivalence result, we investigate the\nlow performance of SimCLR and show how it can match VICReg's with careful\nhyperparameter tuning, improving significantly over known baselines. We also\nchallenge the popular assumption that non-contrastive methods need large output\ndimensions. Our theoretical and quantitative results suggest that the numerical\ngaps between contrastive and non-contrastive methods in certain regimes can be\nclosed given better network design choices and hyperparameter tuning. The\nevidence shows that unifying different SOTA methods is an important direction\nto build a better understanding of self-supervised learning.", "published": "2022-06-03T08:04:12Z", "version": 3}, {"aid": "2206.01714", "authors": ["Nan Liu", "Shuang Li", "Yilun Du", "Antonio Torralba", "Joshua B. Tenenbaum"], "title": "Compositional Visual Generation with Composable Diffusion Models", "url": "http://arxiv.org/pdf/2206.01714v6", "summary": "Large text-guided diffusion models, such as DALLE-2, are able to generate\nstunning photorealistic images given natural language descriptions. While such\nmodels are highly flexible, they struggle to understand the composition of\ncertain concepts, such as confusing the attributes of different objects or\nrelations between objects. In this paper, we propose an alternative structured\napproach for compositional generation using diffusion models. An image is\ngenerated by composing a set of diffusion models, with each of them modeling a\ncertain component of the image. To do this, we interpret diffusion models as\nenergy-based models in which the data distributions defined by the energy\nfunctions may be explicitly combined. The proposed method can generate scenes\nat test time that are substantially more complex than those seen in training,\ncomposing sentence descriptions, object relations, human facial attributes, and\neven generalizing to new combinations that are rarely seen in the real world.\nWe further illustrate how our approach may be used to compose pre-trained\ntext-guided diffusion models and generate photorealistic images containing all\nthe details described in the input descriptions, including the binding of\ncertain object attributes that have been shown difficult for DALLE-2. These\nresults point to the effectiveness of the proposed method in promoting\nstructured generalization for visual generation. Project page:\nhttps://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/", "published": "2022-06-03T17:47:04Z", "version": 6}, {"aid": "2206.02061", "authors": ["Sai Sukruth Bezugam", "Ahmed Shaban", "Manan Suri"], "title": "Low Power Neuromorphic EMG Gesture Classification", "url": "http://arxiv.org/pdf/2206.02061v1", "summary": "EMG (Electromyograph) signal based gesture recognition can prove vital for\napplications such as smart wearables and bio-medical neuro-prosthetic control.\nSpiking Neural Networks (SNNs) are promising for low-power, real-time EMG\ngesture recognition, owing to their inherent spike/event driven spatio-temporal\ndynamics. In literature, there are limited demonstrations of neuromorphic\nhardware implementation (at full chip/board/system scale) for EMG gesture\nclassification. Moreover, most literature attempts exploit primitive SNNs based\non LIF (Leaky Integrate and Fire) neurons. In this work, we address the\naforementioned gaps with following key contributions: (1) Low-power, high\naccuracy demonstration of EMG-signal based gesture recognition using\nneuromorphic Recurrent Spiking Neural Networks (RSNN). In particular, we\npropose a multi-time scale recurrent neuromorphic system based on special\ndouble-exponential adaptive threshold (DEXAT) neurons. Our network achieves\nstate-of-the-art classification accuracy (90%) while using ~53% lesser neurons\nthan best reported prior art on Roshambo EMG dataset. (2) A new multi-channel\nspike encoder scheme for efficient processing of real-valued EMG data on\nneuromorphic systems. (3) Unique multi-compartment methodology to implement\ncomplex adaptive neurons on Intel's dedicated neuromorphic Loihi chip is shown.\n(4) RSNN implementation on Loihi (Nahuku 32) achieves significant\nenergy/latency benefits of ~983X/19X compared to GPU for batch size as 50.", "published": "2022-06-04T22:09:34Z", "version": 1}, {"aid": "2206.02070", "authors": ["Yunfan Lu", "Yiqi Lin", "Hao Wu", "Yunhao Luo", "Xu Zheng", "Hui Xiong", "Lin Wang"], "title": "Priors in Deep Image Restoration and Enhancement: A Survey", "url": "http://arxiv.org/pdf/2206.02070v2", "summary": "Image restoration and enhancement is a process of improving the image quality\nby removing degradations, such as noise, blur, and resolution degradation. Deep\nlearning (DL) has recently been applied to image restoration and enhancement.\nDue to its ill-posed property, plenty of works have been explored priors to\nfacilitate training deep neural networks (DNNs). However, the importance of\npriors has not been systematically studied and analyzed by far in the research\ncommunity. Therefore, this paper serves as the first study that provides a\ncomprehensive overview of recent advancements in priors for deep image\nrestoration and enhancement. Our work covers five primary contents: (1) A\ntheoretical analysis of priors for deep image restoration and enhancement; (2)\nA hierarchical and structural taxonomy of priors commonly used in the DL-based\nmethods; (3) An insightful discussion on each prior regarding its principle,\npotential, and applications; (4) A summary of crucial problems by highlighting\nthe potential future directions, especially adopting the large-scale foundation\nmodels as prior, to spark more research in the community; (5) An open-source\nrepository that provides a taxonomy of all mentioned works and code links.", "published": "2022-06-04T23:33:34Z", "version": 2}, {"aid": "2206.02102", "authors": ["Difeng Cai", "Yuliang Ji", "Huan He", "Qiang Ye", "Yuanzhe Xi"], "title": "AUTM Flow: Atomic Unrestricted Time Machine for Monotonic Normalizing Flows", "url": "http://arxiv.org/pdf/2206.02102v1", "summary": "Nonlinear monotone transformations are used extensively in normalizing flows\nto construct invertible triangular mappings from simple distributions to\ncomplex ones. In existing literature, monotonicity is usually enforced by\nrestricting function classes or model parameters and the inverse transformation\nis often approximated by root-finding algorithms as a closed-form inverse is\nunavailable. In this paper, we introduce a new integral-based approach termed\n\"Atomic Unrestricted Time Machine (AUTM)\", equipped with unrestricted\nintegrands and easy-to-compute explicit inverse. AUTM offers a versatile and\nefficient way to the design of normalizing flows with explicit inverse and\nunrestricted function classes or parameters. Theoretically, we present a\nconstructive proof that AUTM is universal: all monotonic normalizing flows can\nbe viewed as limits of AUTM flows. We provide a concrete example to show how to\napproximate any given monotonic normalizing flow using AUTM flows with\nguaranteed convergence. The result implies that AUTM can be used to transform\nan existing flow into a new one equipped with explicit inverse and unrestricted\nparameters. The performance of the new approach is evaluated on high\ndimensional density estimation, variational inference and image generation.\nExperiments demonstrate superior speed and memory efficiency of AUTM.", "published": "2022-06-05T05:58:04Z", "version": 1}, {"aid": "2206.02200", "authors": ["Abhishek Kumar", "Oladayo S. Ajani", "Swagatam Das", "Rammohan Mallipeddi"], "title": "GridShift: A Faster Mode-seeking Algorithm for Image Segmentation and Object Tracking", "url": "http://arxiv.org/pdf/2206.02200v1", "summary": "In machine learning and computer vision, mean shift (MS) qualifies as one of\nthe most popular mode-seeking algorithms used for clustering and image\nsegmentation. It iteratively moves each data point to the weighted mean of its\nneighborhood data points. The computational cost required to find the neighbors\nof each data point is quadratic to the number of data points. Consequently, the\nvanilla MS appears to be very slow for large-scale datasets. To address this\nissue, we propose a mode-seeking algorithm called GridShift, with significant\nspeedup and principally based on MS. To accelerate, GridShift employs a\ngrid-based approach for neighbor search, which is linear in the number of data\npoints. In addition, GridShift moves the active grid cells (grid cells\nassociated with at least one data point) in place of data points towards the\nhigher density, a step that provides more speedup. The runtime of GridShift is\nlinear in the number of active grid cells and exponential in the number of\nfeatures. Therefore, it is ideal for large-scale low-dimensional applications\nsuch as object tracking and image segmentation. Through extensive experiments,\nwe showcase the superior performance of GridShift compared to other MS-based as\nwell as state-of-the-art algorithms in terms of accuracy and runtime on\nbenchmark datasets for image segmentation. Finally, we provide a new\nobject-tracking algorithm based on GridShift and show promising results for\nobject tracking compared to CamShift and meanshift++.", "published": "2022-06-05T15:08:34Z", "version": 1}, {"aid": "2206.02916", "authors": ["Zhiwei Deng", "Olga Russakovsky"], "title": "Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks", "url": "http://arxiv.org/pdf/2206.02916v2", "summary": "We propose an algorithm that compresses the critical information of a large\ndataset into compact addressable memories. These memories can then be recalled\nto quickly re-train a neural network and recover the performance (instead of\nstoring and re-training on the full original dataset). Building upon the\ndataset distillation framework, we make a key observation that a shared common\nrepresentation allows for more efficient and effective distillation.\nConcretely, we learn a set of bases (aka ``memories'') which are shared between\nclasses and combined through learned flexible addressing functions to generate\na diverse set of training examples. This leads to several benefits: 1) the size\nof compressed data does not necessarily grow linearly with the number of\nclasses; 2) an overall higher compression rate with more effective distillation\nis achieved; and 3) more generalized queries are allowed beyond recalling the\noriginal classes. We demonstrate state-of-the-art results on the dataset\ndistillation task across six benchmarks, including up to 16.5% and 9.7% in\nretained accuracy improvement when distilling CIFAR10 and CIFAR100\nrespectively. We then leverage our framework to perform continual learning,\nachieving state-of-the-art results on four benchmarks, with 23.2% accuracy\nimprovement on MANY. The code is released on our project webpage\nhttps://github.com/princetonvisualai/RememberThePast-DatasetDistillation.", "published": "2022-06-06T21:32:26Z", "version": 2}, {"aid": "2206.03065", "authors": ["Joan Serr\u00e0", "Santiago Pascual", "Jordi Pons", "R. Oguz Araz", "Davide Scaini"], "title": "Universal Speech Enhancement with Score-based Diffusion", "url": "http://arxiv.org/pdf/2206.03065v2", "summary": "Removing background noise from speech audio has been the subject of\nconsiderable effort, especially in recent years due to the rise of virtual\ncommunication and amateur recordings. Yet background noise is not the only\nunpleasant disturbance that can prevent intelligibility: reverb, clipping,\ncodec artifacts, problematic equalization, limited bandwidth, or inconsistent\nloudness are equally disturbing and ubiquitous. In this work, we propose to\nconsider the task of speech enhancement as a holistic endeavor, and present a\nuniversal speech enhancement system that tackles 55 different distortions at\nthe same time. Our approach consists of a generative model that employs\nscore-based diffusion, together with a multi-resolution conditioning network\nthat performs enhancement with mixture density networks. We show that this\napproach significantly outperforms the state of the art in a subjective test\nperformed by expert listeners. We also show that it achieves competitive\nobjective scores with just 4-8 diffusion steps, despite not considering any\nparticular strategy for fast sampling. We hope that both our methodology and\ntechnical contributions encourage researchers and practitioners to adopt a\nuniversal approach to speech enhancement, possibly framing it as a generative\ntask.", "published": "2022-06-07T07:32:32Z", "version": 2}, {"aid": "2206.03179", "authors": ["Ignacio Aguilera-Martos", "\u00c1ngel M. Garc\u00eda-Vico", "Juli\u00e1n Luengo", "Sergio Damas", "Francisco J. Melero", "Jos\u00e9 Javier Valle-Alonso", "Francisco Herrera"], "title": "TSFEDL: A Python Library for Time Series Spatio-Temporal Feature Extraction and Prediction using Deep Learning (with Appendices on Detailed Network Architectures and Experimental Cases of Study)", "url": "http://arxiv.org/pdf/2206.03179v2", "summary": "The combination of convolutional and recurrent neural networks is a promising\nframework that allows the extraction of high-quality spatio-temporal features\ntogether with its temporal dependencies, which is key for time series\nprediction problems such as forecasting, classification or anomaly detection,\namongst others. In this paper, the TSFEDL library is introduced. It compiles 20\nstate-of-the-art methods for both time series feature extraction and\nprediction, employing convolutional and recurrent deep neural networks for its\nuse in several data mining tasks. The library is built upon a set of\nTensorflow+Keras and PyTorch modules under the AGPLv3 license. The performance\nvalidation of the architectures included in this proposal confirms the\nusefulness of this Python package.", "published": "2022-06-07T10:58:33Z", "version": 2}, {"aid": "2206.03951", "authors": ["Kohitij Kar", "Simon Kornblith", "Evelina Fedorenko"], "title": "Interpretability of artificial neural network models in artificial Intelligence vs. neuroscience", "url": "http://arxiv.org/pdf/2206.03951v1", "summary": "Computationally explicit hypotheses of brain function derived from machine\nlearning (ML)-based models have recently revolutionized neuroscience. Despite\nthe unprecedented ability of these artificial neural networks (ANNs) to capture\nresponses in biological neural networks (brains), and our full access to all\ninternal model components (unlike the brain), ANNs are often referred to as\nblack-boxes with limited interpretability. Interpretability, however, is a\nmulti-faceted construct that is used differently across fields. In particular,\ninterpretability, or explainability, efforts in Artificial Intelligence (AI)\nfocus on understanding how different model components contribute to its output\n(i.e., decision making). In contrast, the neuroscientific interpretability of\nANNs requires explicit alignment between model components and neuroscientific\nconstructs (e.g., different brain areas or phenomena, like recurrence or\ntop-down feedback). Given the widespread calls to improve the interpretability\nof AI systems, we here highlight these different notions of interpretability\nand argue that the neuroscientific interpretability of ANNs can be pursued in\nparallel with, but independently from, the ongoing efforts in AI. Certain ML\ntechniques (e.g., deep dream) can be leveraged in both fields, to ask what\nstimulus optimally activates the specific model features (feature visualization\nby optimization), or how different features contribute to the model's output\n(feature attribution). However, without appropriate brain alignment, certain\nfeatures will remain uninterpretable to neuroscientists.", "published": "2022-06-07T15:33:45Z", "version": 1}, {"aid": "2206.03429", "authors": ["Tim Brooks", "Janne Hellsten", "Miika Aittala", "Ting-Chun Wang", "Timo Aila", "Jaakko Lehtinen", "Ming-Yu Liu", "Alexei A. Efros", "Tero Karras"], "title": "Generating Long Videos of Dynamic Scenes", "url": "http://arxiv.org/pdf/2206.03429v2", "summary": "We present a video generation model that accurately reproduces object motion,\nchanges in camera viewpoint, and new content that arises over time. Existing\nvideo generation methods often fail to produce new content as a function of\ntime while maintaining consistencies expected in real environments, such as\nplausible dynamics and object persistence. A common failure case is for content\nto never change due to over-reliance on inductive biases to provide temporal\nconsistency, such as a single latent code that dictates content for the entire\nvideo. On the other extreme, without long-term consistency, generated videos\nmay morph unrealistically between different scenes. To address these\nlimitations, we prioritize the time axis by redesigning the temporal latent\nrepresentation and learning long-term consistency from data by training on\nlonger videos. To this end, we leverage a two-phase training strategy, where we\nseparately train using longer videos at a low resolution and shorter videos at\na high resolution. To evaluate the capabilities of our model, we introduce two\nnew benchmark datasets with explicit focus on long-term temporal dynamics.", "published": "2022-06-07T16:29:51Z", "version": 2}, {"aid": "2206.03727", "authors": ["Jun Yan", "Huilin Yin", "Xiaoyang Deng", "Ziming Zhao", "Wancheng Ge", "Hao Zhang", "Gerhard Rigoll"], "title": "Wavelet Regularization Benefits Adversarial Training", "url": "http://arxiv.org/pdf/2206.03727v1", "summary": "Adversarial training methods are state-of-the-art (SOTA) empirical defense\nmethods against adversarial examples. Many regularization methods have been\nproven to be effective with the combination of adversarial training.\nNevertheless, such regularization methods are implemented in the time domain.\nSince adversarial vulnerability can be regarded as a high-frequency phenomenon,\nit is essential to regulate the adversarially-trained neural network models in\nthe frequency domain. Faced with these challenges, we make a theoretical\nanalysis on the regularization property of wavelets which can enhance\nadversarial training. We propose a wavelet regularization method based on the\nHaar wavelet decomposition which is named Wavelet Average Pooling. This wavelet\nregularization module is integrated into the wide residual neural network so\nthat a new WideWaveletResNet model is formed. On the datasets of CIFAR-10 and\nCIFAR-100, our proposed Adversarial Wavelet Training method realizes\nconsiderable robustness under different types of attacks. It verifies the\nassumption that our wavelet regularization method can enhance adversarial\nrobustness especially in the deep wide neural networks. The visualization\nexperiments of the Frequency Principle (F-Principle) and interpretability are\nimplemented to show the effectiveness of our method. A detailed comparison\nbased on different wavelet base functions is presented. The code is available\nat the repository:\n\\url{https://github.com/momo1986/AdversarialWaveletTraining}.", "published": "2022-06-08T08:00:30Z", "version": 1}, {"aid": "2206.04040", "authors": ["Pavan Kumar Anasosalu Vasu", "James Gabriel", "Jeff Zhu", "Oncel Tuzel", "Anurag Ranjan"], "title": "MobileOne: An Improved One millisecond Mobile Backbone", "url": "http://arxiv.org/pdf/2206.04040v2", "summary": "Efficient neural network backbones for mobile devices are often optimized for\nmetrics such as FLOPs or parameter count. However, these metrics may not\ncorrelate well with latency of the network when deployed on a mobile device.\nTherefore, we perform extensive analysis of different metrics by deploying\nseveral mobile-friendly networks on a mobile device. We identify and analyze\narchitectural and optimization bottlenecks in recent efficient neural networks\nand provide ways to mitigate these bottlenecks. To this end, we design an\nefficient backbone MobileOne, with variants achieving an inference time under 1\nms on an iPhone12 with 75.9% top-1 accuracy on ImageNet. We show that MobileOne\nachieves state-of-the-art performance within the efficient architectures while\nbeing many times faster on mobile. Our best model obtains similar performance\non ImageNet as MobileFormer while being 38x faster. Our model obtains 2.3%\nbetter top-1 accuracy on ImageNet than EfficientNet at similar latency.\nFurthermore, we show that our model generalizes to multiple tasks - image\nclassification, object detection, and semantic segmentation with significant\nimprovements in latency and accuracy as compared to existing efficient\narchitectures when deployed on a mobile device. Code and models are available\nat https://github.com/apple/ml-mobileone", "published": "2022-06-08T17:55:11Z", "version": 2}, {"aid": "2206.04355", "authors": ["Wentao Zhang", "Ziqi Yin", "Zeang Sheng", "Yang Li", "Wen Ouyang", "Xiaosen Li", "Yangyu Tao", "Zhi Yang", "Bin Cui"], "title": "Graph Attention Multi-Layer Perceptron", "url": "http://arxiv.org/pdf/2206.04355v1", "summary": "Graph neural networks (GNNs) have achieved great success in many graph-based\napplications. However, the enormous size and high sparsity level of graphs\nhinder their applications under industrial scenarios. Although some scalable\nGNNs are proposed for large-scale graphs, they adopt a fixed $K$-hop\nneighborhood for each node, thus facing the over-smoothing issue when adopting\nlarge propagation depths for nodes within sparse regions. To tackle the above\nissue, we propose a new GNN architecture -- Graph Attention Multi-Layer\nPerceptron (GAMLP), which can capture the underlying correlations between\ndifferent scales of graph knowledge. We have deployed GAMLP in Tencent with the\nAngel platform, and we further evaluate GAMLP on both real-world datasets and\nlarge-scale industrial datasets. Extensive experiments on these 14 graph\ndatasets demonstrate that GAMLP achieves state-of-the-art performance while\nenjoying high scalability and efficiency. Specifically, it outperforms GAT by\n1.3\\% regarding predictive accuracy on our large-scale Tencent Video dataset\nwhile achieving up to $50\\times$ training speedup. Besides, it ranks top-1 on\nboth the leaderboards of the largest homogeneous and heterogeneous graph (i.e.,\nogbn-papers100M and ogbn-mag) of Open Graph Benchmark.", "published": "2022-06-09T08:56:11Z", "version": 1}, {"aid": "2206.04363", "authors": ["Wei Lu", "Wei Sun", "Xiongkuo Min", "Wenhan Zhu", "Quan Zhou", "Jun He", "Qiyuan Wang", "Zicheng Zhang", "Tao Wang", "Guangtao Zhai"], "title": "Deep Neural Network for Blind Visual Quality Assessment of 4K Content", "url": "http://arxiv.org/pdf/2206.04363v1", "summary": "The 4K content can deliver a more immersive visual experience to consumers\ndue to the huge improvement of spatial resolution. However, existing blind\nimage quality assessment (BIQA) methods are not suitable for the original and\nupscaled 4K contents due to the expanded resolution and specific distortions.\nIn this paper, we propose a deep learning-based BIQA model for 4K content,\nwhich on one hand can recognize true and pseudo 4K content and on the other\nhand can evaluate their perceptual visual quality. Considering the\ncharacteristic that high spatial resolution can represent more abundant\nhigh-frequency information, we first propose a Grey-level Co-occurrence Matrix\n(GLCM) based texture complexity measure to select three representative image\npatches from a 4K image, which can reduce the computational complexity and is\nproven to be very effective for the overall quality prediction through\nexperiments. Then we extract different kinds of visual features from the\nintermediate layers of the convolutional neural network (CNN) and integrate\nthem into the quality-aware feature representation. Finally, two multilayer\nperception (MLP) networks are utilized to map the quality-aware features into\nthe class probability and the quality score for each patch respectively. The\noverall quality index is obtained through the average pooling of patch results.\nThe proposed model is trained through the multi-task learning manner and we\nintroduce an uncertainty principle to balance the losses of the classification\nand regression tasks. The experimental results show that the proposed model\noutperforms all compared BIQA metrics on four 4K content quality assessment\ndatabases.", "published": "2022-06-09T09:10:54Z", "version": 1}, {"aid": "2206.04394", "authors": ["Thomas Fel", "Lucas Hervier", "David Vigouroux", "Antonin Poche", "Justin Plakoo", "Remi Cadene", "Mathieu Chalvidal", "Julien Colin", "Thibaut Boissin", "Louis Bethune", "Agustin Picard", "Claire Nicodeme", "Laurent Gardes", "Gregory Flandin", "Thomas Serre"], "title": "Xplique: A Deep Learning Explainability Toolbox", "url": "http://arxiv.org/pdf/2206.04394v1", "summary": "Today's most advanced machine-learning models are hardly scrutable. The key\nchallenge for explainability methods is to help assisting researchers in\nopening up these black boxes, by revealing the strategy that led to a given\ndecision, by characterizing their internal states or by studying the underlying\ndata representation. To address this challenge, we have developed Xplique: a\nsoftware library for explainability which includes representative\nexplainability methods as well as associated evaluation metrics. It interfaces\nwith one of the most popular learning libraries: Tensorflow as well as other\nlibraries including PyTorch, scikit-learn and Theano. The code is licensed\nunder the MIT license and is freely available at github.com/deel-ai/xplique.", "published": "2022-06-09T10:16:07Z", "version": 1}, {"aid": "2206.04406", "authors": ["Tamara G. Grossmann", "S\u00f6ren Dittmer", "Yury Korolev", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Unsupervised Learning of the Total Variation Flow", "url": "http://arxiv.org/pdf/2206.04406v2", "summary": "The total variation (TV) flow generates a scale-space representation of an\nimage based on the TV functional. This gradient flow observes desirable\nfeatures for images, such as sharp edges and enables spectral, scale, and\ntexture analysis. Solving the TV flow is challenging; one reason is the the\nnon-uniqueness of the subgradients. The standard numerical approach for TV flow\nrequires solving multiple non-smooth optimisation problems. Even with\nstate-of-the-art convex optimisation techniques, this is often prohibitively\nexpensive and strongly motivates the use of alternative, faster approaches.\nInspired by and extending the framework of physics-informed neural networks\n(PINNs), we propose the TVflowNET, an unsupervised neural network approach, to\napproximate the solution of the TV flow given an initial image and a time\ninstance. The TVflowNET requires no ground truth data but rather makes use of\nthe PDE for optimisation of the network parameters. We circumvent the\nchallenges related to the non-uniqueness of the subgradients by additionally\nlearning the related diffusivity term. Our approach significantly speeds up the\ncomputation time and we show that the TVflowNET approximates the TV flow\nsolution with high fidelity for different image sizes and image types.\nAdditionally, we give a full comparison of different network architecture\ndesigns as well as training regimes to underscore the effectiveness of our\napproach.", "published": "2022-06-09T10:39:44Z", "version": 2}, {"aid": "2206.04459", "authors": ["Xijie Huang", "Zhiqiang Shen", "Shichao Li", "Zechun Liu", "Xianghong Hu", "Jeffry Wicaksana", "Eric Xing", "Kwang-Ting Cheng"], "title": "SDQ: Stochastic Differentiable Quantization with Mixed Precision", "url": "http://arxiv.org/pdf/2206.04459v3", "summary": "In order to deploy deep models in a computationally efficient manner, model\nquantization approaches have been frequently used. In addition, as new hardware\nthat supports mixed bitwidth arithmetic operations, recent research on mixed\nprecision quantization (MPQ) begins to fully leverage the capacity of\nrepresentation by searching optimized bitwidths for different layers and\nmodules in a network. However, previous studies mainly search the MPQ strategy\nin a costly scheme using reinforcement learning, neural architecture search,\netc., or simply utilize partial prior knowledge for bitwidth assignment, which\nmight be biased and sub-optimal. In this work, we present a novel Stochastic\nDifferentiable Quantization (SDQ) method that can automatically learn the MPQ\nstrategy in a more flexible and globally-optimized space with smoother gradient\napproximation. Particularly, Differentiable Bitwidth Parameters (DBPs) are\nemployed as the probability factors in stochastic quantization between adjacent\nbitwidth choices. After the optimal MPQ strategy is acquired, we further train\nour network with entropy-aware bin regularization and knowledge distillation.\nWe extensively evaluate our method for several networks on different hardware\n(GPUs and FPGA) and datasets. SDQ outperforms all state-of-the-art mixed or\nsingle precision quantization with a lower bitwidth and is even better than the\nfull-precision counterparts across various ResNet and MobileNet families,\ndemonstrating the effectiveness and superiority of our method.", "published": "2022-06-09T12:38:18Z", "version": 3}, {"aid": "2206.05897", "authors": ["Lin Tian", "Hastings Greer", "Fran\u00e7ois-Xavier Vialard", "Roland Kwitt", "Ra\u00fal San Jos\u00e9 Est\u00e9par", "Richard Jarrett Rushmore", "Nikolaos Makris", "Sylvain Bouix", "Marc Niethammer"], "title": "$\\texttt{GradICON}$: Approximate Diffeomorphisms via Gradient Inverse Consistency", "url": "http://arxiv.org/pdf/2206.05897v4", "summary": "We present an approach to learning regular spatial transformations between\nimage pairs in the context of medical image registration. Contrary to\noptimization-based registration techniques and many modern learning-based\nmethods, we do not directly penalize transformation irregularities but instead\npromote transformation regularity via an inverse consistency penalty. We use a\nneural network to predict a map between a source and a target image as well as\nthe map when swapping the source and target images. Different from existing\napproaches, we compose these two resulting maps and regularize deviations of\nthe $\\bf{Jacobian}$ of this composition from the identity matrix. This\nregularizer -- $\\texttt{GradICON}$ -- results in much better convergence when\ntraining registration models compared to promoting inverse consistency of the\ncomposition of maps directly while retaining the desirable implicit\nregularization effects of the latter. We achieve state-of-the-art registration\nperformance on a variety of real-world medical image datasets using a single\nset of hyperparameters and a single non-dataset-specific training protocol.", "published": "2022-06-13T04:03:49Z", "version": 4}, {"aid": "2206.08933", "authors": ["Weishun Zhong", "Ben Sorscher", "Daniel D Lee", "Haim Sompolinsky"], "title": "A theory of learning with constrained weight-distribution", "url": "http://arxiv.org/pdf/2206.08933v2", "summary": "A central question in computational neuroscience is how structure determines\nfunction in neural networks. The emerging high-quality large-scale connectomic\ndatasets raise the question of what general functional principles can be\ngleaned from structural information such as the distribution of\nexcitatory/inhibitory synapse types and the distribution of synaptic weights.\nMotivated by this question, we developed a statistical mechanical theory of\nlearning in neural networks that incorporates structural information as\nconstraints. We derived an analytical solution for the memory capacity of the\nperceptron, a basic feedforward model of supervised learning, with constraint\non the distribution of its weights. Our theory predicts that the reduction in\ncapacity due to the constrained weight-distribution is related to the\nWasserstein distance between the imposed distribution and that of the standard\nnormal distribution. To test the theoretical predictions, we use optimal\ntransport theory and information geometry to develop an SGD-based algorithm to\nfind weights that simultaneously learn the input-output task and satisfy the\ndistribution constraint. We show that training in our algorithm can be\ninterpreted as geodesic flows in the Wasserstein space of probability\ndistributions. We further developed a statistical mechanical theory for\nteacher-student perceptron rule learning and ask for the best way for the\nstudent to incorporate prior knowledge of the rule. Our theory shows that it is\nbeneficial for the learner to adopt different prior weight distributions during\nlearning, and shows that distribution-constrained learning outperforms\nunconstrained and sign-constrained learning. Our theory and algorithm provide\nnovel strategies for incorporating prior knowledge about weights into learning,\nand reveal a powerful connection between structure and function in neural\nnetworks.", "published": "2022-06-14T00:43:34Z", "version": 2}, {"aid": "2206.07741", "authors": ["Clemens JS Schaefer", "Siddharth Joshi", "Shan Li", "Raul Blazquez"], "title": "Edge Inference with Fully Differentiable Quantized Mixed Precision Neural Networks", "url": "http://arxiv.org/pdf/2206.07741v2", "summary": "The large computing and memory cost of deep neural networks (DNNs) often\nprecludes their use in resource-constrained devices. Quantizing the parameters\nand operations to lower bit-precision offers substantial memory and energy\nsavings for neural network inference, facilitating the use of DNNs on edge\ncomputing platforms. Recent efforts at quantizing DNNs have employed a range of\ntechniques encompassing progressive quantization, step-size adaptation, and\ngradient scaling. This paper proposes a new quantization approach for mixed\nprecision convolutional neural networks (CNNs) targeting edge-computing. Our\nmethod establishes a new pareto frontier in model accuracy and memory footprint\ndemonstrating a range of quantized models, delivering best-in-class accuracy\nbelow 4.3 MB of weights (wgts.) and activations (acts.). Our main contributions\nare: (i) hardware-aware heterogeneous differentiable quantization with\ntensor-sliced learned precision, (ii) targeted gradient modification for wgts.\nand acts. to mitigate quantization errors, and (iii) a multi-phase learning\nschedule to address instability in learning arising from updates to the learned\nquantizer and model parameters. We demonstrate the effectiveness of our\ntechniques on the ImageNet dataset across a range of models including\nEfficientNet-Lite0 (e.g., 4.14MB of wgts. and acts. at 67.66% accuracy) and\nMobileNetV2 (e.g., 3.51MB wgts. and acts. at 65.39% accuracy).", "published": "2022-06-15T18:11:37Z", "version": 2}, {"aid": "2206.07751", "authors": ["Yujia Zheng", "Ignavier Ng", "Kun Zhang"], "title": "On the Identifiability of Nonlinear ICA: Sparsity and Beyond", "url": "http://arxiv.org/pdf/2206.07751v5", "summary": "Nonlinear independent component analysis (ICA) aims to recover the underlying\nindependent latent sources from their observable nonlinear mixtures. How to\nmake the nonlinear ICA model identifiable up to certain trivial indeterminacies\nis a long-standing problem in unsupervised learning. Recent breakthroughs\nreformulate the standard independence assumption of sources as conditional\nindependence given some auxiliary variables (e.g., class labels and/or\ndomain/time indexes) as weak supervision or inductive bias. However, nonlinear\nICA with unconditional priors cannot benefit from such developments. We explore\nan alternative path and consider only assumptions on the mixing process, such\nas Structural Sparsity. We show that under specific instantiations of such\nconstraints, the independent latent sources can be identified from their\nnonlinear mixtures up to a permutation and a component-wise transformation,\nthus achieving nontrivial identifiability of nonlinear ICA without auxiliary\nvariables. We provide estimation methods and validate the theoretical results\nexperimentally. The results on image data suggest that our conditions may hold\nin a number of practical data generating processes.", "published": "2022-06-15T18:24:22Z", "version": 5}, {"aid": "2206.07758", "authors": ["Niv Haim", "Gal Vardi", "Gilad Yehudai", "Ohad Shamir", "Michal Irani"], "title": "Reconstructing Training Data from Trained Neural Networks", "url": "http://arxiv.org/pdf/2206.07758v3", "summary": "Understanding to what extent neural networks memorize training data is an\nintriguing question with practical and theoretical implications. In this paper\nwe show that in some cases a significant fraction of the training data can in\nfact be reconstructed from the parameters of a trained neural network\nclassifier. We propose a novel reconstruction scheme that stems from recent\ntheoretical results about the implicit bias in training neural networks with\ngradient-based methods. To the best of our knowledge, our results are the first\nto show that reconstructing a large portion of the actual training samples from\na trained neural network classifier is generally possible. This has negative\nimplications on privacy, as it can be used as an attack for revealing sensitive\ntraining data. We demonstrate our method for binary MLP classifiers on a few\nstandard computer vision datasets.", "published": "2022-06-15T18:35:16Z", "version": 3}, {"aid": "2206.08094", "authors": ["Sabera Talukder", "Jennifer J. Sun", "Matthew Leonard", "Bingni W. Brunton", "Yisong Yue"], "title": "Deep Neural Imputation: A Framework for Recovering Incomplete Brain Recordings", "url": "http://arxiv.org/pdf/2206.08094v1", "summary": "Neuroscientists and neuroengineers have long relied on multielectrode neural\nrecordings to study the brain. However, in a typical experiment, many factors\ncorrupt neural recordings from individual electrodes, including electrical\nnoise, movement artifacts, and faulty manufacturing. Currently, common practice\nis to discard these corrupted recordings, reducing already limited data that is\ndifficult to collect. To address this challenge, we propose Deep Neural\nImputation (DNI), a framework to recover missing values from electrodes by\nlearning from data collected across spatial locations, days, and participants.\nWe explore our framework with a linear nearest-neighbor approach and two deep\ngenerative autoencoders, demonstrating DNI's flexibility. One deep autoencoder\nmodels participants individually, while the other extends this architecture to\nmodel many participants jointly. We evaluate our models across 12 human\nparticipants implanted with multielectrode intracranial electrocorticography\narrays; participants had no explicit task and behaved naturally across hundreds\nof recording hours. We show that DNI recovers not only time series but also\nfrequency content, and further establish DNI's practical value by recovering\nsignificant performance on a scientifically-relevant downstream neural decoding\ntask.", "published": "2022-06-16T11:20:11Z", "version": 1}, {"aid": "2206.08107", "authors": ["I\u00f1igo Martinez", "Elisabeth Viles", "Igor G. Olaizola"], "title": "Closed-Form Diffeomorphic Transformations for Time Series Alignment", "url": "http://arxiv.org/pdf/2206.08107v1", "summary": "Time series alignment methods call for highly expressive, differentiable and\ninvertible warping functions which preserve temporal topology, i.e\ndiffeomorphisms. Diffeomorphic warping functions can be generated from the\nintegration of velocity fields governed by an ordinary differential equation\n(ODE). Gradient-based optimization frameworks containing diffeomorphic\ntransformations require to calculate derivatives to the differential equation's\nsolution with respect to the model parameters, i.e. sensitivity analysis.\nUnfortunately, deep learning frameworks typically lack\nautomatic-differentiation-compatible sensitivity analysis methods; and implicit\nfunctions, such as the solution of ODE, require particular care. Current\nsolutions appeal to adjoint sensitivity methods, ad-hoc numerical solvers or\nResNet's Eulerian discretization. In this work, we present a closed-form\nexpression for the ODE solution and its gradient under continuous\npiecewise-affine (CPA) velocity functions. We present a highly optimized\nimplementation of the results on CPU and GPU. Furthermore, we conduct extensive\nexperiments on several datasets to validate the generalization ability of our\nmodel to unseen data for time-series joint alignment. Results show significant\nimprovements both in terms of efficiency and accuracy.", "published": "2022-06-16T12:02:12Z", "version": 1}, {"aid": "2206.11233", "authors": ["Parisa Moridian", "Navid Ghassemi", "Mahboobeh Jafari", "Salam Salloum-Asfar", "Delaram Sadeghi", "Marjane Khodatars", "Afshin Shoeibi", "Abbas Khosravi", "Sai Ho Ling", "Abdulhamit Subasi", "Roohallah Alizadehsani", "Juan M. Gorriz", "Sara A Abdulla", "U. Rajendra Acharya"], "title": "Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: A review", "url": "http://arxiv.org/pdf/2206.11233v3", "summary": "Autism spectrum disorder (ASD) is a brain condition characterized by diverse\nsigns and symptoms that appear in early childhood. ASD is also associated with\ncommunication deficits and repetitive behavior in affected individuals. Various\nASD detection methods have been developed, including neuroimaging modalities\nand psychological tests. Among these methods, magnetic resonance imaging (MRI)\nimaging modalities are of paramount importance to physicians. Clinicians rely\non MRI modalities to diagnose ASD accurately. The MRI modalities are\nnon-invasive methods that include functional (fMRI) and structural (sMRI)\nneuroimaging methods. However, diagnosing ASD with fMRI and sMRI for\nspecialists is often laborious and time-consuming; therefore, several\ncomputer-aided design systems (CADS) based on artificial intelligence (AI) have\nbeen developed to assist specialist physicians. Conventional machine learning\n(ML) and deep learning (DL) are the most popular schemes of AI used for\ndiagnosing ASD. This study aims to review the automated detection of ASD using\nAI. We review several CADS that have been developed using ML techniques for the\nautomated diagnosis of ASD using MRI modalities. There has been very limited\nwork on the use of DL techniques to develop automated diagnostic models for\nASD. A summary of the studies developed using DL is provided in the\nSupplementary Appendix. Then, the challenges encountered during the automated\ndiagnosis of ASD using MRI and AI techniques are described in detail.\nAdditionally, a graphical comparison of studies using ML and DL to diagnose ASD\nautomatically is discussed. We suggest future approaches to detecting ASDs\nusing AI techniques and MRI neuroimaging.", "published": "2022-06-20T16:14:21Z", "version": 3}, {"aid": "2206.13397", "authors": ["Severi Rissanen", "Markus Heinonen", "Arno Solin"], "title": "Generative Modelling With Inverse Heat Dissipation", "url": "http://arxiv.org/pdf/2206.13397v7", "summary": "While diffusion models have shown great success in image generation, their\nnoise-inverting generative process does not explicitly consider the structure\nof images, such as their inherent multi-scale nature. Inspired by diffusion\nmodels and the empirical success of coarse-to-fine modelling, we propose a new\ndiffusion-like model that generates images through stochastically reversing the\nheat equation, a PDE that locally erases fine-scale information when run over\nthe 2D plane of the image. We interpret the solution of the forward heat\nequation with constant additive noise as a variational approximation in the\ndiffusion latent variable model. Our new model shows emergent qualitative\nproperties not seen in standard diffusion models, such as disentanglement of\noverall colour and shape in images. Spectral analysis on natural images\nhighlights connections to diffusion models and reveals an implicit\ncoarse-to-fine inductive bias in them.", "published": "2022-06-21T13:40:38Z", "version": 7}, {"aid": "2206.12361", "authors": ["Xi Wang", "Laurence Aitchison"], "title": "Robustness to corruption in pre-trained Bayesian neural networks", "url": "http://arxiv.org/pdf/2206.12361v3", "summary": "We develop ShiftMatch, a new training-data-dependent likelihood for\nrobustness to corruption in Bayesian neural networks (BNNs). ShiftMatch is\ninspired by the training-data-dependent \"EmpCov\" priors from Izmailov et al.\n(2021a), and efficiently matches test-time spatial correlations to those at\ntraining time. Critically, ShiftMatch is designed to leave the neural network's\ntraining time likelihood unchanged, allowing it to use publicly available\nsamples from pre-trained BNNs. Using pre-trained HMC samples, ShiftMatch gives\nstrong performance improvements on CIFAR-10-C, outperforms EmpCov priors\n(though ShiftMatch uses extra information from a minibatch of corrupted test\npoints), and is perhaps the first Bayesian method capable of convincingly\noutperforming plain deep ensembles.", "published": "2022-06-24T16:08:46Z", "version": 3}, {"aid": "2206.14483", "authors": ["C\u00e9dric Rommel", "Joseph Paillard", "Thomas Moreau", "Alexandre Gramfort"], "title": "Data augmentation for learning predictive models on EEG: a systematic comparison", "url": "http://arxiv.org/pdf/2206.14483v2", "summary": "Objective: The use of deep learning for electroencephalography (EEG)\nclassification tasks has been rapidly growing in the last years, yet its\napplication has been limited by the relatively small size of EEG datasets. Data\naugmentation, which consists in artificially increasing the size of the dataset\nduring training, can be employed to alleviate this problem. While a few\naugmentation transformations for EEG data have been proposed in the literature,\ntheir positive impact on performance is often evaluated on a single dataset and\ncompared to one or two competing augmentation methods. This work proposes to\nbetter validate the existing data augmentation approaches through a unified and\nexhaustive analysis. Approach: We compare quantitatively 13 different\naugmentations with two different predictive tasks, datasets and models, using\nthree different types of experiments. Main results: We demonstrate that\nemploying the adequate data augmentations can bring up to 45% accuracy\nimprovements in low data regimes compared to the same model trained without any\naugmentation. Our experiments also show that there is no single best\naugmentation strategy, as the good augmentations differ on each task.\nSignificance: Our results highlight the best data augmentations to consider for\nsleep stage classification and motor imagery brain-computer interfaces. More\nbroadly, it demonstrates that EEG classification tasks benefit from adequate\ndata augmentation", "published": "2022-06-29T09:18:15Z", "version": 2}, {"aid": "2207.02625", "authors": ["Zhennan Wang", "Kehan Li", "Runyi Yu", "Yian Zhao", "Pengchong Qiao", "Chang Liu", "Fan Xu", "Xiangyang Ji", "Guoli Song", "Jie Chen"], "title": "$L_2$BN: Enhancing Batch Normalization by Equalizing the $L_2$ Norms of Features", "url": "http://arxiv.org/pdf/2207.02625v6", "summary": "In this paper, we analyze batch normalization from the perspective of\ndiscriminability and find the disadvantages ignored by previous studies: the\ndifference in $l_2$ norms of sample features can hinder batch normalization\nfrom obtaining more distinguished inter-class features and more compact\nintra-class features. To address this issue, we propose a simple yet effective\nmethod to equalize the $l_2$ norms of sample features. Concretely, we\n$l_2$-normalize each sample feature before feeding them into batch\nnormalization, and therefore the features are of the same magnitude. Since the\nproposed method combines the $l_2$ normalization and batch normalization, we\nname our method $L_2$BN. The $L_2$BN can strengthen the compactness of\nintra-class features and enlarge the discrepancy of inter-class features. The\n$L_2$BN is easy to implement and can exert its effect without any additional\nparameters or hyper-parameters. We evaluate the effectiveness of $L_2$BN\nthrough extensive experiments with various models on image classification and\nacoustic scene classification tasks. The results demonstrate that the $L_2$BN\ncan boost the generalization ability of various neural network models and\nachieve considerable performance improvements.", "published": "2022-07-06T12:34:33Z", "version": 6}, {"aid": "2207.03620", "authors": ["Shiwei Liu", "Tianlong Chen", "Xiaohan Chen", "Xuxi Chen", "Qiao Xiao", "Boqian Wu", "Tommi K\u00e4rkk\u00e4inen", "Mykola Pechenizkiy", "Decebal Mocanu", "Zhangyang Wang"], "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity", "url": "http://arxiv.org/pdf/2207.03620v3", "summary": "Transformers have quickly shined in the computer vision world since the\nemergence of Vision Transformers (ViTs). The dominant role of convolutional\nneural networks (CNNs) seems to be challenged by increasingly effective\ntransformer-based models. Very recently, a couple of advanced convolutional\nmodels strike back with large kernels motivated by the local-window attention\nmechanism, showing appealing performance and efficiency. While one of them,\ni.e. RepLKNet, impressively manages to scale the kernel size to 31x31 with\nimproved performance, the performance starts to saturate as the kernel size\ncontinues growing, compared to the scaling trend of advanced ViTs such as Swin\nTransformer. In this paper, we explore the possibility of training extreme\nconvolutions larger than 31x31 and test whether the performance gap can be\neliminated by strategically enlarging convolutions. This study ends up with a\nrecipe for applying extremely large kernels from the perspective of sparsity,\nwhich can smoothly scale up kernels to 61x61 with better performance. Built on\nthis recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN\narchitecture equipped with sparse factorized 51x51 kernels that can perform on\npar with or better than state-of-the-art hierarchical Transformers and modern\nConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as\nwell as a wide range of downstream tasks including semantic segmentation on\nADE20K, object detection on PASCAL VOC 2007, and object detection/segmentation\non MS COCO.", "published": "2022-07-07T23:55:52Z", "version": 3}, {"aid": "2207.06066", "authors": ["Suneghyeon Cho", "Sanghyun Hong", "Kookjin Lee", "Noseong Park"], "title": "AdamNODEs: When Neural ODE Meets Adaptive Moment Estimation", "url": "http://arxiv.org/pdf/2207.06066v1", "summary": "Recent work by Xia et al. leveraged the continuous-limit of the classical\nmomentum accelerated gradient descent and proposed heavy-ball neural ODEs.\nWhile this model offers computational efficiency and high utility over vanilla\nneural ODEs, this approach often causes the overshooting of internal dynamics,\nleading to unstable training of a model. Prior work addresses this issue by\nusing ad-hoc approaches, e.g., bounding the internal dynamics using specific\nactivation functions, but the resulting models do not satisfy the exact\nheavy-ball ODE. In this work, we propose adaptive momentum estimation neural\nODEs (AdamNODEs) that adaptively control the acceleration of the classical\nmomentum-based approach. We find that its adjoint states also satisfy AdamODE\nand do not require ad-hoc solutions that the prior work employs. In evaluation,\nwe show that AdamNODEs achieve the lowest training loss and efficacy over\nexisting neural ODEs. We also show that AdamNODEs have better training\nstability than classical momentum-based neural ODEs. This result sheds some\nlight on adapting the techniques proposed in the optimization community to\nimproving the training and inference of neural ODEs further. Our code is\navailable at https://github.com/pmcsh04/AdamNODE.", "published": "2022-07-13T09:20:38Z", "version": 1}, {"aid": "2207.06114", "authors": ["Mario Lezcano-Casado"], "title": "Automatic Differentiation: Theory and Practice", "url": "http://arxiv.org/pdf/2207.06114v1", "summary": "We present the classical coordinate-free formalism for forward and backward\nmode ad in the real and complex setting. We show how to formally derive the\nforward and backward formulae for a number of matrix functions starting from\nbasic principles.", "published": "2022-07-13T10:39:58Z", "version": 1}, {"aid": "2207.06635", "authors": ["Min Zhao", "Fan Bao", "Chongxuan Li", "Jun Zhu"], "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations", "url": "http://arxiv.org/pdf/2207.06635v5", "summary": "Score-based diffusion models (SBDMs) have achieved the SOTA FID results in\nunpaired image-to-image translation (I2I). However, we notice that existing\nmethods totally ignore the training data in the source domain, leading to\nsub-optimal solutions for unpaired I2I. To this end, we propose energy-guided\nstochastic differential equations (EGSDE) that employs an energy function\npretrained on both the source and target domains to guide the inference process\nof a pretrained SDE for realistic and faithful unpaired I2I. Building upon two\nfeature extractors, we carefully design the energy function such that it\nencourages the transferred image to preserve the domain-independent features\nand discard domain-specific ones. Further, we provide an alternative\nexplanation of the EGSDE as a product of experts, where each of the three\nexperts (corresponding to the SDE and two feature extractors) solely\ncontributes to faithfulness or realism. Empirically, we compare EGSDE to a\nlarge family of baselines on three widely-adopted unpaired I2I tasks under four\nmetrics. EGSDE not only consistently outperforms existing SBDMs-based methods\nin almost all settings but also achieves the SOTA realism results without\nharming the faithful performance. Furthermore, EGSDE allows for flexible\ntrade-offs between realism and faithfulness and we improve the realism results\nfurther (e.g., FID of 51.04 in Cat to Dog and FID of 50.43 in Wild to Dog on\nAFHQ) by tuning hyper-parameters. The code is available at\nhttps://github.com/ML-GSAI/EGSDE.", "published": "2022-07-14T03:08:33Z", "version": 5}, {"aid": "2207.07730", "authors": ["Jorge A. Mendez", "Eric Eaton"], "title": "How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition", "url": "http://arxiv.org/pdf/2207.07730v2", "summary": "A major goal of artificial intelligence (AI) is to create an agent capable of\nacquiring a general understanding of the world. Such an agent would require the\nability to continually accumulate and build upon its knowledge as it encounters\nnew experiences. Lifelong or continual learning addresses this setting, whereby\nan agent faces a continual stream of problems and must strive to capture the\nknowledge necessary for solving each new task it encounters. If the agent is\ncapable of accumulating knowledge in some form of compositional representation,\nit could then selectively reuse and combine relevant pieces of knowledge to\nconstruct novel solutions. Despite the intuitive appeal of this simple idea,\nthe literatures on lifelong learning and compositional learning have proceeded\nlargely separately. In an effort to promote developments that bridge between\nthe two fields, this article surveys their respective research landscapes and\ndiscusses existing and future connections between them.", "published": "2022-07-15T19:53:20Z", "version": 2}, {"aid": "2207.09455", "authors": ["Andrea Bragagnolo", "Enzo Tartaglione", "Marco Grangetto"], "title": "To update or not to update? Neurons at equilibrium in deep models", "url": "http://arxiv.org/pdf/2207.09455v3", "summary": "Recent advances in deep learning optimization showed that, with some\na-posteriori information on fully-trained models, it is possible to match the\nsame performance by simply training a subset of their parameters. Such a\ndiscovery has a broad impact from theory to applications, driving the research\ntowards methods to identify the minimum subset of parameters to train without\nlook-ahead information exploitation. However, the methods proposed do not match\nthe state-of-the-art performance, and rely on unstructured sparsely connected\nmodels. In this work we shift our focus from the single parameters to the\nbehavior of the whole neuron, exploiting the concept of neuronal equilibrium\n(NEq). When a neuron is in a configuration at equilibrium (meaning that it has\nlearned a specific input-output relationship), we can halt its update; on the\ncontrary, when a neuron is at non-equilibrium, we let its state evolve towards\nan equilibrium state, updating its parameters. The proposed approach has been\ntested on different state-of-the-art learning strategies and tasks, validating\nNEq and observing that the neuronal equilibrium depends on the specific\nlearning setup.", "published": "2022-07-19T08:07:53Z", "version": 3}, {"aid": "2207.09193", "authors": ["Ruiqi Zhang", "Jie Chen"], "title": "NDF: Neural Deformable Fields for Dynamic Human Modelling", "url": "http://arxiv.org/pdf/2207.09193v1", "summary": "We propose Neural Deformable Fields (NDF), a new representation for dynamic\nhuman digitization from a multi-view video. Recent works proposed to represent\na dynamic human body with shared canonical neural radiance fields which links\nto the observation space with deformation fields estimations. However, the\nlearned canonical representation is static and the current design of the\ndeformation fields is not able to represent large movements or detailed\ngeometry changes. In this paper, we propose to learn a neural deformable field\nwrapped around a fitted parametric body model to represent the dynamic human.\nThe NDF is spatially aligned by the underlying reference surface. A neural\nnetwork is then learned to map pose to the dynamics of NDF. The proposed NDF\nrepresentation can synthesize the digitized performer with novel views and\nnovel poses with a detailed and reasonable dynamic appearance. Experiments show\nthat our method significantly outperforms recent human synthesis methods.", "published": "2022-07-19T10:55:41Z", "version": 1}, {"aid": "2207.09238", "authors": ["Mary Phuong", "Marcus Hutter"], "title": "Formal Algorithms for Transformers", "url": "http://arxiv.org/pdf/2207.09238v1", "summary": "This document aims to be a self-contained, mathematically precise overview of\ntransformer architectures and algorithms (*not* results). It covers what\ntransformers are, how they are trained, what they are used for, their key\narchitectural components, and a preview of the most prominent models. The\nreader is assumed to be familiar with basic ML terminology and simpler neural\nnetwork architectures such as MLPs.", "published": "2022-07-19T12:49:02Z", "version": 1}, {"aid": "2207.09442", "authors": ["Luis Pineda", "Taosha Fan", "Maurizio Monge", "Shobha Venkataraman", "Paloma Sodhi", "Ricky T. Q. Chen", "Joseph Ortiz", "Daniel DeTone", "Austin Wang", "Stuart Anderson", "Jing Dong", "Brandon Amos", "Mustafa Mukadam"], "title": "Theseus: A Library for Differentiable Nonlinear Optimization", "url": "http://arxiv.org/pdf/2207.09442v3", "summary": "We present Theseus, an efficient application-agnostic open source library for\ndifferentiable nonlinear least squares (DNLS) optimization built on PyTorch,\nproviding a common framework for end-to-end structured learning in robotics and\nvision. Existing DNLS implementations are application specific and do not\nalways incorporate many ingredients important for efficiency. Theseus is\napplication-agnostic, as we illustrate with several example applications that\nare built using the same underlying differentiable components, such as\nsecond-order optimizers, standard costs functions, and Lie groups. For\nefficiency, Theseus incorporates support for sparse solvers, automatic\nvectorization, batching, GPU acceleration, and gradient computation with\nimplicit differentiation and direct loss minimization. We do extensive\nperformance evaluation in a set of applications, demonstrating significant\nefficiency gains and better scalability when these features are incorporated.\nProject page: https://sites.google.com/view/theseus-ai", "published": "2022-07-19T17:57:40Z", "version": 3}, {"aid": "2207.09542", "authors": ["Shiyu Wang", "Yuanqi Du", "Xiaojie Guo", "Bo Pan", "Zhaohui Qin", "Liang Zhao"], "title": "Controllable Data Generation by Deep Learning: A Review", "url": "http://arxiv.org/pdf/2207.09542v6", "summary": "Designing and generating new data under targeted properties has been\nattracting various critical applications such as molecule design, image editing\nand speech synthesis. Traditional hand-crafted approaches heavily rely on\nexpertise experience and intensive human efforts, yet still suffer from the\ninsufficiency of scientific knowledge and low throughput to support effective\nand efficient data generation. Recently, the advancement of deep learning has\ncreated the opportunity for expressive methods to learn the underlying\nrepresentation and properties of data. Such capability provides new ways of\ndetermining the mutual relationship between the structural patterns and\nfunctional properties of the data and leveraging such relationships to generate\nstructural data, given the desired properties. This article is a systematic\nreview that explains this promising research area, commonly known as\ncontrollable deep data generation. First, the article raises the potential\nchallenges and provides preliminaries. Then the article formally defines\ncontrollable deep data generation, proposes a taxonomy on various techniques\nand summarizes the evaluation metrics in this specific domain. After that, the\narticle introduces exciting applications of controllable deep data generation,\nexperimentally analyzes and compares existing works. Finally, this article\nhighlights the promising future directions of controllable deep data generation\nand identifies five potential challenges.", "published": "2022-07-19T20:44:42Z", "version": 6}, {"aid": "2207.09610", "authors": ["Dongliang Cao", "Florian Bernard"], "title": "Unsupervised Deep Multi-Shape Matching", "url": "http://arxiv.org/pdf/2207.09610v1", "summary": "3D shape matching is a long-standing problem in computer vision and computer\ngraphics. While deep neural networks were shown to lead to state-of-the-art\nresults in shape matching, existing learning-based approaches are limited in\nthe context of multi-shape matching: (i) either they focus on matching pairs of\nshapes only and thus suffer from cycle-inconsistent multi-matchings, or (ii)\nthey require an explicit template shape to address the matching of a collection\nof shapes. In this paper, we present a novel approach for deep multi-shape\nmatching that ensures cycle-consistent multi-matchings while not depending on\nan explicit template shape. To this end, we utilise a shape-to-universe\nmulti-matching representation that we combine with powerful functional map\nregularisation, so that our multi-shape matching neural network can be trained\nin a fully unsupervised manner. While the functional map regularisation is only\nconsidered during training time, functional maps are not computed for\npredicting correspondences, thereby allowing for fast inference. We demonstrate\nthat our method achieves state-of-the-art results on several challenging\nbenchmark datasets, and, most remarkably, that our unsupervised method even\noutperforms recent supervised methods.", "published": "2022-07-20T01:22:08Z", "version": 1}, {"aid": "2207.09734", "authors": ["Chris Fields", "Karl Friston", "James F. Glazebrook", "Michael Levin", "Antonino Marcian\u00f2"], "title": "The Free Energy Principle drives neuromorphic development", "url": "http://arxiv.org/pdf/2207.09734v1", "summary": "We show how any system with morphological degrees of freedom and locally\nlimited free energy will, under the constraints of the free energy principle,\nevolve toward a neuromorphic morphology that supports hierarchical computations\nin which each level of the hierarchy enacts a coarse-graining of its inputs,\nand dually a fine-graining of its outputs. Such hierarchies occur throughout\nbiology, from the architectures of intracellular signal transduction pathways\nto the large-scale organization of perception and action cycles in the\nmammalian brain. Formally, the close formal connections between cone-cocone\ndiagrams (CCCD) as models of quantum reference frames on the one hand, and\nbetween CCCDs and topological quantum field theories on the other, allow the\nrepresentation of such computations in the fully-general quantum-computational\nframework of topological quantum neural networks.", "published": "2022-07-20T08:22:03Z", "version": 1}, {"aid": "2207.09897", "authors": ["Beren Millidge", "Christopher L Buckley"], "title": "Successor Representation Active Inference", "url": "http://arxiv.org/pdf/2207.09897v1", "summary": "Recent work has uncovered close links between between classical reinforcement\nlearning algorithms, Bayesian filtering, and Active Inference which lets us\nunderstand value functions in terms of Bayesian posteriors. An alternative, but\nless explored, model-free RL algorithm is the successor representation, which\nexpresses the value function in terms of a successor matrix of expected future\nstate occupancies. In this paper, we derive the probabilistic interpretation of\nthe successor representation in terms of Bayesian filtering and thus design a\nnovel active inference agent architecture utilizing successor representations\ninstead of model-based planning. We demonstrate that active inference successor\nrepresentations have significant advantages over current active inference\nagents in terms of planning horizon and computational cost. Moreover, we\ndemonstrate how the successor representation agent can generalize to changing\nreward functions such as variants of the expected free energy.", "published": "2022-07-20T13:50:27Z", "version": 1}, {"aid": "2207.09944", "authors": ["Cian Eastwood", "Alexander Robey", "Shashank Singh", "Julius von K\u00fcgelgen", "Hamed Hassani", "George J. Pappas", "Bernhard Sch\u00f6lkopf"], "title": "Probable Domain Generalization via Quantile Risk Minimization", "url": "http://arxiv.org/pdf/2207.09944v4", "summary": "Domain generalization (DG) seeks predictors which perform well on unseen test\ndistributions by leveraging data drawn from multiple related training\ndistributions or domains. To achieve this, DG is commonly formulated as an\naverage- or worst-case problem over the set of possible domains. However,\npredictors that perform well on average lack robustness while predictors that\nperform well in the worst case tend to be overly-conservative. To address this,\nwe propose a new probabilistic framework for DG where the goal is to learn\npredictors that perform well with high probability. Our key idea is that\ndistribution shifts seen during training should inform us of probable shifts at\ntest time, which we realize by explicitly relating training and test domains as\ndraws from the same underlying meta-distribution. To achieve probable DG, we\npropose a new optimization problem called Quantile Risk Minimization (QRM). By\nminimizing the $\\alpha$-quantile of predictor's risk distribution over domains,\nQRM seeks predictors that perform well with probability $\\alpha$. To solve QRM\nin practice, we propose the Empirical QRM (EQRM) algorithm and provide: (i) a\ngeneralization bound for EQRM; and (ii) the conditions under which EQRM\nrecovers the causal predictor as $\\alpha \\to 1$. In our experiments, we\nintroduce a more holistic quantile-focused evaluation protocol for DG and\ndemonstrate that EQRM outperforms state-of-the-art baselines on datasets from\nWILDS and DomainBed.", "published": "2022-07-20T14:41:09Z", "version": 4}, {"aid": "2207.10271", "authors": ["Yan Hong", "Li Niu", "Jianfu Zhang", "Liqing Zhang"], "title": "DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific Delta", "url": "http://arxiv.org/pdf/2207.10271v3", "summary": "Learning to generate new images for a novel category based on only a few\nimages, named as few-shot image generation, has attracted increasing research\ninterest. Several state-of-the-art works have yielded impressive results, but\nthe diversity is still limited. In this work, we propose a novel Delta\nGenerative Adversarial Network (DeltaGAN), which consists of a reconstruction\nsubnetwork and a generation subnetwork. The reconstruction subnetwork captures\nintra-category transformation, i.e., delta, between same-category pairs. The\ngeneration subnetwork generates sample-specific delta for an input image, which\nis combined with this input image to generate a new image within the same\ncategory. Besides, an adversarial delta matching loss is designed to link the\nabove two subnetworks together. Extensive experiments on six benchmark datasets\ndemonstrate the effectiveness of our proposed method. Our code is available at\nhttps://github.com/bcmi/DeltaGAN-Few-Shot-Image-Generation.", "published": "2022-07-21T02:44:30Z", "version": 3}, {"aid": "2207.12941", "authors": ["Fengjun Li", "Xin Feng", "Fanglin Chen", "Guangming Lu", "Wenjie Pei"], "title": "Learning Generalizable Latent Representations for Novel Degradations in Super Resolution", "url": "http://arxiv.org/pdf/2207.12941v1", "summary": "Typical methods for blind image super-resolution (SR) focus on dealing with\nunknown degradations by directly estimating them or learning the degradation\nrepresentations in a latent space. A potential limitation of these methods is\nthat they assume the unknown degradations can be simulated by the integration\nof various handcrafted degradations (e.g., bicubic downsampling), which is not\nnecessarily true. The real-world degradations can be beyond the simulation\nscope by the handcrafted degradations, which are referred to as novel\ndegradations. In this work, we propose to learn a latent representation space\nfor degradations, which can be generalized from handcrafted (base) degradations\nto novel degradations. The obtained representations for a novel degradation in\nthis latent space are then leveraged to generate degraded images consistent\nwith the novel degradation to compose paired training data for SR model.\nFurthermore, we perform variational inference to match the posterior of\ndegradations in latent representation space with a prior distribution (e.g.,\nGaussian distribution). Consequently, we are able to sample more high-quality\nrepresentations for a novel degradation to augment the training data for SR\nmodel. We conduct extensive experiments on both synthetic and real-world\ndatasets to validate the effectiveness and advantages of our method for blind\nsuper-resolution with novel degradations.", "published": "2022-07-25T16:22:30Z", "version": 1}, {"aid": "2207.12599", "authors": ["Yiqiao Li", "Jianlong Zhou", "Sunny Verma", "Fang Chen"], "title": "A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics", "url": "http://arxiv.org/pdf/2207.12599v2", "summary": "Graph neural networks (GNNs) have demonstrated a significant boost in\nprediction performance on graph data. At the same time, the predictions made by\nthese models are often hard to interpret. In that regard, many efforts have\nbeen made to explain the prediction mechanisms of these models from\nperspectives such as GNNExplainer, XGNN and PGExplainer. Although such works\npresent systematic frameworks to interpret GNNs, a holistic review for\nexplainable GNNs is unavailable. In this survey, we present a comprehensive\nreview of explainability techniques developed for GNNs. We focus on explainable\ngraph neural networks and categorize them based on the use of explainable\nmethods. We further provide the common performance metrics for GNNs\nexplanations and point out several future research directions.", "published": "2022-07-26T01:45:54Z", "version": 2}, {"aid": "2207.13050", "authors": ["Arian Bakhtiarnia", "Qi Zhang", "Alexandros Iosifidis"], "title": "Efficient High-Resolution Deep Learning: A Survey", "url": "http://arxiv.org/pdf/2207.13050v2", "summary": "Cameras in modern devices such as smartphones, satellites and medical\nequipment are capable of capturing very high resolution images and videos. Such\nhigh-resolution data often need to be processed by deep learning models for\ncancer detection, automated road navigation, weather prediction, surveillance,\noptimizing agricultural processes and many other applications. Using\nhigh-resolution images and videos as direct inputs for deep learning models\ncreates many challenges due to their high number of parameters, computation\ncost, inference latency and GPU memory consumption. Simple approaches such as\nresizing the images to a lower resolution are common in the literature,\nhowever, they typically significantly decrease accuracy. Several works in the\nliterature propose better alternatives in order to deal with the challenges of\nhigh-resolution data and improve accuracy and speed while complying with\nhardware limitations and time restrictions. This survey describes such\nefficient high-resolution deep learning methods, summarizes real-world\napplications of high-resolution deep learning, and provides comprehensive\ninformation about available high-resolution datasets.", "published": "2022-07-26T17:13:53Z", "version": 2}, {"aid": "2207.13190", "authors": ["Julia Berezutskaya", "Anne-Lise Saive", "Karim Jerbi", "Marcel van Gerven"], "title": "How does artificial intelligence contribute to iEEG research?", "url": "http://arxiv.org/pdf/2207.13190v1", "summary": "Artificial intelligence (AI) is a fast-growing field focused on modeling and\nmachine implementation of various cognitive functions with an increasing number\nof applications in computer vision, text processing, robotics, neurotechnology,\nbio-inspired computing and others. In this chapter, we describe how AI methods\ncan be applied in the context of intracranial electroencephalography (iEEG)\nresearch. IEEG data is unique as it provides extremely high-quality signals\nrecorded directly from brain tissue. Applying advanced AI models to these data\ncarries the potential to further our understanding of many fundamental\nquestions in neuroscience. At the same time, as an invasive technique, iEEG\nlends itself well to long-term, mobile brain-computer interface applications,\nparticularly for communication in severely paralyzed individuals. We provide a\ndetailed overview of these two research directions in the application of AI\ntechniques to iEEG. That is, (1) the development of computational models that\ntarget fundamental questions about the neurobiological nature of cognition\n(AI-iEEG for neuroscience) and (2) applied research on monitoring and\nidentification of event-driven brain states for the development of clinical\nbrain-computer interface systems (AI-iEEG for neurotechnology). We explain key\nmachine learning concepts, specifics of processing and modeling iEEG data and\ndetails of state-of-the-art iEEG-based neurotechnology and brain-computer\ninterfaces.", "published": "2022-07-26T21:38:01Z", "version": 1}, {"aid": "2207.13243", "authors": ["Tilman R\u00e4uker", "Anson Ho", "Stephen Casper", "Dylan Hadfield-Menell"], "title": "Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks", "url": "http://arxiv.org/pdf/2207.13243v6", "summary": "The last decade of machine learning has seen drastic increases in scale and\ncapabilities. Deep neural networks (DNNs) are increasingly being deployed in\nthe real world. However, they are difficult to analyze, raising concerns about\nusing them without a rigorous understanding of how they function. Effective\ntools for interpreting them will be important for building more trustworthy AI\nby helping to identify problems, fix bugs, and improve basic understanding. In\nparticular, \"inner\" interpretability techniques, which focus on explaining the\ninternal components of DNNs, are well-suited for developing a mechanistic\nunderstanding, guiding manual modifications, and reverse engineering solutions.\n  Much recent work has focused on DNN interpretability, and rapid progress has\nthus far made a thorough systematization of methods difficult. In this survey,\nwe review over 300 works with a focus on inner interpretability tools. We\nintroduce a taxonomy that classifies methods by what part of the network they\nhelp to explain (weights, neurons, subnetworks, or latent representations) and\nwhether they are implemented during (intrinsic) or after (post hoc) training.\nTo our knowledge, we are also the first to survey a number of connections\nbetween interpretability research and work in adversarial robustness, continual\nlearning, modularity, network compression, and studying the human visual\nsystem. We discuss key challenges and argue that the status quo in\ninterpretability research is largely unproductive. Finally, we highlight the\nimportance of future work that emphasizes diagnostics, debugging, adversaries,\nand benchmarking in order to make interpretability tools more useful to\nengineers in practical applications.", "published": "2022-07-27T01:59:13Z", "version": 6}, {"aid": "2207.14491", "authors": ["Chaerin Kong", "Nojun Kwak"], "title": "Conservative Generator, Progressive Discriminator: Coordination of Adversaries in Few-shot Incremental Image Synthesis", "url": "http://arxiv.org/pdf/2207.14491v2", "summary": "The capacity to learn incrementally from an online stream of data is an\nenvied trait of human learners, as deep neural networks typically suffer from\ncatastrophic forgetting and stability-plasticity dilemma. Several works have\npreviously explored incremental few-shot learning, a task with greater\nchallenges due to data constraint, mostly in classification setting with mild\nsuccess. In this work, we study the underrepresented task of generative\nincremental few-shot learning. To effectively handle the inherent challenges of\nincremental learning and few-shot learning, we propose a novel framework named\nConPro that leverages the two-player nature of GANs. Specifically, we design a\nconservative generator that preserves past knowledge in parameter and compute\nefficient manner, and a progressive discriminator that learns to reason\nsemantic distances between past and present task samples, minimizing\noverfitting with few data points and pursuing good forward transfer. We present\nexperiments to validate the effectiveness of ConPro.", "published": "2022-07-29T06:00:29Z", "version": 2}, {"aid": "2207.14545", "authors": ["Yanchen Li", "Qingzhong Ai", "Fumihiko Ino"], "title": "A One-Shot Reparameterization Method for Reducing the Loss of Tile Pruning on DNNs", "url": "http://arxiv.org/pdf/2207.14545v1", "summary": "Recently, tile pruning has been widely studied to accelerate the inference of\ndeep neural networks (DNNs). However, we found that the loss due to tile\npruning, which can eliminate important elements together with unimportant\nelements, is large on trained DNNs. In this study, we propose a one-shot\nreparameterization method, called TileTrans, to reduce the loss of tile\npruning. Specifically, we repermute the rows or columns of the weight matrix\nsuch that the model architecture can be kept unchanged after\nreparameterization. This repermutation realizes the reparameterization of the\nDNN model without any retraining. The proposed reparameterization method\ncombines important elements into the same tile; thus, preserving the important\nelements after the tile pruning. Furthermore, TileTrans can be seamlessly\nintegrated into existing tile pruning methods because it is a pre-processing\nmethod executed before pruning, which is orthogonal to most existing methods.\nThe experimental results demonstrate that our method is essential in reducing\nthe loss of tile pruning on DNNs. Specifically, the accuracy is improved by up\nto 17% for AlexNet while 5% for ResNet-34, where both models are pre-trained on\nImageNet.", "published": "2022-07-29T08:27:15Z", "version": 1}, {"aid": "2208.00338", "authors": ["Sein Park", "Yeongsang Jang", "Eunhyeok Park"], "title": "Symmetry Regularization and Saturating Nonlinearity for Robust Quantization", "url": "http://arxiv.org/pdf/2208.00338v1", "summary": "Robust quantization improves the tolerance of networks for various\nimplementations, allowing reliable output in different bit-widths or fragmented\nlow-precision arithmetic. In this work, we perform extensive analyses to\nidentify the sources of quantization error and present three insights to\nrobustify a network against quantization: reduction of error propagation, range\nclamping for error minimization, and inherited robustness against quantization.\nBased on these insights, we propose two novel methods called symmetry\nregularization (SymReg) and saturating nonlinearity (SatNL). Applying the\nproposed methods during training can enhance the robustness of arbitrary neural\nnetworks against quantization on existing post-training quantization (PTQ) and\nquantization-aware training (QAT) algorithms and enables us to obtain a single\nweight flexible enough to maintain the output quality under various conditions.\nWe conduct extensive studies on CIFAR and ImageNet datasets and validate the\neffectiveness of the proposed methods.", "published": "2022-07-31T02:12:28Z", "version": 1}, {"aid": "2208.00508", "authors": ["Kinyua Gikunda"], "title": "Deep Active Learning with Budget Annotation", "url": "http://arxiv.org/pdf/2208.00508v1", "summary": "Digital data collected over the decades and data currently being produced\nwith use of information technology is vastly the unlabeled data or data without\ndescription. The unlabeled data is relatively easy to acquire but expensive to\nlabel even with use of domain experts. Most of the recent works focus on use of\nactive learning with uncertainty metrics measure to address this problem.\nAlthough most uncertainty selection strategies are very effective, they fail to\ntake informativeness of the unlabeled instances into account and are prone to\nquerying outliers. In order to address these challenges we propose an hybrid\napproach of computing both the uncertainty and informativeness of an instance,\nthen automaticaly label the computed instances using budget annotator. To\nreduce the annotation cost, we employ the state-of-the-art pre-trained models\nin order to avoid querying information already contained in those models. Our\nextensive experiments on different sets of datasets demonstrate the efficacy of\nthe proposed approach.", "published": "2022-07-31T20:20:44Z", "version": 1}, {"aid": "2208.00587", "authors": ["Dai Hai Nguyen", "Tetsuya Sakurai"], "title": "A Particle-Based Algorithm for Distributional Optimization on \\textit{Constrained Domains} via Variational Transport and Mirror Descent", "url": "http://arxiv.org/pdf/2208.00587v3", "summary": "We consider the optimization problem of minimizing an objective functional,\nwhich admits a variational form and is defined over probability distributions\non the constrained domain, which poses challenges to both theoretical analysis\nand algorithmic design. Inspired by the mirror descent algorithm for\nconstrained optimization, we propose an iterative particle-based algorithm,\nnamed Mirrored Variational Transport (mirrorVT), extended from the Variational\nTransport framework [7] for dealing with the constrained domain. In particular,\nfor each iteration, mirrorVT maps particles to an unconstrained dual domain\ninduced by a mirror map and then approximately perform Wasserstein gradient\ndescent on the manifold of distributions defined over the dual space by pushing\nparticles. At the end of iteration, particles are mapped back to the original\nconstrained domain. Through simulated experiments, we demonstrate the\neffectiveness of mirrorVT for minimizing the functionals over probability\ndistributions on the simplex- and Euclidean ball-constrained domains. We also\nanalyze its theoretical properties and characterize its convergence to the\nglobal minimum of the objective functional.", "published": "2022-08-01T03:25:01Z", "version": 3}, {"aid": "2208.01195", "authors": ["Wenxuan Ma", "Jinming Zhang", "Shuang Li", "Chi Harold Liu", "Yulin Wang", "Wei Li"], "title": "Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/2208.01195v1", "summary": "Extensive studies on Unsupervised Domain Adaptation (UDA) have propelled the\ndeployment of deep learning from limited experimental datasets into real-world\nunconstrained domains. Most UDA approaches align features within a common\nembedding space and apply a shared classifier for target prediction. However,\nsince a perfectly aligned feature space may not exist when the domain\ndiscrepancy is large, these methods suffer from two limitations. First, the\ncoercive domain alignment deteriorates target domain discriminability due to\nlacking target label supervision. Second, the source-supervised classifier is\ninevitably biased to source data, thus it may underperform in target domain. To\nalleviate these issues, we propose to simultaneously conduct feature alignment\nin two individual spaces focusing on different domains, and create for each\nspace a domain-oriented classifier tailored specifically for that domain.\nSpecifically, we design a Domain-Oriented Transformer (DOT) that has two\nindividual classification tokens to learn different domain-oriented\nrepresentations, and two classifiers to preserve domain-wise discriminability.\nTheoretical guaranteed contrastive-based alignment and the source-guided\npseudo-label refinement strategy are utilized to explore both domain-invariant\nand specific information. Comprehensive experiments validate that our method\nachieves state-of-the-art on several benchmarks.", "published": "2022-08-02T01:38:37Z", "version": 1}, {"aid": "2208.01204", "authors": ["Peter G. Stratton", "Andrew Wabnitz", "Chip Essam", "Allen Cheung", "Tara J. Hamilton"], "title": "Making a Spiking Net Work: Robust brain-like unsupervised machine learning", "url": "http://arxiv.org/pdf/2208.01204v2", "summary": "The surge in interest in Artificial Intelligence (AI) over the past decade\nhas been driven almost exclusively by advances in Artificial Neural Networks\n(ANNs). While ANNs set state-of-the-art performance for many previously\nintractable problems, the use of global gradient descent necessitates large\ndatasets and computational resources for training, potentially limiting their\nscalability for real-world domains. Spiking Neural Networks (SNNs) are an\nalternative to ANNs that use more brain-like artificial neurons and can use\nlocal unsupervised learning to rapidly discover sparse recognizable features in\nthe input data. SNNs, however, struggle with dynamical stability and have\nfailed to match the accuracy of ANNs. Here we show how an SNN can overcome many\nof the shortcomings that have been identified in the literature, including\noffering a principled solution to the dynamical \"vanishing spike problem\", to\noutperform all existing shallow SNNs and equal the performance of an ANN. It\naccomplishes this while using unsupervised learning with unlabeled data and\nonly 1/50th of the training epochs (labeled data is used only for a simple\nlinear readout layer). This result makes SNNs a viable new method for fast,\naccurate, efficient, explainable, and re-deployable machine learning with\nunlabeled data.", "published": "2022-08-02T02:10:00Z", "version": 2}, {"aid": "2208.01265", "authors": ["Soroush Sheikh Gargar"], "title": "Explicit Use of Fourier Spectrum in Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2208.01265v1", "summary": "Generative Adversarial Networks have got the researchers' attention due to\ntheir state-of-the-art performance in generating new images with only a dataset\nof the target distribution. It has been shown that there is a dissimilarity\nbetween the spectrum of authentic images and fake ones. Since the Fourier\ntransform is a bijective mapping, saying that the model has a significant\nproblem in learning the original distribution is a fair conclusion. In this\nwork, we investigate the possible reasons for the mentioned drawback in the\narchitecture and mathematical theory of the current GANs. Then we propose a new\nmodel to reduce the discrepancies between the spectrum of the actual and fake\nimages. To that end, we design a brand new architecture for the frequency\ndomain using the blueprint of geometric deep learning. Then, we experimentally\nshow promising improvements in the quality of the generated images by\nconsidering the Fourier domain representation of the original data as a\nprincipal feature in the training process.", "published": "2022-08-02T06:26:44Z", "version": 1}, {"aid": "2208.01358", "authors": ["Olivier Risser-Maroix", "Benjamin Chamand"], "title": "What can we Learn by Predicting Accuracy?", "url": "http://arxiv.org/pdf/2208.01358v2", "summary": "This paper seeks to answer the following question: \\textit{\"What can we learn\nby predicting accuracy?\"}.\n  Indeed, classification is one of the most popular tasks in machine learning,\nand many loss functions have been developed to maximize this non-differentiable\nobjective function.\n  Unlike past work on loss function design, which was guided mainly by\nintuition and theory before being validated by experimentation, here we propose\nto approach this problem in the opposite way: we seek to extract knowledge by\nexperimentation.\n  This data-driven approach is similar to that used in physics to discover\ngeneral laws from data.\n  We used a symbolic regression method to automatically find a mathematical\nexpression highly correlated with a linear classifier's accuracy.\n  The formula discovered on more than 260 datasets of embeddings has a\nPearson's correlation of 0.96 and a $r^2$ of 0.93.\n  More interestingly, this formula is highly explainable and confirms insights\nfrom various previous papers on loss design.\n  We hope this work will open new perspectives in the search for new heuristics\nleading to a deeper understanding of machine learning theory.", "published": "2022-08-02T10:58:17Z", "version": 2}, {"aid": "2208.01369", "authors": ["Christian S. Pilz", "Benjamin Clemens", "Inka C. Hiss", "Christoph Weiss", "Ulrich Canzler", "Jarek Krajewski", "Ute Habel", "Steffen Leonhardt"], "title": "The Face of Affective Disorders", "url": "http://arxiv.org/pdf/2208.01369v3", "summary": "We study the statistical properties of facial behaviour altered by the\nregulation of brain arousal in the clinical domain of psychiatry. The\nunderlying mechanism is linked to the empirical interpretation of the vigilance\ncontinuum as behavioral surrogate measurement for certain states of mind.\nReferring to the classical scalp-based obtrusive measurements, we name the\npresented method Opto-Electronic Encephalography (OEG) which solely relies on\nmodern camera-based real-time signal processing and computer vision. Based upon\na stochastic representation as coherence of the face dynamics, reflecting the\nhemifacial asymmetry in emotion expressions, we demonstrate an almost flawless\ndistinction between patients and healthy controls as well as between the mental\ndisorders depression and schizophrenia and the symptom severity. In contrast to\nthe standard diagnostic process, which is time-consuming, subjective and does\nnot incorporate neurobiological data such as real-time face dynamics, the\nobjective stochastic modeling of the affective responsiveness only requires a\nfew minutes of video-based facial recordings. We also highlight the potential\nof the methodology as a causal inference model in transdiagnostic analysis to\npredict the outcome of pharmacological treatment. All results are obtained on a\nclinical longitudinal data collection with an amount of 99 patients and 43\ncontrols.", "published": "2022-08-02T11:28:17Z", "version": 3}, {"aid": "2208.01424", "authors": ["Rui-Yang Ju", "Jen-Shiun Chiang", "Chih-Chia Chen", "Yu-Shian Lin"], "title": "Connection Reduction of DenseNet for Image Recognition", "url": "http://arxiv.org/pdf/2208.01424v3", "summary": "Convolutional Neural Networks (CNN) increase depth by stacking convolutional\nlayers, and deeper network models perform better in image recognition.\nEmpirical research shows that simply stacking convolutional layers does not\nmake the network train better, and skip connection (residual learning) can\nimprove network model performance. For the image classification task, models\nwith global densely connected architectures perform well in large datasets like\nImageNet, but are not suitable for small datasets such as CIFAR-10 and SVHN.\nDifferent from dense connections, we propose two new algorithms to connect\nlayers. Baseline is a densely connected network, and the networks connected by\nthe two new algorithms are named ShortNet1 and ShortNet2 respectively. The\nexperimental results of image classification on CIFAR-10 and SVHN show that\nShortNet1 has a 5% lower test error rate and 25% faster inference time than\nBaseline. ShortNet2 speeds up inference time by 40% with less loss in test\naccuracy. Code and pre-trained models are available at\nhttps://github.com/RuiyangJu/Connection_Reduction.", "published": "2022-08-02T13:00:35Z", "version": 3}, {"aid": "2208.01753", "authors": ["Edward Fish", "Jon Weinbren", "Andrew Gilbert"], "title": "Two-Stream Transformer Architecture for Long Video Understanding", "url": "http://arxiv.org/pdf/2208.01753v1", "summary": "Pure vision transformer architectures are highly effective for short video\nclassification and action recognition tasks. However, due to the quadratic\ncomplexity of self attention and lack of inductive bias, transformers are\nresource intensive and suffer from data inefficiencies. Long form video\nunderstanding tasks amplify data and memory efficiency problems in transformers\nmaking current approaches unfeasible to implement on data or memory restricted\ndomains. This paper introduces an efficient Spatio-Temporal Attention Network\n(STAN) which uses a two-stream transformer architecture to model dependencies\nbetween static image features and temporal contextual features. Our proposed\napproach can classify videos up to two minutes in length on a single GPU, is\ndata efficient, and achieves SOTA performance on several long video\nunderstanding tasks.", "published": "2022-08-02T21:03:48Z", "version": 1}, {"aid": "2208.01864", "authors": ["Dohoon Ryu", "Jong Chul Ye"], "title": "Pyramidal Denoising Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2208.01864v3", "summary": "Recently, diffusion model have demonstrated impressive image generation\nperformances, and have been extensively studied in various computer vision\ntasks. Unfortunately, training and evaluating diffusion models consume a lot of\ntime and computational resources. To address this problem, here we present a\nnovel pyramidal diffusion model that can generate high resolution images\nstarting from much coarser resolution images using a {\\em single} score\nfunction trained with a positional embedding. This enables a neural network to\nbe much lighter and also enables time-efficient image generation without\ncompromising its performances. Furthermore, we show that the proposed approach\ncan be also efficiently used for multi-scale super-resolution problem using a\nsingle score function.", "published": "2022-08-03T06:26:18Z", "version": 3}, {"aid": "2208.01903", "authors": ["Jo\u017ee M Ro\u017eanec", "Bojan Nemec"], "title": "Neural Dynamic Movement Primitives -- a survey", "url": "http://arxiv.org/pdf/2208.01903v1", "summary": "One of the most important challenges in robotics is producing accurate\ntrajectories and controlling their dynamic parameters so that the robots can\nperform different tasks. The ability to provide such motion control is closely\nrelated to how such movements are encoded. Advances on deep learning have had a\nstrong repercussion in the development of novel approaches for Dynamic Movement\nPrimitives. In this work, we survey scientific literature related to Neural\nDynamic Movement Primitives, to complement existing surveys on Dynamic Movement\nPrimitives.", "published": "2022-08-03T08:11:08Z", "version": 1}, {"aid": "2208.01996", "authors": ["Xin Zhang", "Ying-Cong Chen"], "title": "Adaptive Domain Generalization via Online Disagreement Minimization", "url": "http://arxiv.org/pdf/2208.01996v2", "summary": "Deep neural networks suffer from significant performance deterioration when\nthere exists distribution shift between deployment and training. Domain\nGeneralization (DG) aims to safely transfer a model to unseen target domains by\nonly relying on a set of source domains. Although various DG approaches have\nbeen proposed, a recent study named DomainBed, reveals that most of them do not\nbeat the simple Empirical Risk Minimization (ERM). To this end, we propose a\ngeneral framework that is orthogonal to existing DG algorithms and could\nimprove their performance consistently. Unlike previous DG works that stake on\na static source model to be hopefully a universal one, our proposed AdaODM\nadaptively modifies the source model at test time for different target domains.\nSpecifically, we create multiple domain-specific classifiers upon a shared\ndomain-generic feature extractor. The feature extractor and classifiers are\ntrained in an adversarial way, where the feature extractor embeds the input\nsamples into a domain-invariant space, and the multiple classifiers capture the\ndistinct decision boundaries that each of them relates to a specific source\ndomain. During testing, distribution differences between target and source\ndomains could be effectively measured by leveraging prediction disagreement\namong source classifiers. By fine-tuning source models to minimize the\ndisagreement at test time, target domain features are well aligned to the\ninvariant feature space. We verify AdaODM on two popular DG methods, namely ERM\nand CORAL, and four DG benchmarks, namely VLCS, PACS, OfficeHome, and\nTerraIncognita. The results show AdaODM stably improves the generalization\ncapacity on unseen domains and achieves state-of-the-art performance.", "published": "2022-08-03T11:51:11Z", "version": 2}, {"aid": "2208.02246", "authors": ["Qiyang Li", "Ajay Jain", "Pieter Abbeel"], "title": "AdaCat: Adaptive Categorical Discretization for Autoregressive Models", "url": "http://arxiv.org/pdf/2208.02246v1", "summary": "Autoregressive generative models can estimate complex continuous data\ndistributions, like trajectory rollouts in an RL environment, image\nintensities, and audio. Most state-of-the-art models discretize continuous data\ninto several bins and use categorical distributions over the bins to\napproximate the continuous data distribution. The advantage is that the\ncategorical distribution can easily express multiple modes and are\nstraightforward to optimize. However, such approximation cannot express sharp\nchanges in density without using significantly more bins, making it parameter\ninefficient. We propose an efficient, expressive, multimodal parameterization\ncalled Adaptive Categorical Discretization (AdaCat). AdaCat discretizes each\ndimension of an autoregressive model adaptively, which allows the model to\nallocate density to fine intervals of interest, improving parameter efficiency.\nAdaCat generalizes both categoricals and quantile-based regression. AdaCat is a\nsimple add-on to any discretization-based distribution estimator. In\nexperiments, AdaCat improves density estimation for real-world tabular data,\nimages, audio, and trajectories, and improves planning in model-based offline\nRL.", "published": "2022-08-03T17:53:46Z", "version": 1}, {"aid": "2208.02845", "authors": ["Qinhua Jenny Sun", "Khuong Vo", "Kitty Lui", "Michael Nunez", "Joachim Vandekerckhove", "Ramesh Srinivasan"], "title": "Decision SincNet: Neurocognitive models of decision making that predict cognitive processes from neural signals", "url": "http://arxiv.org/pdf/2208.02845v2", "summary": "Human decision making behavior is observed with choice-response time data\nduring psychological experiments. Drift-diffusion models of this data consist\nof a Wiener first-passage time (WFPT) distribution and are described by\ncognitive parameters: drift rate, boundary separation, and starting point.\nThese estimated parameters are of interest to neuroscientists as they can be\nmapped to features of cognitive processes of decision making (such as speed,\ncaution, and bias) and related to brain activity. The observed patterns of RT\nalso reflect the variability of cognitive processes from trial to trial\nmediated by neural dynamics. We adapted a SincNet-based shallow neural network\narchitecture to fit the Drift-Diffusion model using EEG signals on every\nexperimental trial. The model consists of a SincNet layer, a depthwise spatial\nconvolution layer, and two separate FC layers that predict drift rate and\nboundary for each trial in-parallel. The SincNet layer parametrized the kernels\nin order to directly learn the low and high cutoff frequencies of bandpass\nfilters that are applied to the EEG data to predict drift and boundary\nparameters. During training, model parameters were updated by minimizing the\nnegative log likelihood function of WFPT distribution given trial RT. We\ndeveloped separate decision SincNet models for each participant performing a\ntwo-alternative forced-choice task. Our results showed that single-trial\nestimates of drift and boundary performed better at predicting RTs than the\nmedian estimates in both training and test data sets, suggesting that our model\ncan successfully use EEG features to estimate meaningful single-trial Diffusion\nmodel parameters. Furthermore, the shallow SincNet architecture identified time\nwindows of information processing related to evidence accumulation and caution\nand the EEG frequency bands that reflect these processes within each\nparticipant.", "published": "2022-08-04T18:51:29Z", "version": 2}, {"aid": "2208.02879", "authors": ["Wenxuan Wu", "Li Fuxin", "Qi Shan"], "title": "PointConvFormer: Revenge of the Point-based Convolution", "url": "http://arxiv.org/pdf/2208.02879v3", "summary": "We introduce PointConvFormer, a novel building block for point cloud based\ndeep network architectures. Inspired by generalization theory, PointConvFormer\ncombines ideas from point convolution, where filter weights are only based on\nrelative position, and Transformers which utilize feature-based attention. In\nPointConvFormer, attention computed from feature difference between points in\nthe neighborhood is used to modify the convolutional weights at each point.\nHence, we preserved the invariances from point convolution, whereas attention\nhelps to select relevant points in the neighborhood for convolution.\nPointConvFormer is suitable for multiple tasks that require details at the\npoint level, such as segmentation and scene flow estimation tasks. We\nexperiment on both tasks with multiple datasets including ScanNet,\nSemanticKitti, FlyingThings3D and KITTI. Our results show that PointConvFormer\noffers a better accuracy-speed tradeoff than classic convolutions, regular\ntransformers, and voxelized sparse convolution approaches. Visualizations show\nthat PointConvFormer performs similarly to convolution on flat areas, whereas\nthe neighborhood selection effect is stronger on object boundaries, showing\nthat it has got the best of both worlds.", "published": "2022-08-04T20:31:46Z", "version": 3}, {"aid": "2208.02896", "authors": ["Neha Hulkund", "Nicolo Fusi", "Jennifer Wortman Vaughan", "David Alvarez-Melis"], "title": "Interpretable Distribution Shift Detection using Optimal Transport", "url": "http://arxiv.org/pdf/2208.02896v1", "summary": "We propose a method to identify and characterize distribution shifts in\nclassification datasets based on optimal transport. It allows the user to\nidentify the extent to which each class is affected by the shift, and retrieves\ncorresponding pairs of samples to provide insights on its nature. We illustrate\nits use on synthetic and natural shift examples. While the results we present\nare preliminary, we hope that this inspires future work on interpretable\nmethods for analyzing distribution shifts.", "published": "2022-08-04T21:55:29Z", "version": 1}, {"aid": "2208.03211", "authors": ["Qingyang Wang", "Michael A. Powell", "Ali Geisa", "Eric Bridgeford", "Carey E. Priebe", "Joshua T. Vogelstein"], "title": "Why do networks have inhibitory/negative connections?", "url": "http://arxiv.org/pdf/2208.03211v8", "summary": "Why do brains have inhibitory connections? Why do deep networks have negative\nweights? We propose an answer from the perspective of representation capacity.\nWe believe representing functions is the primary role of both (i) the brain in\nnatural intelligence, and (ii) deep networks in artificial intelligence. Our\nanswer to why there are inhibitory/negative weights is: to learn more\nfunctions. We prove that, in the absence of negative weights, neural networks\nwith non-decreasing activation functions are not universal approximators. While\nthis may be an intuitive result to some, to the best of our knowledge, there is\nno formal theory, in either machine learning or neuroscience, that demonstrates\nwhy negative weights are crucial in the context of representation capacity.\nFurther, we provide insights on the geometric properties of the representation\nspace that non-negative deep networks cannot represent. We expect these\ninsights will yield a deeper understanding of more sophisticated inductive\npriors imposed on the distribution of weights that lead to more efficient\nbiological and machine learning.", "published": "2022-08-05T14:54:08Z", "version": 8}, {"aid": "2208.05785", "authors": ["Shubhendu Jena", "Franck Multon", "Adnane Boukhayma"], "title": "Neural Mesh-Based Graphics", "url": "http://arxiv.org/pdf/2208.05785v3", "summary": "We revisit NPBG, the popular approach to novel view synthesis that introduced\nthe ubiquitous point feature neural rendering paradigm. We are interested in\nparticular in data-efficient learning with fast view synthesis. We achieve this\nthrough a view-dependent mesh-based denser point descriptor rasterization, in\naddition to a foreground/background scene rendering split, and an improved\nloss. By training solely on a single scene, we outperform NPBG, which has been\ntrained on ScanNet and then scene finetuned. We also perform competitively with\nrespect to the state-of-the-art method SVS, which has been trained on the full\ndataset (DTU and Tanks and Temples) and then scene finetuned, in spite of their\ndeeper neural renderer.", "published": "2022-08-10T09:18:28Z", "version": 3}, {"aid": "2208.07422", "authors": ["Xiaofeng Liu", "Chaehwa Yoo", "Fangxu Xing", "Hyejin Oh", "Georges El Fakhri", "Je-Won Kang", "Jonghye Woo"], "title": "Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives", "url": "http://arxiv.org/pdf/2208.07422v1", "summary": "Deep learning has become the method of choice to tackle real-world problems\nin different domains, partly because of its ability to learn from data and\nachieve impressive performance on a wide range of applications. However, its\nsuccess usually relies on two assumptions: (i) vast troves of labeled datasets\nare required for accurate model fitting, and (ii) training and testing data are\nindependent and identically distributed. Its performance on unseen target\ndomains, thus, is not guaranteed, especially when encountering\nout-of-distribution data at the adaptation stage. The performance drop on data\nin a target domain is a critical problem in deploying deep neural networks that\nare successfully trained on data in a source domain. Unsupervised domain\nadaptation (UDA) is proposed to counter this, by leveraging both labeled source\ndomain data and unlabeled target domain data to carry out various tasks in the\ntarget domain. UDA has yielded promising results on natural image processing,\nvideo analysis, natural language processing, time-series data analysis, medical\nimage analysis, etc. In this review, as a rapidly evolving topic, we provide a\nsystematic comparison of its methods and applications. In addition, the\nconnection of UDA with its closely related tasks, e.g., domain generalization\nand out-of-distribution detection, has also been discussed. Furthermore,\ndeficiencies in current methods and possible promising directions are\nhighlighted.", "published": "2022-08-15T20:05:07Z", "version": 1}, {"aid": "2208.07463", "authors": ["Hao Chen", "Ran Tao", "Han Zhang", "Yidong Wang", "Xiang Li", "Wei Ye", "Jindong Wang", "Guosheng Hu", "Marios Savvides"], "title": "Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets", "url": "http://arxiv.org/pdf/2208.07463v4", "summary": "While parameter efficient tuning (PET) methods have shown great potential\nwith transformer architecture on Natural Language Processing (NLP) tasks, their\neffectiveness with large-scale ConvNets is still under-studied on Computer\nVision (CV) tasks. This paper proposes Conv-Adapter, a PET module designed for\nConvNets. Conv-Adapter is light-weight, domain-transferable, and\narchitecture-agnostic with generalized performance on different tasks. When\ntransferring on downstream tasks, Conv-Adapter learns tasks-specific feature\nmodulation to the intermediate representations of backbones while keeping the\npre-trained parameters frozen. By introducing only a tiny amount of learnable\nparameters, e.g., only 3.5% full fine-tuning parameters of ResNet50. It can\nalso be applied for transformer-based backbones. Conv-Adapter outperforms\nprevious PET baseline methods and achieves comparable or surpasses the\nperformance of full fine-tuning on 23 classification tasks of various domains.\nIt also presents superior performance on the few-shot classification with an\naverage margin of 3.39%. Beyond classification, Conv-Adapter can generalize to\ndetection and segmentation tasks with more than 50% reduction of parameters but\ncomparable performance to the traditional full fine-tuning.", "published": "2022-08-15T22:51:23Z", "version": 4}, {"aid": "2208.07591", "authors": ["Subhankar Roy", "Martin Trapp", "Andrea Pilzer", "Juho Kannala", "Nicu Sebe", "Elisa Ricci", "Arno Solin"], "title": "Uncertainty-guided Source-free Domain Adaptation", "url": "http://arxiv.org/pdf/2208.07591v1", "summary": "Source-free domain adaptation (SFDA) aims to adapt a classifier to an\nunlabelled target data set by only using a pre-trained source model. However,\nthe absence of the source data and the domain shift makes the predictions on\nthe target data unreliable. We propose quantifying the uncertainty in the\nsource model predictions and utilizing it to guide the target adaptation. For\nthis, we construct a probabilistic source model by incorporating priors on the\nnetwork parameters inducing a distribution over the model predictions.\nUncertainties are estimated by employing a Laplace approximation and\nincorporated to identify target data points that do not lie in the source\nmanifold and to down-weight them when maximizing the mutual information on the\ntarget data. Unlike recent works, our probabilistic treatment is\ncomputationally lightweight, decouples source training and target adaptation,\nand requires no specialized source training or changes of the model\narchitecture. We show the advantages of uncertainty-guided SFDA over\ntraditional SFDA in the closed-set and open-set settings and provide empirical\nevidence that our approach is more robust to strong domain shifts even without\ntuning.", "published": "2022-08-16T08:03:30Z", "version": 1}, {"aid": "2208.07765", "authors": ["Taewoo Kim", "Chaeyeon Chung", "Yoonseo Kim", "Sunghyun Park", "Kangyeol Kim", "Jaegul Choo"], "title": "Style Your Hair: Latent Optimization for Pose-Invariant Hairstyle Transfer via Local-Style-Aware Hair Alignment", "url": "http://arxiv.org/pdf/2208.07765v1", "summary": "Editing hairstyle is unique and challenging due to the complexity and\ndelicacy of hairstyle. Although recent approaches significantly improved the\nhair details, these models often produce undesirable outputs when a pose of a\nsource image is considerably different from that of a target hair image,\nlimiting their real-world applications. HairFIT, a pose-invariant hairstyle\ntransfer model, alleviates this limitation yet still shows unsatisfactory\nquality in preserving delicate hair textures. To solve these limitations, we\npropose a high-performing pose-invariant hairstyle transfer model equipped with\nlatent optimization and a newly presented local-style-matching loss. In the\nStyleGAN2 latent space, we first explore a pose-aligned latent code of a target\nhair with the detailed textures preserved based on local style matching. Then,\nour model inpaints the occlusions of the source considering the aligned target\nhair and blends both images to produce a final output. The experimental results\ndemonstrate that our model has strengths in transferring a hairstyle under\nlarger pose differences and preserving local hairstyle textures.", "published": "2022-08-16T14:23:54Z", "version": 1}, {"aid": "2208.07769", "authors": ["Xiaofeng Liu", "Chaehwa Yoo", "Fangxu Xing", "C. -C. Jay Kuo", "Georges El Fakhri", "Jonghye Woo"], "title": "Unsupervised Domain Adaptation for Segmentation with Black-box Source Model", "url": "http://arxiv.org/pdf/2208.07769v1", "summary": "Unsupervised domain adaptation (UDA) has been widely used to transfer\nknowledge from a labeled source domain to an unlabeled target domain to counter\nthe difficulty of labeling in a new domain. The training of conventional\nsolutions usually relies on the existence of both source and target domain\ndata. However, privacy of the large-scale and well-labeled data in the source\ndomain and trained model parameters can become the major concern of cross\ncenter/domain collaborations. In this work, to address this, we propose a\npractical solution to UDA for segmentation with a black-box segmentation model\ntrained in the source domain only, rather than original source data or a\nwhite-box source model. Specifically, we resort to a knowledge distillation\nscheme with exponential mixup decay (EMD) to gradually learn target-specific\nrepresentations. In addition, unsupervised entropy minimization is further\napplied to regularization of the target domain confidence. We evaluated our\nframework on the BraTS 2018 database, achieving performance on par with\nwhite-box source model adaptation approaches.", "published": "2022-08-16T14:29:15Z", "version": 1}, {"aid": "2208.07791", "authors": ["Xiulong Yang", "Sheng-Min Shih", "Yinlin Fu", "Xiaoting Zhao", "Shihao Ji"], "title": "Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model", "url": "http://arxiv.org/pdf/2208.07791v1", "summary": "Diffusion Denoising Probability Models (DDPM) and Vision Transformer (ViT)\nhave demonstrated significant progress in generative tasks and discriminative\ntasks, respectively, and thus far these models have largely been developed in\ntheir own domains. In this paper, we establish a direct connection between DDPM\nand ViT by integrating the ViT architecture into DDPM, and introduce a new\ngenerative model called Generative ViT (GenViT). The modeling flexibility of\nViT enables us to further extend GenViT to hybrid discriminative-generative\nmodeling, and introduce a Hybrid ViT (HybViT). Our work is among the first to\nexplore a single ViT for image generation and classification jointly. We\nconduct a series of experiments to analyze the performance of proposed models\nand demonstrate their superiority over prior state-of-the-arts in both\ngenerative and discriminative tasks. Our code and pre-trained models can be\nfound in https://github.com/sndnyang/Diffusion_ViT .", "published": "2022-08-16T15:02:21Z", "version": 1}, {"aid": "2208.07862", "authors": ["Haonan Qiu", "Yuming Jiang", "Hang Zhou", "Wayne Wu", "Ziwei Liu"], "title": "StyleFaceV: Face Video Generation via Decomposing and Recomposing Pretrained StyleGAN3", "url": "http://arxiv.org/pdf/2208.07862v1", "summary": "Realistic generative face video synthesis has long been a pursuit in both\ncomputer vision and graphics community. However, existing face video generation\nmethods tend to produce low-quality frames with drifted facial identities and\nunnatural movements. To tackle these challenges, we propose a principled\nframework named StyleFaceV, which produces high-fidelity identity-preserving\nface videos with vivid movements. Our core insight is to decompose appearance\nand pose information and recompose them in the latent space of StyleGAN3 to\nproduce stable and dynamic results. Specifically, StyleGAN3 provides strong\npriors for high-fidelity facial image generation, but the latent space is\nintrinsically entangled. By carefully examining its latent properties, we\npropose our decomposition and recomposition designs which allow for the\ndisentangled combination of facial appearance and movements. Moreover, a\ntemporal-dependent model is built upon the decomposed latent features, and\nsamples reasonable sequences of motions that are capable of generating\nrealistic and temporally coherent face videos. Particularly, our pipeline is\ntrained with a joint training strategy on both static images and high-quality\nvideo data, which is of higher data efficiency. Extensive experiments\ndemonstrate that our framework achieves state-of-the-art face video generation\nresults both qualitatively and quantitatively. Notably, StyleFaceV is capable\nof generating realistic $1024\\times1024$ face videos even without\nhigh-resolution training videos.", "published": "2022-08-16T17:47:03Z", "version": 1}, {"aid": "2208.07934", "authors": ["Povilas Daniu\u0161is", "Shubham Juneja", "Lukas Kuzma", "Virginijus Marcinkevi\u010dius"], "title": "Measuring Statistical Dependencies via Maximum Norm and Characteristic Functions", "url": "http://arxiv.org/pdf/2208.07934v1", "summary": "In this paper, we focus on the problem of statistical dependence estimation\nusing characteristic functions. We propose a statistical dependence measure,\nbased on the maximum-norm of the difference between joint and product-marginal\ncharacteristic functions. The proposed measure can detect arbitrary statistical\ndependence between two random vectors of possibly different dimensions, is\ndifferentiable, and easily integrable into modern machine learning and deep\nlearning pipelines. We also conduct experiments both with simulated and real\ndata. Our simulations show, that the proposed method can measure statistical\ndependencies in high-dimensional, non-linear data, and is less affected by the\ncurse of dimensionality, compared to the previous work in this line of\nresearch. The experiments with real data demonstrate the potential\napplicability of our statistical measure for two different empirical inference\nscenarios, showing statistically significant improvement in the performance\ncharacteristics when applied for supervised feature extraction and deep neural\nnetwork regularization. In addition, we provide a link to the accompanying\nopen-source repository https://bit.ly/3d4ch5I.", "published": "2022-08-16T20:24:31Z", "version": 1}, {"aid": "2208.08083", "authors": ["Dong Huang", "Qingwen Bu", "Yuhao Qing", "Haowen Pi", "Sen Wang", "Heming Cui"], "title": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models", "url": "http://arxiv.org/pdf/2208.08083v1", "summary": "Deep neural networks (DNNs) are vulnerable to adversarial examples, in which\nDNNs are misled to false outputs due to inputs containing imperceptible\nperturbations. Adversarial training, a reliable and effective method of\ndefense, may significantly reduce the vulnerability of neural networks and\nbecomes the de facto standard for robust learning. While many recent works\npractice the data-centric philosophy, such as how to generate better\nadversarial examples or use generative models to produce additional training\ndata, we look back to the models themselves and revisit the adversarial\nrobustness from the perspective of deep feature distribution as an insightful\ncomplementarity. In this paper, we propose Branch Orthogonality adveRsarial\nTraining (BORT) to obtain state-of-the-art performance with solely the original\ndataset for adversarial training. To practice our design idea of integrating\nmultiple orthogonal solution spaces, we leverage a simple and straightforward\nmulti-branch neural network that eclipses adversarial attacks with no increase\nin inference time. We heuristically propose a corresponding loss function,\nbranch-orthogonal loss, to make each solution space of the multi-branch model\northogonal. We evaluate our approach on CIFAR-10, CIFAR-100, and SVHN against\n\\ell_{\\infty} norm-bounded perturbations of size \\epsilon = 8/255,\nrespectively. Exhaustive experiments are conducted to show that our method goes\nbeyond all state-of-the-art methods without any tricks. Compared to all methods\nthat do not use additional data for training, our models achieve 67.3% and\n41.5% robust accuracy on CIFAR-10 and CIFAR-100 (improving upon the\nstate-of-the-art by +7.23% and +9.07%). We also outperform methods using a\ntraining set with a far larger scale than ours. All our models and codes are\navailable online at https://github.com/huangd1999/BORT.", "published": "2022-08-17T05:42:59Z", "version": 1}, {"aid": "2208.08092", "authors": ["Jaskirat Singh", "Liang Zheng", "Cameron Smith", "Jose Echevarria"], "title": "Paint2Pix: Interactive Painting based Progressive Image Synthesis and Editing", "url": "http://arxiv.org/pdf/2208.08092v1", "summary": "Controllable image synthesis with user scribbles is a topic of keen interest\nin the computer vision community. In this paper, for the first time we study\nthe problem of photorealistic image synthesis from incomplete and primitive\nhuman paintings. In particular, we propose a novel approach paint2pix, which\nlearns to predict (and adapt) \"what a user wants to draw\" from rudimentary\nbrushstroke inputs, by learning a mapping from the manifold of incomplete human\npaintings to their realistic renderings. When used in conjunction with recent\nworks in autonomous painting agents, we show that paint2pix can be used for\nprogressive image synthesis from scratch. During this process, paint2pix allows\na novice user to progressively synthesize the desired image output, while\nrequiring just few coarse user scribbles to accurately steer the trajectory of\nthe synthesis process. Furthermore, we find that our approach also forms a\nsurprisingly convenient approach for real image editing, and allows the user to\nperform a diverse range of custom fine-grained edits through the addition of\nonly a few well-placed brushstrokes. Supplemental video and demo are available\nat https://1jsingh.github.io/paint2pix", "published": "2022-08-17T06:08:11Z", "version": 1}, {"aid": "2208.08160", "authors": ["Luke Thorburn", "Maria Polukarov", "Carmine Ventre"], "title": "Error in the Euclidean Preference Model", "url": "http://arxiv.org/pdf/2208.08160v3", "summary": "Spatial models of preference, in the form of vector embeddings, are learned\nby many deep learning and multiagent systems, including recommender systems.\nOften these models are assumed to approximate a Euclidean structure, where an\nindividual prefers alternatives positioned closer to their \"ideal point\", as\nmeasured by the Euclidean metric. However, Bogomolnaia and Laslier (2007)\nshowed that there exist ordinal preference profiles that cannot be represented\nwith this structure if the Euclidean space has two fewer dimensions than there\nare individuals or alternatives. We extend this result, showing that there are\nsituations in which almost all preference profiles cannot be represented with\nthe Euclidean model, and derive a theoretical lower bound on the expected error\nwhen using the Euclidean model to approximate non-Euclidean preference\nprofiles. Our results have implications for the interpretation and use of\nvector embeddings, because in some cases close approximation of arbitrary, true\nordinal relationships can be expected only if the dimensionality of the\nembeddings is a substantial fraction of the number of entities represented.", "published": "2022-08-17T09:01:17Z", "version": 3}, {"aid": "2208.08161", "authors": ["Dongyang Kuang", "Craig Michoski"], "title": "KAM -- a Kernel Attention Module for Emotion Classification with EEG Data", "url": "http://arxiv.org/pdf/2208.08161v2", "summary": "In this work, a kernel attention module is presented for the task of\nEEG-based emotion classification with neural networks. The proposed module\nutilizes a self-attention mechanism by performing a kernel trick, demanding\nsignificantly fewer trainable parameters and computations than standard\nattention modules. The design also provides a scalar for quantitatively\nexamining the amount of attention assigned during deep feature refinement,\nhence help better interpret a trained model. Using EEGNet as the backbone\nmodel, extensive experiments are conducted on the SEED dataset to assess the\nmodule's performance on within-subject classification tasks compared to other\nSOTA attention modules. Requiring only one extra parameter, the inserted module\nis shown to boost the base model's mean prediction accuracy up to more than 1\\%\nacross 15 subjects. A key component of the method is the interpretability of\nsolutions, which is addressed using several different techniques, and is\nincluded throughout as part of the dependency analysis.", "published": "2022-08-17T09:02:09Z", "version": 2}, {"aid": "2208.08661", "authors": ["Yi-Fan Zhang", "Jindong Wang", "Jian Liang", "Zhang Zhang", "Baosheng Yu", "Liang Wang", "Dacheng Tao", "Xing Xie"], "title": "Domain-Specific Risk Minimization for Out-of-Distribution Generalization", "url": "http://arxiv.org/pdf/2208.08661v4", "summary": "Recent domain generalization (DG) approaches typically use the hypothesis\nlearned on source domains for inference on the unseen target domain. However,\nsuch a hypothesis can be arbitrarily far from the optimal one for the target\ndomain, induced by a gap termed ``adaptivity gap''. Without exploiting the\ndomain information from the unseen test samples, adaptivity gap estimation and\nminimization are intractable, which hinders us to robustify a model to any\nunknown distribution. In this paper, we first establish a generalization bound\nthat explicitly considers the adaptivity gap. Our bound motivates two\nstrategies to reduce the gap: the first one is ensembling multiple classifiers\nto enrich the hypothesis space, then we propose effective gap estimation\nmethods for guiding the selection of a better hypothesis for the target. The\nother method is minimizing the gap directly by adapting model parameters using\nonline target samples. We thus propose \\textbf{Domain-specific Risk\nMinimization (DRM)}. During training, DRM models the distributions of different\nsource domains separately; for inference, DRM performs online model steering\nusing the source hypothesis for each arriving target sample. Extensive\nexperiments demonstrate the effectiveness of the proposed DRM for domain\ngeneralization with the following advantages: 1) it significantly outperforms\ncompetitive baselines on different distributional shift settings; 2) it\nachieves either comparable or superior accuracies on all source domains\ncompared to vanilla empirical risk minimization; 3) it remains simple and\nefficient during training, and 4) it is complementary to invariant learning\napproaches.", "published": "2022-08-18T06:42:49Z", "version": 4}, {"aid": "2208.08713", "authors": ["Samuel T. Wauthier", "Bram Vanhecke", "Tim Verbelen", "Bart Dhoedt"], "title": "Learning Generative Models for Active Inference using Tensor Networks", "url": "http://arxiv.org/pdf/2208.08713v2", "summary": "Active inference provides a general framework for behavior and learning in\nautonomous agents. It states that an agent will attempt to minimize its\nvariational free energy, defined in terms of beliefs over observations,\ninternal states and policies. Traditionally, every aspect of a discrete active\ninference model must be specified by hand, i.e. by manually defining the hidden\nstate space structure, as well as the required distributions such as likelihood\nand transition probabilities. Recently, efforts have been made to learn state\nspace representations automatically from observations using deep neural\nnetworks. In this paper, we present a novel approach of learning state spaces\nusing quantum physics-inspired tensor networks. The ability of tensor networks\nto represent the probabilistic nature of quantum states as well as to reduce\nlarge state spaces makes tensor networks a natural candidate for active\ninference. We show how tensor networks can be used as a generative model for\nsequential data. Furthermore, we show how one can obtain beliefs from such a\ngenerative model and how an active inference agent can use these to compute the\nexpected free energy. Finally, we demonstrate our method on the classic T-maze\nenvironment.", "published": "2022-08-18T08:55:06Z", "version": 2}, {"aid": "2208.08932", "authors": ["Janis Postels", "Martin Danelljan", "Luc Van Gool", "Federico Tombari"], "title": "ManiFlow: Implicitly Representing Manifolds with Normalizing Flows", "url": "http://arxiv.org/pdf/2208.08932v1", "summary": "Normalizing Flows (NFs) are flexible explicit generative models that have\nbeen shown to accurately model complex real-world data distributions. However,\ntheir invertibility constraint imposes limitations on data distributions that\nreside on lower dimensional manifolds embedded in higher dimensional space.\nPractically, this shortcoming is often bypassed by adding noise to the data\nwhich impacts the quality of the generated samples. In contrast to prior work,\nwe approach this problem by generating samples from the original data\ndistribution given full knowledge about the perturbed distribution and the\nnoise model. To this end, we establish that NFs trained on perturbed data\nimplicitly represent the manifold in regions of maximum likelihood. Then, we\npropose an optimization objective that recovers the most likely point on the\nmanifold given a sample from the perturbed distribution. Finally, we focus on\n3D point clouds for which we utilize the explicit nature of NFs, i.e. surface\nnormals extracted from the gradient of the log-likelihood and the\nlog-likelihood itself, to apply Poisson surface reconstruction to refine\ngenerated point sets.", "published": "2022-08-18T16:07:59Z", "version": 1}, {"aid": "2208.09058", "authors": ["Mahault Albarracin", "Riddhi J. Pitliya", "Maxwell J. D. Ramstead", "Jeffrey Yoshimi"], "title": "Mapping Husserlian phenomenology onto active inference", "url": "http://arxiv.org/pdf/2208.09058v3", "summary": "Phenomenology is the rigorous descriptive study of conscious experience.\nRecent attempts to formalize Husserlian phenomenology provide us with a\nmathematical model of perception as a function of prior knowledge and\nexpectation. In this paper, we re-examine elements of Husserlian phenomenology\nthrough the lens of active inference. In doing so, we aim to advance the\nproject of computational phenomenology, as recently outlined by proponents of\nactive inference. We propose that key aspects of Husserl's descriptions of\nconsciousness can be mapped onto aspects of the generative models associated\nwith the active inference approach. We first briefly review active inference.\nWe then discuss Husserl's phenomenology, with a focus on time consciousness.\nFinally, we present our mapping from Husserlian phenomenology to active\ninference.", "published": "2022-08-18T20:55:42Z", "version": 3}, {"aid": "2208.09203", "authors": ["Riccardo Renzulli", "Marco Grangetto"], "title": "Towards Efficient Capsule Networks", "url": "http://arxiv.org/pdf/2208.09203v1", "summary": "From the moment Neural Networks dominated the scene for image processing, the\ncomputational complexity needed to solve the targeted tasks skyrocketed:\nagainst such an unsustainable trend, many strategies have been developed,\nambitiously targeting performance's preservation. Promoting sparse topologies,\nfor example, allows the deployment of deep neural networks models on embedded,\nresource-constrained devices. Recently, Capsule Networks were introduced to\nenhance explainability of a model, where each capsule is an explicit\nrepresentation of an object or its parts. These models show promising results\non toy datasets, but their low scalability prevents deployment on more complex\ntasks. In this work, we explore sparsity besides capsule representations to\nimprove their computational efficiency by reducing the number of capsules. We\nshow how pruning with Capsule Network achieves high generalization with less\nmemory requirements, computational effort, and inference and training time.", "published": "2022-08-19T08:03:25Z", "version": 1}, {"aid": "2208.09392", "authors": ["Arpit Bansal", "Eitan Borgnia", "Hong-Min Chu", "Jie S. Li", "Hamid Kazemi", "Furong Huang", "Micah Goldblum", "Jonas Geiping", "Tom Goldstein"], "title": "Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise", "url": "http://arxiv.org/pdf/2208.09392v1", "summary": "Standard diffusion models involve an image transform -- adding Gaussian noise\n-- and an image restoration operator that inverts this degradation. We observe\nthat the generative behavior of diffusion models is not strongly dependent on\nthe choice of image degradation, and in fact an entire family of generative\nmodels can be constructed by varying this choice. Even when using completely\ndeterministic degradations (e.g., blur, masking, and more), the training and\ntest-time update rules that underlie diffusion models can be easily generalized\nto create generative models. The success of these fully deterministic models\ncalls into question the community's understanding of diffusion models, which\nrelies on noise in either gradient Langevin dynamics or variational inference,\nand paves the way for generalized diffusion models that invert arbitrary\nprocesses. Our code is available at\nhttps://github.com/arpitbansal297/Cold-Diffusion-Models", "published": "2022-08-19T15:18:39Z", "version": 1}, {"aid": "2208.09801", "authors": ["Jiachen Sun", "Weili Nie", "Zhiding Yu", "Z. Morley Mao", "Chaowei Xiao"], "title": "PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D Point Cloud Recognition", "url": "http://arxiv.org/pdf/2208.09801v1", "summary": "3D Point cloud is becoming a critical data representation in many real-world\napplications like autonomous driving, robotics, and medical imaging. Although\nthe success of deep learning further accelerates the adoption of 3D point\nclouds in the physical world, deep learning is notorious for its vulnerability\nto adversarial attacks. In this work, we first identify that the\nstate-of-the-art empirical defense, adversarial training, has a major\nlimitation in applying to 3D point cloud models due to gradient obfuscation. We\nfurther propose PointDP, a purification strategy that leverages diffusion\nmodels to defend against 3D adversarial attacks. We extensively evaluate\nPointDP on six representative 3D point cloud architectures, and leverage 10+\nstrong and adaptive attacks to demonstrate its lower-bound robustness. Our\nevaluation shows that PointDP achieves significantly better robustness than\nstate-of-the-art purification methods under strong attacks. Results of\ncertified defenses on randomized smoothing combined with PointDP will be\nincluded in the near future.", "published": "2022-08-21T04:49:17Z", "version": 1}, {"aid": "2208.10498", "authors": ["Dalin Zhang", "Kaixuan Chen", "Yan Zhao", "Bin Yang", "Lina Yao", "Christian S. Jensen"], "title": "Design Automation for Fast, Lightweight, and Effective Deep Learning Models: A Survey", "url": "http://arxiv.org/pdf/2208.10498v1", "summary": "Deep learning technologies have demonstrated remarkable effectiveness in a\nwide range of tasks, and deep learning holds the potential to advance a\nmultitude of applications, including in edge computing, where deep models are\ndeployed on edge devices to enable instant data processing and response. A key\nchallenge is that while the application of deep models often incurs substantial\nmemory and computational costs, edge devices typically offer only very limited\nstorage and computational capabilities that may vary substantially across\ndevices. These characteristics make it difficult to build deep learning\nsolutions that unleash the potential of edge devices while complying with their\nconstraints. A promising approach to addressing this challenge is to automate\nthe design of effective deep learning models that are lightweight, require only\na little storage, and incur only low computational overheads. This survey\noffers comprehensive coverage of studies of design automation techniques for\ndeep learning models targeting edge computing. It offers an overview and\ncomparison of key metrics that are used commonly to quantify the proficiency of\nmodels in terms of effectiveness, lightness, and computational costs. The\nsurvey then proceeds to cover three categories of the state-of-the-art of deep\nmodel design automation techniques: automated neural architecture search,\nautomated model compression, and joint automated design and compression.\nFinally, the survey covers open issues and directions for future research.", "published": "2022-08-22T12:12:43Z", "version": 1}, {"aid": "2208.10531", "authors": ["Qucheng Peng", "Zhengming Ding", "Lingjuan Lyu", "Lichao Sun", "Chen Chen"], "title": "RAIN: RegulArization on Input and Network for Black-Box Domain Adaptation", "url": "http://arxiv.org/pdf/2208.10531v4", "summary": "Source-Free domain adaptation transits the source-trained model towards\ntarget domain without exposing the source data, trying to dispel these concerns\nabout data privacy and security. However, this paradigm is still at risk of\ndata leakage due to adversarial attacks on the source model. Hence, the\nBlack-Box setting only allows to use the outputs of source model, but still\nsuffers from overfitting on the source domain more severely due to source\nmodel's unseen weights. In this paper, we propose a novel approach named RAIN\n(RegulArization on Input and Network) for Black-Box domain adaptation from both\ninput-level and network-level regularization. For the input-level, we design a\nnew data augmentation technique as Phase MixUp, which highlights task-relevant\nobjects in the interpolations, thus enhancing input-level regularization and\nclass consistency for target models. For network-level, we develop a Subnetwork\nDistillation mechanism to transfer knowledge from the target subnetwork to the\nfull target network via knowledge distillation, which thus alleviates\noverfitting on the source domain by learning diverse target representations.\nExtensive experiments show that our method achieves state-of-the-art\nperformance on several cross-domain benchmarks under both single- and\nmulti-source black-box domain adaptation.", "published": "2022-08-22T18:18:47Z", "version": 4}, {"aid": "2208.10668", "authors": ["Anna A. Ivanova", "Martin Schrimpf", "Stefano Anzellotti", "Noga Zaslavsky", "Evelina Fedorenko", "Leyla Isik"], "title": "Beyond linear regression: mapping models in cognitive neuroscience should align with research goals", "url": "http://arxiv.org/pdf/2208.10668v1", "summary": "Many cognitive neuroscience studies use large feature sets to predict and\ninterpret brain activity patterns. Feature sets take many forms, from human\nstimulus annotations to representations in deep neural networks. Of crucial\nimportance in all these studies is the mapping model, which defines the space\nof possible relationships between features and neural data. Until recently,\nmost encoding and decoding studies have used linear mapping models. Increasing\navailability of large datasets and computing resources has recently allowed\nsome researchers to employ more flexible nonlinear mapping models instead;\nhowever, the question of whether nonlinear mapping models can yield meaningful\nscientific insights remains debated. Here, we discuss the choice of a mapping\nmodel in the context of three overarching desiderata: predictive accuracy,\ninterpretability, and biological plausibility. We show that, contrary to\npopular intuition, these desiderata do not map cleanly onto the\nlinear/nonlinear divide; instead, each desideratum can refer to multiple\nresearch goals, each of which imposes its own constraints on the mapping model.\nMoreover, we argue that, instead of categorically treating the mapping models\nas linear or nonlinear, we should instead aim to estimate the complexity of\nthese models. We show that, in many cases, complexity provides a more accurate\nreflection of restrictions imposed by various research goals. Finally, we\noutline several complexity metrics that can be used to effectively evaluate\nmapping models.", "published": "2022-08-23T01:25:26Z", "version": 1}, {"aid": "2208.11511", "authors": ["Taewook Ko", "Chong-Kwon Kim"], "title": "A Graph Convolution for Signed Directed Graphs", "url": "http://arxiv.org/pdf/2208.11511v3", "summary": "A signed directed graph is a graph with sign and direction information on the\nedges. Even though signed directed graphs are more informative than unsigned or\nundirected graphs, they are more complicated to analyze and have received less\nresearch attention. This paper investigates a spectral graph convolution model\nto fully utilize the information embedded in signed directed edges. We propose\na novel complex Hermitian adjacency matrix that encodes graph information via\ncomplex numbers. Compared to a simple connection-based adjacency matrix, the\ncomplex Hermitian can represent edge direction, sign, and connectivity via its\nphases and magnitudes. Then, we define a magnetic Laplacian of the proposed\nadjacency matrix and prove that it is positive semi-definite (PSD) for the\nanalyses using spectral graph convolution. We perform extensive experiments on\nfour real-world datasets. Our experiments show that the proposed scheme\noutperforms several state-of-the-art techniques.", "published": "2022-08-23T01:58:35Z", "version": 3}, {"aid": "2208.10716", "authors": ["Weihao Yan", "Yeqiang Qian", "Chunxiang Wang", "Ming Yang"], "title": "Threshold-adaptive Unsupervised Focal Loss for Domain Adaptation of Semantic Segmentation", "url": "http://arxiv.org/pdf/2208.10716v1", "summary": "Semantic segmentation is an important task for intelligent vehicles to\nunderstand the environment. Current deep learning methods require large amounts\nof labeled data for training. Manual annotation is expensive, while simulators\ncan provide accurate annotations. However, the performance of the semantic\nsegmentation model trained with the data of the simulator will significantly\ndecrease when applied in the actual scene. Unsupervised domain adaptation (UDA)\nfor semantic segmentation has recently gained increasing research attention,\naiming to reduce the domain gap and improve the performance on the target\ndomain. In this paper, we propose a novel two-stage entropy-based UDA method\nfor semantic segmentation. In stage one, we design a threshold-adaptative\nunsupervised focal loss to regularize the prediction in the target domain,\nwhich has a mild gradient neutralization mechanism and mitigates the problem\nthat hard samples are barely optimized in entropy-based methods. In stage two,\nwe introduce a data augmentation method named cross-domain image mixing (CIM)\nto bridge the semantic knowledge from two domains. Our method achieves\nstate-of-the-art 58.4% and 59.6% mIoUs on SYNTHIA-to-Cityscapes and\nGTA5-to-Cityscapes using DeepLabV2 and competitive performance using the\nlightweight BiSeNet.", "published": "2022-08-23T03:48:48Z", "version": 1}, {"aid": "2208.10730", "authors": ["Ming-Yang Ho", "Min-Sheng Wu", "Che-Ming Wu"], "title": "Ultra-high-resolution unpaired stain transformation via Kernelized Instance Normalization", "url": "http://arxiv.org/pdf/2208.10730v1", "summary": "While hematoxylin and eosin (H&E) is a standard staining procedure,\nimmunohistochemistry (IHC) staining further serves as a diagnostic and\nprognostic method. However, acquiring special staining results requires\nsubstantial costs.\n  Hence, we proposed a strategy for ultra-high-resolution unpaired\nimage-to-image translation: Kernelized Instance Normalization (KIN), which\npreserves local information and successfully achieves seamless stain\ntransformation with constant GPU memory usage. Given a patch, corresponding\nposition, and a kernel, KIN computes local statistics using convolution\noperation. In addition, KIN can be easily plugged into most currently developed\nframeworks without re-training.\n  We demonstrate that KIN achieves state-of-the-art stain transformation by\nreplacing instance normalization (IN) layers with KIN layers in three popular\nframeworks and testing on two histopathological datasets. Furthermore, we\nmanifest the generalizability of KIN with high-resolution natural images.\nFinally, human evaluation and several objective metrics are used to compare the\nperformance of different approaches.\n  Overall, this is the first successful study for the ultra-high-resolution\nunpaired image-to-image translation with constant space complexity. Code is\navailable at: https://github.com/Kaminyou/URUST", "published": "2022-08-23T04:47:43Z", "version": 1}, {"aid": "2208.10758", "authors": ["Tianwei Chen", "Noa Garcia", "Mayu Otani", "Chenhui Chu", "Yuta Nakashima", "Hajime Nagahara"], "title": "Learning More May Not Be Better: Knowledge Transferability in Vision and Language Tasks", "url": "http://arxiv.org/pdf/2208.10758v1", "summary": "Is more data always better to train vision-and-language models? We study\nknowledge transferability in multi-modal tasks. The current tendency in machine\nlearning is to assume that by joining multiple datasets from different tasks\ntheir overall performance will improve. However, we show that not all the\nknowledge transfers well or has a positive impact on related tasks, even when\nthey share a common goal. We conduct an exhaustive analysis based on hundreds\nof cross-experiments on 12 vision-and-language tasks categorized in 4 groups.\nWhereas tasks in the same group are prone to improve each other, results show\nthat this is not always the case. Other factors such as dataset size or\npre-training stage have also a great impact on how well the knowledge is\ntransferred.", "published": "2022-08-23T06:39:18Z", "version": 1}, {"aid": "2208.12055", "authors": ["Haozhe Liu", "Bing Li", "Haoqian Wu", "Hanbang Liang", "Yawen Huang", "Yuexiang Li", "Bernard Ghanem", "Yefeng Zheng"], "title": "Combating Mode Collapse in GANs via Manifold Entropy Estimation", "url": "http://arxiv.org/pdf/2208.12055v6", "summary": "Generative Adversarial Networks (GANs) have shown compelling results in\nvarious tasks and applications in recent years. However, mode collapse remains\na critical problem in GANs. In this paper, we propose a novel training pipeline\nto address the mode collapse issue of GANs. Different from existing methods, we\npropose to generalize the discriminator as feature embedding and maximize the\nentropy of distributions in the embedding space learned by the discriminator.\nSpecifically, two regularization terms, i.e., Deep Local Linear Embedding\n(DLLE) and Deep Isometric feature Mapping (DIsoMap), are designed to encourage\nthe discriminator to learn the structural information embedded in the data,\nsuch that the embedding space learned by the discriminator can be well-formed.\nBased on the well-learned embedding space supported by the discriminator, a\nnon-parametric entropy estimator is designed to efficiently maximize the\nentropy of embedding vectors, playing as an approximation of maximizing the\nentropy of the generated distribution. By improving the discriminator and\nmaximizing the distance of the most similar samples in the embedding space, our\npipeline effectively reduces the mode collapse without sacrificing the quality\nof generated samples. Extensive experimental results show the effectiveness of\nour method, which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs.\n12.43 in FID) and surpasses the recent state-of-the-art energy-based model on\nthe ANIME-FACE dataset (2.80 vs. 2.26 in Inception score). The code is\navailable at https://github.com/HaozheLiu-ST/MEE", "published": "2022-08-25T12:33:31Z", "version": 6}, {"aid": "2208.13040", "authors": ["Ziheng Wu", "Xinyi Zou", "Wenmeng Zhou", "Jun Huang"], "title": "YOLOX-PAI: An Improved YOLOX, Stronger and Faster than YOLOv6", "url": "http://arxiv.org/pdf/2208.13040v3", "summary": "We develop an all-in-one computer vision toolbox named EasyCV to facilitate\nthe use of various SOTA computer vision methods. Recently, we add YOLOX-PAI, an\nimproved version of YOLOX, into EasyCV. We conduct ablation studies to\ninvestigate the influence of some detection methods on YOLOX. We also provide\nan easy use for PAI-Blade which is used to accelerate the inference process\nbased on BladeDISC and TensorRT. Finally, we receive 42.8 mAP on COCO dateset\nwithin 1.0 ms on a single NVIDIA V100 GPU, which is a bit faster than YOLOv6. A\nsimple but efficient predictor api is also designed in EasyCV to conduct\nend2end object detection. Codes and models are now available at:\nhttps://github.com/alibaba/EasyCV.", "published": "2022-08-27T15:37:26Z", "version": 3}, {"aid": "2208.13975", "authors": ["Shlok Mohta", "Hisahiro Suganuma", "Yoshiki Tanaka"], "title": "MRL: Learning to Mix with Attention and Convolutions", "url": "http://arxiv.org/pdf/2208.13975v1", "summary": "In this paper, we present a new neural architectural block for the vision\ndomain, named Mixing Regionally and Locally (MRL), developed with the aim of\neffectively and efficiently mixing the provided input features. We bifurcate\nthe input feature mixing task as mixing at a regional and local scale. To\nachieve an efficient mix, we exploit the domain-wide receptive field provided\nby self-attention for regional-scale mixing and convolutional kernels\nrestricted to local scale for local-scale mixing. More specifically, our\nproposed method mixes regional features associated with local features within a\ndefined region, followed by a local-scale features mix augmented by regional\nfeatures. Experiments show that this hybridization of self-attention and\nconvolution brings improved capacity, generalization (right inductive bias),\nand efficiency. Under similar network settings, MRL outperforms or is at par\nwith its counterparts in classification, object detection, and segmentation\ntasks. We also show that our MRL-based network architecture achieves\nstate-of-the-art performance for H&E histology datasets. We achieved DICE of\n0.843, 0.855, and 0.892 for Kumar, CoNSep, and CPM-17 datasets, respectively,\nwhile highlighting the versatility offered by the MRL framework by\nincorporating layers like group convolutions to improve dataset-specific\ngeneralization.", "published": "2022-08-30T03:42:29Z", "version": 1}, {"aid": "2208.14039", "authors": ["Woon-Ha Yeo", "Wang-Taek Oh", "Kyung-Su Kang", "Young-Il Kim", "Han-Cheol Ryu"], "title": "CAIR: Fast and Lightweight Multi-Scale Color Attention Network for Instagram Filter Removal", "url": "http://arxiv.org/pdf/2208.14039v1", "summary": "Image restoration is an important and challenging task in computer vision.\nReverting a filtered image to its original image is helpful in various computer\nvision tasks. We employ a nonlinear activation function free network (NAFNet)\nfor a fast and lightweight model and add a color attention module that extracts\nuseful color information for better accuracy. We propose an accurate, fast,\nlightweight network with multi-scale and color attention for Instagram filter\nremoval (CAIR). Experiment results show that the proposed CAIR outperforms\nexisting Instagram filter removal networks in fast and lightweight ways, about\n11$\\times$ faster and 2.4$\\times$ lighter while exceeding 3.69 dB PSNR on IFFI\ndataset. CAIR can successfully remove the Instagram filter with high quality\nand restore color information in qualitative results. The source code and\npretrained weights are available at \\url{https://github.com/HnV-Lab/CAIR}.", "published": "2022-08-30T07:42:45Z", "version": 1}, {"aid": "2208.14133", "authors": ["Yong Zhong", "Hongtao Liu", "Xiaodong Liu", "Fan Bao", "Weiran Shen", "Chongxuan Li"], "title": "Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models", "url": "http://arxiv.org/pdf/2208.14133v3", "summary": "Deep generative models (DGMs) are data-eager because learning a complex model\non limited data suffers from a large variance and easily overfits. Inspired by\nthe classical perspective of the bias-variance tradeoff, we propose regularized\ndeep generative model (Reg-DGM), which leverages a nontransferable pre-trained\nmodel to reduce the variance of generative modeling with limited data.\nFormally, Reg-DGM optimizes a weighted sum of a certain divergence and the\nexpectation of an energy function, where the divergence is between the data and\nthe model distributions, and the energy function is defined by the pre-trained\nmodel w.r.t. the model distribution. We analyze a simple yet representative\nGaussian-fitting case to demonstrate how the weighting hyperparameter trades\noff the bias and the variance. Theoretically, we characterize the existence and\nthe uniqueness of the global minimum of Reg-DGM in a non-parametric setting and\nprove its convergence with neural networks trained by gradient-based methods.\nEmpirically, with various pre-trained feature extractors and a data-dependent\nenergy function, Reg-DGM consistently improves the generation performance of\nstrong DGMs with limited data and achieves competitive results to the\nstate-of-the-art methods. Our implementation is available at\nhttps://github.com/ML-GSAI/Reg-ADA-APA.", "published": "2022-08-30T10:28:50Z", "version": 3}, {"aid": "2208.14360", "authors": ["Mostafa Mehdipour Ghazi", "Mads Nielsen"], "title": "FAST-AID Brain: Fast and Accurate Segmentation Tool using Artificial Intelligence Developed for Brain", "url": "http://arxiv.org/pdf/2208.14360v1", "summary": "Medical images used in clinical practice are heterogeneous and not the same\nquality as scans studied in academic research. Preprocessing breaks down in\nextreme cases when anatomy, artifacts, or imaging parameters are unusual or\nprotocols are different. Methods robust to these variations are most needed. A\nnovel deep learning method is proposed for fast and accurate segmentation of\nthe human brain into 132 regions. The proposed model uses an efficient\nU-Net-like network and benefits from the intersection points of different views\nand hierarchical relations for the fusion of the orthogonal 2D planes and brain\nlabels during the end-to-end training. Weakly supervised learning is deployed\nto take the advantage of partially labeled data for the whole brain\nsegmentation and estimation of the intracranial volume (ICV). Moreover, data\naugmentation is used to expand the magnetic resonance imaging (MRI) data by\ngenerating realistic brain scans with high variability for robust training of\nthe model while preserving data privacy. The proposed method can be applied to\nbrain MRI data including skull or any other artifacts without preprocessing the\nimages or a drop in performance. Several experiments using different atlases\nare conducted to evaluate the segmentation performance of the trained model\ncompared to the state-of-the-art, and the results show higher segmentation\naccuracy and robustness of the proposed model compared to the existing methods\nacross different intra- and inter-domain datasets.", "published": "2022-08-30T16:06:07Z", "version": 1}, {"aid": "2208.14699", "authors": ["Xingchao Liu", "Lemeng Wu", "Mao Ye", "Qiang Liu"], "title": "Let us Build Bridges: Understanding and Extending Diffusion Generative Models", "url": "http://arxiv.org/pdf/2208.14699v1", "summary": "Diffusion-based generative models have achieved promising results recently,\nbut raise an array of open questions in terms of conceptual understanding,\ntheoretical analysis, algorithm improvement and extensions to discrete,\nstructured, non-Euclidean domains. This work tries to re-exam the overall\nframework, in order to gain better theoretical understandings and develop\nalgorithmic extensions for data from arbitrary domains. By viewing diffusion\nmodels as latent variable models with unobserved diffusion trajectories and\napplying maximum likelihood estimation (MLE) with latent trajectories imputed\nfrom an auxiliary distribution, we show that both the model construction and\nthe imputation of latent trajectories amount to constructing diffusion bridge\nprocesses that achieve deterministic values and constraints at end point, for\nwhich we provide a systematic study and a suit of tools. Leveraging our\nframework, we present 1) a first theoretical error analysis for learning\ndiffusion generation models, and 2) a simple and unified approach to learning\non data from different discrete and constrained domains. Experiments show that\nour methods perform superbly on generating images, semantic segments and 3D\npoint clouds.", "published": "2022-08-31T08:58:10Z", "version": 1}, {"aid": "2208.14706", "authors": ["Zhaowen Li", "Xu Zhao", "Chaoyang Zhao", "Ming Tang", "Jinqiao Wang"], "title": "Transfering Low-Frequency Features for Domain Adaptation", "url": "http://arxiv.org/pdf/2208.14706v1", "summary": "Previous unsupervised domain adaptation methods did not handle the\ncross-domain problem from the perspective of frequency for computer vision. The\nimages or feature maps of different domains can be decomposed into the\nlow-frequency component and high-frequency component. This paper proposes the\nassumption that low-frequency information is more domain-invariant while the\nhigh-frequency information contains domain-related information. Hence, we\nintroduce an approach, named low-frequency module (LFM), to extract\ndomain-invariant feature representations. The LFM is constructed with the\ndigital Gaussian low-pass filter. Our method is easy to implement and\nintroduces no extra hyperparameter. We design two effective ways to utilize the\nLFM for domain adaptation, and our method is complementary to other existing\nmethods and formulated as a plug-and-play unit that can be combined with these\nmethods. Experimental results demonstrate that our LFM outperforms\nstate-of-the-art methods for various computer vision tasks, including image\nclassification and object detection.", "published": "2022-08-31T09:13:25Z", "version": 1}, {"aid": "2208.14784", "authors": ["Junqi Tang", "Guixian Xu", "Subhadip Mukherjee", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Practical Operator Sketching Framework for Accelerating Iterative Data-Driven Solutions in Inverse Problems", "url": "http://arxiv.org/pdf/2208.14784v2", "summary": "We propose a new operator-sketching paradigm for designing efficient\niterative data-driven reconstruction (IDR) schemes, e.g. Plug-and-Play\nalgorithms and deep unrolling networks. These IDR schemes are currently the\nstate-of-the-art solutions for imaging inverse problems. However, for\nhigh-dimensional imaging tasks, especially X-ray CT and MRI imaging, these IDR\nschemes typically become inefficient both in terms of computation, due to the\nneed of computing multiple times the high-dimensional forward and adjoint\noperators. In this work, we explore and propose a universal dimensionality\nreduction framework for accelerating IDR schemes in solving imaging inverse\nproblems, based on leveraging the sketching techniques from stochastic\noptimization. Using this framework, we derive a number of accelerated IDR\nschemes, such as the plug-and-play multi-stage sketched gradient (PnP-MS2G) and\nsketching-based primal-dual (LSPD and Sk-LSPD) deep unrolling networks.\nMeanwhile, for fully accelerating PnP schemes when the denoisers are\ncomputationally expensive, we provide novel stochastic lazy denoising schemes\n(Lazy-PnP and Lazy-PnP-EQ), leveraging the ProxSkip scheme in optimization and\nequivariant image denoisers, which can massively accelerate the PnP algorithms\nwith improved practicality. We provide theoretical analysis for recovery\nguarantees of instances of the proposed framework. Our numerical experiments on\nnatural image processing and tomographic image reconstruction demonstrate the\nremarkable effectiveness of our sketched IDR schemes.", "published": "2022-08-31T11:45:21Z", "version": 2}, {"aid": "2209.00232", "authors": ["Pourya Shamsolmoali", "Masoumeh Zareapoor", "Swagatam Das", "Eric Granger", "Salvador Garcia"], "title": "Hybrid Gromov-Wasserstein Embedding for Capsule Learning", "url": "http://arxiv.org/pdf/2209.00232v2", "summary": "Capsule networks (CapsNets) aim to parse images into a hierarchy of objects,\nparts, and their relations using a two-step process involving part-whole\ntransformation and hierarchical component routing. However, this hierarchical\nrelationship modeling is computationally expensive, which has limited the wider\nuse of CapsNet despite its potential advantages. The current state of CapsNet\nmodels primarily focuses on comparing their performance with capsule baselines,\nfalling short of achieving the same level of proficiency as deep CNN variants\nin intricate tasks. To address this limitation, we present an efficient\napproach for learning capsules that surpasses canonical baseline models and\neven demonstrates superior performance compared to high-performing convolution\nmodels. Our contribution can be outlined in two aspects: firstly, we introduce\na group of subcapsules onto which an input vector is projected. Subsequently,\nwe present the Hybrid Gromov-Wasserstein framework, which initially quantifies\nthe dissimilarity between the input and the components modeled by the\nsubcapsules, followed by determining their alignment degree through optimal\ntransport. This innovative mechanism capitalizes on new insights into defining\nalignment between the input and subcapsules, based on the similarity of their\nrespective component distributions. This approach enhances CapsNets' capacity\nto learn from intricate, high-dimensional data while retaining their\ninterpretability and hierarchical structure. Our proposed model offers two\ndistinct advantages: (i) its lightweight nature facilitates the application of\ncapsules to more intricate vision tasks, including object detection; (ii) it\noutperforms baseline approaches in these demanding tasks.", "published": "2022-09-01T05:26:32Z", "version": 2}, {"aid": "2209.00796", "authors": ["Ling Yang", "Zhilong Zhang", "Yang Song", "Shenda Hong", "Runsheng Xu", "Yue Zhao", "Wentao Zhang", "Bin Cui", "Ming-Hsuan Yang"], "title": "Diffusion Models: A Comprehensive Survey of Methods and Applications", "url": "http://arxiv.org/pdf/2209.00796v14", "summary": "Diffusion models have emerged as a powerful new family of deep generative\nmodels with record-breaking performance in many applications, including image\nsynthesis, video generation, and molecule design. In this survey, we provide an\noverview of the rapidly expanding body of work on diffusion models,\ncategorizing the research into three key areas: efficient sampling, improved\nlikelihood estimation, and handling data with special structures. We also\ndiscuss the potential for combining diffusion models with other generative\nmodels for enhanced results. We further review the wide-ranging applications of\ndiffusion models in fields spanning from computer vision, natural language\ngeneration, temporal data modeling, to interdisciplinary applications in other\nscientific disciplines. This survey aims to provide a contextualized, in-depth\nlook at the state of diffusion models, identifying the key areas of focus and\npointing to potential areas for further exploration. Github:\nhttps://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.", "published": "2022-09-02T02:59:10Z", "version": 14}, {"aid": "2209.01398", "authors": ["Zitai Wang", "Qianqian Xu", "Zhiyong Yang", "Yuan He", "Xiaochun Cao", "Qingming Huang"], "title": "Optimizing Partial Area Under the Top-k Curve: Theory and Practice", "url": "http://arxiv.org/pdf/2209.01398v1", "summary": "Top-k error has become a popular metric for large-scale classification\nbenchmarks due to the inevitable semantic ambiguity among classes. Existing\nliterature on top-k optimization generally focuses on the optimization method\nof the top-k objective, while ignoring the limitations of the metric itself. In\nthis paper, we point out that the top-k objective lacks enough discrimination\nsuch that the induced predictions may give a totally irrelevant label a top\nrank. To fix this issue, we develop a novel metric named partial Area Under the\ntop-k Curve (AUTKC). Theoretical analysis shows that AUTKC has a better\ndiscrimination ability, and its Bayes optimal score function could give a\ncorrect top-K ranking with respect to the conditional probability. This shows\nthat AUTKC does not allow irrelevant labels to appear in the top list.\nFurthermore, we present an empirical surrogate risk minimization framework to\noptimize the proposed metric. Theoretically, we present (1) a sufficient\ncondition for Fisher consistency of the Bayes optimal score function; (2) a\ngeneralization upper bound which is insensitive to the number of classes under\na simple hyperparameter setting. Finally, the experimental results on four\nbenchmark datasets validate the effectiveness of our proposed framework.", "published": "2022-09-03T11:09:13Z", "version": 1}, {"aid": "2209.02567", "authors": ["Alex B. Kiefer", "Beren Millidge", "Alexander Tschantz", "Christopher L. Buckley"], "title": "Capsule Networks as Generative Models", "url": "http://arxiv.org/pdf/2209.02567v2", "summary": "Capsule networks are a neural network architecture specialized for visual\nscene recognition. Features and pose information are extracted from a scene and\nthen dynamically routed through a hierarchy of vector-valued nodes called\n'capsules' to create an implicit scene graph, with the ultimate aim of learning\nvision directly as inverse graphics. Despite these intuitions, however, capsule\nnetworks are not formulated as explicit probabilistic generative models;\nmoreover, the routing algorithms typically used are ad-hoc and primarily\nmotivated by algorithmic intuition. In this paper, we derive an alternative\ncapsule routing algorithm utilizing iterative inference under sparsity\nconstraints. We then introduce an explicit probabilistic generative model for\ncapsule networks based on the self-attention operation in transformer networks\nand show how it is related to a variant of predictive coding networks using\nVon-Mises-Fisher (VMF) circular Gaussian distributions.", "published": "2022-09-06T15:21:28Z", "version": 2}, {"aid": "2209.03355", "authors": ["Simone Angarano", "Francesco Salvetti", "Mauro Martini", "Marcello Chiaberge"], "title": "Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation", "url": "http://arxiv.org/pdf/2209.03355v2", "summary": "Single-Image Super-Resolution can support robotic tasks in environments where\na reliable visual stream is required to monitor the mission, handle\nteleoperation or study relevant visual details. In this work, we propose an\nefficient Generative Adversarial Network model for real-time Super-Resolution,\ncalled EdgeSRGAN (code available at https://github.com/PIC4SeR/EdgeSRGAN). We\nadopt a tailored architecture of the original SRGAN and model quantization to\nboost the execution on CPU and Edge TPU devices, achieving up to 200 fps\ninference. We further optimize our model by distilling its knowledge to a\nsmaller version of the network and obtain remarkable improvements compared to\nthe standard training approach. Our experiments show that our fast and\nlightweight model preserves considerably satisfying image quality compared to\nheavier state-of-the-art models. Finally, we conduct experiments on image\ntransmission with bandwidth degradation to highlight the advantages of the\nproposed system for mobile robotic applications.", "published": "2022-09-07T10:58:41Z", "version": 2}, {"aid": "2209.03456", "authors": ["Mohammad Saeed Ebrahimi Saadabadi", "Sahar Rahimi Malakshan", "Sobhan Soleymani", "Moktari Mostofa", "Nasser M. Nasrabadi"], "title": "Information Maximization for Extreme Pose Face Recognition", "url": "http://arxiv.org/pdf/2209.03456v1", "summary": "In this paper, we seek to draw connections between the frontal and profile\nface images in an abstract embedding space. We exploit this connection using a\ncoupled-encoder network to project frontal/profile face images into a common\nlatent embedding space. The proposed model forces the similarity of\nrepresentations in the embedding space by maximizing the mutual information\nbetween two views of the face. The proposed coupled-encoder benefits from three\ncontributions for matching faces with extreme pose disparities. First, we\nleverage our pose-aware contrastive learning to maximize the mutual information\nbetween frontal and profile representations of identities. Second, a memory\nbuffer, which consists of latent representations accumulated over past\niterations, is integrated into the model so it can refer to relatively much\nmore instances than the mini-batch size. Third, a novel pose-aware adversarial\ndomain adaptation method forces the model to learn an asymmetric mapping from\nprofile to frontal representation. In our framework, the coupled-encoder learns\nto enlarge the margin between the distribution of genuine and imposter faces,\nwhich results in high mutual information between different views of the same\nidentity. The effectiveness of the proposed model is investigated through\nextensive experiments, evaluations, and ablation studies on four benchmark\ndatasets, and comparison with the compelling state-of-the-art algorithms.", "published": "2022-09-07T20:30:06Z", "version": 1}, {"aid": "2209.03704", "authors": ["Vijay Srinivas Tida", "Sai Venkatesh Chilukoti", "Xiali Hei", "Sonya Hsu"], "title": "Kernel-Segregated Transpose Convolution Operation", "url": "http://arxiv.org/pdf/2209.03704v3", "summary": "Transpose convolution has shown prominence in many deep learning\napplications. However, transpose convolution layers are computationally\nintensive due to the increased feature map size due to adding zeros after each\nelement in each row and column. Thus, convolution operation on the expanded\ninput feature map leads to poor utilization of hardware resources. The main\nreason for unnecessary multiplication operations is zeros at predefined\npositions in the input feature map. We propose an algorithmic-level\noptimization technique for the effective transpose convolution implementation\nto solve these problems. Based on kernel activations, we segregated the\noriginal kernel into four sub-kernels. This scheme could reduce memory\nrequirements and unnecessary multiplications. Our proposed method was $3.09\n(3.02) \\times$ faster computation using the Titan X GPU (Intel Dual Core CPU)\nwith a flower dataset from the Kaggle website. Furthermore, the proposed\noptimization method can be generalized to existing devices without additional\nhardware requirements. A simple deep learning model containing one transpose\nconvolution layer was used to evaluate the optimization method. It showed $2.2\n\\times$ faster training using the MNIST dataset with an Intel Dual-core CPU\nthan the conventional implementation.", "published": "2022-09-08T10:42:49Z", "version": 3}, {"aid": "2209.03793", "authors": ["Bowen Li", "Thomas Lukasiewicz"], "title": "Lightweight Long-Range Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2209.03793v1", "summary": "In this paper, we introduce novel lightweight generative adversarial\nnetworks, which can effectively capture long-range dependencies in the image\ngeneration process, and produce high-quality results with a much simpler\narchitecture. To achieve this, we first introduce a long-range module, allowing\nthe network to dynamically adjust the number of focused sampling pixels and to\nalso augment sampling locations. Thus, it can break the limitation of the fixed\ngeometric structure of the convolution operator, and capture long-range\ndependencies in both spatial and channel-wise directions. Also, the proposed\nlong-range module can highlight negative relations between pixels, working as a\nregularization to stabilize training. Furthermore, we propose a new generation\nstrategy through which we introduce metadata into the image generation process\nto provide basic information about target images, which can stabilize and speed\nup the training process. Our novel long-range module only introduces few\nadditional parameters and is easily inserted into existing models to capture\nlong-range dependencies. Extensive experiments demonstrate the competitive\nperformance of our method with a lightweight architecture.", "published": "2022-09-08T13:05:01Z", "version": 1}, {"aid": "2209.04049", "authors": ["Masataro Asai"], "title": "Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics", "url": "http://arxiv.org/pdf/2209.04049v8", "summary": "The symbolic AI community is increasingly trying to embrace machine learning\nin neuro-symbolic architectures, yet is still struggling due to cultural\nbarriers. To break the barrier, this rather opinionated personal memo attempts\nto explain and rectify the conventions in Statistics, Machine Learning, and\nDeep Learning from the viewpoint of outsiders. It provides a step-by-step\nprotocol for designing a machine learning system that satisfies a minimum\ntheoretical guarantee necessary for being taken seriously by the symbolic AI\ncommunity, i.e., it discusses \"in what condition we can stop worrying and\naccept statistical machine learning.\" Unlike most textbooks which are written\nfor students trying to specialize in Stat/ML/DL and willing to accept jargons,\nthis memo is written for experienced symbolic researchers that hear a lot of\nbuzz but are still uncertain and skeptical. Information on Stat/ML/DL is\ncurrently too scattered or too noisy to invest in. This memo prioritizes\ncompactness, citations to old papers (many in early 20th century), and concepts\nthat resonate well with symbolic paradigms in order to offer time savings. It\nprioritizes general mathematical modeling and does not discuss any specific\nfunction approximator, such as neural networks (NNs), SVMs, decision trees,\netc. Finally, it is open to corrections. Consider this memo as something\nsimilar to a blog post taking the form of a paper on Arxiv.", "published": "2022-09-08T22:15:20Z", "version": 8}, {"aid": "2209.05442", "authors": ["Giannis Daras", "Mauricio Delbracio", "Hossein Talebi", "Alexandros G. Dimakis", "Peyman Milanfar"], "title": "Soft Diffusion: Score Matching for General Corruptions", "url": "http://arxiv.org/pdf/2209.05442v2", "summary": "We define a broader family of corruption processes that generalizes\npreviously known diffusion models. To reverse these general diffusions, we\npropose a new objective called Soft Score Matching that provably learns the\nscore function for any linear corruption process and yields state of the art\nresults for CelebA. Soft Score Matching incorporates the degradation process in\nthe network. Our new loss trains the model to predict a clean image,\n\\textit{that after corruption}, matches the diffused observation. We show that\nour objective learns the gradient of the likelihood under suitable regularity\nconditions for a family of corruption processes. We further develop a\nprincipled way to select the corruption levels for general diffusion processes\nand a novel sampling method that we call Momentum Sampler. We show\nexperimentally that our framework works for general linear corruption\nprocesses, such as Gaussian blur and masking. We achieve state-of-the-art FID\nscore $1.85$ on CelebA-64, outperforming all previous linear diffusion models.\nWe also show significant computational benefits compared to vanilla denoising\ndiffusion.", "published": "2022-09-12T17:45:03Z", "version": 2}, {"aid": "2209.05557", "authors": ["Emiel Hoogeboom", "Tim Salimans"], "title": "Blurring Diffusion Models", "url": "http://arxiv.org/pdf/2209.05557v3", "summary": "Recently, Rissanen et al., (2022) have presented a new type of diffusion\nprocess for generative modeling based on heat dissipation, or blurring, as an\nalternative to isotropic Gaussian diffusion. Here, we show that blurring can\nequivalently be defined through a Gaussian diffusion process with non-isotropic\nnoise. In making this connection, we bridge the gap between inverse heat\ndissipation and denoising diffusion, and we shed light on the inductive bias\nthat results from this modeling choice. Finally, we propose a generalized class\nof diffusion models that offers the best of both standard Gaussian denoising\ndiffusion and inverse heat dissipation, which we call Blurring Diffusion\nModels.", "published": "2022-09-12T19:16:48Z", "version": 3}, {"aid": "2209.05732", "authors": ["Weipeng Huang", "Junjie Tao", "Changbo Deng", "Ming Fan", "Wenqiang Wan", "Qi Xiong", "Guangyuan Piao"], "title": "R\u00e9nyi Divergence Deep Mutual Learning", "url": "http://arxiv.org/pdf/2209.05732v7", "summary": "This paper revisits Deep Mutual Learning (DML), a simple yet effective\ncomputing paradigm. We propose using R\\'{e}nyi divergence instead of the KL\ndivergence, which is more flexible and tunable, to improve vanilla DML. This\nmodification is able to consistently improve performance over vanilla DML with\nlimited additional complexity. The convergence properties of the proposed\nparadigm are analyzed theoretically, and Stochastic Gradient Descent with a\nconstant learning rate is shown to converge with $\\mathcal{O}(1)$-bias in the\nworst case scenario for nonconvex optimization tasks. That is, learning will\nreach nearby local optima but continue searching within a bounded scope, which\nmay help mitigate overfitting. Finally, our extensive empirical results\ndemonstrate the advantage of combining DML and R\\'{e}nyi divergence, leading to\nfurther improvement in model generalization.", "published": "2022-09-13T04:58:35Z", "version": 7}, {"aid": "2209.06168", "authors": ["Lewis Belcher", "Johan Gudmundsson", "Michael Green"], "title": "Borch: A Deep Universal Probabilistic Programming Language", "url": "http://arxiv.org/pdf/2209.06168v1", "summary": "Ever since the Multilayered Perceptron was first introduced the connectionist\ncommunity has struggled with the concept of uncertainty and how this could be\nrepresented in these types of models. This past decade has seen a lot of effort\nin trying to join the principled approach of probabilistic modeling with the\nscalable nature of deep neural networks. While the theoretical benefits of this\nconsolidation are clear, there are also several important practical aspects of\nthese endeavors; namely to force the models we create to represent, learn, and\nreport uncertainty in every prediction that is made. Many of these efforts have\nbeen based on extending existing frameworks with additional structures. We\npresent Borch, a scalable deep universal probabilistic programming language,\nbuilt on top of PyTorch. The code is available for download and use in our\nrepository https://gitlab.com/desupervised/borch.", "published": "2022-09-13T17:18:01Z", "version": 1}, {"aid": "2209.06383", "authors": ["Lingran Zhao", "Zhen Dong", "Kurt Keutzer"], "title": "Analysis of Quantization on MLP-based Vision Models", "url": "http://arxiv.org/pdf/2209.06383v1", "summary": "Quantization is wildly taken as a model compression technique, which obtains\nefficient models by converting floating-point weights and activations in the\nneural network into lower-bit integers. Quantization has been proven to work\nwell on convolutional neural networks and transformer-based models. Despite the\ndecency of these models, recent works have shown that MLP-based models are able\nto achieve comparable results on various tasks ranging from computer vision,\nNLP to 3D point cloud, while achieving higher throughput due to the parallelism\nand network simplicity. However, as we show in the paper, directly applying\nquantization to MLP-based models will lead to significant accuracy degradation.\nBased on our analysis, two major issues account for the accuracy gap: 1) the\nrange of activations in MLP-based models can be too large to quantize, and 2)\nspecific components in the MLP-based models are sensitive to quantization.\nConsequently, we propose to 1) apply LayerNorm to control the quantization\nrange of activations, 2) utilize bounded activation functions, 3) apply\npercentile quantization on activations, 4) use our improved module named\nmultiple token-mixing MLPs, and 5) apply linear asymmetric quantizer for\nsensitive operations. Equipped with the abovementioned techniques, our Q-MLP\nmodels can achieve 79.68% accuracy on ImageNet with 8-bit uniform quantization\n(model size 30 MB) and 78.47% with 4-bit quantization (15 MB).", "published": "2022-09-14T02:55:57Z", "version": 1}, {"aid": "2209.06823", "authors": ["Yonglong Jiang", "Liangliang Li", "Yuan Xue", "Hongbing Ma"], "title": "DEANet: Decomposition Enhancement and Adjustment Network for Low-Light Image Enhancement", "url": "http://arxiv.org/pdf/2209.06823v1", "summary": "Images obtained under low-light conditions will seriously affect the quality\nof the images. Solving the problem of poor low-light image quality can\neffectively improve the visual quality of images and better improve the\nusability of computer vision. In addition, it has very important applications\nin many fields. This paper proposes a DEANet based on Retinex for low-light\nimage enhancement. It combines the frequency information and content\ninformation of the image into three sub-networks: decomposition network,\nenhancement network and adjustment network. These three sub-networks are\nrespectively used for decomposition, denoising, contrast enhancement and detail\npreservation, adjustment, and image generation. Our model has good robust\nresults for all low-light images. The model is trained on the public data set\nLOL, and the experimental results show that our method is better than the\nexisting state-of-the-art methods in terms of vision and quality.", "published": "2022-09-14T03:01:55Z", "version": 1}, {"aid": "2209.06405", "authors": ["Xiaomeng Wu", "Takahito Kawanishi", "Kunio Kashino"], "title": "Reflectance-Guided, Contrast-Accumulated Histogram Equalization", "url": "http://arxiv.org/pdf/2209.06405v1", "summary": "Existing image enhancement methods fall short of expectations because with\nthem it is difficult to improve global and local image contrast simultaneously.\nTo address this problem, we propose a histogram equalization-based method that\nadapts to the data-dependent requirements of brightness enhancement and\nimproves the visibility of details without losing the global contrast. This\nmethod incorporates the spatial information provided by image context in\ndensity estimation for discriminative histogram equalization. To minimize the\nadverse effect of non-uniform illumination, we propose defining spatial\ninformation on the basis of image reflectance estimated with edge preserving\nsmoothing. Our method works particularly well for determining how the\nbackground brightness should be adaptively adjusted and for revealing useful\nimage details hidden in the dark.", "published": "2022-09-14T04:14:30Z", "version": 1}, {"aid": "2209.07659", "authors": ["Fang Chen", "Gourav Datta", "Souvik Kundu", "Peter Beerel"], "title": "Self-Attentive Pooling for Efficient Deep Learning", "url": "http://arxiv.org/pdf/2209.07659v3", "summary": "Efficient custom pooling techniques that can aggressively trim the dimensions\nof a feature map and thereby reduce inference compute and memory footprint for\nresource-constrained computer vision applications have recently gained\nsignificant traction. However, prior pooling works extract only the local\ncontext of the activation maps, limiting their effectiveness. In contrast, we\npropose a novel non-local self-attentive pooling method that can be used as a\ndrop-in replacement to the standard pooling layers, such as max/average pooling\nor strided convolution. The proposed self-attention module uses patch\nembedding, multi-head self-attention, and spatial-channel restoration, followed\nby sigmoid activation and exponential soft-max. This self-attention mechanism\nefficiently aggregates dependencies between non-local activation patches during\ndown-sampling. Extensive experiments on standard object classification and\ndetection tasks with various convolutional neural network (CNN) architectures\ndemonstrate the superiority of our proposed mechanism over the state-of-the-art\n(SOTA) pooling techniques. In particular, we surpass the test accuracy of\nexisting pooling techniques on different variants of MobileNet-V2 on ImageNet\nby an average of 1.2%. With the aggressive down-sampling of the activation maps\nin the initial layers (providing up to 22x reduction in memory consumption),\nour approach achieves 1.43% higher test accuracy compared to SOTA techniques\nwith iso-memory footprints. This enables the deployment of our models in\nmemory-constrained devices, such as micro-controllers (without losing\nsignificant accuracy), because the initial activation maps consume a\nsignificant amount of on-chip memory for high-resolution images required for\ncomplex vision tasks. Our proposed pooling method also leverages the idea of\nchannel pruning to further reduce memory footprints.", "published": "2022-09-16T00:35:14Z", "version": 3}, {"aid": "2209.07738", "authors": ["Zimian Wei", "Hengyue Pan", "Lujun Li", "Menglong Lu", "Xin Niu", "Peijie Dong", "Dongsheng Li"], "title": "DMFormer: Closing the Gap Between CNN and Vision Transformers", "url": "http://arxiv.org/pdf/2209.07738v3", "summary": "Vision transformers have shown excellent performance in computer vision\ntasks. As the computation cost of their self-attention mechanism is expensive,\nrecent works tried to replace the self-attention mechanism in vision\ntransformers with convolutional operations, which is more efficient with\nbuilt-in inductive bias. However, these efforts either ignore multi-level\nfeatures or lack dynamic prosperity, leading to sub-optimal performance. In\nthis paper, we propose a Dynamic Multi-level Attention mechanism (DMA), which\ncaptures different patterns of input images by multiple kernel sizes and\nenables input-adaptive weights with a gating mechanism. Based on DMA, we\npresent an efficient backbone network named DMFormer. DMFormer adopts the\noverall architecture of vision transformers, while replacing the self-attention\nmechanism with our proposed DMA. Extensive experimental results on ImageNet-1K\nand ADE20K datasets demonstrated that DMFormer achieves state-of-the-art\nperformance, which outperforms similar-sized vision transformers(ViTs) and\nconvolutional neural networks (CNNs).", "published": "2022-09-16T06:45:01Z", "version": 3}, {"aid": "2209.07947", "authors": ["Chao Li", "Aojun Zhou", "Anbang Yao"], "title": "Omni-Dimensional Dynamic Convolution", "url": "http://arxiv.org/pdf/2209.07947v1", "summary": "Learning a single static convolutional kernel in each convolutional layer is\nthe common training paradigm of modern Convolutional Neural Networks (CNNs).\nInstead, recent research in dynamic convolution shows that learning a linear\ncombination of $n$ convolutional kernels weighted with their input-dependent\nattentions can significantly improve the accuracy of light-weight CNNs, while\nmaintaining efficient inference. However, we observe that existing works endow\nconvolutional kernels with the dynamic property through one dimension\n(regarding the convolutional kernel number) of the kernel space, but the other\nthree dimensions (regarding the spatial size, the input channel number and the\noutput channel number for each convolutional kernel) are overlooked. Inspired\nby this, we present Omni-dimensional Dynamic Convolution (ODConv), a more\ngeneralized yet elegant dynamic convolution design, to advance this line of\nresearch. ODConv leverages a novel multi-dimensional attention mechanism with a\nparallel strategy to learn complementary attentions for convolutional kernels\nalong all four dimensions of the kernel space at any convolutional layer. As a\ndrop-in replacement of regular convolutions, ODConv can be plugged into many\nCNN architectures. Extensive experiments on the ImageNet and MS-COCO datasets\nshow that ODConv brings solid accuracy boosts for various prevailing CNN\nbackbones including both light-weight and large ones, e.g.,\n3.77%~5.71%|1.86%~3.72% absolute top-1 improvements to MobivleNetV2|ResNet\nfamily on the ImageNet dataset. Intriguingly, thanks to its improved feature\nlearning ability, ODConv with even one single kernel can compete with or\noutperform existing dynamic convolution counterparts with multiple kernels,\nsubstantially reducing extra parameters. Furthermore, ODConv is also superior\nto other attention modules for modulating the output features or the\nconvolutional weights.", "published": "2022-09-16T14:05:38Z", "version": 1}, {"aid": "2209.09422", "authors": ["Tongda Xu", "Han Gao", "Chenjian Gao", "Yuanyuan Wang", "Dailan He", "Jinyong Pi", "Jixiang Luo", "Ziyu Zhu", "Mao Ye", "Hongwei Qin", "Yan Wang", "Jingjing Liu", "Ya-Qin Zhang"], "title": "Bit Allocation using Optimization", "url": "http://arxiv.org/pdf/2209.09422v5", "summary": "In this paper, we consider the problem of bit allocation in Neural Video\nCompression (NVC). First, we reveal a fundamental relationship between bit\nallocation in NVC and Semi-Amortized Variational Inference (SAVI).\nSpecifically, we show that SAVI with GoP (Group-of-Picture)-level likelihood is\nequivalent to pixel-level bit allocation with precise rate \\& quality\ndependency model. Based on this equivalence, we establish a new paradigm of bit\nallocation using SAVI. Different from previous bit allocation methods, our\napproach requires no empirical model and is thus optimal. Moreover, as the\noriginal SAVI using gradient ascent only applies to single-level latent, we\nextend the SAVI to multi-level such as NVC by recursively applying\nback-propagating through gradient ascent. Finally, we propose a tractable\napproximation for practical implementation. Our method can be applied to\nscenarios where performance outweights encoding speed, and serves as an\nempirical bound on the R-D performance of bit allocation. Experimental results\nshow that current state-of-the-art bit allocation algorithms still have a room\nof $\\approx 0.5$ dB PSNR to improve compared with ours. Code is available at\n\\url{https://github.com/tongdaxu/Bit-Allocation-Using-Optimization}.", "published": "2022-09-20T02:40:52Z", "version": 5}, {"aid": "2209.10512", "authors": ["Marius Millea"], "title": "Improved Marginal Unbiased Score Expansion (MUSE) via Implicit Differentiation", "url": "http://arxiv.org/pdf/2209.10512v1", "summary": "We apply the technique of implicit differentiation to boost performance,\nreduce numerical error, and remove required user-tuning in the Marginal\nUnbiased Score Expansion (MUSE) algorithm for hierarchical Bayesian inference.\nWe demonstrate these improvements on three representative inference problems:\n1) an extended Neal's funnel 2) Bayesian neural networks, and 3) probabilistic\nprincipal component analysis. On our particular test cases, MUSE with implicit\ndifferentiation is faster than Hamiltonian Monte Carlo by factors of 155, 397,\nand 5, respectively, or factors of 65, 278, and 1 without implicit\ndifferentiation, and yields good approximate marginal posteriors. The Julia and\nPython MUSE packages have been updated to use implicit differentiation, and can\nsolve problems defined by hand or with any of a number of popular probabilistic\nprogramming languages and automatic differentiation backends.", "published": "2022-09-21T17:20:20Z", "version": 1}, {"aid": "2209.11178", "authors": ["Yilun Xu", "Ziming Liu", "Max Tegmark", "Tommi Jaakkola"], "title": "Poisson Flow Generative Models", "url": "http://arxiv.org/pdf/2209.11178v4", "summary": "We propose a new \"Poisson flow\" generative model (PFGM) that maps a uniform\ndistribution on a high-dimensional hemisphere into any data distribution. We\ninterpret the data points as electrical charges on the $z=0$ hyperplane in a\nspace augmented with an additional dimension $z$, generating a high-dimensional\nelectric field (the gradient of the solution to Poisson equation). We prove\nthat if these charges flow upward along electric field lines, their initial\ndistribution in the $z=0$ plane transforms into a distribution on the\nhemisphere of radius $r$ that becomes uniform in the $r \\to\\infty$ limit. To\nlearn the bijective transformation, we estimate the normalized field in the\naugmented space. For sampling, we devise a backward ODE that is anchored by the\nphysically meaningful additional dimension: the samples hit the unaugmented\ndata manifold when the $z$ reaches zero. Experimentally, PFGM achieves current\nstate-of-the-art performance among the normalizing flow models on CIFAR-10,\nwith an Inception score of $9.68$ and a FID score of $2.35$. It also performs\non par with the state-of-the-art SDE approaches while offering $10\\times $ to\n$20 \\times$ acceleration on image generation tasks. Additionally, PFGM appears\nmore tolerant of estimation errors on a weaker network architecture and robust\nto the step size in the Euler method. The code is available at\nhttps://github.com/Newbeeer/poisson_flow .", "published": "2022-09-22T17:26:58Z", "version": 4}, {"aid": "2209.12753", "authors": ["Chen-Hao Chao", "Wei-Fang Sun", "Bo-Wun Cheng", "Chun-Yi Lee"], "title": "On Investigating the Conservative Property of Score-Based Generative Models", "url": "http://arxiv.org/pdf/2209.12753v3", "summary": "Existing Score-Based Models (SBMs) can be categorized into constrained SBMs\n(CSBMs) or unconstrained SBMs (USBMs) according to their parameterization\napproaches. CSBMs model probability density functions as Boltzmann\ndistributions, and assign their predictions as the negative gradients of some\nscalar-valued energy functions. On the other hand, USBMs employ flexible\narchitectures capable of directly estimating scores without the need to\nexplicitly model energy functions. In this paper, we demonstrate that the\narchitectural constraints of CSBMs may limit their modeling ability. In\naddition, we show that USBMs' inability to preserve the property of\nconservativeness may lead to degraded performance in practice. To address the\nabove issues, we propose Quasi-Conservative Score-Based Models (QCSBMs) for\nkeeping the advantages of both CSBMs and USBMs. Our theoretical derivations\ndemonstrate that the training objective of QCSBMs can be efficiently integrated\ninto the training processes by leveraging the Hutchinson's trace estimator. In\naddition, our experimental results on the CIFAR-10, CIFAR-100, ImageNet, and\nSVHN datasets validate the effectiveness of QCSBMs. Finally, we justify the\nadvantage of QCSBMs using an example of a one-layered autoencoder.", "published": "2022-09-26T15:00:18Z", "version": 3}, {"aid": "2209.13774", "authors": ["Chenlin Meng", "Linqi Zhou", "Kristy Choi", "Tri Dao", "Stefano Ermon"], "title": "ButterflyFlow: Building Invertible Layers with Butterfly Matrices", "url": "http://arxiv.org/pdf/2209.13774v1", "summary": "Normalizing flows model complex probability distributions using maps obtained\nby composing invertible layers. Special linear layers such as masked and 1x1\nconvolutions play a key role in existing architectures because they increase\nexpressive power while having tractable Jacobians and inverses. We propose a\nnew family of invertible linear layers based on butterfly layers, which are\nknown to theoretically capture complex linear structures including permutations\nand periodicity, yet can be inverted efficiently. This representational power\nis a key advantage of our approach, as such structures are common in many\nreal-world datasets. Based on our invertible butterfly layers, we construct a\nnew class of normalizing flow models called ButterflyFlow. Empirically, we\ndemonstrate that ButterflyFlows not only achieve strong density estimation\nresults on natural images such as MNIST, CIFAR-10, and ImageNet 32x32, but also\nobtain significantly better log-likelihoods on structured datasets such as\ngalaxy images and MIMIC-III patient cohorts -- all while being more efficient\nin terms of memory and computation than relevant baselines.", "published": "2022-09-28T01:58:18Z", "version": 1}, {"aid": "2209.13929", "authors": ["Man Yao", "Guangshe Zhao", "Hengyu Zhang", "Yifan Hu", "Lei Deng", "Yonghong Tian", "Bo Xu", "Guoqi Li"], "title": "Attention Spiking Neural Networks", "url": "http://arxiv.org/pdf/2209.13929v1", "summary": "Benefiting from the event-driven and sparse spiking characteristics of the\nbrain, spiking neural networks (SNNs) are becoming an energy-efficient\nalternative to artificial neural networks (ANNs). However, the performance gap\nbetween SNNs and ANNs has been a great hindrance to deploying SNNs ubiquitously\nfor a long time. To leverage the full potential of SNNs, we study the effect of\nattention mechanisms in SNNs. We first present our idea of attention with a\nplug-and-play kit, termed the Multi-dimensional Attention (MA). Then, a new\nattention SNN architecture with end-to-end training called \"MA-SNN\" is\nproposed, which infers attention weights along the temporal, channel, as well\nas spatial dimensions separately or simultaneously. Based on the existing\nneuroscience theories, we exploit the attention weights to optimize membrane\npotentials, which in turn regulate the spiking response in a data-dependent\nway. At the cost of negligible additional parameters, MA facilitates vanilla\nSNNs to achieve sparser spiking activity, better performance, and energy\nefficiency concurrently. Experiments are conducted in event-based DVS128\nGesture/Gait action recognition and ImageNet-1k image classification. On\nGesture/Gait, the spike counts are reduced by 84.9%/81.6%, and the task\naccuracy and energy efficiency are improved by 5.9%/4.7% and\n3.4$\\times$/3.2$\\times$. On ImageNet-1K, we achieve top-1 accuracy of 75.92%\nand 77.08% on single/4-step Res-SNN-104, which are state-of-the-art results in\nSNNs. To our best knowledge, this is for the first time, that the SNN community\nachieves comparable or even better performance compared with its ANN\ncounterpart in the large-scale dataset. Our work lights up SNN's potential as a\ngeneral backbone to support various applications for SNNs, with a great balance\nbetween effectiveness and efficiency.", "published": "2022-09-28T09:00:45Z", "version": 1}, {"aid": "2209.14593", "authors": ["Beomsu Kim", "Jong Chul Ye"], "title": "Denoising MCMC for Accelerating Diffusion-Based Generative Models", "url": "http://arxiv.org/pdf/2209.14593v1", "summary": "Diffusion models are powerful generative models that simulate the reverse of\ndiffusion processes using score functions to synthesize data from noise. The\nsampling process of diffusion models can be interpreted as solving the reverse\nstochastic differential equation (SDE) or the ordinary differential equation\n(ODE) of the diffusion process, which often requires up to thousands of\ndiscretization steps to generate a single image. This has sparked a great\ninterest in developing efficient integration techniques for reverse-S/ODEs.\nHere, we propose an orthogonal approach to accelerating score-based sampling:\nDenoising MCMC (DMCMC). DMCMC first uses MCMC to produce samples in the product\nspace of data and variance (or diffusion time). Then, a reverse-S/ODE\nintegrator is used to denoise the MCMC samples. Since MCMC traverses close to\nthe data manifold, the computation cost of producing a clean sample for DMCMC\nis much less than that of producing a clean sample from noise. To verify the\nproposed concept, we show that Denoising Langevin Gibbs (DLG), an instance of\nDMCMC, successfully accelerates all six reverse-S/ODE integrators considered in\nthis work on the tasks of CIFAR10 and CelebA-HQ-256 image generation. Notably,\ncombined with integrators of Karras et al. (2022) and pre-trained score models\nof Song et al. (2021b), DLG achieves SOTA results. In the limited number of\nscore function evaluation (NFE) settings on CIFAR10, we have $3.86$ FID with\n$\\approx 10$ NFE and $2.63$ FID with $\\approx 20$ NFE. On CelebA-HQ-256, we\nhave $6.99$ FID with $\\approx 160$ NFE, which beats the current best record of\nKim et al. (2022) among score-based models, $7.16$ FID with $4000$ NFE. Code:\nhttps://github.com/1202kbs/DMCMC", "published": "2022-09-29T07:16:10Z", "version": 1}, {"aid": "2209.14687", "authors": ["Hyungjin Chung", "Jeongsol Kim", "Michael T. Mccann", "Marc L. Klasky", "Jong Chul Ye"], "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems", "url": "http://arxiv.org/pdf/2209.14687v4", "summary": "Diffusion models have been recently studied as powerful generative inverse\nproblem solvers, owing to their high quality reconstructions and the ease of\ncombining existing iterative solvers. However, most works focus on solving\nsimple linear inverse problems in noiseless settings, which significantly\nunder-represents the complexity of real-world problems. In this work, we extend\ndiffusion solvers to efficiently handle general noisy (non)linear inverse\nproblems via approximation of the posterior sampling. Interestingly, the\nresulting posterior sampling scheme is a blended version of diffusion sampling\nwith the manifold constrained gradient without a strict measurement consistency\nprojection step, yielding a more desirable generative path in noisy settings\ncompared to the previous studies. Our method demonstrates that diffusion models\ncan incorporate various measurement noise statistics such as Gaussian and\nPoisson, and also efficiently handle noisy nonlinear inverse problems such as\nFourier phase retrieval and non-uniform deblurring. Code available at\nhttps://github.com/DPS2022/diffusion-posterior-sampling", "published": "2022-09-29T11:12:27Z", "version": 4}, {"aid": "2209.14751", "authors": ["Ulises Chialva", "Vicente Gonz\u00e1lez Bosc\u00e1", "Horacio G. Rotstein"], "title": "Low-dimensional models of single neurons: A review", "url": "http://arxiv.org/pdf/2209.14751v3", "summary": "The classical Hodgkin-Huxley (HH) point-neuron model of action potential\ngeneration is four-dimensional. It consists of four ordinary differential\nequations describing the dynamics of the membrane potential and three gating\nvariables associated to a transient sodium and a delayed-rectifier potassium\nionic currents. Conductance-based models of HH type are higher-dimensional\nextensions of the classical HH model. They include a number of supplementary\nstate variables associated with other ionic current types, and are able to\ndescribe additional phenomena such as sub-threshold oscillations, mixed-mode\noscillations (subthreshold oscillations interspersed with spikes), clustering\nand bursting. In this manuscript we discuss biophysically plausible and\nphenomenological reduced models that preserve the biophysical and/or dynamic\ndescription of models of HH type and the ability to produce complex phenomena,\nbut the number of effective dimensions (state variables) is lower. We describe\nseveral representative models. We also describe systematic and heuristic\nmethods of deriving reduced models from models of HH type.", "published": "2022-09-29T13:07:21Z", "version": 3}, {"aid": "2209.14778", "authors": ["Randall Balestriero", "Richard G. Baraniuk"], "title": "Batch Normalization Explained", "url": "http://arxiv.org/pdf/2209.14778v1", "summary": "A critically important, ubiquitous, and yet poorly understood ingredient in\nmodern deep networks (DNs) is batch normalization (BN), which centers and\nnormalizes the feature maps. To date, only limited progress has been made\nunderstanding why BN boosts DN learning and inference performance; work has\nfocused exclusively on showing that BN smooths a DN's loss landscape. In this\npaper, we study BN theoretically from the perspective of function\napproximation; we exploit the fact that most of today's state-of-the-art DNs\nare continuous piecewise affine (CPA) splines that fit a predictor to the\ntraining data via affine mappings defined over a partition of the input space\n(the so-called \"linear regions\"). {\\em We demonstrate that BN is an\nunsupervised learning technique that -- independent of the DN's weights or\ngradient-based learning -- adapts the geometry of a DN's spline partition to\nmatch the data.} BN provides a \"smart initialization\" that boosts the\nperformance of DN learning, because it adapts even a DN initialized with random\nweights to align its spline partition with the data. We also show that the\nvariation of BN statistics between mini-batches introduces a dropout-like\nrandom perturbation to the partition boundaries and hence the decision boundary\nfor classification problems. This per mini-batch perturbation reduces\noverfitting and improves generalization by increasing the margin between the\ntraining samples and the decision boundary.", "published": "2022-09-29T13:41:27Z", "version": 1}, {"aid": "2209.14855", "authors": ["Yuan Yin", "Matthieu Kirchmeyer", "Jean-Yves Franceschi", "Alain Rakotomamonjy", "Patrick Gallinari"], "title": "Continuous PDE Dynamics Forecasting with Implicit Neural Representations", "url": "http://arxiv.org/pdf/2209.14855v2", "summary": "Effective data-driven PDE forecasting methods often rely on fixed spatial and\n/ or temporal discretizations. This raises limitations in real-world\napplications like weather prediction where flexible extrapolation at arbitrary\nspatiotemporal locations is required. We address this problem by introducing a\nnew data-driven approach, DINo, that models a PDE's flow with continuous-time\ndynamics of spatially continuous functions. This is achieved by embedding\nspatial observations independently of their discretization via Implicit Neural\nRepresentations in a small latent space temporally driven by a learned ODE.\nThis separate and flexible treatment of time and space makes DINo the first\ndata-driven model to combine the following advantages. It extrapolates at\narbitrary spatial and temporal locations; it can learn from sparse irregular\ngrids or manifolds; at test time, it generalizes to new grids or resolutions.\nDINo outperforms alternative neural PDE forecasters in a variety of challenging\ngeneralization scenarios on representative PDE systems.", "published": "2022-09-29T15:17:50Z", "version": 2}, {"aid": "2209.14988", "authors": ["Ben Poole", "Ajay Jain", "Jonathan T. Barron", "Ben Mildenhall"], "title": "DreamFusion: Text-to-3D using 2D Diffusion", "url": "http://arxiv.org/pdf/2209.14988v1", "summary": "Recent breakthroughs in text-to-image synthesis have been driven by diffusion\nmodels trained on billions of image-text pairs. Adapting this approach to 3D\nsynthesis would require large-scale datasets of labeled 3D data and efficient\narchitectures for denoising 3D data, neither of which currently exist. In this\nwork, we circumvent these limitations by using a pretrained 2D text-to-image\ndiffusion model to perform text-to-3D synthesis. We introduce a loss based on\nprobability density distillation that enables the use of a 2D diffusion model\nas a prior for optimization of a parametric image generator. Using this loss in\na DeepDream-like procedure, we optimize a randomly-initialized 3D model (a\nNeural Radiance Field, or NeRF) via gradient descent such that its 2D\nrenderings from random angles achieve a low loss. The resulting 3D model of the\ngiven text can be viewed from any angle, relit by arbitrary illumination, or\ncomposited into any 3D environment. Our approach requires no 3D training data\nand no modifications to the image diffusion model, demonstrating the\neffectiveness of pretrained image diffusion models as priors.", "published": "2022-09-29T17:50:40Z", "version": 1}, {"aid": "2209.15001", "authors": ["Ali Hassani", "Humphrey Shi"], "title": "Dilated Neighborhood Attention Transformer", "url": "http://arxiv.org/pdf/2209.15001v3", "summary": "Transformers are quickly becoming one of the most heavily applied deep\nlearning architectures across modalities, domains, and tasks. In vision, on top\nof ongoing efforts into plain transformers, hierarchical transformers have also\ngained significant attention, thanks to their performance and easy integration\ninto existing frameworks. These models typically employ localized attention\nmechanisms, such as the sliding-window Neighborhood Attention (NA) or Swin\nTransformer's Shifted Window Self Attention. While effective at reducing self\nattention's quadratic complexity, local attention weakens two of the most\ndesirable properties of self attention: long range inter-dependency modeling,\nand global receptive field. In this paper, we introduce Dilated Neighborhood\nAttention (DiNA), a natural, flexible and efficient extension to NA that can\ncapture more global context and expand receptive fields exponentially at no\nadditional cost. NA's local attention and DiNA's sparse global attention\ncomplement each other, and therefore we introduce Dilated Neighborhood\nAttention Transformer (DiNAT), a new hierarchical vision transformer built upon\nboth. DiNAT variants enjoy significant improvements over strong baselines such\nas NAT, Swin, and ConvNeXt. Our large model is faster and ahead of its Swin\ncounterpart by 1.6% box AP in COCO object detection, 1.4% mask AP in COCO\ninstance segmentation, and 1.4% mIoU in ADE20K semantic segmentation. Paired\nwith new frameworks, our large variant is the new state of the art panoptic\nsegmentation model on COCO (58.5 PQ) and ADE20K (49.4 PQ), and instance\nsegmentation model on Cityscapes (45.1 AP) and ADE20K (35.4 AP) (no extra\ndata). It also matches the state of the art specialized semantic segmentation\nmodels on ADE20K (58.1 mIoU), and ranks second on Cityscapes (84.5 mIoU) (no\nextra data).", "published": "2022-09-29T17:57:08Z", "version": 3}, {"aid": "2209.15179", "authors": ["Hui Wei", "Hao Tang", "Xuemei Jia", "Zhixiang Wang", "Hanxun Yu", "Zhubo Li", "Shin'ichi Satoh", "Luc Van Gool", "Zheng Wang"], "title": "Physical Adversarial Attack meets Computer Vision: A Decade Survey", "url": "http://arxiv.org/pdf/2209.15179v4", "summary": "Despite the impressive achievements of Deep Neural Networks (DNNs) in\ncomputer vision, their vulnerability to adversarial attacks remains a critical\nconcern. Extensive research has demonstrated that incorporating sophisticated\nperturbations into input images can lead to a catastrophic degradation in DNNs'\nperformance. This perplexing phenomenon not only exists in the digital space\nbut also in the physical world. Consequently, it becomes imperative to evaluate\nthe security of DNNs-based systems to ensure their safe deployment in\nreal-world scenarios, particularly in security-sensitive applications. To\nfacilitate a profound understanding of this topic, this paper presents a\ncomprehensive overview of physical adversarial attacks. Firstly, we distill\nfour general steps for launching physical adversarial attacks. Building upon\nthis foundation, we uncover the pervasive role of artifacts carrying\nadversarial perturbations in the physical world. These artifacts influence each\nstep. To denote them, we introduce a new term: adversarial medium. Then, we\ntake the first step to systematically evaluate the performance of physical\nadversarial attacks, taking the adversarial medium as a first attempt. Our\nproposed evaluation metric, hiPAA, comprises six perspectives: Effectiveness,\nStealthiness, Robustness, Practicability, Aesthetics, and Economics. We also\nprovide comparative results across task categories, together with insightful\nobservations and suggestions for future research directions.", "published": "2022-09-30T01:59:53Z", "version": 4}, {"aid": "2209.15246", "authors": ["Mohammad Azizmalayeri", "Arshia Soltani Moakhar", "Arman Zarei", "Reihaneh Zohrabi", "Mohammad Taghi Manzuri", "Mohammad Hossein Rohban"], "title": "Your Out-of-Distribution Detection Method is Not Robust!", "url": "http://arxiv.org/pdf/2209.15246v1", "summary": "Out-of-distribution (OOD) detection has recently gained substantial attention\ndue to the importance of identifying out-of-domain samples in reliability and\nsafety. Although OOD detection methods have advanced by a great deal, they are\nstill susceptible to adversarial examples, which is a violation of their\npurpose. To mitigate this issue, several defenses have recently been proposed.\nNevertheless, these efforts remained ineffective, as their evaluations are\nbased on either small perturbation sizes, or weak attacks. In this work, we\nre-examine these defenses against an end-to-end PGD attack on in/out data with\nlarger perturbation sizes, e.g. up to commonly used $\\epsilon=8/255$ for the\nCIFAR-10 dataset. Surprisingly, almost all of these defenses perform worse than\na random detection under the adversarial setting. Next, we aim to provide a\nrobust OOD detection method. In an ideal defense, the training should expose\nthe model to almost all possible adversarial perturbations, which can be\nachieved through adversarial training. That is, such training perturbations\nshould based on both in- and out-of-distribution samples. Therefore, unlike OOD\ndetection in the standard setting, access to OOD, as well as in-distribution,\nsamples sounds necessary in the adversarial training setup. These tips lead us\nto adopt generative OOD detection methods, such as OpenGAN, as a baseline. We\nsubsequently propose the Adversarially Trained Discriminator (ATD), which\nutilizes a pre-trained robust model to extract robust features, and a generator\nmodel to create OOD samples. Using ATD with CIFAR-10 and CIFAR-100 as the\nin-distribution data, we could significantly outperform all previous methods in\nthe robust AUROC while maintaining high standard AUROC and classification\naccuracy. The code repository is available at https://github.com/rohban-lab/ATD .", "published": "2022-09-30T05:49:00Z", "version": 1}, {"aid": "2209.15261", "authors": ["Yubei Chen", "Zeyu Yun", "Yi Ma", "Bruno Olshausen", "Yann LeCun"], "title": "Minimalistic Unsupervised Learning with the Sparse Manifold Transform", "url": "http://arxiv.org/pdf/2209.15261v2", "summary": "We describe a minimalistic and interpretable method for unsupervised\nlearning, without resorting to data augmentation, hyperparameter tuning, or\nother engineering designs, that achieves performance close to the SOTA SSL\nmethods. Our approach leverages the sparse manifold transform, which unifies\nsparse coding, manifold learning, and slow feature analysis. With a one-layer\ndeterministic sparse manifold transform, one can achieve 99.3% KNN top-1\naccuracy on MNIST, 81.1% KNN top-1 accuracy on CIFAR-10 and 53.2% on CIFAR-100.\nWith a simple gray-scale augmentation, the model gets 83.2% KNN top-1 accuracy\non CIFAR-10 and 57% on CIFAR-100. These results significantly close the gap\nbetween simplistic \"white-box\" methods and the SOTA methods. Additionally, we\nprovide visualization to explain how an unsupervised representation transform\nis formed. The proposed method is closely connected to latent-embedding\nself-supervised methods and can be treated as the simplest form of VICReg.\nThough there remains a small performance gap between our simple constructive\nmodel and SOTA methods, the evidence points to this as a promising direction\nfor achieving a principled and white-box approach to unsupervised learning.", "published": "2022-09-30T06:38:30Z", "version": 2}, {"aid": "2209.15605", "authors": ["Maan Qraitem", "Kate Saenko", "Bryan A. Plummer"], "title": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation", "url": "http://arxiv.org/pdf/2209.15605v8", "summary": "Prior work has shown that Visual Recognition datasets frequently\nunderrepresent bias groups $B$ (\\eg Female) within class labels $Y$ (\\eg\nProgrammers). This dataset bias can lead to models that learn spurious\ncorrelations between class labels and bias groups such as age, gender, or race.\nMost recent methods that address this problem require significant architectural\nchanges or additional loss functions requiring more hyper-parameter tuning.\nAlternatively, data sampling baselines from the class imbalance literature (\\eg\nUndersampling, Upweighting), which can often be implemented in a single line of\ncode and often have no hyperparameters, offer a cheaper and more efficient\nsolution. However, these methods suffer from significant shortcomings. For\nexample, Undersampling drops a significant part of the input distribution per\nepoch while Oversampling repeats samples, causing overfitting. To address these\nshortcomings, we introduce a new class-conditioned sampling method: Bias\nMimicking. The method is based on the observation that if a class $c$ bias\ndistribution, \\ie $P_D(B|Y=c)$ is mimicked across every $c^{\\prime}\\neq c$,\nthen $Y$ and $B$ are statistically independent. Using this notion, BM, through\na novel training procedure, ensures that the model is exposed to the entire\ndistribution per epoch without repeating samples. Consequently, Bias Mimicking\nimproves underrepresented groups' accuracy of sampling methods by 3\\% over four\nbenchmarks while maintaining and sometimes improving performance over\nnonsampling methods. Code: \\url{https://github.com/mqraitem/Bias-Mimicking}", "published": "2022-09-30T17:33:00Z", "version": 8}, {"aid": "2210.00038", "authors": ["Zhiqi Bu", "Yu-Xiang Wang", "Sheng Zha", "George Karypis"], "title": "Differentially Private Optimization on Large Model at Small Cost", "url": "http://arxiv.org/pdf/2210.00038v2", "summary": "Differentially private (DP) optimization is the standard paradigm to learn\nlarge neural networks that are accurate and privacy-preserving. The\ncomputational cost for DP deep learning, however, is notoriously heavy due to\nthe per-sample gradient clipping. Existing DP implementations are 2-1000X more\ncostly in time and space complexity than the standard (non-private) training.\nIn this work, we develop a novel Book-Keeping (BK) technique that implements\nexisting DP optimizers (thus achieving the same accuracy), with a substantial\nimprovement on the computational cost. Specifically, BK enables DP training on\nlarge models and high dimensional data to be roughly as fast and memory-saving\nas the standard training, whereas previous DP algorithms can be inefficient or\nincapable of training due to memory error. The computational advantage of BK is\nsupported by the complexity analysis as well as extensive experiments on vision\nand language tasks. Our implementation achieves state-of-the-art (SOTA)\naccuracy with very small extra cost: on GPT2 and at almost the same memory cost\n(<1% overhead), BK has 1.03X the time complexity of the standard training\n(0.83X training speed in practice), and 0.61X the time complexity of the most\nefficient DP implementation (1.36X training speed in practice). We open-source\nthe codebase for the BK algorithm at the FastDP library\n(https://github.com/awslabs/fast-differential-privacy).", "published": "2022-09-30T18:38:53Z", "version": 2}, {"aid": "2210.01797", "authors": ["Sanjay Chawla", "Preslav Nakov", "Ahmed Ali", "Wendy Hall", "Issa Khalil", "Xiaosong Ma", "Husrev Taha Sencar", "Ingmar Weber", "Michael Wooldridge", "Ting Yu"], "title": "Ten Years after ImageNet: A 360\u00b0 Perspective on AI", "url": "http://arxiv.org/pdf/2210.01797v1", "summary": "It is ten years since neural networks made their spectacular comeback.\nPrompted by this anniversary, we take a holistic perspective on Artificial\nIntelligence (AI). Supervised Learning for cognitive tasks is effectively\nsolved - provided we have enough high-quality labeled data. However, deep\nneural network models are not easily interpretable, and thus the debate between\nblackbox and whitebox modeling has come to the fore. The rise of attention\nnetworks, self-supervised learning, generative modeling, and graph neural\nnetworks has widened the application space of AI. Deep Learning has also\npropelled the return of reinforcement learning as a core building block of\nautonomous decision making systems. The possible harms made possible by new AI\ntechnologies have raised socio-technical issues such as transparency, fairness,\nand accountability. The dominance of AI by Big-Tech who control talent,\ncomputing resources, and most importantly, data may lead to an extreme AI\ndivide. Failure to meet high expectations in high profile, and much heralded\nflagship projects like self-driving vehicles could trigger another AI winter.", "published": "2022-10-01T01:41:17Z", "version": 1}, {"aid": "2210.00379", "authors": ["Kyle Gao", "Yina Gao", "Hongjie He", "Dening Lu", "Linlin Xu", "Jonathan Li"], "title": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review", "url": "http://arxiv.org/pdf/2210.00379v5", "summary": "Neural Radiance Field (NeRF) has recently become a significant development in\nthe field of Computer Vision, allowing for implicit, neural network-based scene\nrepresentation and novel view synthesis. NeRF models have found diverse\napplications in robotics, urban mapping, autonomous navigation, virtual\nreality/augmented reality, and more. Due to the growing popularity of NeRF and\nits expanding research area, we present a comprehensive survey of NeRF papers\nfrom the past two years. Our survey is organized into architecture and\napplication-based taxonomies and provides an introduction to the theory of NeRF\nand its training via differentiable volume rendering. We also present a\nbenchmark comparison of the performance and speed of key NeRF models. By\ncreating this survey, we hope to introduce new researchers to NeRF, provide a\nhelpful reference for influential works in this field, as well as motivate\nfuture research directions with our discussion section.", "published": "2022-10-01T21:35:11Z", "version": 5}, {"aid": "2210.00405", "authors": ["Bin Xia", "Yulun Zhang", "Yitong Wang", "Yapeng Tian", "Wenming Yang", "Radu Timofte", "Luc Van Gool"], "title": "Basic Binary Convolution Unit for Binarized Image Restoration Network", "url": "http://arxiv.org/pdf/2210.00405v2", "summary": "Lighter and faster image restoration (IR) models are crucial for the\ndeployment on resource-limited devices. Binary neural network (BNN), one of the\nmost promising model compression methods, can dramatically reduce the\ncomputations and parameters of full-precision convolutional neural networks\n(CNN). However, there are different properties between BNN and full-precision\nCNN, and we can hardly use the experience of designing CNN to develop BNN. In\nthis study, we reconsider components in binary convolution, such as residual\nconnection, BatchNorm, activation function, and structure, for IR tasks. We\nconduct systematic analyses to explain each component's role in binary\nconvolution and discuss the pitfalls. Specifically, we find that residual\nconnection can reduce the information loss caused by binarization; BatchNorm\ncan solve the value range gap between residual connection and binary\nconvolution; The position of the activation function dramatically affects the\nperformance of BNN. Based on our findings and analyses, we design a simple yet\nefficient basic binary convolution unit (BBCU). Furthermore, we divide IR\nnetworks into four parts and specially design variants of BBCU for each part to\nexplore the benefit of binarizing these parts. We conduct experiments on\ndifferent IR tasks, and our BBCU significantly outperforms other BNNs and\nlightweight models, which shows that BBCU can serve as a basic unit for\nbinarized IR networks. All codes and models will be released.", "published": "2022-10-02T01:54:40Z", "version": 2}, {"aid": "2210.00479", "authors": ["Siddharth Roheda", "Ashkan Panahi", "Hamid Krim"], "title": "Fast OT for Latent Domain Adaptation", "url": "http://arxiv.org/pdf/2210.00479v1", "summary": "In this paper, we address the problem of unsupervised Domain Adaptation. The\nneed for such an adaptation arises when the distribution of the target data\ndiffers from that which is used to develop the model and the ground truth\ninformation of the target data is unknown. We propose an algorithm that uses\noptimal transport theory with a verifiably efficient and implementable solution\nto learn the best latent feature representation. This is achieved by minimizing\nthe cost of transporting the samples from the target domain to the distribution\nof the source domain.", "published": "2022-10-02T10:25:12Z", "version": 1}, {"aid": "2210.00545", "authors": ["Jiahuan Ren", "Zhao Zhang", "Richang Hong", "Mingliang Xu", "Yi Yang", "Shuicheng Yan"], "title": "Seeing Through the Noisy Dark: Towards Real-world Low-Light Image Enhancement and Denoising", "url": "http://arxiv.org/pdf/2210.00545v3", "summary": "Low-light image enhancement (LLIE) aims at improving the illumination and\nvisibility of dark images with lighting noise. To handle the real-world\nlow-light images often with heavy and complex noise, some efforts have been\nmade for joint LLIE and denoising, which however only achieve inferior\nrestoration performance. We attribute it to two challenges: 1) in real-world\nlow-light images, noise is somewhat covered by low-lighting and the left noise\nafter denoising would be inevitably amplified during enhancement; 2) conversion\nof raw data to sRGB would cause information loss and also more noise, and hence\nprior LLIE methods trained on raw data are unsuitable for more common sRGB\nimages. In this work, we propose a novel Low-light Enhancement & Denoising\nNetwork for real-world low-light images (RLED-Net) in the sRGB color space. In\nRLED-Net, we apply a plug-and-play differentiable Latent Subspace\nReconstruction Block (LSRB) to embed the real-world images into low-rank\nsubspaces to suppress the noise and rectify the errors, such that the impact of\nnoise during enhancement can be effectively shrunk. We then present an\nefficient Crossed-channel & Shift-window Transformer (CST) layer with two\nbranches to calculate the window and channel attentions to resist the\ndegradation (e.g., speckle noise and blur) caused by the noise in input images.\nBased on the CST layers, we further present a U-structure network CSTNet as\nbackbone for deep feature recovery, and construct a feature refine block to\nrefine the final features. Extensive experiments on both real noisy images and\npublic image databases well verify the effectiveness of the proposed RLED-Net\nfor RLLIE and denoising simultaneously.", "published": "2022-10-02T14:57:23Z", "version": 3}, {"aid": "2210.00752", "authors": ["Xiaoming Li", "Chaofeng Chen", "Xianhui Lin", "Wangmeng Zuo", "Lei Zhang"], "title": "From Face to Natural Image: Learning Real Degradation for Blind Image Super-Resolution", "url": "http://arxiv.org/pdf/2210.00752v2", "summary": "How to design proper training pairs is critical for super-resolving\nreal-world low-quality (LQ) images, which suffers from the difficulties in\neither acquiring paired ground-truth high-quality (HQ) images or synthesizing\nphoto-realistic degraded LQ observations. Recent works mainly focus on modeling\nthe degradation with handcrafted or estimated degradation parameters, which are\nhowever incapable to model complicated real-world degradation types, resulting\nin limited quality improvement. Notably, LQ face images, which may have the\nsame degradation process as natural images, can be robustly restored with\nphoto-realistic textures by exploiting their strong structural priors. This\nmotivates us to use the real-world LQ face images and their restored HQ\ncounterparts to model the complex real-world degradation (namely ReDegNet), and\nthen transfer it to HQ natural images to synthesize their realistic LQ\ncounterparts. By taking these paired HQ-LQ face images as inputs to explicitly\npredict the degradation-aware and content-independent representations, we could\ncontrol the degraded image generation, and subsequently transfer these\ndegradation representations from face to natural images to synthesize the\ndegraded LQ natural images. Experiments show that our ReDegNet can well learn\nthe real degradation process from face images. The restoration network trained\nwith our synthetic pairs performs favorably against SOTAs. More importantly,\nour method provides a new way to handle the real-world complex scenarios by\nlearning their degradation representations from the facial portions, which can\nbe used to significantly improve the quality of non-facial areas. The source\ncode is available at https://github.com/csxmli2016/ReDegNet.", "published": "2022-10-03T08:09:21Z", "version": 2}, {"aid": "2210.01802", "authors": ["Haixiang Sun", "Ye Shi", "Jingya Wang", "Hoang Duong Tuan", "H. Vincent Poor", "Dacheng Tao"], "title": "Alternating Differentiation for Optimization Layers", "url": "http://arxiv.org/pdf/2210.01802v2", "summary": "The idea of embedding optimization problems into deep neural networks as\noptimization layers to encode constraints and inductive priors has taken hold\nin recent years. Most existing methods focus on implicitly differentiating\nKarush-Kuhn-Tucker (KKT) conditions in a way that requires expensive\ncomputations on the Jacobian matrix, which can be slow and memory-intensive. In\nthis paper, we developed a new framework, named Alternating Differentiation\n(Alt-Diff), that differentiates optimization problems (here, specifically in\nthe form of convex optimization problems with polyhedral constraints) in a fast\nand recursive way. Alt-Diff decouples the differentiation procedure into a\nprimal update and a dual update in an alternating way. Accordingly, Alt-Diff\nsubstantially decreases the dimensions of the Jacobian matrix especially for\noptimization with large-scale constraints and thus increases the computational\nspeed of implicit differentiation. We show that the gradients obtained by\nAlt-Diff are consistent with those obtained by differentiating KKT conditions.\nIn addition, we propose to truncate Alt-Diff to further accelerate the\ncomputational speed. Under some standard assumptions, we show that the\ntruncation error of gradients is upper bounded by the same order of variables'\nestimation error. Therefore, Alt-Diff can be truncated to further increase\ncomputational speed without sacrificing much accuracy. A series of\ncomprehensive experiments validate the superiority of Alt-Diff.", "published": "2022-10-03T11:32:13Z", "version": 2}, {"aid": "2210.02192", "authors": ["Jinxin Zhou", "Chong You", "Xiao Li", "Kangning Liu", "Sheng Liu", "Qing Qu", "Zhihui Zhu"], "title": "Are All Losses Created Equal: A Neural Collapse Perspective", "url": "http://arxiv.org/pdf/2210.02192v2", "summary": "While cross entropy (CE) is the most commonly used loss to train deep neural\nnetworks for classification tasks, many alternative losses have been developed\nto obtain better empirical performance. Among them, which one is the best to\nuse is still a mystery, because there seem to be multiple factors affecting the\nanswer, such as properties of the dataset, the choice of network architecture,\nand so on. This paper studies the choice of loss function by examining the\nlast-layer features of deep networks, drawing inspiration from a recent line\nwork showing that the global optimal solution of CE and mean-square-error (MSE)\nlosses exhibits a Neural Collapse phenomenon. That is, for sufficiently large\nnetworks trained until convergence, (i) all features of the same class collapse\nto the corresponding class mean and (ii) the means associated with different\nclasses are in a configuration where their pairwise distances are all equal and\nmaximized. We extend such results and show through global solution and\nlandscape analyses that a broad family of loss functions including commonly\nused label smoothing (LS) and focal loss (FL) exhibits Neural Collapse. Hence,\nall relevant losses(i.e., CE, LS, FL, MSE) produce equivalent features on\ntraining data. Based on the unconstrained feature model assumption, we provide\neither the global landscape analysis for LS loss or the local landscape\nanalysis for FL loss and show that the (only!) global minimizers are neural\ncollapse solutions, while all other critical points are strict saddles whose\nHessian exhibit negative curvature directions either in the global scope for LS\nloss or in the local scope for FL loss near the optimal solution. The\nexperiments further show that Neural Collapse features obtained from all\nrelevant losses lead to largely identical performance on test data as well,\nprovided that the network is sufficiently large and trained until convergence.", "published": "2022-10-04T00:36:45Z", "version": 2}, {"aid": "2210.01820", "authors": ["Chenglin Yang", "Siyuan Qiao", "Qihang Yu", "Xiaoding Yuan", "Yukun Zhu", "Alan Yuille", "Hartwig Adam", "Liang-Chieh Chen"], "title": "MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models", "url": "http://arxiv.org/pdf/2210.01820v2", "summary": "This paper presents MOAT, a family of neural networks that build on top of\nMObile convolution (i.e., inverted residual blocks) and ATtention. Unlike the\ncurrent works that stack separate mobile convolution and transformer blocks, we\neffectively merge them into a MOAT block. Starting with a standard Transformer\nblock, we replace its multi-layer perceptron with a mobile convolution block,\nand further reorder it before the self-attention operation. The mobile\nconvolution block not only enhances the network representation capacity, but\nalso produces better downsampled features. Our conceptually simple MOAT\nnetworks are surprisingly effective, achieving 89.1% / 81.5% top-1 accuracy on\nImageNet-1K / ImageNet-1K-V2 with ImageNet22K pretraining. Additionally, MOAT\ncan be seamlessly applied to downstream tasks that require large resolution\ninputs by simply converting the global attention to window attention. Thanks to\nthe mobile convolution that effectively exchanges local information between\npixels (and thus cross-windows), MOAT does not need the extra window-shifting\nmechanism. As a result, on COCO object detection, MOAT achieves 59.2% box AP\nwith 227M model parameters (single-scale inference, and hard NMS), and on\nADE20K semantic segmentation, MOAT attains 57.6% mIoU with 496M model\nparameters (single-scale inference). Finally, the tiny-MOAT family, obtained by\nsimply reducing the channel sizes, also surprisingly outperforms several\nmobile-specific transformer-based models on ImageNet. The tiny-MOAT family is\nalso benchmarked on downstream tasks, serving as a baseline for the community.\nWe hope our simple yet effective MOAT will inspire more seamless integration of\nconvolution and self-attention. Code is publicly available.", "published": "2022-10-04T18:00:06Z", "version": 2}, {"aid": "2210.01941", "authors": ["Kareem Ahmed", "Zhe Zeng", "Mathias Niepert", "Guy Van den Broeck"], "title": "SIMPLE: A Gradient Estimator for $k$-Subset Sampling", "url": "http://arxiv.org/pdf/2210.01941v2", "summary": "$k$-subset sampling is ubiquitous in machine learning, enabling\nregularization and interpretability through sparsity. The challenge lies in\nrendering $k$-subset sampling amenable to end-to-end learning. This has\ntypically involved relaxing the reparameterized samples to allow for\nbackpropagation, with the risk of introducing high bias and high variance. In\nthis work, we fall back to discrete $k$-subset sampling on the forward pass.\nThis is coupled with using the gradient with respect to the exact marginals,\ncomputed efficiently, as a proxy for the true gradient. We show that our\ngradient estimator, SIMPLE, exhibits lower bias and variance compared to\nstate-of-the-art estimators, including the straight-through Gumbel estimator\nwhen $k = 1$. Empirical results show improved performance on learning to\nexplain and sparse linear regression. We provide an algorithm for computing the\nexact ELBO for the $k$-subset distribution, obtaining significantly lower loss\ncompared to SOTA.", "published": "2022-10-04T22:33:16Z", "version": 2}, {"aid": "2210.01986", "authors": ["Yue-Ting Pan", "Jing-Lun Chou", "Chun-Shu Wei"], "title": "MAtt: A Manifold Attention Network for EEG Decoding", "url": "http://arxiv.org/pdf/2210.01986v1", "summary": "Recognition of electroencephalographic (EEG) signals highly affect the\nefficiency of non-invasive brain-computer interfaces (BCIs). While recent\nadvances of deep-learning (DL)-based EEG decoders offer improved performances,\nthe development of geometric learning (GL) has attracted much attention for\noffering exceptional robustness in decoding noisy EEG data. However, there is a\nlack of studies on the merged use of deep neural networks (DNNs) and geometric\nlearning for EEG decoding. We herein propose a manifold attention network\n(mAtt), a novel geometric deep learning (GDL)-based model, featuring a manifold\nattention mechanism that characterizes spatiotemporal representations of EEG\ndata fully on a Riemannian symmetric positive definite (SPD) manifold. The\nevaluation of the proposed MAtt on both time-synchronous and -asyncronous EEG\ndatasets suggests its superiority over other leading DL methods for general EEG\ndecoding. Furthermore, analysis of model interpretation reveals the capability\nof MAtt in capturing informative EEG features and handling the non-stationarity\nof brain dynamics.", "published": "2022-10-05T02:26:31Z", "version": 1}, {"aid": "2210.02303", "authors": ["Jonathan Ho", "William Chan", "Chitwan Saharia", "Jay Whang", "Ruiqi Gao", "Alexey Gritsenko", "Diederik P. Kingma", "Ben Poole", "Mohammad Norouzi", "David J. Fleet", "Tim Salimans"], "title": "Imagen Video: High Definition Video Generation with Diffusion Models", "url": "http://arxiv.org/pdf/2210.02303v1", "summary": "We present Imagen Video, a text-conditional video generation system based on\na cascade of video diffusion models. Given a text prompt, Imagen Video\ngenerates high definition videos using a base video generation model and a\nsequence of interleaved spatial and temporal video super-resolution models. We\ndescribe how we scale up the system as a high definition text-to-video model\nincluding design decisions such as the choice of fully-convolutional temporal\nand spatial super-resolution models at certain resolutions, and the choice of\nthe v-parameterization of diffusion models. In addition, we confirm and\ntransfer findings from previous work on diffusion-based image generation to the\nvideo generation setting. Finally, we apply progressive distillation to our\nvideo models with classifier-free guidance for fast, high quality sampling. We\nfind Imagen Video not only capable of generating videos of high fidelity, but\nalso having a high degree of controllability and world knowledge, including the\nability to generate diverse videos and text animations in various artistic\nstyles and with 3D object understanding. See\nhttps://imagen.research.google/video/ for samples.", "published": "2022-10-05T14:41:38Z", "version": 1}, {"aid": "2210.02382", "authors": ["Mathias Vetsch", "Sandro Lombardi", "Marc Pollefeys", "Martin R. Oswald"], "title": "NeuralMeshing: Differentiable Meshing of Implicit Neural Representations", "url": "http://arxiv.org/pdf/2210.02382v1", "summary": "The generation of triangle meshes from point clouds, i.e. meshing, is a core\ntask in computer graphics and computer vision. Traditional techniques directly\nconstruct a surface mesh using local decision heuristics, while some recent\nmethods based on neural implicit representations try to leverage data-driven\napproaches for this meshing process. However, it is challenging to define a\nlearnable representation for triangle meshes of unknown topology and size and\nfor this reason, neural implicit representations rely on non-differentiable\npost-processing in order to extract the final triangle mesh. In this work, we\npropose a novel differentiable meshing algorithm for extracting surface meshes\nfrom neural implicit representations. Our method produces the mesh in an\niterative fashion, which makes it applicable to shapes of various scales and\nadaptive to the local curvature of the shape. Furthermore, our method produces\nmeshes with regular tessellation patterns and fewer triangle faces compared to\nexisting methods. Experiments demonstrate the comparable reconstruction\nperformance and favorable mesh properties over baselines.", "published": "2022-10-05T16:52:25Z", "version": 1}, {"aid": "2210.02579", "authors": ["Gwangbin Bae", "Martin de La Gorce", "Tadas Baltrusaitis", "Charlie Hewitt", "Dong Chen", "Julien Valentin", "Roberto Cipolla", "Jingjing Shen"], "title": "DigiFace-1M: 1 Million Digital Face Images for Face Recognition", "url": "http://arxiv.org/pdf/2210.02579v1", "summary": "State-of-the-art face recognition models show impressive accuracy, achieving\nover 99.8% on Labeled Faces in the Wild (LFW) dataset. Such models are trained\non large-scale datasets that contain millions of real human face images\ncollected from the internet. Web-crawled face images are severely biased (in\nterms of race, lighting, make-up, etc) and often contain label noise. More\nimportantly, the face images are collected without explicit consent, raising\nethical concerns. To avoid such problems, we introduce a large-scale synthetic\ndataset for face recognition, obtained by rendering digital faces using a\ncomputer graphics pipeline. We first demonstrate that aggressive data\naugmentation can significantly reduce the synthetic-to-real domain gap. Having\nfull control over the rendering pipeline, we also study how each attribute\n(e.g., variation in facial pose, accessories and textures) affects the\naccuracy. Compared to SynFace, a recent method trained on GAN-generated\nsynthetic faces, we reduce the error rate on LFW by 52.5% (accuracy from 91.93%\nto 96.17%). By fine-tuning the network on a smaller number of real face images\nthat could reasonably be obtained with consent, we achieve accuracy that is\ncomparable to the methods trained on millions of real face images.", "published": "2022-10-05T22:02:48Z", "version": 1}, {"aid": "2210.03158", "authors": ["Yan Zheng", "Lemeng Wu", "Xingchao Liu", "Zhen Chen", "Qiang Liu", "Qixing Huang"], "title": "Neural Volumetric Mesh Generator", "url": "http://arxiv.org/pdf/2210.03158v1", "summary": "Deep generative models have shown success in generating 3D shapes with\ndifferent representations. In this work, we propose Neural Volumetric Mesh\nGenerator(NVMG) which can generate novel and high-quality volumetric meshes.\nUnlike the previous 3D generative model for point cloud, voxel, and implicit\nsurface, the volumetric mesh representation is a ready-to-use representation in\nindustry with details on both the surface and interior. Generating this such\nhighly-structured data thus brings a significant challenge. We first propose a\ndiffusion-based generative model to tackle this problem by generating voxelized\nshapes with close-to-reality outlines and structures. We can simply obtain a\ntetrahedral mesh as a template with the voxelized shape. Further, we use a\nvoxel-conditional neural network to predict the smooth implicit surface\nconditioned on the voxels, and progressively project the tetrahedral mesh to\nthe predicted surface under regularizations. The regularization terms are\ncarefully designed so that they can (1) get rid of the defects like flipping\nand high distortion; (2) force the regularity of the interior and surface\nstructure during the deformation procedure for a high-quality final mesh. As\nshown in the experiments, our pipeline can generate high-quality artifact-free\nvolumetric and surface meshes from random noise or a reference image without\nany post-processing. Compared with the state-of-the-art voxel-to-mesh\ndeformation method, we show more robustness and better performance when taking\ngenerated voxels as input.", "published": "2022-10-06T18:46:51Z", "version": 1}, {"aid": "2210.03204", "authors": ["Zhongnan Qu"], "title": "Enabling Deep Learning on Edge Devices", "url": "http://arxiv.org/pdf/2210.03204v1", "summary": "Deep neural networks (DNNs) have succeeded in many different perception\ntasks, e.g., computer vision, natural language processing, reinforcement\nlearning, etc. The high-performed DNNs heavily rely on intensive resource\nconsumption. For example, training a DNN requires high dynamic memory, a\nlarge-scale dataset, and a large number of computations (a long training time);\neven inference with a DNN also demands a large amount of static storage,\ncomputations (a long inference time), and energy. Therefore, state-of-the-art\nDNNs are often deployed on a cloud server with a large number of\nsuper-computers, a high-bandwidth communication bus, a shared storage\ninfrastructure, and a high power supplement.\n  Recently, some new emerging intelligent applications, e.g., AR/VR, mobile\nassistants, Internet of Things, require us to deploy DNNs on\nresource-constrained edge devices. Compare to a cloud server, edge devices\noften have a rather small amount of resources. To deploy DNNs on edge devices,\nwe need to reduce the size of DNNs, i.e., we target a better trade-off between\nresource consumption and model accuracy.\n  In this dissertation, we studied four edge intelligence scenarios, i.e.,\nInference on Edge Devices, Adaptation on Edge Devices, Learning on Edge\nDevices, and Edge-Server Systems, and developed different methodologies to\nenable deep learning in each scenario. Since current DNNs are often\nover-parameterized, our goal is to find and reduce the redundancy of the DNNs\nin each scenario.", "published": "2022-10-06T20:52:57Z", "version": 1}, {"aid": "2210.03301", "authors": ["Yuan Lan", "Liang Qin", "Zhaoyi Sun", "Yang Xiang", "Jie Sun"], "title": "GOLLIC: Learning Global Context beyond Patches for Lossless High-Resolution Image Compression", "url": "http://arxiv.org/pdf/2210.03301v1", "summary": "Neural-network-based approaches recently emerged in the field of data\ncompression and have already led to significant progress in image compression,\nespecially in achieving a higher compression ratio. In the lossless image\ncompression scenario, however, existing methods often struggle to learn a\nprobability model of full-size high-resolution images due to the limitation of\nthe computation source. The current strategy is to crop high-resolution images\ninto multiple non-overlapping patches and process them independently. This\nstrategy ignores long-term dependencies beyond patches, thus limiting modeling\nperformance. To address this problem, we propose a hierarchical latent variable\nmodel with a global context to capture the long-term dependencies of\nhigh-resolution images. Besides the latent variable unique to each patch, we\nintroduce shared latent variables between patches to construct the global\ncontext. The shared latent variables are extracted by a self-supervised\nclustering module inside the model's encoder. This clustering module assigns\neach patch the confidence that it belongs to any cluster. Later, shared latent\nvariables are learned according to latent variables of patches and their\nconfidence, which reflects the similarity of patches in the same cluster and\nbenefits the global context modeling. Experimental results show that our global\ncontext model improves compression ratio compared to the engineered codecs and\ndeep learning models on three benchmark high-resolution image datasets, DIV2K,\nCLIC.pro, and CLIC.mobile.", "published": "2022-10-07T03:15:02Z", "version": 1}, {"aid": "2210.03310", "authors": ["Mengye Ren", "Simon Kornblith", "Renjie Liao", "Geoffrey Hinton"], "title": "Scaling Forward Gradient With Local Losses", "url": "http://arxiv.org/pdf/2210.03310v3", "summary": "Forward gradient learning computes a noisy directional gradient and is a\nbiologically plausible alternative to backprop for learning deep neural\nnetworks. However, the standard forward gradient algorithm, when applied\nnaively, suffers from high variance when the number of parameters to be learned\nis large. In this paper, we propose a series of architectural and algorithmic\nmodifications that together make forward gradient learning practical for\nstandard deep learning benchmark tasks. We show that it is possible to\nsubstantially reduce the variance of the forward gradient estimator by applying\nperturbations to activations rather than weights. We further improve the\nscalability of forward gradient by introducing a large number of local greedy\nloss functions, each of which involves only a small number of learnable\nparameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more\nsuitable for local learning. Our approach matches backprop on MNIST and\nCIFAR-10 and significantly outperforms previously proposed backprop-free\nalgorithms on ImageNet.", "published": "2022-10-07T03:52:27Z", "version": 3}, {"aid": "2210.03586", "authors": ["Xi Weng", "Lei Huang", "Lei Zhao", "Rao Muhammad Anwer", "Salman Khan", "Fahad Shahbaz Khan"], "title": "An Investigation into Whitening Loss for Self-supervised Learning", "url": "http://arxiv.org/pdf/2210.03586v1", "summary": "A desirable objective in self-supervised learning (SSL) is to avoid feature\ncollapse. Whitening loss guarantees collapse avoidance by minimizing the\ndistance between embeddings of positive pairs under the conditioning that the\nembeddings from different views are whitened. In this paper, we propose a\nframework with an informative indicator to analyze whitening loss, which\nprovides a clue to demystify several interesting phenomena as well as a\npivoting point connecting to other SSL methods. We reveal that batch whitening\n(BW) based methods do not impose whitening constraints on the embedding, but\nthey only require the embedding to be full-rank. This full-rank constraint is\nalso sufficient to avoid dimensional collapse. Based on our analysis, we\npropose channel whitening with random group partition (CW-RGP), which exploits\nthe advantages of BW-based methods in preventing collapse and avoids their\ndisadvantages requiring large batch size. Experimental results on ImageNet\nclassification and COCO object detection reveal that the proposed CW-RGP\npossesses a promising potential for learning good representations. The code is\navailable at https://github.com/winci-ai/CW-RGP.", "published": "2022-10-07T14:43:29Z", "version": 1}, {"aid": "2210.03651", "authors": ["Asher Trockman", "Devin Willmott", "J. Zico Kolter"], "title": "Understanding the Covariance Structure of Convolutional Filters", "url": "http://arxiv.org/pdf/2210.03651v1", "summary": "Neural network weights are typically initialized at random from univariate\ndistributions, controlling just the variance of individual weights even in\nhighly-structured operations like convolutions. Recent ViT-inspired\nconvolutional networks such as ConvMixer and ConvNeXt use large-kernel\ndepthwise convolutions whose learned filters have notable structure; this\npresents an opportunity to study their empirical covariances. In this work, we\nfirst observe that such learned filters have highly-structured covariance\nmatrices, and moreover, we find that covariances calculated from small networks\nmay be used to effectively initialize a variety of larger networks of different\ndepths, widths, patch sizes, and kernel sizes, indicating a degree of\nmodel-independence to the covariance structure. Motivated by these findings, we\nthen propose a learning-free multivariate initialization scheme for\nconvolutional filters using a simple, closed-form construction of their\ncovariance. Models using our initialization outperform those using traditional\nunivariate initializations, and typically meet or exceed the performance of\nthose initialized from the covariances of learned filters; in some cases, this\nimprovement can be achieved without training the depthwise convolutional\nfilters at all.", "published": "2022-10-07T15:59:13Z", "version": 1}, {"aid": "2210.03689", "authors": ["Xuejing Lei", "Wei Wang", "C. -C. Jay Kuo"], "title": "GENHOP: An Image Generation Method Based on Successive Subspace Learning", "url": "http://arxiv.org/pdf/2210.03689v1", "summary": "Being different from deep-learning-based (DL-based) image generation methods,\na new image generative model built upon successive subspace learning principle\nis proposed and named GenHop (an acronym of Generative PixelHop) in this work.\nGenHop consists of three modules: 1) high-to-low dimension reduction, 2) seed\nimage generation, and 3) low-to-high dimension expansion. In the first module,\nit builds a sequence of high-to-low dimensional subspaces through a sequence of\nwhitening processes, each of which contains samples of joint-spatial-spectral\nrepresentation. In the second module, it generates samples in the lowest\ndimensional subspace. In the third module, it finds a proper high-dimensional\nsample for a seed image by adding details back via locally linear embedding\n(LLE) and a sequence of coloring processes. Experiments show that GenHop can\ngenerate visually pleasant images whose FID scores are comparable or even\nbetter than those of DL-based generative models for MNIST, Fashion-MNIST and\nCelebA datasets.", "published": "2022-10-07T16:51:24Z", "version": 1}, {"aid": "2210.05559", "authors": ["Chen Henry Wu", "Fernando De la Torre"], "title": "Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance", "url": "http://arxiv.org/pdf/2210.05559v2", "summary": "Diffusion models have achieved unprecedented performance in generative\nmodeling. The commonly-adopted formulation of the latent code of diffusion\nmodels is a sequence of gradually denoised samples, as opposed to the simpler\n(e.g., Gaussian) latent space of GANs, VAEs, and normalizing flows. This paper\nprovides an alternative, Gaussian formulation of the latent space of various\ndiffusion models, as well as an invertible DPM-Encoder that maps images into\nthe latent space. While our formulation is purely based on the definition of\ndiffusion models, we demonstrate several intriguing consequences. (1)\nEmpirically, we observe that a common latent space emerges from two diffusion\nmodels trained independently on related domains. In light of this finding, we\npropose CycleDiffusion, which uses DPM-Encoder for unpaired image-to-image\ntranslation. Furthermore, applying CycleDiffusion to text-to-image diffusion\nmodels, we show that large-scale text-to-image diffusion models can be used as\nzero-shot image-to-image editors. (2) One can guide pre-trained diffusion\nmodels and GANs by controlling the latent codes in a unified, plug-and-play\nformulation based on energy-based models. Using the CLIP model and a face\nrecognition model as guidance, we demonstrate that diffusion models have better\ncoverage of low-density sub-populations and individuals than GANs. The code is\npublicly available at https://github.com/ChenWu98/cycle-diffusion.", "published": "2022-10-11T15:53:52Z", "version": 2}, {"aid": "2210.05635", "authors": ["Claudio Ravasio", "Lyndon Da Cruz", "Christos Bergeles"], "title": "Oflib: Facilitating Operations with and on Optical Flow Fields in Python", "url": "http://arxiv.org/pdf/2210.05635v2", "summary": "We present a robust theoretical framework for the characterisation and\nmanipulation of optical flow, i.e 2D vector fields, in the context of their use\nin motion estimation algorithms and beyond. The definition of two frames of\nreference guides the mathematical derivation of flow field application,\ninversion, evaluation, and composition operations. This structured approach is\nthen used as the foundation for an implementation in Python 3, with the fully\ndifferentiable PyTorch version oflibpytorch supporting back-propagation as\nrequired for deep learning. We verify the flow composition method empirically\nand provide a working example for its application to optical flow ground truth\nin synthetic training data creation. All code is publicly available.", "published": "2022-10-11T17:28:10Z", "version": 2}, {"aid": "2210.05834", "authors": ["Nidhin Harilal", "Rohan Patil"], "title": "Effectiveness of the Recent Advances in Capsule Networks", "url": "http://arxiv.org/pdf/2210.05834v1", "summary": "Convolutional neural networks (CNNs) have revolutionized the field of deep\nneural networks. However, recent research has shown that CNNs fail to\ngeneralize under various conditions and hence the idea of capsules was\nintroduced in 2011, though the real surge of research started from 2017. In\nthis paper, we present an overview of the recent advances in capsule\narchitecture and routing mechanisms. In addition, we find that the relative\nfocus in recent literature is on modifying routing procedure or architecture as\na whole but the study of other finer components, specifically, squash function\nis wanting. Thus, we also present some new insights regarding the effect of\nsquash functions in performance of the capsule networks. Finally, we conclude\nby discussing and proposing possible opportunities in the field of capsule\nnetworks.", "published": "2022-10-11T23:30:12Z", "version": 1}, {"aid": "2210.05988", "authors": ["Pin-Hua Lai", "Bo-Shan Wang", "Wei-Chun Yang", "Hsiang-Chieh Tsou", "Chun-Shu Wei"], "title": "CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG Reconstruction", "url": "http://arxiv.org/pdf/2210.05988v2", "summary": "Human electroencephalography (EEG) is a brain monitoring modality that senses\ncortical neuroelectrophysiological activity in high-temporal resolution. One of\nthe greatest challenges posed in applications of EEG is the unstable signal\nquality susceptible to inevitable artifacts during recordings. To date, most\nexisting techniques for EEG artifact removal and reconstruction are applicable\nto offline analysis solely, or require individualized training data to\nfacilitate online reconstruction. We have proposed CLEEGN, a novel\nconvolutional neural network for plug-and-play automatic EEG reconstruction.\nCLEEGN is based on a subject-independent pre-trained model using existing data\nand can operate on a new user without any further calibration. The performance\nof CLEEGN was validated using multiple evaluations including waveform\nobservation, reconstruction error assessment, and decoding accuracy on\nwell-studied labeled datasets. The results of simulated online validation\nsuggest that, even without any calibration, CLEEGN can largely preserve\ninherent brain activity and outperforms leading online/offline artifact removal\nmethods in the decoding accuracy of reconstructed EEG data. In addition,\nvisualization of model parameters and latent features exhibit the model\nbehavior and reveal explainable insights related to existing knowledge of\nneuroscience. We foresee pervasive applications of CLEEGN in prospective works\nof online plug-and-play EEG decoding and analysis.", "published": "2022-10-12T07:56:09Z", "version": 2}, {"aid": "2210.06002", "authors": ["Chenggong Zhang", "Zhilei Liu"], "title": "Face Super-Resolution with Progressive Embedding of Multi-scale Face Priors", "url": "http://arxiv.org/pdf/2210.06002v1", "summary": "The face super-resolution (FSR) task is to reconstruct high-resolution face\nimages from low-resolution inputs. Recent works have achieved success on this\ntask by utilizing facial priors such as facial landmarks. Most existing methods\npay more attention to global shape and structure information, but less to local\ntexture information, which makes them cannot recover local details well. In\nthis paper, we propose a novel recurrent convolutional network based framework\nfor face super-resolution, which progressively introduces both global shape and\nlocal texture information. We take full advantage of the intermediate outputs\nof the recurrent network, and landmarks information and facial action units\n(AUs) information are extracted in the output of the first and second steps\nrespectively, rather than low-resolution input. Moreover, we introduced AU\nclassification results as a novel quantitative metric for facial details\nrestoration. Extensive experiments show that our proposed method significantly\noutperforms state-of-the-art FSR methods in terms of image quality and facial\ndetails restoration.", "published": "2022-10-12T08:16:52Z", "version": 1}, {"aid": "2210.06201", "authors": ["Pedro Sanchez", "Xiao Liu", "Alison Q O'Neil", "Sotirios A. Tsaftaris"], "title": "Diffusion Models for Causal Discovery via Topological Ordering", "url": "http://arxiv.org/pdf/2210.06201v2", "summary": "Discovering causal relations from observational data becomes possible with\nadditional assumptions such as considering the functional relations to be\nconstrained as nonlinear with additive noise (ANM). Even with strong\nassumptions, causal discovery involves an expensive search problem over the\nspace of directed acyclic graphs (DAGs). \\emph{Topological ordering} approaches\nreduce the optimisation space of causal discovery by searching over a\npermutation rather than graph space. For ANMs, the \\emph{Hessian} of the data\nlog-likelihood can be used for finding leaf nodes in a causal graph, allowing\nits topological ordering. However, existing computational methods for obtaining\nthe Hessian still do not scale as the number of variables and the number of\nsamples increase. Therefore, inspired by recent innovations in diffusion\nprobabilistic models (DPMs), we propose \\emph{DiffAN}\\footnote{Implementation\nis available at \\url{https://github.com/vios-s/DiffAN} .}, a topological\nordering algorithm that leverages DPMs for learning a Hessian function. We\nintroduce theory for updating the learned Hessian without re-training the\nneural network, and we show that computing with a subset of samples gives an\naccurate approximation of the ordering, which allows scaling to datasets with\nmore samples and variables. We show empirically that our method scales\nexceptionally well to datasets with up to $500$ nodes and up to $10^5$ samples\nwhile still performing on par over small datasets with state-of-the-art causal\ndiscovery methods. Implementation is available at\nhttps://github.com/vios-s/DiffAN .", "published": "2022-10-12T13:36:29Z", "version": 2}, {"aid": "2210.06223", "authors": ["Yizeng Han", "Zhihang Yuan", "Yifan Pu", "Chenhao Xue", "Shiji Song", "Guangyu Sun", "Gao Huang"], "title": "Latency-aware Spatial-wise Dynamic Networks", "url": "http://arxiv.org/pdf/2210.06223v1", "summary": "Spatial-wise dynamic convolution has become a promising approach to improving\nthe inference efficiency of deep networks. By allocating more computation to\nthe most informative pixels, such an adaptive inference paradigm reduces the\nspatial redundancy in image features and saves a considerable amount of\nunnecessary computation. However, the theoretical efficiency achieved by\nprevious methods can hardly translate into a realistic speedup, especially on\nthe multi-core processors (e.g. GPUs). The key challenge is that the existing\nliterature has only focused on designing algorithms with minimal computation,\nignoring the fact that the practical latency can also be influenced by\nscheduling strategies and hardware properties. To bridge the gap between\ntheoretical computation and practical efficiency, we propose a latency-aware\nspatial-wise dynamic network (LASNet), which performs coarse-grained spatially\nadaptive inference under the guidance of a novel latency prediction model. The\nlatency prediction model can efficiently estimate the inference latency of\ndynamic networks by simultaneously considering algorithms, scheduling\nstrategies, and hardware properties. We use the latency predictor to guide both\nthe algorithm design and the scheduling optimization on various hardware\nplatforms. Experiments on image classification, object detection and instance\nsegmentation demonstrate that the proposed framework significantly improves the\npractical inference efficiency of deep networks. For example, the average\nlatency of a ResNet-101 on the ImageNet validation set could be reduced by 36%\nand 46% on a server GPU (Nvidia Tesla-V100) and an edge device (Nvidia Jetson\nTX2 GPU) respectively without sacrificing the accuracy. Code is available at\nhttps://github.com/LeapLabTHU/LASNet.", "published": "2022-10-12T14:09:27Z", "version": 1}, {"aid": "2210.06705", "authors": ["Satyen Kale", "Jason D. Lee", "Chris De Sa", "Ayush Sekhari", "Karthik Sridharan"], "title": "From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent", "url": "http://arxiv.org/pdf/2210.06705v1", "summary": "Stochastic Gradient Descent (SGD) has been the method of choice for learning\nlarge-scale non-convex models. While a general analysis of when SGD works has\nbeen elusive, there has been a lot of recent progress in understanding the\nconvergence of Gradient Flow (GF) on the population loss, partly due to the\nsimplicity that a continuous-time analysis buys us. An overarching theme of our\npaper is providing general conditions under which SGD converges, assuming that\nGF on the population loss converges. Our main tool to establish this connection\nis a general converse Lyapunov like theorem, which implies the existence of a\nLyapunov potential under mild assumptions on the rates of convergence of GF. In\nfact, using these potentials, we show a one-to-one correspondence between rates\nof convergence of GF and geometrical properties of the underlying objective.\nWhen these potentials further satisfy certain self-bounding properties, we show\nthat they can be used to provide a convergence guarantee for Gradient Descent\n(GD) and SGD (even when the paths of GF and GD/SGD are quite far apart). It\nturns out that these self-bounding assumptions are in a sense also necessary\nfor GD/SGD to work. Using our framework, we provide a unified analysis for\nGD/SGD not only for classical settings like convex losses, or objectives that\nsatisfy PL / KL properties, but also for more complex problems including Phase\nRetrieval and Matrix sq-root, and extending the results in the recent work of\nChatterjee 2022.", "published": "2022-10-13T03:55:04Z", "version": 1}, {"aid": "2210.06932", "authors": ["Chang Liu", "Yuwen Yang", "Yue Ding", "Hongtao Lu"], "title": "NoMorelization: Building Normalizer-Free Models from a Sample's Perspective", "url": "http://arxiv.org/pdf/2210.06932v1", "summary": "The normalizing layer has become one of the basic configurations of deep\nlearning models, but it still suffers from computational inefficiency,\ninterpretability difficulties, and low generality. After gaining a deeper\nunderstanding of the recent normalization and normalizer-free research works\nfrom a sample's perspective, we reveal the fact that the problem lies in the\nsampling noise and the inappropriate prior assumption. In this paper, we\npropose a simple and effective alternative to normalization, which is called\n\"NoMorelization\". NoMorelization is composed of two trainable scalars and a\nzero-centered noise injector. Experimental results demonstrate that\nNoMorelization is a general component for deep learning and is suitable for\ndifferent model paradigms (e.g., convolution-based and attention-based models)\nto tackle different tasks (e.g., discriminative and generative tasks). Compared\nwith existing mainstream normalizers (e.g., BN, LN, and IN) and\nstate-of-the-art normalizer-free methods, NoMorelization shows the best\nspeed-accuracy trade-off.", "published": "2022-10-13T12:04:24Z", "version": 1}, {"aid": "2210.06965", "authors": ["Cristina Vasconcelos", "Cengiz Oztireli", "Mark Matthews", "Milad Hashemi", "Kevin Swersky", "Andrea Tagliasacchi"], "title": "CUF: Continuous Upsampling Filters", "url": "http://arxiv.org/pdf/2210.06965v2", "summary": "Neural fields have rapidly been adopted for representing 3D signals, but\ntheir application to more classical 2D image-processing has been relatively\nlimited. In this paper, we consider one of the most important operations in\nimage processing: upsampling. In deep learning, learnable upsampling layers\nhave extensively been used for single image super-resolution. We propose to\nparameterize upsampling kernels as neural fields. This parameterization leads\nto a compact architecture that obtains a 40-fold reduction in the number of\nparameters when compared with competing arbitrary-scale super-resolution\narchitectures. When upsampling images of size 256x256 we show that our\narchitecture is 2x-10x more efficient than competing arbitrary-scale\nsuper-resolution architectures, and more efficient than sub-pixel convolutions\nwhen instantiated to a single-scale model. In the general setting, these gains\ngrow polynomially with the square of the target scale. We validate our method\non standard benchmarks showing such efficiency gains can be achieved without\nsacrifices in super-resolution performance.", "published": "2022-10-13T12:45:51Z", "version": 2}, {"aid": "2210.07069", "authors": ["Veronika Koren", "Stefano Panzeri"], "title": "Biologically plausible solutions for spiking networks with efficient coding", "url": "http://arxiv.org/pdf/2210.07069v2", "summary": "Understanding how the dynamics of neural networks is shaped by the\ncomputations they perform is a fundamental question in neuroscience. Recently,\nthe framework of efficient coding proposed a theory of how spiking neural\nnetworks can compute low-dimensional stimulus signals with high efficiency.\nEfficient spiking networks are based on time-dependent minimization of a loss\nfunction related to information coding with spikes. To inform the understanding\nof the function and dynamics of biological networks in the brain, however, the\nmathematical models have to be informed by biology and obey the same\nconstraints as biological networks. Currently, spiking network models of\nefficient coding have been extended to include some features of biological\nplausibility, such as architectures with excitatory and inhibitory neurons.\nHowever, biological realism of efficient coding theories is still limited to\nsimple cases and does not include single neuron and network properties that are\nknown to be key in biological circuits. Here, we revisit the theory of\nefficient coding with spikes to develop spiking neural networks that are closer\nto biological circuits. Namely, we find a biologically plausible spiking model\nrealizing efficient coding in the case of a generalized leaky\nintegrate-and-fire network with excitatory and inhibitory units, equipped with\nfast and slow synaptic currents, local homeostatic currents such as\nspike-triggered adaptation, hyperpolarization-activated rebound current,\nheterogeneous firing thresholds and resets, heterogeneous postsynaptic\npotentials, and structured, low-rank connectivity. We show how the complexity\nof E-E connectivity matrix shapes network responses.", "published": "2022-10-13T14:49:51Z", "version": 2}, {"aid": "2210.07906", "authors": ["Cecilia Latotzke", "Batuhan Balim", "Tobias Gemmeke"], "title": "Post-Training Quantization for Energy Efficient Realization of Deep Neural Networks", "url": "http://arxiv.org/pdf/2210.07906v1", "summary": "The biggest challenge for the deployment of Deep Neural Networks (DNNs) close\nto the generated data on edge devices is their size, i.e., memory footprint and\ncomputational complexity. Both are significantly reduced with quantization.\nWith the resulting lower word-length, the energy efficiency of DNNs increases\nproportionally. However, lower word-length typically causes accuracy\ndegradation. To counteract this effect, the quantized DNN is retrained.\nUnfortunately, training costs up to 5000x more energy than the inference of the\nquantized DNN. To address this issue, we propose a post-training quantization\nflow without the need for retraining. For this, we investigated different\nquantization options. Furthermore, our analysis systematically assesses the\nimpact of reduced word-lengths of weights and activations revealing a clear\ntrend for the choice of word-length. Both aspects have not been systematically\ninvestigated so far. Our results are independent of the depth of the DNNs and\napply to uniform quantization, allowing fast quantization of a given\npre-trained DNN. We excel state-of-the-art for 6 bit by 2.2% Top-1 accuracy for\nImageNet. Without retraining, our quantization to 8 bit surpasses\nfloating-point accuracy.", "published": "2022-10-14T15:43:57Z", "version": 1}, {"aid": "2210.08772", "authors": ["Dejia Xu", "Peihao Wang", "Yifan Jiang", "Zhiwen Fan", "Zhangyang Wang"], "title": "Signal Processing for Implicit Neural Representations", "url": "http://arxiv.org/pdf/2210.08772v3", "summary": "Implicit Neural Representations (INRs) encoding continuous multi-media data\nvia multi-layer perceptrons has shown undebatable promise in various computer\nvision tasks. Despite many successful applications, editing and processing an\nINR remains intractable as signals are represented by latent parameters of a\nneural network. Existing works manipulate such continuous representations via\nprocessing on their discretized instance, which breaks down the compactness and\ncontinuous nature of INR. In this work, we present a pilot study on the\nquestion: how to directly modify an INR without explicit decoding? We answer\nthis question by proposing an implicit neural signal processing network, dubbed\nINSP-Net, via differential operators on INR. Our key insight is that spatial\ngradients of neural networks can be computed analytically and are invariant to\ntranslation, while mathematically we show that any continuous convolution\nfilter can be uniformly approximated by a linear combination of high-order\ndifferential operators. With these two knobs, INSP-Net instantiates the signal\nprocessing operator as a weighted composition of computational graphs\ncorresponding to the high-order derivatives of INRs, where the weighting\nparameters can be data-driven learned. Based on our proposed INSP-Net, we\nfurther build the first Convolutional Neural Network (CNN) that implicitly runs\non INRs, named INSP-ConvNet. Our experiments validate the expressiveness of\nINSP-Net and INSP-ConvNet in fitting low-level image and geometry processing\nkernels (e.g. blurring, deblurring, denoising, inpainting, and smoothening) as\nwell as for high-level tasks on implicit fields such as image classification.", "published": "2022-10-17T06:29:07Z", "version": 3}, {"aid": "2210.09446", "authors": ["Stefano B. Blumberg", "Daniele Rav\u00ed", "Mou-Cheng Xu", "Matteo Figini", "Iasonas Kokkinos", "Daniel C. Alexander"], "title": "Deformably-Scaled Transposed Convolution", "url": "http://arxiv.org/pdf/2210.09446v1", "summary": "Transposed convolution is crucial for generating high-resolution outputs, yet\nhas received little attention compared to convolution layers. In this work we\nrevisit transposed convolution and introduce a novel layer that allows us to\nplace information in the image selectively and choose the `stroke breadth' at\nwhich the image is synthesized, whilst incurring a small additional parameter\ncost. For this we introduce three ideas: firstly, we regress offsets to the\npositions where the transpose convolution results are placed; secondly we\nbroadcast the offset weight locations over a learnable neighborhood; and\nthirdly we use a compact parametrization to share weights and restrict offsets.\nWe show that simply substituting upsampling operators with our novel layer\nproduces substantial improvements across tasks as diverse as instance\nsegmentation, object detection, semantic segmentation, generative image\nmodeling, and 3D magnetic resonance image enhancement, while outperforming all\nexisting variants of transposed convolutions. Our novel layer can be used as a\ndrop-in replacement for 2D and 3D upsampling operators and the code will be\npublicly available.", "published": "2022-10-17T21:35:29Z", "version": 1}, {"aid": "2210.09486", "authors": ["Md Mahmudur Rahman", "Rameswar Panda", "Mohammad Arif Ul Alam"], "title": "Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous Learning", "url": "http://arxiv.org/pdf/2210.09486v1", "summary": "We present a new semi-supervised domain adaptation framework that combines a\nnovel auto-encoder-based domain adaptation model with a simultaneous learning\nscheme providing stable improvements over state-of-the-art domain adaptation\nmodels. Our framework holds strong distribution matching property by training\nboth source and target auto-encoders using a novel simultaneous learning scheme\non a single graph with an optimally modified MMD loss objective function.\nAdditionally, we design a semi-supervised classification approach by\ntransferring the aligned domain invariant feature spaces from source domain to\nthe target domain. We evaluate on three datasets and show proof that our\nframework can effectively solve both fragile convergence (adversarial) and weak\ndistribution matching problems between source and target feature space\n(discrepancy) with a high `speed' of adaptation requiring a very low number of\niterations.", "published": "2022-10-18T00:10:11Z", "version": 1}, {"aid": "2210.09655", "authors": ["Chaewon Kim", "Seung-Jun Moon", "Gyeong-Moon Park"], "title": "WINE: Wavelet-Guided GAN Inversion and Editing for High-Fidelity Refinement", "url": "http://arxiv.org/pdf/2210.09655v2", "summary": "Recent advanced GAN inversion models aim to convey high-fidelity information\nfrom original images to generators through methods using generator tuning or\nhigh-dimensional feature learning. Despite these efforts, accurately\nreconstructing image-specific details remains as a challenge due to the\ninherent limitations both in terms of training and structural aspects, leading\nto a bias towards low-frequency information. In this paper, we look into the\nwidely used pixel loss in GAN inversion, revealing its predominant focus on the\nreconstruction of low-frequency features. We then propose WINE, a\nWavelet-guided GAN Inversion aNd Editing model, which transfers the\nhigh-frequency information through wavelet coefficients via newly proposed\nwavelet loss and wavelet fusion scheme. Notably, WINE is the first attempt to\ninterpret GAN inversion in the frequency domain. Our experimental results\nshowcase the precision of WINE in preserving high-frequency details and\nenhancing image quality. Even in editing scenarios, WINE outperforms existing\nstate-of-the-art GAN inversion models with a fine balance between editability\nand reconstruction quality.", "published": "2022-10-18T07:48:59Z", "version": 2}, {"aid": "2210.09765", "authors": ["Fernando Alonso-Fernandez", "Reuben A. Farrugia", "Josef Bigun"], "title": "Very Low-Resolution Iris Recognition Via Eigen-Patch Super-Resolution and Matcher Fusion", "url": "http://arxiv.org/pdf/2210.09765v1", "summary": "Current research in iris recognition is moving towards enabling more relaxed\nacquisition conditions. This has effects on the quality of acquired images,\nwith low resolution being a predominant issue. Here, we evaluate a\nsuper-resolution algorithm used to reconstruct iris images based on\nEigen-transformation of local image patches. Each patch is reconstructed\nseparately, allowing better quality of enhanced images by preserving local\ninformation. Contrast enhancement is used to improve the reconstruction\nquality, while matcher fusion has been adopted to improve iris recognition\nperformance. We validate the system using a database of 1,872 near-infrared\niris images. The presented approach is superior to bilinear or bicubic\ninterpolation, especially at lower resolutions, and the fusion of the two\nsystems pushes the EER to below 5% for down-sampling factors up to a image size\nof only 13x13.", "published": "2022-10-18T11:25:19Z", "version": 1}, {"aid": "2210.09879", "authors": ["Jan Niklas B\u00f6hm", "Philipp Berens", "Dmitry Kobak"], "title": "Unsupervised visualization of image datasets using contrastive learning", "url": "http://arxiv.org/pdf/2210.09879v3", "summary": "Visualization methods based on the nearest neighbor graph, such as t-SNE or\nUMAP, are widely used for visualizing high-dimensional data. Yet, these\napproaches only produce meaningful results if the nearest neighbors themselves\nare meaningful. For images represented in pixel space this is not the case, as\ndistances in pixel space are often not capturing our sense of similarity and\ntherefore neighbors are not semantically close. This problem can be\ncircumvented by self-supervised approaches based on contrastive learning, such\nas SimCLR, relying on data augmentation to generate implicit neighbors, but\nthese methods do not produce two-dimensional embeddings suitable for\nvisualization. Here, we present a new method, called t-SimCNE, for unsupervised\nvisualization of image data. T-SimCNE combines ideas from contrastive learning\nand neighbor embeddings, and trains a parametric mapping from the\nhigh-dimensional pixel space into two dimensions. We show that the resulting 2D\nembeddings achieve classification accuracy comparable to the state-of-the-art\nhigh-dimensional SimCLR representations, thus faithfully capturing semantic\nrelationships. Using t-SimCNE, we obtain informative visualizations of the\nCIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and\nhighlighting artifacts and outliers.", "published": "2022-10-18T14:13:20Z", "version": 3}, {"aid": "2210.09962", "authors": ["Harshan Baskar", "Anirudh S Chakravarthy", "Prateek Garg", "Divyam Goel", "Abhijith S Raj", "Kshitij Kumar", "Lakshya", "Ravichandra Parvatham", "V Sushant", "Bijay Kumar Rout"], "title": "Nighttime Dehaze-Enhancement", "url": "http://arxiv.org/pdf/2210.09962v1", "summary": "In this paper, we introduce a new computer vision task called nighttime\ndehaze-enhancement. This task aims to jointly perform dehazing and lightness\nenhancement. Our task fundamentally differs from nighttime dehazing -- our goal\nis to jointly dehaze and enhance scenes, while nighttime dehazing aims to\ndehaze scenes under a nighttime setting. In order to facilitate further\nresearch on this task, we release a new benchmark dataset called Reside-$\\beta$\nNight dataset, consisting of 4122 nighttime hazed images from 2061 scenes and\n2061 ground truth images. Moreover, we also propose a new network called NDENet\n(Nighttime Dehaze-Enhancement Network), which jointly performs dehazing and\nlow-light enhancement in an end-to-end manner. We evaluate our method on the\nproposed benchmark and achieve SSIM of 0.8962 and PSNR of 26.25. We also\ncompare our network with other baseline networks on our benchmark to\ndemonstrate the effectiveness of our approach. We believe that nighttime\ndehaze-enhancement is an essential task particularly for autonomous navigation\napplications, and hope that our work will open up new frontiers in research.\nOur dataset and code will be made publicly available upon acceptance of our\npaper.", "published": "2022-10-18T16:19:25Z", "version": 1}, {"aid": "2210.10205", "authors": ["Eric Luhman", "Troy Luhman"], "title": "Optimizing Hierarchical Image VAEs for Sample Quality", "url": "http://arxiv.org/pdf/2210.10205v1", "summary": "While hierarchical variational autoencoders (VAEs) have achieved great\ndensity estimation on image modeling tasks, samples from their prior tend to\nlook less convincing than models with similar log-likelihood. We attribute this\nto learned representations that over-emphasize compressing imperceptible\ndetails of the image. To address this, we introduce a KL-reweighting strategy\nto control the amount of infor mation in each latent group, and employ a\nGaussian output layer to reduce sharpness in the learning objective. To trade\noff image diversity for fidelity, we additionally introduce a classifier-free\nguidance strategy for hierarchical VAEs. We demonstrate the effectiveness of\nthese techniques in our experiments. Code is available at\nhttps://github.com/tcl9876/visual-vae.", "published": "2022-10-18T23:10:58Z", "version": 1}, {"aid": "2210.10275", "authors": ["Sean Kulinski", "David I. Inouye"], "title": "Towards Explaining Distribution Shifts", "url": "http://arxiv.org/pdf/2210.10275v2", "summary": "A distribution shift can have fundamental consequences such as signaling a\nchange in the operating environment or significantly reducing the accuracy of\ndownstream models. Thus, understanding distribution shifts is critical for\nexamining and hopefully mitigating the effect of such a shift. Most prior work\nfocuses on merely detecting if a shift has occurred and assumes any detected\nshift can be understood and handled appropriately by a human operator. We hope\nto aid in these manual mitigation tasks by explaining the distribution shift\nusing interpretable transportation maps from the original distribution to the\nshifted one. We derive our interpretable mappings from a relaxation of optimal\ntransport, where the candidate mappings are restricted to a set of\ninterpretable mappings. We then inspect multiple quintessential use-cases of\ndistribution shift in real-world tabular, text, and image datasets to showcase\nhow our explanatory mappings provide a better balance between detail and\ninterpretability than baseline explanations by both visual inspection and our\nPercentExplained metric.", "published": "2022-10-19T03:38:57Z", "version": 2}, {"aid": "2210.10413", "authors": ["Rao Muhammad Umer", "Christian Micheloni"], "title": "Real Image Super-Resolution using GAN through modeling of LR and HR process", "url": "http://arxiv.org/pdf/2210.10413v1", "summary": "The current existing deep image super-resolution methods usually assume that\na Low Resolution (LR) image is bicubicly downscaled of a High Resolution (HR)\nimage. However, such an ideal bicubic downsampling process is different from\nthe real LR degradations, which usually come from complicated combinations of\ndifferent degradation processes, such as camera blur, sensor noise, sharpening\nartifacts, JPEG compression, and further image editing, and several times image\ntransmission over the internet and unpredictable noises. It leads to the highly\nill-posed nature of the inverse upscaling problem. To address these issues, we\npropose a GAN-based SR approach with learnable adaptive sinusoidal\nnonlinearities incorporated in LR and SR models by directly learn degradation\ndistributions and then synthesize paired LR/HR training data to train the\ngeneralized SR model to real image degradations. We demonstrate the\neffectiveness of our proposed approach in quantitative and qualitative\nexperiments.", "published": "2022-10-19T09:23:37Z", "version": 1}, {"aid": "2210.10605", "authors": ["Charles Laroche", "Andr\u00e9s Almansa", "Eva Coupet\u00e9", "Matias Tassano"], "title": "Provably Convergent Plug & Play Linearized ADMM, applied to Deblurring Spatially Varying Kernels", "url": "http://arxiv.org/pdf/2210.10605v3", "summary": "Plug & Play methods combine proximal algorithms with denoiser priors to solve\ninverse problems. These methods rely on the computability of the proximal\noperator of the data fidelity term. In this paper, we propose a Plug & Play\nframework based on linearized ADMM that allows us to bypass the computation of\nintractable proximal operators. We demonstrate the convergence of the algorithm\nand provide results on restoration tasks such as super-resolution and\ndeblurring with non-uniform blur.", "published": "2022-10-19T14:51:44Z", "version": 3}, {"aid": "2210.11549", "authors": ["Ziyue Xiang", "Paolo Bestagini", "Stefano Tubaro", "Edward J. Delp"], "title": "H4VDM: H.264 Video Device Matching", "url": "http://arxiv.org/pdf/2210.11549v3", "summary": "Methods that can determine if two given video sequences are captured by the\nsame device (e.g., mobile telephone or digital camera) can be used in many\nforensics tasks. In this paper we refer to this as \"video device matching\". In\nopen-set video forensics scenarios it is easier to determine if two video\nsequences were captured with the same device than identifying the specific\ndevice. In this paper, we propose a technique for open-set video device\nmatching. Given two H.264 compressed video sequences, our method can determine\nif they are captured by the same device, even if our method has never\nencountered the device in training. We denote our proposed technique as H.264\nVideo Device Matching (H4VDM). H4VDM uses H.264 compression information\nextracted from video sequences to make decisions. It is more robust against\nartifacts that alter camera sensor fingerprints, and it can be used to analyze\nrelatively small fragments of the H.264 sequence. We trained and tested our\nmethod on a publicly available video forensics dataset consisting of 35\ndevices, where our proposed method demonstrated good performance.", "published": "2022-10-20T19:31:23Z", "version": 3}, {"aid": "2210.11672", "authors": ["Kyungsu Lee", "Jaeseung Yang", "Haeyun Lee", "Jae Youn Hwang"], "title": "Stochastic Adaptive Activation Function", "url": "http://arxiv.org/pdf/2210.11672v1", "summary": "The simulation of human neurons and neurotransmission mechanisms has been\nrealized in deep neural networks based on the theoretical implementations of\nactivation functions. However, recent studies have reported that the threshold\npotential of neurons exhibits different values according to the locations and\ntypes of individual neurons, and that the activation functions have limitations\nin terms of representing this variability. Therefore, this study proposes a\nsimple yet effective activation function that facilitates different thresholds\nand adaptive activations according to the positions of units and the contexts\nof inputs. Furthermore, the proposed activation function mathematically\nexhibits a more generalized form of Swish activation function, and thus we\ndenoted it as Adaptive SwisH (ASH). ASH highlights informative features that\nexhibit large values in the top percentiles in an input, whereas it rectifies\nlow values. Most importantly, ASH exhibits trainable, adaptive, and\ncontext-aware properties compared to other activation functions. Furthermore,\nASH represents general formula of the previously studied activation function\nand provides a reasonable mathematical background for the superior performance.\nTo validate the effectiveness and robustness of ASH, we implemented ASH into\nmany deep learning models for various tasks, including classification,\ndetection, segmentation, and image generation. Experimental analysis\ndemonstrates that our activation function can provide the benefits of more\naccurate prediction and earlier convergence in many deep learning applications.", "published": "2022-10-21T01:57:25Z", "version": 1}, {"aid": "2210.11675", "authors": ["Shuyin Xia", "Xiaoyu Lian", "Guoyin Wang", "Xinbo Gao", "Yabin Shao"], "title": "Granular-Ball Fuzzy Set and Its Implementation in SVM", "url": "http://arxiv.org/pdf/2210.11675v2", "summary": "Most existing fuzzy set methods use points as their input, which is the\nfinest granularity from the perspective of granular computing. Consequently,\nthese methods are neither efficient nor robust to label noise. Therefore, we\npropose a frame-work called granular-ball fuzzy set by introducing\ngranular-ball computing into fuzzy set. The computational framework is based on\nthe granular-balls input rather than points; therefore, it is more efficient\nand robust than traditional fuzzy methods, and can be used in various fields of\nfuzzy data processing according to its extensibility. Furthermore, the\nframework is extended to the classifier fuzzy support vector machine (FSVM), to\nderive the granular ball fuzzy SVM (GBFSVM). The experimental results\ndemonstrate the effectiveness and efficiency of GBFSVM.", "published": "2022-10-21T02:03:52Z", "version": 2}, {"aid": "2210.11707", "authors": ["Mayu Otani", "Yale Song", "Yang Wang"], "title": "Video Summarization Overview", "url": "http://arxiv.org/pdf/2210.11707v1", "summary": "With the broad growth of video capturing devices and applications on the web,\nit is more demanding to provide desired video content for users efficiently.\nVideo summarization facilitates quickly grasping video content by creating a\ncompact summary of videos. Much effort has been devoted to automatic video\nsummarization, and various problem settings and approaches have been proposed.\nOur goal is to provide an overview of this field. This survey covers early\nstudies as well as recent approaches which take advantage of deep learning\ntechniques. We describe video summarization approaches and their underlying\nconcepts. We also discuss benchmarks and evaluations. We overview how prior\nwork addressed evaluation and detail the pros and cons of the evaluation\nprotocols. Last but not least, we discuss open challenges in this field.", "published": "2022-10-21T03:29:31Z", "version": 1}, {"aid": "2210.12254", "authors": ["Vikram Voleti", "Christopher Pal", "Adam Oberman"], "title": "Score-based Denoising Diffusion with Non-Isotropic Gaussian Noise Models", "url": "http://arxiv.org/pdf/2210.12254v2", "summary": "Generative models based on denoising diffusion techniques have led to an\nunprecedented increase in the quality and diversity of imagery that is now\npossible to create with neural generative models. However, most contemporary\nstate-of-the-art methods are derived from a standard isotropic Gaussian\nformulation. In this work we examine the situation where non-isotropic Gaussian\ndistributions are used. We present the key mathematical derivations for\ncreating denoising diffusion models using an underlying non-isotropic Gaussian\nnoise model. We also provide initial experiments with the CIFAR-10 dataset to\nhelp verify empirically that this more general modeling approach can also yield\nhigh-quality samples.", "published": "2022-10-21T21:16:46Z", "version": 2}, {"aid": "2210.12523", "authors": ["Athiya Deviyani", "Efe Sinan Hoplamaz", "Alan Savio Paul"], "title": "How Real is Real: Evaluating the Robustness of Real-World Super Resolution", "url": "http://arxiv.org/pdf/2210.12523v1", "summary": "Image super-resolution (SR) is a field in computer vision that focuses on\nreconstructing high-resolution images from the respective low-resolution image.\nHowever, super-resolution is a well-known ill-posed problem as most methods\nrely on the downsampling method performed on the high-resolution image to form\nthe low-resolution image to be known. Unfortunately, this is not something that\nis available in real-life super-resolution applications such as increasing the\nquality of a photo taken on a mobile phone. In this paper we will evaluate\nmultiple state-of-the-art super-resolution methods and gauge their performance\nwhen presented with various types of real-life images and discuss the benefits\nand drawbacks of each method. We also introduce a novel dataset, WideRealSR,\ncontaining real images from a wide variety of sources. Finally, through careful\nexperimentation and evaluation, we will present a potential solution to\nalleviate the generalization problem which is imminent in most state-of-the-art\nsuper-resolution models.", "published": "2022-10-22T18:53:45Z", "version": 1}, {"aid": "2210.13461", "authors": ["Rajesh P. N. Rao", "Dimitrios C. Gklezakos", "Vishwas Sathish"], "title": "Active Predictive Coding: A Unified Neural Framework for Learning Hierarchical World Models for Perception and Planning", "url": "http://arxiv.org/pdf/2210.13461v1", "summary": "Predictive coding has emerged as a prominent model of how the brain learns\nthrough predictions, anticipating the importance accorded to predictive\nlearning in recent AI architectures such as transformers. Here we propose a new\nframework for predictive coding called active predictive coding which can learn\nhierarchical world models and solve two radically different open problems in\nAI: (1) how do we learn compositional representations, e.g., part-whole\nhierarchies, for equivariant vision? and (2) how do we solve large-scale\nplanning problems, which are hard for traditional reinforcement learning, by\ncomposing complex action sequences from primitive policies? Our approach\nexploits hypernetworks, self-supervised learning and reinforcement learning to\nlearn hierarchical world models that combine task-invariant state transition\nnetworks and task-dependent policy networks at multiple abstraction levels. We\ndemonstrate the viability of our approach on a variety of vision datasets\n(MNIST, FashionMNIST, Omniglot) as well as on a scalable hierarchical planning\nproblem. Our results represent, to our knowledge, the first demonstration of a\nunified solution to the part-whole learning problem posed by Hinton, the nested\nreference frames problem posed by Hawkins, and the integrated state-action\nhierarchy learning problem in reinforcement learning.", "published": "2022-10-23T05:44:22Z", "version": 1}, {"aid": "2210.12746", "authors": ["Rozenn Dahyot"], "title": "Principal Component Classification", "url": "http://arxiv.org/pdf/2210.12746v2", "summary": "We propose to directly compute classification estimates by learning features\nencoded with their class scores using PCA. Our resulting model has a\nencoder-decoder structure suitable for supervised learning, it is\ncomputationally efficient and performs well for classification on several\ndatasets.", "published": "2022-10-23T15:05:14Z", "version": 2}, {"aid": "2210.12761", "authors": ["Karl Friston", "Lancelot Da Costa", "Dalton A. R. Sakthivadivel", "Conor Heins", "Grigorios A. Pavliotis", "Maxwell Ramstead", "Thomas Parr"], "title": "Path integrals, particular kinds, and strange things", "url": "http://arxiv.org/pdf/2210.12761v3", "summary": "This paper describes a path integral formulation of the free energy\nprinciple. The ensuing account expresses the paths or trajectories that a\nparticle takes as it evolves over time. The main results are a method or\nprinciple of least action that can be used to emulate the behaviour of\nparticles in open exchange with their external milieu. Particles are defined by\na particular partition, in which internal states are individuated from external\nstates by active and sensory blanket states. The variational principle at hand\nallows one to interpret internal dynamics - of certain kinds of particles - as\ninferring external states that are hidden behind blanket states. We consider\ndifferent kinds of particles, and to what extent they can be imbued with an\nelementary form of inference or sentience. Specifically, we consider the\ndistinction between dissipative and conservative particles, inert and active\nparticles and, finally, ordinary and strange particles. Strange particles can\nbe described as inferring their own actions, endowing them with apparent\nautonomy or agency. In short - of the kinds of particles afforded by a\nparticular partition - strange kinds may be apt for describing sentient\nbehaviour.", "published": "2022-10-23T16:01:16Z", "version": 3}, {"aid": "2210.13564", "authors": ["Alfonso Nieto-Castanon"], "title": "Preparing fMRI Data for Statistical Analysis", "url": "http://arxiv.org/pdf/2210.13564v1", "summary": "This chapter describes several procedures used to prepare fMRI data for\nstatistical analyses. It includes the description of common preprocessing\nsteps, such as spatial realignment, coregistration, and spatial normalization,\naimed at the spatial alignment of all fMRI data within- and between- subjects,\nas well as several denoising procedures aimed at minimizing the impact of\ncommon noise sources, including physiological and residual subject motion\neffects, on the BOLD signal time series. The chapter ends with a description of\nquality control procedures recommended for detecting potential problems in the\nfMRI data and evaluating its suitability for subsequent statistical analyses.", "published": "2022-10-24T19:38:45Z", "version": 1}, {"aid": "2210.14219", "authors": ["Pavol Harar", "Dennis Elbr\u00e4chter", "Monika D\u00f6rfler", "Kory D. Johnson"], "title": "Redistributor: Transforming Empirical Data Distributions", "url": "http://arxiv.org/pdf/2210.14219v2", "summary": "We present an algorithm and package, Redistributor, which forces a collection\nof scalar samples to follow a desired distribution. When given independent and\nidentically distributed samples of some random variable $S$ and the continuous\ncumulative distribution function of some desired target $T$, it provably\nproduces a consistent estimator of the transformation $R$ which satisfies\n$R(S)=T$ in distribution. As the distribution of $S$ or $T$ may be unknown, we\nalso include algorithms for efficiently estimating these distributions from\nsamples. This allows for various interesting use cases in image processing,\nwhere Redistributor serves as a remarkably simple and easy-to-use tool that is\ncapable of producing visually appealing results. For color correction it\noutperforms other model-based methods and excels in achieving photorealistic\nstyle transfer, surpassing deep learning methods in content preservation. The\npackage is implemented in Python and is optimized to efficiently handle large\ndatasets, making it also suitable as a preprocessing step in machine learning.\nThe source code is available at https://github.com/paloha/redistributor.", "published": "2022-10-25T17:59:03Z", "version": 2}, {"aid": "2210.14907", "authors": ["Pouria Mistani", "Samira Pakravan", "Rajesh Ilango", "Sanjay Choudhry", "Frederic Gibou"], "title": "Neuro-symbolic partial differential equation solver", "url": "http://arxiv.org/pdf/2210.14907v1", "summary": "We present a highly scalable strategy for developing mesh-free neuro-symbolic\npartial differential equation solvers from existing numerical discretizations\nfound in scientific computing. This strategy is unique in that it can be used\nto efficiently train neural network surrogate models for the solution functions\nand the differential operators, while retaining the accuracy and convergence\nproperties of state-of-the-art numerical solvers. This neural bootstrapping\nmethod is based on minimizing residuals of discretized differential systems on\na set of random collocation points with respect to the trainable parameters of\nthe neural network, achieving unprecedented resolution and optimal scaling for\nsolving physical and biological systems.", "published": "2022-10-25T22:56:43Z", "version": 1}, {"aid": "2210.14491", "authors": ["Hana Hebishima", "Mina Arakaki", "Chikako Dozono", "Hanna Frolova", "Shinichi Inage"], "title": "Mathematical definition of public language, and modeling of will and consciousness based on the public language", "url": "http://arxiv.org/pdf/2210.14491v1", "summary": "To propose a mathematical model of consciousness and will, we first simulated\nthe inverted qualia with a toy model of a neural network. As a result, we\nconfirmed that there can be an inverted qualia on the neural network. In other\nwords, the qualia were individual-dependent and considered difficult as an\nindicator of consciousness and will. To solve that difficulty, we introduce a\nprobability space and a random variable into a set of qualia and define a\npublic language for events. Based on this idea of public language,\nconsciousness and will are modeled. In this proposal, future actions are\nrandomly selected from the comparison between \"recognition of events\" by\nexternal observation and past episodic memory, and the actual \"recognition of\nactions\" is regarded as the occurrence of consciousness. The basic formula is\nalso derived. This proposal is compared with other past philosophical\ndiscussions.", "published": "2022-10-26T05:32:27Z", "version": 1}, {"aid": "2211.08408", "authors": ["Nikolay Manchev", "Michael Spratling"], "title": "On the biological plausibility of orthogonal initialisation for solving gradient instability in deep neural networks", "url": "http://arxiv.org/pdf/2211.08408v1", "summary": "Initialising the synaptic weights of artificial neural networks (ANNs) with\northogonal matrices is known to alleviate vanishing and exploding gradient\nproblems. A major objection against such initialisation schemes is that they\nare deemed biologically implausible as they mandate factorization techniques\nthat are difficult to attribute to a neurobiological process. This paper\npresents two initialisation schemes that allow a network to naturally evolve\nits weights to form orthogonal matrices, provides theoretical analysis that\npre-training orthogonalisation always converges, and empirically confirms that\nthe proposed schemes outperform randomly initialised recurrent and feedforward\nnetworks.", "published": "2022-10-27T06:08:06Z", "version": 1}, {"aid": "2211.05567", "authors": ["Shudong Huang", "Wentao Feng", "Chenwei Tang", "Jiancheng Lv"], "title": "Partial Differential Equations Meet Deep Neural Networks: A Survey", "url": "http://arxiv.org/pdf/2211.05567v2", "summary": "Many problems in science and engineering can be represented by a set of\npartial differential equations (PDEs) through mathematical modeling.\nMechanism-based computation following PDEs has long been an essential paradigm\nfor studying topics such as computational fluid dynamics, multiphysics\nsimulation, molecular dynamics, or even dynamical systems. It is a vibrant\nmulti-disciplinary field of increasing importance and with extraordinary\npotential. At the same time, solving PDEs efficiently has been a long-standing\nchallenge. Generally, except for a few differential equations for which\nanalytical solutions are directly available, many more equations must rely on\nnumerical approaches such as the finite difference method, finite element\nmethod, finite volume method, and boundary element method to be solved\napproximately. These numerical methods usually divide a continuous problem\ndomain into discrete points and then concentrate on solving the system at each\nof those points. Though the effectiveness of these traditional numerical\nmethods, the vast number of iterative operations accompanying each step forward\nsignificantly reduces the efficiency. Recently, another equally important\nparadigm, data-based computation represented by deep learning, has emerged as\nan effective means of solving PDEs. Surprisingly, a comprehensive review for\nthis interesting subfield is still lacking. This survey aims to categorize and\nreview the current progress on Deep Neural Networks (DNNs) for PDEs. We discuss\nthe literature published in this subfield over the past decades and present\nthem in a common taxonomy, followed by an overview and classification of\napplications of these related methods in scientific research and engineering\nscenarios. The origin, developing history, character, sort, as well as the\nfuture trends in each potential direction of this subfield are also introduced.", "published": "2022-10-27T07:01:56Z", "version": 2}, {"aid": "2210.15818", "authors": ["Salman Mohamadi", "Gianfranco Doretto", "Donald A. Adjeroh"], "title": "FUSSL: Fuzzy Uncertain Self Supervised Learning", "url": "http://arxiv.org/pdf/2210.15818v1", "summary": "Self supervised learning (SSL) has become a very successful technique to\nharness the power of unlabeled data, with no annotation effort. A number of\ndeveloped approaches are evolving with the goal of outperforming supervised\nalternatives, which have been relatively successful. One main issue in SSL is\nrobustness of the approaches under different settings. In this paper, for the\nfirst time, we recognize the fundamental limits of SSL coming from the use of a\nsingle-supervisory signal. To address this limitation, we leverage the power of\nuncertainty representation to devise a robust and general standard hierarchical\nlearning/training protocol for any SSL baseline, regardless of their\nassumptions and approaches. Essentially, using the information bottleneck\nprinciple, we decompose feature learning into a two-stage training procedure,\neach with a distinct supervision signal. This double supervision approach is\ncaptured in two key steps: 1) invariance enforcement to data augmentation, and\n2) fuzzy pseudo labeling (both hard and soft annotation). This simple, yet,\neffective protocol which enables cross-class/cluster feature learning, is\ninstantiated via an initial training of an ensemble of models through\ninvariance enforcement to data augmentation as first training phase, and then\nassigning fuzzy labels to the original samples for the second training phase.\nWe consider multiple alternative scenarios with double supervision and evaluate\nthe effectiveness of our approach on recent baselines, covering four different\nSSL paradigms, including geometrical, contrastive, non-contrastive, and\nhard/soft whitening (redundancy reduction) baselines. Extensive experiments\nunder multiple settings show that the proposed training protocol consistently\nimproves the performance of the former baselines, independent of their\nrespective underlying principles.", "published": "2022-10-28T01:06:10Z", "version": 1}, {"aid": "2210.15957", "authors": ["Gagan Acharya", "Sebastian F. Ruf", "Erfan Nozari"], "title": "Brain Modeling for Control: A Review", "url": "http://arxiv.org/pdf/2210.15957v1", "summary": "Neurostimulation technologies have seen a recent surge in interest from the\nneuroscience and controls communities alike due to their proven potential to\ntreat conditions such as Parkinson's Disease, and depression. The provided\nstimulation can be of different types, such as electric, and optogenetic, and\nis generally applied to a specific region of the brain in order to drive the\nlocal and/or global dynamics to a desired state of (in)activity. However, an\nunderlying theoretical understanding of the efficacy of neurostimulation is\nstill lacking. From a control-theoretic perspective, it is important to\nunderstand how each stimulus modality interacts with the complex brain network\nin order to assess the controllability of the system and develop\nneurophysiologically relevant computational models that can be used to design\nthe stimulation profile in a closed-loop manner. In this paper, we review the\ncomputational modeling studies of (i) deep brain stimulation, (ii) transcranial\nmagnetic stimulation, (iii) direct current stimulation, (iv) transcranial\nelectrical stimulation, and (v) optogenetics as five of the most popular\nneurostimulation technologies in research and clinical settings. For each\ntechnology, we split the reviewed studies into (a)theory-driven biophysical\nmodels capturing the low-level physics of the interactions between the\nstimulation source and neuronal tissue, (b) data-driven stimulus-response\nmodels which capture the end-to-end effects of stimulation on various\nbiomarkers of interest and (c) data-driven dynamical system models that extract\nthe precise dynamics of the brain's response to neurostimulation from neural\ndata. While our focus is particularly on the latter category due to their\ngreater utility in control design, we review key works in the former two\ncategories as the basis and context in which dynamical system models have been\nand will be developed.", "published": "2022-10-28T07:23:31Z", "version": 1}, {"aid": "2210.16046", "authors": ["Masakazu Yoshimura", "Junji Otsuka", "Atsushi Irie", "Takeshi Ohashi"], "title": "Rawgment: Noise-Accounted RAW Augmentation Enables Recognition in a Wide Variety of Environments", "url": "http://arxiv.org/pdf/2210.16046v2", "summary": "Image recognition models that work in challenging environments (e.g.,\nextremely dark, blurry, or high dynamic range conditions) must be useful.\nHowever, creating training datasets for such environments is expensive and hard\ndue to the difficulties of data collection and annotation. It is desirable if\nwe could get a robust model without the need for hard-to-obtain datasets. One\nsimple approach is to apply data augmentation such as color jitter and blur to\nstandard RGB (sRGB) images in simple scenes. Unfortunately, this approach\nstruggles to yield realistic images in terms of pixel intensity and noise\ndistribution due to not considering the non-linearity of Image Signal\nProcessors (ISPs) and noise characteristics of image sensors. Instead, we\npropose a noise-accounted RAW image augmentation method. In essence, color\njitter and blur augmentation are applied to a RAW image before applying\nnon-linear ISP, resulting in realistic intensity. Furthermore, we introduce a\nnoise amount alignment method that calibrates the domain gap in the noise\nproperty caused by the augmentation. We show that our proposed noise-accounted\nRAW augmentation method doubles the image recognition accuracy in challenging\nenvironments only with simple training data.", "published": "2022-10-28T10:33:45Z", "version": 2}, {"aid": "2211.02144", "authors": ["Pablo Barcel\u00f3", "Mauricio Duarte", "Crist\u00f3bal Rojas", "Tomasz Steifer"], "title": "No Agreement Without Loss: Learning and Social Choice in Peer Review", "url": "http://arxiv.org/pdf/2211.02144v2", "summary": "In peer review systems, reviewers are often asked to evaluate various\nfeatures of submissions, such as technical quality or novelty. A score is given\nto each of the predefined features and based on these the reviewer has to\nprovide an overall quantitative recommendation. It may be assumed that each\nreviewer has her own mapping from the set of features to a recommendation, and\nthat different reviewers have different mappings in mind. This introduces an\nelement of arbitrariness known as commensuration bias. In this paper we discuss\na framework, introduced by Noothigattu, Shah and Procaccia, and then applied by\nthe organizers of the AAAI 2022 conference. Noothigattu, Shah and Procaccia\nproposed to aggregate reviewer's mapping by minimizing certain loss functions,\nand studied axiomatic properties of this approach, in the sense of social\nchoice theory. We challenge several of the results and assumptions used in\ntheir work and report a number of negative results. On the one hand, we study a\ntrade-off between some of the axioms proposed and the ability of the method to\nproperly capture agreements of the majority of reviewers. On the other hand, we\nshow that dropping a certain unrealistic assumption has dramatic effects,\nincluding causing the method to be discontinuous.", "published": "2022-11-03T21:03:23Z", "version": 2}, {"aid": "2211.02255", "authors": ["Kaiwen Hou", "Guillaume Rabusseau"], "title": "Spectral Regularization: an Inductive Bias for Sequence Modeling", "url": "http://arxiv.org/pdf/2211.02255v1", "summary": "Various forms of regularization in learning tasks strive for different\nnotions of simplicity. This paper presents a spectral regularization technique,\nwhich attaches a unique inductive bias to sequence modeling based on an\nintuitive concept of simplicity defined in the Chomsky hierarchy. From\nfundamental connections between Hankel matrices and regular grammars, we\npropose to use the trace norm of the Hankel matrix, the tightest convex\nrelaxation of its rank, as the spectral regularizer. To cope with the fact that\nthe Hankel matrix is bi-infinite, we propose an unbiased stochastic estimator\nfor its trace norm. Ultimately, we demonstrate experimental results on Tomita\ngrammars, which exhibit the potential benefits of spectral regularization and\nvalidate the proposed stochastic estimator.", "published": "2022-11-04T04:07:05Z", "version": 1}, {"aid": "2211.02272", "authors": ["Ali Borji"], "title": "Logits are predictive of network type", "url": "http://arxiv.org/pdf/2211.02272v1", "summary": "We show that it is possible to predict which deep network has generated a\ngiven logit vector with accuracy well above chance. We utilize a number of\nnetworks on a dataset, initialized with random weights or pretrained weights,\nas well as fine-tuned networks. A classifier is then trained on the logit\nvectors of the trained set of this dataset to map the logit vector to the\nnetwork index that has generated it. The classifier is then evaluated on the\ntest set of the dataset. Results are better with randomly initialized networks,\nbut also generalize to pretrained networks as well as fine-tuned ones.\nClassification accuracy is higher using unnormalized logits than normalized\nones. We find that there is little transfer when applying a classifier to the\nsame networks but with different sets of weights. In addition to help better\nunderstand deep networks and the way they encode uncertainty, we anticipate our\nfinding to be useful in some applications (e.g. tailoring an adversarial attack\nfor a certain type of network). Code is available at\nhttps://github.com/aliborji/logits.", "published": "2022-11-04T05:53:27Z", "version": 1}, {"aid": "2211.02386", "authors": ["Xinxin Wang", "Guanzhong Wang", "Qingqing Dang", "Yi Liu", "Xiaoguang Hu", "Dianhai Yu"], "title": "PP-YOLOE-R: An Efficient Anchor-Free Rotated Object Detector", "url": "http://arxiv.org/pdf/2211.02386v1", "summary": "Arbitrary-oriented object detection is a fundamental task in visual scenes\ninvolving aerial images and scene text. In this report, we present PP-YOLOE-R,\nan efficient anchor-free rotated object detector based on PP-YOLOE. We\nintroduce a bag of useful tricks in PP-YOLOE-R to improve detection precision\nwith marginal extra parameters and computational cost. As a result,\nPP-YOLOE-R-l and PP-YOLOE-R-x achieve 78.14 and 78.28 mAP respectively on DOTA\n1.0 dataset with single-scale training and testing, which outperform almost all\nother rotated object detectors. With multi-scale training and testing,\nPP-YOLOE-R-l and PP-YOLOE-R-x further improve the detection precision to 80.02\nand 80.73 mAP. In this case, PP-YOLOE-R-x surpasses all anchor-free methods and\ndemonstrates competitive performance to state-of-the-art anchor-based two-stage\nmodels. Further, PP-YOLOE-R is deployment friendly and PP-YOLOE-R-s/m/l/x can\nreach 69.8/55.1/48.3/37.1 FPS respectively on RTX 2080 Ti with TensorRT and\nFP16-precision. Source code and pre-trained models are available at\nhttps://github.com/PaddlePaddle/PaddleDetection, which is powered by\nhttps://github.com/PaddlePaddle/Paddle.", "published": "2022-11-04T11:38:30Z", "version": 1}, {"aid": "2211.02578", "authors": ["Luis Oala", "Marco Aversa", "Gabriel Nobis", "Kurt Willis", "Yoan Neuenschwander", "Mich\u00e8le Buck", "Christian Matek", "Jerome Extermann", "Enrico Pomarico", "Wojciech Samek", "Roderick Murray-Smith", "Christoph Clausen", "Bruno Sanguinetti"], "title": "Data Models for Dataset Drift Controls in Machine Learning With Optical Images", "url": "http://arxiv.org/pdf/2211.02578v3", "summary": "Camera images are ubiquitous in machine learning research. They also play a\ncentral role in the delivery of important services spanning medicine and\nenvironmental surveying. However, the application of machine learning models in\nthese domains has been limited because of robustness concerns. A primary\nfailure mode are performance drops due to differences between the training and\ndeployment data. While there are methods to prospectively validate the\nrobustness of machine learning models to such dataset drifts, existing\napproaches do not account for explicit models of the primary object of\ninterest: the data. This limits our ability to study and understand the\nrelationship between data generation and downstream machine learning model\nperformance in a physically accurate manner. In this study, we demonstrate how\nto overcome this limitation by pairing traditional machine learning with\nphysical optics to obtain explicit and differentiable data models. We\ndemonstrate how such data models can be constructed for image data and used to\ncontrol downstream machine learning model performance related to dataset drift.\nThe findings are distilled into three applications. First, drift synthesis\nenables the controlled generation of physically faithful drift test cases to\npower model selection and targeted generalization. Second, the gradient\nconnection between machine learning task model and data model allows advanced,\nprecise tolerancing of task model sensitivity to changes in the data\ngeneration. These drift forensics can be used to precisely specify the\nacceptable data environments in which a task model may be run. Third, drift\noptimization opens up the possibility to create drifts that can help the task\nmodel learn better faster, effectively optimizing the data generating process\nitself. A guide to access the open code and datasets is available at\nhttps://github.com/aiaudit-org/raw2logit.", "published": "2022-11-04T16:50:10Z", "version": 3}, {"aid": "2211.02633", "authors": ["Gyuhak Kim", "Changnan Xiao", "Tatsuya Konishi", "Zixuan Ke", "Bing Liu"], "title": "A Theoretical Study on Solving Continual Learning", "url": "http://arxiv.org/pdf/2211.02633v1", "summary": "Continual learning (CL) learns a sequence of tasks incrementally. There are\ntwo popular CL settings, class incremental learning (CIL) and task incremental\nlearning (TIL). A major challenge of CL is catastrophic forgetting (CF). While\na number of techniques are already available to effectively overcome CF for\nTIL, CIL remains to be highly challenging. So far, little theoretical study has\nbeen done to provide a principled guidance on how to solve the CIL problem.\nThis paper performs such a study. It first shows that probabilistically, the\nCIL problem can be decomposed into two sub-problems: Within-task Prediction\n(WP) and Task-id Prediction (TP). It further proves that TP is correlated with\nout-of-distribution (OOD) detection, which connects CIL and OOD detection. The\nkey conclusion of this study is that regardless of whether WP and TP or OOD\ndetection are defined explicitly or implicitly by a CIL algorithm, good WP and\ngood TP or OOD detection are necessary and sufficient for good CIL\nperformances. Additionally, TIL is simply WP. Based on the theoretical result,\nnew CIL methods are also designed, which outperform strong baselines in both\nCIL and TIL settings by a large margin.", "published": "2022-11-04T17:45:55Z", "version": 1}, {"aid": "2211.02695", "authors": ["Hadi Salman", "Caleb Parks", "Shi Yin Hong", "Justin Zhan"], "title": "WaveNets: Wavelet Channel Attention Networks", "url": "http://arxiv.org/pdf/2211.02695v2", "summary": "Channel Attention reigns supreme as an effective technique in the field of\ncomputer vision. However, the proposed channel attention by SENet suffers from\ninformation loss in feature learning caused by the use of Global Average\nPooling (GAP) to represent channels as scalars. Thus, designing effective\nchannel attention mechanisms requires finding a solution to enhance features\npreservation in modeling channel inter-dependencies. In this work, we utilize\nWavelet transform compression as a solution to the channel representation\nproblem. We first test wavelet transform as an Auto-Encoder model equipped with\nconventional channel attention module. Next, we test wavelet transform as a\nstandalone channel compression method. We prove that global average pooling is\nequivalent to the recursive approximate Haar wavelet transform. With this\nproof, we generalize channel attention using Wavelet compression and name it\nWaveNet. Implementation of our method can be embedded within existing channel\nattention methods with a couple of lines of code. We test our proposed method\nusing ImageNet dataset for image classification task. Our method outperforms\nthe baseline SENet, and achieves the state-of-the-art results. Our code\nimplementation is publicly available at https://github.com/hady1011/WaveNet-C.", "published": "2022-11-04T18:26:47Z", "version": 2}, {"aid": "2211.02831", "authors": ["Tao Wang", "Kaihao Zhang", "Xuanxi Chen", "Wenhan Luo", "Jiankang Deng", "Tong Lu", "Xiaochun Cao", "Wei Liu", "Hongdong Li", "Stefanos Zafeiriou"], "title": "A Survey of Deep Face Restoration: Denoise, Super-Resolution, Deblur, Artifact Removal", "url": "http://arxiv.org/pdf/2211.02831v1", "summary": "Face Restoration (FR) aims to restore High-Quality (HQ) faces from\nLow-Quality (LQ) input images, which is a domain-specific image restoration\nproblem in the low-level computer vision area. The early face restoration\nmethods mainly use statistic priors and degradation models, which are difficult\nto meet the requirements of real-world applications in practice. In recent\nyears, face restoration has witnessed great progress after stepping into the\ndeep learning era. However, there are few works to study deep learning-based\nface restoration methods systematically. Thus, this paper comprehensively\nsurveys recent advances in deep learning techniques for face restoration.\nSpecifically, we first summarize different problem formulations and analyze the\ncharacteristic of the face image. Second, we discuss the challenges of face\nrestoration. Concerning these challenges, we present a comprehensive review of\nexisting FR methods, including prior based methods and deep learning-based\nmethods. Then, we explore developed techniques in the task of FR covering\nnetwork architectures, loss functions, and benchmark datasets. We also conduct\na systematic benchmark evaluation on representative methods. Finally, we\ndiscuss future directions, including network designs, metrics, benchmark\ndatasets, applications,etc. We also provide an open-source repository for all\nthe discussed methods, which is available at\nhttps://github.com/TaoWangzj/Awesome-Face-Restoration.", "published": "2022-11-05T07:08:15Z", "version": 1}, {"aid": "2211.02947", "authors": ["Sanchar Palit", "Biplab Banerjee", "Subhasis Chaudhuri"], "title": "Prototypical quadruplet for few-shot class incremental learning", "url": "http://arxiv.org/pdf/2211.02947v3", "summary": "Scarcity of data and incremental learning of new tasks pose two major\nbottlenecks for many modern computer vision algorithms. The phenomenon of\ncatastrophic forgetting, i.e., the model's inability to classify previously\nlearned data after training with new batches of data, is a major challenge.\nConventional methods address catastrophic forgetting while compromising the\ncurrent session's training. Generative replay-based approaches, such as\ngenerative adversarial networks (GANs), have been proposed to mitigate\ncatastrophic forgetting, but training GANs with few samples may lead to\ninstability. To address these challenges, we propose a novel method that\nimproves classification robustness by identifying a better embedding space\nusing an improved contrasting loss. Our approach retains previously acquired\nknowledge in the embedding space, even when trained with new classes, by\nupdating previous session class prototypes to represent the true class mean,\nwhich is crucial for our nearest class mean classification strategy. We\ndemonstrate the effectiveness of our method by showing that the embedding space\nremains intact after training the model with new classes and outperforms\nexisting state-of-the-art algorithms in terms of accuracy across different\nsessions.", "published": "2022-11-05T17:19:14Z", "version": 3}, {"aid": "2211.03019", "authors": ["Dennis Fedorishin", "Deen Dayal Mohan", "Bhavin Jawade", "Srirangaraj Setlur", "Venu Govindaraju"], "title": "Hear The Flow: Optical Flow-Based Self-Supervised Visual Sound Source Localization", "url": "http://arxiv.org/pdf/2211.03019v1", "summary": "Learning to localize the sound source in videos without explicit annotations\nis a novel area of audio-visual research. Existing work in this area focuses on\ncreating attention maps to capture the correlation between the two modalities\nto localize the source of the sound. In a video, oftentimes, the objects\nexhibiting movement are the ones generating the sound. In this work, we capture\nthis characteristic by modeling the optical flow in a video as a prior to\nbetter aid in localizing the sound source. We further demonstrate that the\naddition of flow-based attention substantially improves visual sound source\nlocalization. Finally, we benchmark our method on standard sound source\nlocalization datasets and achieve state-of-the-art performance on the Soundnet\nFlickr and VGG Sound Source datasets. Code:\nhttps://github.com/denfed/heartheflow.", "published": "2022-11-06T03:48:45Z", "version": 1}, {"aid": "2211.03989", "authors": ["Yifei Zhou", "Zilu Li", "Abhinav Shrivastava", "Hengshuang Zhao", "Antonio Torralba", "Taipeng Tian", "Ser-Nam Lim"], "title": "$BT^2$: Backward-compatible Training with Basis Transformation", "url": "http://arxiv.org/pdf/2211.03989v3", "summary": "Modern retrieval system often requires recomputing the representation of\nevery piece of data in the gallery when updating to a better representation\nmodel. This process is known as backfilling and can be especially costly in the\nreal world where the gallery often contains billions of samples. Recently,\nresearchers have proposed the idea of Backward Compatible Training (BCT) where\nthe new representation model can be trained with an auxiliary loss to make it\nbackward compatible with the old representation. In this way, the new\nrepresentation can be directly compared with the old representation, in\nprinciple avoiding the need for any backfilling. However, followup work shows\nthat there is an inherent tradeoff where a backward compatible representation\nmodel cannot simultaneously maintain the performance of the new model itself.\nThis paper reports our ``not-so-surprising'' finding that adding extra\ndimensions to the representation can help here. However, we also found that\nnaively increasing the dimension of the representation did not work. To deal\nwith this, we propose Backward-compatible Training with a novel Basis\nTransformation ($BT^2$). A basis transformation (BT) is basically a learnable\nset of parameters that applies an orthonormal transformation. Such a\ntransformation possesses an important property whereby the original information\ncontained in its input is retained in its output. We show in this paper how a\nBT can be utilized to add only the necessary amount of additional dimensions.\nWe empirically verify the advantage of $BT^2$ over other state-of-the-art\nmethods in a wide range of settings. We then further extend $BT^2$ to other\nchallenging yet more practical settings, including significant change in model\narchitecture (CNN to Transformers), modality change, and even a series of\nupdates in the model architecture mimicking the evolution of deep learning\nmodels.", "published": "2022-11-08T04:00:23Z", "version": 3}, {"aid": "2211.04049", "authors": ["Moritz Schubotz", "Ankit Satpute", "Andre Greiner-Petter", "Akiko Aizawa", "Bela Gipp"], "title": "Caching and Reproducibility: Making Data Science experiments faster and FAIRer", "url": "http://arxiv.org/pdf/2211.04049v2", "summary": "Small to medium-scale data science experiments often rely on research\nsoftware developed ad-hoc by individual scientists or small teams. Often there\nis no time to make the research software fast, reusable, and open access. The\nconsequence is twofold. First, subsequent researchers must spend significant\nwork hours building upon the proposed hypotheses or experimental framework. In\nthe worst case, others cannot reproduce the experiment and reuse the findings\nfor subsequent research. Second, suppose the ad-hoc research software fails\nduring often long-running computationally expensive experiments. In that case,\nthe overall effort to iteratively improve the software and rerun the\nexperiments creates significant time pressure on the researchers. We suggest\nmaking caching an integral part of the research software development process,\neven before the first line of code is written. This article outlines caching\nrecommendations for developing research software in data science projects. Our\nrecommendations provide a perspective to circumvent common problems such as\npropriety dependence, speed, etc. At the same time, caching contributes to the\nreproducibility of experiments in the open science workflow. Concerning the\nfour guiding principles, i.e., Findability, Accessibility, Interoperability,\nand Reusability (FAIR), we foresee that including the proposed recommendation\nin a research software development will make the data related to that software\nFAIRer for both machines and humans. We exhibit the usefulness of some of the\nproposed recommendations on our recently completed research software project in\nmathematical information retrieval.", "published": "2022-11-08T07:11:02Z", "version": 2}, {"aid": "2211.04700", "authors": ["Zhao Zhang", "Suiyi Zhao", "Xiaojie Jin", "Mingliang Xu", "Yi Yang", "Shuicheng Yan", "Meng Wang"], "title": "Noise Self-Regression: A New Learning Paradigm to Enhance Low-Light Images Without Task-Related Data", "url": "http://arxiv.org/pdf/2211.04700v3", "summary": "Deep learning-based low-light image enhancement (LLIE) is a task of\nleveraging deep neural networks to enhance the image illumination while keeping\nthe image content unchanged. From the perspective of training data, existing\nmethods complete the LLIE task driven by one of the following three data types:\npaired data, unpaired data and zero-reference data. Each type of these\ndata-driven methods has its own advantages, e.g., zero-reference data-based\nmethods have very low requirements on training data and can meet the human\nneeds in many scenarios. In this paper, we leverage pure Gaussian noise to\ncomplete the LLIE task, which further reduces the requirements for training\ndata in LLIE tasks and can be used as another alternative in practical use.\nSpecifically, we propose Noise SElf-Regression (NoiSER) without access to any\ntask-related data, simply learns a convolutional neural network equipped with\nan instance-normalization layer by taking a random noise image,\n$\\mathcal{N}(0,\\sigma^2)$ for each pixel, as both input and output for each\ntraining pair, and then the low-light image is fed to the trained network for\npredicting the normal-light image. Technically, an intuitive explanation for\nits effectiveness is as follows: 1) the self-regression reconstructs the\ncontrast between adjacent pixels of the input image, 2) the\ninstance-normalization layer may naturally remediate the overall\nmagnitude/lighting of the input image, and 3) the $\\mathcal{N}(0,\\sigma^2)$\nassumption for each pixel enforces the output image to follow the well-known\ngray-world hypothesis when the image size is big enough. Compared to current\nstate-of-the-art LLIE methods with access to different task-related data,\nNoiSER is highly competitive in enhancement quality, yet with a much smaller\nmodel size, and much lower training and inference cost. Besides, NoiSER also\nexcels in mitigating overexposure and handling joint tasks.", "published": "2022-11-09T06:18:18Z", "version": 3}, {"aid": "2211.05018", "authors": ["Matthew Aquilina", "Keith George Ciantar", "Christian Galea", "Kenneth P. Camilleri", "Reuben A. Farrugia", "John Abela"], "title": "The Best of Both Worlds: a Framework for Combining Degradation Prediction with High Performance Super-Resolution Networks", "url": "http://arxiv.org/pdf/2211.05018v1", "summary": "To date, the best-performing blind super-resolution (SR) techniques follow\none of two paradigms: A) generate and train a standard SR network on synthetic\nlow-resolution - high-resolution (LR - HR) pairs or B) attempt to predict the\ndegradations an LR image has suffered and use these to inform a customised SR\nnetwork. Despite significant progress, subscribers to the former miss out on\nuseful degradation information that could be used to improve the SR process. On\nthe other hand, followers of the latter rely on weaker SR networks, which are\nsignificantly outperformed by the latest architectural advancements. In this\nwork, we present a framework for combining any blind SR prediction mechanism\nwith any deep SR network, using a metadata insertion block to insert prediction\nvectors into SR network feature maps. Through comprehensive testing, we prove\nthat state-of-the-art contrastive and iterative prediction schemes can be\nsuccessfully combined with high-performance SR networks such as RCAN and HAN\nwithin our framework. We show that our hybrid models consistently achieve\nstronger SR performance than both their non-blind and blind counterparts.\nFurthermore, we demonstrate our framework's robustness by predicting\ndegradations and super-resolving images from a complex pipeline of blurring,\nnoise and compression.", "published": "2022-11-09T16:49:35Z", "version": 1}, {"aid": "2211.12421", "authors": ["Jiaxing Xu", "Yunhan Yang", "David Tse Jung Huang", "Sophi Shilpa Gururajapathy", "Yiping Ke", "Miao Qiao", "Alan Wang", "Haribalan Kumar", "Josh McGeown", "Eryn Kwon"], "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark", "url": "http://arxiv.org/pdf/2211.12421v6", "summary": "This paper presents a comprehensive and quality collection of functional\nhuman brain network data for potential research in the intersection of\nneuroscience, machine learning, and graph analytics. Anatomical and functional\nMRI images have been used to understand the functional connectivity of the\nhuman brain and are particularly important in identifying underlying\nneurodegenerative conditions such as Alzheimer's, Parkinson's, and Autism.\nRecently, the study of the brain in the form of brain networks using machine\nlearning and graph analytics has become increasingly popular, especially to\npredict the early onset of these conditions. A brain network, represented as a\ngraph, retains rich structural and positional information that traditional\nexamination methods are unable to capture. However, the lack of publicly\naccessible brain network data prevents researchers from data-driven\nexplorations. One of the main difficulties lies in the complicated\ndomain-specific preprocessing steps and the exhaustive computation required to\nconvert the data from MRI images into brain networks. We bridge this gap by\ncollecting a large amount of MRI images from public databases and a private\nsource, working with domain experts to make sensible design choices, and\npreprocessing the MRI images to produce a collection of brain network datasets.\nThe datasets originate from 6 different sources, cover 4 brain conditions, and\nconsist of a total of 2,702 subjects. We test our graph datasets on 12 machine\nlearning models to provide baselines and validate the data quality on a recent\ngraph analysis model. To lower the barrier to entry and promote the research in\nthis interdisciplinary field, we release our brain network data and complete\npreprocessing details including codes at\nhttps://doi.org/10.17608/k6.auckland.21397377 and\nhttps://github.com/brainnetuoa/data_driven_network_neuroscience.", "published": "2022-11-11T02:14:28Z", "version": 6}, {"aid": "2211.06009", "authors": ["Na Lei", "Zezeng Li", "Zebin Xu", "Ying Li", "Xianfeng Gu"], "title": "What's the Situation with Intelligent Mesh Generation: A Survey and Perspectives", "url": "http://arxiv.org/pdf/2211.06009v3", "summary": "Intelligent Mesh Generation (IMG) represents a novel and promising field of\nresearch, utilizing machine learning techniques to generate meshes. Despite its\nrelative infancy, IMG has significantly broadened the adaptability and\npracticality of mesh generation techniques, delivering numerous breakthroughs\nand unveiling potential future pathways. However, a noticeable void exists in\nthe contemporary literature concerning comprehensive surveys of IMG methods.\nThis paper endeavors to fill this gap by providing a systematic and thorough\nsurvey of the current IMG landscape. With a focus on 113 preliminary IMG\nmethods, we undertake a meticulous analysis from various angles, encompassing\ncore algorithm techniques and their application scope, agent learning\nobjectives, data types, targeted challenges, as well as advantages and\nlimitations. We have curated and categorized the literature, proposing three\nunique taxonomies based on key techniques, output mesh unit elements, and\nrelevant input data types. This paper also underscores several promising future\nresearch directions and challenges in IMG. To augment reader accessibility, a\ndedicated IMG project page is available at\n\\url{https://github.com/xzb030/IMG_Survey}.", "published": "2022-11-11T05:24:16Z", "version": 3}, {"aid": "2211.06163", "authors": ["Longbin Yan", "Yunxiao Qin", "Shumin Liu", "Jie Chen"], "title": "Dual Complementary Dynamic Convolution for Image Recognition", "url": "http://arxiv.org/pdf/2211.06163v1", "summary": "As a powerful engine, vanilla convolution has promoted huge breakthroughs in\nvarious computer tasks. However, it often suffers from sample and content\nagnostic problems, which limits the representation capacities of the\nconvolutional neural networks (CNNs). In this paper, we for the first time\nmodel the scene features as a combination of the local spatial-adaptive parts\nowned by the individual and the global shift-invariant parts shared to all\nindividuals, and then propose a novel two-branch dual complementary dynamic\nconvolution (DCDC) operator to flexibly deal with these two types of features.\nThe DCDC operator overcomes the limitations of vanilla convolution and most\nexisting dynamic convolutions who capture only spatial-adaptive features, and\nthus markedly boosts the representation capacities of CNNs. Experiments show\nthat the DCDC operator based ResNets (DCDC-ResNets) significantly outperform\nvanilla ResNets and most state-of-the-art dynamic convolutional networks on\nimage classification, as well as downstream tasks including object detection,\ninstance and panoptic segmentation tasks, while with lower FLOPs and\nparameters.", "published": "2022-11-11T12:32:12Z", "version": 1}, {"aid": "2211.06262", "authors": ["Yi Ren", "Yanyang Xiao", "Guo-Qiang Bi", "Pek-Ming Lau"], "title": "Principles for generation of reverberation", "url": "http://arxiv.org/pdf/2211.06262v2", "summary": "In modern neuroscience, memory has been postulated to stored in neural\ncircuits as sequential spike train and Reverberation is one of the specific\nexample.Former research has made much progress on phenomenon description.\nHowever, the mechanism of reverberation has been unclear yet.\n  In this study, combining electrophysiological record and numerical\nsimulation, we confirmed a formerly unrealized neuron property that is\nnecessary for the burst generation in reverberation.\n  Secondly, we find out the mechanism of sequential pattern generation which\nclearly explained by network topology and asynchronous neurotransmitter\nrelease. In addition, we also developed a pipeline that could design the\nnetwork fire in manually set order.\n  Thirdly, we explored the dynamics of STDP learning and chased down the\neffects of STDP Rule in reverberation. With these understandings, we developed\na STDP based learning rule which could drive the network to remember any\npresupposed sequence.\n  These results indicated that neuron circuit can remember malformation through\nSTDP rule. Those information are stored in synapse connections. By this way,\nanimals remember information as spike sequence pattern.", "published": "2022-11-11T15:10:53Z", "version": 2}, {"aid": "2211.07036", "authors": ["Ted Moskovitz", "Kevin Miller", "Maneesh Sahani", "Matthew M. Botvinick"], "title": "A Unified Theory of Dual-Process Control", "url": "http://arxiv.org/pdf/2211.07036v3", "summary": "Dual-process theories play a central role in both psychology and\nneuroscience, figuring prominently in fields ranging from executive control to\nreward-based learning to judgment and decision making. In each of these\ndomains, two mechanisms appear to operate concurrently, one relatively high in\ncomputational complexity, the other relatively simple. Why is neural\ninformation processing organized in this way? We propose an answer to this\nquestion based on the notion of compression. The key insight is that\ndual-process structure can enhance adaptive behavior by allowing an agent to\nminimize the description length of its own behavior. We apply a single model\nbased on this observation to findings from research on executive control,\nreward-based learning, and judgment and decision making, showing that seemingly\ndiverse dual-process phenomena can be understood as domain-specific\nconsequences of a single underlying set of computational principles.", "published": "2022-11-13T22:43:58Z", "version": 3}, {"aid": "2211.07077", "authors": ["Byungho Jo", "Donghyeon Cho", "In Kyu Park", "Sungeun Hong"], "title": "IFQA: Interpretable Face Quality Assessment", "url": "http://arxiv.org/pdf/2211.07077v2", "summary": "Existing face restoration models have relied on general assessment metrics\nthat do not consider the characteristics of facial regions. Recent works have\ntherefore assessed their methods using human studies, which is not scalable and\ninvolves significant effort. This paper proposes a novel face-centric metric\nbased on an adversarial framework where a generator simulates face restoration\nand a discriminator assesses image quality. Specifically, our per-pixel\ndiscriminator enables interpretable evaluation that cannot be provided by\ntraditional metrics. Moreover, our metric emphasizes facial primary regions\nconsidering that even minor changes to the eyes, nose, and mouth significantly\naffect human cognition. Our face-oriented metric consistently surpasses\nexisting general or facial image quality assessment metrics by impressive\nmargins. We demonstrate the generalizability of the proposed strategy in\nvarious architectural designs and challenging scenarios. Interestingly, we find\nthat our IFQA can lead to performance improvement as an objective function.", "published": "2022-11-14T03:04:38Z", "version": 2}, {"aid": "2211.08030", "authors": ["Johannes Merkle", "Christian Rathgeb", "Benjamin Tams", "Dhay-Parn Lou", "Andr\u00e9 D\u00f6rsch", "Pawel Drozdowski"], "title": "State of the Art of Quality Assessment of Facial Images", "url": "http://arxiv.org/pdf/2211.08030v1", "summary": "The goal of the project \"Facial Metrics for EES\" is to develop, implement and\npublish an open source algorithm for the quality assessment of facial images\n(OFIQ) for face recognition, in particular for border control scenarios.1 In\norder to stimulate the harmonization of the requirements and practices applied\nfor QA for facial images, the insights gained and algorithms developed in the\nproject will be contributed to the current (2022) revision of the ISO/IEC\n29794-5 standard. Furthermore, the implemented quality metrics and algorithms\nwill consider the recommendations and requirements from other relevant\nstandards, in particular ISO/IEC 19794-5:2011, ISO/IEC 29794-5:2010, ISO/IEC\n39794-5:2019 and Version 5.2 of the BSI Technical Guideline TR-03121 Part 3\nVolume 1. In order to establish an informed basis for the selection of quality\nmetrics and the development of corresponding quality assessment algorithms, the\nstate of the art of methods and algorithms (defining a metric), implementations\nand datasets for quality assessment for facial images is surveyed. For all\nrelevant quality aspects, this document summarizes the requirements of the\naforementioned standards, known results on their impact on face recognition\nperformance, publicly available datasets, proposed methods and algorithms and\nopen source software implementations.", "published": "2022-11-15T10:30:58Z", "version": 1}, {"aid": "2211.08332", "authors": ["Xingqian Xu", "Zhangyang Wang", "Eric Zhang", "Kai Wang", "Humphrey Shi"], "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion Model", "url": "http://arxiv.org/pdf/2211.08332v4", "summary": "Recent advances in diffusion models have set an impressive milestone in many\ngeneration tasks, and trending works such as DALL-E2, Imagen, and Stable\nDiffusion have attracted great interest. Despite the rapid landscape changes,\nrecent new approaches focus on extensions and performance rather than capacity,\nthus requiring separate models for separate tasks. In this work, we expand the\nexisting single-flow diffusion pipeline into a multi-task multimodal network,\ndubbed Versatile Diffusion (VD), that handles multiple flows of text-to-image,\nimage-to-text, and variations in one unified model. The pipeline design of VD\ninstantiates a unified multi-flow diffusion framework, consisting of sharable\nand swappable layer modules that enable the crossmodal generality beyond images\nand text. Through extensive experiments, we demonstrate that VD successfully\nachieves the following: a) VD outperforms the baseline approaches and handles\nall its base tasks with competitive quality; b) VD enables novel extensions\nsuch as disentanglement of style and semantics, dual- and multi-context\nblending, etc.; c) The success of our multi-flow multimodal framework over\nimages and text may inspire further diffusion-based universal AI research. Our\ncode and models are open-sourced at\nhttps://github.com/SHI-Labs/Versatile-Diffusion.", "published": "2022-11-15T17:44:05Z", "version": 4}, {"aid": "2211.08403", "authors": ["Keller Jordan", "Hanie Sedghi", "Olga Saukh", "Rahim Entezari", "Behnam Neyshabur"], "title": "REPAIR: REnormalizing Permuted Activations for Interpolation Repair", "url": "http://arxiv.org/pdf/2211.08403v3", "summary": "In this paper we look into the conjecture of Entezari et al. (2021) which\nstates that if the permutation invariance of neural networks is taken into\naccount, then there is likely no loss barrier to the linear interpolation\nbetween SGD solutions. First, we observe that neuron alignment methods alone\nare insufficient to establish low-barrier linear connectivity between SGD\nsolutions due to a phenomenon we call variance collapse: interpolated deep\nnetworks suffer a collapse in the variance of their activations, causing poor\nperformance. Next, we propose REPAIR (REnormalizing Permuted Activations for\nInterpolation Repair) which mitigates variance collapse by rescaling the\npreactivations of such interpolated networks. We explore the interaction\nbetween our method and the choice of normalization layer, network width, and\ndepth, and demonstrate that using REPAIR on top of neuron alignment methods\nleads to 60%-100% relative barrier reduction across a wide variety of\narchitecture families and tasks. In particular, we report a 74% barrier\nreduction for ResNet50 on ImageNet and 90% barrier reduction for ResNet18 on\nCIFAR10.", "published": "2022-11-15T18:45:26Z", "version": 3}, {"aid": "2211.11747", "authors": ["Jorg Bornschein", "Alexandre Galashov", "Ross Hemsley", "Amal Rannen-Triki", "Yutian Chen", "Arslan Chaudhry", "Xu Owen He", "Arthur Douillard", "Massimo Caccia", "Qixuang Feng", "Jiajun Shen", "Sylvestre-Alvise Rebuffi", "Kitty Stacpoole", "Diego de las Casas", "Will Hawkins", "Angeliki Lazaridou", "Yee Whye Teh", "Andrei A. Rusu", "Razvan Pascanu", "Marc'Aurelio Ranzato"], "title": "NEVIS'22: A Stream of 100 Tasks Sampled from 30 Years of Computer Vision Research", "url": "http://arxiv.org/pdf/2211.11747v2", "summary": "A shared goal of several machine learning communities like continual\nlearning, meta-learning and transfer learning, is to design algorithms and\nmodels that efficiently and robustly adapt to unseen tasks. An even more\nambitious goal is to build models that never stop adapting, and that become\nincreasingly more efficient through time by suitably transferring the accrued\nknowledge. Beyond the study of the actual learning algorithm and model\narchitecture, there are several hurdles towards our quest to build such models,\nsuch as the choice of learning protocol, metric of success and data needed to\nvalidate research hypotheses. In this work, we introduce the Never-Ending\nVIsual-classification Stream (NEVIS'22), a benchmark consisting of a stream of\nover 100 visual classification tasks, sorted chronologically and extracted from\npapers sampled uniformly from computer vision proceedings spanning the last\nthree decades. The resulting stream reflects what the research community\nthought was meaningful at any point in time, and it serves as an ideal test bed\nto assess how well models can adapt to new tasks, and do so better and more\nefficiently as time goes by. Despite being limited to classification, the\nresulting stream has a rich diversity of tasks from OCR, to texture analysis,\nscene recognition, and so forth. The diversity is also reflected in the wide\nrange of dataset sizes, spanning over four orders of magnitude. Overall,\nNEVIS'22 poses an unprecedented challenge for current sequential learning\napproaches due to the scale and diversity of tasks, yet with a low entry\nbarrier as it is limited to a single modality and well understood supervised\nlearning problems. Moreover, we provide a reference implementation including\nstrong baselines and an evaluation protocol to compare methods in terms of\ntheir trade-off between accuracy and compute.", "published": "2022-11-15T18:57:46Z", "version": 2}, {"aid": "2211.08460", "authors": ["Laura Nicol\u00e1s-S\u00e1enz", "Agapito Ledezma", "Javier Pascau", "Arrate Mu\u00f1oz-Barrutia"], "title": "ABANICCO: A New Color Space for Multi-Label Pixel Classification and Color Segmentation", "url": "http://arxiv.org/pdf/2211.08460v1", "summary": "In any computer vision task involving color images, a necessary step is\nclassifying pixels according to color and segmenting the respective areas.\nHowever, the development of methods able to successfully complete this task has\nproven challenging, mainly due to the gap between human color perception,\nlinguistic color terms, and digital representation. In this paper, we propose a\nnovel method combining geometric analysis of color theory, fuzzy color spaces,\nand multi-label systems for the automatic classification of pixels according to\n12 standard color categories (Green, Yellow, Light Orange, Deep Orange, Red,\nPink, Purple, Ultramarine, Blue, Teal, Brown, and Neutral). Moreover, we\npresent a robust, unsupervised, unbiased strategy for color naming based on\nstatistics and color theory. ABANICCO was tested against the state of the art\nin color classification and with the standarized ISCC-NBS color system,\nproviding accurate classification and a standard, easily understandable\nalternative for hue naming recognizable by humans and machines. We expect this\nsolution to become the base to successfully tackle a myriad of problems in all\nfields of computer vision, such as region characterization, histopathology\nanalysis, fire detection, product quality prediction, object description, and\nhyperspectral imaging.", "published": "2022-11-15T19:26:51Z", "version": 1}, {"aid": "2211.08486", "authors": ["Chuqin Geng", "Xiaojie Xu", "Haolin Ye", "Xujie Si"], "title": "Scalar Invariant Networks with Zero Bias", "url": "http://arxiv.org/pdf/2211.08486v4", "summary": "Just like weights, bias terms are the learnable parameters of many popular\nmachine learning models, including neural networks. Biases are thought to\nenhance the representational power of neural networks, enabling them to solve a\nvariety of tasks in computer vision. However, we argue that biases can be\ndisregarded for some image-related tasks such as image classification, by\nconsidering the intrinsic distribution of images in the input space and desired\nmodel properties from first principles. Our findings suggest that zero-bias\nneural networks can perform comparably to biased networks for practical image\nclassification tasks. We demonstrate that zero-bias neural networks possess a\nvaluable property called scalar (multiplication) invariance. This means that\nthe prediction of the network remains unchanged when the contrast of the input\nimage is altered. We extend scalar invariance to more general cases, enabling\nformal verification of certain convex regions of the input space. Additionally,\nwe prove that zero-bias neural networks are fair in predicting the zero image.\nUnlike state-of-the-art models that may exhibit bias toward certain labels,\nzero-bias networks have uniform belief in all labels. We believe dropping bias\nterms can be considered as a geometric prior in designing neural network\narchitecture for image classification, which shares the spirit of adapting\nconvolutions as the transnational invariance prior. The robustness and fairness\nadvantages of zero-bias neural networks may also indicate a promising path\ntowards trustworthy and ethical AI.", "published": "2022-11-15T20:26:07Z", "version": 4}, {"aid": "2211.08892", "authors": ["Tianze Luo", "Zhanfeng Mo", "Sinno Jialin Pan"], "title": "Fast Graph Generation via Spectral Diffusion", "url": "http://arxiv.org/pdf/2211.08892v2", "summary": "Generating graph-structured data is a challenging problem, which requires\nlearning the underlying distribution of graphs. Various models such as graph\nVAE, graph GANs, and graph diffusion models have been proposed to generate\nmeaningful and reliable graphs, among which the diffusion models have achieved\nstate-of-the-art performance. In this paper, we argue that running full-rank\ndiffusion SDEs on the whole graph adjacency matrix space hinders diffusion\nmodels from learning graph topology generation, and hence significantly\ndeteriorates the quality of generated graph data. To address this limitation,\nwe propose an efficient yet effective Graph Spectral Diffusion Model (GSDM),\nwhich is driven by low-rank diffusion SDEs on the graph spectrum space. Our\nspectral diffusion model is further proven to enjoy a substantially stronger\ntheoretical guarantee than standard diffusion models. Extensive experiments\nacross various datasets demonstrate that, our proposed GSDM turns out to be the\nSOTA model, by exhibiting both significantly higher generation quality and much\nless computational consumption than the baselines.", "published": "2022-11-16T12:56:32Z", "version": 2}, {"aid": "2211.09788", "authors": ["Shoufa Chen", "Peize Sun", "Yibing Song", "Ping Luo"], "title": "DiffusionDet: Diffusion Model for Object Detection", "url": "http://arxiv.org/pdf/2211.09788v2", "summary": "We propose DiffusionDet, a new framework that formulates object detection as\na denoising diffusion process from noisy boxes to object boxes. During the\ntraining stage, object boxes diffuse from ground-truth boxes to random\ndistribution, and the model learns to reverse this noising process. In\ninference, the model refines a set of randomly generated boxes to the output\nresults in a progressive way. Our work possesses an appealing property of\nflexibility, which enables the dynamic number of boxes and iterative\nevaluation. The extensive experiments on the standard benchmarks show that\nDiffusionDet achieves favorable performance compared to previous\nwell-established detectors. For example, DiffusionDet achieves 5.3 AP and 4.8\nAP gains when evaluated with more boxes and iteration steps, under a zero-shot\ntransfer setting from COCO to CrowdHuman. Our code is available at\nhttps://github.com/ShoufaChen/DiffusionDet.", "published": "2022-11-17T18:56:19Z", "version": 2}, {"aid": "2211.09869", "authors": ["Titas Anciukevi\u010dius", "Zexiang Xu", "Matthew Fisher", "Paul Henderson", "Hakan Bilen", "Niloy J. Mitra", "Paul Guerrero"], "title": "RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation", "url": "http://arxiv.org/pdf/2211.09869v4", "summary": "Diffusion models currently achieve state-of-the-art performance for both\nconditional and unconditional image generation. However, so far, image\ndiffusion models do not support tasks required for 3D understanding, such as\nview-consistent 3D generation or single-view object reconstruction. In this\npaper, we present RenderDiffusion, the first diffusion model for 3D generation\nand inference, trained using only monocular 2D supervision. Central to our\nmethod is a novel image denoising architecture that generates and renders an\nintermediate three-dimensional representation of a scene in each denoising\nstep. This enforces a strong inductive structure within the diffusion process,\nproviding a 3D consistent representation while only requiring 2D supervision.\nThe resulting 3D representation can be rendered from any view. We evaluate\nRenderDiffusion on FFHQ, AFHQ, ShapeNet and CLEVR datasets, showing competitive\nperformance for generation of 3D scenes and inference of 3D scenes from 2D\nimages. Additionally, our diffusion-based approach allows us to use 2D\ninpainting to edit 3D scenes.", "published": "2022-11-17T20:17:04Z", "version": 4}, {"aid": "2211.09906", "authors": ["Ciaran Murphy-Royal", "ShiNung Ching", "Thomas Papouin"], "title": "Contextual guidance: An integrated theory for astrocytes function in brain circuits and behavior", "url": "http://arxiv.org/pdf/2211.09906v1", "summary": "The participation of astrocytes in brain computation was formally\nhypothesized in 1992, coinciding with the discovery that these glial cells\ndisplay a complex form of Ca2+ excitability. This fostered conceptual advances\ncentered on the notion of reciprocal interactions between neurons and\nastrocytes, which permitted a critical leap forward in uncovering many roles of\nastrocytes in brain circuits, and signaled the rise of a major new force in\nneuroscience: that of glial biology. In the past decade, a multitude of\nunconventional and disparate functions of astrocytes have been documented that\nare not predicted by these canonical models and that are challenging to piece\ntogether into a holistic and parsimonious picture. This highlights a disconnect\nbetween the rapidly evolving field of astrocyte biology and the conceptual\nframeworks guiding it, and emphasizes the need for a careful reconsideration of\nhow we theorize the functional position of astrocytes in brain circuitry. Here,\nwe propose a unifying, highly transferable, data-driven, and\ncomputationally-relevant conceptual framework for astrocyte biology, which we\ncoin contextual guidance. It describes astrocytes as contextual gates that\ndecode multiple environmental factors to shape neural circuitry in an adaptive,\nstate-dependent fashion. This paradigm is organically inclusive of all\nfundamental features of astrocytes, many of which have remained unaccounted for\nin previous theories. We find that this new concept provides an intuitive and\npowerful theoretical space to improve our understanding of brain function and\ncomputational models thereof across scales because it depicts astrocytes as a\nhub for circumstantial inputs into relevant specialized circuits that permits\nadaptive behaviors at the network and organism level.", "published": "2022-11-17T21:38:00Z", "version": 1}, {"aid": "2211.10085", "authors": ["Mingyu Kang", "Duxin Chen", "Ning Meng", "Gang Yan", "Wenwu Yu"], "title": "Identifying Unique Causal Network from Nonstationary Time Series", "url": "http://arxiv.org/pdf/2211.10085v3", "summary": "Identifying causality is a challenging task in many data-intensive scenarios.\nMany algorithms have been proposed for this critical task. However, most of\nthem consider the learning algorithms for directed acyclic graph (DAG) of\nBayesian network (BN). These BN-based models only have limited causal\nexplainability because of the issue of Markov equivalence class. Moreover, they\nare dependent on the assumption of stationarity, whereas many sampling time\nseries from complex system are nonstationary. The nonstationary time series\nbring dataset shift problem, which leads to the unsatisfactory performances of\nthese algorithms. To fill these gaps, a novel causation model named Unique\nCausal Network (UCN) is proposed in this paper. Different from the previous\nBN-based models, UCN considers the influence of time delay, and proves the\nuniqueness of obtained network structure, which addresses the issue of Markov\nequivalence class. Furthermore, based on the decomposability property of UCN, a\nhigher-order causal entropy (HCE) algorithm is designed to identify the\nstructure of UCN in a distributed way. HCE algorithm measures the strength of\ncausality by using nearest-neighbors entropy estimator, which works well on\nnonstationary time series. Finally, lots of experiments validate that HCE\nalgorithm achieves state-of-the-art accuracy when time series are\nnonstationary, compared to the other baseline algorithms.", "published": "2022-11-18T08:28:54Z", "version": 3}, {"aid": "2211.10564", "authors": ["Mahmoud Salem", "Mohamed Osama Ahmed", "Frederick Tung", "Gabriel Oliveira"], "title": "Gumbel-Softmax Selective Networks", "url": "http://arxiv.org/pdf/2211.10564v1", "summary": "ML models often operate within the context of a larger system that can adapt\nits response when the ML model is uncertain, such as falling back on safe\ndefaults or a human in the loop. This commonly encountered operational context\ncalls for principled techniques for training ML models with the option to\nabstain from predicting when uncertain. Selective neural networks are trained\nwith an integrated option to abstain, allowing them to learn to recognize and\noptimize for the subset of the data distribution for which confident\npredictions can be made. However, optimizing selective networks is challenging\ndue to the non-differentiability of the binary selection function (the discrete\ndecision of whether to predict or abstain). This paper presents a general\nmethod for training selective networks that leverages the Gumbel-softmax\nreparameterization trick to enable selection within an end-to-end\ndifferentiable training framework. Experiments on public datasets demonstrate\nthe potential of Gumbel-softmax selective networks for selective regression and\nclassification.", "published": "2022-11-19T02:20:14Z", "version": 1}, {"aid": "2211.10655", "authors": ["Hyungjin Chung", "Dohoon Ryu", "Michael T. McCann", "Marc L. Klasky", "Jong Chul Ye"], "title": "Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models", "url": "http://arxiv.org/pdf/2211.10655v1", "summary": "Diffusion models have emerged as the new state-of-the-art generative model\nwith high quality samples, with intriguing properties such as mode coverage and\nhigh flexibility. They have also been shown to be effective inverse problem\nsolvers, acting as the prior of the distribution, while the information of the\nforward model can be granted at the sampling stage. Nonetheless, as the\ngenerative process remains in the same high dimensional (i.e. identical to data\ndimension) space, the models have not been extended to 3D inverse problems due\nto the extremely high memory and computational cost. In this paper, we combine\nthe ideas from the conventional model-based iterative reconstruction with the\nmodern diffusion models, which leads to a highly effective method for solving\n3D medical image reconstruction tasks such as sparse-view tomography, limited\nangle tomography, compressed sensing MRI from pre-trained 2D diffusion models.\nIn essence, we propose to augment the 2D diffusion prior with a model-based\nprior in the remaining direction at test time, such that one can achieve\ncoherent reconstructions across all dimensions. Our method can be run in a\nsingle commodity GPU, and establishes the new state-of-the-art, showing that\nthe proposed method can perform reconstructions of high fidelity and accuracy\neven in the most extreme cases (e.g. 2-view 3D tomography). We further reveal\nthat the generalization capacity of the proposed method is surprisingly high,\nand can be used to reconstruct volumes that are entirely different from the\ntraining dataset.", "published": "2022-11-19T10:32:21Z", "version": 1}, {"aid": "2211.11751", "authors": ["Chenkang Zhang", "Lei Luo", "Bin Gu"], "title": "Denoising Multi-Similarity Formulation: A Self-paced Curriculum-Driven Approach for Robust Metric Learning", "url": "http://arxiv.org/pdf/2211.11751v2", "summary": "Deep Metric Learning (DML) is a group of techniques that aim to measure the\nsimilarity between objects through the neural network. Although the number of\nDML methods has rapidly increased in recent years, most previous studies cannot\neffectively handle noisy data, which commonly exists in practical applications\nand often leads to serious performance deterioration. To overcome this\nlimitation, in this paper, we build a connection between noisy samples and hard\nsamples in the framework of self-paced learning, and propose a\n\\underline{B}alanced \\underline{S}elf-\\underline{P}aced \\underline{M}etric\n\\underline{L}earning (BSPML) algorithm with a denoising multi-similarity\nformulation, where noisy samples are treated as extremely hard samples and\nadaptively excluded from the model training by sample weighting. Especially,\ndue to the pairwise relationship and a new balance regularization term, the\nsub-problem \\emph{w.r.t.} sample weights is a nonconvex quadratic function. To\nefficiently solve this nonconvex quadratic problem, we propose a doubly\nstochastic projection coordinate gradient algorithm. Importantly, we\ntheoretically prove the convergence not only for the doubly stochastic\nprojection coordinate gradient algorithm, but also for our BSPML algorithm.\nExperimental results on several standard data sets demonstrate that our BSPML\nalgorithm has better generalization ability and robustness than the\nstate-of-the-art robust DML approaches.", "published": "2022-11-19T15:28:19Z", "version": 2}, {"aid": "2211.10851", "authors": ["Thomas J. Ringstrom"], "title": "Reward is not Necessary: How to Create a Modular & Compositional Self-Preserving Agent for Life-Long Learning", "url": "http://arxiv.org/pdf/2211.10851v4", "summary": "Reinforcement Learning views the maximization of rewards and avoidance of\npunishments as central to explaining goal-directed behavior. However, over a\nlife, organisms will need to learn about many different aspects of the world's\nstructure: the states of the world and state-vector transition dynamics. The\nnumber of combinations of states grows exponentially as an agent incorporates\nnew knowledge, and there is no obvious weighted combination of pre-existing\nrewards or costs defined for a given combination of states, as such a weighting\nwould need to encode information about good and bad combinations prior to an\nagent's experience in the world. Therefore, we must develop more naturalistic\naccounts of behavior and motivation in large state-spaces. We show that it is\npossible to use only the intrinsic motivation metric of empowerment, which\nmeasures the agent's capacity to realize many possible futures under a\ntransition operator. We propose to scale empowerment to hierarchical\nstate-spaces by using Operator Bellman Equations. These equations produce\nstate-time feasibility functions, which are compositional hierarchical\nstate-time transition operators that map an initial state and time when an\nagent begins a policy to the final states and times of completing a goal.\nBecause these functions are hierarchical operators we can define hierarchical\nempowerment measures on them. An agent can then optimize plans to distant\nstates and times to maximize its hierarchical empowerment-gain, allowing it to\ndiscover goals that bring about a more favorable coupling of its internal\nstructure (physiological states) to its external environment (world structure &\nspatial state). Life-long agents could therefore be primarily animated by\nprinciples of compositionality and empowerment, exhibiting self-concern for the\ngrowth & maintenance of their own structural integrity without recourse to\nreward-maximization.", "published": "2022-11-20T02:48:01Z", "version": 4}, {"aid": "2211.11665", "authors": ["Lyndon R. Duong", "Jingyang Zhou", "Josue Nassar", "Jules Berman", "Jeroen Olieslagers", "Alex H. Williams"], "title": "Representational dissimilarity metric spaces for stochastic neural networks", "url": "http://arxiv.org/pdf/2211.11665v2", "summary": "Quantifying similarity between neural representations -- e.g. hidden layer\nactivation vectors -- is a perennial problem in deep learning and neuroscience\nresearch. Existing methods compare deterministic responses (e.g. artificial\nnetworks that lack stochastic layers) or averaged responses (e.g.,\ntrial-averaged firing rates in biological data). However, these measures of\n_deterministic_ representational similarity ignore the scale and geometric\nstructure of noise, both of which play important roles in neural computation.\nTo rectify this, we generalize previously proposed shape metrics (Williams et\nal. 2021) to quantify differences in _stochastic_ representations. These new\ndistances satisfy the triangle inequality, and thus can be used as a rigorous\nbasis for many supervised and unsupervised analyses. Leveraging this novel\nframework, we find that the stochastic geometries of neurobiological\nrepresentations of oriented visual gratings and naturalistic scenes\nrespectively resemble untrained and trained deep network representations.\nFurther, we are able to more accurately predict certain network attributes\n(e.g. training hyperparameters) from its position in stochastic (versus\ndeterministic) shape space.", "published": "2022-11-21T17:32:40Z", "version": 2}, {"aid": "2211.12082", "authors": ["Ramy Hussein", "David Shin", "Moss Zhao", "Jia Guo", "Guido Davidzon", "Michael Moseley", "Greg Zaharchuk"], "title": "Brain MRI-to-PET Synthesis using 3D Convolutional Attention Networks", "url": "http://arxiv.org/pdf/2211.12082v1", "summary": "Accurate quantification of cerebral blood flow (CBF) is essential for the\ndiagnosis and assessment of a wide range of neurological diseases. Positron\nemission tomography (PET) with radiolabeled water (15O-water) is considered the\ngold-standard for the measurement of CBF in humans. PET imaging, however, is\nnot widely available because of its prohibitive costs and use of short-lived\nradiopharmaceutical tracers that typically require onsite cyclotron production.\nMagnetic resonance imaging (MRI), in contrast, is more readily accessible and\ndoes not involve ionizing radiation. This study presents a convolutional\nencoder-decoder network with attention mechanisms to predict gold-standard\n15O-water PET CBF from multi-sequence MRI scans, thereby eliminating the need\nfor radioactive tracers. Inputs to the prediction model include several\ncommonly used MRI sequences (T1-weighted, T2-FLAIR, and arterial spin\nlabeling). The model was trained and validated using 5-fold cross-validation in\na group of 126 subjects consisting of healthy controls and cerebrovascular\ndisease patients, all of whom underwent simultaneous $15O-water PET/MRI. The\nresults show that such a model can successfully synthesize high-quality PET CBF\nmeasurements (with an average SSIM of 0.924 and PSNR of 38.8 dB) and is more\naccurate compared to concurrent and previous PET synthesis methods. We also\ndemonstrate the clinical significance of the proposed algorithm by evaluating\nthe agreement for identifying the vascular territories with abnormally low CBF.\nSuch methods may enable more widespread and accurate CBF evaluation in larger\ncohorts who cannot undergo PET imaging due to radiation concerns, lack of\naccess, or logistic challenges.", "published": "2022-11-22T08:25:44Z", "version": 1}, {"aid": "2211.12117", "authors": ["Pengcheng Lei", "Faming Fang", "Guixu Zhang"], "title": "Flow Guidance Deformable Compensation Network for Video Frame Interpolation", "url": "http://arxiv.org/pdf/2211.12117v1", "summary": "Motion-based video frame interpolation (VFI) methods have made remarkable\nprogress with the development of deep convolutional networks over the past\nyears. While their performance is often jeopardized by the inaccuracy of flow\nmap estimation, especially in the case of large motion and occlusion. In this\npaper, we propose a flow guidance deformable compensation network (FGDCN) to\novercome the drawbacks of existing motion-based methods. FGDCN decomposes the\nframe sampling process into two steps: a flow step and a deformation step.\nSpecifically, the flow step utilizes a coarse-to-fine flow estimation network\nto directly estimate the intermediate flows and synthesizes an anchor frame\nsimultaneously. To ensure the accuracy of the estimated flow, a distillation\nloss and a task-oriented loss are jointly employed in this step. Under the\nguidance of the flow priors learned in step one, the deformation step designs a\npyramid deformable compensation network to compensate for the missing details\nof the flow step. In addition, a pyramid loss is proposed to supervise the\nmodel in both the image and frequency domain. Experimental results show that\nthe proposed algorithm achieves excellent performance on various datasets with\nfewer parameters.", "published": "2022-11-22T09:35:14Z", "version": 1}, {"aid": "2211.12698", "authors": ["Chun Bao", "Jie Cao", "Yaqian Ning", "Yang Cheng", "Qun Hao"], "title": "Rega-Net:Retina Gabor Attention for Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2211.12698v2", "summary": "Extensive research works demonstrate that the attention mechanism in\nconvolutional neural networks (CNNs) effectively improves accuracy.\nNevertheless, few works design attention mechanisms using large receptive\nfields. In this work, we propose a novel attention method named Rega-net to\nincrease CNN accuracy by enlarging the receptive field. Inspired by the\nmechanism of the human retina, we design convolutional kernels to resemble the\nnon-uniformly distributed structure of the human retina. Then, we sample\nvariable-resolution values in the Gabor function distribution and fill these\nvalues in retina-like kernels. This distribution allows essential features to\nbe more visible in the center position of the receptive field. We further\ndesign an attention module including these retina-like kernels. Experiments\ndemonstrate that our Rega-Net achieves 79.96% top-1 accuracy on ImageNet-1K\nclassification and 43.1% mAP on COCO2017 object detection. The mAP of the\nRega-Net increased by up to 3.5% compared to baseline networks.", "published": "2022-11-23T04:24:21Z", "version": 2}, {"aid": "2211.13524", "authors": ["Yinhuai Wang", "Yujie Hu", "Jiwen Yu", "Jian Zhang"], "title": "GAN Prior based Null-Space Learning for Consistent Super-Resolution", "url": "http://arxiv.org/pdf/2211.13524v1", "summary": "Consistency and realness have always been the two critical issues of image\nsuper-resolution. While the realness has been dramatically improved with the\nuse of GAN prior, the state-of-the-art methods still suffer inconsistencies in\nlocal structures and colors (e.g., tooth and eyes). In this paper, we show that\nthese inconsistencies can be analytically eliminated by learning only the\nnull-space component while fixing the range-space part. Further, we design a\npooling-based decomposition (PD), a universal range-null space decomposition\nfor super-resolution tasks, which is concise, fast, and parameter-free. PD can\nbe easily applied to state-of-the-art GAN Prior based SR methods to eliminate\ntheir inconsistencies, neither compromising the realness nor bringing extra\nparameters or computational costs. Besides, our ablation studies reveal that PD\ncan replace pixel-wise losses for training and achieve better generalization\nperformance when facing unseen downsamplings or even real-world degradation.\nExperiments show that the use of PD refreshes state-of-the-art SR performance\nand speeds up the convergence of training up to 2~10 times.", "published": "2022-11-24T10:45:15Z", "version": 1}, {"aid": "2211.13676", "authors": ["Seung Ho Park", "Young Su Moon", "Nam Ik Cho"], "title": "Perception-Oriented Single Image Super-Resolution using Optimal Objective Estimation", "url": "http://arxiv.org/pdf/2211.13676v3", "summary": "Single-image super-resolution (SISR) networks trained with perceptual and\nadversarial losses provide high-contrast outputs compared to those of networks\ntrained with distortion-oriented losses, such as L1 or L2. However, it has been\nshown that using a single perceptual loss is insufficient for accurately\nrestoring locally varying diverse shapes in images, often generating\nundesirable artifacts or unnatural details. For this reason, combinations of\nvarious losses, such as perceptual, adversarial, and distortion losses, have\nbeen attempted, yet it remains challenging to find optimal combinations. Hence,\nin this paper, we propose a new SISR framework that applies optimal objectives\nfor each region to generate plausible results in overall areas of\nhigh-resolution outputs. Specifically, the framework comprises two models: a\npredictive model that infers an optimal objective map for a given\nlow-resolution (LR) input and a generative model that applies a target\nobjective map to produce the corresponding SR output. The generative model is\ntrained over our proposed objective trajectory representing a set of essential\nobjectives, which enables the single network to learn various SR results\ncorresponding to combined losses on the trajectory. The predictive model is\ntrained using pairs of LR images and corresponding optimal objective maps\nsearched from the objective trajectory. Experimental results on five benchmarks\nshow that the proposed method outperforms state-of-the-art perception-driven SR\nmethods in LPIPS, DISTS, PSNR, and SSIM metrics. The visual results also\ndemonstrate the superiority of our method in perception-oriented\nreconstruction. The code and models are available at\nhttps://github.com/seungho-snu/SROOE.", "published": "2022-11-24T15:45:03Z", "version": 3}, {"aid": "2211.13724", "authors": ["Ali Harakeh", "Jordan Hu", "Naiqing Guan", "Steven L. Waslander", "Liam Paull"], "title": "Estimating Regression Predictive Distributions with Sample Networks", "url": "http://arxiv.org/pdf/2211.13724v1", "summary": "Estimating the uncertainty in deep neural network predictions is crucial for\nmany real-world applications. A common approach to model uncertainty is to\nchoose a parametric distribution and fit the data to it using maximum\nlikelihood estimation. The chosen parametric form can be a poor fit to the\ndata-generating distribution, resulting in unreliable uncertainty estimates. In\nthis work, we propose SampleNet, a flexible and scalable architecture for\nmodeling uncertainty that avoids specifying a parametric form on the output\ndistribution. SampleNets do so by defining an empirical distribution using\nsamples that are learned with the Energy Score and regularized with the\nSinkhorn Divergence. SampleNets are shown to be able to well-fit a wide range\nof distributions and to outperform baselines on large-scale real-world\nregression tasks.", "published": "2022-11-24T17:23:29Z", "version": 1}, {"aid": "2211.13757", "authors": ["Gene Chou", "Yuval Bahat", "Felix Heide"], "title": "Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions", "url": "http://arxiv.org/pdf/2211.13757v2", "summary": "Probabilistic diffusion models have achieved state-of-the-art results for\nimage synthesis, inpainting, and text-to-image tasks. However, they are still\nin the early stages of generating complex 3D shapes. This work proposes\nDiffusion-SDF, a generative model for shape completion, single-view\nreconstruction, and reconstruction of real-scanned point clouds. We use neural\nsigned distance functions (SDFs) as our 3D representation to parameterize the\ngeometry of various signals (e.g., point clouds, 2D images) through neural\nnetworks. Neural SDFs are implicit functions and diffusing them amounts to\nlearning the reversal of their neural network weights, which we solve using a\ncustom modulation module. Extensive experiments show that our method is capable\nof both realistic unconditional generation and conditional generation from\npartial inputs. This work expands the domain of diffusion models from learning\n2D, explicit representations, to 3D, implicit representations.", "published": "2022-11-24T18:59:01Z", "version": 2}, {"aid": "2211.14794", "authors": ["Guangrun Wang", "Philip H. S. Torr"], "title": "Traditional Classification Neural Networks are Good Generators: They are Competitive with DDPMs and GANs", "url": "http://arxiv.org/pdf/2211.14794v2", "summary": "Classifiers and generators have long been separated. We break down this\nseparation and showcase that conventional neural network classifiers can\ngenerate high-quality images of a large number of categories, being comparable\nto the state-of-the-art generative models (e.g., DDPMs and GANs). We achieve\nthis by computing the partial derivative of the classification loss function\nwith respect to the input to optimize the input to produce an image. Since it\nis widely known that directly optimizing the inputs is similar to targeted\nadversarial attacks incapable of generating human-meaningful images, we propose\na mask-based stochastic reconstruction module to make the gradients\nsemantic-aware to synthesize plausible images. We further propose a\nprogressive-resolution technique to guarantee fidelity, which produces\nphotorealistic images. Furthermore, we introduce a distance metric loss and a\nnon-trivial distribution loss to ensure classification neural networks can\nsynthesize diverse and high-fidelity images. Using traditional neural network\nclassifiers, we can generate good-quality images of 256$\\times$256 resolution\non ImageNet. Intriguingly, our method is also applicable to text-to-image\ngeneration by regarding image-text foundation models as generalized\nclassifiers.\n  Proving that classifiers have learned the data distribution and are ready for\nimage generation has far-reaching implications, for classifiers are much easier\nto train than generative models like DDPMs and GANs. We don't even need to\ntrain classification models because tons of public ones are available for\ndownload. Also, this holds great potential for the interpretability and\nrobustness of classifiers. Project page is at\n\\url{https://classifier-as-generator.github.io/}.", "published": "2022-11-27T11:25:35Z", "version": 2}, {"aid": "2211.17106", "authors": ["Xingyi Yang", "Daquan Zhou", "Jiashi Feng", "Xinchao Wang"], "title": "Diffusion Probabilistic Model Made Slim", "url": "http://arxiv.org/pdf/2211.17106v1", "summary": "Despite the recent visually-pleasing results achieved, the massive\ncomputational cost has been a long-standing flaw for diffusion probabilistic\nmodels (DPMs), which, in turn, greatly limits their applications on\nresource-limited platforms. Prior methods towards efficient DPM, however, have\nlargely focused on accelerating the testing yet overlooked their huge\ncomplexity and sizes. In this paper, we make a dedicated attempt to lighten DPM\nwhile striving to preserve its favourable performance. We start by training a\nsmall-sized latent diffusion model (LDM) from scratch, but observe a\nsignificant fidelity drop in the synthetic images. Through a thorough\nassessment, we find that DPM is intrinsically biased against high-frequency\ngeneration, and learns to recover different frequency components at different\ntime-steps. These properties make compact networks unable to represent\nfrequency dynamics with accurate high-frequency estimation. Towards this end,\nwe introduce a customized design for slim DPM, which we term as Spectral\nDiffusion (SD), for light-weight image synthesis. SD incorporates wavelet\ngating in its architecture to enable frequency dynamic feature extraction at\nevery reverse steps, and conducts spectrum-aware distillation to promote\nhigh-frequency recovery by inverse weighting the objective based on spectrum\nmagni tudes. Experimental results demonstrate that, SD achieves 8-18x\ncomputational complexity reduction as compared to the latent diffusion models\non a series of conditional and unconditional image generation tasks while\nretaining competitive image fidelity.", "published": "2022-11-27T16:27:28Z", "version": 1}, {"aid": "2212.02226", "authors": ["Xueqing Liu", "Tao Tu", "Paul Sajda"], "title": "Inferring latent neural sources via deep transcoding of simultaneously acquired EEG and fMRI", "url": "http://arxiv.org/pdf/2212.02226v1", "summary": "Simultaneous EEG-fMRI is a multi-modal neuroimaging technique that provides\ncomplementary spatial and temporal resolution. Challenging has been developing\nprincipled and interpretable approaches for fusing the modalities, specifically\napproaches enabling inference of latent source spaces representative of neural\nactivity. In this paper, we address this inference problem within the framework\nof transcoding -- mapping from a specific encoding (modality) to a decoding\n(the latent source space) and then encoding the latent source space to the\nother modality. Specifically, we develop a symmetric method consisting of a\ncyclic convolutional transcoder that transcodes EEG to fMRI and vice versa.\nWithout any prior knowledge of either the hemodynamic response function or lead\nfield matrix, the complete data-driven method exploits the temporal and spatial\nrelationships between the modalities and latent source spaces to learn these\nmappings. We quantify, for both the simulated and real EEG-fMRI data, how well\nthe modalities can be transcoded from one to another as well as the source\nspaces that are recovered, all evaluated on unseen data. In addition to\nenabling a new way to symmetrically infer a latent source space, the method can\nalso be seen as low-cost computational neuroimaging -- i.e. generating an\n'expensive' fMRI BOLD image from 'low cost' EEG data.", "published": "2022-11-27T23:44:16Z", "version": 1}, {"aid": "2211.15736", "authors": ["Yuzhang Shang", "Zhihang Yuan", "Bin Xie", "Bingzhe Wu", "Yan Yan"], "title": "Post-training Quantization on Diffusion Models", "url": "http://arxiv.org/pdf/2211.15736v3", "summary": "Denoising diffusion (score-based) generative models have recently achieved\nsignificant accomplishments in generating realistic and diverse data. These\napproaches define a forward diffusion process for transforming data into noise\nand a backward denoising process for sampling data from noise. Unfortunately,\nthe generation process of current denoising diffusion models is notoriously\nslow due to the lengthy iterative noise estimations, which rely on cumbersome\nneural networks. It prevents the diffusion models from being widely deployed,\nespecially on edge devices. Previous works accelerate the generation process of\ndiffusion model (DM) via finding shorter yet effective sampling trajectories.\nHowever, they overlook the cost of noise estimation with a heavy network in\nevery iteration. In this work, we accelerate generation from the perspective of\ncompressing the noise estimation network. Due to the difficulty of retraining\nDMs, we exclude mainstream training-aware compression paradigms and introduce\npost-training quantization (PTQ) into DM acceleration. However, the output\ndistributions of noise estimation networks change with time-step, making\nprevious PTQ methods fail in DMs since they are designed for single-time step\nscenarios. To devise a DM-specific PTQ method, we explore PTQ on DM in three\naspects: quantized operations, calibration dataset, and calibration metric. We\nsummarize and use several observations derived from all-inclusive\ninvestigations to formulate our method, which especially targets the unique\nmulti-time-step structure of DMs. Experimentally, our method can directly\nquantize full-precision DMs into 8-bit models while maintaining or even\nimproving their performance in a training-free manner. Importantly, our method\ncan serve as a plug-and-play module on other fast-sampling methods, e.g., DDIM.\nThe code is available at https://github.com/42Shawn/PTQ4DM .", "published": "2022-11-28T19:33:39Z", "version": 3}, {"aid": "2211.17091", "authors": ["Dongjun Kim", "Yeongmin Kim", "Se Jung Kwon", "Wanmo Kang", "Il-Chul Moon"], "title": "Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models", "url": "http://arxiv.org/pdf/2211.17091v4", "summary": "The proposed method, Discriminator Guidance, aims to improve sample\ngeneration of pre-trained diffusion models. The approach introduces a\ndiscriminator that gives explicit supervision to a denoising sample path\nwhether it is realistic or not. Unlike GANs, our approach does not require\njoint training of score and discriminator networks. Instead, we train the\ndiscriminator after score training, making discriminator training stable and\nfast to converge. In sample generation, we add an auxiliary term to the\npre-trained score to deceive the discriminator. This term corrects the model\nscore to the data score at the optimal discriminator, which implies that the\ndiscriminator helps better score estimation in a complementary way. Using our\nalgorithm, we achive state-of-the-art results on ImageNet 256x256 with FID 1.83\nand recall 0.64, similar to the validation data's FID (1.68) and recall (0.66).\nWe release the code at https://github.com/alsdudrla10/DG.", "published": "2022-11-28T20:04:12Z", "version": 4}, {"aid": "2211.16032", "authors": ["Han Zhang", "Ruili Feng", "Zhantao Yang", "Lianghua Huang", "Yu Liu", "Yifei Zhang", "Yujun Shen", "Deli Zhao", "Jingren Zhou", "Fan Cheng"], "title": "Dimensionality-Varying Diffusion Process", "url": "http://arxiv.org/pdf/2211.16032v1", "summary": "Diffusion models, which learn to reverse a signal destruction process to\ngenerate new data, typically require the signal at each step to have the same\ndimension. We argue that, considering the spatial redundancy in image signals,\nthere is no need to maintain a high dimensionality in the evolution process,\nespecially in the early generation phase. To this end, we make a theoretical\ngeneralization of the forward diffusion process via signal decomposition.\nConcretely, we manage to decompose an image into multiple orthogonal components\nand control the attenuation of each component when perturbing the image. That\nway, along with the noise strength increasing, we are able to diminish those\ninconsequential components and thus use a lower-dimensional signal to represent\nthe source, barely losing information. Such a reformulation allows to vary\ndimensions in both training and inference of diffusion models. Extensive\nexperiments on a range of datasets suggest that our approach substantially\nreduces the computational cost and achieves on-par or even better synthesis\nperformance compared to baseline methods. We also show that our strategy\nfacilitates high-resolution image synthesis and improves FID of diffusion model\ntrained on FFHQ at $1024\\times1024$ resolution from 52.40 to 10.46. Code and\nmodels will be made publicly available.", "published": "2022-11-29T09:05:55Z", "version": 1}, {"aid": "2211.16095", "authors": ["Seong-Woong Kim", "Dong-Wan Choi"], "title": "Better Generalized Few-Shot Learning Even Without Base Data", "url": "http://arxiv.org/pdf/2211.16095v2", "summary": "This paper introduces and studies zero-base generalized few-shot learning\n(zero-base GFSL), which is an extreme yet practical version of few-shot\nlearning problem. Motivated by the cases where base data is not available due\nto privacy or ethical issues, the goal of zero-base GFSL is to newly\nincorporate the knowledge of few samples of novel classes into a pretrained\nmodel without any samples of base classes. According to our analysis, we\ndiscover the fact that both mean and variance of the weight distribution of\nnovel classes are not properly established, compared to those of base classes.\nThe existing GFSL methods attempt to make the weight norms balanced, which we\nfind helps only the variance part, but discard the importance of mean of\nweights particularly for novel classes, leading to the limited performance in\nthe GFSL problem even with base data. In this paper, we overcome this\nlimitation by proposing a simple yet effective normalization method that can\neffectively control both mean and variance of the weight distribution of novel\nclasses without using any base samples and thereby achieve a satisfactory\nperformance on both novel and base classes. Our experimental results somewhat\nsurprisingly show that the proposed zero-base GFSL method that does not utilize\nany base samples even outperforms the existing GFSL methods that make the best\nuse of base data. Our implementation is available at:\nhttps://github.com/bigdata-inha/Zero-Base-GFSL.", "published": "2022-11-29T11:10:40Z", "version": 2}, {"aid": "2211.16135", "authors": ["Sicong Liu", "Xiaochen Li", "Zimu Zhou", "Bin Guo", "Meng Zhang", "Haochen Shen", "Zhiwen Yu"], "title": "AdaEnlight: Energy-aware Low-light Video Stream Enhancement on Mobile Devices", "url": "http://arxiv.org/pdf/2211.16135v2", "summary": "The ubiquity of camera-embedded devices and the advances in deep learning\nhave stimulated various intelligent mobile video applications. These\napplications often demand on-device processing of video streams to deliver\nreal-time, high-quality services for privacy and robustness concerns. However,\nthe performance of these applications is constrained by the raw video streams,\nwhich tend to be taken with small-aperture cameras of ubiquitous mobile\nplatforms in dim light. Despite extensive low-light video enhancement\nsolutions, they are unfit for deployment to mobile devices due to their complex\nmodels and and ignorance of system dynamics like energy budgets. In this paper,\nwe propose AdaEnlight, an energy-aware low-light video stream enhancement\nsystem on mobile devices. It achieves real-time video enhancement with\ncompetitive visual quality while allowing runtime behavior adaptation to the\nplatform-imposed dynamic energy budgets. We report extensive experiments on\ndiverse datasets, scenarios, and platforms and demonstrate the superiority of\nAdaEnlight compared with state-of-the-art low-light image and video enhancement\nsolutions.", "published": "2022-11-29T12:12:34Z", "version": 2}, {"aid": "2211.16246", "authors": ["Debo Cheng", "Ziqi Xu", "Jiuyong Li", "Lin Liu", "Jixue Liu", "Thuc Duy Le"], "title": "Causal Inference with Conditional Instruments using Deep Generative Models", "url": "http://arxiv.org/pdf/2211.16246v1", "summary": "The instrumental variable (IV) approach is a widely used way to estimate the\ncausal effects of a treatment on an outcome of interest from observational data\nwith latent confounders. A standard IV is expected to be related to the\ntreatment variable and independent of all other variables in the system.\nHowever, it is challenging to search for a standard IV from data directly due\nto the strict conditions. The conditional IV (CIV) method has been proposed to\nallow a variable to be an instrument conditioning on a set of variables,\nallowing a wider choice of possible IVs and enabling broader practical\napplications of the IV approach. Nevertheless, there is not a data-driven\nmethod to discover a CIV and its conditioning set directly from data. To fill\nthis gap, in this paper, we propose to learn the representations of the\ninformation of a CIV and its conditioning set from data with latent confounders\nfor average causal effect estimation. By taking advantage of deep generative\nmodels, we develop a novel data-driven approach for simultaneously learning the\nrepresentation of a CIV from measured variables and generating the\nrepresentation of its conditioning set given measured variables. Extensive\nexperiments on synthetic and real-world datasets show that our method\noutperforms the existing IV methods.", "published": "2022-11-29T14:31:54Z", "version": 1}, {"aid": "2211.16356", "authors": ["Runjia Li", "Yang Yu", "Charlie Haywood"], "title": "Real-time Blind Deblurring Based on Lightweight Deep-Wiener-Network", "url": "http://arxiv.org/pdf/2211.16356v3", "summary": "In this paper, we address the problem of blind deblurring with high\nefficiency. We propose a set of lightweight deep-wiener-network to finish the\ntask with real-time speed. The Network contains a deep neural network for\nestimating parameters of wiener networks and a wiener network for deblurring.\nExperimental evaluations show that our approaches have an edge on State of the\nArt in terms of inference times and numbers of parameters. Two of our models\ncan reach a speed of 100 images per second, which is qualified for real-time\ndeblurring. Further research may focus on some real-world applications of\ndeblurring with our models.", "published": "2022-11-29T16:42:01Z", "version": 3}, {"aid": "2211.16678", "authors": ["Kyoungwan Woo", "Achyuta Rajaram"], "title": "FREDSR: Fourier Residual Efficient Diffusive GAN for Single Image Super Resolution", "url": "http://arxiv.org/pdf/2211.16678v1", "summary": "FREDSR is a GAN variant that aims to outperform traditional GAN models in\nspecific tasks such as Single Image Super Resolution with extreme parameter\nefficiency at the cost of per-dataset generalizeability. FREDSR integrates fast\nFourier transformation, residual prediction, diffusive discriminators, etc to\nachieve strong performance in comparisons to other models on the UHDSR4K\ndataset for Single Image 3x Super Resolution from 360p and 720p with only 37000\nparameters. The model follows the characteristics of the given dataset,\nresulting in lower generalizeability but higher performance on tasks such as\nreal time up-scaling.", "published": "2022-11-30T01:58:52Z", "version": 1}, {"aid": "2211.16780", "authors": ["Quyen Tran", "Hoang Phan", "Khoat Than", "Dinh Phung", "Trung Le"], "title": "Continual Learning with Optimal Transport based Mixture Model", "url": "http://arxiv.org/pdf/2211.16780v2", "summary": "Online Class Incremental learning (CIL) is a challenging setting in Continual\nLearning (CL), wherein data of new tasks arrive in incoming streams and online\nlearning models need to handle incoming data streams without revisiting\nprevious ones. Existing works used a single centroid adapted with incoming data\nstreams to characterize a class. This approach possibly exposes limitations\nwhen the incoming data stream of a class is naturally multimodal. To address\nthis issue, in this work, we first propose an online mixture model learning\napproach based on nice properties of the mature optimal transport theory\n(OT-MM). Specifically, the centroids and covariance matrices of the mixture\nmodel are adapted incrementally according to incoming data streams. The\nadvantages are two-fold: (i) we can characterize more accurately complex data\nstreams and (ii) by using centroids for each class produced by OT-MM, we can\nestimate the similarity of an unseen example to each class more reasonably when\ndoing inference. Moreover, to combat the catastrophic forgetting in the CIL\nscenario, we further propose Dynamic Preservation. Particularly, after\nperforming the dynamic preservation technique across data streams, the latent\nrepresentations of the classes in the old and new tasks become more condensed\nthemselves and more separate from each other. Together with a contraction\nfeature extractor, this technique facilitates the model in mitigating the\ncatastrophic forgetting. The experimental results on real-world datasets show\nthat our proposed method can significantly outperform the current\nstate-of-the-art baselines.", "published": "2022-11-30T06:40:29Z", "version": 2}, {"aid": "2211.17115", "authors": ["Giannis Daras", "Alexandros G. Dimakis"], "title": "Multiresolution Textual Inversion", "url": "http://arxiv.org/pdf/2211.17115v1", "summary": "We extend Textual Inversion to learn pseudo-words that represent a concept at\ndifferent resolutions. This allows us to generate images that use the concept\nwith different levels of detail and also to manipulate different resolutions\nusing language. Once learned, the user can generate images at different levels\nof agreement to the original concept; \"A photo of $S^*(0)$\" produces the exact\nobject while the prompt \"A photo of $S^*(0.8)$\" only matches the rough outlines\nand colors. Our framework allows us to generate images that use different\nresolutions of an image (e.g. details, textures, styles) as separate\npseudo-words that can be composed in various ways. We open-soure our code in\nthe following URL: https://github.com/giannisdaras/multires_textual_inversion", "published": "2022-11-30T15:57:56Z", "version": 1}, {"aid": "2212.00490", "authors": ["Yinhuai Wang", "Jiwen Yu", "Jian Zhang"], "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model", "url": "http://arxiv.org/pdf/2212.00490v2", "summary": "Most existing Image Restoration (IR) models are task-specific, which can not\nbe generalized to different degradation operators. In this work, we propose the\nDenoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for\narbitrary linear IR problems, including but not limited to image\nsuper-resolution, colorization, inpainting, compressed sensing, and deblurring.\nDDNM only needs a pre-trained off-the-shelf diffusion model as the generative\nprior, without any extra training or network modifications. By refining only\nthe null-space contents during the reverse diffusion process, we can yield\ndiverse results satisfying both data consistency and realness. We further\npropose an enhanced and robust version, dubbed DDNM+, to support noisy\nrestoration and improve restoration quality for hard tasks. Our experiments on\nseveral IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot\nIR methods. We also demonstrate that DDNM+ can solve complex real-world\napplications, e.g., old photo restoration.", "published": "2022-12-01T13:33:47Z", "version": 2}, {"aid": "2212.01354", "authors": ["Karl J Friston", "Maxwell J D Ramstead", "Alex B Kiefer", "Alexander Tschantz", "Christopher L Buckley", "Mahault Albarracin", "Riddhi J Pitliya", "Conor Heins", "Brennan Klein", "Beren Millidge", "Dalton A R Sakthivadivel", "Toby St Clere Smithe", "Magnus Koudahl", "Safae Essafi Tremblay", "Capm Petersen", "Kaiser Fung", "Jason G Fox", "Steven Swanson", "Dan Mapes", "Gabriel Ren\u00e9"], "title": "Designing Ecosystems of Intelligence from First Principles", "url": "http://arxiv.org/pdf/2212.01354v2", "summary": "This white paper lays out a vision of research and development in the field\nof artificial intelligence for the next decade (and beyond). Its denouement is\na cyber-physical ecosystem of natural and synthetic sense-making, in which\nhumans are integral participants -- what we call ''shared intelligence''. This\nvision is premised on active inference, a formulation of adaptive behavior that\ncan be read as a physics of intelligence, and which inherits from the physics\nof self-organization. In this context, we understand intelligence as the\ncapacity to accumulate evidence for a generative model of one's sensed world --\nalso known as self-evidencing. Formally, this corresponds to maximizing\n(Bayesian) model evidence, via belief updating over several scales: i.e.,\ninference, learning, and model selection. Operationally, this self-evidencing\ncan be realized via (variational) message passing or belief propagation on a\nfactor graph. Crucially, active inference foregrounds an existential imperative\nof intelligent systems; namely, curiosity or the resolution of uncertainty.\nThis same imperative underwrites belief sharing in ensembles of agents, in\nwhich certain aspects (i.e., factors) of each agent's generative world model\nprovide a common ground or frame of reference. Active inference plays a\nfoundational role in this ecology of belief sharing -- leading to a formal\naccount of collective intelligence that rests on shared narratives and goals.\nWe also consider the kinds of communication protocols that must be developed to\nenable such an ecosystem of intelligences and motivate the development of a\nshared hyper-spatial modeling language and transaction protocol, as a first --\nand key -- step towards such an ecology.", "published": "2022-12-02T18:24:06Z", "version": 2}, {"aid": "2212.01433", "authors": ["Sheng Liu", "Xu Zhang", "Nitesh Sekhar", "Yue Wu", "Prateek Singhal", "Carlos Fernandez-Granda"], "title": "Avoiding spurious correlations via logit correction", "url": "http://arxiv.org/pdf/2212.01433v2", "summary": "Empirical studies suggest that machine learning models trained with empirical\nrisk minimization (ERM) often rely on attributes that may be spuriously\ncorrelated with the class labels. Such models typically lead to poor\nperformance during inference for data lacking such correlations. In this work,\nwe explicitly consider a situation where potential spurious correlations are\npresent in the majority of training data. In contrast with existing approaches,\nwhich use the ERM model outputs to detect the samples without spurious\ncorrelations and either heuristically upweight or upsample those samples, we\npropose the logit correction (LC) loss, a simple yet effective improvement on\nthe softmax cross-entropy loss, to correct the sample logit. We demonstrate\nthat minimizing the LC loss is equivalent to maximizing the group-balanced\naccuracy, so the proposed LC could mitigate the negative impacts of spurious\ncorrelations. Our extensive experimental results further reveal that the\nproposed LC loss outperforms state-of-the-art solutions on multiple popular\nbenchmarks by a large margin, an average 5.5\\% absolute improvement, without\naccess to spurious attribute labels. LC is also competitive with oracle methods\nthat make use of the attribute labels. Code is available at\nhttps://github.com/shengliu66/LC.", "published": "2022-12-02T20:30:59Z", "version": 2}, {"aid": "2212.01508", "authors": ["Rajkumar Vasudeva Raju", "J. Swaroop Guntupalli", "Guangyao Zhou", "Miguel L\u00e1zaro-Gredilla", "Dileep George"], "title": "Space is a latent sequence: Structured sequence learning as a unified theory of representation in the hippocampus", "url": "http://arxiv.org/pdf/2212.01508v1", "summary": "Fascinating and puzzling phenomena, such as landmark vector cells, splitter\ncells, and event-specific representations to name a few, are regularly\ndiscovered in the hippocampus. Without a unifying principle that can explain\nthese divergent observations, each experiment seemingly discovers a new anomaly\nor coding type. Here, we provide a unifying principle that the mental\nrepresentation of space is an emergent property of latent higher-order sequence\nlearning. Treating space as a sequence resolves myriad phenomena, and suggests\nthat the place-field mapping methodology where sequential neuron responses are\ninterpreted in spatial and Euclidean terms might itself be a source of\nanomalies. Our model, called Clone-structured Causal Graph (CSCG), uses a\nspecific higher-order graph scaffolding to learn latent representations by\nmapping sensory inputs to unique contexts. Learning to compress sequential and\nepisodic experiences using CSCGs result in the emergence of cognitive maps -\nmental representations of spatial and conceptual relationships in an\nenvironment that are suited for planning, introspection, consolidation, and\nabstraction. We demonstrate that over a dozen different hippocampal phenomena,\nranging from those reported in classic experiments to the most recent ones, are\nsuccinctly and mechanistically explained by our model.", "published": "2022-12-03T02:00:56Z", "version": 1}, {"aid": "2212.01624", "authors": ["Feng Li", "Yixuan Wu", "Huihui Bai", "Weisi Lin", "Runmin Cong", "Yao Zhao"], "title": "Learning Detail-Structure Alternative Optimization for Blind Super-Resolution", "url": "http://arxiv.org/pdf/2212.01624v1", "summary": "Existing convolutional neural networks (CNN) based image super-resolution\n(SR) methods have achieved impressive performance on bicubic kernel, which is\nnot valid to handle unknown degradations in real-world applications. Recent\nblind SR methods suggest to reconstruct SR images relying on blur kernel\nestimation. However, their results still remain visible artifacts and detail\ndistortion due to the estimation errors. To alleviate these problems, in this\npaper, we propose an effective and kernel-free network, namely DSSR, which\nenables recurrent detail-structure alternative optimization without blur kernel\nprior incorporation for blind SR. Specifically, in our DSSR, a detail-structure\nmodulation module (DSMM) is built to exploit the interaction and collaboration\nof image details and structures. The DSMM consists of two components: a detail\nrestoration unit (DRU) and a structure modulation unit (SMU). The former aims\nat regressing the intermediate HR detail reconstruction from LR structural\ncontexts, and the latter performs structural contexts modulation conditioned on\nthe learned detail maps at both HR and LR spaces. Besides, we use the output of\nDSMM as the hidden state and design our DSSR architecture from a recurrent\nconvolutional neural network (RCNN) view. In this way, the network can\nalternatively optimize the image details and structural contexts, achieving\nco-optimization across time. Moreover, equipped with the recurrent connection,\nour DSSR allows low- and high-level feature representations complementary by\nobserving previous HR details and contexts at every unrolling time. Extensive\nexperiments on synthetic datasets and real-world images demonstrate that our\nmethod achieves the state-of-the-art against existing methods. The source code\ncan be found at https://github.com/Arcananana/DSSR.", "published": "2022-12-03T14:44:17Z", "version": 1}, {"aid": "2212.01735", "authors": ["Zhijie Wu", "Yuhe Jin", "Kwang Moo Yi"], "title": "Neural Fourier Filter Bank", "url": "http://arxiv.org/pdf/2212.01735v4", "summary": "We present a novel method to provide efficient and highly detailed\nreconstructions. Inspired by wavelets, we learn a neural field that decompose\nthe signal both spatially and frequency-wise. We follow the recent grid-based\nparadigm for spatial decomposition, but unlike existing work, encourage\nspecific frequencies to be stored in each grid via Fourier features encodings.\nWe then apply a multi-layer perceptron with sine activations, taking these\nFourier encoded features in at appropriate layers so that higher-frequency\ncomponents are accumulated on top of lower-frequency components sequentially,\nwhich we sum up to form the final output. We demonstrate that our method\noutperforms the state of the art regarding model compactness and convergence\nspeed on multiple tasks: 2D image fitting, 3D shape reconstruction, and neural\nradiance fields. Our code is available at https://github.com/ubc-vision/NFFB.", "published": "2022-12-04T03:45:08Z", "version": 4}, {"aid": "2212.02936", "authors": ["Samuel Weinbach", "Marco Bellagente", "Constantin Eichenberg", "Andrew Dai", "Robert Baldock", "Souradeep Nanda", "Bj\u00f6rn Deiseroth", "Koen Oostermeijer", "Hannah Teufel", "Andres Felipe Cruz-Salinas"], "title": "M-VADER: A Model for Diffusion with Multimodal Context", "url": "http://arxiv.org/pdf/2212.02936v2", "summary": "We introduce M-VADER: a diffusion model (DM) for image generation where the\noutput can be specified using arbitrary combinations of images and text. We\nshow how M-VADER enables the generation of images specified using combinations\nof image and text, and combinations of multiple images. Previously, a number of\nsuccessful DM image generation algorithms have been introduced that make it\npossible to specify the output image using a text prompt. Inspired by the\nsuccess of those models, and led by the notion that language was already\ndeveloped to describe the elements of visual contexts that humans find most\nimportant, we introduce an embedding model closely related to a vision-language\nmodel. Specifically, we introduce the embedding model S-MAGMA: a 13 billion\nparameter multimodal decoder combining components from an autoregressive\nvision-language model MAGMA and biases finetuned for semantic search.", "published": "2022-12-06T12:45:21Z", "version": 2}, {"aid": "2212.03293", "authors": ["Muheng Li", "Yueqi Duan", "Jie Zhou", "Jiwen Lu"], "title": "Diffusion-SDF: Text-to-Shape via Voxelized Diffusion", "url": "http://arxiv.org/pdf/2212.03293v2", "summary": "With the rising industrial attention to 3D virtual modeling technology,\ngenerating novel 3D content based on specified conditions (e.g. text) has\nbecome a hot issue. In this paper, we propose a new generative 3D modeling\nframework called Diffusion-SDF for the challenging task of text-to-shape\nsynthesis. Previous approaches lack flexibility in both 3D data representation\nand shape generation, thereby failing to generate highly diversified 3D shapes\nconforming to the given text descriptions. To address this, we propose a SDF\nautoencoder together with the Voxelized Diffusion model to learn and generate\nrepresentations for voxelized signed distance fields (SDFs) of 3D shapes.\nSpecifically, we design a novel UinU-Net architecture that implants a\nlocal-focused inner network inside the standard U-Net architecture, which\nenables better reconstruction of patch-independent SDF representations. We\nextend our approach to further text-to-shape tasks including text-conditioned\nshape completion and manipulation. Experimental results show that Diffusion-SDF\ngenerates both higher quality and more diversified 3D shapes that conform well\nto given text descriptions when compared to previous approaches. Code is\navailable at: https://github.com/ttlmh/Diffusion-SDF", "published": "2022-12-06T19:46:47Z", "version": 2}, {"aid": "2212.03306", "authors": ["Yao Su", "Zhentian Qian", "Lifang He", "Xiangnan Kong"], "title": "ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data", "url": "http://arxiv.org/pdf/2212.03306v1", "summary": "Brain extraction and registration are important preprocessing steps in\nneuroimaging data analysis, where the goal is to extract the brain regions from\nMRI scans (i.e., extraction step) and align them with a target brain image\n(i.e., registration step). Conventional research mainly focuses on developing\nmethods for the extraction and registration tasks separately under supervised\nsettings. The performance of these methods highly depends on the amount of\ntraining samples and visual inspections performed by experts for error\ncorrection. However, in many medical studies, collecting voxel-level labels and\nconducting manual quality control in high-dimensional neuroimages (e.g., 3D\nMRI) are very expensive and time-consuming. Moreover, brain extraction and\nregistration are highly related tasks in neuroimaging data and should be solved\ncollectively. In this paper, we study the problem of unsupervised collective\nextraction and registration in neuroimaging data. We propose a unified\nend-to-end framework, called ERNet (Extraction-Registration Network), to\njointly optimize the extraction and registration tasks, allowing feedback\nbetween them. Specifically, we use a pair of multi-stage extraction and\nregistration modules to learn the extraction mask and transformation, where the\nextraction network improves the extraction accuracy incrementally and the\nregistration network successively warps the extracted image until it is\nwell-aligned with the target image. Experiment results on real-world datasets\nshow that our proposed method can effectively improve the performance on\nextraction and registration tasks in neuroimaging data. Our code and data can\nbe found at https://github.com/ERNetERNet/ERNet", "published": "2022-12-06T20:12:54Z", "version": 1}, {"aid": "2212.03361", "authors": ["Tsiry Mayet", "Simon Bernard", "Clement Chatelain", "Romain Herault"], "title": "Domain Translation via Latent Space Mapping", "url": "http://arxiv.org/pdf/2212.03361v1", "summary": "In this paper, we investigate the problem of multi-domain translation: given\nan element $a$ of domain $A$, we would like to generate a corresponding $b$\nsample in another domain $B$, and vice versa. Acquiring supervision in multiple\ndomains can be a tedious task, also we propose to learn this translation from\none domain to another when supervision is available as a pair $(a,b)\\sim\nA\\times B$ and leveraging possible unpaired data when only $a\\sim A$ or only\n$b\\sim B$ is available. We introduce a new unified framework called Latent\nSpace Mapping (\\model) that exploits the manifold assumption in order to learn,\nfrom each domain, a latent space. Unlike existing approaches, we propose to\nfurther regularize each latent space using available domains by learning each\ndependency between pairs of domains. We evaluate our approach in three tasks\nperforming i) synthetic dataset with image translation, ii) real-world task of\nsemantic segmentation for medical images, and iii) real-world task of facial\nlandmark detection.", "published": "2022-12-06T23:09:40Z", "version": 1}, {"aid": "2212.04195", "authors": ["Zi-Xuan Zhou", "Xi-Nian Zuo"], "title": "A Paradigm Shift in Neuroscience Driven by Big Data: State of art, Challenges, and Proof of Concept", "url": "http://arxiv.org/pdf/2212.04195v2", "summary": "A recent editorial in Nature noted that cognitive neuroscience is at a\ncrossroads where it is a thorny issue to reliably reveal brain-behavior\nassociations. This commentary sketches a big data science way out for cognitive\nneuroscience, namely population neuroscience. In terms of design, analysis, and\ninterpretations, population neuroscience research takes the design control to\nan unprecedented level, greatly expands the dimensions of the data analysis\nspace, and paves a paradigm shift for exploring mechanisms on brain-behavior\nassociations.", "published": "2022-12-08T11:23:07Z", "version": 2}, {"aid": "2212.04316", "authors": ["Francesco L\u00e4ssig", "Pau Vilimelis Aceituno", "Martino Sorbaro", "Benjamin F. Grewe"], "title": "Bio-Inspired, Task-Free Continual Learning through Activity Regularization", "url": "http://arxiv.org/pdf/2212.04316v1", "summary": "The ability to sequentially learn multiple tasks without forgetting is a key\nskill of biological brains, whereas it represents a major challenge to the\nfield of deep learning. To avoid catastrophic forgetting, various continual\nlearning (CL) approaches have been devised. However, these usually require\ndiscrete task boundaries. This requirement seems biologically implausible and\noften limits the application of CL methods in the real world where tasks are\nnot always well defined. Here, we take inspiration from neuroscience, where\nsparse, non-overlapping neuronal representations have been suggested to prevent\ncatastrophic forgetting. As in the brain, we argue that these sparse\nrepresentations should be chosen on the basis of feed forward\n(stimulus-specific) as well as top-down (context-specific) information. To\nimplement such selective sparsity, we use a bio-plausible form of hierarchical\ncredit assignment known as Deep Feedback Control (DFC) and combine it with a\nwinner-take-all sparsity mechanism. In addition to sparsity, we introduce\nlateral recurrent connections within each layer to further protect previously\nlearned representations. We evaluate the new sparse-recurrent version of DFC on\nthe split-MNIST computer vision benchmark and show that only the combination of\nsparsity and intra-layer recurrent connections improves CL performance with\nrespect to standard backpropagation. Our method achieves similar performance to\nwell-known CL methods, such as Elastic Weight Consolidation and Synaptic\nIntelligence, without requiring information about task boundaries. Overall, we\nshowcase the idea of adopting computational principles from the brain to derive\nnew, task-free learning algorithms for CL.", "published": "2022-12-08T15:14:20Z", "version": 1}, {"aid": "2212.04319", "authors": ["Seongmin Hong", "Inbum Park", "Se Young Chun"], "title": "On the Robustness of Normalizing Flows for Inverse Problems in Imaging", "url": "http://arxiv.org/pdf/2212.04319v2", "summary": "Conditional normalizing flows can generate diverse image samples for solving\ninverse problems. Most normalizing flows for inverse problems in imaging employ\nthe conditional affine coupling layer that can generate diverse images quickly.\nHowever, unintended severe artifacts are occasionally observed in the output of\nthem. In this work, we address this critical issue by investigating the origins\nof these artifacts and proposing the conditions to avoid them. First of all, we\nempirically and theoretically reveal that these problems are caused by\n\"exploding inverse\" in the conditional affine coupling layer for certain\nout-of-distribution (OOD) conditional inputs. Then, we further validated that\nthe probability of causing erroneous artifacts in pixels is highly correlated\nwith a Mahalanobis distance-based OOD score for inverse problems in imaging.\nLastly, based on our investigations, we propose a remark to avoid exploding\ninverse and then based on it, we suggest a simple remedy that substitutes the\naffine coupling layers with the modified rational quadratic spline coupling\nlayers in normalizing flows, to encourage the robustness of generated image\nsamples. Our experimental results demonstrated that our suggested methods\neffectively suppressed critical artifacts occurring in normalizing flows for\nsuper-resolution space generation and low-light image enhancement.", "published": "2022-12-08T15:18:28Z", "version": 2}, {"aid": "2212.04362", "authors": ["Jiezhang Cao", "Qin Wang", "Yongqin Xian", "Yawei Li", "Bingbing Ni", "Zhiming Pi", "Kai Zhang", "Yulun Zhang", "Radu Timofte", "Luc Van Gool"], "title": "CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution", "url": "http://arxiv.org/pdf/2212.04362v3", "summary": "Learning continuous image representations is recently gaining popularity for\nimage super-resolution (SR) because of its ability to reconstruct\nhigh-resolution images with arbitrary scales from low-resolution inputs.\nExisting methods mostly ensemble nearby features to predict the new pixel at\nany queried coordinate in the SR image. Such a local ensemble suffers from some\nlimitations: i) it has no learnable parameters and it neglects the similarity\nof the visual features; ii) it has a limited receptive field and cannot\nensemble relevant features in a large field which are important in an image. To\naddress these issues, this paper proposes a continuous implicit\nattention-in-attention network, called CiaoSR. We explicitly design an implicit\nattention network to learn the ensemble weights for the nearby local features.\nFurthermore, we embed a scale-aware attention in this implicit attention\nnetwork to exploit additional non-local information. Extensive experiments on\nbenchmark datasets demonstrate CiaoSR significantly outperforms the existing\nsingle image SR methods with the same backbone. In addition, CiaoSR also\nachieves the state-of-the-art performance on the arbitrary-scale SR task. The\neffectiveness of the method is also demonstrated on the real-world SR setting.\nMore importantly, CiaoSR can be flexibly integrated into any backbone to\nimprove the SR performance.", "published": "2022-12-08T15:57:46Z", "version": 3}, {"aid": "2212.04705", "authors": ["Youming Deng", "Xueting Li", "Sifei Liu", "Ming-Hsuan Yang"], "title": "Physics-based Indirect Illumination for Inverse Rendering", "url": "http://arxiv.org/pdf/2212.04705v2", "summary": "We present a physics-based inverse rendering method that learns the\nillumination, geometry, and materials of a scene from posed multi-view RGB\nimages. To model the illumination of a scene, existing inverse rendering works\neither completely ignore the indirect illumination or model it by coarse\napproximations, leading to sub-optimal illumination, geometry, and material\nprediction of the scene. In this work, we propose a physics-based illumination\nmodel that first locates surface points through an efficient refined sphere\ntracing algorithm, then explicitly traces the incoming indirect lights at each\nsurface point based on reflection. Then, we estimate each identified indirect\nlight through an efficient neural network. Moreover, we utilize the Leibniz's\nintegral rule to resolve non-differentiability in the proposed illumination\nmodel caused by boundary lights inspired by differentiable irradiance in\ncomputer graphics. As a result, the proposed differentiable illumination model\ncan be learned end-to-end together with geometry and materials estimation. As a\nside product, our physics-based inverse rendering model also facilitates\nflexible and realistic material editing as well as relighting. Extensive\nexperiments on synthetic and real-world datasets demonstrate that the proposed\nmethod performs favorably against existing inverse rendering methods on novel\nview synthesis and inverse rendering.", "published": "2022-12-09T07:33:49Z", "version": 2}, {"aid": "2212.04780", "authors": ["Yongkweon Jeon", "Chungman Lee", "Ho-young Kim"], "title": "Genie: Show Me the Data for Quantization", "url": "http://arxiv.org/pdf/2212.04780v3", "summary": "Zero-shot quantization is a promising approach for developing lightweight\ndeep neural networks when data is inaccessible owing to various reasons,\nincluding cost and issues related to privacy. By exploiting the learned\nparameters ($\\mu$ and $\\sigma$) of batch normalization layers in an\nFP32-pre-trained model, zero-shot quantization schemes focus on generating\nsynthetic data. Subsequently, they distill knowledge from the pre-trained model\n(teacher) to the quantized model (student) such that the quantized model can be\noptimized with the synthetic dataset. However, thus far, zero-shot quantization\nhas primarily been discussed in the context of quantization-aware training\nmethods, which require task-specific losses and long-term optimization as much\nas retraining. We thus introduce a post-training quantization scheme for\nzero-shot quantization that produces high-quality quantized networks within a\nfew hours. Furthermore, we propose a framework called Genie~that generates data\nsuited for quantization. With the data synthesized by Genie, we can produce\nrobust quantized models without real datasets, which is comparable to few-shot\nquantization. We also propose a post-training quantization algorithm to enhance\nthe performance of quantized models. By combining them, we can bridge the gap\nbetween zero-shot and few-shot quantization while significantly improving the\nquantization performance compared to that of existing approaches. In other\nwords, we can obtain a unique state-of-the-art zero-shot quantization approach.\nThe code is available at \\url{https://github.com/SamsungLabs/Genie}.", "published": "2022-12-09T11:18:40Z", "version": 3}, {"aid": "2212.06339", "authors": ["Hongteng Xu", "Minjie Cheng"], "title": "Regularized Optimal Transport Layers for Generalized Global Pooling Operations", "url": "http://arxiv.org/pdf/2212.06339v1", "summary": "Global pooling is one of the most significant operations in many machine\nlearning models and tasks, which works for information fusion and structured\ndata (like sets and graphs) representation. However, without solid mathematical\nfundamentals, its practical implementations often depend on empirical\nmechanisms and thus lead to sub-optimal, even unsatisfactory performance. In\nthis work, we develop a novel and generalized global pooling framework through\nthe lens of optimal transport. The proposed framework is interpretable from the\nperspective of expectation-maximization. Essentially, it aims at learning an\noptimal transport across sample indices and feature dimensions, making the\ncorresponding pooling operation maximize the conditional expectation of input\ndata. We demonstrate that most existing pooling methods are equivalent to\nsolving a regularized optimal transport (ROT) problem with different\nspecializations, and more sophisticated pooling operations can be implemented\nby hierarchically solving multiple ROT problems. Making the parameters of the\nROT problem learnable, we develop a family of regularized optimal transport\npooling (ROTP) layers. We implement the ROTP layers as a new kind of deep\nimplicit layer. Their model architectures correspond to different optimization\nalgorithms. We test our ROTP layers in several representative set-level machine\nlearning scenarios, including multi-instance learning (MIL), graph\nclassification, graph set representation, and image classification.\nExperimental results show that applying our ROTP layers can reduce the\ndifficulty of the design and selection of global pooling -- our ROTP layers may\neither imitate some existing global pooling methods or lead to some new pooling\nlayers fitting data better. The code is available at\n\\url{https://github.com/SDS-Lab/ROT-Pooling}.", "published": "2022-12-13T02:46:36Z", "version": 1}, {"aid": "2212.08420", "authors": ["Mert Bulent Sariyildiz", "Karteek Alahari", "Diane Larlus", "Yannis Kalantidis"], "title": "Fake it till you make it: Learning transferable representations from synthetic ImageNet clones", "url": "http://arxiv.org/pdf/2212.08420v2", "summary": "Recent image generation models such as Stable Diffusion have exhibited an\nimpressive ability to generate fairly realistic images starting from a simple\ntext prompt. Could such models render real images obsolete for training image\nprediction models? In this paper, we answer part of this provocative question\nby investigating the need for real images when training models for ImageNet\nclassification. Provided only with the class names that have been used to build\nthe dataset, we explore the ability of Stable Diffusion to generate synthetic\nclones of ImageNet and measure how useful these are for training classification\nmodels from scratch. We show that with minimal and class-agnostic prompt\nengineering, ImageNet clones are able to close a large part of the gap between\nmodels produced by synthetic images and models trained with real images, for\nthe several standard classification benchmarks that we consider in this study.\nMore importantly, we show that models trained on synthetic images exhibit\nstrong generalization properties and perform on par with models trained on real\ndata for transfer. Project page: https://europe.naverlabs.com/imagenet-sd/", "published": "2022-12-16T11:44:01Z", "version": 2}, {"aid": "2212.13912", "authors": ["Sarah Boufelja Y.", "Anthony Quinn", "Martin Corless", "Robert Shorten"], "title": "Fully Probabilistic Design for Optimal Transport", "url": "http://arxiv.org/pdf/2212.13912v1", "summary": "The goal of this paper is to introduce a new theoretical framework for\nOptimal Transport (OT), using the terminology and techniques of Fully\nProbabilistic Design (FPD). Optimal Transport is the canonical method for\ncomparing probability measures and has been successfully applied in a wide\nrange of areas (computer vision Rubner et al. [2004], computer graphics Solomon\net al. [2015], natural language processing Kusner et al. [2015], etc.).\nHowever, we argue that the current OT framework suffers from two shortcomings:\nfirst, it is hard to induce generic constraints and probabilistic knowledge in\nthe OT problem; second, the current formalism does not address the question of\nuncertainty in the marginals, lacking therefore the mechanisms to design robust\nsolutions. By viewing the OT problem as the optimal design of a probability\ndensity function with marginal constraints, we prove that OT is an instance of\nthe more generic FPD framework. In this new setting, we can furnish the OT\nframework with the necessary mechanisms for processing probabilistic\nconstraints and deriving uncertainty quantifiers, hence establishing a new\nextended framework, called FPD-OT. Our main contribution in this paper is to\nestablish the connection between OT and FPD, providing new theoretical insights\nfor both. This will lay the foundations for the application of FPD-OT in a\nsubsequent work, notably in processing more sophisticated knowledge\nconstraints, as well as in designing robust solutions in the case of uncertain\nmarginals.", "published": "2022-12-19T12:52:47Z", "version": 1}, {"aid": "2212.10772", "authors": ["Shen Zheng", "Yiling Ma", "Jinqian Pan", "Changjie Lu", "Gaurav Gupta"], "title": "Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond", "url": "http://arxiv.org/pdf/2212.10772v5", "summary": "This paper presents a comprehensive survey of low-light image and video\nenhancement, addressing two primary challenges in the field. The first\nchallenge is the prevalence of mixed over-/under-exposed images, which are not\nadequately addressed by existing methods. In response, this work introduces two\nenhanced variants of the SICE dataset: SICE_Grad and SICE_Mix, designed to\nbetter represent these complexities. The second challenge is the scarcity of\nsuitable low-light video datasets for training and testing. To address this,\nthe paper introduces the Night Wenzhou dataset, a large-scale, high-resolution\nvideo collection that features challenging fast-moving aerial scenes and\nstreetscapes with varied illuminations and degradation. This study also\nconducts an extensive analysis of key techniques and performs comparative\nexperiments using the proposed and current benchmark datasets. The survey\nconcludes by highlighting emerging applications, discussing unresolved\nchallenges, and suggesting future research directions within the LLIE\ncommunity. The datasets are available at\nhttps://github.com/ShenZheng2000/LLIE_Survey.", "published": "2022-12-21T05:08:37Z", "version": 5}, {"aid": "2212.11870", "authors": ["Blair Bilodeau", "Natasha Jaques", "Pang Wei Koh", "Been Kim"], "title": "Impossibility Theorems for Feature Attribution", "url": "http://arxiv.org/pdf/2212.11870v3", "summary": "Despite a sea of interpretability methods that can produce plausible\nexplanations, the field has also empirically seen many failure cases of such\nmethods. In light of these results, it remains unclear for practitioners how to\nuse these methods and choose between them in a principled way. In this paper,\nwe show that for moderately rich model classes (easily satisfied by neural\nnetworks), any feature attribution method that is complete and linear -- for\nexample, Integrated Gradients and SHAP -- can provably fail to improve on\nrandom guessing for inferring model behaviour. Our results apply to common\nend-tasks such as characterizing local model behaviour, identifying spurious\nfeatures, and algorithmic recourse. One takeaway from our work is the\nimportance of concretely defining end-tasks: once such an end-task is defined,\na simple and direct approach of repeated model evaluations can outperform many\nother complex feature attribution methods.", "published": "2022-12-22T17:03:57Z", "version": 3}, {"aid": "2212.12538", "authors": ["Toby St Clere Smithe"], "title": "Mathematical Foundations for a Compositional Account of the Bayesian Brain", "url": "http://arxiv.org/pdf/2212.12538v3", "summary": "This dissertation reports some first steps towards a compositional account of\nactive inference and the Bayesian brain. Specifically, we use the tools of\ncontemporary applied category theory to supply functorial semantics for\napproximate inference. To do so, we define on the `syntactic' side the new\nnotion of Bayesian lens and show that Bayesian updating composes according to\nthe compositional lens pattern. Using Bayesian lenses, and inspired by\ncompositional game theory, we define fibrations of statistical games and\nclassify various problems of statistical inference as corresponding sections:\nthe chain rule of the relative entropy is formalized as a strict section, while\nmaximum likelihood estimation and the free energy give lax sections. In the\nprocess, we introduce a new notion of `copy-composition'.\n  On the `semantic' side, we present a new formalization of general open\ndynamical systems (particularly: deterministic, stochastic, and random; and\ndiscrete- and continuous-time) as certain coalgebras of polynomial functors,\nwhich we show collect into monoidal opindexed categories (or, alternatively,\ninto algebras for multicategories of generalized polynomial functors). We use\nthese opindexed categories to define monoidal bicategories of cilia: dynamical\nsystems which control lenses, and which supply the target for our functorial\nsemantics. Accordingly, we construct functors which explain the bidirectional\ncompositional structure of predictive coding neural circuits under the free\nenergy principle, thereby giving a formal mathematical underpinning to the\nbidirectionality observed in the cortex. Along the way, we explain how to\ncompose rate-coded neural circuits using an algebra for a multicategory of\nlinear circuit diagrams, showing subsequently that this is subsumed by lenses\nand polynomial functors.", "published": "2022-12-23T18:58:17Z", "version": 3}, {"aid": "2212.12552", "authors": ["Xu Ma", "Huan Wang", "Can Qin", "Kunpeng Li", "Xingchen Zhao", "Jie Fu", "Yun Fu"], "title": "A Close Look at Spatial Modeling: From Attention to Convolution", "url": "http://arxiv.org/pdf/2212.12552v1", "summary": "Vision Transformers have shown great promise recently for many vision tasks\ndue to the insightful architecture design and attention mechanism. By\nrevisiting the self-attention responses in Transformers, we empirically observe\ntwo interesting issues. First, Vision Transformers present a queryirrelevant\nbehavior at deep layers, where the attention maps exhibit nearly consistent\ncontexts in global scope, regardless of the query patch position (also\nhead-irrelevant). Second, the attention maps are intrinsically sparse, few\ntokens dominate the attention weights; introducing the knowledge from ConvNets\nwould largely smooth the attention and enhance the performance. Motivated by\nabove observations, we generalize self-attention formulation to abstract a\nqueryirrelevant global context directly and further integrate the global\ncontext into convolutions. The resulting model, a Fully Convolutional Vision\nTransformer (i.e., FCViT), purely consists of convolutional layers and firmly\ninherits the merits of both attention mechanism and convolutions, including\ndynamic property, weight sharing, and short- and long-range feature modeling,\netc. Experimental results demonstrate the effectiveness of FCViT. With less\nthan 14M parameters, our FCViT-S12 outperforms related work ResT-Lite by 3.7%\ntop1 accuracy on ImageNet-1K. When scaling FCViT to larger models, we still\nperform better than previous state-of-the-art ConvNeXt with even fewer\nparameters. FCViT-based models also demonstrate promising transferability to\ndownstream tasks, like object detection, instance segmentation, and semantic\nsegmentation. Codes and models are made available at:\nhttps://github.com/ma-xu/FCViT.", "published": "2022-12-23T19:13:43Z", "version": 1}, {"aid": "2212.12653", "authors": ["Dan Liu", "Xi Chen", "Chen Ma", "Xue Liu"], "title": "Hyperspherical Quantization: Toward Smaller and More Accurate Models", "url": "http://arxiv.org/pdf/2212.12653v1", "summary": "Model quantization enables the deployment of deep neural networks under\nresource-constrained devices. Vector quantization aims at reducing the model\nsize by indexing model weights with full-precision embeddings, i.e., codewords,\nwhile the index needs to be restored to 32-bit during computation. Binary and\nother low-precision quantization methods can reduce the model size up to\n32$\\times$, however, at the cost of a considerable accuracy drop. In this\npaper, we propose an efficient framework for ternary quantization to produce\nsmaller and more accurate compressed models. By integrating hyperspherical\nlearning, pruning and reinitialization, our proposed Hyperspherical\nQuantization (HQ) method reduces the cosine distance between the full-precision\nand ternary weights, thus reducing the bias of the straight-through gradient\nestimator during ternary quantization. Compared with existing work at similar\ncompression levels ($\\sim$30$\\times$, $\\sim$40$\\times$), our method\nsignificantly improves the test accuracy and reduces the model size.", "published": "2022-12-24T04:42:15Z", "version": 1}, {"aid": "2212.12749", "authors": ["Linqi Zhou", "Michael Poli", "Winnie Xu", "Stefano Massaroli", "Stefano Ermon"], "title": "Deep Latent State Space Models for Time-Series Generation", "url": "http://arxiv.org/pdf/2212.12749v3", "summary": "Methods based on ordinary differential equations (ODEs) are widely used to\nbuild generative models of time-series. In addition to high computational\noverhead due to explicitly computing hidden states recurrence, existing\nODE-based models fall short in learning sequence data with sharp transitions -\ncommon in many real-world systems - due to numerical challenges during\noptimization. In this work, we propose LS4, a generative model for sequences\nwith latent variables evolving according to a state space ODE to increase\nmodeling capacity. Inspired by recent deep state space models (S4), we achieve\nspeedups by leveraging a convolutional representation of LS4 which bypasses the\nexplicit evaluation of hidden states. We show that LS4 significantly\noutperforms previous continuous-time generative models in terms of marginal\ndistribution, classification, and prediction scores on real-world datasets in\nthe Monash Forecasting Repository, and is capable of modeling highly stochastic\ndata with sharp temporal transitions. LS4 sets state-of-the-art for\ncontinuous-time latent generative models, with significant improvement of mean\nsquared error and tighter variational lower bounds on irregularly-sampled\ndatasets, while also being x100 faster than other baselines on long sequences.", "published": "2022-12-24T15:17:42Z", "version": 3}, {"aid": "2212.12795", "authors": ["Diederik Aerts", "Jonito Aerts Argu\u00eblles", "Lester Beltran", "Sandro Sozzo"], "title": "Development of a Thermodynamics of Human Cognition and Human Culture", "url": "http://arxiv.org/pdf/2212.12795v2", "summary": "Inspired by foundational studies in classical and quantum physics, and by\ninformation retrieval studies in quantum information theory, we prove that the\nnotions of 'energy' and 'entropy' can be consistently introduced in human\nlanguage and, more generally, in human culture. More explicitly, if energy is\nattributed to words according to their frequency of appearance in a text, then\nthe ensuing energy levels are distributed non-classically, namely, they obey\nBose-Einstein, rather than Maxwell-Boltzmann, statistics, as a consequence of\nthe genuinely 'quantum indistinguishability' of the words that appear in the\ntext. Secondly, the 'quantum entanglement' due to the way meaning is carried by\na text reduces the (von Neumann) entropy of the words that appear in the text,\na behaviour which cannot be explained within classical (thermodynamic or\ninformation) entropy. We claim here that this 'quantum-type behaviour is valid\nin general in human language', namely, any text is conceptually more concrete\nthan the words composing it, which entails that the entropy of the overall text\ndecreases. In addition, we provide examples taken from cognition, where\nquantization of energy appears in categorical perception, and from culture,\nwhere entities collaborate, thus 'entangle', to decrease overall entropy. We\nuse these findings to propose the development of a new 'non-classical\nthermodynamic theory' for human cognition, which also covers broad parts of\nhuman culture and its artefacts and bridges concepts with quantum physics\nentities.", "published": "2022-12-24T18:19:05Z", "version": 2}, {"aid": "2212.13038", "authors": ["Xinyi Wang", "Jianteng Peng", "Sufang Zhang", "Bihui Chen", "Yi Wang", "Yandong Guo"], "title": "A Survey of Face Recognition", "url": "http://arxiv.org/pdf/2212.13038v1", "summary": "Recent years witnessed the breakthrough of face recognition with deep\nconvolutional neural networks. Dozens of papers in the field of FR are\npublished every year. Some of them were applied in the industrial community and\nplayed an important role in human life such as device unlock, mobile payment,\nand so on. This paper provides an introduction to face recognition, including\nits history, pipeline, algorithms based on conventional manually designed\nfeatures or deep learning, mainstream training, evaluation datasets, and\nrelated applications. We have analyzed and compared state-of-the-art works as\nmany as possible, and also carefully designed a set of experiments to find the\neffect of backbone size and data distribution. This survey is a material of the\ntutorial named The Practical Face Recognition Technology in the Industrial\nWorld in the FG2023.", "published": "2022-12-26T08:36:58Z", "version": 1}, {"aid": "2212.13185", "authors": ["Tong Wei", "Yash Patel", "Alexander Shekhovtsov", "Jiri Matas", "Daniel Barath"], "title": "Generalized Differentiable RANSAC", "url": "http://arxiv.org/pdf/2212.13185v3", "summary": "We propose $\\nabla$-RANSAC, a generalized differentiable RANSAC that allows\nlearning the entire randomized robust estimation pipeline. The proposed\napproach enables the use of relaxation techniques for estimating the gradients\nin the sampling distribution, which are then propagated through a\ndifferentiable solver. The trainable quality function marginalizes over the\nscores from all the models estimated within $\\nabla$-RANSAC to guide the\nnetwork learning accurate and useful inlier probabilities or to train feature\ndetection and matching networks. Our method directly maximizes the probability\nof drawing a good hypothesis, allowing us to learn better sampling\ndistributions. We test $\\nabla$-RANSAC on various real-world scenarios on\nfundamental and essential matrix estimation, and 3D point cloud registration,\noutdoors and indoors, with handcrafted and learning-based features. It is\nsuperior to the state-of-the-art in terms of accuracy while running at a\nsimilar speed to its less accurate alternatives. The code and trained models\nare available at https://github.com/weitong8591/differentiable_ransac.", "published": "2022-12-26T15:13:13Z", "version": 3}, {"aid": "2212.13350", "authors": ["Xiaoxin He", "Bryan Hooi", "Thomas Laurent", "Adam Perold", "Yann LeCun", "Xavier Bresson"], "title": "A Generalization of ViT/MLP-Mixer to Graphs", "url": "http://arxiv.org/pdf/2212.13350v2", "summary": "Graph Neural Networks (GNNs) have shown great potential in the field of graph\nrepresentation learning. Standard GNNs define a local message-passing mechanism\nwhich propagates information over the whole graph domain by stacking multiple\nlayers. This paradigm suffers from two major limitations, over-squashing and\npoor long-range dependencies, that can be solved using global attention but\nsignificantly increases the computational cost to quadratic complexity. In this\nwork, we propose an alternative approach to overcome these structural\nlimitations by leveraging the ViT/MLP-Mixer architectures introduced in\ncomputer vision. We introduce a new class of GNNs, called Graph ViT/MLP-Mixer,\nthat holds three key properties. First, they capture long-range dependency and\nmitigate the issue of over-squashing as demonstrated on Long Range Graph\nBenchmark and TreeNeighbourMatch datasets. Second, they offer better speed and\nmemory efficiency with a complexity linear to the number of nodes and edges,\nsurpassing the related Graph Transformer and expressive GNN models. Third, they\nshow high expressivity in terms of graph isomorphism as they can distinguish at\nleast 3-WL non-isomorphic graphs. We test our architecture on 4 simulated\ndatasets and 7 real-world benchmarks, and show highly competitive results on\nall of them. The source code is available for reproducibility at:\n\\url{https://github.com/XiaoxinHe/Graph-ViT-MLPMixer}.", "published": "2022-12-27T03:27:46Z", "version": 2}, {"aid": "2301.00265", "authors": ["Yuqi Fang", "Pew-Thian Yap", "Weili Lin", "Hongtu Zhu", "Mingxia Liu"], "title": "Source-Free Unsupervised Domain Adaptation: A Survey", "url": "http://arxiv.org/pdf/2301.00265v2", "summary": "Unsupervised domain adaptation (UDA) via deep learning has attracted\nappealing attention for tackling domain-shift problems caused by distribution\ndiscrepancy across different domains. Existing UDA approaches highly depend on\nthe accessibility of source domain data, which is usually limited in practical\nscenarios due to privacy protection, data storage and transmission cost, and\ncomputation burden. To tackle this issue, many source-free unsupervised domain\nadaptation (SFUDA) methods have been proposed recently, which perform knowledge\ntransfer from a pre-trained source model to unlabeled target domain with source\ndata inaccessible. A comprehensive review of these works on SFUDA is of great\nsignificance. In this paper, we provide a timely and systematic literature\nreview of existing SFUDA approaches from a technical perspective. Specifically,\nwe categorize current SFUDA studies into two groups, i.e., white-box SFUDA and\nblack-box SFUDA, and further divide them into finer subcategories based on\ndifferent learning strategies they use. We also investigate the challenges of\nmethods in each subcategory, discuss the advantages/disadvantages of white-box\nand black-box SFUDA methods, conclude the commonly used benchmark datasets, and\nsummarize the popular techniques for improved generalizability of models\nlearned without using source data. We finally discuss several promising future\ndirections in this field.", "published": "2022-12-31T18:44:45Z", "version": 2}, {"aid": "2301.05187", "authors": ["Vishwanath Saragadam", "Daniel LeJeune", "Jasper Tan", "Guha Balakrishnan", "Ashok Veeraraghavan", "Richard G. Baraniuk"], "title": "WIRE: Wavelet Implicit Neural Representations", "url": "http://arxiv.org/pdf/2301.05187v1", "summary": "Implicit neural representations (INRs) have recently advanced numerous\nvision-related areas. INR performance depends strongly on the choice of the\nnonlinear activation function employed in its multilayer perceptron (MLP)\nnetwork. A wide range of nonlinearities have been explored, but, unfortunately,\ncurrent INRs designed to have high accuracy also suffer from poor robustness\n(to signal noise, parameter variation, etc.). Inspired by harmonic analysis, we\ndevelop a new, highly accurate and robust INR that does not exhibit this\ntradeoff. Wavelet Implicit neural REpresentation (WIRE) uses a continuous\ncomplex Gabor wavelet activation function that is well-known to be optimally\nconcentrated in space-frequency and to have excellent biases for representing\nimages. A wide range of experiments (image denoising, image inpainting,\nsuper-resolution, computed tomography reconstruction, image overfitting, and\nnovel view synthesis with neural radiance fields) demonstrate that WIRE defines\nthe new state of the art in INR accuracy, training time, and robustness.", "published": "2023-01-05T20:24:56Z", "version": 1}, {"aid": "2301.02328", "authors": ["Divyansh Garg", "Joey Hejna", "Matthieu Geist", "Stefano Ermon"], "title": "Extreme Q-Learning: MaxEnt RL without Entropy", "url": "http://arxiv.org/pdf/2301.02328v2", "summary": "Modern Deep Reinforcement Learning (RL) algorithms require estimates of the\nmaximal Q-value, which are difficult to compute in continuous domains with an\ninfinite number of possible actions. In this work, we introduce a new update\nrule for online and offline RL which directly models the maximal value using\nExtreme Value Theory (EVT), drawing inspiration from economics. By doing so, we\navoid computing Q-values using out-of-distribution actions which is often a\nsubstantial source of error. Our key insight is to introduce an objective that\ndirectly estimates the optimal soft-value functions (LogSumExp) in the maximum\nentropy RL setting without needing to sample from a policy. Using EVT, we\nderive our \\emph{Extreme Q-Learning} framework and consequently online and, for\nthe first time, offline MaxEnt Q-learning algorithms, that do not explicitly\nrequire access to a policy or its entropy. Our method obtains consistently\nstrong performance in the D4RL benchmark, outperforming prior works by\n\\emph{10+ points} on the challenging Franka Kitchen tasks while offering\nmoderate improvements over SAC and TD3 on online DM Control tasks.\nVisualizations and code can be found on our website at\nhttps://div99.github.io/XQL/.", "published": "2023-01-05T23:14:38Z", "version": 2}, {"aid": "2301.02610", "authors": ["Marco Kemmerling"], "title": "Feedback-Gated Rectified Linear Units", "url": "http://arxiv.org/pdf/2301.02610v1", "summary": "Feedback connections play a prominent role in the human brain but have not\nreceived much attention in artificial neural network research. Here, a\nbiologically inspired feedback mechanism which gates rectified linear units is\nproposed. On the MNIST dataset, autoencoders with feedback show faster\nconvergence, better performance, and more robustness to noise compared to their\ncounterparts without feedback. Some benefits, although less pronounced and less\nconsistent, can be observed when networks with feedback are applied on the\nCIFAR-10 dataset.", "published": "2023-01-06T17:14:11Z", "version": 1}, {"aid": "2301.03019", "authors": ["Patrick Kr\u00fcger", "Hanno Gottschalk"], "title": "Equivariant and Steerable Neural Networks: A review with special emphasis on the symmetric group", "url": "http://arxiv.org/pdf/2301.03019v1", "summary": "Convolutional neural networks revolutionized computer vision and natrual\nlanguage processing. Their efficiency, as compared to fully connected neural\nnetworks, has its origin in the architecture, where convolutions reflect the\ntranslation invariance in space and time in pattern or speech recognition\ntasks. Recently, Cohen and Welling have put this in the broader perspective of\ninvariance under symmetry groups, which leads to the concept of group\nequivaiant neural networks and more generally steerable neural networks. In\nthis article, we review the architecture of such networks including equivariant\nlayers and filter banks, activation with capsules and group pooling. We apply\nthis formalism to the symmetric group, for which we work out a number of\ndetails on representations and capsules that are not found in the literature.", "published": "2023-01-08T11:05:31Z", "version": 1}, {"aid": "2301.03362", "authors": ["Michael Elad", "Bahjat Kawar", "Gregory Vaksman"], "title": "Image Denoising: The Deep Learning Revolution and Beyond -- A Survey Paper --", "url": "http://arxiv.org/pdf/2301.03362v1", "summary": "Image denoising (removal of additive white Gaussian noise from an image) is\none of the oldest and most studied problems in image processing. An extensive\nwork over several decades has led to thousands of papers on this subject, and\nto many well-performing algorithms for this task. Indeed, 10 years ago, these\nachievements have led some researchers to suspect that \"Denoising is Dead\", in\nthe sense that all that can be achieved in this domain has already been\nobtained. However, this turned out to be far from the truth, with the\npenetration of deep learning (DL) into image processing. The era of DL brought\na revolution to image denoising, both by taking the lead in today's ability for\nnoise removal in images, and by broadening the scope of denoising problems\nbeing treated. Our paper starts by describing this evolution, highlighting in\nparticular the tension and synergy that exist between classical approaches and\nmodern DL-based alternatives in design of image denoisers.\n  The recent transitions in the field of image denoising go far beyond the\nability to design better denoisers. In the 2nd part of this paper we focus on\nrecently discovered abilities and prospects of image denoisers. We expose the\npossibility of using denoisers to serve other problems, such as regularizing\ngeneral inverse problems and serving as the prime engine in diffusion-based\nimage synthesis. We also unveil the idea that denoising and other inverse\nproblems might not have a unique solution as common algorithms would have us\nbelieve. Instead, we describe constructive ways to produce randomized and\ndiverse high quality results for inverse problems, all fueled by the progress\nthat DL brought to image denoising.\n  This survey paper aims to provide a broad view of the history of image\ndenoising and closely related topics. Our aim is to give a better context to\nrecent discoveries, and to the influence of DL in our domain.", "published": "2023-01-09T14:16:40Z", "version": 1}, {"aid": "2301.04333", "authors": ["Sheo Yon Jhin", "Minju Jo", "Seungji Kook", "Noseong Park", "Sungpil Woo", "Sunhwan Lim"], "title": "Learnable Path in Neural Controlled Differential Equations", "url": "http://arxiv.org/pdf/2301.04333v1", "summary": "Neural controlled differential equations (NCDEs), which are continuous\nanalogues to recurrent neural networks (RNNs), are a specialized model in\n(irregular) time-series processing. In comparison with similar models, e.g.,\nneural ordinary differential equations (NODEs), the key distinctive\ncharacteristics of NCDEs are i) the adoption of the continuous path created by\nan interpolation algorithm from each raw discrete time-series sample and ii)\nthe adoption of the Riemann--Stieltjes integral. It is the continuous path\nwhich makes NCDEs be analogues to continuous RNNs. However, NCDEs use existing\ninterpolation algorithms to create the path, which is unclear whether they can\ncreate an optimal path. To this end, we present a method to generate another\nlatent path (rather than relying on existing interpolation algorithms), which\nis identical to learning an appropriate interpolation method. We design an\nencoder-decoder module based on NCDEs and NODEs, and a special training method\nfor it. Our method shows the best performance in both time-series\nclassification and forecasting.", "published": "2023-01-11T07:05:27Z", "version": 1}, {"aid": "2301.05832", "authors": ["Tadahiro Taniguchi", "Shingo Murata", "Masahiro Suzuki", "Dimitri Ognibene", "Pablo Lanillos", "Emre Ugur", "Lorenzo Jamone", "Tomoaki Nakamura", "Alejandra Ciria", "Bruno Lara", "Giovanni Pezzulo"], "title": "World Models and Predictive Coding for Cognitive and Developmental Robotics: Frontiers and Challenges", "url": "http://arxiv.org/pdf/2301.05832v1", "summary": "Creating autonomous robots that can actively explore the environment, acquire\nknowledge and learn skills continuously is the ultimate achievement envisioned\nin cognitive and developmental robotics. Their learning processes should be\nbased on interactions with their physical and social world in the manner of\nhuman learning and cognitive development. Based on this context, in this paper,\nwe focus on the two concepts of world models and predictive coding. Recently,\nworld models have attracted renewed attention as a topic of considerable\ninterest in artificial intelligence. Cognitive systems learn world models to\nbetter predict future sensory observations and optimize their policies, i.e.,\ncontrollers. Alternatively, in neuroscience, predictive coding proposes that\nthe brain continuously predicts its inputs and adapts to model its own dynamics\nand control behavior in its environment. Both ideas may be considered as\nunderpinning the cognitive development of robots and humans capable of\ncontinual or lifelong learning. Although many studies have been conducted on\npredictive coding in cognitive robotics and neurorobotics, the relationship\nbetween world model-based approaches in AI and predictive coding in robotics\nhas rarely been discussed. Therefore, in this paper, we clarify the\ndefinitions, relationships, and status of current research on these topics, as\nwell as missing pieces of world models and predictive coding in conjunction\nwith crucially related concepts such as the free-energy principle and active\ninference in the context of cognitive and developmental robotics. Furthermore,\nwe outline the frontiers and challenges involved in world models and predictive\ncoding toward the further integration of AI and robotics, as well as the\ncreation of robots with real cognitive and developmental capabilities in the\nfuture.", "published": "2023-01-14T06:38:14Z", "version": 1}, {"aid": "2301.05993", "authors": ["Iv\u00e1n Vall\u00e9s-P\u00e9rez", "Emilio Soria-Olivas", "Marcelino Mart\u00ednez-Sober", "Antonio J. Serrano-L\u00f3pez", "Joan Vila-Franc\u00e9s", "Juan G\u00f3mez-Sanch\u00eds"], "title": "Empirical study of the modulus as activation function in computer vision applications", "url": "http://arxiv.org/pdf/2301.05993v1", "summary": "In this work we propose a new non-monotonic activation function: the modulus.\nThe majority of the reported research on nonlinearities is focused on monotonic\nfunctions. We empirically demonstrate how by using the modulus activation\nfunction on computer vision tasks the models generalize better than with other\nnonlinearities - up to a 15% accuracy increase in CIFAR100 and 4% in CIFAR10,\nrelative to the best of the benchmark activations tested. With the proposed\nactivation function the vanishing gradient and dying neurons problems\ndisappear, because the derivative of the activation function is always 1 or -1.\nThe simplicity of the proposed function and its derivative make this solution\nspecially suitable for TinyML and hardware applications.", "published": "2023-01-15T00:32:03Z", "version": 1}, {"aid": "2301.05994", "authors": ["Gangli Liu"], "title": "Min-Max-Jump distance and its applications", "url": "http://arxiv.org/pdf/2301.05994v6", "summary": "We explore three applications of Min-Max-Jump distance (MMJ distance).\nMMJ-based K-means revises K-means with MMJ distance. MMJ-based Silhouette\ncoefficient revises Silhouette coefficient with MMJ distance. We also tested\nthe Clustering with Neural Network and Index (CNNI) model with MMJ-based\nSilhouette coefficient. In the last application, we tested using Min-Max-Jump\ndistance for predicting labels of new points, after a clustering analysis of\ndata. Result shows Min-Max-Jump distance achieves good performances in all the\nthree proposed applications. In addition, we devise several algorithms for\ncalculating or estimating the distance.", "published": "2023-01-15T00:55:40Z", "version": 6}, {"aid": "2301.06030", "authors": ["Zhenglong Zhou", "Geshi Yeung", "Anna C. Schapiro"], "title": "Self-recovery of memory via generative replay", "url": "http://arxiv.org/pdf/2301.06030v1", "summary": "A remarkable capacity of the brain is its ability to autonomously reorganize\nmemories during offline periods. Memory replay, a mechanism hypothesized to\nunderlie biological offline learning, has inspired offline methods for reducing\nforgetting in artificial neural networks in continual learning settings. A\nmemory-efficient and neurally-plausible method is generative replay, which\nachieves state of the art performance on continual learning benchmarks.\nHowever, unlike the brain, standard generative replay does not self-reorganize\nmemories when trained offline on its own replay samples. We propose a novel\narchitecture that augments generative replay with an adaptive, brain-like\ncapacity to autonomously recover memories. We demonstrate this capacity of the\narchitecture across several continual learning tasks and environments.", "published": "2023-01-15T07:28:14Z", "version": 1}, {"aid": "2301.06158", "authors": ["T. M. Kamsma", "W. Q. Boon", "T. ter Rele", "C. Spitoni", "R. van Roij"], "title": "Iontronic Neuromorphic Signaling with Conical Microfluidic Memristors", "url": "http://arxiv.org/pdf/2301.06158v2", "summary": "Experiments have shown that the conductance of conical channels, filled with\nan aqueous electrolyte, can strongly depend on the history of the applied\nvoltage. These channels hence have a memory and are promising elements in\nbrain-inspired (iontronic) circuits. We show here that the memory of such\nchannels stems from transient concentration polarization over the ionic\ndiffusion time. We derive an analytic approximation for these dynamics which\nshows good agreement with full finite-element calculations. Using our analytic\napproximation, we propose an experimentally realisable Hodgkin-Huxley iontronic\ncircuit where micrometer cones take on the role of sodium and potassium\nchannels. Our proposed circuit exhibits key features of neuronal communication\nsuch as all-or-none action potentials upon a pulse stimulus and a spike train\nupon a sustained stimulus.", "published": "2023-01-15T18:46:16Z", "version": 2}, {"aid": "2301.07016", "authors": ["V. A. Aksyuk"], "title": "Consciousness is entailed by compositional learning of new causal structures in deep predictive processing systems", "url": "http://arxiv.org/pdf/2301.07016v3", "summary": "Machine learning algorithms have achieved superhuman performance in specific\ncomplex domains. However, learning online from few examples and compositional\nlearning for efficient generalization across domains remain elusive. In humans,\nsuch learning includes specific declarative memory formation and is closely\nassociated with consciousness. Predictive processing has been advanced as a\nprincipled Bayesian framework for understanding the cortex as implementing deep\ngenerative models for both sensory perception and action control. However,\npredictive processing offers little direct insight into fast compositional\nlearning or of the separation between conscious and unconscious contents. Here,\npropose that access consciousness arises as a consequence of a particular\nlearning mechanism operating within a predictive processing system. We extend\npredictive processing by adding online, single-example new structure learning\nvia hierarchical binding of unpredicted inferences. This system learns new\ncauses by quickly connecting together novel combinations of perceptions, which\nmanifests as working memories that can become short- and long-term declarative\nmemories retrievable by associative recall. The contents of such bound\nrepresentations are unified yet differentiated, can be maintained by selective\nattention and are globally available. The proposed learning process explains\ncontrast and masking manipulations, postdictive perceptual integration, and\nother paradigm cases of consciousness research. 'Phenomenal conscious\nexperience' is how the learning system transparently models its own\nfunctioning, giving rise to perceptual illusions underlying the meta-problem of\nconsciousness. Our proposal naturally unifies the feature binding, recurrent\nprocessing, predictive processing, and global workspace theories of\nconsciousness.", "published": "2023-01-17T17:06:48Z", "version": 3}, {"aid": "2301.07581", "authors": ["Jan Flusser", "Matej Lebl", "Matteo Pedone", "Filip Sroubek", "Jitka Kostkova"], "title": "Blur Invariants for Image Recognition", "url": "http://arxiv.org/pdf/2301.07581v1", "summary": "Blur is an image degradation that is difficult to remove. Invariants with\nrespect to blur offer an alternative way of a~description and recognition of\nblurred images without any deblurring. In this paper, we present an original\nunified theory of blur invariants. Unlike all previous attempts, the new theory\ndoes not require any prior knowledge of the blur type. The invariants are\nconstructed in the Fourier domain by means of orthogonal projection operators\nand moment expansion is used for efficient and stable computation. It is shown\nthat all blur invariants published earlier are just particular cases of this\napproach. Experimental comparison to concurrent approaches shows the advantages\nof the proposed theory.", "published": "2023-01-18T14:58:32Z", "version": 1}, {"aid": "2301.07733", "authors": ["Aaron Defazio", "Konstantin Mishchenko"], "title": "Learning-Rate-Free Learning by D-Adaptation", "url": "http://arxiv.org/pdf/2301.07733v5", "summary": "D-Adaptation is an approach to automatically setting the learning rate which\nasymptotically achieves the optimal rate of convergence for minimizing convex\nLipschitz functions, with no back-tracking or line searches, and no additional\nfunction value or gradient evaluations per step. Our approach is the first\nhyper-parameter free method for this class without additional multiplicative\nlog factors in the convergence rate. We present extensive experiments for SGD\nand Adam variants of our method, where the method automatically matches\nhand-tuned learning rates across more than a dozen diverse machine learning\nproblems, including large-scale vision and language problems.\n  An open-source implementation is available.", "published": "2023-01-18T19:00:50Z", "version": 5}, {"aid": "2301.08113", "authors": ["Christoph Dalitz"], "title": "Soft Thresholding for Visual Image Enhancement", "url": "http://arxiv.org/pdf/2301.08113v1", "summary": "Thresholding converts a greyscale image into a binary image, and is thus\noften a necessary segmentation step in image processing. For a human viewer\nhowever, thresholding usually has a negative impact on the legibility of\ndocument images. This report describes a simple method for \"smearing out\" the\nthreshold and transforming the greyscale image into a different greyscale\nimage. The method is similar to fuzzy thresholding, but is discussed here in\nthe simpler context of greyscale transformations and, unlike fuzzy\nthresholding, it is independent from the method for finding the threshold. A\nsimple formula is presented for automatically determining the width of the\nthreshold spread. The method can be used, e.g., for enhancing images for the\npresentation in online facsimile repositories.", "published": "2023-01-19T15:05:13Z", "version": 1}, {"aid": "2301.08187", "authors": ["Fabian Falck", "Christopher Williams", "Dominic Danks", "George Deligiannidis", "Christopher Yau", "Chris Holmes", "Arnaud Doucet", "Matthew Willetts"], "title": "A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs", "url": "http://arxiv.org/pdf/2301.08187v1", "summary": "U-Net architectures are ubiquitous in state-of-the-art deep learning, however\ntheir regularisation properties and relationship to wavelets are understudied.\nIn this paper, we formulate a multi-resolution framework which identifies\nU-Nets as finite-dimensional truncations of models on an infinite-dimensional\nfunction space. We provide theoretical results which prove that average pooling\ncorresponds to projection within the space of square-integrable functions and\nshow that U-Nets with average pooling implicitly learn a Haar wavelet basis\nrepresentation of the data. We then leverage our framework to identify\nstate-of-the-art hierarchical VAEs (HVAEs), which have a U-Net architecture, as\na type of two-step forward Euler discretisation of multi-resolution diffusion\nprocesses which flow from a point mass, introducing sampling instabilities. We\nalso demonstrate that HVAEs learn a representation of time which allows for\nimproved parameter efficiency through weight-sharing. We use this observation\nto achieve state-of-the-art HVAE performance with half the number of parameters\nof existing models, exploiting the properties of our continuous-time\nformulation.", "published": "2023-01-19T17:33:48Z", "version": 1}, {"aid": "2301.08210", "authors": ["Petar Veli\u010dkovi\u0107"], "title": "Everything is Connected: Graph Neural Networks", "url": "http://arxiv.org/pdf/2301.08210v1", "summary": "In many ways, graphs are the main modality of data we receive from nature.\nThis is due to the fact that most of the patterns we see, both in natural and\nartificial systems, are elegantly representable using the language of graph\nstructures. Prominent examples include molecules (represented as graphs of\natoms and bonds), social networks and transportation networks. This potential\nhas already been seen by key scientific and industrial groups, with\nalready-impacted application areas including traffic forecasting, drug\ndiscovery, social network analysis and recommender systems. Further, some of\nthe most successful domains of application for machine learning in previous\nyears -- images, text and speech processing -- can be seen as special cases of\ngraph representation learning, and consequently there has been significant\nexchange of information between these areas. The main aim of this short survey\nis to enable the reader to assimilate the key concepts in the area, and\nposition graph representation learning in a proper context with related fields.", "published": "2023-01-19T18:09:43Z", "version": 1}, {"aid": "2301.08284", "authors": ["Lukas Gonon", "Robin Graeber", "Arnulf Jentzen"], "title": "The necessity of depth for artificial neural networks to approximate certain classes of smooth and bounded functions without the curse of dimensionality", "url": "http://arxiv.org/pdf/2301.08284v1", "summary": "In this article we study high-dimensional approximation capacities of shallow\nand deep artificial neural networks (ANNs) with the rectified linear unit\n(ReLU) activation. In particular, it is a key contribution of this work to\nreveal that for all $a,b\\in\\mathbb{R}$ with $b-a\\geq 7$ we have that the\nfunctions $[a,b]^d\\ni x=(x_1,\\dots,x_d)\\mapsto\\prod_{i=1}^d x_i\\in\\mathbb{R}$\nfor $d\\in\\mathbb{N}$ as well as the functions $[a,b]^d\\ni x =(x_1,\\dots,\nx_d)\\mapsto\\sin(\\prod_{i=1}^d x_i) \\in \\mathbb{R} $ for $ d \\in \\mathbb{N} $\ncan neither be approximated without the curse of dimensionality by means of\nshallow ANNs nor insufficiently deep ANNs with ReLU activation but can be\napproximated without the curse of dimensionality by sufficiently deep ANNs with\nReLU activation. We show that the product functions and the sine of the product\nfunctions are polynomially tractable approximation problems among the\napproximating class of deep ReLU ANNs with the number of hidden layers being\nallowed to grow in the dimension $ d \\in \\mathbb{N} $. We establish the above\noutlined statements not only for the product functions and the sine of the\nproduct functions but also for other classes of target functions, in\nparticular, for classes of uniformly globally bounded $ C^{ \\infty }\n$-functions with compact support on any $[a,b]^d$ with $a\\in\\mathbb{R}$,\n$b\\in(a,\\infty)$. Roughly speaking, in this work we lay open that simple\napproximation problems such as approximating the sine or cosine of products\ncannot be solved in standard implementation frameworks by shallow or\ninsufficiently deep ANNs with ReLU activation in polynomial time, but can be\napproximated by sufficiently deep ReLU ANNs with the number of parameters\ngrowing at most polynomially.", "published": "2023-01-19T19:52:41Z", "version": 1}, {"aid": "2301.08727", "authors": ["Colin White", "Mahmoud Safari", "Rhea Sukthanker", "Binxin Ru", "Thomas Elsken", "Arber Zela", "Debadeepta Dey", "Frank Hutter"], "title": "Neural Architecture Search: Insights from 1000 Papers", "url": "http://arxiv.org/pdf/2301.08727v2", "summary": "In the past decade, advances in deep learning have resulted in breakthroughs\nin a variety of areas, including computer vision, natural language\nunderstanding, speech recognition, and reinforcement learning. Specialized,\nhigh-performing neural architectures are crucial to the success of deep\nlearning in these areas. Neural architecture search (NAS), the process of\nautomating the design of neural architectures for a given task, is an\ninevitable next step in automating machine learning and has already outpaced\nthe best human-designed architectures on many tasks. In the past few years,\nresearch in NAS has been progressing rapidly, with over 1000 papers released\nsince 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized\nand comprehensive guide to neural architecture search. We give a taxonomy of\nsearch spaces, algorithms, and speedup techniques, and we discuss resources\nsuch as benchmarks, best practices, other surveys, and open-source libraries.", "published": "2023-01-20T18:47:24Z", "version": 2}, {"aid": "2301.08846", "authors": ["Xu Tan", "Tao Qin", "Jiang Bian", "Tie-Yan Liu", "Yoshua Bengio"], "title": "Regeneration Learning: A Learning Paradigm for Data Generation", "url": "http://arxiv.org/pdf/2301.08846v1", "summary": "Machine learning methods for conditional data generation usually build a\nmapping from source conditional data X to target data Y. The target Y (e.g.,\ntext, speech, music, image, video) is usually high-dimensional and complex, and\ncontains information that does not exist in source data, which hinders\neffective and efficient learning on the source-target mapping. In this paper,\nwe present a learning paradigm called regeneration learning for data\ngeneration, which first generates Y' (an abstraction/representation of Y) from\nX and then generates Y from Y'. During training, Y' is obtained from Y through\neither handcrafted rules or self-supervised learning and is used to learn\nX-->Y' and Y'-->Y. Regeneration learning extends the concept of representation\nlearning to data generation tasks, and can be regarded as a counterpart of\ntraditional representation learning, since 1) regeneration learning handles the\nabstraction (Y') of the target data Y for data generation while traditional\nrepresentation learning handles the abstraction (X') of source data X for data\nunderstanding; 2) both the processes of Y'-->Y in regeneration learning and\nX-->X' in representation learning can be learned in a self-supervised way\n(e.g., pre-training); 3) both the mappings from X to Y' in regeneration\nlearning and from X' to Y in representation learning are simpler than the\ndirect mapping from X to Y. We show that regeneration learning can be a\nwidely-used paradigm for data generation (e.g., text generation, speech\nrecognition, speech synthesis, music composition, image generation, and video\ngeneration) and can provide valuable insights into developing data generation\nmethods.", "published": "2023-01-21T01:33:34Z", "version": 1}, {"aid": "2301.09299", "authors": ["Yinheng Li", "Han Ding", "Shaofei Wang"], "title": "Self-Supervised Image Representation Learning: Transcending Masking with Paired Image Overlay", "url": "http://arxiv.org/pdf/2301.09299v1", "summary": "Self-supervised learning has become a popular approach in recent years for\nits ability to learn meaningful representations without the need for data\nannotation. This paper proposes a novel image augmentation technique,\noverlaying images, which has not been widely applied in self-supervised\nlearning. This method is designed to provide better guidance for the model to\nunderstand underlying information, resulting in more useful representations.\nThe proposed method is evaluated using contrastive learning, a widely used\nself-supervised learning method that has shown solid performance in downstream\ntasks. The results demonstrate the effectiveness of the proposed augmentation\ntechnique in improving the performance of self-supervised models.", "published": "2023-01-23T07:00:04Z", "version": 1}, {"aid": "2301.09820", "authors": ["Zihao Fu", "Anthony Man-Cho So", "Nigel Collier"], "title": "A Stability Analysis of Fine-Tuning a Pre-Trained Model", "url": "http://arxiv.org/pdf/2301.09820v2", "summary": "Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,\netc.) has proven to be one of the most promising paradigms in recent NLP\nresearch. However, numerous recent works indicate that fine-tuning suffers from\nthe instability problem, i.e., tuning the same model under the same setting\nresults in significantly different performance. Many recent works have proposed\ndifferent methods to solve this problem, but there is no theoretical\nunderstanding of why and how these methods work. In this paper, we propose a\nnovel theoretical stability analysis of fine-tuning that focuses on two\ncommonly used settings, namely, full fine-tuning and head tuning. We define the\nstability under each setting and prove the corresponding stability bounds. The\ntheoretical bounds explain why and how several existing methods can stabilize\nthe fine-tuning procedure. In addition to being able to explain most of the\nobserved empirical discoveries, our proposed theoretical analysis framework can\nalso help in the design of effective and provable methods. Based on our theory,\nwe propose three novel strategies to stabilize the fine-tuning procedure,\nnamely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self\nUnsupervised Re-Training (SURT). We extensively evaluate our proposed\napproaches on 11 widely used real-world benchmark datasets, as well as hundreds\nof synthetic classification datasets. The experiment results show that our\nproposed methods significantly stabilize the fine-tuning procedure and also\ncorroborate our theoretical analysis.", "published": "2023-01-24T05:11:17Z", "version": 2}, {"aid": "2301.09858", "authors": ["Edouard Yvinec", "Arnaud Dapogny", "Matthieu Cord", "Kevin Bailly"], "title": "PowerQuant: Automorphism Search for Non-Uniform Quantization", "url": "http://arxiv.org/pdf/2301.09858v1", "summary": "Deep neural networks (DNNs) are nowadays ubiquitous in many domains such as\ncomputer vision. However, due to their high latency, the deployment of DNNs\nhinges on the development of compression techniques such as quantization which\nconsists in lowering the number of bits used to encode the weights and\nactivations. Growing concerns for privacy and security have motivated the\ndevelopment of data-free techniques, at the expanse of accuracy. In this paper,\nwe identity the uniformity of the quantization operator as a limitation of\nexisting approaches, and propose a data-free non-uniform method. More\nspecifically, we argue that to be readily usable without dedicated hardware and\nimplementation, non-uniform quantization shall not change the nature of the\nmathematical operations performed by the DNN. This leads to search among the\ncontinuous automorphisms of $(\\mathbb{R}_+^*,\\times)$, which boils down to the\npower functions defined by their exponent. To find this parameter, we propose\nto optimize the reconstruction error of each layer: in particular, we show that\nthis procedure is locally convex and admits a unique solution. At inference\ntime, we show that our approach, dubbed PowerQuant, only require simple\nmodifications in the quantized DNN activation functions. As such, with only\nnegligible overhead, it significantly outperforms existing methods in a variety\nof configurations.", "published": "2023-01-24T08:30:14Z", "version": 1}, {"aid": "2301.09939", "authors": ["T. R. F. Phillips", "C. E. Heaney", "C. Boyang", "A. G. Buchan", "C. C. Pain"], "title": "Solving the Discretised Neutron Diffusion Equations using Neural Networks", "url": "http://arxiv.org/pdf/2301.09939v1", "summary": "This paper presents a new approach which uses the tools within Artificial\nIntelligence (AI) software libraries as an alternative way of solving partial\ndifferential equations (PDEs) that have been discretised using standard\nnumerical methods. In particular, we describe how to represent numerical\ndiscretisations arising from the finite volume and finite element methods by\npre-determining the weights of convolutional layers within a neural network. As\nthe weights are defined by the discretisation scheme, no training of the\nnetwork is required and the solutions obtained are identical (accounting for\nsolver tolerances) to those obtained with standard codes often written in\nFortran or C++. We also explain how to implement the Jacobi method and a\nmultigrid solver using the functions available in AI libraries. For the latter,\nwe use a U-Net architecture which is able to represent a sawtooth multigrid\nmethod. A benefit of using AI libraries in this way is that one can exploit\ntheir power and their built-in technologies. For example, their executions are\nalready optimised for different computer architectures, whether it be CPUs,\nGPUs or new-generation AI processors. In this article, we apply the proposed\napproach to eigenvalue problems in reactor physics where neutron transport is\ndescribed by diffusion theory. For a fuel assembly benchmark, we demonstrate\nthat the solution obtained from our new approach is the same (accounting for\nsolver tolerances) as that obtained from the same discretisation coded in a\nstandard way using Fortran. We then proceed to solve a reactor core benchmark\nusing the new approach.", "published": "2023-01-24T11:46:09Z", "version": 1}, {"aid": "2301.10002", "authors": ["Ilias Rentzeperis", "Luca Calatroni", "Laurent Perrinet", "Dario Prandi"], "title": "Beyond $\\ell_1$ sparse coding in V1", "url": "http://arxiv.org/pdf/2301.10002v2", "summary": "Growing evidence indicates that only a sparse subset from a pool of sensory\nneurons is active for the encoding of visual stimuli at any instant in time.\nTraditionally, to replicate such biological sparsity, generative models have\nbeen using the $\\ell_1$ norm as a penalty due to its convexity, which makes it\namenable to fast and simple algorithmic solvers. In this work, we use\nbiological vision as a test-bed and show that the soft thresholding operation\nassociated to the use of the $\\ell_1$ norm is highly suboptimal compared to\nother functions suited to approximating $\\ell_q$ with $0 \\leq q < 1 $\n(including recently proposed Continuous Exact relaxations), both in terms of\nperformance and in the production of features that are akin to signatures of\nthe primary visual cortex. We show that $\\ell_1$ sparsity produces a denser\ncode or employs a pool with more neurons, i.e. has a higher degree of\novercompleteness, in order to maintain the same reconstruction error as the\nother methods considered. For all the penalty functions tested, a subset of the\nneurons develop orientation selectivity similarly to V1 neurons. When their\ncode is sparse enough, the methods also develop receptive fields with varying\nfunctionalities, another signature of V1. Compared to other methods, soft\nthresholding achieves this level of sparsity at the expense of much degraded\nreconstruction performance, that more likely than not is not acceptable in\nbiological vision. Our results indicate that V1 uses a sparsity inducing\nregularization that is closer to the $\\ell_0$ pseudo-norm rather than to the\n$\\ell_1$ norm.", "published": "2023-01-24T13:53:07Z", "version": 2}, {"aid": "2301.10297", "authors": ["Sebastian Michelmann", "Manoj Kumar", "Kenneth A. Norman", "Mariya Toneva"], "title": "Large language models can segment narrative events similarly to humans", "url": "http://arxiv.org/pdf/2301.10297v1", "summary": "Humans perceive discrete events such as \"restaurant visits\" and \"train rides\"\nin their continuous experience. One important prerequisite for studying human\nevent perception is the ability of researchers to quantify when one event ends\nand another begins. Typically, this information is derived by aggregating\nbehavioral annotations from several observers. Here we present an alternative\ncomputational approach where event boundaries are derived using a large\nlanguage model, GPT-3, instead of using human annotations. We demonstrate that\nGPT-3 can segment continuous narrative text into events. GPT-3-annotated events\nare significantly correlated with human event annotations. Furthermore, these\nGPT-derived annotations achieve a good approximation of the \"consensus\"\nsolution (obtained by averaging across human annotations); the boundaries\nidentified by GPT-3 are closer to the consensus, on average, than boundaries\nidentified by individual human annotators. This finding suggests that GPT-3\nprovides a feasible solution for automated event annotations, and it\ndemonstrates a further parallel between human cognition and prediction in large\nlanguage models. In the future, GPT-3 may thereby help to elucidate the\nprinciples underlying human event perception.", "published": "2023-01-24T20:34:37Z", "version": 1}, {"aid": "2012.03436", "authors": ["Jicong Fan", "Lijun Ding", "Chengrun Yang", "Zhao Zhang", "Madeleine Udell"], "title": "Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank Tensor Completion and Tensor Robust Principal Component Analysis", "url": "http://arxiv.org/pdf/2012.03436v5", "summary": "The nuclear norm and Schatten-$p$ quasi-norm are popular rank proxies in\nlow-rank matrix recovery. However, computing the nuclear norm or Schatten-$p$\nquasi-norm of a tensor is hard in both theory and practice, hindering their\napplication to low-rank tensor completion (LRTC) and tensor robust principal\ncomponent analysis (TRPCA). In this paper, we propose a new class of tensor\nrank regularizers based on the Euclidean norms of the CP component vectors of a\ntensor and show that these regularizers are monotonic transformations of tensor\nSchatten-$p$ quasi-norm. This connection enables us to minimize the\nSchatten-$p$ quasi-norm in LRTC and TRPCA implicitly via the component vectors.\nThe method scales to big tensors and provides an arbitrarily sharper rank proxy\nfor low-rank tensor recovery compared to the nuclear norm. On the other hand,\nwe study the generalization abilities of LRTC with the Schatten-$p$ quasi-norm\nregularizer and LRTC with the proposed regularizers. The theorems show that a\nrelatively sharper regularizer leads to a tighter error bound, which is\nconsistent with our numerical results. Particularly, we prove that for LRTC\nwith Schatten-$p$ quasi-norm regularizer on $d$-order tensors, $p=1/d$ is\nalways better than any $p>1/d$ in terms of the generalization ability. We also\nprovide a recovery error bound to verify the usefulness of small $p$ in the\nSchatten-$p$ quasi-norm for TRPCA. Numerical results on synthetic data and real\ndata demonstrate the effectiveness of the regularization methods and theorems.", "published": "2020-12-07T03:34:03Z", "version": 5}, {"aid": "2012.04112", "authors": ["Evgeny Hershkovitch Neiterman", "Michael Klyuchka", "Gil Ben-Artzi"], "title": "Adaptive Enhancement of Extreme Low-Light Images", "url": "http://arxiv.org/pdf/2012.04112v3", "summary": "Existing methods for enhancing dark images captured in a very low-light\nenvironment assume that the intensity level of the optimal output image is\nknown and already included in the training set. However, this assumption often\ndoes not hold, leading to output images that contain visual imperfections such\nas dark regions or low contrast. To facilitate the training and evaluation of\nadaptive models that can overcome this limitation, we have created a dataset of\n1500 raw images taken in both indoor and outdoor low-light conditions. Based on\nour dataset, we introduce a deep learning model capable of enhancing input\nimages with a wide range of intensity levels at runtime, including ones that\nare not seen during training. Our experimental results demonstrate that our\nproposed dataset combined with our model can consistently and effectively\nenhance images across a wide range of diverse and challenging scenarios.", "published": "2020-12-07T23:31:59Z", "version": 3}, {"aid": "2103.13860", "authors": ["Domenico Maisto", "Francesco Gregoretti", "Karl Friston", "Giovanni Pezzulo"], "title": "Active Inference Tree Search in Large POMDPs", "url": "http://arxiv.org/pdf/2103.13860v6", "summary": "The ability to plan ahead efficiently is key for both living organisms and\nartificial systems. Model-based planning and prospection are widely studied in\ncognitive neuroscience and artificial intelligence (AI), but from different\nperspectives--and with different desiderata in mind (biological realism versus\nscalability) that are difficult to reconcile. Here, we introduce a novel method\nto plan in POMDPs--Active Inference Tree Search (AcT)--that combines the\nnormative character and biological realism of a leading planning theory in\nneuroscience (Active Inference) and the scalability of tree search methods in\nAI. This unification enhances both approaches. On the one hand, tree searches\nenable the biologically grounded, first principle method of active inference to\nbe applied to large-scale problems. On the other hand, active inference\nprovides a principled solution to the exploration-exploitation dilemma, which\nis often addressed heuristically in tree search methods. Our simulations show\nthat AcT successfully navigates binary trees that are challenging for\nsampling-based methods, problems that require adaptive exploration, and the\nlarge POMDP problem 'RockSample'--in which AcT reproduces state-of-the-art\nPOMDP solutions. Furthermore, we illustrate how AcT can be used to simulate\nneurophysiological responses (e.g., in the hippocampus and prefrontal cortex)\nof humans and other animals that solve large planning problems. These numerical\nanalyses show that Active Tree Search is a principled realisation of\nneuroscientific and AI planning theories, which offer both biological realism\nand scalability.", "published": "2021-03-25T14:17:09Z", "version": 6}, {"aid": "2106.07865", "authors": ["Brandon R. Munn", "Eli J. M\u00fcller", "James M. Shine"], "title": "Noradrenergic neuromodulation of nonlinear bursting neurons controls critical dynamics", "url": "http://arxiv.org/pdf/2106.07865v3", "summary": "In order to remain adaptable to a dynamic environment, neural activity must\nbe simultaneously both sensitive and stable. To solve this problem, the brain\nhas been hypothesised to sit near a critical boundary. Yet, precisely how\ncriticality and these opposing information processing modes are implemented in\nthe brain remains elusive. A potential solution to this problem involves\nmodulating intrinsically nonlinear neurons within the cerebral cortex with\nneuromodulatory neurotransmitters such as noradrenaline, a highly-conserved\nchemical released from the pontine locus coeruleus. Here we confirm that\nneuronal spiking in mice is poised close to the critical point of a branching\nprocess and that time-varying signatures of criticality fluctuate with\nneuromodulatory tone, as assessed by dynamic alterations in pupil diameter. We\nexplore these results theoretically by creating a dual-compartment model of\nnon-linear pyramidal neurons - capable of both regular spike and bursting modes\n- that replicates our main empirical findings of slightly subcritical dynamics.\nWe then probe our model at a resolution impossible in vivo to demonstrate that\nnoradrenaline differentially alters spiking- and bursting-criticality to\nfacilitate sensitive and stable dynamics following an inverted-U profile that\npeaks at intermediate noradrenergic tone. Finally, we demonstrate that this\nintermediate noradrenergic regime displays burst avalanches with power-law size\nand duration distributions and scaling relationship belonging to the\nuniversality class of self-organized criticality. Our results confirm that the\nnoradrenergic ascending arousal system acts as a control parameter for emergent\ncritical dynamics in the brain. This methodology could be extended to explore\nother neuromodulators as control parameters of the brain.", "published": "2021-06-15T03:59:16Z", "version": 3}, {"aid": "2106.11396", "authors": ["Feihu Huang", "Junyi Li", "Shangqian Gao"], "title": "BiAdam: Fast Adaptive Bilevel Optimization Methods", "url": "http://arxiv.org/pdf/2106.11396v4", "summary": "Bilevel optimization recently has attracted increased interest in machine\nlearning due to its many applications such as hyper-parameter optimization and\nmeta learning. Although many bilevel methods recently have been proposed, these\nmethods do not consider using adaptive learning rates. It is well known that\nadaptive learning rates can accelerate optimization algorithms. To fill this\ngap, in the paper, we propose a novel fast adaptive bilevel framework to solve\nstochastic bilevel optimization problems that the outer problem is possibly\nnonconvex and the inner problem is strongly convex. Our framework uses unified\nadaptive matrices including many types of adaptive learning rates, and can\nflexibly use the momentum and variance reduced techniques. In particular, we\nprovide a useful convergence analysis framework for the bilevel optimization.\nSpecifically, we propose a fast single-loop adaptive bilevel optimization\n(BiAdam) algorithm, which achieves a sample complexity of\n$\\tilde{O}(\\epsilon^{-4})$ for finding an $\\epsilon$-stationary solution.\nMeanwhile, we propose an accelerated version of BiAdam algorithm (VR-BiAdam),\nwhich reaches the best known sample complexity of $\\tilde{O}(\\epsilon^{-3})$.\nTo the best of our knowledge, we first study the adaptive bilevel optimization\nmethods with adaptive learning rates. Experimental results on data\nhyper-cleaning and hyper-representation learning tasks demonstrate the\nefficiency of our algorithms.", "published": "2021-06-21T20:16:40Z", "version": 4}, {"aid": "2107.00627", "authors": ["Junqing Huang", "Haihui Wang", "Xuechao Wang", "Michael Ruzhansky"], "title": "Semi-Sparsity for Smoothing Filters", "url": "http://arxiv.org/pdf/2107.00627v3", "summary": "In this paper, we propose an interesting semi-sparsity smoothing algorithm\nbased on a novel sparsity-inducing optimization framework. This method is\nderived from the multiple observations that semi-sparsity prior knowledge is\nmore universally applicable, especially in areas where sparsity is not fully\nadmitted, such as polynomial-smoothing surfaces. We illustrate that this\nsemi-sparsity can be identified into a generalized $L_0$-norm minimization in\nhigher-order gradient domains, thereby giving rise to a new \"feature-aware\"\nfiltering method with a powerful simultaneous-fitting ability in both sparse\nfeatures (singularities and sharpening edges) and non-sparse regions\n(polynomial-smoothing surfaces). Notice that a direct solver is always\nunavailable due to the non-convexity and combinatorial nature of $L_0$-norm\nminimization. Instead, we solve the model based on an efficient half-quadratic\nsplitting minimization with fast Fourier transforms (FFTs) for acceleration. We\nfinally demonstrate its versatility and many benefits to a series of\nsignal/image processing and computer vision applications.", "published": "2021-07-01T17:31:42Z", "version": 3}, {"aid": "2109.01594", "authors": ["Serkan Kiranyaz", "Junaid Malik", "Mehmet Yamac", "Mert Duman", "Ilke Adalioglu", "Esin Guldogan", "Turker Ince", "Moncef Gabbouj"], "title": "Super Neurons", "url": "http://arxiv.org/pdf/2109.01594v2", "summary": "Self-Organized Operational Neural Networks (Self-ONNs) have recently been\nproposed as new-generation neural network models with nonlinear learning units,\ni.e., the generative neurons that yield an elegant level of diversity; however,\nlike its predecessor, conventional Convolutional Neural Networks (CNNs), they\nstill have a common drawback: localized (fixed) kernel operations. This\nseverely limits the receptive field and information flow between layers and\nthus brings the necessity for deep and complex models. It is highly desired to\nimprove the receptive field size without increasing the kernel dimensions. This\nrequires a significant upgrade over the generative neurons to achieve the\nnon-localized kernel operations for each connection between consecutive layers.\nIn this article, we present superior (generative) neuron models (or super\nneurons in short) that allow random or learnable kernel shifts and thus can\nincrease the receptive field size of each connection. The kernel localization\nprocess varies among the two super-neuron models. The first model assumes\nrandomly localized kernels within a range and the second one learns (optimizes)\nthe kernel locations during training. An extensive set of comparative\nevaluations against conventional and deformable convolutional, along with the\ngenerative neurons demonstrates that super neurons can empower Self-ONNs to\nachieve a superior learning and generalization capability with a minimal\ncomputational complexity burden.", "published": "2021-08-03T16:17:45Z", "version": 2}, {"aid": "2110.06804", "authors": ["Chunyu Yuan", "Sos S. Agaian"], "title": "A comprehensive review of Binary Neural Network", "url": "http://arxiv.org/pdf/2110.06804v4", "summary": "Deep learning (DL) has recently changed the development of intelligent\nsystems and is widely adopted in many real-life applications. Despite their\nvarious benefits and potentials, there is a high demand for DL processing in\ndifferent computationally limited and energy-constrained devices. It is natural\nto study game-changing technologies such as Binary Neural Networks (BNN) to\nincrease deep learning capabilities. Recently remarkable progress has been made\nin BNN since they can be implemented and embedded on tiny restricted devices\nand save a significant amount of storage, computation cost, and energy\nconsumption. However, nearly all BNN acts trade with extra memory, computation\ncost, and higher performance. This article provides a complete overview of\nrecent developments in BNN. This article focuses exclusively on 1-bit\nactivations and weights 1-bit convolution networks, contrary to previous\nsurveys in which low-bit works are mixed in. It conducted a complete\ninvestigation of BNN's development -from their predecessors to the latest BNN\nalgorithms/techniques, presenting a broad design pipeline and discussing each\nmodule's variants. Along the way, it examines BNN (a) purpose: their early\nsuccesses and challenges; (b) BNN optimization: selected representative works\nthat contain essential optimization techniques; (c) deployment: open-source\nframeworks for BNN modeling and development; (d) terminal: efficient computing\narchitectures and devices for BNN and (e) applications: diverse applications\nwith BNN. Moreover, this paper discusses potential directions and future\nresearch opportunities in each section.", "published": "2021-10-11T22:44:15Z", "version": 4}, {"aid": "2110.10303", "authors": ["Devansh Arpit", "Aadyot Bhatnagar", "Huan Wang", "Caiming Xiong"], "title": "Momentum Contrastive Autoencoder: Using Contrastive Learning for Latent Space Distribution Matching in WAE", "url": "http://arxiv.org/pdf/2110.10303v2", "summary": "Wasserstein autoencoder (WAE) shows that matching two distributions is\nequivalent to minimizing a simple autoencoder (AE) loss under the constraint\nthat the latent space of this AE matches a pre-specified prior distribution.\nThis latent space distribution matching is a core component of WAE, and a\nchallenging task. In this paper, we propose to use the contrastive learning\nframework that has been shown to be effective for self-supervised\nrepresentation learning, as a means to resolve this problem. We do so by\nexploiting the fact that contrastive learning objectives optimize the latent\nspace distribution to be uniform over the unit hyper-sphere, which can be\neasily sampled from. We show that using the contrastive learning framework to\noptimize the WAE loss achieves faster convergence and more stable optimization\ncompared with existing popular algorithms for WAE. This is also reflected in\nthe FID scores on CelebA and CIFAR-10 datasets, and the realistic generated\nimage quality on the CelebA-HQ dataset.", "published": "2021-10-19T22:55:47Z", "version": 2}, {"aid": "2111.04335", "authors": ["Pieter Adriaans"], "title": "Differential information theory", "url": "http://arxiv.org/pdf/2111.04335v2", "summary": "This paper presents a new foundational approach to information theory based\non the concept of the information efficiency of a recursive function, which is\ndefined as the difference between the information in the input and the output.\nThe theory allows us to study planar representations of various infinite\ndomains. Dilation theory studies the information effects of recursive\noperations in terms of topological deformations of the plane. I show that the\nwell-known class of finite sets of natural numbers behaves erratically under\nsuch transformations. It is subject to phase transitions that in some cases\nhave a fractal nature. The class is \\emph{semi-countable}: there is no\nintrinsic information theory for this class and there are no efficient methods\nfor systematic search.\n  There is a relation between the information efficiency of the function and\nthe time needed to compute it: a deterministic computational process can\ndestroy information in linear time, but it can only generate information at\nlogarithmic speed. Checking functions for problems in $NP$ are information\ndiscarding. Consequently, when we try to solve a decision problem based on an\nefficiently computable checking function, we need exponential time to\nreconstruct the information destroyed by such a function. At the end of the\npaper I sketch a systematic taxonomy for problems in $NP$.", "published": "2021-11-08T08:53:29Z", "version": 2}, {"aid": "2201.05818", "authors": ["Florian Ellsaesser", "Guido Fioretti", "Gail E. James"], "title": "Measuring Non-Probabilistic Uncertainty: A cognitive, logical and computational assessment of known and unknown unknowns", "url": "http://arxiv.org/pdf/2201.05818v5", "summary": "There are two reasons why uncertainty may not be adequately described by\nProbability Theory. The first one is due to unique or nearly-unique events,\nthat either never realized or occurred too seldom for frequencies to be\nreliably measured. The second one arises when one fears that something may\nhappen, that one is not even able to figure out, e.g., if one asks: \"Climate\nchange, financial crises, pandemic, war, what next?\"\n  In both cases, simple one-to-one cognitive maps between available\nalternatives and possible consequences eventually melt down. However, such\ndestructions reflect into the changing narratives of business executives,\nemployees and other stakeholders in specific, identifiable and differential\nways. In particular, texts such as consultants' reports or letters to\nshareholders can be analysed in order to detect the impact of both sorts of\nuncertainty onto the causal relations that normally guide decision-making.\n  We propose structural measures of cognitive maps as a means to measure\nnon-probabilistic uncertainty, eventually suggesting that automated text\nanalysis can greatly augment the possibilities offered by these techniques.\nProspective applications may concern actors ranging from statistical institutes\nto businesses as well as the general public.", "published": "2022-01-15T10:04:05Z", "version": 5}, {"aid": "2202.00666", "authors": ["Clara Meister", "Tiago Pimentel", "Gian Wiher", "Ryan Cotterell"], "title": "Locally Typical Sampling", "url": "http://arxiv.org/pdf/2202.00666v5", "summary": "Today's probabilistic language generators fall short when it comes to\nproducing coherent and fluent text despite the fact that the underlying models\nperform well under standard metrics, e.g., perplexity. This discrepancy has\npuzzled the language generation community for the last few years. In this work,\nwe posit that the abstraction of natural language generation as a discrete\nstochastic process--which allows for an information-theoretic analysis--can\nprovide new insights into the behavior of probabilistic language generators,\ne.g., why high-probability texts can be dull or repetitive. Humans use language\nas a means of communicating information, aiming to do so in a simultaneously\nefficient and error-minimizing manner; in fact, psycholinguistics research\nsuggests humans choose each word in a string with this subconscious goal in\nmind. We formally define the set of strings that meet this criterion: those for\nwhich each word has an information content close to the expected information\ncontent, i.e., the conditional entropy of our model. We then propose a simple\nand efficient procedure for enforcing this criterion when generating from\nprobabilistic models, which we call locally typical sampling. Automatic and\nhuman evaluations show that, in comparison to nucleus and top-k sampling,\nlocally typical sampling offers competitive performance (in both abstractive\nsummarization and story generation) in terms of quality while consistently\nreducing degenerate repetitions.", "published": "2022-02-01T18:58:45Z", "version": 5}, {"aid": "2202.04110", "authors": ["Guangyao Zhou", "Antoine Dedieu", "Nishanth Kumar", "Wolfgang Lehrach", "Miguel L\u00e1zaro-Gredilla", "Shrinu Kushagra", "Dileep George"], "title": "PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX", "url": "http://arxiv.org/pdf/2202.04110v4", "summary": "PGMax is an open-source Python package for (a) easily specifying discrete\nProbabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically\nrunning efficient and scalable loopy belief propagation (LBP) in JAX. PGMax\nsupports general factor graphs with tractable factors, and leverages modern\naccelerators like GPUs for inference. Compared with existing alternatives,\nPGMax obtains higher-quality inference results with up to three\norders-of-magnitude inference time speedups. PGMax additionally interacts\nseamlessly with the rapidly growing JAX ecosystem, opening up new research\npossibilities. Our source code, examples and documentation are available at\nhttps://github.com/deepmind/PGMax.", "published": "2022-02-08T19:27:48Z", "version": 4}, {"aid": "2203.08382", "authors": ["Xuan Su", "Jiaming Song", "Chenlin Meng", "Stefano Ermon"], "title": "Dual Diffusion Implicit Bridges for Image-to-Image Translation", "url": "http://arxiv.org/pdf/2203.08382v4", "summary": "Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. The training process requires concurrent\naccess to both datasets, which hinders data separation and privacy protection;\nand existing models cannot be easily adapted for translation of new domain\npairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation\nmethod based on diffusion models, that circumvents training on domain pairs.\nImage translation with DDIBs relies on two diffusion models trained\nindependently on each domain, and is a two-step process: DDIBs first obtain\nlatent encodings for source images with the source diffusion model, and then\ndecode such encodings using the target model to construct target images. Both\nsteps are defined via ordinary differential equations (ODEs), thus the process\nis cycle consistent only up to discretization errors of the ODE solvers.\nTheoretically, we interpret DDIBs as concatenation of source to latent, and\nlatent to target Schrodinger Bridges, a form of entropy-regularized optimal\ntransport, to explain the efficacy of the method. Experimentally, we apply\nDDIBs on synthetic and high-resolution image datasets, to demonstrate their\nutility in a wide variety of translation tasks and their inherent optimal\ntransport properties.", "published": "2022-03-16T04:10:45Z", "version": 4}, {"aid": "2203.11200", "authors": ["Jie Chen", "Shouzhen Chen", "Junbin Gao", "Zengfeng Huang", "Junping Zhang", "Jian Pu"], "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily", "url": "http://arxiv.org/pdf/2203.11200v3", "summary": "Due to the homophily assumption in graph convolution networks (GNNs), a\ncommon consensus in the graph node classification task is that GNNs perform\nwell on homophilic graphs but may fail on heterophilic graphs with many\ninter-class edges. However, the previous inter-class edges perspective and\nrelated homo-ratio metrics cannot well explain the GNNs performance under some\nheterophilic datasets, which implies that not all the inter-class edges are\nharmful to GNNs. In this work, we propose a new metric based on von Neumann\nentropy to re-examine the heterophily problem of GNNs and investigate the\nfeature aggregation of inter-class edges from an entire neighbor identifiable\nperspective. Moreover, we propose a simple yet effective Conv-Agnostic GNN\nframework (CAGNNs) to enhance the performance of most GNNs on heterophily\ndatasets by learning the neighbor effect for each node. Specifically, we first\ndecouple the feature of each node into the discriminative feature for\ndownstream tasks and the aggregation feature for graph convolution. Then, we\npropose a shared mixer module to adaptively evaluate the neighbor effect of\neach node to incorporate the neighbor information. The proposed framework can\nbe regarded as a plug-in component and is compatible with most GNNs. The\nexperimental results over nine well-known benchmark datasets indicate that our\nframework can significantly improve performance, especially for the heterophily\ngraphs. The average performance gain is 9.81%, 25.81%, and 20.61% compared with\nGIN, GAT, and GCN, respectively. Extensive ablation studies and robustness\nanalysis further verify the effectiveness, robustness, and interpretability of\nour framework. Code is available at https://github.com/JC-202/CAGNN.", "published": "2022-03-19T14:26:43Z", "version": 3}, {"aid": "2203.14495", "authors": ["Hiroki Naganuma", "Hideaki Iiduka"], "title": "Conjugate Gradient Method for Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2203.14495v3", "summary": "One of the training strategies of generative models is to minimize the\nJensen--Shannon divergence between the model distribution and the data\ndistribution. Since data distribution is unknown, generative adversarial\nnetworks (GANs) formulate this problem as a game between two models, a\ngenerator and a discriminator. The training can be formulated in the context of\ngame theory and the local Nash equilibrium (LNE). It does not seem feasible to\nderive guarantees of stability or optimality for the existing methods. This\noptimization problem is far more challenging than the single objective setting.\nHere, we use the conjugate gradient method to reliably and efficiently solve\nthe LNE problem in GANs. We give a proof and convergence analysis under mild\nassumptions showing that the proposed method converges to a LNE with three\ndifferent learning rate update rules, including a constant learning rate.\nFinally, we demonstrate that the proposed method outperforms stochastic\ngradient descent (SGD) and momentum SGD in terms of best Frechet inception\ndistance (FID) score and outperforms Adam on average. The code is available at\n\\url{https://github.com/Hiroki11x/ConjugateGradient_GAN}.", "published": "2022-03-28T04:44:45Z", "version": 3}, {"aid": "2203.17255", "authors": ["Jared Edward Reser"], "title": "A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Thought Is Structured by the Iterative Updating of Working Memory", "url": "http://arxiv.org/pdf/2203.17255v7", "summary": "This article provides an analytical framework for how to simulate human-like\nthought processes within a computer. It describes how attention and memory\nshould be structured, updated, and utilized to search for associative additions\nto the stream of thought. The focus is on replicating the dynamics of the\nmammalian working memory system, which features two forms of persistent\nactivity: sustained firing (preserving information on the order of seconds) and\nsynaptic potentiation (preserving information from minutes to hours). The\narticle uses a series of figures to systematically demonstrate how the\niterative updating of these working memory stores provides functional\norganization to behavior, cognition, and awareness.\n  In a machine learning implementation, these two memory stores should be\nupdated continuously and in an iterative fashion. This means each state should\npreserve a proportion of the coactive representations from the state before it\n(where each representation is an ensemble of neural network nodes). This makes\neach state a revised iteration of the preceding state and causes successive\nconfigurations to overlap and blend with respect to the information they\ncontain. Thus, the set of concepts in working memory will evolve gradually and\nincrementally over time. Transitions between states happen as persistent\nactivity spreads activation energy throughout the hierarchical network,\nsearching long-term memory for the most appropriate representation to be added\nto the global workspace. The result is a chain of associatively linked\nintermediate states capable of advancing toward a solution or goal. Iterative\nupdating is conceptualized here as an information processing strategy, a model\nof working memory, a theory of consciousness, and an algorithm for designing\nand programming artificial intelligence (AI, AGI, and ASI).", "published": "2022-03-29T22:28:30Z", "version": 7}, {"aid": "2203.17271", "authors": ["Tian Yun", "Usha Bhalla", "Ellie Pavlick", "Chen Sun"], "title": "Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?", "url": "http://arxiv.org/pdf/2203.17271v3", "summary": "Vision-language (VL) pretrained models have achieved impressive performance\non multimodal reasoning and zero-shot recognition tasks. Many of these VL\nmodels are pretrained on unlabeled image and caption pairs from the internet.\nIn this paper, we study whether representations of primitive concepts--such as\ncolors, shapes, or the attributes of object parts--emerge automatically within\nthese pretrained VL models. We propose a two-step framework, Compositional\nConcept Mapping (CompMap), to investigate this. CompMap first asks a VL model\nto generate primitive concept activations with text prompts, and then learns to\nconstruct a composition model that maps the primitive concept activations (e.g.\nthe likelihood of black tail or red wing) to composite concepts (e.g. a\nred-winged blackbird). We show that a composition model can be reliably learn\nfrom ground truth primitive concepts. We thus hypothesize that if primitive\nconcepts indeed emerge in a VL pretrained model, its primitive concept\nactivations can be used to learn a composition model similar to the one\ndesigned by experts. We propose a quantitative metric to measure the degree of\nsimilarity, and refer to the metric as the interpretability metric. We also\nmeasure the classification accuracy when using the primitive concept\nactivations and the learned composition model to predict the composite\nconcepts, and refer to it as the usefulness metric. Our study reveals that\nstate-of-the-art VL pretrained models learn primitive concepts that are highly\nuseful for fine-grained visual recognition on the CUB dataset, and\ncompositional generalization tasks on the MIT-States dataset. However, we\nobserve that the learned composition models have low interpretability in our\nqualitative analyses. Our results reveal the limitations of existing VL models,\nand the necessity of pretraining objectives that encourage the acquisition of\nprimitive concepts.", "published": "2022-03-31T17:59:05Z", "version": 3}, {"aid": "2204.00964", "authors": ["Minchul Kim", "Anil K. Jain", "Xiaoming Liu"], "title": "AdaFace: Quality Adaptive Margin for Face Recognition", "url": "http://arxiv.org/pdf/2204.00964v2", "summary": "Recognition in low quality face datasets is challenging because facial\nattributes are obscured and degraded. Advances in margin-based loss functions\nhave resulted in enhanced discriminability of faces in the embedding space.\nFurther, previous studies have studied the effect of adaptive losses to assign\nmore importance to misclassified (hard) examples. In this work, we introduce\nanother aspect of adaptiveness in the loss function, namely the image quality.\nWe argue that the strategy to emphasize misclassified samples should be\nadjusted according to their image quality. Specifically, the relative\nimportance of easy or hard samples should be based on the sample's image\nquality. We propose a new loss function that emphasizes samples of different\ndifficulties based on their image quality. Our method achieves this in the form\nof an adaptive margin function by approximating the image quality with feature\nnorms. Extensive experiments show that our method, AdaFace, improves the face\nrecognition performance over the state-of-the-art (SoTA) on four datasets\n(IJB-B, IJB-C, IJB-S and TinyFace). Code and models are released in\nhttps://github.com/mk-minchul/AdaFace.", "published": "2022-04-03T01:23:41Z", "version": 2}, {"aid": "2204.06108", "authors": ["Nicholas Richardson", "Hayden Schaeffer", "Giang Tran"], "title": "SRMD: Sparse Random Mode Decomposition", "url": "http://arxiv.org/pdf/2204.06108v2", "summary": "Signal decomposition and multiscale signal analysis provide many useful tools\nfor time-frequency analysis. We proposed a random feature method for analyzing\ntime-series data by constructing a sparse approximation to the spectrogram. The\nrandomization is both in the time window locations and the frequency sampling,\nwhich lowers the overall sampling and computational cost. The sparsification of\nthe spectrogram leads to a sharp separation between time-frequency clusters\nwhich makes it easier to identify intrinsic modes, and thus leads to a new\ndata-driven mode decomposition. The applications include signal representation,\noutlier removal, and mode decomposition. On the benchmark tests, we show that\nour approach outperforms other state-of-the-art decomposition methods.", "published": "2022-04-12T22:40:10Z", "version": 2}, {"aid": "2204.06552", "authors": ["Edoardo Mello Rella", "Ajad Chhatkuli", "Ender Konukoglu", "Luc Van Gool"], "title": "Neural Vector Fields for Implicit Surface Representation and Inference", "url": "http://arxiv.org/pdf/2204.06552v3", "summary": "Implicit fields have recently shown increasing success in representing and\nlearning 3D shapes accurately. Signed distance fields and occupancy fields are\ndecades old and still the preferred representations, both with well-studied\nproperties, despite their restriction to closed surfaces. With neural networks,\nseveral other variations and training principles have been proposed with the\ngoal to represent all classes of shapes. In this paper, we develop a novel and\nyet a fundamental representation considering unit vectors in 3D space and call\nit Vector Field (VF): at each point in $\\mathbb{R}^3$, VF is directed at the\nclosest point on the surface. We theoretically demonstrate that VF can be\neasily transformed to surface density by computing the flux density. Unlike\nother standard representations, VF directly encodes an important physical\nproperty of the surface, its normal. We further show the advantages of VF\nrepresentation, in learning open, closed, or multi-layered as well as piecewise\nplanar surfaces. We compare our method on several datasets including ShapeNet\nwhere the proposed new neural implicit field shows superior accuracy in\nrepresenting any type of shape, outperforming other standard methods. Code is\navailable at https://github.com/edomel/ImplicitVF.", "published": "2022-04-13T17:53:34Z", "version": 3}, {"aid": "2204.06645", "authors": ["Keaton Hamm", "Nick Henscheid", "Shujie Kang"], "title": "Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning", "url": "http://arxiv.org/pdf/2204.06645v3", "summary": "In this paper, we propose Wasserstein Isometric Mapping (Wassmap), a\nnonlinear dimensionality reduction technique that provides solutions to some\ndrawbacks in existing global nonlinear dimensionality reduction algorithms in\nimaging applications. Wassmap represents images via probability measures in\nWasserstein space, then uses pairwise Wasserstein distances between the\nassociated measures to produce a low-dimensional, approximately isometric\nembedding. We show that the algorithm is able to exactly recover parameters of\nsome image manifolds including those generated by translations or dilations of\na fixed generating measure. Additionally, we show that a discrete version of\nthe algorithm retrieves parameters from manifolds generated from discrete\nmeasures by providing a theoretical bridge to transfer recovery results from\nfunctional data to discrete data. Testing of the proposed algorithms on various\nimage data manifolds show that Wassmap yields good embeddings compared with\nother global and local techniques.", "published": "2022-04-13T21:43:28Z", "version": 3}, {"aid": "2204.07610", "authors": ["Odd Erik Gundersen", "Kevin Coakley", "Christine Kirkpatrick", "Yolanda Gil"], "title": "Sources of Irreproducibility in Machine Learning: A Review", "url": "http://arxiv.org/pdf/2204.07610v2", "summary": "Background: Many published machine learning studies are irreproducible.\nIssues with methodology and not properly accounting for variation introduced by\nthe algorithm themselves or their implementations are attributed as the main\ncontributors to the irreproducibility.Problem: There exist no theoretical\nframework that relates experiment design choices to potential effects on the\nconclusions. Without such a framework, it is much harder for practitioners and\nresearchers to evaluate experiment results and describe the limitations of\nexperiments. The lack of such a framework also makes it harder for independent\nresearchers to systematically attribute the causes of failed reproducibility\nexperiments. Objective: The objective of this paper is to develop a framework\nthat enable applied data science practitioners and researchers to understand\nwhich experiment design choices can lead to false findings and how and by this\nhelp in analyzing the conclusions of reproducibility experiments. Method: We\nhave compiled an extensive list of factors reported in the literature that can\nlead to machine learning studies being irreproducible. These factors are\norganized and categorized in a reproducibility framework motivated by the\nstages of the scientific method. The factors are analyzed for how they can\naffect the conclusions drawn from experiments. A model comparison study is used\nas an example. Conclusion: We provide a framework that describes machine\nlearning methodology from experimental design decisions to the conclusions\ninferred from them.", "published": "2022-04-15T18:26:03Z", "version": 2}, {"aid": "2204.10588", "authors": ["Andreas Habring", "Martin Holler"], "title": "A Note on the Regularity of Images Generated by Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2204.10588v2", "summary": "The regularity of images generated by convolutional neural networks, such as\nthe U-net, generative networks, or the deep image prior, is analyzed. In a\nresolution-independent, infinite dimensional setting, it is shown that such\nimages, represented as functions, are always continuous and, in some\ncircumstances, even continuously differentiable, contradicting the widely\naccepted modeling of sharp edges in images via jump discontinuities. While such\nstatements require an infinite dimensional setting, the connection to\n(discretized) neural networks used in practice is made by considering the limit\nas the resolution approaches infinity. As practical consequence, the results of\nthis paper in particular provide analytical evidence that basic L2\nregularization of network weights might lead to over-smoothed outputs.", "published": "2022-04-22T09:19:49Z", "version": 2}, {"aid": "2205.06769", "authors": ["W. Jeffrey Johnston", "Justin M. Fine", "Seng Bum Michael Yoo", "R. Becket Ebitz", "Benjamin Y. Hayden"], "title": "Subspace orthogonalization as a mechanism for binding values to space", "url": "http://arxiv.org/pdf/2205.06769v2", "summary": "When choosing between options, we must solve an important binding problem.\nThe values of the options must be associated with information about the action\nneeded to select them. We hypothesize that the brain solves this binding\nproblem through use of distinct population subspaces. To test this hypothesis,\nwe examined the responses of single neurons in five reward-sensitive regions in\nrhesus macaques performing a risky choice task. In all areas, neurons encoded\nthe value of the offers presented on both the left and the right side of the\ndisplay in semi-orthogonal subspaces, which served to bind the values of the\ntwo offers to their positions in space. Supporting the idea that this\northogonalization is functionally meaningful, we observed a session-to-session\ncovariation between choice behavior and the orthogonalization of the two value\nsubspaces: trials with less orthogonalized subspaces were associated with\ngreater likelihood of choosing the less valued option. Further inspection\nrevealed that these semi-orthogonal subspaces arose from a combination of\nlinear and nonlinear mixed selectivity in the neural population. We show this\ncombination of selectivity balances reliable binding with an ability to\ngeneralize value across different spatial locations. These results support the\nhypothesis that semi-orthogonal subspaces support reliable binding, which is\nessential to flexible behavior in the face of multiple options.", "published": "2022-05-13T16:57:54Z", "version": 2}, {"aid": "2205.09435", "authors": ["David S. Watson", "Kristin Blesch", "Jan Kapar", "Marvin N. Wright"], "title": "Adversarial random forests for density estimation and generative modeling", "url": "http://arxiv.org/pdf/2205.09435v4", "summary": "We propose methods for density estimation and data synthesis using a novel\nform of unsupervised random forests. Inspired by generative adversarial\nnetworks, we implement a recursive procedure in which trees gradually learn\nstructural properties of the data through alternating rounds of generation and\ndiscrimination. The method is provably consistent under minimal assumptions.\nUnlike classic tree-based alternatives, our approach provides smooth\n(un)conditional densities and allows for fully synthetic data generation. We\nachieve comparable or superior performance to state-of-the-art probabilistic\ncircuits and deep learning models on various tabular data benchmarks while\nexecuting about two orders of magnitude faster on average. An accompanying\n$\\texttt{R}$ package, $\\texttt{arf}$, is available on $\\texttt{CRAN}$.", "published": "2022-05-19T09:50:25Z", "version": 4}, {"aid": "2205.16007", "authors": ["Zhicong Tang", "Shuyang Gu", "Jianmin Bao", "Dong Chen", "Fang Wen"], "title": "Improved Vector Quantized Diffusion Models", "url": "http://arxiv.org/pdf/2205.16007v2", "summary": "Vector quantized diffusion (VQ-Diffusion) is a powerful generative model for\ntext-to-image synthesis, but sometimes can still generate low-quality samples\nor weakly correlated images with text input. We find these issues are mainly\ndue to the flawed sampling strategy. In this paper, we propose two important\ntechniques to further improve the sample quality of VQ-Diffusion. 1) We explore\nclassifier-free guidance sampling for discrete denoising diffusion model and\npropose a more general and effective implementation of classifier-free\nguidance. 2) We present a high-quality inference strategy to alleviate the\njoint distribution issue in VQ-Diffusion. Finally, we conduct experiments on\nvarious datasets to validate their effectiveness and show that the improved\nVQ-Diffusion suppresses the vanilla version by large margins. We achieve an\n8.44 FID score on MSCOCO, surpassing VQ-Diffusion by 5.42 FID score. When\ntrained on ImageNet, we dramatically improve the FID score from 11.89 to 4.83,\ndemonstrating the superiority of our proposed techniques.", "published": "2022-05-31T17:59:53Z", "version": 2}, {"aid": "2206.01730", "authors": ["J\u00e9r\u00f4me Bolte", "Ryan Boustany", "Edouard Pauwels", "B\u00e9atrice Pesquet-Popescu"], "title": "On the complexity of nonsmooth automatic differentiation", "url": "http://arxiv.org/pdf/2206.01730v2", "summary": "Using the notion of conservative gradient, we provide a simple model to\nestimate the computational costs of the backward and forward modes of\nalgorithmic differentiation for a wide class of nonsmooth programs. The\noverhead complexity of the backward mode turns out to be independent of the\ndimension when using programs with locally Lipschitz semi-algebraic or\ndefinable elementary functions. This considerably extends Baur-Strassen's\nsmooth cheap gradient principle. We illustrate our results by establishing fast\nbackpropagation results of conservative gradients through feedforward neural\nnetworks with standard activation and loss functions. Nonsmooth\nbackpropagation's cheapness contrasts with concurrent forward approaches, which\nhave, to this day, dimensional-dependent worst-case overhead estimates. We\nprovide further results suggesting the superiority of backward propagation of\nconservative gradients. Indeed, we relate the complexity of computing a large\nnumber of directional derivatives to that of matrix multiplication, and we show\nthat finding two subgradients in the Clarke subdifferential of a function is an\nNP-hard problem.", "published": "2022-06-01T08:43:35Z", "version": 2}, {"aid": "2206.01934", "authors": ["Hoang Phan", "Ngoc Tran", "Trung Le", "Toan Tran", "Nhat Ho", "Dinh Phung"], "title": "Stochastic Multiple Target Sampling Gradient Descent", "url": "http://arxiv.org/pdf/2206.01934v4", "summary": "Sampling from an unnormalized target distribution is an essential problem\nwith many applications in probabilistic inference. Stein Variational Gradient\nDescent (SVGD) has been shown to be a powerful method that iteratively updates\na set of particles to approximate the distribution of interest. Furthermore,\nwhen analysing its asymptotic properties, SVGD reduces exactly to a\nsingle-objective optimization problem and can be viewed as a probabilistic\nversion of this single-objective optimization problem. A natural question then\narises: \"Can we derive a probabilistic version of the multi-objective\noptimization?\". To answer this question, we propose Stochastic Multiple Target\nSampling Gradient Descent (MT-SGD), enabling us to sample from multiple\nunnormalized target distributions. Specifically, our MT-SGD conducts a flow of\nintermediate distributions gradually orienting to multiple target\ndistributions, which allows the sampled particles to move to the joint\nhigh-likelihood region of the target distributions. Interestingly, the\nasymptotic analysis shows that our approach reduces exactly to the\nmultiple-gradient descent algorithm for multi-objective optimization, as\nexpected. Finally, we conduct comprehensive experiments to demonstrate the\nmerit of our approach to multi-task learning.", "published": "2022-06-04T07:54:35Z", "version": 4}, {"aid": "2206.06214", "authors": ["Yingqian Wang", "Zhengyu Liang", "Longguang Wang", "Jungang Yang", "Wei An", "Yulan Guo"], "title": "Real-World Light Field Image Super-Resolution via Degradation Modulation", "url": "http://arxiv.org/pdf/2206.06214v2", "summary": "Recent years have witnessed the great advances of deep neural networks (DNNs)\nin light field (LF) image super-resolution (SR). However, existing DNN-based LF\nimage SR methods are developed on a single fixed degradation (e.g., bicubic\ndownsampling), and thus cannot be applied to super-resolve real LF images with\ndiverse degradation. In this paper, we propose a simple yet effective method\nfor real-world LF image SR. In our method, a practical LF degradation model is\ndeveloped to formulate the degradation process of real LF images. Then, a\nconvolutional neural network is designed to incorporate the degradation prior\ninto the SR process. By training on LF images using our formulated degradation,\nour network can learn to modulate different degradation while incorporating\nboth spatial and angular information in LF images. Extensive experiments on\nboth synthetically degraded and real-world LF images demonstrate the\neffectiveness of our method. Compared with existing state-of-the-art single and\nLF image SR methods, our method achieves superior SR performance under a wide\nrange of degradation, and generalizes better to real LF images. Codes and\nmodels are available at https://yingqianwang.github.io/LF-DMnet/.", "published": "2022-06-13T14:44:46Z", "version": 2}, {"aid": "2206.07568", "authors": ["Benjamin Eysenbach", "Tianjun Zhang", "Ruslan Salakhutdinov", "Sergey Levine"], "title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning", "url": "http://arxiv.org/pdf/2206.07568v2", "summary": "In reinforcement learning (RL), it is easier to solve a task if given a good\nrepresentation. While deep RL should automatically acquire such good\nrepresentations, prior work often finds that learning representations in an\nend-to-end fashion is unstable and instead equip RL algorithms with additional\nrepresentation learning parts (e.g., auxiliary losses, data augmentation). How\ncan we design RL algorithms that directly acquire good representations? In this\npaper, instead of adding representation learning parts to an existing RL\nalgorithm, we show (contrastive) representation learning methods can be cast as\nRL algorithms in their own right. To do this, we build upon prior work and\napply contrastive representation learning to action-labeled trajectories, in\nsuch a way that the (inner product of) learned representations exactly\ncorresponds to a goal-conditioned value function. We use this idea to\nreinterpret a prior RL method as performing contrastive learning, and then use\nthe idea to propose a much simpler method that achieves similar performance.\nAcross a range of goal-conditioned RL tasks, we demonstrate that contrastive RL\nmethods achieve higher success rates than prior non-contrastive methods,\nincluding in the offline RL setting. We also show that contrastive RL\noutperforms prior methods on image-based tasks, without using data augmentation\nor auxiliary objectives.", "published": "2022-06-15T14:34:15Z", "version": 2}, {"aid": "2206.13508", "authors": ["Guillermo Iglesias", "Edgar Talavera", "\u00c1ngel Gonz\u00e1lez-Prieto", "Alberto Mozo", "Sandra G\u00f3mez-Canaval"], "title": "Data Augmentation techniques in time series domain: A survey and taxonomy", "url": "http://arxiv.org/pdf/2206.13508v4", "summary": "With the latest advances in Deep Learning-based generative models, it has not\ntaken long to take advantage of their remarkable performance in the area of\ntime series. Deep neural networks used to work with time series heavily depend\non the size and consistency of the datasets used in training. These features\nare not usually abundant in the real world, where they are usually limited and\noften have constraints that must be guaranteed. Therefore, an effective way to\nincrease the amount of data is by using Data Augmentation techniques, either by\nadding noise or permutations and by generating new synthetic data. This work\nsystematically reviews the current state-of-the-art in the area to provide an\noverview of all available algorithms and proposes a taxonomy of the most\nrelevant research. The efficiency of the different variants will be evaluated\nas a central part of the process, as well as the different metrics to evaluate\nthe performance and the main problems concerning each model will be analysed.\nThe ultimate aim of this study is to provide a summary of the evolution and\nperformance of areas that produce better results to guide future researchers in\nthis field.", "published": "2022-06-25T17:09:00Z", "version": 4}, {"aid": "2207.00713", "authors": ["Yanwei Jia", "Xun Yu Zhou"], "title": "q-Learning in Continuous Time", "url": "http://arxiv.org/pdf/2207.00713v3", "summary": "We study the continuous-time counterpart of Q-learning for reinforcement\nlearning (RL) under the entropy-regularized, exploratory diffusion process\nformulation introduced by Wang et al. (2020). As the conventional (big)\nQ-function collapses in continuous time, we consider its first-order\napproximation and coin the term ``(little) q-function\". This function is\nrelated to the instantaneous advantage rate function as well as the\nHamiltonian. We develop a ``q-learning\" theory around the q-function that is\nindependent of time discretization. Given a stochastic policy, we jointly\ncharacterize the associated q-function and value function by martingale\nconditions of certain stochastic processes, in both on-policy and off-policy\nsettings. We then apply the theory to devise different actor-critic algorithms\nfor solving underlying RL problems, depending on whether or not the density\nfunction of the Gibbs measure generated from the q-function can be computed\nexplicitly. One of our algorithms interprets the well-known Q-learning\nalgorithm SARSA, and another recovers a policy gradient (PG) based\ncontinuous-time algorithm proposed in Jia and Zhou (2022b). Finally, we conduct\nsimulation experiments to compare the performance of our algorithms with those\nof PG-based algorithms in Jia and Zhou (2022b) and time-discretized\nconventional Q-learning algorithms.", "published": "2022-07-02T02:20:41Z", "version": 3}, {"aid": "2207.02849", "authors": ["Sang Keun Choe", "Willie Neiswanger", "Pengtao Xie", "Eric Xing"], "title": "Betty: An Automatic Differentiation Library for Multilevel Optimization", "url": "http://arxiv.org/pdf/2207.02849v2", "summary": "Gradient-based multilevel optimization (MLO) has gained attention as a\nframework for studying numerous problems, ranging from hyperparameter\noptimization and meta-learning to neural architecture search and reinforcement\nlearning. However, gradients in MLO, which are obtained by composing\nbest-response Jacobians via the chain rule, are notoriously difficult to\nimplement and memory/compute intensive. We take an initial step towards closing\nthis gap by introducing Betty, a software library for large-scale MLO. At its\ncore, we devise a novel dataflow graph for MLO, which allows us to (1) develop\nefficient automatic differentiation for MLO that reduces the computational\ncomplexity from O(d^3) to O(d^2), (2) incorporate systems support such as\nmixed-precision and data-parallel training for scalability, and (3) facilitate\nimplementation of MLO programs of arbitrary complexity while allowing a modular\ninterface for diverse algorithmic and systems design choices. We empirically\ndemonstrate that Betty can be used to implement an array of MLO programs, while\nalso observing up to 11% increase in test accuracy, 14% decrease in GPU memory\nusage, and 20% decrease in training wall time over existing implementations on\nmultiple benchmarks. We also showcase that Betty enables scaling MLO to models\nwith hundreds of millions of parameters. We open-source the code at\nhttps://github.com/leopard-ai/betty.", "published": "2022-07-05T14:01:15Z", "version": 2}, {"aid": "2207.05197", "authors": ["Matthieu Gilson", "Enzo Tagliazucchi", "Rodrigo Cofre"], "title": "Entropy production of Multivariate Ornstein-Uhlenbeck processes correlates with consciousness levels in the human brain", "url": "http://arxiv.org/pdf/2207.05197v2", "summary": "Consciousness is supported by complex patterns of brain activity which are\nindicative of irreversible non-equilibrium dynamics. While the framework of\nstochastic thermodynamics has facilitated the understanding of physical systems\nof this kind, its application to infer the level of consciousness from\nempirical data remains elusive. We faced this challenge by calculating entropy\nproduction in a multivariate Ornstein-Uhlenbeck process fitted to fMRI brain\nactivity recordings. To test this approach, we focused on the transition from\nwakefulness to deep sleep, revealing a monotonous relationship between entropy\nproduction and the level of consciousness. Our results constitute robust\nsignatures of consciousness while also advancing our understanding of the link\nbetween consciousness and complexity from the fundamental perspective of\nstatistical physics.", "published": "2022-07-11T21:27:27Z", "version": 2}, {"aid": "2207.05543", "authors": ["Harrison Zhu", "Carles Balsells Rodas", "Yingzhen Li"], "title": "Markovian Gaussian Process Variational Autoencoders", "url": "http://arxiv.org/pdf/2207.05543v3", "summary": "Sequential VAEs have been successfully considered for many high-dimensional\ntime series modelling problems, with many variant models relying on\ndiscrete-time mechanisms such as recurrent neural networks (RNNs). On the other\nhand, continuous-time methods have recently gained attraction, especially in\nthe context of irregularly-sampled time series, where they can better handle\nthe data than discrete-time methods. One such class are Gaussian process\nvariational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian\nprocess (GP). However, a major limitation of GPVAEs is that it inherits the\ncubic computational cost as GPs, making it unattractive to practioners. In this\nwork, we leverage the equivalent discrete state space representation of\nMarkovian GPs to enable linear time GPVAE training via Kalman filtering and\nsmoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of\nhigh-dimensional temporal and spatiotemporal tasks that our method performs\nfavourably compared to existing approaches whilst being computationally highly\nscalable.", "published": "2022-07-12T14:10:01Z", "version": 3}, {"aid": "2208.11308", "authors": ["Evgenii Indenbom", "Nicolae-C\u0103t\u0103lin Ristea", "Ando Saabas", "Tanel P\u00e4rnamaa", "Jegor Gu\u017evin"], "title": "Deep model with built-in cross-attention alignment for acoustic echo cancellation", "url": "http://arxiv.org/pdf/2208.11308v2", "summary": "With recent research advances, deep learning models have become an attractive\nchoice for acoustic echo cancellation (AEC) in real-time teleconferencing\napplications. Since acoustic echo is one of the major sources of poor audio\nquality, a wide variety of deep models have been proposed. However, an\nimportant but often omitted requirement for good echo cancellation quality is\nthe synchronization of the microphone and far end signals. Typically\nimplemented using classical algorithms based on cross-correlation, the\nalignment module is a separate functional block with known design limitations.\nIn our work we propose a deep learning architecture with built-in\nself-attention based alignment, which is able to handle unaligned inputs,\nimproving echo cancellation performance while simplifying the communication\npipeline. Moreover, we show that our approach achieves significant improvements\nfor difficult delay estimation cases on real recordings from AEC Challenge data\nset.", "published": "2022-08-24T05:29:47Z", "version": 2}, {"aid": "2208.13056", "authors": ["Zhihao Duan", "Ming Lu", "Zhan Ma", "Fengqing Zhu"], "title": "Lossy Image Compression with Quantized Hierarchical VAEs", "url": "http://arxiv.org/pdf/2208.13056v2", "summary": "Recent research has shown a strong theoretical connection between variational\nautoencoders (VAEs) and the rate-distortion theory. Motivated by this, we\nconsider the problem of lossy image compression from the perspective of\ngenerative modeling. Starting with ResNet VAEs, which are originally designed\nfor data (image) distribution modeling, we redesign their latent variable model\nusing a quantization-aware posterior and prior, enabling easy quantization and\nentropy coding at test time. Along with improved neural network architecture,\nwe present a powerful and efficient model that outperforms previous methods on\nnatural image lossy compression. Our model compresses images in a\ncoarse-to-fine fashion and supports parallel encoding and decoding, leading to\nfast execution on GPUs. Code is available at\nhttps://github.com/duanzhiihao/lossy-vae.", "published": "2022-08-27T17:15:38Z", "version": 2}, {"aid": "2209.04934", "authors": ["Johannes Brandstetter", "Rianne van den Berg", "Max Welling", "Jayesh K. Gupta"], "title": "Clifford Neural Layers for PDE Modeling", "url": "http://arxiv.org/pdf/2209.04934v2", "summary": "Partial differential equations (PDEs) see widespread use in sciences and\nengineering to describe simulation of physical processes as scalar and vector\nfields interacting and coevolving over time. Due to the computationally\nexpensive nature of their standard solution methods, neural PDE surrogates have\nbecome an active research topic to accelerate these simulations. However,\ncurrent methods do not explicitly take into account the relationship between\ndifferent fields and their internal components, which are often correlated.\nViewing the time evolution of such correlated fields through the lens of\nmultivector fields allows us to overcome these limitations. Multivector fields\nconsist of scalar, vector, as well as higher-order components, such as\nbivectors and trivectors. Their algebraic properties, such as multiplication,\naddition and other arithmetic operations can be described by Clifford algebras.\nTo our knowledge, this paper presents the first usage of such multivector\nrepresentations together with Clifford convolutions and Clifford Fourier\ntransforms in the context of deep learning. The resulting Clifford neural\nlayers are universally applicable and will find direct use in the areas of\nfluid dynamics, weather forecasting, and the modeling of physical systems in\ngeneral. We empirically evaluate the benefit of Clifford neural layers by\nreplacing convolution and Fourier operations in common neural PDE surrogates by\ntheir Clifford counterparts on 2D Navier-Stokes and weather modeling tasks, as\nwell as 3D Maxwell equations. For similar parameter count, Clifford neural\nlayers consistently improve generalization capabilities of the tested neural\nPDE surrogates. Source code for our PyTorch implementation is available at\nhttps://microsoft.github.io/cliffordlayers/.", "published": "2022-09-08T17:35:30Z", "version": 2}, {"aid": "2209.05829", "authors": ["Vito Dichio", "Fabrizio De Vico Fallani"], "title": "Statistical models of complex brain networks: a maximum entropy approach", "url": "http://arxiv.org/pdf/2209.05829v4", "summary": "The brain is a highly complex system. Most of such complexity stems from the\nintermingled connections between its parts, which give rise to rich dynamics\nand to the emergence of high-level cognitive functions. Disentangling the\nunderlying network structure is crucial to understand the brain functioning\nunder both healthy and pathological conditions. Yet, analyzing brain networks\nis challenging, in part because their structure represents only one possible\nrealization of a generative stochastic process which is in general unknown.\nHaving a formal way to cope with such intrinsic variability is therefore\ncentral for the characterization of brain network properties. Addressing this\nissue entails the development of appropriate tools mostly adapted from network\nscience and statistics. Here, we focus on a particular class of maximum entropy\nmodels for networks, i.e. exponential random graph models (ERGMs), as a\nparsimonious approach to identify the local connection mechanisms behind\nobserved global network structure. Efforts are reviewed on the quest for basic\norganizational properties of human brain networks, as well as on the\nidentification of predictive biomarkers of neurological diseases such as\nstroke. We conclude with a discussion on how emerging results and tools from\nstatistical graph modeling, associated with forthcoming improvements in\nexperimental data acquisition, could lead to a finer probabilistic description\nof complex systems in network neuroscience.", "published": "2022-09-13T09:08:38Z", "version": 4}, {"aid": "2209.13131", "authors": ["Brian Moser", "Federico Raue", "Stanislav Frolov", "J\u00f6rn Hees", "Sebastian Palacio", "Andreas Dengel"], "title": "Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances", "url": "http://arxiv.org/pdf/2209.13131v2", "summary": "With the advent of Deep Learning (DL), Super-Resolution (SR) has also become\na thriving research area. However, despite promising results, the field still\nfaces challenges that require further research e.g., allowing flexible\nupsampling, more effective loss functions, and better evaluation metrics. We\nreview the domain of SR in light of recent advances, and examine\nstate-of-the-art models such as diffusion (DDPM) and transformer-based SR\nmodels. We present a critical discussion on contemporary strategies used in SR,\nand identify promising yet unexplored research directions. We complement\nprevious surveys by incorporating the latest developments in the field such as\nuncertainty-driven losses, wavelet networks, neural architecture search, novel\nnormalization methods, and the latests evaluation techniques. We also include\nseveral visualizations for the models and methods throughout each chapter in\norder to facilitate a global understanding of the trends in the field. This\nreview is ultimately aimed at helping researchers to push the boundaries of DL\napplied to SR.", "published": "2022-09-27T03:28:34Z", "version": 2}, {"aid": "2210.10107", "authors": ["George F R Ellis"], "title": "Physical Time and Human Time", "url": "http://arxiv.org/pdf/2210.10107v4", "summary": "This is a comment on both Gruber et al (2022) and Bunamano and Rovelli\n(2022), which discuss the relation between physical time and human time. I\nclaim here, contrary to many views discussed there, that there is no\nfoundational conflict between the way physics views the passage of time and the\nway the mind/brain perceives it. The problem rather resides in a number of\nmisconceptions leading to the representation of spacetime as a timeless Block\nUniverse. The physical expanding universe is in fact an Evolving Block Universe\nwith a time-dependent future boundary. This establishes a global direction of\ntime that determines local arrows of time. Furthermore time passes when quantum\nwave function collapse takes place; during this process, information is lost.\nThe mind/brain acts as an imperfect clock, which coarse-grains the physical\npassage of time along a world line to determine the experienced passage of\ntime, because neuronal processes take time to occur. This happens in a\ncontextual way, so experienced time is not linearly related to physical time in\ngeneral. Finally I point out that the Universe is never infinitely old: its\nfuture endpoint always lies infinitely faraway in the future", "published": "2022-10-18T19:09:05Z", "version": 4}, {"aid": "2210.10960", "authors": ["Mingi Kwon", "Jaeseok Jeong", "Youngjung Uh"], "title": "Diffusion Models already have a Semantic Latent Space", "url": "http://arxiv.org/pdf/2210.10960v2", "summary": "Diffusion models achieve outstanding generative performance in various\ndomains. Despite their great success, they lack semantic latent space which is\nessential for controlling the generative process. To address the problem, we\npropose asymmetric reverse process (Asyrp) which discovers the semantic latent\nspace in frozen pretrained diffusion models. Our semantic latent space, named\nh-space, has nice properties for accommodating semantic image manipulation:\nhomogeneity, linearity, robustness, and consistency across timesteps. In\naddition, we introduce a principled design of the generative process for\nversatile editing and quality boost ing by quantifiable measures: editing\nstrength of an interval and quality deficiency at a timestep. Our method is\napplicable to various architectures (DDPM++, iD- DPM, and ADM) and datasets\n(CelebA-HQ, AFHQ-dog, LSUN-church, LSUN- bedroom, and METFACES). Project page:\nhttps://kwonminki.github.io/Asyrp/", "published": "2022-10-20T02:07:23Z", "version": 2}, {"aid": "2210.13545", "authors": ["Julius Ott", "Lorenzo Servadei", "Jose Arjona-Medina", "Enrico Rinaldi", "Gianfranco Mauro", "Daniela S\u00e1nchez Lopera", "Michael Stephan", "Thomas Stadelmayer", "Avik Santra", "Robert Wille"], "title": "MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling", "url": "http://arxiv.org/pdf/2210.13545v2", "summary": "Data selection is essential for any data-based optimization technique, such\nas Reinforcement Learning. State-of-the-art sampling strategies for the\nexperience replay buffer improve the performance of the Reinforcement Learning\nagent. However, they do not incorporate uncertainty in the Q-Value estimation.\nConsequently, they cannot adapt the sampling strategies, including exploration\nand exploitation of transitions, to the complexity of the task. To address\nthis, this paper proposes a new sampling strategy that leverages the\nexploration-exploitation trade-off. This is enabled by the uncertainty\nestimation of the Q-Value function, which guides the sampling to explore more\nsignificant transitions and, thus, learn a more efficient policy. Experiments\non classical control environments demonstrate stable results across various\nenvironments. They show that the proposed method outperforms state-of-the-art\nsampling strategies for dense rewards w.r.t. convergence and peak performance\nby 26% on average.", "published": "2022-10-24T18:55:41Z", "version": 2}, {"aid": "2211.01177", "authors": ["Gautam Singh", "Yeongbin Kim", "Sungjin Ahn"], "title": "Neural Systematic Binder", "url": "http://arxiv.org/pdf/2211.01177v3", "summary": "The key to high-level cognition is believed to be the ability to\nsystematically manipulate and compose knowledge pieces. While token-like\nstructured knowledge representations are naturally provided in text, it is\nelusive how to obtain them for unstructured modalities such as scene images. In\nthis paper, we propose a neural mechanism called Neural Systematic Binder or\nSysBinder for constructing a novel structured representation called Block-Slot\nRepresentation. In Block-Slot Representation, object-centric representations\nknown as slots are constructed by composing a set of independent factor\nrepresentations called blocks, to facilitate systematic generalization.\nSysBinder obtains this structure in an unsupervised way by alternatingly\napplying two different binding principles: spatial binding for spatial\nmodularity across the full scene and factor binding for factor modularity\nwithin an object. SysBinder is a simple, deterministic, and general-purpose\nlayer that can be applied as a drop-in module in any arbitrary neural network\nand on any modality. In experiments, we find that SysBinder provides\nsignificantly better factor disentanglement within the slots than the\nconventional object-centric methods, including, for the first time, in visually\ncomplex scene images such as CLEVR-Tex. Furthermore, we demonstrate\nfactor-level systematicity in controlled scene generation by decoding unseen\nfactor combinations.", "published": "2022-11-02T14:53:07Z", "version": 3}, {"aid": "2211.06291", "authors": ["Mrinank Sharma", "Sebastian Farquhar", "Eric Nalisnick", "Tom Rainforth"], "title": "Do Bayesian Neural Networks Need To Be Fully Stochastic?", "url": "http://arxiv.org/pdf/2211.06291v2", "summary": "We investigate the benefit of treating all the parameters in a Bayesian\nneural network stochastically and find compelling theoretical and empirical\nevidence that this standard construction may be unnecessary. To this end, we\nprove that expressive predictive distributions require only small amounts of\nstochasticity. In particular, partially stochastic networks with only $n$\nstochastic biases are universal probabilistic predictors for $n$-dimensional\npredictive problems. In empirical investigations, we find no systematic benefit\nof full stochasticity across four different inference modalities and eight\ndatasets; partially stochastic networks can match and sometimes even outperform\nfully stochastic networks, despite their reduced memory costs.", "published": "2022-11-11T16:00:21Z", "version": 2}, {"aid": "2211.12047", "authors": ["Alexander Ororbia", "Ankur Mali"], "title": "Convolutional Neural Generative Coding: Scaling Predictive Coding to Natural Images", "url": "http://arxiv.org/pdf/2211.12047v2", "summary": "In this work, we develop convolutional neural generative coding (Conv-NGC), a\ngeneralization of predictive coding to the case of\nconvolution/deconvolution-based computation. Specifically, we concretely\nimplement a flexible neurobiologically-motivated algorithm that progressively\nrefines latent state feature maps in order to dynamically form a more accurate\ninternal representation/reconstruction model of natural images. The performance\nof the resulting sensory processing system is evaluated on complex datasets\nsuch as Color-MNIST, CIFAR-10, and Street House View Numbers (SVHN). We study\nthe effectiveness of our brain-inspired model on the tasks of reconstruction\nand image denoising and find that it is competitive with convolutional\nauto-encoding systems trained by backpropagation of errors and outperforms them\nwith respect to out-of-distribution reconstruction (including the full 90k\nCINIC-10 test set).", "published": "2022-11-22T06:42:41Z", "version": 2}, {"aid": "2211.15115", "authors": ["Wenbin An", "Feng Tian", "Qinghua Zheng", "Wei Ding", "QianYing Wang", "Ping Chen"], "title": "Generalized Category Discovery with Decoupled Prototypical Network", "url": "http://arxiv.org/pdf/2211.15115v2", "summary": "Generalized Category Discovery (GCD) aims to recognize both known and novel\ncategories from a set of unlabeled data, based on another dataset labeled with\nonly known categories. Without considering differences between known and novel\ncategories, current methods learn about them in a coupled manner, which can\nhurt model's generalization and discriminative ability. Furthermore, the\ncoupled training approach prevents these models transferring category-specific\nknowledge explicitly from labeled data to unlabeled data, which can lose\nhigh-level semantic information and impair model performance. To mitigate above\nlimitations, we present a novel model called Decoupled Prototypical Network\n(DPN). By formulating a bipartite matching problem for category prototypes, DPN\ncan not only decouple known and novel categories to achieve different training\ntargets effectively, but also align known categories in labeled and unlabeled\ndata to transfer category-specific knowledge explicitly and capture high-level\nsemantics. Furthermore, DPN can learn more discriminative features for both\nknown and novel categories through our proposed Semantic-aware Prototypical\nLearning (SPL). Besides capturing meaningful semantic information, SPL can also\nalleviate the noise of hard pseudo labels through semantic-weighted soft\nassignment. Extensive experiments show that DPN outperforms state-of-the-art\nmodels by a large margin on all evaluation metrics across multiple benchmark\ndatasets. Code and data are available at https://github.com/Lackel/DPN.", "published": "2022-11-28T08:05:45Z", "version": 2}, {"aid": "2212.04247", "authors": ["Chengwei Zheng", "Wenbin Lin", "Feng Xu"], "title": "EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points", "url": "http://arxiv.org/pdf/2212.04247v2", "summary": "Neural radiance fields (NeRF) achieve highly photo-realistic novel-view\nsynthesis, but it's a challenging problem to edit the scenes modeled by\nNeRF-based methods, especially for dynamic scenes. We propose editable neural\nradiance fields that enable end-users to easily edit dynamic scenes and even\nsupport topological changes. Input with an image sequence from a single camera,\nour network is trained fully automatically and models topologically varying\ndynamics using our picked-out surface key points. Then end-users can edit the\nscene by easily dragging the key points to desired new positions. To achieve\nthis, we propose a scene analysis method to detect and initialize key points by\nconsidering the dynamics in the scene, and a weighted key points strategy to\nmodel topologically varying dynamics by joint key points and weights\noptimization. Our method supports intuitive multi-dimensional (up to 3D)\nediting and can generate novel scenes that are unseen in the input sequence.\nExperiments demonstrate that our method achieves high-quality editing on\nvarious dynamic scenes and outperforms the state-of-the-art. Our code and\ncaptured data are available at https://chengwei-zheng.github.io/EditableNeRF/.", "published": "2022-12-07T06:08:03Z", "version": 2}, {"aid": "2212.05895", "authors": ["Haibin He", "Xinyuan Chen", "Chaoyue Wang", "Juhua Liu", "Bo Du", "Dacheng Tao", "Yu Qiao"], "title": "Diff-Font: Diffusion Model for Robust One-Shot Font Generation", "url": "http://arxiv.org/pdf/2212.05895v3", "summary": "Font generation is a difficult and time-consuming task, especially in those\nlanguages using ideograms that have complicated structures with a large number\nof characters, such as Chinese. To solve this problem, few-shot font generation\nand even one-shot font generation have attracted a lot of attention. However,\nmost existing font generation methods may still suffer from (i) large\ncross-font gap challenge; (ii) subtle cross-font variation problem; and (iii)\nincorrect generation of complicated characters. In this paper, we propose a\nnovel one-shot font generation method based on a diffusion model, named\nDiff-Font, which can be stably trained on large datasets. The proposed model\naims to generate the entire font library by giving only one sample as the\nreference. Specifically, a large stroke-wise dataset is constructed, and a\nstroke-wise diffusion model is proposed to preserve the structure and the\ncompletion of each generated character. To our best knowledge, the proposed\nDiff-Font is the first work that developed diffusion models to handle the font\ngeneration task. The well-trained Diff-Font is not only robust to font gap and\nfont variation, but also achieved promising performance on difficult character\ngeneration. Compared to previous font generation methods, our model reaches\nstate-of-the-art performance both qualitatively and quantitatively.", "published": "2022-12-12T13:51:50Z", "version": 3}, {"aid": "2212.10602", "authors": ["Alexander Gorsky"], "title": "Page time and the order parameter for a consciousness state", "url": "http://arxiv.org/pdf/2212.10602v2", "summary": "In this short note using the analogy with the recent resolution of the black\nhole information paradox we conjecture the order parameter for the state of\nconsciousness based on the notion of the Page curve and the Page time. The\nentanglement between the state of the brain and time series of neuronal firing\nas well as the non-orthogonality of the functional connectomes play a key role.", "published": "2022-12-18T18:31:50Z", "version": 2}, {"aid": "2212.10048", "authors": ["Yang Jiao", "Kai Yang", "Tiancheng Wu", "Dongjin Song", "Chengtao Jian"], "title": "Asynchronous Distributed Bilevel Optimization", "url": "http://arxiv.org/pdf/2212.10048v3", "summary": "Bilevel optimization plays an essential role in many machine learning tasks,\nranging from hyperparameter optimization to meta-learning. Existing studies on\nbilevel optimization, however, focus on either centralized or synchronous\ndistributed setting. The centralized bilevel optimization approaches require\ncollecting massive amount of data to a single server, which inevitably incur\nsignificant communication expenses and may give rise to data privacy risks.\nSynchronous distributed bilevel optimization algorithms, on the other hand,\noften face the straggler problem and will immediately stop working if a few\nworkers fail to respond. As a remedy, we propose Asynchronous Distributed\nBilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel\noptimization problems with both nonconvex upper-level and lower-level objective\nfunctions, and its convergence is theoretically guaranteed. Furthermore, it is\nrevealed through theoretic analysis that the iteration complexity of ADBO to\nobtain the $\\epsilon$-stationary point is upper bounded by\n$\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public\ndatasets have been conducted to elucidate the effectiveness and efficiency of\nthe proposed ADBO.", "published": "2022-12-20T07:44:48Z", "version": 3}, {"aid": "2301.06907", "authors": ["Gabriel Turinici"], "title": "Deep Conditional Measure Quantization", "url": "http://arxiv.org/pdf/2301.06907v2", "summary": "Quantization of a probability measure means representing it with a finite set\nof Dirac masses that approximates the input distribution well enough (in some\nmetric space of probability measures). Various methods exists to do so, but the\nsituation of quantizing a conditional law has been less explored. We propose a\nmethod, called DCMQ, involving a Huber-energy kernel-based approach coupled\nwith a deep neural network architecture. The method is tested on several\nexamples and obtains promising results.", "published": "2023-01-17T14:18:17Z", "version": 2}, {"aid": "2301.07455", "authors": ["O. R. Kirubeswaran", "Katherine R. Storrs"], "title": "Inconsistent illusory motion in predictive coding deep neural networks", "url": "http://arxiv.org/pdf/2301.07455v2", "summary": "Why do we perceive illusory motion in some static images? Several accounts\nhave been proposed based on eye movements, response latencies to different\nimage elements, or interactions between image patterns and motion energy\ndetectors. Recently, PredNet, a recurrent deep neural network (DNN) based on\npredictive coding principles, was reported to reproduce the \"Rotating Snakes\"\nillusion, suggesting a role for predictive coding in illusory motion. We\nreplicate this finding and then use a series of \"in silico psychophysics\"\nexperiments to examine whether PredNet behaves consistently with human\nobservers for simplified variants of the illusory stimuli. We also measure\nresponse latencies to individual elements of the Rotating Snakes pattern by\nprobing internal units in the network. A pretrained PredNet model predicted\nillusory motion for all subcomponents of the Rotating Snakes stimulus,\nconsistent with human observers. However, we found no simple response delays in\ninternal units, as found in physiological data. The PredNet model's detection\nof motion in gradients was based on contrast, not luminance, as it is in human\nperception. Finally, we tested the robustness of the illusion on 10 identical\nPredNets trained on the same video data; we found a large variation in the\nability of the network to reproduce the illusion and predict motion for\nsimplified variants of the illusion. Also, unlike human observers, none of the\nnetworks predicted illusory motion for greyscale variants of the pattern. Even\nwhen a DNN successfully reproduces some idiosyncrasy of human vision, a more\ndetailed investigation can reveal inconsistencies between humans and the\nnetwork and between different instances of the same network. The inconsistency\nof the Rotating Snakes illusion in PredNets trained from different\ninitializations suggests that predictive coding does not reliably lead to\nhuman-like illusory motion.", "published": "2023-01-18T11:56:24Z", "version": 2}, {"aid": "2301.09245", "authors": ["Feng-Lei Fan", "Yingxin Li", "Hanchuan Peng", "Tieyong Zeng", "Fei Wang"], "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks", "url": "http://arxiv.org/pdf/2301.09245v2", "summary": "Throughout history, the development of artificial intelligence, particularly\nartificial neural networks, has been open to and constantly inspired by the\nincreasingly deepened understanding of the brain, such as the inspiration of\nneocognitron, which is the pioneering work of convolutional neural networks.\nPer the motives of the emerging field: NeuroAI, a great amount of neuroscience\nknowledge can help catalyze the next generation of AI by endowing a network\nwith more powerful capabilities. As we know, the human brain has numerous\nmorphologically and functionally different neurons, while artificial neural\nnetworks are almost exclusively built on a single neuron type. In the human\nbrain, neuronal diversity is an enabling factor for all kinds of biological\nintelligent behaviors. Since an artificial network is a miniature of the human\nbrain, introducing neuronal diversity should be valuable in terms of addressing\nthose essential problems of artificial networks such as efficiency,\ninterpretability, and memory. In this Primer, we first discuss the\npreliminaries of biological neuronal diversity and the characteristics of\ninformation transmission and processing in a biological neuron. Then, we review\nstudies of designing new neurons for artificial networks. Next, we discuss what\ngains can neuronal diversity bring into artificial networks and exemplary\napplications in several important fields. Lastly, we discuss the challenges and\nfuture directions of neuronal diversity to explore the potential of NeuroAI.", "published": "2023-01-23T02:23:45Z", "version": 2}, {"aid": "2301.09474", "authors": ["Qitian Wu", "Chenxiao Yang", "Wentao Zhao", "Yixuan He", "David Wipf", "Junchi Yan"], "title": "DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion", "url": "http://arxiv.org/pdf/2301.09474v4", "summary": "Real-world data generation often involves complex inter-dependencies among\ninstances, violating the IID-data hypothesis of standard learning paradigms and\nposing a challenge for uncovering the geometric structures for learning desired\ninstance representations. To this end, we introduce an energy constrained\ndiffusion model which encodes a batch of instances from a dataset into\nevolutionary states that progressively incorporate other instances' information\nby their interactions. The diffusion process is constrained by descent criteria\nw.r.t.~a principled energy function that characterizes the global consistency\nof instance representations over latent structures. We provide rigorous theory\nthat implies closed-form optimal estimates for the pairwise diffusion strength\namong arbitrary instance pairs, which gives rise to a new class of neural\nencoders, dubbed as DIFFormer (diffusion-based Transformers), with two\ninstantiations: a simple version with linear complexity for prohibitive\ninstance numbers, and an advanced version for learning complex structures.\nExperiments highlight the wide applicability of our model as a general-purpose\nencoder backbone with superior performance in various tasks, such as node\nclassification on large graphs, semi-supervised image/text classification, and\nspatial-temporal dynamics prediction.", "published": "2023-01-23T15:18:54Z", "version": 4}, {"aid": "2301.11108", "authors": ["David McAllester"], "title": "On the Mathematics of Diffusion Models", "url": "http://arxiv.org/pdf/2301.11108v3", "summary": "This paper gives direct derivations of the differential equations and\nlikelihood formulas of diffusion models assuming only knowledge of Gaussian\ndistributions. A VAE analysis derives both forward and backward stochastic\ndifferential equations (SDEs) as well as non-variational integral expressions\nfor likelihood formulas. A score-matching analysis derives the reverse\ndiffusion ordinary differential equation (ODE) and a family of\nreverse-diffusion SDEs parameterized by noise level. The paper presents the\nmathematics directly with attributions saved for a final section.", "published": "2023-01-25T16:39:00Z", "version": 3}, {"aid": "2301.11706", "authors": ["Mang Ning", "Enver Sangineto", "Angelo Porrello", "Simone Calderara", "Rita Cucchiara"], "title": "Input Perturbation Reduces Exposure Bias in Diffusion Models", "url": "http://arxiv.org/pdf/2301.11706v3", "summary": "Denoising Diffusion Probabilistic Models have shown an impressive generation\nquality, although their long sampling chain leads to high computational costs.\nIn this paper, we observe that a long sampling chain also leads to an error\naccumulation phenomenon, which is similar to the exposure bias problem in\nautoregressive text generation. Specifically, we note that there is a\ndiscrepancy between training and testing, since the former is conditioned on\nthe ground truth samples, while the latter is conditioned on the previously\ngenerated results. To alleviate this problem, we propose a very simple but\neffective training regularization, consisting in perturbing the ground truth\nsamples to simulate the inference time prediction errors. We empirically show\nthat, without affecting the recall and precision, the proposed input\nperturbation leads to a significant improvement in the sample quality while\nreducing both the training and the inference times. For instance, on CelebA\n64$\\times$64, we achieve a new state-of-the-art FID score of 1.27, while saving\n37.5% of the training time. The code is publicly available at\nhttps://github.com/forever208/DDPM-IP", "published": "2023-01-27T13:34:54Z", "version": 3}, {"aid": "2301.12935", "authors": ["Shengmeng Li", "Luping Liu", "Zenghao Chai", "Runnan Li", "Xu Tan"], "title": "ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2301.12935v3", "summary": "Though denoising diffusion probabilistic models (DDPMs) have achieved\nremarkable generation results, the low sampling efficiency of DDPMs still\nlimits further applications. Since DDPMs can be formulated as diffusion\nordinary differential equations (ODEs), various fast sampling methods can be\nderived from solving diffusion ODEs. However, we notice that previous sampling\nmethods with fixed analytical form are not robust with the error in the noise\nestimated from pretrained diffusion models. In this work, we construct an\nerror-robust Adams solver (ERA-Solver), which utilizes the implicit Adams\nnumerical method that consists of a predictor and a corrector. Different from\nthe traditional predictor based on explicit Adams methods, we leverage a\nLagrange interpolation function as the predictor, which is further enhanced\nwith an error-robust strategy to adaptively select the Lagrange bases with\nlower error in the estimated noise. Experiments on Cifar10, LSUN-Church, and\nLSUN-Bedroom datasets demonstrate that our proposed ERA-Solver achieves 5.14,\n9.42, and 9.69 Fenchel Inception Distance (FID) for image generation, with only\n10 network evaluations.", "published": "2023-01-30T14:32:47Z", "version": 3}, {"aid": "2302.00487", "authors": ["Liyuan Wang", "Xingxing Zhang", "Hang Su", "Jun Zhu"], "title": "A Comprehensive Survey of Continual Learning: Theory, Method and Application", "url": "http://arxiv.org/pdf/2302.00487v3", "summary": "To cope with real-world dynamics, an intelligent system needs to\nincrementally acquire, update, accumulate, and exploit knowledge throughout its\nlifetime. This ability, known as continual learning, provides a foundation for\nAI systems to develop themselves adaptively. In a general sense, continual\nlearning is explicitly limited by catastrophic forgetting, where learning a new\ntask usually results in a dramatic performance degradation of the old tasks.\nBeyond this, increasingly numerous advances have emerged in recent years that\nlargely extend the understanding and application of continual learning. The\ngrowing and widespread interest in this direction demonstrates its realistic\nsignificance as well as complexity. In this work, we present a comprehensive\nsurvey of continual learning, seeking to bridge the basic settings, theoretical\nfoundations, representative methods, and practical applications. Based on\nexisting theoretical and empirical results, we summarize the general objectives\nof continual learning as ensuring a proper stability-plasticity trade-off and\nan adequate intra/inter-task generalizability in the context of resource\nefficiency. Then we provide a state-of-the-art and elaborated taxonomy,\nextensively analyzing how representative methods address continual learning,\nand how they are adapted to particular challenges in realistic applications.\nThrough an in-depth discussion of promising directions, we believe that such a\nholistic perspective can greatly facilitate subsequent exploration in this\nfield and beyond.", "published": "2023-01-31T11:34:56Z", "version": 3}, {"aid": "2302.00626", "authors": ["Chun-Wun Cheng", "Christina Runkel", "Lihao Liu", "Raymond H Chan", "Carola-Bibiane Sch\u00f6nlieb", "Angelica I Aviles-Rivero"], "title": "Continuous U-Net: Faster, Greater and Noiseless", "url": "http://arxiv.org/pdf/2302.00626v1", "summary": "Image segmentation is a fundamental task in image analysis and clinical\npractice. The current state-of-the-art techniques are based on U-shape type\nencoder-decoder networks with skip connections, called U-Net. Despite the\npowerful performance reported by existing U-Net type networks, they suffer from\nseveral major limitations. Issues include the hard coding of the receptive\nfield size, compromising the performance and computational cost, as well as the\nfact that they do not account for inherent noise in the data. They have\nproblems associated with discrete layers, and do not offer any theoretical\nunderpinning. In this work we introduce continuous U-Net, a novel family of\nnetworks for image segmentation. Firstly, continuous U-Net is a continuous deep\nneural network that introduces new dynamic blocks modelled by second order\nordinary differential equations. Secondly, we provide theoretical guarantees\nfor our network demonstrating faster convergence, higher robustness and less\nsensitivity to noise. Thirdly, we derive qualitative measures to tailor-made\nsegmentation tasks. We demonstrate, through extensive numerical and visual\nresults, that our model outperforms existing U-Net blocks for several medical\nimage segmentation benchmarking datasets.", "published": "2023-02-01T17:46:00Z", "version": 1}, {"aid": "2302.00670", "authors": ["Yilun Xu", "Shangyuan Tong", "Tommi Jaakkola"], "title": "Stable Target Field for Reduced Variance Score Estimation in Diffusion Models", "url": "http://arxiv.org/pdf/2302.00670v2", "summary": "Diffusion models generate samples by reversing a fixed forward diffusion\nprocess. Despite already providing impressive empirical results, these\ndiffusion models algorithms can be further improved by reducing the variance of\nthe training targets in their denoising score-matching objective. We argue that\nthe source of such variance lies in the handling of intermediate noise-variance\nscales, where multiple modes in the data affect the direction of reverse paths.\nWe propose to remedy the problem by incorporating a reference batch which we\nuse to calculate weighted conditional scores as more stable training targets.\nWe show that the procedure indeed helps in the challenging intermediate regime\nby reducing (the trace of) the covariance of training targets. The new stable\ntargets can be seen as trading bias for reduced variance, where the bias\nvanishes with increasing reference batch size. Empirically, we show that the\nnew objective improves the image quality, stability, and training speed of\nvarious popular diffusion models across datasets with both general ODE and SDE\nsolvers. When used in combination with EDM, our method yields a current SOTA\nFID of 1.90 with 35 network evaluations on the unconditional CIFAR-10\ngeneration task. The code is available at https://github.com/Newbeeer/stf", "published": "2023-02-01T18:57:01Z", "version": 2}, {"aid": "2302.00727", "authors": ["Sing-Yuan Yeh", "Fu-Chieh Chang", "Chang-Wei Yueh", "Pei-Yuan Wu", "Alberto Bernacchia", "Sattar Vakili"], "title": "Sample Complexity of Kernel-Based Q-Learning", "url": "http://arxiv.org/pdf/2302.00727v1", "summary": "Modern reinforcement learning (RL) often faces an enormous state-action\nspace. Existing analytical results are typically for settings with a small\nnumber of state-actions, or simple models such as linearly modeled Q-functions.\nTo derive statistically efficient RL policies handling large state-action\nspaces, with more general Q-functions, some recent works have considered\nnonlinear function approximation using kernel ridge regression. In this work,\nwe derive sample complexities for kernel based Q-learning when a generative\nmodel exists. We propose a nonparametric Q-learning algorithm which finds an\n$\\epsilon$-optimal policy in an arbitrarily large scale discounted MDP. The\nsample complexity of the proposed algorithm is order optimal with respect to\n$\\epsilon$ and the complexity of the kernel (in terms of its information gain).\nTo the best of our knowledge, this is the first result showing a finite sample\ncomplexity under such a general model.", "published": "2023-02-01T19:46:25Z", "version": 1}, {"aid": "2302.01404", "authors": ["Suhas Kotha", "Christopher Brix", "Zico Kolter", "Krishnamurthy Dvijotham", "Huan Zhang"], "title": "Provably Bounding Neural Network Preimages", "url": "http://arxiv.org/pdf/2302.01404v4", "summary": "Most work on the formal verification of neural networks has focused on\nbounding the set of outputs that correspond to a given set of inputs (for\nexample, bounded perturbations of a nominal input). However, many use cases of\nneural network verification require solving the inverse problem, or\nover-approximating the set of inputs that lead to certain outputs. We present\nthe INVPROP algorithm for verifying properties over the preimage of a linearly\nconstrained output set, which can be combined with branch-and-bound to increase\nprecision. Contrary to other approaches, our efficient algorithm is\nGPU-accelerated and does not require a linear programming solver. We\ndemonstrate our algorithm for identifying safe control regions for a dynamical\nsystem via backward reachability analysis, verifying adversarial robustness,\nand detecting out-of-distribution inputs to a neural network. Our results show\nthat in certain settings, we find over-approximations over 2500x tighter than\nprior work while being 2.5x faster. By strengthening robustness verification\nwith output constraints, we consistently verify more properties than the\nprevious state-of-the-art on multiple benchmarks, including a large model with\n167k neurons in VNN-COMP 2023. Our algorithm has been incorporated into the\n$\\alpha,\\!\\beta$-CROWN verifier, available at https://abcrown.org.", "published": "2023-02-02T20:34:45Z", "version": 4}, {"aid": "2302.02234", "authors": ["Lingyan Ruan", "Mojtaba Bemana", "Hans-peter Seidel", "Karol Myszkowski", "Bin Chen"], "title": "Revisiting Image Deblurring with an Efficient ConvNet", "url": "http://arxiv.org/pdf/2302.02234v1", "summary": "Image deblurring aims to recover the latent sharp image from its blurry\ncounterpart and has a wide range of applications in computer vision. The\nConvolution Neural Networks (CNNs) have performed well in this domain for many\nyears, and until recently an alternative network architecture, namely\nTransformer, has demonstrated even stronger performance. One can attribute its\nsuperiority to the multi-head self-attention (MHSA) mechanism, which offers a\nlarger receptive field and better input content adaptability than CNNs.\nHowever, as MHSA demands high computational costs that grow quadratically with\nrespect to the input resolution, it becomes impractical for high-resolution\nimage deblurring tasks. In this work, we propose a unified lightweight CNN\nnetwork that features a large effective receptive field (ERF) and demonstrates\ncomparable or even better performance than Transformers while bearing less\ncomputational costs. Our key design is an efficient CNN block dubbed LaKD,\nequipped with a large kernel depth-wise convolution and spatial-channel mixing\nstructure, attaining comparable or larger ERF than Transformers but with a\nsmaller parameter scale. Specifically, we achieve +0.17dB / +0.43dB PSNR over\nthe state-of-the-art Restormer on defocus / motion deblurring benchmark\ndatasets with 32% fewer parameters and 39% fewer MACs. Extensive experiments\ndemonstrate the superior performance of our network and the effectiveness of\neach module. Furthermore, we propose a compact and intuitive ERFMeter metric\nthat quantitatively characterizes ERF, and shows a high correlation to the\nnetwork performance. We hope this work can inspire the research community to\nfurther explore the pros and cons of CNN and Transformer architectures beyond\nimage deblurring tasks.", "published": "2023-02-04T20:42:46Z", "version": 1}, {"aid": "2302.10184", "authors": ["Zhongzhan Huang", "Mingfu Liang", "Shanshan Zhong", "Liang Lin"], "title": "AttNS: Attention-Inspired Numerical Solving For Limited Data Scenarios", "url": "http://arxiv.org/pdf/2302.10184v2", "summary": "We propose the attention-inspired numerical solver (AttNS), a concise method\nthat helps the generalization and robustness issues faced by the AI-Hybrid\nnumerical solver in solving differential equations due to limited data. AttNS\nis inspired by the effectiveness of attention modules in Residual Neural\nNetworks (ResNet) in enhancing model generalization and robustness for\nconventional deep learning tasks. Drawing from the dynamical system perspective\nof ResNet, we seamlessly incorporate attention mechanisms into the design of\nnumerical methods tailored for the characteristics of solving differential\nequations. Our results on benchmarks, ranging from high-dimensional problems to\nchaotic systems, showcases AttNS consistently enhancing various numerical\nsolvers without any intricate model crafting. Finally, we analyze AttNS\nexperimentally and theoretically, demonstrating its ability to achieve strong\ngeneralization and robustness while ensuring the convergence of the solver.\nThis includes requiring less data compared to other advanced methods to achieve\ncomparable generalization errors and better prevention of numerical explosion\nissues when solving differential equations.", "published": "2023-02-05T01:39:21Z", "version": 2}, {"aid": "2302.02334", "authors": ["Chenyu Zheng", "Guoqiang Wu", "Fan Bao", "Yue Cao", "Chongxuan Li", "Jun Zhu"], "title": "Revisiting Discriminative vs. Generative Classifiers: Theory and Implications", "url": "http://arxiv.org/pdf/2302.02334v2", "summary": "A large-scale deep model pre-trained on massive labeled or unlabeled data\ntransfers well to downstream tasks. Linear evaluation freezes parameters in the\npre-trained model and trains a linear classifier separately, which is efficient\nand attractive for transfer. However, little work has investigated the\nclassifier in linear evaluation except for the default logistic regression.\nInspired by the statistical efficiency of naive Bayes, the paper revisits the\nclassical topic on discriminative vs. generative classifiers. Theoretically,\nthe paper considers the surrogate loss instead of the zero-one loss in analyses\nand generalizes the classical results from binary cases to multiclass ones. We\nshow that, under mild assumptions, multiclass naive Bayes requires $O(\\log n)$\nsamples to approach its asymptotic error while the corresponding multiclass\nlogistic regression requires $O(n)$ samples, where $n$ is the feature\ndimension. To establish it, we present a multiclass $\\mathcal{H}$-consistency\nbound framework and an explicit bound for logistic loss, which are of\nindependent interests. Simulation results on a mixture of Gaussian validate our\ntheoretical findings. Experiments on various pre-trained deep vision models\nshow that naive Bayes consistently converges faster as the number of data\nincreases. Besides, naive Bayes shows promise in few-shot cases and we observe\nthe \"two regimes\" phenomenon in pre-trained supervised models. Our code is\navailable at https://github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers.", "published": "2023-02-05T08:30:42Z", "version": 2}, {"aid": "2302.03225", "authors": ["Yu-Neng Chuang", "Guanchu Wang", "Fan Yang", "Zirui Liu", "Xuanting Cai", "Mengnan Du", "Xia Hu"], "title": "Efficient XAI Techniques: A Taxonomic Survey", "url": "http://arxiv.org/pdf/2302.03225v2", "summary": "Recently, there has been a growing demand for the deployment of Explainable\nArtificial Intelligence (XAI) algorithms in real-world applications. However,\ntraditional XAI methods typically suffer from a high computational complexity\nproblem, which discourages the deployment of real-time systems to meet the\ntime-demanding requirements of real-world scenarios. Although many approaches\nhave been proposed to improve the efficiency of XAI methods, a comprehensive\nunderstanding of the achievements and challenges is still needed. To this end,\nin this paper we provide a review of efficient XAI. Specifically, we categorize\nexisting techniques of XAI acceleration into efficient non-amortized and\nefficient amortized methods. The efficient non-amortized methods focus on\ndata-centric or model-centric acceleration upon each individual instance. In\ncontrast, amortized methods focus on learning a unified distribution of model\nexplanations, following the predictive, generative, or reinforcement\nframeworks, to rapidly derive multiple model explanations. We also analyze the\nlimitations of an efficient XAI pipeline from the perspectives of the training\nphase, the deployment phase, and the use scenarios. Finally, we summarize the\nchallenges of deploying XAI acceleration methods to real-world scenarios,\novercoming the trade-off between faithfulness and efficiency, and the selection\nof different acceleration methods.", "published": "2023-02-07T03:15:38Z", "version": 2}, {"aid": "2302.03686", "authors": ["Andy Shih", "Dorsa Sadigh", "Stefano Ermon"], "title": "Long Horizon Temperature Scaling", "url": "http://arxiv.org/pdf/2302.03686v2", "summary": "Temperature scaling is a popular technique for tuning the sharpness of a\nmodel distribution. It is used extensively for sampling likely generations and\ncalibrating model uncertainty, and even features as a controllable parameter to\nmany large language models in deployment. However, autoregressive models rely\non myopic temperature scaling that greedily optimizes the next token. To\naddress this, we propose Long Horizon Temperature Scaling (LHTS), a novel\napproach for sampling from temperature-scaled joint distributions. LHTS is\ncompatible with all likelihood-based models, and optimizes for the long horizon\nlikelihood of samples. We derive a temperature-dependent LHTS objective, and\nshow that finetuning a model on a range of temperatures produces a single model\ncapable of generation with a controllable long horizon temperature parameter.\nWe experiment with LHTS on image diffusion models and character/language\nautoregressive models, demonstrating advantages over myopic temperature scaling\nin likelihood and sample quality, and showing improvements in accuracy on a\nmultiple choice analogy task by $10\\%$.", "published": "2023-02-07T18:59:32Z", "version": 2}, {"aid": "2302.03750", "authors": ["Hao Liang", "Josue Ortega Caro", "Vikram Maheshri", "Ankit B. Patel", "Guha Balakrishnan"], "title": "Linking convolutional kernel size to generalization bias in face analysis CNNs", "url": "http://arxiv.org/pdf/2302.03750v2", "summary": "Training dataset biases are by far the most scrutinized factors when\nexplaining algorithmic biases of neural networks. In contrast, hyperparameters\nrelated to the neural network architecture have largely been ignored even\nthough different network parameterizations are known to induce different\nimplicit biases over learned features. For example, convolutional kernel size\nis known to affect the frequency content of features learned in CNNs. In this\nwork, we present a causal framework for linking an architectural hyperparameter\nto out-of-distribution algorithmic bias. Our framework is experimental, in that\nwe train several versions of a network with an intervention to a specific\nhyperparameter, and measure the resulting causal effect of this choice on\nperformance bias when a particular out-of-distribution image perturbation is\napplied. In our experiments, we focused on measuring the causal relationship\nbetween convolutional kernel size and face analysis classification bias across\ndifferent subpopulations (race/gender), with respect to high-frequency image\ndetails. We show that modifying kernel size, even in one layer of a CNN,\nchanges the frequency content of learned features significantly across data\nsubgroups leading to biased generalization performance even in the presence of\na balanced dataset.", "published": "2023-02-07T20:55:09Z", "version": 2}, {"aid": "2302.03763", "authors": ["Richard Gast", "Thomas R. Kn\u00f6sche", "Ann Kennedy"], "title": "PyRates -- A Code-Generation Tool for Dynamical Systems Modeling", "url": "http://arxiv.org/pdf/2302.03763v2", "summary": "Mathematical models allow us to gain a deeper understanding of real-world\ndynamical systems. One of the most powerful mathematical frameworks for\nmodeling real-world phenomena are systems of differential equations. In the\nmajority of fields that use differential equations, numerical methods are\nessential for conducting model-based research. Although many software solutions\nare available for the numerical study of differential equation systems, a\ncommon framework for implementing differential equation systems is lacking.\nThis hinders progress in dynamical systems research and limits the shareability\nand reproducibility of results.\n  PyRates is a Python-based software for modeling and analyzing dynamical\nsystems. It provides a user-friendly interface for defining models, which is\nbased on a graph-based, hierarchical structure that mirrors the modular\norganization of real-world dynamical systems. This design allows users to\nleverage the hierarchical structure of their systems and create their models\nwith minimal effort.\n  Importantly, the core of PyRates is a versatile code-generation system, which\ncan translate user-defined models into \"backend\" implementations in various\nlanguages, including Python, Fortran, and Julia. This allows users to access a\nwide range of analysis methods for dynamical systems, eliminating the need for\nmanual translation between code bases.\n  We demonstrate PyRates's capabilities in three use cases, where it generates\nNumPy code for numerical simulations, Fortran code for bifurcation analysis,\nand PyTorch code for neural network optimization. Finally, PyRates can be used\nas a model definition interface for the creation of new dynamical systems\ntools. We developed two such software packages, PyCoBi and RectiPy, as\nextensions of PyRates for specific dynamical systems modeling applications.", "published": "2023-02-07T21:43:40Z", "version": 2}, {"aid": "2302.03830", "authors": ["Mohammad Farazi", "Zhangsihao Yang", "Wenhui Zhu", "Peijie Qiu", "Yalin Wang"], "title": "TetCNN: Convolutional Neural Networks on Tetrahedral Meshes", "url": "http://arxiv.org/pdf/2302.03830v2", "summary": "Convolutional neural networks (CNN) have been broadly studied on images,\nvideos, graphs, and triangular meshes. However, it has seldom been studied on\ntetrahedral meshes. Given the merits of using volumetric meshes in applications\nlike brain image analysis, we introduce a novel interpretable graph CNN\nframework for the tetrahedral mesh structure. Inspired by ChebyNet, our model\nexploits the volumetric Laplace-Beltrami Operator (LBO) to define filters over\ncommonly used graph Laplacian which lacks the Riemannian metric information of\n3D manifolds. For pooling adaptation, we introduce new objective functions for\nlocalized minimum cuts in the Graclus algorithm based on the LBO. We employ a\npiece-wise constant approximation scheme that uses the clustering assignment\nmatrix to estimate the LBO on sampled meshes after each pooling. Finally,\nadapting the Gradient-weighted Class Activation Mapping algorithm for\ntetrahedral meshes, we use the obtained heatmaps to visualize discovered\nregions-of-interest as biomarkers. We demonstrate the effectiveness of our\nmodel on cortical tetrahedral meshes from patients with Alzheimer's disease, as\nthere is scientific evidence showing the correlation of cortical thickness to\nneurodegenerative disease progression. Our results show the superiority of our\nLBO-based convolution layer and adapted pooling over the conventionally used\nunitary cortical thickness, graph Laplacian, and point cloud representation.", "published": "2023-02-08T01:52:48Z", "version": 2}, {"aid": "2302.04304", "authors": ["Xiuyu Li", "Yijiang Liu", "Long Lian", "Huanrui Yang", "Zhen Dong", "Daniel Kang", "Shanghang Zhang", "Kurt Keutzer"], "title": "Q-Diffusion: Quantizing Diffusion Models", "url": "http://arxiv.org/pdf/2302.04304v3", "summary": "Diffusion models have achieved great success in image synthesis through\niterative noise estimation using deep neural networks. However, the slow\ninference, high memory consumption, and computation intensity of the noise\nestimation model hinder the efficient adoption of diffusion models. Although\npost-training quantization (PTQ) is considered a go-to compression method for\nother tasks, it does not work out-of-the-box on diffusion models. We propose a\nnovel PTQ method specifically tailored towards the unique multi-timestep\npipeline and model architecture of the diffusion models, which compresses the\nnoise estimation network to accelerate the generation process. We identify the\nkey difficulty of diffusion model quantization as the changing output\ndistributions of noise estimation networks over multiple time steps and the\nbimodal activation distribution of the shortcut layers within the noise\nestimation network. We tackle these challenges with timestep-aware calibration\nand split shortcut quantization in this work. Experimental results show that\nour proposed method is able to quantize full-precision unconditional diffusion\nmodels into 4-bit while maintaining comparable performance (small FID change of\nat most 2.34 compared to >100 for traditional PTQ) in a training-free manner.\nOur approach can also be applied to text-guided image generation, where we can\nrun stable diffusion in 4-bit weights with high generation quality for the\nfirst time.", "published": "2023-02-08T19:38:59Z", "version": 3}, {"aid": "2302.05017", "authors": ["Bingnan Wang", "Fanjiang Xu", "Quan Zheng"], "title": "A survey on facial image deblurring", "url": "http://arxiv.org/pdf/2302.05017v2", "summary": "When a facial image is blurred, it significantly affects high-level vision\ntasks such as face recognition. The purpose of facial image deblurring is to\nrecover a clear image from a blurry input image, which can improve the\nrecognition accuracy, etc. However, general deblurring methods do not perform\nwell on facial images. Therefore, some face deblurring methods have been\nproposed to improve performance by adding semantic or structural information as\nspecific priors according to the characteristics of the facial images. In this\npaper, we survey and summarize recently published methods for facial image\ndeblurring, most of which are based on deep learning. First, we provide a brief\nintroduction to the modeling of image blurring. Next, we summarize face\ndeblurring methods into two categories: model-based methods and deep\nlearning-based methods. Furthermore, we summarize the datasets, loss functions,\nand performance evaluation metrics commonly used in the neural network training\nprocess. We show the performance of classical methods on these datasets and\nmetrics and provide a brief discussion on the differences between model-based\nand learning-based methods. Finally, we discuss the current challenges and\npossible future research directions.", "published": "2023-02-10T02:24:56Z", "version": 2}, {"aid": "2302.05282", "authors": ["Daniele Paliotta", "Mathieu Alain", "B\u00e1lint M\u00e1t\u00e9", "Fran\u00e7ois Fleuret"], "title": "Graph Neural Networks Go Forward-Forward", "url": "http://arxiv.org/pdf/2302.05282v1", "summary": "We present the Graph Forward-Forward (GFF) algorithm, an extension of the\nForward-Forward procedure to graphs, able to handle features distributed over a\ngraph's nodes. This allows training graph neural networks with forward passes\nonly, without backpropagation. Our method is agnostic to the message-passing\nscheme, and provides a more biologically plausible learning scheme than\nbackpropagation, while also carrying computational advantages. With GFF, graph\nneural networks are trained greedily layer by layer, using both positive and\nnegative samples. We run experiments on 11 standard graph property prediction\ntasks, showing how GFF provides an effective alternative to backpropagation for\ntraining graph neural networks. This shows in particular that this procedure is\nremarkably efficient in spite of combining the per-layer training with the\nlocality of the processing in a GNN.", "published": "2023-02-10T14:45:36Z", "version": 1}, {"aid": "2302.05872", "authors": ["Guan-Horng Liu", "Arash Vahdat", "De-An Huang", "Evangelos A. Theodorou", "Weili Nie", "Anima Anandkumar"], "title": "I$^2$SB: Image-to-Image Schr\u00f6dinger Bridge", "url": "http://arxiv.org/pdf/2302.05872v3", "summary": "We propose Image-to-Image Schr\\\"odinger Bridge (I$^2$SB), a new class of\nconditional diffusion models that directly learn the nonlinear diffusion\nprocesses between two given distributions. These diffusion bridges are\nparticularly useful for image restoration, as the degraded images are\nstructurally informative priors for reconstructing the clean images. I$^2$SB\nbelongs to a tractable class of Schr\\\"odinger bridge, the nonlinear extension\nto score-based models, whose marginal distributions can be computed\nanalytically given boundary pairs. This results in a simulation-free framework\nfor nonlinear diffusions, where the I$^2$SB training becomes scalable by\nadopting practical techniques used in standard diffusion models. We validate\nI$^2$SB in solving various image restoration tasks, including inpainting,\nsuper-resolution, deblurring, and JPEG restoration on ImageNet 256x256 and show\nthat I$^2$SB surpasses standard conditional diffusion models with more\ninterpretable generative processes. Moreover, I$^2$SB matches the performance\nof inverse methods that additionally require the knowledge of the corruption\noperators. Our work opens up new algorithmic opportunities for developing\nefficient nonlinear diffusion models on a large scale. scale. Project page and\ncodes: https://i2sb.github.io/", "published": "2023-02-12T08:35:39Z", "version": 3}, {"aid": "2302.06403", "authors": ["Xu Ji", "Eric Elmoznino", "George Deane", "Axel Constant", "Guillaume Dumas", "Guillaume Lajoie", "Jonathan Simon", "Yoshua Bengio"], "title": "Sources of Richness and Ineffability for Phenomenally Conscious States", "url": "http://arxiv.org/pdf/2302.06403v5", "summary": "Conscious states (states that there is something it is like to be in) seem\nboth rich or full of detail, and ineffable or hard to fully describe or recall.\nThe problem of ineffability, in particular, is a longstanding issue in\nphilosophy that partly motivates the explanatory gap: the belief that\nconsciousness cannot be reduced to underlying physical processes. Here, we\nprovide an information theoretic dynamical systems perspective on the richness\nand ineffability of consciousness. In our framework, the richness of conscious\nexperience corresponds to the amount of information in a conscious state and\nineffability corresponds to the amount of information lost at different stages\nof processing. We describe how attractor dynamics in working memory would\ninduce impoverished recollections of our original experiences, how the discrete\nsymbolic nature of language is insufficient for describing the rich and\nhigh-dimensional structure of experiences, and how similarity in the cognitive\nfunction of two individuals relates to improved communicability of their\nexperiences to each other. While our model may not settle all questions\nrelating to the explanatory gap, it makes progress toward a fully physicalist\nexplanation of the richness and ineffability of conscious experience: two\nimportant aspects that seem to be part of what makes qualitative character so\npuzzling.", "published": "2023-02-13T14:41:04Z", "version": 5}, {"aid": "2302.06833", "authors": ["Kyle Sargent", "Jing Yu Koh", "Han Zhang", "Huiwen Chang", "Charles Herrmann", "Pratul Srinivasan", "Jiajun Wu", "Deqing Sun"], "title": "VQ3D: Learning a 3D-Aware Generative Model on ImageNet", "url": "http://arxiv.org/pdf/2302.06833v1", "summary": "Recent work has shown the possibility of training generative models of 3D\ncontent from 2D image collections on small datasets corresponding to a single\nobject class, such as human faces, animal faces, or cars. However, these models\nstruggle on larger, more complex datasets. To model diverse and unconstrained\nimage collections such as ImageNet, we present VQ3D, which introduces a\nNeRF-based decoder into a two-stage vector-quantized autoencoder. Our Stage 1\nallows for the reconstruction of an input image and the ability to change the\ncamera position around the image, and our Stage 2 allows for the generation of\nnew 3D scenes. VQ3D is capable of generating and reconstructing 3D-aware images\nfrom the 1000-class ImageNet dataset of 1.2 million training images. We achieve\nan ImageNet generation FID score of 16.8, compared to 69.8 for the next best\nbaseline method.", "published": "2023-02-14T05:15:16Z", "version": 1}, {"aid": "2302.07167", "authors": ["Daniel Nyga", "Mareike Picklum", "Tom Schierenbeck", "Michael Beetz"], "title": "Joint Probability Trees", "url": "http://arxiv.org/pdf/2302.07167v1", "summary": "We introduce Joint Probability Trees (JPT), a novel approach that makes\nlearning of and reasoning about joint probability distributions tractable for\npractical applications. JPTs support both symbolic and subsymbolic variables in\na single hybrid model, and they do not rely on prior knowledge about variable\ndependencies or families of distributions. JPT representations build on tree\nstructures that partition the problem space into relevant subregions that are\nelicited from the training data instead of postulating a rigid dependency model\nprior to learning. Learning and reasoning scale linearly in JPTs, and the tree\nstructure allows white-box reasoning about any posterior probability $P(Q|E)$,\nsuch that interpretable explanations can be provided for any inference result.\nOur experiments showcase the practical applicability of JPTs in\nhigh-dimensional heterogeneous probability spaces with millions of training\nsamples, making it a promising alternative to classic probabilistic graphical\nmodels.", "published": "2023-02-14T16:29:41Z", "version": 1}, {"aid": "2302.07238", "authors": ["Thamsanqa Mlotshwa", "Heinrich van Deventer", "Anna Sergeevna Bosman"], "title": "Cauchy Loss Function: Robustness Under Gaussian and Cauchy Noise", "url": "http://arxiv.org/pdf/2302.07238v1", "summary": "In supervised machine learning, the choice of loss function implicitly\nassumes a particular noise distribution over the data. For example, the\nfrequently used mean squared error (MSE) loss assumes a Gaussian noise\ndistribution. The choice of loss function during training and testing affects\nthe performance of artificial neural networks (ANNs). It is known that MSE may\nyield substandard performance in the presence of outliers. The Cauchy loss\nfunction (CLF) assumes a Cauchy noise distribution, and is therefore\npotentially better suited for data with outliers. This papers aims to determine\nthe extent of robustness and generalisability of the CLF as compared to MSE.\nCLF and MSE are assessed on a few handcrafted regression problems, and a\nreal-world regression problem with artificially simulated outliers, in the\ncontext of ANN training. CLF yielded results that were either comparable to or\nbetter than the results yielded by MSE, with a few notable exceptions.", "published": "2023-02-14T18:34:44Z", "version": 1}, {"aid": "2302.07253", "authors": ["Benjamin Hoover", "Yuchen Liang", "Bao Pham", "Rameswar Panda", "Hendrik Strobelt", "Duen Horng Chau", "Mohammed J. Zaki", "Dmitry Krotov"], "title": "Energy Transformer", "url": "http://arxiv.org/pdf/2302.07253v2", "summary": "Our work combines aspects of three promising paradigms in machine learning,\nnamely, attention mechanism, energy-based models, and associative memory.\nAttention is the power-house driving modern deep learning successes, but it\nlacks clear theoretical foundations. Energy-based models allow a principled\napproach to discriminative and generative tasks, but the design of the energy\nfunctional is not straightforward. At the same time, Dense Associative Memory\nmodels or Modern Hopfield Networks have a well-established theoretical\nfoundation, and allow an intuitive design of the energy function. We propose a\nnovel architecture, called the Energy Transformer (or ET for short), that uses\na sequence of attention layers that are purposely designed to minimize a\nspecifically engineered energy function, which is responsible for representing\nthe relationships between the tokens. In this work, we introduce the\ntheoretical foundations of ET, explore its empirical capabilities using the\nimage completion task, and obtain strong quantitative results on the graph\nanomaly detection and graph classification tasks.", "published": "2023-02-14T18:51:22Z", "version": 2}, {"aid": "2302.07350", "authors": ["J. Swaroop Guntupalli", "Rajkumar Vasudeva Raju", "Shrinu Kushagra", "Carter Wendelken", "Danny Sawyer", "Ishan Deshpande", "Guangyao Zhou", "Miguel L\u00e1zaro-Gredilla", "Dileep George"], "title": "Graph schemas as abstractions for transfer learning, inference, and planning", "url": "http://arxiv.org/pdf/2302.07350v2", "summary": "Transferring latent structure from one environment or problem to another is a\nmechanism by which humans and animals generalize with very little data.\nInspired by cognitive and neurobiological insights, we propose graph schemas as\na mechanism of abstraction for transfer learning. Graph schemas start with\nlatent graph learning where perceptually aliased observations are disambiguated\nin the latent space using contextual information. Latent graph learning is also\nemerging as a new computational model of the hippocampus to explain map\nlearning and transitive inference. Our insight is that a latent graph can be\ntreated as a flexible template -- a schema -- that models concepts and\nbehaviors, with slots that bind groups of latent nodes to the specific\nobservations or groundings. By treating learned latent graphs (schemas) as\nprior knowledge, new environments can be quickly learned as compositions of\nschemas and their newly learned bindings. We evaluate graph schemas on two\npreviously published challenging tasks: the memory & planning game and one-shot\nStreetLearn, which are designed to test rapid task solving in novel\nenvironments. Graph schemas can be learned in far fewer episodes than previous\nbaselines, and can model and plan in a few steps in novel variations of these\ntasks. We also demonstrate learning, matching, and reusing graph schemas in\nmore challenging 2D and 3D environments with extensive perceptual aliasing and\nsize variations, and show how different schemas can be composed to model larger\nand more complex environments. To summarize, our main contribution is a unified\nsystem, inspired and grounded in cognitive science, that facilitates rapid\ntransfer learning of new environments using schemas via map-induction and\ncomposition that handles perceptual aliasing.", "published": "2023-02-14T21:23:22Z", "version": 2}, {"aid": "2302.07950", "authors": ["Kazuki Irie", "R\u00f3bert Csord\u00e1s", "J\u00fcrgen Schmidhuber"], "title": "Self-Organising Neural Discrete Representation Learning \u00e0 la Kohonen", "url": "http://arxiv.org/pdf/2302.07950v2", "summary": "Unsupervised learning of discrete representations in neural networks (NNs)\nfrom continuous ones is essential for many modern applications. Vector\nQuantisation (VQ) has become popular for this, in particular in the context of\ngenerative models, such as Variational Auto-Encoders (VAEs), where the\nexponential moving average-based VQ (EMA-VQ) algorithm is often used. Here, we\nstudy an alternative VQ algorithm based on Kohonen's learning rule for the\nSelf-Organising Map (KSOM; 1982). EMA-VQ is a special case of KSOM. KSOM is\nknown to offer two potential benefits: empirically, it converges faster than\nEMA-VQ, and KSOM-generated discrete representations form a topological\nstructure on the grid whose nodes are the discrete symbols, resulting in an\nartificial version of the brain's topographic map. We revisit these properties\nby using KSOM in VQ-VAEs for image processing. In our experiments, the speed-up\ncompared to well-configured EMA-VQ is only observable at the beginning of\ntraining, but KSOM is generally much more robust, e.g., w.r.t. the choice of\ninitialisation schemes.", "published": "2023-02-15T21:04:04Z", "version": 2}, {"aid": "2302.08175", "authors": ["Frank Nielsen"], "title": "A numerical approximation method for the Fisher-Rao distance between multivariate normal distributions", "url": "http://arxiv.org/pdf/2302.08175v6", "summary": "We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao's distances between successive nearby normal\ndistributions on the curves by the square root of Jeffreys divergence, the\nsymmetrized Kullback-Leibler divergence. We consider experimentally the linear\ninterpolation curves in the ordinary, natural and expectation parameterizations\nof the normal distributions, and compare these curves with a curve derived from\nthe Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal\nmanifold into the cone of $(d+1)\\times (d+1)$ symmetric positive-definite\nmatrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on\nour experiments and assess the quality of our approximation technique by\ncomparing the numerical approximations with both lower and upper bounds.\nFinally, we present several information-geometric properties of the Calvo and\nOller's isometric embedding.", "published": "2023-02-16T09:44:55Z", "version": 6}, {"aid": "2302.08183", "authors": ["Dan Meller", "Nicolas Berkouk"], "title": "Singular Value Representation: A New Graph Perspective On Neural Networks", "url": "http://arxiv.org/pdf/2302.08183v1", "summary": "We introduce the Singular Value Representation (SVR), a new method to\nrepresent the internal state of neural networks using SVD factorization of the\nweights. This construction yields a new weighted graph connecting what we call\nspectral neurons, that correspond to specific activation patterns of classical\nneurons. We derive a precise statistical framework to discriminate meaningful\nconnections between spectral neurons for fully connected and convolutional\nlayers.\n  To demonstrate the usefulness of our approach for machine learning research,\nwe highlight two discoveries we made using the SVR. First, we highlight the\nemergence of a dominant connection in VGG networks that spans multiple deep\nlayers. Second, we witness, without relying on any input data, that batch\nnormalization can induce significant connections between near-kernels of deep\nlayers, leading to a remarkable spontaneous sparsification phenomenon.", "published": "2023-02-16T10:10:31Z", "version": 1}, {"aid": "2302.08392", "authors": ["Christoph B\u00f6rgers"], "title": "Infinitesimal phase response functions can be misleading", "url": "http://arxiv.org/pdf/2302.08392v2", "summary": "Phase response functions are the central tool in the mathematical analysis of\npulse-coupled oscillators. When an oscillator receives a brief input pulse, the\nphase response function specifies how its phase shifts as a function of the\nphase at which the input is received. When the pulse is weak, it is customary\nto linearize around zero pulse strength. The result is called the infinitesimal\nphase response function. These ideas have been used extensively in theoretical\nbiology, and also in some areas of engineering. I give examples showing that\nthe infinitesimal phase response function may predict that two oscillators, as\nthey exchange pulses back and fourth, will converge to synchrony, yet this is\nfalse when the exact phase response function is used, for all positive\ninteraction strengths. For short, the analogue of the Hartman-Grobman theorem\nthat one might expect to hold at first sight is invalid. I give a condition\nunder which the prediction derived using the infinitesimal phase response\nfunction does hold for the exact phase response function when interactions are\nsufficiently weak but positive. However, I argue that this condition may often\nfail to hold.", "published": "2023-02-16T16:11:21Z", "version": 2}, {"aid": "2302.08411", "authors": ["Martin Zach", "Thomas Pock", "Erich Kobler", "Antonin Chambolle"], "title": "Explicit Diffusion of Gaussian Mixture Model Based Image Priors", "url": "http://arxiv.org/pdf/2302.08411v1", "summary": "In this work we tackle the problem of estimating the density $f_X$ of a\nrandom variable $X$ by successive smoothing, such that the smoothed random\nvariable $Y$ fulfills $(\\partial_t - \\Delta_1)f_Y(\\,\\cdot\\,, t) = 0$,\n$f_Y(\\,\\cdot\\,, 0) = f_X$. With a focus on image processing, we propose a\nproduct/fields of experts model with Gaussian mixture experts that admits an\nanalytic expression for $f_Y (\\,\\cdot\\,, t)$ under an orthogonality constraint\non the filters. This construction naturally allows the model to be trained\nsimultaneously over the entire diffusion horizon using empirical Bayes. We show\npreliminary results on image denoising where our model leads to competitive\nresults while being tractable, interpretable, and having only a small number of\nlearnable parameters. As a byproduct, our model can be used for reliable noise\nestimation, allowing blind denoising of images corrupted by heteroscedastic\nnoise.", "published": "2023-02-16T16:39:13Z", "version": 1}, {"aid": "2302.08458", "authors": ["Marcelo J. Rozenberg"], "title": "Solid State Neuroscience: Spiking Neural Networks as Time Matter", "url": "http://arxiv.org/pdf/2302.08458v1", "summary": "We aim at building a bridge between to {\\it a priori} disconnected fields:\nNeuroscience and Material Science. We construct an analogy based on identifying\nspikes events in time with the positions of particles of matter. We show that\none may think of the dynamical states of spiking neurons and spiking neural\nnetworks as {\\it time-matter}. Namely, a structure of spike-events in time\nhaving analogue properties to that of ordinary matter. We can define for neural\nsystems notions equivalent to the equations of state, phase diagrams and their\nphase transitions. For instance, the familiar Ideal Gas Law relation (P$v$ =\nconstant) emerges as analogue of the Ideal Integrate and Fire neuron model\nrelation ($I_{in}$ISI = constant). We define the neural analogue of the spatial\nstructure correlation function, that can characterize spiking states with\ntemporal long-range order, such as regular tonic spiking. We also define the\n``neuro-compressibility'' response function in analogy to the lattice\ncompressibility. We show that similarly to the case of ordinary matter, the\nanomalous behavior of the neuro-compressibility is a precursor effect that\nsignals the onset of changes in spiking states. We propose that the notion of\nneuro-compressibility may open the way to develop novel medical tools for the\nearly diagnose of diseases. It may allow to predict impending anomalous neural\nstates, such as Parkinson's tremors, epileptic seizures, electric\ncardiopathies, and perhaps may even serve as a predictor of the likelihood of\nregaining consciousness.", "published": "2023-02-16T18:04:10Z", "version": 1}, {"aid": "2302.08478", "authors": ["Tomoki Yoshida", "Yuki Kondo", "Takahiro Maeda", "Kazutoshi Akita", "Norimichi Ukita"], "title": "Kernelized Back-Projection Networks for Blind Super Resolution", "url": "http://arxiv.org/pdf/2302.08478v3", "summary": "Since non-blind Super Resolution (SR) fails to super-resolve Low-Resolution\n(LR) images degraded by arbitrary degradations, SR with the degradation model\nis required. However, this paper reveals that non-blind SR that is trained\nsimply with various blur kernels exhibits comparable performance as those with\nthe degradation model for blind SR. This result motivates us to revisit\nhigh-performance non-blind SR and extend it to blind SR with blur kernels. This\npaper proposes two SR networks by integrating kernel estimation and SR branches\nin an iterative end-to-end manner. In the first model, which is called the\nKernel Conditioned Back-Projection Network (KCBPN), the low-dimensional kernel\nrepresentations are estimated for conditioning the SR branch. In our second\nmodel, the Kernelized BackProjection Network (KBPN), a raw kernel is estimated\nand directly employed for modeling the image degradation. The estimated kernel\nis employed not only for back-propagating its residual but also for\nforward-propagating the residual to iterative stages. This forward-propagation\nencourages these stages to learn a variety of different features in different\nstages by focusing on pixels with large residuals in each stage. Experimental\nresults validate the effectiveness of our proposed networks for kernel\nestimation and SR. We will release the code for this work.", "published": "2023-02-16T18:35:39Z", "version": 3}, {"aid": "2302.08545", "authors": ["Minghao Li", "Ran Ben Basat", "Shay Vargaftik", "ChonLam Lao", "Kevin Xu", "Michael Mitzenmacher", "Minlan Yu"], "title": "THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic Compression", "url": "http://arxiv.org/pdf/2302.08545v2", "summary": "Deep neural networks (DNNs) are the de facto standard for essential use\ncases, such as image classification, computer vision, and natural language\nprocessing. As DNNs and datasets get larger, they require distributed training\non increasingly larger clusters. A main bottleneck is the resulting\ncommunication overhead where workers exchange model updates (i.e., gradients)\non a per-round basis. To address this bottleneck and accelerate training, a\nwidely-deployed approach is compression. However, previous deployments often\napply bi-directional compression schemes by simply using a uni-directional\ngradient compression scheme in each direction. This results in significant\ncomputational overheads at the parameter server and increased compression\nerror, leading to longer training and lower accuracy. We introduce Tensor\nHomomorphic Compression (THC), a novel bi-directional compression framework\nthat enables the direct aggregation of compressed values and thus eliminating\nthe aforementioned computational overheads. Moreover, THC is compatible with\nin-network aggregation (INA), which allows for further acceleration. Our\nevaluation shows that training representative vision and language models with\nTHC reaches target accuracy by 1.40x to 1.47x faster using INA and 1.28x to\n1.33x faster using a software PS compared with state-of-the-art systems.", "published": "2023-02-16T19:48:20Z", "version": 2}, {"aid": "2302.09160", "authors": ["William T. Redman", "Juan M. Bello-Rivas", "Maria Fonoberova", "Ryan Mohr", "Ioannis G. Kevrekidis", "Igor Mezi\u0107"], "title": "Identifying Equivalent Training Dynamics", "url": "http://arxiv.org/pdf/2302.09160v3", "summary": "Study of the nonlinear evolution deep neural network (DNN) parameters undergo\nduring training has uncovered regimes of distinct dynamical behavior. While a\ndetailed understanding of these phenomena has the potential to advance\nimprovements in training efficiency and robustness, the lack of methods for\nidentifying when DNN models have equivalent dynamics limits the insight that\ncan be gained from prior work. Topological conjugacy, a notion from dynamical\nsystems theory, provides a precise definition of dynamical equivalence,\noffering a possible route to address this need. However, topological\nconjugacies have historically been challenging to compute. By leveraging\nadvances in Koopman operator theory, we develop a framework for identifying\nconjugate and non-conjugate training dynamics. To validate our approach, we\ndemonstrate that comparing Koopman eigenvalues can correctly identify a known\nequivalence between online mirror descent and online gradient descent. We then\nutilize our approach to: (a) identify non-conjugate training dynamics between\nshallow and wide fully connected neural networks; (b) characterize the early\nphase of training dynamics in convolutional neural networks; (c) uncover\nnon-conjugate training dynamics in Transformers that do and do not undergo\ngrokking. Our results, across a range of DNN architectures, illustrate the\nflexibility of our framework and highlight its potential for shedding new light\non training dynamics.", "published": "2023-02-17T22:15:20Z", "version": 3}, {"aid": "2302.10163", "authors": ["Marc W. Howard", "Zahra G. Esfahani", "Bao Le", "Per B. Sederberg"], "title": "Learning temporal relationships between symbols with Laplace Neural Manifolds", "url": "http://arxiv.org/pdf/2302.10163v4", "summary": "Firing across populations of neurons in many regions of the mammalian brain\nmaintains a temporal memory, a neural timeline of the recent past. Behavioral\nresults demonstrate that people can both remember the past and anticipate the\nfuture over an analogous internal timeline. This paper presents a mathematical\nframework for building this timeline of the future. We assume that the input to\nthe system is a time series of symbols--sparse tokenized representations of the\npresent--in continuous time. The goal is to record pairwise temporal\nrelationships between symbols over a wide range of time scales. We assume that\nthe brain has access to a temporal memory in the form of the real Laplace\ntransform. Hebbian associations with a diversity of synaptic time scales are\nformed between the past timeline and the present symbol. The associative memory\nstores the convolution between the past and the present. Knowing the temporal\nrelationship between the past and the present allows one to infer relationships\nbetween the present and the future. With appropriate normalization, this\nHebbian associative matrix can store a Laplace successor representation and a\nLaplace predecessor representation from which measures of temporal contingency\ncan be evaluated. The diversity of synaptic time constants allows for learning\nof non-stationary statistics as well as joint statistics between triplets of\nsymbols. This framework synthesizes a number of recent neuroscientific findings\nincluding results from dopamine neurons in the mesolimbic forebrain.", "published": "2023-02-20T18:49:34Z", "version": 4}, {"aid": "2302.10266", "authors": ["M. Amine Mahmoudi", "Aladine Chetouani", "Fatma Boufera", "Hedi Tabia"], "title": "Kernel function impact on convolutional neural networks", "url": "http://arxiv.org/pdf/2302.10266v1", "summary": "This paper investigates the usage of kernel functions at the different layers\nin a convolutional neural network. We carry out extensive studies of their\nimpact on convolutional, pooling and fully-connected layers. We notice that the\nlinear kernel may not be sufficiently effective to fit the input data\ndistributions, whereas high order kernels prone to over-fitting. This leads to\nconclude that a trade-off between complexity and performance should be reached.\nWe show how one can effectively leverage kernel functions, by introducing a\nmore distortion aware pooling layers which reduces over-fitting while keeping\ntrack of the majority of the information fed into subsequent layers. We further\npropose Kernelized Dense Layers (KDL), which replace fully-connected layers,\nand capture higher order feature interactions. The experiments on conventional\nclassification datasets i.e. MNIST, FASHION-MNIST and CIFAR-10, show that the\nproposed techniques improve the performance of the network compared to\nclassical convolution, pooling and fully connected layers. Moreover,\nexperiments on fine-grained classification i.e. facial expression databases,\nnamely RAF-DB, FER2013 and ExpW demonstrate that the discriminative power of\nthe network is boosted, since the proposed techniques improve the awareness to\nslight visual details and allows the network reaching state-of-the-art results.", "published": "2023-02-20T19:57:01Z", "version": 1}, {"aid": "2302.10392", "authors": ["Qi Lin", "Zifan Li", "John Lafferty", "Ilker Yildirim"], "title": "From seeing to remembering: Images with harder-to-reconstruct representations leave stronger memory traces", "url": "http://arxiv.org/pdf/2302.10392v1", "summary": "Much of what we remember is not due to intentional selection, but simply a\nby-product of perceiving. This raises a foundational question about the\narchitecture of the mind: How does perception interface with and influence\nmemory? Here, inspired by a classic proposal relating perceptual processing to\nmemory durability, the level-of-processing theory, we present a sparse coding\nmodel for compressing feature embeddings of images, and show that the\nreconstruction residuals from this model predict how well images are encoded\ninto memory. In an open memorability dataset of scene images, we show that\nreconstruction error not only explains memory accuracy but also response\nlatencies during retrieval, subsuming, in the latter case, all of the variance\nexplained by powerful vision-only models. We also confirm a prediction of this\naccount with 'model-driven psychophysics'. This work establishes reconstruction\nerror as a novel signal interfacing perception and memory, possibly through\nadaptive modulation of perceptual processing.", "published": "2023-02-21T01:40:32Z", "version": 1}, {"aid": "2302.10688", "authors": ["Tianyu Pang", "Cheng Lu", "Chao Du", "Min Lin", "Shuicheng Yan", "Zhijie Deng"], "title": "On Calibrating Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2302.10688v3", "summary": "Recently, diffusion probabilistic models (DPMs) have achieved promising\nresults in diverse generative tasks. A typical DPM framework includes a forward\nprocess that gradually diffuses the data distribution and a reverse process\nthat recovers the data distribution from time-dependent data scores. In this\nwork, we observe that the stochastic reverse process of data scores is a\nmartingale, from which concentration bounds and the optional stopping theorem\nfor data scores can be derived. Then, we discover a simple way for calibrating\nan arbitrary pretrained DPM, with which the score matching loss can be reduced\nand the lower bounds of model likelihood can consequently be increased. We\nprovide general calibration guidelines under various model parametrizations.\nOur calibration method is performed only once and the resulting models can be\nused repeatedly for sampling. We conduct experiments on multiple datasets to\nempirically validate our proposal. Our code is at\nhttps://github.com/thudzj/Calibrated-DPMs.", "published": "2023-02-21T14:14:40Z", "version": 3}, {"aid": "2303.01514", "authors": ["Chris Fields", "Filippo Fabrocini", "Karl Friston", "James F. Glazebrook", "Hananel Hazan", "Michael Levin", "Antonino Marciano"], "title": "Control flow in active inference systems", "url": "http://arxiv.org/pdf/2303.01514v1", "summary": "Living systems face both environmental complexity and limited access to\nfree-energy resources. Survival under these conditions requires a control\nsystem that can activate, or deploy, available perception and action resources\nin a context specific way. We show here that when systems are described as\nexecuting active inference driven by the free-energy principle (and hence can\nbe considered Bayesian prediction-error minimizers), their control flow systems\ncan always be represented as tensor networks (TNs). We show how TNs as control\nsystems can be implmented within the general framework of quantum topological\nneural networks, and discuss the implications of these results for modeling\nbiological systems at multiple scales.", "published": "2023-02-25T02:31:47Z", "version": 1}, {"aid": "2303.04146", "authors": ["J. A. Scott Kelso"], "title": "The Critical Brain Hypothesis? Meet The Metastable Brain~Mind", "url": "http://arxiv.org/pdf/2303.04146v1", "summary": "In contrast to the critical brain hypothesis in which the brain tunes itself\nto a critical point between $states$ of chaos and order, analysis of\nCoordination Dynamics suggests that a vast repertoire of $coexisting$\n$tendencies$ exists for regions of the brain to integrate and segregate at the\nsame time. Rather than teetering between order and randomness, the brain~mind\nlives in an immense sea of metastability where it can create functional\ninformation.", "published": "2023-02-28T18:56:31Z", "version": 1}, {"aid": "2303.00848", "authors": ["Diederik P. Kingma", "Ruiqi Gao"], "title": "Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation", "url": "http://arxiv.org/pdf/2303.00848v7", "summary": "To achieve the highest perceptual quality, state-of-the-art diffusion models\nare optimized with objectives that typically look very different from the\nmaximum likelihood and the Evidence Lower Bound (ELBO) objectives. In this\nwork, we reveal that diffusion model objectives are actually closely related to\nthe ELBO.\n  Specifically, we show that all commonly used diffusion model objectives\nequate to a weighted integral of ELBOs over different noise levels, where the\nweighting depends on the specific objective used. Under the condition of\nmonotonic weighting, the connection is even closer: the diffusion objective\nthen equals the ELBO, combined with simple data augmentation, namely Gaussian\nnoise perturbation. We show that this condition holds for a number of\nstate-of-the-art diffusion models.\n  In experiments, we explore new monotonic weightings and demonstrate their\neffectiveness, achieving state-of-the-art FID scores on the high-resolution\nImageNet benchmark.", "published": "2023-03-01T22:36:05Z", "version": 7}, {"aid": "2303.00879", "authors": ["Stephanie Chen", "Juan Pablo Vigneaux"], "title": "Categorical magnitude and entropy", "url": "http://arxiv.org/pdf/2303.00879v2", "summary": "Given any finite set equipped with a probability measure, one may compute its\nShannon entropy or information content. The entropy becomes the logarithm of\nthe cardinality of the set when the uniform probability is used. Leinster\nintroduced a notion of Euler characteristic for certain finite categories, also\nknown as magnitude, that can be seen as a categorical generalization of\ncardinality. This paper aims to connect the two ideas by considering the\nextension of Shannon entropy to finite categories endowed with probability, in\nsuch a way that the magnitude is recovered when a certain choice of \"uniform\"\nprobability is made.", "published": "2023-03-02T00:36:36Z", "version": 2}, {"aid": "2303.01505", "authors": ["Dan Liu", "Xue Liu"], "title": "Ternary Quantization: A Survey", "url": "http://arxiv.org/pdf/2303.01505v1", "summary": "Inference time, model size, and accuracy are critical for deploying deep\nneural network models. Numerous research efforts have been made to compress\nneural network models with faster inference and higher accuracy. Pruning and\nquantization are mainstream methods to this end. During model quantization,\nconverting individual float values of layer weights to low-precision ones can\nsubstantially reduce the computational overhead and improve the inference\nspeed. Many quantization methods have been studied, for example, vector\nquantization, low-bit quantization, and binary/ternary quantization. This\nsurvey focuses on ternary quantization. We review the evolution of ternary\nquantization and investigate the relationships among existing ternary\nquantization methods from the perspective of projection function and\noptimization methods.", "published": "2023-03-02T03:38:51Z", "version": 1}, {"aid": "2303.01506", "authors": ["Huiqi Deng", "Na Zou", "Mengnan Du", "Weifu Chen", "Guocan Feng", "Ziwei Yang", "Zheyang Li", "Quanshi Zhang"], "title": "Understanding and Unifying Fourteen Attribution Methods with Taylor Interactions", "url": "http://arxiv.org/pdf/2303.01506v2", "summary": "Various attribution methods have been developed to explain deep neural\nnetworks (DNNs) by inferring the attribution/importance/contribution score of\neach input variable to the final output. However, existing attribution methods\nare often built upon different heuristics. There remains a lack of a unified\ntheoretical understanding of why these methods are effective and how they are\nrelated. To this end, for the first time, we formulate core mechanisms of\nfourteen attribution methods, which were designed on different heuristics, into\nthe same mathematical system, i.e., the system of Taylor interactions.\nSpecifically, we prove that attribution scores estimated by fourteen\nattribution methods can all be reformulated as the weighted sum of two types of\neffects, i.e., independent effects of each individual input variable and\ninteraction effects between input variables. The essential difference among the\nfourteen attribution methods mainly lies in the weights of allocating different\neffects. Based on the above findings, we propose three principles for a fair\nallocation of effects to evaluate the faithfulness of the fourteen attribution\nmethods.", "published": "2023-03-02T04:50:05Z", "version": 2}, {"aid": "2303.01509", "authors": ["Anik Mallik", "Haoxin Wang", "Jiang Xie", "Dawei Chen", "Kyungtae Han"], "title": "EPAM: A Predictive Energy Model for Mobile AI", "url": "http://arxiv.org/pdf/2303.01509v1", "summary": "Artificial intelligence (AI) has enabled a new paradigm of smart applications\n-- changing our way of living entirely. Many of these AI-enabled applications\nhave very stringent latency requirements, especially for applications on mobile\ndevices (e.g., smartphones, wearable devices, and vehicles). Hence, smaller and\nquantized deep neural network (DNN) models are developed for mobile devices,\nwhich provide faster and more energy-efficient computation for mobile AI\napplications. However, how AI models consume energy in a mobile device is still\nunexplored. Predicting the energy consumption of these models, along with their\ndifferent applications, such as vision and non-vision, requires a thorough\ninvestigation of their behavior using various processing sources. In this\npaper, we introduce a comprehensive study of mobile AI applications considering\ndifferent DNN models and processing sources, focusing on computational resource\nutilization, delay, and energy consumption. We measure the latency, energy\nconsumption, and memory usage of all the models using four processing sources\nthrough extensive experiments. We explain the challenges in such investigations\nand how we propose to overcome them. Our study highlights important insights,\nsuch as how mobile AI behaves in different applications (vision and non-vision)\nusing CPU, GPU, and NNAPI. Finally, we propose a novel Gaussian process\nregression-based general predictive energy model based on DNN structures,\ncomputation resources, and processors, which can predict the energy for each\ncomplete application cycle irrespective of device configuration and\napplication. This study provides crucial facts and an energy prediction\nmechanism to the AI research community to help bring energy efficiency to\nmobile AI applications.", "published": "2023-03-02T09:11:23Z", "version": 1}, {"aid": "2303.01515", "authors": ["Wanyu Bian"], "title": "Optimization-Based Deep learning methods for Magnetic Resonance Imaging Reconstruction and Synthesis", "url": "http://arxiv.org/pdf/2303.01515v1", "summary": "This dissertation is devoted to provide advanced nonconvex nonsmooth\nvariational models of (Magnetic Resonance Image) MRI reconstruction, efficient\nlearnable image reconstruction algorithms and parameter training algorithms\nthat improve the accuracy and robustness of the optimization-based deep\nlearning methods for compressed sensing MRI reconstruction and synthesis. The\nfirst part introduces a novel optimization based deep neural network whose\narchitecture is inspired by proximal gradient descent for solving a variational\nmodel. The second part is a substantial extension of the preliminary work in\nthe first part by solving the calibration-free fast pMRI reconstruction problem\nin a discrete-time optimal control framework. The third part aims at developing\na generalizable Magnetic Resonance Imaging (MRI) reconstruction method in the\nmeta-learning framework. The last part aims to synthesize target modality of\nMRI by using partially scanned k-space data from source modalities instead of\nfully scanned data that is used in the state-of-the-art multimodal synthesis.", "published": "2023-03-02T18:59:44Z", "version": 1}, {"aid": "2303.01559", "authors": ["Haozhe Liu", "Wentian Zhang", "Bing Li", "Haoqian Wu", "Nanjun He", "Yawen Huang", "Yuexiang Li", "Bernard Ghanem", "Yefeng Zheng"], "title": "Improving GAN Training via Feature Space Shrinkage", "url": "http://arxiv.org/pdf/2303.01559v2", "summary": "Due to the outstanding capability for data generation, Generative Adversarial\nNetworks (GANs) have attracted considerable attention in unsupervised learning.\nHowever, training GANs is difficult, since the training distribution is dynamic\nfor the discriminator, leading to unstable image representation. In this paper,\nwe address the problem of training GANs from a novel perspective, \\emph{i.e.,}\nrobust image classification. Motivated by studies on robust image\nrepresentation, we propose a simple yet effective module, namely AdaptiveMix,\nfor GANs, which shrinks the regions of training data in the image\nrepresentation space of the discriminator. Considering it is intractable to\ndirectly bound feature space, we propose to construct hard samples and narrow\ndown the feature distance between hard and easy samples. The hard samples are\nconstructed by mixing a pair of training images. We evaluate the effectiveness\nof our AdaptiveMix with widely-used and state-of-the-art GAN architectures. The\nevaluation results demonstrate that our AdaptiveMix can facilitate the training\nof GANs and effectively improve the image quality of generated samples. We also\nshow that our AdaptiveMix can be further applied to image classification and\nOut-Of-Distribution (OOD) detection tasks, by equipping it with\nstate-of-the-art methods. Extensive experiments on seven publicly available\ndatasets show that our method effectively boosts the performance of baselines.\nThe code is publicly available at\nhttps://github.com/WentianZhang-ML/AdaptiveMix.", "published": "2023-03-02T20:22:24Z", "version": 2}, {"aid": "2303.01567", "authors": ["Matthias Rath", "Alexandru Paul Condurache"], "title": "Deep Neural Networks with Efficient Guaranteed Invariances", "url": "http://arxiv.org/pdf/2303.01567v1", "summary": "We address the problem of improving the performance and in particular the\nsample complexity of deep neural networks by enforcing and guaranteeing\ninvariances to symmetry transformations rather than learning them from data.\nGroup-equivariant convolutions are a popular approach to obtain equivariant\nrepresentations. The desired corresponding invariance is then imposed using\npooling operations. For rotations, it has been shown that using invariant\nintegration instead of pooling further improves the sample complexity. In this\ncontribution, we first expand invariant integration beyond rotations to flips\nand scale transformations. We then address the problem of incorporating\nmultiple desired invariances into a single network. For this purpose, we\npropose a multi-stream architecture, where each stream is invariant to a\ndifferent transformation such that the network can simultaneously benefit from\nmultiple invariances. We demonstrate our approach with successful experiments\non Scaled-MNIST, SVHN, CIFAR-10 and STL-10.", "published": "2023-03-02T20:44:45Z", "version": 1}, {"aid": "2303.01618", "authors": ["Th\u00e9ophile Champion", "Marek Grze\u015b", "Lisa Bonheme", "Howard Bowman"], "title": "Deconstructing deep active inference", "url": "http://arxiv.org/pdf/2303.01618v2", "summary": "Active inference is a theory of perception, learning and decision making,\nwhich can be applied to neuroscience, robotics, and machine learning. Recently,\nreasearch has been taking place to scale up this framework using Monte-Carlo\ntree search and deep learning. The goal of this activity is to solve more\ncomplicated tasks using deep active inference. First, we review the existing\nliterature, then, we progresively build a deep active inference agent. For two\nagents, we have experimented with five definitions of the expected free energy\nand three different action selection strategies. According to our experiments,\nthe models able to solve the dSprites environment are the ones that maximise\nrewards. Finally, we compare the similarity of the representation learned by\nthe layers of various agents using centered kernel alignment. Importantly, the\nagent maximising reward and the agent minimising expected free energy learn\nvery similar representations except for the last layer of the critic network\n(reflecting the difference in learning objective), and the variance layers of\nthe transition and encoder networks. We found that the reward maximising agent\nis a lot more certain than the agent minimising expected free energy. This is\nbecause the agent minimising expected free energy always picks the action down,\nand does not gather enough data for the other actions. In contrast, the agent\nmaximising reward, keeps on selecting the actions left and right, enabling it\nto successfully solve the task. The only difference between those two agents is\nthe epistemic value, which aims to make the outputs of the transition and\nencoder networks as close as possible. Thus, the agent minimising expected free\nenergy picks a single action (down), and becomes an expert at predicting the\nfuture when selecting this action. This makes the KL divergence between the\noutput of the transition and encoder networks small.", "published": "2023-03-02T22:39:56Z", "version": 2}, {"aid": "2303.01723", "authors": ["Nir Shlezinger", "Mengyuan Ma", "Ortal Lavi", "Nhan Thanh Nguyen", "Yonina C. Eldar", "Markku Juntti"], "title": "AI-Empowered Hybrid MIMO Beamforming", "url": "http://arxiv.org/pdf/2303.01723v1", "summary": "Hybrid multiple-input multiple-output (MIMO) is an attractive technology for\nrealizing extreme massive MIMO systems envisioned for future wireless\ncommunications in a scalable and power-efficient manner. However, the fact that\nhybrid MIMO systems implement part of their beamforming in analog and part in\ndigital makes the optimization of their beampattern notably more challenging\ncompared with conventional fully digital MIMO. Consequently, recent years have\nwitnessed a growing interest in using data-aided artificial intelligence (AI)\ntools for hybrid beamforming design. This article reviews candidate strategies\nto leverage data to improve real-time hybrid beamforming design. We discuss the\narchitectural constraints and characterize the core challenges associated with\nhybrid beamforming optimization. We then present how these challenges are\ntreated via conventional optimization, and identify different AI-aided design\napproaches. These can be roughly divided into purely data-driven deep learning\nmodels and different forms of deep unfolding techniques for combining AI with\nclassical optimization.We provide a systematic comparative study between\nexisting approaches including both numerical evaluations and qualitative\nmeasures. We conclude by presenting future research opportunities associated\nwith the incorporation of AI in hybrid MIMO systems.", "published": "2023-03-03T06:04:20Z", "version": 1}, {"aid": "2303.01748", "authors": ["Kushagra Pandey", "Stephan Mandt"], "title": "A Complete Recipe for Diffusion Generative Models", "url": "http://arxiv.org/pdf/2303.01748v2", "summary": "Score-based Generative Models (SGMs) have demonstrated exceptional synthesis\noutcomes across various tasks. However, the current design landscape of the\nforward diffusion process remains largely untapped and often relies on physical\nheuristics or simplifying assumptions. Utilizing insights from the development\nof scalable Bayesian posterior samplers, we present a complete recipe for\nformulating forward processes in SGMs, ensuring convergence to the desired\ntarget distribution. Our approach reveals that several existing SGMs can be\nseen as specific manifestations of our framework. Building upon this method, we\nintroduce Phase Space Langevin Diffusion (PSLD), which relies on score-based\nmodeling within an augmented space enriched by auxiliary variables akin to\nphysical phase space. Empirical results exhibit the superior sample quality and\nimproved speed-quality trade-off of PSLD compared to various competing\napproaches on established image synthesis benchmarks. Remarkably, PSLD achieves\nsample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional\nCIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in\nconditional synthesis using pre-trained score networks, offering an appealing\nalternative as an SGM backbone for future advancements. Code and model\ncheckpoints can be accessed at \\url{https://github.com/mandt-lab/PSLD}.", "published": "2023-03-03T07:20:58Z", "version": 2}, {"aid": "2303.01841", "authors": ["Edward De Brouwer", "Rahul G. Krishnan"], "title": "Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections", "url": "http://arxiv.org/pdf/2303.01841v1", "summary": "Neural ordinary differential equations (Neural ODEs) are an effective\nframework for learning dynamical systems from irregularly sampled time series\ndata. These models provide a continuous-time latent representation of the\nunderlying dynamical system where new observations at arbitrary time points can\nbe used to update the latent representation of the dynamical system. Existing\nparameterizations for the dynamics functions of Neural ODEs limit the ability\nof the model to retain global information about the time series; specifically,\na piece-wise integration of the latent process between observations can result\nin a loss of memory on the dynamic patterns of previously observed data points.\nWe propose PolyODE, a Neural ODE that models the latent continuous-time process\nas a projection onto a basis of orthogonal polynomials. This formulation\nenforces long-range memory and preserves a global representation of the\nunderlying dynamical system. Our construction is backed by favourable\ntheoretical guarantees and in a series of experiments, we demonstrate that it\noutperforms previous works in the reconstruction of past and future data, and\nin downstream prediction tasks.", "published": "2023-03-03T10:49:09Z", "version": 1}, {"aid": "2303.02045", "authors": ["Danruo Deng", "Guangyong Chen", "Yang Yu", "Furui Liu", "Pheng-Ann Heng"], "title": "Uncertainty Estimation by Fisher Information-based Evidential Deep Learning", "url": "http://arxiv.org/pdf/2303.02045v3", "summary": "Uncertainty estimation is a key factor that makes deep learning reliable in\npractical applications. Recently proposed evidential neural networks explicitly\naccount for different uncertainties by treating the network's outputs as\nevidence to parameterize the Dirichlet distribution, and achieve impressive\nperformance in uncertainty estimation. However, for high data uncertainty\nsamples but annotated with the one-hot label, the evidence-learning process for\nthose mislabeled classes is over-penalized and remains hindered. To address\nthis problem, we propose a novel method, Fisher Information-based Evidential\nDeep Learning ($\\mathcal{I}$-EDL). In particular, we introduce Fisher\nInformation Matrix (FIM) to measure the informativeness of evidence carried by\neach sample, according to which we can dynamically reweight the objective loss\nterms to make the network more focused on the representation learning of\nuncertain classes. The generalization ability of our network is further\nimproved by optimizing the PAC-Bayesian bound. As demonstrated empirically, our\nproposed method consistently outperforms traditional EDL-related algorithms in\nmultiple uncertainty estimation tasks, especially in the more challenging\nfew-shot classification settings.", "published": "2023-03-03T16:12:59Z", "version": 3}, {"aid": "2303.02186", "authors": ["Jeroen Berrevoets", "Krzysztof Kacprzyk", "Zhaozhi Qian", "Mihaela van der Schaar"], "title": "Causal Deep Learning", "url": "http://arxiv.org/pdf/2303.02186v2", "summary": "Causality has the potential to truly transform the way we solve a large\nnumber of real-world problems. Yet, so far, its potential largely remains to be\nunlocked as causality often requires crucial assumptions which cannot be tested\nin practice. To address this challenge, we propose a new way of thinking about\ncausality -- we call this causal deep learning. Our causal deep learning\nframework spans three dimensions: (1) a structural dimension, which\nincorporates partial yet testable causal knowledge rather than assuming either\ncomplete or no causal knowledge among the variables of interest; (2) a\nparametric dimension, which encompasses parametric forms that capture the type\nof relationships among the variables of interest; and (3) a temporal dimension,\nwhich captures exposure times or how the variables of interest interact\n(possibly causally) over time. Causal deep learning enables us to make progress\non a variety of real-world problems by leveraging partial causal knowledge\n(including independencies among variables) and quantitatively characterising\ncausal relationships among variables of interest (possibly over time). Our\nframework clearly identifies which assumptions are testable and which ones are\nnot, such that the resulting solutions can be judiciously adopted in practice.\nUsing our formulation we can combine or chain together causal representations\nto solve specific problems without losing track of which assumptions are\nrequired to build these solutions, pushing real-world impact in healthcare,\neconomics and business, environmental sciences and education, through causal\ndeep learning.", "published": "2023-03-03T19:19:18Z", "version": 2}, {"aid": "2303.02262", "authors": ["Avik Pal", "Alan Edelman", "Chris Rackauckas"], "title": "Locally Regularized Neural Differential Equations: Some Black Boxes Were Meant to Remain Closed!", "url": "http://arxiv.org/pdf/2303.02262v3", "summary": "Implicit layer deep learning techniques, like Neural Differential Equations,\nhave become an important modeling framework due to their ability to adapt to\nnew problems automatically. Training a neural differential equation is\neffectively a search over a space of plausible dynamical systems. However,\ncontrolling the computational cost for these models is difficult since it\nrelies on the number of steps the adaptive solver takes. Most prior works have\nused higher-order methods to reduce prediction timings while greatly increasing\ntraining time or reducing both training and prediction timings by relying on\nspecific training algorithms, which are harder to use as a drop-in replacement\ndue to strict requirements on automatic differentiation. In this manuscript, we\nuse internal cost heuristics of adaptive differential equation solvers at\nstochastic time points to guide the training toward learning a dynamical system\nthat is easier to integrate. We \"close the black-box\" and allow the use of our\nmethod with any adjoint technique for gradient calculations of the differential\nequation solution. We perform experimental studies to compare our method to\nglobal regularization to show that we attain similar performance numbers\nwithout compromising the flexibility of implementation on ordinary differential\nequations (ODEs) and stochastic differential equations (SDEs). We develop two\nsampling strategies to trade off between performance and training time. Our\nmethod reduces the number of function evaluations to 0.556-0.733x and\naccelerates predictions by 1.3-2x.", "published": "2023-03-03T23:31:15Z", "version": 3}, {"aid": "2303.02328", "authors": ["Sangrok Lee", "Jongseong Bae", "Ha Young Kim"], "title": "Decompose, Adjust, Compose: Effective Normalization by Playing with Frequency for Domain Generalization", "url": "http://arxiv.org/pdf/2303.02328v3", "summary": "Domain generalization (DG) is a principal task to evaluate the robustness of\ncomputer vision models. Many previous studies have used normalization for DG.\nIn normalization, statistics and normalized features are regarded as style and\ncontent, respectively. However, it has a content variation problem when\nremoving style because the boundary between content and style is unclear. This\nstudy addresses this problem from the frequency domain perspective, where\namplitude and phase are considered as style and content, respectively. First,\nwe verify the quantitative phase variation of normalization through the\nmathematical derivation of the Fourier transform formula. Then, based on this,\nwe propose a novel normalization method, PCNorm, which eliminates style only as\nthe preserving content through spectral decomposition. Furthermore, we propose\nadvanced PCNorm variants, CCNorm and SCNorm, which adjust the degrees of\nvariations in content and style, respectively. Thus, they can learn\ndomain-agnostic representations for DG. With the normalization methods, we\npropose ResNet-variant models, DAC-P and DAC-SC, which are robust to the domain\ngap. The proposed models outperform other recent DG methods. The DAC-SC\nachieves an average state-of-the-art performance of 65.6% on five datasets:\nPACS, VLCS, Office-Home, DomainNet, and TerraIncognita.", "published": "2023-03-04T05:23:11Z", "version": 3}, {"aid": "2303.02448", "authors": ["Wenqian Li", "Yinchuan Li", "Zhigang Li", "Jianye Hao", "Yan Pang"], "title": "DAG Matters! GFlowNets Enhanced Explainer For Graph Neural Networks", "url": "http://arxiv.org/pdf/2303.02448v1", "summary": "Uncovering rationales behind predictions of graph neural networks (GNNs) has\nreceived increasing attention over the years. Existing literature mainly focus\non selecting a subgraph, through combinatorial optimization, to provide\nfaithful explanations. However, the exponential size of candidate subgraphs\nlimits the applicability of state-of-the-art methods to large-scale GNNs. We\nenhance on this through a different approach: by proposing a generative\nstructure -- GFlowNets-based GNN Explainer (GFlowExplainer), we turn the\noptimization problem into a step-by-step generative problem. Our GFlowExplainer\naims to learn a policy that generates a distribution of subgraphs for which the\nprobability of a subgraph is proportional to its' reward. The proposed approach\neliminates the influence of node sequence and thus does not need any\npre-training strategies. We also propose a new cut vertex matrix to efficiently\nexplore parent states for GFlowNets structure, thus making our approach\napplicable in a large-scale setting. We conduct extensive experiments on both\nsynthetic and real datasets, and both qualitative and quantitative results show\nthe superiority of our GFlowExplainer.", "published": "2023-03-04T16:15:25Z", "version": 1}, {"aid": "2303.02490", "authors": ["Binxu Wang", "John J. Vastola"], "title": "Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later", "url": "http://arxiv.org/pdf/2303.02490v2", "summary": "How do diffusion generative models convert pure noise into meaningful images?\nIn a variety of pretrained diffusion models (including conditional latent space\nmodels like Stable Diffusion), we observe that the reverse diffusion process\nthat underlies image generation has the following properties: (i) individual\ntrajectories tend to be low-dimensional and resemble 2D `rotations'; (ii)\nhigh-variance scene features like layout tend to emerge earlier, while\nlow-variance details tend to emerge later; and (iii) early perturbations tend\nto have a greater impact on image content than later perturbations. To\nunderstand these phenomena, we derive and study a closed-form solution to the\nprobability flow ODE for a Gaussian distribution, which shows that the reverse\ndiffusion state rotates towards a gradually-specified target on the image\nmanifold. It also shows that generation involves first committing to an\noutline, and then to finer and finer details. We find that this solution\naccurately describes the initial phase of image generation for pretrained\nmodels, and can in principle be used to make image generation more efficient by\nskipping reverse diffusion steps. Finally, we use our solution to characterize\nthe image manifold in Stable Diffusion. Our viewpoint reveals an unexpected\nsimilarity between generation by GANs and diffusion and provides a conceptual\nlink between diffusion and image retrieval.", "published": "2023-03-04T20:08:57Z", "version": 2}, {"aid": "2303.03887", "authors": ["Weili Zeng"], "title": "How to Construct Energy for Images? Denoising Autoencoder Can Be Energy Based Model", "url": "http://arxiv.org/pdf/2303.03887v1", "summary": "Energy-based models parameterize the unnormalized log-probability of data\nsamples, but there is a lack of guidance on how to construct the \"energy\". In\nthis paper, we propose a Denoising-EBM which decomposes the image energy into\n\"semantic energy\" and \"texture energy\". We define the \"semantic energy\" in the\nlatent space of DAE to model the high-level representations, and define the\npixel-level reconstruction error for denoising as \"texture energy\". Inspired by\nscore-based model, our model utilizes multi-scale noisy samples for\nmaximum-likelihood training and it outputs a vector instead of a scalar for\nexploring a larger set of functions during optimization. After training, the\nsemantics are first synthesized by fast MCMC through \"semantic energy\", and\nthen the pixel-level refinement of semantic image will be performed to generate\nperfect samples based on \"texture energy\". Ultimately, our model can outperform\nmost EBMs in image generation. And we also demonstrate that Denoising-EBM has\ntop performance among EBMs for out-of-distribution detection.", "published": "2023-03-05T05:35:55Z", "version": 1}, {"aid": "2303.02733", "authors": ["Alexander Detkov", "Mohammad Salameh", "Muhammad Fetrat Qharabagh", "Jialin Zhang", "Wei Lui", "Shangling Jui", "Di Niu"], "title": "Reparameterization through Spatial Gradient Scaling", "url": "http://arxiv.org/pdf/2303.02733v2", "summary": "Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.", "published": "2023-03-05T17:57:33Z", "version": 2}, {"aid": "2303.02165", "authors": ["Xuan Shen", "Yaohua Wang", "Ming Lin", "Yilun Huang", "Hao Tang", "Xiuyu Sun", "Yanzhi Wang"], "title": "DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural Network", "url": "http://arxiv.org/pdf/2303.02165v3", "summary": "The rapid advances in Vision Transformer (ViT) refresh the state-of-the-art\nperformances in various vision tasks, overshadowing the conventional CNN-based\nmodels. This ignites a few recent striking-back research in the CNN world\nshowing that pure CNN models can achieve as good performance as ViT models when\ncarefully tuned. While encouraging, designing such high-performance CNN models\nis challenging, requiring non-trivial prior knowledge of network design. To\nthis end, a novel framework termed Mathematical Architecture Design for Deep\nCNN (DeepMAD) is proposed to design high-performance CNN models in a principled\nway. In DeepMAD, a CNN network is modeled as an information processing system\nwhose expressiveness and effectiveness can be analytically formulated by their\nstructural parameters. Then a constrained mathematical programming (MP) problem\nis proposed to optimize these structural parameters. The MP problem can be\neasily solved by off-the-shelf MP solvers on CPUs with a small memory\nfootprint. In addition, DeepMAD is a pure mathematical framework: no GPU or\ntraining data is required during network design. The superiority of DeepMAD is\nvalidated on multiple large-scale computer vision benchmark datasets. Notably\non ImageNet-1k, only using conventional convolutional layers, DeepMAD achieves\n0.7% and 1.5% higher top-1 accuracy than ConvNeXt and Swin on Tiny level, and\n0.8% and 0.9% higher on Small level.", "published": "2023-03-05T21:31:49Z", "version": 3}, {"aid": "2303.03667", "authors": ["Jierun Chen", "Shiu-hong Kao", "Hao He", "Weipeng Zhuo", "Song Wen", "Chul-Ho Lee", "S. -H. Gary Chan"], "title": "Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks", "url": "http://arxiv.org/pdf/2303.03667v3", "summary": "To design fast neural networks, many works have been focusing on reducing the\nnumber of floating-point operations (FLOPs). We observe that such reduction in\nFLOPs, however, does not necessarily lead to a similar level of reduction in\nlatency. This mainly stems from inefficiently low floating-point operations per\nsecond (FLOPS). To achieve faster networks, we revisit popular operators and\ndemonstrate that such low FLOPS is mainly due to frequent memory access of the\noperators, especially the depthwise convolution. We hence propose a novel\npartial convolution (PConv) that extracts spatial features more efficiently, by\ncutting down redundant computation and memory access simultaneously. Building\nupon our PConv, we further propose FasterNet, a new family of neural networks,\nwhich attains substantially higher running speed than others on a wide range of\ndevices, without compromising on accuracy for various vision tasks. For\nexample, on ImageNet-1k, our tiny FasterNet-T0 is $2.8\\times$, $3.3\\times$, and\n$2.4\\times$ faster than MobileViT-XXS on GPU, CPU, and ARM processors,\nrespectively, while being $2.9\\%$ more accurate. Our large FasterNet-L achieves\nimpressive $83.5\\%$ top-1 accuracy, on par with the emerging Swin-B, while\nhaving $36\\%$ higher inference throughput on GPU, as well as saving $37\\%$\ncompute time on CPU. Code is available at\n\\url{https://github.com/JierunChen/FasterNet}.", "published": "2023-03-07T06:05:30Z", "version": 3}, {"aid": "2303.03758", "authors": ["Finn Behrendt", "Debayan Bhattacharya", "Julia Kr\u00fcger", "Roland Opfer", "Alexander Schlaefer"], "title": "Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI", "url": "http://arxiv.org/pdf/2303.03758v1", "summary": "The use of supervised deep learning techniques to detect pathologies in brain\nMRI scans can be challenging due to the diversity of brain anatomy and the need\nfor annotated data sets. An alternative approach is to use unsupervised anomaly\ndetection, which only requires sample-level labels of healthy brains to create\na reference representation. This reference representation can then be compared\nto unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To\naccomplish this, generative models are needed to create anatomically consistent\nMRI scans of healthy brains. While recent diffusion models have shown promise\nin this task, accurately generating the complex structure of the human brain\nremains a challenge. In this paper, we propose a method that reformulates the\ngeneration task of diffusion models as a patch-based estimation of healthy\nbrain anatomy, using spatial context to guide and improve reconstruction. We\nevaluate our approach on data of tumors and multiple sclerosis lesions and\ndemonstrate a relative improvement of 25.1% compared to existing baselines.", "published": "2023-03-07T09:40:22Z", "version": 1}, {"aid": "2303.04001", "authors": ["Rodrigo Mello", "Filipe Calegario", "Geber Ramalho"], "title": "ELODIN: Naming Concepts in Embedding Spaces", "url": "http://arxiv.org/pdf/2303.04001v2", "summary": "Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.", "published": "2023-03-07T16:00:26Z", "version": 2}, {"aid": "2303.04336", "authors": ["Guillaume Berger", "Manik Dhingra", "Antoine Mercier", "Yashesh Savani", "Sunny Panchal", "Fatih Porikli"], "title": "QuickSRNet: Plain Single-Image Super-Resolution Architecture for Faster Inference on Mobile Platforms", "url": "http://arxiv.org/pdf/2303.04336v2", "summary": "In this work, we present QuickSRNet, an efficient super-resolution\narchitecture for real-time applications on mobile platforms. Super-resolution\nclarifies, sharpens, and upscales an image to higher resolution. Applications\nsuch as gaming and video playback along with the ever-improving display\ncapabilities of TVs, smartphones, and VR headsets are driving the need for\nefficient upscaling solutions. While existing deep learning-based\nsuper-resolution approaches achieve impressive results in terms of visual\nquality, enabling real-time DL-based super-resolution on mobile devices with\ncompute, thermal, and power constraints is challenging. To address these\nchallenges, we propose QuickSRNet, a simple yet effective architecture that\nprovides better accuracy-to-latency trade-offs than existing neural\narchitectures for single-image super resolution. We present training tricks to\nspeed up existing residual-based super-resolution architectures while\nmaintaining robustness to quantization. Our proposed architecture produces\n1080p outputs via 2x upscaling in 2.2 ms on a modern smartphone, making it\nideal for high-fps real-time applications.", "published": "2023-03-08T02:19:54Z", "version": 2}, {"aid": "2303.04571", "authors": ["Yang Yuan"], "title": "A Categorical Framework of General Intelligence", "url": "http://arxiv.org/pdf/2303.04571v2", "summary": "Can machines think? Since Alan Turing asked this question in 1950, nobody is\nable to give a direct answer, due to the lack of solid mathematical foundations\nfor general intelligence. In this paper, we introduce a categorical framework\ntowards this goal, with two main results. First, we investigate object\nrepresentation through presheaves, introducing the notion of self-state\nawareness as a categorical analogue to self-consciousness, along with\ncorresponding algorithms for its enforcement and evaluation. Secondly, we\nextend object representation to scenario representation using diagrams and\nlimits, which then become building blocks for mathematical modeling,\ninterpretability and AI safety. As an ancillary result, our framework\nintroduces various categorical invariance properties that can serve as the\nalignment signals for model training.", "published": "2023-03-08T13:37:01Z", "version": 2}, {"aid": "2303.04589", "authors": ["Xiaoyu Ren", "Zhongying Deng", "Jin Ye", "Junjun He", "Dongxu Yang"], "title": "FCN+: Global Receptive Convolution Makes FCN Great Again", "url": "http://arxiv.org/pdf/2303.04589v2", "summary": "Fully convolutional network (FCN) is a seminal work for semantic\nsegmentation. However, due to its limited receptive field, FCN cannot\neffectively capture global context information which is vital for semantic\nsegmentation. As a result, it is beaten by state-of-the-art methods that\nleverage different filter sizes for larger receptive fields. However, such a\nstrategy usually introduces more parameters and increases the computational\ncost. In this paper, we propose a novel global receptive convolution (GRC) to\neffectively increase the receptive field of FCN for context information\nextraction, which results in an improved FCN termed FCN+. The GRC provides the\nglobal receptive field for convolution without introducing any extra learnable\nparameters. The motivation of GRC is that different channels of a convolutional\nfilter can have different grid sampling locations across the whole input\nfeature map. Specifically, the GRC first divides the channels of the filter\ninto two groups. The grid sampling locations of the first group are shifted to\ndifferent spatial coordinates across the whole feature map, according to their\nchannel indexes. This can help the convolutional filter capture the global\ncontext information. The grid sampling location of the second group remains\nunchanged to keep the original location information. By convolving using these\ntwo groups, the GRC can integrate the global context into the original location\ninformation of each pixel for better dense prediction results. With the GRC\nbuilt in, FCN+ can achieve comparable performance to state-of-the-art methods\nfor semantic segmentation tasks, as verified on PASCAL VOC 2012, Cityscapes,\nand ADE20K. Our code will be released at\nhttps://github.com/Zhongying-Deng/FCN_Plus.", "published": "2023-03-08T14:04:07Z", "version": 2}, {"aid": "2303.04923", "authors": ["Karthik Shetty", "Annette Birkhold", "Srikrishna Jaganathan", "Norbert Strobel", "Bernhard Egger", "Markus Kowarschik", "Andreas Maier"], "title": "BOSS: Bones, Organs and Skin Shape Model", "url": "http://arxiv.org/pdf/2303.04923v1", "summary": "Objective: A digital twin of a patient can be a valuable tool for enhancing\nclinical tasks such as workflow automation, patient-specific X-ray dose\noptimization, markerless tracking, positioning, and navigation assistance in\nimage-guided interventions. However, it is crucial that the patient's surface\nand internal organs are of high quality for any pose and shape estimates. At\npresent, the majority of statistical shape models (SSMs) are restricted to a\nsmall number of organs or bones or do not adequately represent the general\npopulation. Method: To address this, we propose a deformable human shape and\npose model that combines skin, internal organs, and bones, learned from CT\nimages. By modeling the statistical variations in a pose-normalized space using\nprobabilistic PCA while also preserving joint kinematics, our approach offers a\nholistic representation of the body that can benefit various medical\napplications. Results: We assessed our model's performance on a registered\ndataset, utilizing the unified shape space, and noted an average error of 3.6\nmm for bones and 8.8 mm for organs. To further verify our findings, we\nconducted additional tests on publicly available datasets with multi-part\nsegmentations, which confirmed the effectiveness of our model. Conclusion: This\nworks shows that anatomically parameterized statistical shape models can be\ncreated accurately and in a computationally efficient manner. Significance: The\nproposed approach enables the construction of shape models that can be directly\napplied to various medical applications, including biomechanics and\nreconstruction.", "published": "2023-03-08T22:31:24Z", "version": 1}, {"aid": "2303.04976", "authors": ["Umais Zahid", "Qinghai Guo", "Karl Friston", "Zafeirios Fountas"], "title": "Curvature-Sensitive Predictive Coding with Approximate Laplace Monte Carlo", "url": "http://arxiv.org/pdf/2303.04976v1", "summary": "Predictive coding (PC) accounts of perception now form one of the dominant\ncomputational theories of the brain, where they prescribe a general algorithm\nfor inference and learning over hierarchical latent probabilistic models.\nDespite this, they have enjoyed little export to the broader field of machine\nlearning, where comparative generative modelling techniques have flourished. In\npart, this has been due to the poor performance of models trained with PC when\nevaluated by both sample quality and marginal likelihood. By adopting the\nperspective of PC as a variational Bayes algorithm under the Laplace\napproximation, we identify the source of these deficits to lie in the exclusion\nof an associated Hessian term in the PC objective function, which would\notherwise regularise the sharpness of the probability landscape and prevent\nover-certainty in the approximate posterior. To remedy this, we make three\nprimary contributions: we begin by suggesting a simple Monte Carlo estimated\nevidence lower bound which relies on sampling from the Hessian-parameterised\nvariational posterior. We then derive a novel block diagonal approximation to\nthe full Hessian matrix that has lower memory requirements and favourable\nmathematical properties. Lastly, we present an algorithm that combines our\nmethod with standard PC to reduce memory complexity further. We evaluate models\ntrained with our approach against the standard PC framework on image benchmark\ndatasets. Our approach produces higher log-likelihoods and qualitatively better\nsamples that more closely capture the diversity of the data-generating\ndistribution.", "published": "2023-03-09T01:29:58Z", "version": 1}, {"aid": "2303.05125", "authors": ["Zhiheng Liu", "Ruili Feng", "Kai Zhu", "Yifei Zhang", "Kecheng Zheng", "Yu Liu", "Deli Zhao", "Jingren Zhou", "Yang Cao"], "title": "Cones: Concept Neurons in Diffusion Models for Customized Generation", "url": "http://arxiv.org/pdf/2303.05125v1", "summary": "Human brains respond to semantic features of presented stimuli with different\nneurons. It is then curious whether modern deep neural networks admit a similar\nbehavior pattern. Specifically, this paper finds a small cluster of neurons in\na diffusion model corresponding to a particular subject. We call those neurons\nthe concept neurons. They can be identified by statistics of network gradients\nto a stimulation connected with the given subject. The concept neurons\ndemonstrate magnetic properties in interpreting and manipulating generation\nresults. Shutting them can directly yield the related subject contextualized in\ndifferent scenes. Concatenating multiple clusters of concept neurons can\nvividly generate all related concepts in a single image. A few steps of further\nfine-tuning can enhance the multi-concept capability, which may be the first to\nmanage to generate up to four different subjects in a single image. For\nlarge-scale applications, the concept neurons are environmentally friendly as\nwe only need to store a sparse cluster of int index instead of dense float32\nvalues of the parameters, which reduces storage consumption by 90\\% compared\nwith previous subject-driven generation methods. Extensive qualitative and\nquantitative studies on diverse scenarios show the superiority of our method in\ninterpreting and manipulating diffusion models.", "published": "2023-03-09T09:16:04Z", "version": 1}, {"aid": "2303.05848", "authors": ["Thom Badings", "Thiago D. Sim\u00e3o", "Marnix Suilen", "Nils Jansen"], "title": "Decision-Making Under Uncertainty: Beyond Probabilities", "url": "http://arxiv.org/pdf/2303.05848v1", "summary": "This position paper reflects on the state-of-the-art in decision-making under\nuncertainty. A classical assumption is that probabilities can sufficiently\ncapture all uncertainty in a system. In this paper, the focus is on the\nuncertainty that goes beyond this classical interpretation, particularly by\nemploying a clear distinction between aleatoric and epistemic uncertainty. The\npaper features an overview of Markov decision processes (MDPs) and extensions\nto account for partial observability and adversarial behavior. These models\nsufficiently capture aleatoric uncertainty but fail to account for epistemic\nuncertainty robustly. Consequently, we present a thorough overview of so-called\nuncertainty models that exhibit uncertainty in a more robust interpretation. We\nshow several solution techniques for both discrete and continuous models,\nranging from formal verification, over control-based abstractions, to\nreinforcement learning. As an integral part of this paper, we list and discuss\nseveral key challenges that arise when dealing with rich types of uncertainty\nin a model-based fashion.", "published": "2023-03-10T10:53:33Z", "version": 1}, {"aid": "2303.06164", "authors": ["Bryan Lim", "Manon Flageat", "Antoine Cully"], "title": "Understanding the Synergies between Quality-Diversity and Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/2303.06164v1", "summary": "The synergies between Quality-Diversity (QD) and Deep Reinforcement Learning\n(RL) have led to powerful hybrid QD-RL algorithms that have shown tremendous\npotential, and brings the best of both fields. However, only a single deep RL\nalgorithm (TD3) has been used in prior hybrid methods despite notable progress\nmade by other RL algorithms. Additionally, there are fundamental differences in\nthe optimization procedures between QD and RL which would benefit from a more\nprincipled approach. We propose Generalized Actor-Critic QD-RL, a unified\nmodular framework for actor-critic deep RL methods in the QD-RL setting. This\nframework provides a path to study insights from Deep RL in the QD-RL setting,\nwhich is an important and efficient way to make progress in QD-RL. We introduce\ntwo new algorithms, PGA-ME (SAC) and PGA-ME (DroQ) which apply recent\nadvancements in Deep RL to the QD-RL setting, and solves the humanoid\nenvironment which was not possible using existing QD-RL algorithms. However, we\nalso find that not all insights from Deep RL can be effectively translated to\nQD-RL. Critically, this work also demonstrates that the actor-critic models in\nQD-RL are generally insufficiently trained and performance gains can be\nachieved without any additional environment evaluations.", "published": "2023-03-10T19:02:42Z", "version": 1}, {"aid": "2303.06173", "authors": ["Xander Davies", "Lauro Langosco", "David Krueger"], "title": "Unifying Grokking and Double Descent", "url": "http://arxiv.org/pdf/2303.06173v1", "summary": "A principled understanding of generalization in deep learning may require\nunifying disparate observations under a single conceptual framework. Previous\nwork has studied \\emph{grokking}, a training dynamic in which a sustained\nperiod of near-perfect training performance and near-chance test performance is\neventually followed by generalization, as well as the superficially similar\n\\emph{double descent}. These topics have so far been studied in isolation. We\nhypothesize that grokking and double descent can be understood as instances of\nthe same learning dynamics within a framework of pattern learning speeds. We\npropose that this framework also applies when varying model capacity instead of\noptimization steps, and provide the first demonstration of model-wise grokking.", "published": "2023-03-10T19:16:53Z", "version": 1}, {"aid": "2303.08080", "authors": ["Shimon Edelman"], "title": "Verbal behavior without syntactic structures: beyond Skinner and Chomsky", "url": "http://arxiv.org/pdf/2303.08080v1", "summary": "What does it mean to know language? Since the Chomskian revolution, one\npopular answer to this question has been: to possess a generative grammar that\nexclusively licenses certain syntactic structures. Decades later, not even an\napproximation to such a grammar, for any language, has been formulated; the\nidea that grammar is universal and innately specified has proved barren; and\nattempts to show how it could be learned from experience invariably come up\nshort. To move on from this impasse, we must rediscover the extent to which\nlanguage is like any other human behavior: dynamic, social, multimodal,\npatterned, and purposive, its purpose being to promote desirable actions (or\nthoughts) in others and self. Recent psychological, computational,\nneurobiological, and evolutionary insights into the shaping and structure of\nbehavior may then point us toward a new, viable account of language.", "published": "2023-03-11T00:01:21Z", "version": 1}, {"aid": "2303.06298", "authors": ["Samir Mitha", "Seungho Choe", "Pejman Jahbedar Maralani", "Alan R. Moody", "April Khademi"], "title": "MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer", "url": "http://arxiv.org/pdf/2303.06298v1", "summary": "We propose a novel architecture called MLP-SRGAN, which is a single-dimension\nSuper Resolution Generative Adversarial Network (SRGAN) that utilizes\nMulti-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to\nupsample in the slice direction. MLP-SRGAN is trained and validated using high\nresolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was\napplied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with\nlow spatial resolution in the slice dimension to examine performance on\nheld-out (unseen) clinical data. Upsampled results are compared to several\nstate-of-the-art SR networks. For images with high resolution (HR) ground\ntruths, peak-signal-to-noise-ratio (PSNR) and structural similarity index\n(SSIM) are used to measure upsampling performance. Several new structural,\nno-reference image quality metrics were proposed to quantify sharpness (edge\nstrength), noise (entropy), and blurriness (low frequency information) in the\nabsence of ground truths. Results show MLP-SRGAN results in sharper edges, less\nblurring, preserves more texture and fine-anatomical detail, with fewer\nparameters, faster training/evaluation time, and smaller model size than\nexisting methods. Code for MLP-SRGAN training and inference, data generators,\nmodels and no-reference image quality metrics will be available at\nhttps://github.com/IAMLAB-Ryerson/MLP-SRGAN.", "published": "2023-03-11T04:05:57Z", "version": 1}, {"aid": "2303.06869", "authors": ["Biao Qian", "Yang Wang", "Richang Hong", "Meng Wang"], "title": "Adaptive Data-Free Quantization", "url": "http://arxiv.org/pdf/2303.06869v3", "summary": "Data-free quantization (DFQ) recovers the performance of quantized network\n(Q) without the original data, but generates the fake sample via a generator\n(G) by learning from full-precision network (P), which, however, is totally\nindependent of Q, overlooking the adaptability of the knowledge from generated\nsamples, i.e., informative or not to the learning process of Q, resulting into\nthe overflow of generalization error. Building on this, several critical\nquestions -- how to measure the sample adaptability to Q under varied bit-width\nscenarios? whether the largest adaptability is the best? how to generate the\nsamples with adaptive adaptability to improve Q's generalization? To answer the\nabove questions, in this paper, we propose an Adaptive Data-Free Quantization\n(AdaDFQ) method, which revisits DFQ from a zero-sum game perspective upon the\nsample adaptability between two players -- a generator and a quantized network.\nFollowing this viewpoint, we further define the disagreement and agreement\nsamples to form two boundaries, where the margin is optimized to adaptively\nregulate the adaptability of generated samples to Q, so as to address the\nover-and-under fitting issues. Our AdaDFQ reveals: 1) the largest adaptability\nis NOT the best for sample generation to benefit Q's generalization; 2) the\nknowledge of the generated sample should not be informative to Q only, but also\nrelated to the category and distribution information of the training data for\nP. The theoretical and empirical analysis validate the advantages of AdaDFQ\nover the state-of-the-arts. Our code is available at\nhttps://github.com/hfutqian/AdaDFQ.", "published": "2023-03-13T05:37:40Z", "version": 3}, {"aid": "2303.07402", "authors": ["Zhinan Qiao", "Xiaohui Yuan"], "title": "Designing Deep Networks for Scene Recognition", "url": "http://arxiv.org/pdf/2303.07402v1", "summary": "Most deep learning backbones are evaluated on ImageNet. Using scenery images\nas an example, we conducted extensive experiments to demonstrate the widely\naccepted principles in network design may result in dramatic performance\ndifferences when the data is altered. Exploratory experiments are engaged to\nexplain the underlining cause of the differences. Based on our observation,\nthis paper presents a novel network design methodology: data-oriented network\ndesign. In other words, instead of designing universal backbones, the scheming\nof the networks should treat the characteristics of data as a crucial\ncomponent. We further proposed a Deep-Narrow Network and Dilated Pooling\nmodule, which improved the scene recognition performance using less than half\nof the computational resources compared to the benchmark network architecture\nResNets. The source code is publicly available on\nhttps://github.com/ZN-Qiao/Deep-Narrow-Network.", "published": "2023-03-13T18:28:06Z", "version": 1}, {"aid": "2303.07507", "authors": ["Zaheer Abbas", "Rosie Zhao", "Joseph Modayil", "Adam White", "Marlos C. Machado"], "title": "Loss of Plasticity in Continual Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/2303.07507v1", "summary": "The ability to learn continually is essential in a complex and changing\nworld. In this paper, we characterize the behavior of canonical value-based\ndeep reinforcement learning (RL) approaches under varying degrees of\nnon-stationarity. In particular, we demonstrate that deep RL agents lose their\nability to learn good policies when they cycle through a sequence of Atari 2600\ngames. This phenomenon is alluded to in prior work under various guises --\ne.g., loss of plasticity, implicit under-parameterization, primacy bias, and\ncapacity loss. We investigate this phenomenon closely at scale and analyze how\nthe weights, gradients, and activations change over time in several experiments\nwith varying dimensions (e.g., similarity between games, number of games,\nnumber of frames per game), with some experiments spanning 50 days and 2\nbillion environment interactions. Our analysis shows that the activation\nfootprint of the network becomes sparser, contributing to the diminishing\ngradients. We investigate a remarkably simple mitigation strategy --\nConcatenated ReLUs (CReLUs) activation function -- and demonstrate its\neffectiveness in facilitating continual learning in a changing environment.", "published": "2023-03-13T22:37:15Z", "version": 1}, {"aid": "2303.07677", "authors": ["Hui Tang", "Yao Lu", "Qi Xuan"], "title": "SR-init: An interpretable layer pruning method", "url": "http://arxiv.org/pdf/2303.07677v2", "summary": "Despite the popularization of deep neural networks (DNNs) in many fields, it\nis still challenging to deploy state-of-the-art models to resource-constrained\ndevices due to high computational overhead. Model pruning provides a feasible\nsolution to the aforementioned challenges. However, the interpretation of\nexisting pruning criteria is always overlooked. To counter this issue, we\npropose a novel layer pruning method by exploring the Stochastic\nRe-initialization. Our SR-init method is inspired by the discovery that the\naccuracy drop due to stochastic re-initialization of layer parameters differs\nin various layers. On the basis of this observation, we come up with a layer\npruning criterion, i.e., those layers that are not sensitive to stochastic\nre-initialization (low accuracy drop) produce less contribution to the model\nand could be pruned with acceptable loss. Afterward, we experimentally verify\nthe interpretability of SR-init via feature visualization. The visual\nexplanation demonstrates that SR-init is theoretically feasible, thus we\ncompare it with state-of-the-art methods to further evaluate its\npracticability. As for ResNet56 on CIFAR-10 and CIFAR-100, SR-init achieves a\ngreat reduction in parameters (63.98% and 37.71%) with an ignorable drop in\ntop-1 accuracy (-0.56% and 0.8%). With ResNet50 on ImageNet, we achieve a\n15.59% FLOPs reduction by removing 39.29% of the parameters, with only a drop\nof 0.6% in top-1 accuracy. Our code is available at\nhttps://github.com/huitang-zjut/SR-init.", "published": "2023-03-14T07:26:55Z", "version": 2}, {"aid": "2303.07683", "authors": ["Javier D\u00edaz", "Hiroyasu Ando", "GoEun Han", "Olga Malyshevskaya", "Xifang Hayashi", "Juan-Carlos Letelier", "Masashi Yanagisawa", "Kaspar E. Vogt"], "title": "Recovering Arrhythmic EEG Transients from Their Stochastic Interference", "url": "http://arxiv.org/pdf/2303.07683v1", "summary": "Traditionally, the neuronal dynamics underlying electroencephalograms (EEG)\nhave been understood as arising from \\textit{rhythmic oscillators with varying\ndegrees of synchronization}. This dominant metaphor employs frequency domain\nEEG analysis to identify the most prominent populations of neuronal current\nsources in terms of their frequency and spectral power. However, emerging\nperspectives on EEG highlight its arrhythmic nature, which is primarily\ninferred from broadband EEG properties like the ubiquitous $1/f$ spectrum. In\nthe present study, we use an \\textit{arrhythmic superposition of pulses} as a\nmetaphor to explain the origin of EEG. This conceptualization has a fundamental\nproblem because the interference produced by the superpositions of pulses\ngenerates colored Gaussian noise, masking the temporal profile of the\ngenerating pulse. We solved this problem by developing a mathematical method\ninvolving the derivative of the autocovariance function to recover excellent\napproximations of the underlying pulses, significantly extending the analysis\nof this type of stochastic processes. When the method is applied to spontaneous\nmouse EEG sampled at $5$ kHz during the sleep-wake cycle, specific patterns --\ncalled $\\Psi$-patterns -- characterizing NREM sleep, REM sleep, and wakefulness\nare revealed. $\\Psi$-patterns can be understood theoretically as \\textit{power\ndensity in the time domain} and correspond to combinations of generating pulses\nat different time scales. Remarkably, we report the first EEG\nwakefulness-specific feature, which corresponds to an ultra-fast ($\\sim 1$ ms)\ntransient component of the observed patterns. By shifting the paradigm of EEG\ngenesis from oscillators to random pulse generators, our theoretical framework\npushes the boundaries of traditional Fourier-based EEG analysis, paving the way\nfor new insights into the arrhythmic components of neural dynamics.", "published": "2023-03-14T07:53:28Z", "version": 1}, {"aid": "2303.07820", "authors": ["Yifan Pu", "Yiru Wang", "Zhuofan Xia", "Yizeng Han", "Yulin Wang", "Weihao Gan", "Zidong Wang", "Shiji Song", "Gao Huang"], "title": "Adaptive Rotated Convolution for Rotated Object Detection", "url": "http://arxiv.org/pdf/2303.07820v2", "summary": "Rotated object detection aims to identify and locate objects in images with\narbitrary orientation. In this scenario, the oriented directions of objects\nvary considerably across different images, while multiple orientations of\nobjects exist within an image. This intrinsic characteristic makes it\nchallenging for standard backbone networks to extract high-quality features of\nthese arbitrarily orientated objects. In this paper, we present Adaptive\nRotated Convolution (ARC) module to handle the aforementioned challenges. In\nour ARC module, the convolution kernels rotate adaptively to extract object\nfeatures with varying orientations in different images, and an efficient\nconditional computation mechanism is introduced to accommodate the large\norientation variations of objects within an image. The two designs work\nseamlessly in rotated object detection problem. Moreover, ARC can conveniently\nserve as a plug-and-play module in various vision backbones to boost their\nrepresentation ability to detect oriented objects accurately. Experiments on\ncommonly used benchmarks (DOTA and HRSC2016) demonstrate that equipped with our\nproposed ARC module in the backbone network, the performance of multiple\npopular oriented object detectors is significantly improved (\\eg +3.03\\% mAP on\nRotated RetinaNet and +4.16\\% on CFA). Combined with the highly competitive\nmethod Oriented R-CNN, the proposed approach achieves state-of-the-art\nperformance on the DOTA dataset with 81.77\\% mAP. Code is available at\n\\url{https://github.com/LeapLabTHU/ARC}.", "published": "2023-03-14T11:53:12Z", "version": 2}, {"aid": "2303.08063", "authors": ["Weiyang Jin", "Yongpei Zhu", "Yuxi Peng"], "title": "Interpretable ODE-style Generative Diffusion Model via Force Field Construction", "url": "http://arxiv.org/pdf/2303.08063v3", "summary": "For a considerable time, researchers have focused on developing a method that\nestablishes a deep connection between the generative diffusion model and\nmathematical physics. Despite previous efforts, progress has been limited to\nthe pursuit of a single specialized method. In order to advance the\ninterpretability of diffusion models and explore new research directions, it is\nessential to establish a unified ODE-style generative diffusion model. Such a\nmodel should draw inspiration from physical models and possess a clear\ngeometric meaning. This paper aims to identify various physical models that are\nsuitable for constructing ODE-style generative diffusion models accurately from\na mathematical perspective. We then summarize these models into a unified\nmethod. Additionally, we perform a case study where we use the theoretical\nmodel identified by our method to develop a range of new diffusion model\nmethods, and conduct experiments. Our experiments on CIFAR-10 demonstrate the\neffectiveness of our approach. We have constructed a computational framework\nthat attains highly proficient results with regards to image generation speed,\nalongside an additional model that demonstrates exceptional performance in both\nInception score and FID score. These results underscore the significance of our\nmethod in advancing the field of diffusion models.", "published": "2023-03-14T16:58:11Z", "version": 3}, {"aid": "2303.08085", "authors": ["Hagay Michaeli", "Tomer Michaeli", "Daniel Soudry"], "title": "Alias-Free Convnets: Fractional Shift Invariance via Polynomial Activations", "url": "http://arxiv.org/pdf/2303.08085v2", "summary": "Although CNNs are believed to be invariant to translations, recent works have\nshown this is not the case, due to aliasing effects that stem from downsampling\nlayers. The existing architectural solutions to prevent aliasing are partial\nsince they do not solve these effects, that originate in non-linearities. We\npropose an extended anti-aliasing method that tackles both downsampling and\nnon-linear layers, thus creating truly alias-free, shift-invariant CNNs. We\nshow that the presented model is invariant to integer as well as fractional\n(i.e., sub-pixel) translations, thus outperforming other shift-invariant\nmethods in terms of robustness to adversarial translations.", "published": "2023-03-14T17:16:16Z", "version": 2}, {"aid": "2303.08133", "authors": ["Zhen Liu", "Yao Feng", "Michael J. Black", "Derek Nowrouzezahrai", "Liam Paull", "Weiyang Liu"], "title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling", "url": "http://arxiv.org/pdf/2303.08133v2", "summary": "We consider the task of generating realistic 3D shapes, which is useful for a\nvariety of applications such as automatic scene generation and physical\nsimulation. Compared to other 3D representations like voxels and point clouds,\nmeshes are more desirable in practice, because (1) they enable easy and\narbitrary manipulation of shapes for relighting and simulation, and (2) they\ncan fully leverage the power of modern graphics pipelines which are mostly\noptimized for meshes. Previous scalable methods for generating meshes typically\nrely on sub-optimal post-processing, and they tend to produce overly-smooth or\nnoisy surfaces without fine-grained geometric details. To overcome these\nshortcomings, we take advantage of the graph structure of meshes and use a\nsimple yet very effective generative modeling method to generate 3D meshes.\nSpecifically, we represent meshes with deformable tetrahedral grids, and then\ntrain a diffusion model on this direct parametrization. We demonstrate the\neffectiveness of our model on multiple generative tasks.", "published": "2023-03-14T17:59:01Z", "version": 2}, {"aid": "2303.08134", "authors": ["Renrui Zhang", "Liuhui Wang", "Ziyu Guo", "Yali Wang", "Peng Gao", "Hongsheng Li", "Jianbo Shi"], "title": "Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis", "url": "http://arxiv.org/pdf/2303.08134v2", "summary": "We present a Non-parametric Network for 3D point cloud analysis, Point-NN,\nwhich consists of purely non-learnable components: farthest point sampling\n(FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric\nfunctions. Surprisingly, it performs well on various 3D tasks, requiring no\nparameters or training, and even surpasses existing fully trained models.\nStarting from this basic non-parametric model, we propose two extensions.\nFirst, Point-NN can serve as a base architectural framework to construct\nParametric Networks by simply inserting linear layers on top. Given the\nsuperior non-parametric foundation, the derived Point-PN exhibits a high\nperformance-efficiency trade-off with only a few learnable parameters. Second,\nPoint-NN can be regarded as a plug-and-play module for the already trained 3D\nmodels during inference. Point-NN captures the complementary geometric\nknowledge and enhances existing methods for different 3D benchmarks without\nre-training. We hope our work may cast a light on the community for\nunderstanding 3D point clouds with non-parametric methods. Code is available at\nhttps://github.com/ZrrSkywalker/Point-NN.", "published": "2023-03-14T17:59:02Z", "version": 2}, {"aid": "2303.08320", "authors": ["Zhengxiong Luo", "Dayou Chen", "Yingya Zhang", "Yan Huang", "Liang Wang", "Yujun Shen", "Deli Zhao", "Jingren Zhou", "Tieniu Tan"], "title": "VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation", "url": "http://arxiv.org/pdf/2303.08320v4", "summary": "A diffusion probabilistic model (DPM), which constructs a forward diffusion\nprocess by gradually adding noise to data points and learns the reverse\ndenoising process to generate new samples, has been shown to handle complex\ndata distribution. Despite its recent success in image synthesis, applying DPMs\nto video generation is still challenging due to high-dimensional data spaces.\nPrevious methods usually adopt a standard diffusion process, where frames in\nthe same video clip are destroyed with independent noises, ignoring the content\nredundancy and temporal correlation. This work presents a decomposed diffusion\nprocess via resolving the per-frame noise into a base noise that is shared\namong all frames and a residual noise that varies along the time axis. The\ndenoising pipeline employs two jointly-learned networks to match the noise\ndecomposition accordingly. Experiments on various datasets confirm that our\napproach, termed as VideoFusion, surpasses both GAN-based and diffusion-based\nalternatives in high-quality video generation. We further show that our\ndecomposed formulation can benefit from pre-trained image diffusion models and\nwell-support text-conditioned video creation.", "published": "2023-03-15T02:16:39Z", "version": 4}, {"aid": "2303.08496", "authors": ["Jorge Vila-Tom\u00e1s", "Pablo Hern\u00e1ndez-C\u00e1mara", "Jes\u00fas Malo"], "title": "Psychophysics of Artificial Neural Networks Questions Classical Hue Cancellation Experiments", "url": "http://arxiv.org/pdf/2303.08496v2", "summary": "We show that classical hue cancellation experiments lead to human-like\nopponent curves even if the task is done by trivial (identity) artificial\nnetworks. Specifically, human-like opponent spectral sensitivities always\nemerge in artificial networks as long as (i) the retina converts the input\nradiation into any tristimulus-like representation, and (ii) the post-retinal\nnetwork solves the standard hue cancellation task, e.g. the network looks for\nthe weights of the cancelling lights so that every monochromatic stimulus plus\nthe weighted cancelling lights match a grey reference in the (arbitrary) color\nrepresentation used by the network. In fact, the specific cancellation lights\n(and not the network architecture) are key to obtain human-like curves: results\nshow that the classical choice of the lights is the one that leads to the best\n(more human-like) result, and any other choices lead to progressively different\nspectral sensitivities. We show this in two ways: through artificial\npsychophysics using a range of networks with different architectures and a\nrange of cancellation lights, and through a change-of-basis theoretical analogy\nof the experiments. This suggests that the opponent curves of the classical\nexperiment are just a by-product of the front-end photoreceptors and of a very\nspecific experimental choice but they do not inform about the downstream color\nrepresentation. In fact, the architecture of the post-retinal network (signal\nrecombination or internal color space) seems irrelevant for the emergence of\nthe curves in the classical experiment. This result in artificial networks\nquestions the conventional interpretation of the classical result in humans by\nJameson and Hurvich.", "published": "2023-03-15T10:13:34Z", "version": 2}, {"aid": "2303.08714", "authors": ["Shuyao Shang", "Zhengyang Shan", "Guangxing Liu", "LunQian Wang", "XingHua Wang", "Zekai Zhang", "Jinglin Zhang"], "title": "ResDiff: Combining CNN and Diffusion Model for Image Super-Resolution", "url": "http://arxiv.org/pdf/2303.08714v3", "summary": "Adapting the Diffusion Probabilistic Model (DPM) for direct image\nsuper-resolution is wasteful, given that a simple Convolutional Neural Network\n(CNN) can recover the main low-frequency content. Therefore, we present\nResDiff, a novel Diffusion Probabilistic Model based on Residual structure for\nSingle Image Super-Resolution (SISR). ResDiff utilizes a combination of a CNN,\nwhich restores primary low-frequency components, and a DPM, which predicts the\nresidual between the ground-truth image and the CNN predicted image. In\ncontrast to the common diffusion-based methods that directly use LR images to\nguide the noise towards HR space, ResDiff utilizes the CNN's initial prediction\nto direct the noise towards the residual space between HR space and\nCNN-predicted space, which not only accelerates the generation process but also\nacquires superior sample quality. Additionally, a frequency-domain-based loss\nfunction for CNN is introduced to facilitate its restoration, and a\nfrequency-domain guided diffusion is designed for DPM on behalf of predicting\nhigh-frequency details. The extensive experiments on multiple benchmark\ndatasets demonstrate that ResDiff outperforms previous diffusion based methods\nin terms of shorter model convergence time, superior generation quality, and\nmore diverse samples.", "published": "2023-03-15T15:50:11Z", "version": 3}, {"aid": "2303.09295", "authors": ["Zhendong Wang", "Jianmin Bao", "Wengang Zhou", "Weilun Wang", "Hezhen Hu", "Hong Chen", "Houqiang Li"], "title": "DIRE for Diffusion-Generated Image Detection", "url": "http://arxiv.org/pdf/2303.09295v1", "summary": "Diffusion models have shown remarkable success in visual synthesis, but have\nalso raised concerns about potential abuse for malicious purposes. In this\npaper, we seek to build a detector for telling apart real images from\ndiffusion-generated images. We find that existing detectors struggle to detect\nimages generated by diffusion models, even if we include generated images from\na specific diffusion model in their training data. To address this issue, we\npropose a novel image representation called DIffusion Reconstruction Error\n(DIRE), which measures the error between an input image and its reconstruction\ncounterpart by a pre-trained diffusion model. We observe that\ndiffusion-generated images can be approximately reconstructed by a diffusion\nmodel while real images cannot. It provides a hint that DIRE can serve as a\nbridge to distinguish generated and real images. DIRE provides an effective way\nto detect images generated by most diffusion models, and it is general for\ndetecting generated images from unseen diffusion models and robust to various\nperturbations. Furthermore, we establish a comprehensive diffusion-generated\nbenchmark including images generated by eight diffusion models to evaluate the\nperformance of diffusion-generated image detectors. Extensive experiments on\nour collected benchmark demonstrate that DIRE exhibits superiority over\nprevious generated-image detectors. The code and dataset are available at\nhttps://github.com/ZhendongWang6/DIRE.", "published": "2023-03-16T13:15:03Z", "version": 1}, {"aid": "2303.09556", "authors": ["Tiankai Hang", "Shuyang Gu", "Chen Li", "Jianmin Bao", "Dong Chen", "Han Hu", "Xin Geng", "Baining Guo"], "title": "Efficient Diffusion Training via Min-SNR Weighting Strategy", "url": "http://arxiv.org/pdf/2303.09556v3", "summary": "Denoising diffusion models have been a mainstream approach for image\ngeneration, however, training these models often suffers from slow convergence.\nIn this paper, we discovered that the slow convergence is partly due to\nconflicting optimization directions between timesteps. To address this issue,\nwe treat the diffusion training as a multi-task learning problem, and introduce\na simple yet effective approach referred to as Min-SNR-$\\gamma$. This method\nadapts loss weights of timesteps based on clamped signal-to-noise ratios, which\neffectively balances the conflicts among timesteps. Our results demonstrate a\nsignificant improvement in converging speed, 3.4$\\times$ faster than previous\nweighting strategies. It is also more effective, achieving a new record FID\nscore of 2.06 on the ImageNet $256\\times256$ benchmark using smaller\narchitectures than that employed in previous state-of-the-art. The code is\navailable at https://github.com/TiankaiHang/Min-SNR-Diffusion-Training.", "published": "2023-03-16T17:59:56Z", "version": 3}, {"aid": "2303.11934", "authors": ["Trenton Bricken", "Xander Davies", "Deepak Singh", "Dmitry Krotov", "Gabriel Kreiman"], "title": "Sparse Distributed Memory is a Continual Learner", "url": "http://arxiv.org/pdf/2303.11934v1", "summary": "Continual learning is a problem for artificial neural networks that their\nbiological counterparts are adept at solving. Building on work using Sparse\nDistributed Memory (SDM) to connect a core neural circuit with the powerful\nTransformer model, we create a modified Multi-Layered Perceptron (MLP) that is\na strong continual learner. We find that every component of our MLP variant\ntranslated from biology is necessary for continual learning. Our solution is\nalso free from any memory replay or task information, and introduces novel\nmethods to train sparse networks that may be broadly applicable.", "published": "2023-03-20T16:54:10Z", "version": 1}, {"aid": "2303.11435", "authors": ["Mauricio Delbracio", "Peyman Milanfar"], "title": "Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration", "url": "http://arxiv.org/pdf/2303.11435v5", "summary": "Inversion by Direct Iteration (InDI) is a new formulation for supervised\nimage restoration that avoids the so-called \"regression to the mean\" effect and\nproduces more realistic and detailed images than existing regression-based\nmethods. It does this by gradually improving image quality in small steps,\nsimilar to generative denoising diffusion models. Image restoration is an\nill-posed problem where multiple high-quality images are plausible\nreconstructions of a given low-quality input. Therefore, the outcome of a\nsingle step regression model is typically an aggregate of all possible\nexplanations, therefore lacking details and realism. The main advantage of InDI\nis that it does not try to predict the clean target image in a single step but\ninstead gradually improves the image in small steps, resulting in better\nperceptual quality. While generative denoising diffusion models also work in\nsmall steps, our formulation is distinct in that it does not require knowledge\nof any analytic form of the degradation process. Instead, we directly learn an\niterative restoration process from low-quality and high-quality paired\nexamples. InDI can be applied to virtually any image degradation, given paired\ntraining data. In conditional denoising diffusion image restoration the\ndenoising network generates the restored image by repeatedly denoising an\ninitial image of pure noise, conditioned on the degraded input. Contrary to\nconditional denoising formulations, InDI directly proceeds by iteratively\nrestoring the input low-quality image, producing high-quality results on a\nvariety of image restoration tasks, including motion and out-of-focus\ndeblurring, super-resolution, compression artifact removal, and denoising.", "published": "2023-03-20T20:28:17Z", "version": 5}, {"aid": "2303.13750", "authors": ["Qian Tao", "Zhen Wang", "Wenyuan Yu", "Yaliang Li", "Zhewei Wei"], "title": "LON-GNN: Spectral GNNs with Learnable Orthonormal Basis", "url": "http://arxiv.org/pdf/2303.13750v2", "summary": "In recent years, a plethora of spectral graph neural networks (GNN) methods\nhave utilized polynomial basis with learnable coefficients to achieve top-tier\nperformances on many node-level tasks. Although various kinds of polynomial\nbases have been explored, each such method adopts a fixed polynomial basis\nwhich might not be the optimal choice for the given graph. Besides, we identify\nthe so-called over-passing issue of these methods and show that it is somewhat\nrooted in their less-principled regularization strategy and unnormalized basis.\nIn this paper, we make the first attempts to address these two issues.\nLeveraging Jacobi polynomials, we design a novel spectral GNN, LON-GNN, with\nLearnable OrthoNormal bases and prove that regularizing coefficients becomes\nequivalent to regularizing the norm of learned filter function now. We conduct\nextensive experiments on diverse graph datasets to evaluate the fitting and\ngeneralization capability of LON-GNN, where the results imply its superiority.", "published": "2023-03-24T02:07:46Z", "version": 2}, {"aid": "2303.13826", "authors": ["Huantong Li", "Xiangmiao Wu", "Fanbing Lv", "Daihai Liao", "Thomas H. Li", "Yonggang Zhang", "Bo Han", "Mingkui Tan"], "title": "Hard Sample Matters a Lot in Zero-Shot Quantization", "url": "http://arxiv.org/pdf/2303.13826v1", "summary": "Zero-shot quantization (ZSQ) is promising for compressing and accelerating\ndeep neural networks when the data for training full-precision models are\ninaccessible. In ZSQ, network quantization is performed using synthetic\nsamples, thus, the performance of quantized models depends heavily on the\nquality of synthetic samples. Nonetheless, we find that the synthetic samples\nconstructed in existing ZSQ methods can be easily fitted by models.\nAccordingly, quantized models obtained by these methods suffer from significant\nperformance degradation on hard samples. To address this issue, we propose HArd\nsample Synthesizing and Training (HAST). Specifically, HAST pays more attention\nto hard samples when synthesizing samples and makes synthetic samples hard to\nfit when training quantized models. HAST aligns features extracted by\nfull-precision and quantized models to ensure the similarity between features\nextracted by these two models. Extensive experiments show that HAST\nsignificantly outperforms existing ZSQ methods, achieving performance\ncomparable to models that are quantized with real data.", "published": "2023-03-24T06:22:57Z", "version": 1}, {"aid": "2303.13896", "authors": ["Grigorios G Chrysos", "Bohan Wang", "Jiankang Deng", "Volkan Cevher"], "title": "Regularization of polynomial networks for image recognition", "url": "http://arxiv.org/pdf/2303.13896v1", "summary": "Deep Neural Networks (DNNs) have obtained impressive performance across\ntasks, however they still remain as black boxes, e.g., hard to theoretically\nanalyze. At the same time, Polynomial Networks (PNs) have emerged as an\nalternative method with a promising performance and improved interpretability\nbut have yet to reach the performance of the powerful DNN baselines. In this\nwork, we aim to close this performance gap. We introduce a class of PNs, which\nare able to reach the performance of ResNet across a range of six benchmarks.\nWe demonstrate that strong regularization is critical and conduct an extensive\nstudy of the exact regularization schemes required to match performance. To\nfurther motivate the regularization schemes, we introduce D-PolyNets that\nachieve a higher-degree of expansion than previously proposed polynomial\nnetworks. D-PolyNets are more parameter-efficient while achieving a similar\nperformance as other polynomial networks. We expect that our new models can\nlead to an understanding of the role of elementwise activation functions (which\nare no longer required for training PNs). The source code is available at\nhttps://github.com/grigorisg9gr/regularized_polynomials.", "published": "2023-03-24T10:05:22Z", "version": 1}, {"aid": "2303.14341", "authors": ["Yifu Ding", "Haotong Qin", "Qinghua Yan", "Zhenhua Chai", "Junjie Liu", "Xiaolin Wei", "Xianglong Liu"], "title": "Towards Accurate Post-Training Quantization for Vision Transformer", "url": "http://arxiv.org/pdf/2303.14341v1", "summary": "Vision transformer emerges as a potential architecture for vision tasks.\nHowever, the intense computation and non-negligible delay hinder its\napplication in the real world. As a widespread model compression technique,\nexisting post-training quantization methods still cause severe performance\ndrops. We find the main reasons lie in (1) the existing calibration metric is\ninaccurate in measuring the quantization influence for extremely low-bit\nrepresentation, and (2) the existing quantization paradigm is unfriendly to the\npower-law distribution of Softmax. Based on these observations, we propose a\nnovel Accurate Post-training Quantization framework for Vision Transformer,\nnamely APQ-ViT. We first present a unified Bottom-elimination Blockwise\nCalibration scheme to optimize the calibration metric to perceive the overall\nquantization disturbance in a blockwise manner and prioritize the crucial\nquantization errors that influence more on the final output. Then, we design a\nMatthew-effect Preserving Quantization for Softmax to maintain the power-law\ncharacter and keep the function of the attention mechanism. Comprehensive\nexperiments on large-scale classification and detection datasets demonstrate\nthat our APQ-ViT surpasses the existing post-training quantization methods by\nconvincing margins, especially in lower bit-width settings (e.g., averagely up\nto 5.17% improvement for classification and 24.43% for detection on W4A4). We\nalso highlight that APQ-ViT enjoys versatility and works well on diverse\ntransformer variants.", "published": "2023-03-25T03:05:26Z", "version": 1}, {"aid": "2303.14389", "authors": ["Shanghua Gao", "Pan Zhou", "Ming-Ming Cheng", "Shuicheng Yan"], "title": "MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer", "url": "http://arxiv.org/pdf/2303.14389v2", "summary": "Despite its success in image synthesis, we observe that diffusion\nprobabilistic models (DPMs) often lack contextual reasoning ability to learn\nthe relations among object parts in an image, leading to a slow learning\nprocess. To solve this issue, we propose a Masked Diffusion Transformer (MDT)\nthat introduces a mask latent modeling scheme to explicitly enhance the DPMs'\nability to contextual relation learning among object semantic parts in an\nimage. During training, MDT operates in the latent space to mask certain\ntokens. Then, an asymmetric diffusion transformer is designed to predict masked\ntokens from unmasked ones while maintaining the diffusion generation process.\nOur MDT can reconstruct the full information of an image from its incomplete\ncontextual input, thus enabling it to learn the associated relations among\nimage tokens. We further improve MDT with a more efficient macro network\nstructure and training strategy, named MDTv2. Experimental results show that\nMDTv2 achieves superior image synthesis performance, e.g., a new SOTA FID score\nof 1.58 on the ImageNet dataset, and has more than 10x faster learning speed\nthan the previous SOTA DiT. The source code is released at\nhttps://github.com/sail-sg/MDT.", "published": "2023-03-25T07:47:21Z", "version": 2}, {"aid": "2303.14448", "authors": ["Trevor McCourt", "Ila R. Fiete", "Isaac L. Chuang"], "title": "Noisy dynamical systems evolve error correcting codes and modularity", "url": "http://arxiv.org/pdf/2303.14448v2", "summary": "Noise is a ubiquitous feature of the physical world. As a result, the first\nprerequisite of life is fault tolerance: maintaining integrity of state despite\nexternal bombardment. Recent experimental advances have revealed that\nbiological systems achieve fault tolerance by implementing mathematically\nintricate error-correcting codes and by organizing in a modular fashion that\nphysically separates functionally distinct subsystems. These elaborate\nstructures represent a vanishing volume in the massive genetic configuration\nspace. How is it possible that the primitive process of evolution, by which all\nbiological systems evolved, achieved such unusual results? In this work,\nthrough experiments in Boolean networks, we show that the simultaneous presence\nof error correction and modularity in biological systems is no coincidence.\nRather, it is a typical co-occurrence in noisy dynamic systems undergoing\nevolution. From this, we deduce the principle of error correction enhanced\nevolvability: systems possessing error-correcting codes are more effectively\nimproved by evolution than those without.", "published": "2023-03-25T11:54:18Z", "version": 2}, {"aid": "2303.16067", "authors": ["Aaron Pache", "Mark CW van Rossum"], "title": "Lazy learning: a biologically-inspired plasticity rule for fast and energy efficient synaptic plasticity", "url": "http://arxiv.org/pdf/2303.16067v1", "summary": "When training neural networks for classification tasks with backpropagation,\nparameters are updated on every trial, even if the sample is classified\ncorrectly. In contrast, humans concentrate their learning effort on errors.\nInspired by human learning, we introduce lazy learning, which only learns on\nincorrect samples. Lazy learning can be implemented in a few lines of code and\nrequires no hyperparameter tuning. Lazy learning achieves state-of-the-art\nperformance and is particularly suited when datasets are large. For instance,\nit reaches 99.2% test accuracy on Extended MNIST using a single-layer MLP, and\ndoes so 7.6x faster than a matched backprop network", "published": "2023-03-26T16:17:04Z", "version": 1}, {"aid": "2303.15672", "authors": ["Guanghui Lan", "Alexander Shapiro"], "title": "Numerical Methods for Convex Multistage Stochastic Optimization", "url": "http://arxiv.org/pdf/2303.15672v1", "summary": "Optimization problems involving sequential decisions in a stochastic\nenvironment were studied in Stochastic Programming (SP), Stochastic Optimal\nControl (SOC) and Markov Decision Processes (MDP). In this paper we mainly\nconcentrate on SP and SOC modelling approaches. In these frameworks there are\nnatural situations when the considered problems are convex. Classical approach\nto sequential optimization is based on dynamic programming. It has the problem\nof the so-called ``Curse of Dimensionality\", in that its computational\ncomplexity increases exponentially with increase of dimension of state\nvariables. Recent progress in solving convex multistage stochastic problems is\nbased on cutting planes approximations of the cost-to-go (value) functions of\ndynamic programming equations. Cutting planes type algorithms in dynamical\nsettings is one of the main topics of this paper. We also discuss Stochastic\nApproximation type methods applied to multistage stochastic optimization\nproblems. From the computational complexity point of view, these two types of\nmethods seem to be complimentary to each other. Cutting plane type methods can\nhandle multistage problems with a large number of stages, but a relatively\nsmaller number of state (decision) variables. On the other hand, stochastic\napproximation type methods can only deal with a small number of stages, but a\nlarge number of decision variables.", "published": "2023-03-28T01:30:40Z", "version": 1}, {"aid": "2303.15953", "authors": ["Matt Gorbett", "Darrell Whitley"], "title": "Randomly Initialized Subnetworks with Iterative Weight Recycling", "url": "http://arxiv.org/pdf/2303.15953v1", "summary": "The Multi-Prize Lottery Ticket Hypothesis posits that randomly initialized\nneural networks contain several subnetworks that achieve comparable accuracy to\nfully trained models of the same architecture. However, current methods require\nthat the network is sufficiently overparameterized. In this work, we propose a\nmodification to two state-of-the-art algorithms (Edge-Popup and Biprop) that\nfinds high-accuracy subnetworks with no additional storage cost or scaling. The\nalgorithm, Iterative Weight Recycling, identifies subsets of important weights\nwithin a randomly initialized network for intra-layer reuse. Empirically we\nshow improvements on smaller network architectures and higher prune rates,\nfinding that model sparsity can be increased through the \"recycling\" of\nexisting weights. In addition to Iterative Weight Recycling, we complement the\nMulti-Prize Lottery Ticket Hypothesis with a reciprocal finding: high-accuracy,\nrandomly initialized subnetwork's produce diverse masks, despite being\ngenerated with the same hyperparameter's and pruning strategy. We explore the\nlandscapes of these masks, which show high variability.", "published": "2023-03-28T13:12:00Z", "version": 1}, {"aid": "2303.16001", "authors": ["Tim Elsner", "Victor Czech", "Julia Berger", "Zain Selman", "Isaak Lim", "Leif Kobbelt"], "title": "Adaptive Voronoi NeRFs", "url": "http://arxiv.org/pdf/2303.16001v2", "summary": "Neural Radiance Fields (NeRFs) learn to represent a 3D scene from just a set\nof registered images. Increasing sizes of a scene demands more complex\nfunctions, typically represented by neural networks, to capture all details.\nTraining and inference then involves querying the neural network millions of\ntimes per image, which becomes impractically slow. Since such complex functions\ncan be replaced by multiple simpler functions to improve speed, we show that a\nhierarchy of Voronoi diagrams is a suitable choice to partition the scene. By\nequipping each Voronoi cell with its own NeRF, our approach is able to quickly\nlearn a scene representation. We propose an intuitive partitioning of the space\nthat increases quality gains during training by distributing information evenly\namong the networks and avoids artifacts through a top-down adaptive refinement.\nOur framework is agnostic to the underlying NeRF method and easy to implement,\nwhich allows it to be applied to various NeRF variants for improved learning\nand rendering speeds.", "published": "2023-03-28T14:16:08Z", "version": 2}, {"aid": "2303.16258", "authors": ["Konstantin Klemm", "Anita Mehta", "Peter F. Stadler"], "title": "Optimisation via encodings: a renormalisation group perspective", "url": "http://arxiv.org/pdf/2303.16258v2", "summary": "Difficult, in particular NP-complete, optimization problems are traditionally\nsolved approximately using search heuristics. These are usually slowed down by\nthe rugged landscapes encountered, because local minima arrest the search\nprocess. Cover-encoding maps were devised to circumvent this problem by\ntransforming the original landscape to one that is free of local minima and\nenriched in near-optimal solutions. By definition, these involve the mapping of\nthe original (larger) search space into smaller subspaces, by processes that\ntypically amount to a form of coarse-graining. In this paper, we explore the\ndetails of this coarse-graining using formal arguments, as well as concrete\nexamples of cover-encoding maps, that are investigated analytically as well as\ncomputationally. Our results strongly suggest that the coarse-graining involved\nin cover-encoding maps bears a strong resemblance to that encountered in\nrenormalisation group schemes. Given the apparently disparate nature of these\ntwo formalisms, these strong similarities are rather startling, and suggest\ndeep mathematical underpinnings that await further exploration.", "published": "2023-03-28T19:07:33Z", "version": 2}, {"aid": "2303.16280", "authors": ["Dmitrii Torbunov", "Yi Huang", "Huan-Hsin Tseng", "Haiwang Yu", "Jin Huang", "Shinjae Yoo", "Meifeng Lin", "Brett Viren", "Yihui Ren"], "title": "UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation", "url": "http://arxiv.org/pdf/2303.16280v3", "summary": "An unpaired image-to-image (I2I) translation technique seeks to find a\nmapping between two domains of data in a fully unsupervised manner. While\ninitial solutions to the I2I problem were provided by generative adversarial\nneural networks (GANs), diffusion models (DMs) currently hold the\nstate-of-the-art status on the I2I translation benchmarks in terms of Frechet\ninception distance (FID). Yet, DMs suffer from limitations, such as not using\ndata from the source domain during the training or maintaining consistency of\nthe source and translated images only via simple pixel-wise errors. This work\nimproves a recent UVCGAN model and equips it with modern advancements in model\narchitectures and training procedures. The resulting revised model\nsignificantly outperforms other advanced GAN- and DM-based competitors on a\nvariety of benchmarks. In the case of Male-to-Female translation of CelebA, the\nmodel achieves more than 40% improvement in FID score compared to the\nstate-of-the-art results. This work also demonstrates the ineffectiveness of\nthe pixel-wise I2I translation faithfulness metrics and suggests their\nrevision. The code and trained models are available at\nhttps://github.com/LS4GAN/uvcgan2", "published": "2023-03-28T19:46:34Z", "version": 3}, {"aid": "2303.16321", "authors": ["Aditya Dave", "Ioannis Faros", "Nishanth Venkatesh", "Andreas A. Malikopoulos"], "title": "Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon", "url": "http://arxiv.org/pdf/2303.16321v2", "summary": "Safety-critical cyber-physical systems require control strategies whose\nworst-case performance is robust against adversarial disturbances and modeling\nuncertainties. In this paper, we present a framework for approximate control\nand learning in partially observed systems to minimize the worst-case\ndiscounted cost over an infinite time horizon. We model disturbances to the\nsystem as finite-valued uncertain variables with unknown probability\ndistributions. For problems with known system dynamics, we construct a dynamic\nprogramming (DP) decomposition to compute the optimal control strategy. Our\nfirst contribution is to define information states that improve the\ncomputational tractability of this DP without loss of optimality. Then, we\ndescribe a simplification for a class of problems where the incurred cost is\nobservable at each time instance. Our second contribution is defining an\napproximate information state that can be constructed or learned directly from\nobserved data for problems with observable costs. We derive bounds on the\nperformance loss of the resulting approximate control strategy and illustrate\nthe effectiveness of our approach in partially observed decision-making\nproblems with a numerical example.", "published": "2023-03-28T21:40:06Z", "version": 2}, {"aid": "2303.16343", "authors": ["Michal Kosinski", "Poruz Khambatta", "Yilun Wang"], "title": "Facial recognition technology and human raters can predict political orientation from images of expressionless faces even when controlling for demographics and self-presentation", "url": "http://arxiv.org/pdf/2303.16343v4", "summary": "Carefully standardized facial images of 591 participants were taken in the\nlaboratory, while controlling for self-presentation, facial expression, head\norientation, and image properties. They were presented to human raters and a\nfacial recognition algorithm: both humans (r=.21) and the algorithm (r=.22)\ncould predict participants' scores on a political orientation scale (Cronbach's\nalpha=.94) decorrelated with age, gender, and ethnicity. These effects are on\npar with how well job interviews predict job success, or alcohol drives\naggressiveness. Algorithm's predictive accuracy was even higher (r=.31) when it\nleveraged information on participants' age, gender, and ethnicity. Moreover,\nthe associations between facial appearance and political orientation seem to\ngeneralize beyond our sample: The predictive model derived from standardized\nimages (while controlling for age, gender, and ethnicity) could predict\npolitical orientation (r=.13) from naturalistic images of 3,401 politicians\nfrom the U.S., UK, and Canada. The analysis of facial features associated with\npolitical orientation revealed that conservatives tended to have larger lower\nfaces. The predictability of political orientation from standardized images has\ncritical implications for privacy, the regulation of facial recognition\ntechnology, and understanding the origins and consequences of political\norientation.", "published": "2023-03-28T22:47:28Z", "version": 4}, {"aid": "2303.16411", "authors": ["Man Zhou", "Naishan Zheng", "Jie Huang", "Chunle Guo", "Chongyi Li"], "title": "Unlocking Masked Autoencoders as Loss Function for Image and Video Restoration", "url": "http://arxiv.org/pdf/2303.16411v1", "summary": "Image and video restoration has achieved a remarkable leap with the advent of\ndeep learning. The success of deep learning paradigm lies in three key\ncomponents: data, model, and loss. Currently, many efforts have been devoted to\nthe first two while seldom study focuses on loss function. With the question\n``are the de facto optimization functions e.g., $L_1$, $L_2$, and perceptual\nlosses optimal?'', we explore the potential of loss and raise our belief\n``learned loss function empowers the learning capability of neural networks for\nimage and video restoration''.\n  Concretely, we stand on the shoulders of the masked Autoencoders (MAE) and\nformulate it as a `learned loss function', owing to the fact the pre-trained\nMAE innately inherits the prior of image reasoning. We investigate the efficacy\nof our belief from three perspectives: 1) from task-customized MAE to native\nMAE, 2) from image task to video task, and 3) from transformer structure to\nconvolution neural network structure. Extensive experiments across multiple\nimage and video tasks, including image denoising, image super-resolution, image\nenhancement, guided image super-resolution, video denoising, and video\nenhancement, demonstrate the consistent performance improvements introduced by\nthe learned loss function. Besides, the learned loss function is preferable as\nit can be directly plugged into existing networks during training without\ninvolving computations in the inference stage. Code will be publicly available.", "published": "2023-03-29T02:41:08Z", "version": 1}, {"aid": "2303.16459", "authors": ["Stefan Abi-Karam", "Cong Hao"], "title": "GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization", "url": "http://arxiv.org/pdf/2303.16459v2", "summary": "There are plenty of graph neural network (GNN) accelerators being proposed.\nHowever, they highly rely on users' hardware expertise and are usually\noptimized for one specific GNN model, making them challenging for practical\nuse. Therefore, in this work, we propose GNNBuilder, the first automated,\ngeneric, end-to-end GNN accelerator generation framework. It features four\nadvantages: (1) GNNBuilder can automatically generate GNN accelerators for a\nwide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes\nstandard PyTorch programming interface, introducing zero overhead for algorithm\ndevelopers; (3) GNNBuilder supports end-to-end code generation, simulation,\naccelerator optimization, and hardware deployment, realizing a push-button\nfashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate\nperformance models of its generated accelerator, enabling fast and flexible\ndesign space exploration (DSE). In the experiments, first, we show that our\naccelerator performance model has errors within $36\\%$ for latency prediction\nand $18\\%$ for BRAM count prediction. Second, we show that our generated\naccelerators can outperform CPU by $6.33\\times$ and GPU by $6.87\\times$. This\nframework is open-source, and the code is available at\nhttps://github.com/sharc-lab/gnn-builder.", "published": "2023-03-29T05:08:21Z", "version": 2}, {"aid": "2303.16491", "authors": ["Sicheng Gao", "Xuhui Liu", "Bohan Zeng", "Sheng Xu", "Yanjing Li", "Xiaoyan Luo", "Jianzhuang Liu", "Xiantong Zhen", "Baochang Zhang"], "title": "Implicit Diffusion Models for Continuous Super-Resolution", "url": "http://arxiv.org/pdf/2303.16491v2", "summary": "Image super-resolution (SR) has attracted increasing attention due to its\nwide applications. However, current SR methods generally suffer from\nover-smoothing and artifacts, and most work only with fixed magnifications.\nThis paper introduces an Implicit Diffusion Model (IDM) for high-fidelity\ncontinuous image super-resolution. IDM integrates an implicit neural\nrepresentation and a denoising diffusion model in a unified end-to-end\nframework, where the implicit neural representation is adopted in the decoding\nprocess to learn continuous-resolution representation. Furthermore, we design a\nscale-controllable conditioning mechanism that consists of a low-resolution\n(LR) conditioning network and a scaling factor. The scaling factor regulates\nthe resolution and accordingly modulates the proportion of the LR information\nand generated features in the final output, which enables the model to\naccommodate the continuous-resolution requirement. Extensive experiments\nvalidate the effectiveness of our IDM and demonstrate its superior performance\nover prior arts.", "published": "2023-03-29T07:02:20Z", "version": 2}, {"aid": "2303.16513", "authors": ["Hao-Wei Chen", "Yu-Syuan Xu", "Min-Fong Hong", "Yi-Min Tsai", "Hsien-Kai Kuo", "Chun-Yi Lee"], "title": "Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution", "url": "http://arxiv.org/pdf/2303.16513v1", "summary": "Implicit neural representation has recently shown a promising ability in\nrepresenting images with arbitrary resolutions. In this paper, we present a\nLocal Implicit Transformer (LIT), which integrates the attention mechanism and\nfrequency encoding technique into a local implicit image function. We design a\ncross-scale local attention block to effectively aggregate local features. To\nfurther improve representative power, we propose a Cascaded LIT (CLIT) that\nexploits multi-scale features, along with a cumulative training strategy that\ngradually increases the upsampling scales during training. We have conducted\nextensive experiments to validate the effectiveness of these components and\nanalyze various training strategies. The qualitative and quantitative results\ndemonstrate that LIT and CLIT achieve favorable results and outperform the\nprior works in arbitrary super-resolution tasks.", "published": "2023-03-29T07:41:56Z", "version": 1}, {"aid": "2303.16666", "authors": ["Pan Xiao", "Peijie Qiu", "Sungmin Ha", "Abdalla Bani", "Shuang Zhou", "Aristeidis Sotiras"], "title": "SC-VAE: Sparse Coding-based Variational Autoencoder with Learned ISTA", "url": "http://arxiv.org/pdf/2303.16666v2", "summary": "Learning rich data representations from unlabeled data is a key challenge\ntowards applying deep learning algorithms in downstream tasks. Several variants\nof variational autoencoders (VAEs) have been proposed to learn compact data\nrepresentations by encoding high-dimensional data in a lower dimensional space.\nTwo main classes of VAEs methods may be distinguished depending on the\ncharacteristics of the meta-priors that are enforced in the representation\nlearning step. The first class of methods derives a continuous encoding by\nassuming a static prior distribution in the latent space. The second class of\nmethods learns instead a discrete latent representation using vector\nquantization (VQ) along with a codebook. However, both classes of methods\nsuffer from certain challenges, which may lead to suboptimal image\nreconstruction results. The first class suffers from posterior collapse,\nwhereas the second class suffers from codebook collapse. To address these\nchallenges, we introduce a new VAE variant, termed sparse coding-based VAE with\nlearned ISTA (SC-VAE), which integrates sparse coding within variational\nautoencoder framework. The proposed method learns sparse data representations\nthat consist of a linear combination of a small number of predetermined\northogonal atoms. The sparse coding problem is solved using a learnable version\nof the iterative shrinkage thresholding algorithm (ISTA). Experiments on two\nimage datasets demonstrate that our model achieves improved image\nreconstruction results compared to state-of-the-art methods. Moreover, we\ndemonstrate that the use of learned sparse code vectors allows us to perform\ndownstream tasks like image generation and unsupervised image segmentation\nthrough clustering image patches.", "published": "2023-03-29T13:18:33Z", "version": 2}, {"aid": "2303.17589", "authors": ["Qingyang Wang", "Michael A. Powell", "Ali Geisa", "Eric W. Bridgeford", "Joshua T. Vogelstein"], "title": "Polarity is all you need to learn and transfer faster", "url": "http://arxiv.org/pdf/2303.17589v2", "summary": "Natural intelligences (NIs) thrive in a dynamic world - they learn quickly,\nsometimes with only a few samples. In contrast, artificial intelligences (AIs)\ntypically learn with a prohibitive number of training samples and computational\npower. What design principle difference between NI and AI could contribute to\nsuch a discrepancy? Here, we investigate the role of weight polarity:\ndevelopment processes initialize NIs with advantageous polarity configurations;\nas NIs grow and learn, synapse magnitudes update, yet polarities are largely\nkept unchanged. We demonstrate with simulation and image classification tasks\nthat if weight polarities are adequately set a priori, then networks learn with\nless time and data. We also explicitly illustrate situations in which a priori\nsetting the weight polarities is disadvantageous for networks. Our work\nillustrates the value of weight polarities from the perspective of statistical\nand computational efficiency during learning.", "published": "2023-03-29T14:43:04Z", "version": 2}, {"aid": "2303.16947", "authors": ["Congpei Qiu", "Tong Zhang", "Wei Ke", "Mathieu Salzmann", "Sabine S\u00fcsstrunk"], "title": "De-coupling and De-positioning Dense Self-supervised Learning", "url": "http://arxiv.org/pdf/2303.16947v1", "summary": "Dense Self-Supervised Learning (SSL) methods address the limitations of using\nimage-level feature representations when handling images with multiple objects.\nAlthough the dense features extracted by employing segmentation maps and\nbounding boxes allow networks to perform SSL for each object, we show that they\nsuffer from coupling and positional bias, which arise from the receptive field\nincreasing with layer depth and zero-padding. We address this by introducing\nthree data augmentation strategies, and leveraging them in (i) a decoupling\nmodule that aims to robustify the network to variations in the object's\nsurroundings, and (ii) a de-positioning module that encourages the network to\ndiscard positional object information. We demonstrate the benefits of our\nmethod on COCO and on a new challenging benchmark, OpenImage-MINI, for object\nclassification, semantic segmentation, and object detection. Our extensive\nexperiments evidence the better generalization of our method compared to the\nSOTA dense SSL methods", "published": "2023-03-29T18:07:25Z", "version": 1}, {"aid": "2303.17015", "authors": ["Ziya Erko\u00e7", "Fangchang Ma", "Qi Shan", "Matthias Nie\u00dfner", "Angela Dai"], "title": "HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion", "url": "http://arxiv.org/pdf/2303.17015v1", "summary": "Implicit neural fields, typically encoded by a multilayer perceptron (MLP)\nthat maps from coordinates (e.g., xyz) to signals (e.g., signed distances),\nhave shown remarkable promise as a high-fidelity and compact representation.\nHowever, the lack of a regular and explicit grid structure also makes it\nchallenging to apply generative modeling directly on implicit neural fields in\norder to synthesize new data. To this end, we propose HyperDiffusion, a novel\napproach for unconditional generative modeling of implicit neural fields.\nHyperDiffusion operates directly on MLP weights and generates new neural\nimplicit fields encoded by synthesized MLP parameters. Specifically, a\ncollection of MLPs is first optimized to faithfully represent individual data\nsamples. Subsequently, a diffusion process is trained in this MLP weight space\nto model the underlying distribution of neural implicit fields. HyperDiffusion\nenables diffusion modeling over a implicit, compact, and yet high-fidelity\nrepresentation of complex signals across 3D shapes and 4D mesh animations\nwithin one single unified framework.", "published": "2023-03-29T20:44:42Z", "version": 1}, {"aid": "2303.17056", "authors": ["Shentong Mo", "Yapeng Tian"], "title": "Audio-Visual Grouping Network for Sound Localization from Mixtures", "url": "http://arxiv.org/pdf/2303.17056v1", "summary": "Sound source localization is a typical and challenging task that predicts the\nlocation of sound sources in a video. Previous single-source methods mainly\nused the audio-visual association as clues to localize sounding objects in each\nimage. Due to the mixed property of multiple sound sources in the original\nspace, there exist rare multi-source approaches to localizing multiple sources\nsimultaneously, except for one recent work using a contrastive random walk in\nthe graph with images and separated sound as nodes. Despite their promising\nperformance, they can only handle a fixed number of sources, and they cannot\nlearn compact class-aware representations for individual sources. To alleviate\nthis shortcoming, in this paper, we propose a novel audio-visual grouping\nnetwork, namely AVGN, that can directly learn category-wise semantic features\nfor each source from the input audio mixture and image to localize multiple\nsources simultaneously. Specifically, our AVGN leverages learnable audio-visual\nclass tokens to aggregate class-aware source features. Then, the aggregated\nsemantic features for each source can be used as guidance to localize the\ncorresponding visual regions. Compared to existing multi-source methods, our\nnew framework can localize a flexible number of sources and disentangle\ncategory-aware audio-visual representations for individual sound sources. We\nconduct extensive experiments on MUSIC, VGGSound-Instruments, and VGG-Sound\nSources benchmarks. The results demonstrate that the proposed AVGN can achieve\nstate-of-the-art sounding object localization performance on both single-source\nand multi-source scenarios. Code is available at\n\\url{https://github.com/stoneMo/AVGN}.", "published": "2023-03-29T22:58:55Z", "version": 1}, {"aid": "2303.17075", "authors": ["Lenore Blum", "Manuel Blum"], "title": "Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence", "url": "http://arxiv.org/pdf/2303.17075v1", "summary": "We have defined the Conscious Turing Machine (CTM) for the purpose of\ninvestigating a Theoretical Computer Science (TCS) approach to consciousness.\nFor this, we have hewn to the TCS demand for simplicity and understandability.\nThe CTM is consequently and intentionally a simple machine. It is not a model\nof the brain, though its design has greatly benefited - and continues to\nbenefit - from neuroscience and psychology. The CTM is a model of and for\nconsciousness.\n  Although it is developed to understand consciousness, the CTM offers a\nthoughtful and novel guide to the creation of an Artificial General\nIntelligence (AGI). For example, the CTM has an enormous number of powerful\nprocessors, some with specialized expertise, others unspecialized but poised to\ndevelop an expertise. For whatever problem must be dealt with, the CTM has an\nexcellent way to utilize those processors that have the required knowledge,\nability, and time to work on the problem, even if it is not aware of which ones\nthese may be.", "published": "2023-03-30T00:39:10Z", "version": 1}, {"aid": "2303.17076", "authors": ["Qinsheng Zhang", "Jiaming Song", "Xun Huang", "Yongxin Chen", "Ming-Yu Liu"], "title": "DiffCollage: Parallel Generation of Large Content with Diffusion Models", "url": "http://arxiv.org/pdf/2303.17076v1", "summary": "We present DiffCollage, a compositional diffusion model that can generate\nlarge content by leveraging diffusion models trained on generating pieces of\nthe large content. Our approach is based on a factor graph representation where\neach factor node represents a portion of the content and a variable node\nrepresents their overlap. This representation allows us to aggregate\nintermediate outputs from diffusion models defined on individual nodes to\ngenerate content of arbitrary size and shape in parallel without resorting to\nan autoregressive generation procedure. We apply DiffCollage to various tasks,\nincluding infinite image generation, panorama image generation, and\nlong-duration text-guided motion generation. Extensive experimental results\nwith a comparison to strong autoregressive baselines verify the effectiveness\nof our approach.", "published": "2023-03-30T00:51:12Z", "version": 1}, {"aid": "2303.17127", "authors": ["Thalaiyasingam Ajanthan", "Matt Ma", "Anton van den Hengel", "Stephen Gould"], "title": "Adaptive Cross Batch Normalization for Metric Learning", "url": "http://arxiv.org/pdf/2303.17127v1", "summary": "Metric learning is a fundamental problem in computer vision whereby a model\nis trained to learn a semantically useful embedding space via ranking losses.\nTraditionally, the effectiveness of a ranking loss depends on the minibatch\nsize, and is, therefore, inherently limited by the memory constraints of the\nunderlying hardware. While simply accumulating the embeddings across\nminibatches has proved useful (Wang et al. [2020]), we show that it is equally\nimportant to ensure that the accumulated embeddings are up to date. In\nparticular, it is necessary to circumvent the representational drift between\nthe accumulated embeddings and the feature embeddings at the current training\niteration as the learnable parameters are being updated. In this paper, we\nmodel representational drift as distribution misalignment and tackle it using\nmoment matching. The result is a simple method for updating the stored\nembeddings to match the first and second moments of the current embeddings at\neach training iteration. Experiments on three popular image retrieval datasets,\nnamely, SOP, In-Shop, and DeepFashion2, demonstrate that our approach\nsignificantly improves the performance in all scenarios.", "published": "2023-03-30T03:22:52Z", "version": 1}, {"aid": "2303.17583", "authors": ["Sachin Shah", "Sakshum Kulshrestha", "Christopher A. Metzler"], "title": "TiDy-PSFs: Computational Imaging with Time-Averaged Dynamic Point-Spread-Functions", "url": "http://arxiv.org/pdf/2303.17583v1", "summary": "Point-spread-function (PSF) engineering is a powerful computational imaging\ntechniques wherein a custom phase mask is integrated into an optical system to\nencode additional information into captured images. Used in combination with\ndeep learning, such systems now offer state-of-the-art performance at monocular\ndepth estimation, extended depth-of-field imaging, lensless imaging, and other\ntasks. Inspired by recent advances in spatial light modulator (SLM) technology,\nthis paper answers a natural question: Can one encode additional information\nand achieve superior performance by changing a phase mask dynamically over\ntime? We first prove that the set of PSFs described by static phase masks is\nnon-convex and that, as a result, time-averaged PSFs generated by dynamic phase\nmasks are fundamentally more expressive. We then demonstrate, in simulation,\nthat time-averaged dynamic (TiDy) phase masks can offer substantially improved\nmonocular depth estimation and extended depth-of-field imaging performance.", "published": "2023-03-30T17:51:07Z", "version": 1}, {"aid": "2303.18242", "authors": ["Sam Bond-Taylor", "Chris G. Willcocks"], "title": "$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States", "url": "http://arxiv.org/pdf/2303.18242v2", "summary": "This paper introduces $\\infty$-Diff, a generative diffusion model defined in\nan infinite-dimensional Hilbert space, which can model infinite resolution\ndata. By training on randomly sampled subsets of coordinates and denoising\ncontent only at those locations, we learn a continuous function for arbitrary\nresolution sampling. Unlike prior neural field-based infinite-dimensional\nmodels, which use point-wise functions requiring latent compression, our method\nemploys non-local integral operators to map between Hilbert spaces, allowing\nspatial context aggregation. This is achieved with an efficient multi-scale\nfunction-space architecture that operates directly on raw sparse coordinates,\ncoupled with a mollified diffusion process that smooths out irregularities.\nThrough experiments on high-resolution datasets, we found that even at an\n$8\\times$ subsampling rate, our model retains high-quality diffusion. This\nleads to significant run-time and memory savings, delivers samples with lower\nFID scores, and scales beyond the training resolution while retaining detail.", "published": "2023-03-31T17:58:08Z", "version": 2}, {"aid": "2304.00306", "authors": ["Rahul Chand", "Rajat Arora", "K Ram Prabhakar", "R Venkatesh Babu"], "title": "CapsFlow: Optical Flow Estimation with Capsule Networks", "url": "http://arxiv.org/pdf/2304.00306v2", "summary": "We present a framework to use recently introduced Capsule Networks for\nsolving the problem of Optical Flow, one of the fundamental computer vision\ntasks. Most of the existing state of the art deep architectures either uses a\ncorrelation oepration to match features from them. While correlation layer is\nsensitive to the choice of hyperparameters and does not put a prior on the\nunderlying structure of the object, spatio temporal features will be limited by\nthe network's receptive field. Also, we as humans look at moving objects as\nwhole, something which cannot be encoded by correlation or spatio temporal\nfeatures. Capsules, on the other hand, are specialized to model seperate\nentities and their pose as a continuous matrix. Thus, we show that a simpler\nlinear operation over poses of the objects detected by the capsules in enough\nto model flow. We show reslts on a small toy dataset where we outperform\nFlowNetC and PWC-Net models.", "published": "2023-04-01T12:35:41Z", "version": 2}, {"aid": "2304.00424", "authors": ["Seokeon Choi", "Debasmit Das", "Sungha Choi", "Seunghan Yang", "Hyunsin Park", "Sungrack Yun"], "title": "Progressive Random Convolutions for Single Domain Generalization", "url": "http://arxiv.org/pdf/2304.00424v1", "summary": "Single domain generalization aims to train a generalizable model with only\none source domain to perform well on arbitrary unseen target domains. Image\naugmentation based on Random Convolutions (RandConv), consisting of one\nconvolution layer randomly initialized for each mini-batch, enables the model\nto learn generalizable visual representations by distorting local textures\ndespite its simple and lightweight structure. However, RandConv has structural\nlimitations in that the generated image easily loses semantics as the kernel\nsize increases, and lacks the inherent diversity of a single convolution\noperation. To solve the problem, we propose a Progressive Random Convolution\n(Pro-RandConv) method that recursively stacks random convolution layers with a\nsmall kernel size instead of increasing the kernel size. This progressive\napproach can not only mitigate semantic distortions by reducing the influence\nof pixels away from the center in the theoretical receptive field, but also\ncreate more effective virtual domains by gradually increasing the style\ndiversity. In addition, we develop a basic random convolution layer into a\nrandom convolution block including deformable offsets and affine transformation\nto support texture and contrast diversification, both of which are also\nrandomly initialized. Without complex generators or adversarial learning, we\ndemonstrate that our simple yet effective augmentation strategy outperforms\nstate-of-the-art methods on single domain generalization benchmarks.", "published": "2023-04-02T01:42:51Z", "version": 1}, {"aid": "2304.01227", "authors": ["Samira Kabri", "Tim Roith", "Daniel Tenbrinck", "Martin Burger"], "title": "Resolution-Invariant Image Classification based on Fourier Neural Operators", "url": "http://arxiv.org/pdf/2304.01227v1", "summary": "In this paper we investigate the use of Fourier Neural Operators (FNOs) for\nimage classification in comparison to standard Convolutional Neural Networks\n(CNNs). Neural operators are a discretization-invariant generalization of\nneural networks to approximate operators between infinite dimensional function\nspaces. FNOs - which are neural operators with a specific parametrization -\nhave been applied successfully in the context of parametric PDEs. We derive the\nFNO architecture as an example for continuous and Fr\\'echet-differentiable\nneural operators on Lebesgue spaces. We further show how CNNs can be converted\ninto FNOs and vice versa and propose an interpolation-equivariant adaptation of\nthe architecture.", "published": "2023-04-02T10:23:36Z", "version": 1}, {"aid": "2304.01283", "authors": ["Steffen Lewitzka", "Vin\u00edcius Pinto"], "title": "Belief, knowledge and evidence", "url": "http://arxiv.org/pdf/2304.01283v1", "summary": "We present a logical system that combines the well-known classical epistemic\nconcepts of belief and knowledge with a concept of evidence such that the\nintuitive principle \\textit{`evidence yields belief and knowledge'} is\nsatisfied. Our approach relies on previous works of the first author\n\\cite{lewjlc2, lewigpl, lewapal} who introduced a modal system containing\n$S5$-style principles for the reasoning about intutionistic truth (i.e.\n\\textit{proof}) and, inspired by \\cite{artpro}, combined that system with\nconcepts of \\textit{intuitionistic} belief and knowledge. We consider that\ncombined system and replace the constructive concept of \\textit{proof} with a\nclassical notion of \\textit{evidence}. This results in a logic that combines\nmodal system $S5$ with classical epistemic principles where $\\square\\varphi$\nreads as `$\\varphi$ is evident' in an epistemic sense. Inspired by\n\\cite{lewapal}, and in contrast to the usual possible worlds semantics found in\nthe literature, we propose here a relational, frame-based semantics where\nbelief and knowledge are not modeled via accessibility relations but directly\nas sets of propositions (sets of sets of worlds).", "published": "2023-04-03T18:20:02Z", "version": 1}, {"aid": "2304.01297", "authors": ["Jacob Piland", "Christopher Sweet", "Priscila Saboia", "Charles Vardeman II", "Adam Czajka"], "title": "Non-Generative Energy Based Models", "url": "http://arxiv.org/pdf/2304.01297v1", "summary": "Energy-based models (EBM) have become increasingly popular within computer\nvision. EBMs bring a probabilistic approach to training deep neural networks\n(DNN) and have been shown to enhance performance in areas such as calibration,\nout-of-distribution detection, and adversarial resistance. However, these\nadvantages come at the cost of estimating input data probabilities, usually\nusing a Langevin based method such as Stochastic Gradient Langevin Dynamics\n(SGLD), which bring additional computational costs, require parameterization,\ncaching methods for efficiency, and can run into stability and scaling issues.\nEBMs use dynamical methods to draw samples from the probability density\nfunction (PDF) defined by the current state of the network and compare them to\nthe training data using a maximum log likelihood approach to learn the correct\nPDF.\n  We propose a non-generative training approach, Non-Generative EBM (NG-EBM),\nthat utilizes the {\\it{Approximate Mass}}, identified by Grathwohl et al., as a\nloss term to direct the training. We show that our NG-EBM training strategy\nretains many of the benefits of EBM in calibration, out-of-distribution\ndetection, and adversarial resistance, but without the computational complexity\nand overhead of the traditional approaches. In particular, the NG-EBM approach\nimproves the Expected Calibration Error by a factor of 2.5 for CIFAR10 and 7.5\ntimes for CIFAR100, when compared to traditionally trained models.", "published": "2023-04-03T18:47:37Z", "version": 1}, {"aid": "2304.01406", "authors": ["Huzi Cheng", "Joshua W. Brown"], "title": "Learning with augmented target information: An alternative theory of Feedback Alignment", "url": "http://arxiv.org/pdf/2304.01406v1", "summary": "While error backpropagation (BP) has dominated the training of nearly all\nmodern neural networks for a long time, it suffers from several biological\nplausibility issues such as the symmetric weight requirement and synchronous\nupdates. Feedback Alignment (FA) was proposed as an alternative to BP to\naddress those dilemmas and has been demonstrated to be effective on various\ntasks and network architectures. Despite its simplicity and effectiveness, a\nsatisfying explanation of how FA works across different architectures is still\nlacking. Here we propose a novel, architecture-agnostic theory of how FA works\nthrough the lens of information theory: Instead of approximating gradients\ncalculated by BP with the same parameter, FA learns effective representations\nby embedding target information into neural networks to be trained. We show\nthis through the analysis of FA dynamics in idealized settings and then via a\nseries of experiments. Based on the implications of this theory, we designed\nthree variants of FA and show their comparable performance on several tasks.\nThese variants also account for some phenomena and theories in neuroscience\nsuch as predictive coding and representational drift.", "published": "2023-04-03T22:44:03Z", "version": 1}, {"aid": "2304.01432", "authors": ["Zhaoyue Chen", "Yifan Sun"], "title": "Reducing Discretization Error in the Frank-Wolfe Method", "url": "http://arxiv.org/pdf/2304.01432v2", "summary": "The Frank-Wolfe algorithm is a popular method in structurally constrained\nmachine learning applications, due to its fast per-iteration complexity.\nHowever, one major limitation of the method is a slow rate of convergence that\nis difficult to accelerate due to erratic, zig-zagging step directions, even\nasymptotically close to the solution. We view this as an artifact of\ndiscretization; that is to say, the Frank-Wolfe \\emph{flow}, which is its\ntrajectory at asymptotically small step sizes, does not zig-zag, and reducing\ndiscretization error will go hand-in-hand in producing a more stabilized\nmethod, with better convergence properties. We propose two improvements: a\nmultistep Frank-Wolfe method that directly applies optimized higher-order\ndiscretization schemes; and an LMO-averaging scheme with reduced discretization\nerror, and whose local convergence rate over general convex sets accelerates\nfrom a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.", "published": "2023-04-04T00:43:05Z", "version": 2}, {"aid": "2304.01434", "authors": ["Jaeill Kim", "Suhyun Kang", "Duhun Hwang", "Jungwook Shin", "Wonjong Rhee"], "title": "VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution", "url": "http://arxiv.org/pdf/2304.01434v1", "summary": "Since the introduction of deep learning, a wide scope of representation\nproperties, such as decorrelation, whitening, disentanglement, rank, isotropy,\nand mutual information, have been studied to improve the quality of\nrepresentation. However, manipulating such properties can be challenging in\nterms of implementational effectiveness and general applicability. To address\nthese limitations, we propose to regularize von Neumann entropy~(VNE) of\nrepresentation. First, we demonstrate that the mathematical formulation of VNE\nis superior in effectively manipulating the eigenvalues of the representation\nautocorrelation matrix. Then, we demonstrate that it is widely applicable in\nimproving state-of-the-art algorithms or popular benchmark algorithms by\ninvestigating domain-generalization, meta-learning, self-supervised learning,\nand generative models. In addition, we formally establish theoretical\nconnections with rank, disentanglement, and isotropy of representation.\nFinally, we provide discussions on the dimension control of VNE and the\nrelationship with Shannon entropy. Code is available at:\nhttps://github.com/jaeill/CVPR23-VNE.", "published": "2023-04-04T01:03:32Z", "version": 1}, {"aid": "2304.01585", "authors": ["Nilah Ravi Nair", "Fernando Moya Rueda", "Christopher Reining", "Gernot A. Fink"], "title": "Multi-Channel Time-Series Person and Soft-Biometric Identification", "url": "http://arxiv.org/pdf/2304.01585v1", "summary": "Multi-channel time-series datasets are popular in the context of human\nactivity recognition (HAR). On-body device (OBD) recordings of human movements\nare often preferred for HAR applications not only for their reliability but as\nan approach for identity protection, e.g., in industrial settings.\nContradictory, the gait activity is a biometric, as the cyclic movement is\ndistinctive and collectable. In addition, the gait cycle has proven to contain\nsoft-biometric information of human groups, such as age and height. Though\ngeneral human movements have not been considered a biometric, they might\ncontain identity information. This work investigates person and soft-biometrics\nidentification from OBD recordings of humans performing different activities\nusing deep architectures. Furthermore, we propose the use of attribute\nrepresentation for soft-biometric identification. We evaluate the method on\nfour datasets of multi-channel time-series HAR, measuring the performance of a\nperson and soft-biometrics identification and its relation concerning performed\nactivities. We find that person identification is not limited to gait activity.\nThe impact of activities on the identification performance was found to be\ntraining and dataset specific. Soft-biometric based attribute representation\nshows promising results and emphasis the necessity of larger datasets.", "published": "2023-04-04T07:24:51Z", "version": 1}, {"aid": "2304.02473", "authors": ["Christopher Zach"], "title": "Fully Variational Noise-Contrastive Estimation", "url": "http://arxiv.org/pdf/2304.02473v1", "summary": "By using the underlying theory of proper scoring rules, we design a family of\nnoise-contrastive estimation (NCE) methods that are tractable for latent\nvariable models. Both terms in the underlying NCE loss, the one using data\nsamples and the one using noise samples, can be lower-bounded as in variational\nBayes, therefore we call this family of losses fully variational\nnoise-contrastive estimation. Variational autoencoders are a particular example\nin this family and therefore can be also understood as separating real data\nfrom synthetic samples using an appropriate classification loss. We further\ndiscuss other instances in this family of fully variational NCE objectives and\nindicate differences in their empirical behavior.", "published": "2023-04-04T09:42:20Z", "version": 1}, {"aid": "2304.01834", "authors": ["Ntumba Elie Nsampi", "Adarsh Djeacoumar", "Hans-Peter Seidel", "Tobias Ritschel", "Thomas Leimk\u00fchler"], "title": "Neural Field Convolutions by Repeated Differentiation", "url": "http://arxiv.org/pdf/2304.01834v4", "summary": "Neural fields are evolving towards a general-purpose continuous\nrepresentation for visual computing. Yet, despite their numerous appealing\nproperties, they are hardly amenable to signal processing. As a remedy, we\npresent a method to perform general continuous convolutions with general\ncontinuous signals such as neural fields. Observing that piecewise polynomial\nkernels reduce to a sparse set of Dirac deltas after repeated differentiation,\nwe leverage convolution identities and train a repeated integral field to\nefficiently execute large-scale convolutions. We demonstrate our approach on a\nvariety of data modalities and spatially-varying kernels.", "published": "2023-04-04T14:39:44Z", "version": 4}, {"aid": "2304.02008", "authors": ["R\u00e9mi Pautrat", "Iago Su\u00e1rez", "Yifan Yu", "Marc Pollefeys", "Viktor Larsson"], "title": "GlueStick: Robust Image Matching by Sticking Points and Lines Together", "url": "http://arxiv.org/pdf/2304.02008v3", "summary": "Line segments are powerful features complementary to points. They offer\nstructural cues, robust to drastic viewpoint and illumination changes, and can\nbe present even in texture-less areas. However, describing and matching them is\nmore challenging compared to points due to partial occlusions, lack of texture,\nor repetitiveness. This paper introduces a new matching paradigm, where points,\nlines, and their descriptors are unified into a single wireframe structure. We\npropose GlueStick, a deep matching Graph Neural Network (GNN) that takes two\nwireframes from different images and leverages the connectivity information\nbetween nodes to better glue them together. In addition to the increased\nefficiency brought by the joint matching, we also demonstrate a large boost of\nperformance when leveraging the complementary nature of these two features in a\nsingle architecture. We show that our matching strategy outperforms the\nstate-of-the-art approaches independently matching line segments and points for\na wide variety of datasets and tasks. The code is available at\nhttps://github.com/cvg/GlueStick.", "published": "2023-04-04T17:58:14Z", "version": 3}, {"aid": "2304.02049", "authors": ["Samuele Poppi", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "title": "Multi-Class Unlearning for Image Classification via Weight Filtering", "url": "http://arxiv.org/pdf/2304.02049v2", "summary": "Machine Unlearning is an emerging paradigm for selectively removing the\nimpact of training datapoints from a network. Unlike existing methods that\ntarget a limited subset or a single class, our framework unlearns all classes\nin a single round. We achieve this by modulating the network's components using\nmemory matrices, enabling the network to demonstrate selective unlearning\nbehavior for any class after training. By discovering weights that are specific\nto each class, our approach also recovers a representation of the classes which\nis explainable by design. We test the proposed framework on small- and\nmedium-scale image classification datasets, with both convolution- and\nTransformer-based backbones, showcasing the potential for explainable solutions\nthrough unlearning.", "published": "2023-04-04T18:01:59Z", "version": 2}, {"aid": "2304.02285", "authors": ["Xiaomeng Wu", "Yongqing Sun", "Akisato Kimura"], "title": "Deep Quantigraphic Image Enhancement via Comparametric Equations", "url": "http://arxiv.org/pdf/2304.02285v1", "summary": "Most recent methods of deep image enhancement can be generally classified\ninto two types: decompose-and-enhance and illumination estimation-centric. The\nformer is usually less efficient, and the latter is constrained by a strong\nassumption regarding image reflectance as the desired enhancement result. To\nalleviate this constraint while retaining high efficiency, we propose a novel\ntrainable module that diversifies the conversion from the low-light image and\nillumination map to the enhanced image. It formulates image enhancement as a\ncomparametric equation parameterized by a camera response function and an\nexposure compensation ratio. By incorporating this module in an illumination\nestimation-centric DNN, our method improves the flexibility of deep image\nenhancement, limits the computational burden to illumination estimation, and\nallows for fully unsupervised learning adaptable to the diverse demands of\ndifferent tasks.", "published": "2023-04-05T08:14:41Z", "version": 1}, {"aid": "2304.02330", "authors": ["Sanghyeon Kim", "Eunbyung Park"], "title": "SMPConv: Self-moving Point Representations for Continuous Convolution", "url": "http://arxiv.org/pdf/2304.02330v1", "summary": "Continuous convolution has recently gained prominence due to its ability to\nhandle irregularly sampled data and model long-term dependency. Also, the\npromising experimental results of using large convolutional kernels have\ncatalyzed the development of continuous convolution since they can construct\nlarge kernels very efficiently. Leveraging neural networks, more specifically\nmultilayer perceptrons (MLPs), is by far the most prevalent approach to\nimplementing continuous convolution. However, there are a few drawbacks, such\nas high computational costs, complex hyperparameter tuning, and limited\ndescriptive power of filters. This paper suggests an alternative approach to\nbuilding a continuous convolution without neural networks, resulting in more\ncomputationally efficient and improved performance. We present self-moving\npoint representations where weight parameters freely move, and interpolation\nschemes are used to implement continuous functions. When applied to construct\nconvolutional kernels, the experimental results have shown improved performance\nwith drop-in replacement in the existing frameworks. Due to its lightweight\nstructure, we are first to demonstrate the effectiveness of continuous\nconvolution in a large-scale setting, e.g., ImageNet, presenting the\nimprovements over the prior arts. Our code is available on\nhttps://github.com/sangnekim/SMPConv", "published": "2023-04-05T09:36:30Z", "version": 1}, {"aid": "2304.02658", "authors": ["Umais Zahid", "Qinghai Guo", "Zafeirios Fountas"], "title": "Predictive Coding as a Neuromorphic Alternative to Backpropagation: A Critical Evaluation", "url": "http://arxiv.org/pdf/2304.02658v1", "summary": "Backpropagation has rapidly become the workhorse credit assignment algorithm\nfor modern deep learning methods. Recently, modified forms of predictive coding\n(PC), an algorithm with origins in computational neuroscience, have been shown\nto result in approximately or exactly equal parameter updates to those under\nbackpropagation. Due to this connection, it has been suggested that PC can act\nas an alternative to backpropagation with desirable properties that may\nfacilitate implementation in neuromorphic systems. Here, we explore these\nclaims using the different contemporary PC variants proposed in the literature.\nWe obtain time complexity bounds for these PC variants which we show are\nlower-bounded by backpropagation. We also present key properties of these\nvariants that have implications for neurobiological plausibility and their\ninterpretations, particularly from the perspective of standard PC as a\nvariational Bayes algorithm for latent probabilistic models. Our findings shed\nnew light on the connection between the two learning frameworks and suggest\nthat, in its current forms, PC may have more limited potential as a direct\nreplacement of backpropagation than previously envisioned.", "published": "2023-04-05T11:48:47Z", "version": 1}, {"aid": "2304.02626", "authors": ["Sergey Prokudin", "Qianli Ma", "Maxime Raafat", "Julien Valentin", "Siyu Tang"], "title": "Dynamic Point Fields", "url": "http://arxiv.org/pdf/2304.02626v2", "summary": "Recent years have witnessed significant progress in the field of neural\nsurface reconstruction. While the extensive focus was put on volumetric and\nimplicit approaches, a number of works have shown that explicit graphics\nprimitives such as point clouds can significantly reduce computational\ncomplexity, without sacrificing the reconstructed surface quality. However,\nless emphasis has been put on modeling dynamic surfaces with point primitives.\nIn this work, we present a dynamic point field model that combines the\nrepresentational benefits of explicit point-based graphics with implicit\ndeformation networks to allow efficient modeling of non-rigid 3D surfaces.\nUsing explicit surface primitives also allows us to easily incorporate\nwell-established constraints such as-isometric-as-possible regularisation.\nWhile learning this deformation model is prone to local optima when trained in\na fully unsupervised manner, we propose to additionally leverage semantic\ninformation such as keypoint dynamics to guide the deformation learning. We\ndemonstrate our model with an example application of creating an expressive\nanimatable human avatar from a collection of 3D scans. Here, previous methods\nmostly rely on variants of the linear blend skinning paradigm, which\nfundamentally limits the expressivity of such models when dealing with complex\ncloth appearances such as long skirts. We show the advantages of our dynamic\npoint field framework in terms of its representational power, learning\nefficiency, and robustness to out-of-distribution novel poses.", "published": "2023-04-05T17:52:37Z", "version": 2}, {"aid": "2304.02628", "authors": ["Robert-Jan Bruintjes", "Tomasz Motyka", "Jan van Gemert"], "title": "What Affects Learned Equivariance in Deep Image Recognition Models?", "url": "http://arxiv.org/pdf/2304.02628v2", "summary": "Equivariance w.r.t. geometric transformations in neural networks improves\ndata efficiency, parameter efficiency and robustness to out-of-domain\nperspective shifts. When equivariance is not designed into a neural network,\nthe network can still learn equivariant functions from the data. We quantify\nthis learned equivariance, by proposing an improved measure for equivariance.\nWe find evidence for a correlation between learned translation equivariance and\nvalidation accuracy on ImageNet. We therefore investigate what can increase the\nlearned equivariance in neural networks, and find that data augmentation,\nreduced model capacity and inductive bias in the form of convolutions induce\nhigher learned equivariance in neural networks.", "published": "2023-04-05T17:54:25Z", "version": 2}, {"aid": "2304.02643", "authors": ["Alexander Kirillov", "Eric Mintun", "Nikhila Ravi", "Hanzi Mao", "Chloe Rolland", "Laura Gustafson", "Tete Xiao", "Spencer Whitehead", "Alexander C. Berg", "Wan-Yen Lo", "Piotr Doll\u00e1r", "Ross Girshick"], "title": "Segment Anything", "url": "http://arxiv.org/pdf/2304.02643v1", "summary": "We introduce the Segment Anything (SA) project: a new task, model, and\ndataset for image segmentation. Using our efficient model in a data collection\nloop, we built the largest segmentation dataset to date (by far), with over 1\nbillion masks on 11M licensed and privacy respecting images. The model is\ndesigned and trained to be promptable, so it can transfer zero-shot to new\nimage distributions and tasks. We evaluate its capabilities on numerous tasks\nand find that its zero-shot performance is impressive -- often competitive with\nor even superior to prior fully supervised results. We are releasing the\nSegment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and\n11M images at https://segment-anything.com to foster research into foundation\nmodels for computer vision.", "published": "2023-04-05T17:59:46Z", "version": 1}, {"aid": "2304.02695", "authors": ["Zhangyi Cheng", "Xiang Zhang", "Lei Yu", "Jianzhuang Liu", "Wen Yang", "Gui-Song Xia"], "title": "Recovering Continuous Scene Dynamics from A Single Blurry Image with Events", "url": "http://arxiv.org/pdf/2304.02695v1", "summary": "This paper aims at demystifying a single motion-blurred image with events and\nrevealing temporally continuous scene dynamics encrypted behind motion blurs.\nTo achieve this end, an Implicit Video Function (IVF) is learned to represent a\nsingle motion blurred image with concurrent events, enabling the latent sharp\nimage restoration of arbitrary timestamps in the range of imaging exposures.\nSpecifically, a dual attention transformer is proposed to efficiently leverage\nmerits from both modalities, i.e., the high temporal resolution of event\nfeatures and the smoothness of image features, alleviating temporal ambiguities\nwhile suppressing the event noise. The proposed network is trained only with\nthe supervision of ground-truth images of limited referenced timestamps.\nMotion- and texture-guided supervisions are employed simultaneously to enhance\nrestorations of the non-referenced timestamps and improve the overall\nsharpness. Experiments on synthetic, semi-synthetic, and real-world datasets\ndemonstrate that our proposed method outperforms state-of-the-art methods by a\nlarge margin in terms of both objective PSNR and SSIM measurements and\nsubjective evaluations.", "published": "2023-04-05T18:44:17Z", "version": 1}, {"aid": "2304.02847", "authors": ["Jonas Ngnawe", "Marianne Abemgnigni Njifon", "Jonathan Heek", "Yann Dauphin"], "title": "Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets", "url": "http://arxiv.org/pdf/2304.02847v2", "summary": "Deep networks have achieved impressive results on a range of well-curated\nbenchmark datasets. Surprisingly, their performance remains sensitive to\nperturbations that have little effect on human performance. In this work, we\npropose a novel extension of Mixup called Robustmix that regularizes networks\nto classify based on lower-frequency spatial features. We show that this type\nof regularization improves robustness on a range of benchmarks such as\nImagenet-C and Stylized Imagenet. It adds little computational overhead and,\nfurthermore, does not require a priori knowledge of a large set of image\ntransformations. We find that this approach further complements recent advances\nin model architecture and data augmentation, attaining a state-of-the-art mCE\nof 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of\n16 mCE compared to the baseline.", "published": "2023-04-06T03:24:00Z", "version": 2}, {"aid": "2304.02859", "authors": ["Zhengzhong Tu", "Peyman Milanfar", "Hossein Talebi"], "title": "MULLER: Multilayer Laplacian Resizer for Vision", "url": "http://arxiv.org/pdf/2304.02859v1", "summary": "Image resizing operation is a fundamental preprocessing module in modern\ncomputer vision. Throughout the deep learning revolution, researchers have\noverlooked the potential of alternative resizing methods beyond the commonly\nused resizers that are readily available, such as nearest-neighbors, bilinear,\nand bicubic. The key question of our interest is whether the front-end resizer\naffects the performance of deep vision models? In this paper, we present an\nextremely lightweight multilayer Laplacian resizer with only a handful of\ntrainable parameters, dubbed MULLER resizer. MULLER has a bandpass nature in\nthat it learns to boost details in certain frequency subbands that benefit the\ndownstream recognition models. We show that MULLER can be easily plugged into\nvarious training pipelines, and it effectively boosts the performance of the\nunderlying vision task with little to no extra cost. Specifically, we select a\nstate-of-the-art vision Transformer, MaxViT, as the baseline, and show that, if\ntrained with MULLER, MaxViT gains up to 0.6% top-1 accuracy, and meanwhile\nenjoys 36% inference cost saving to achieve similar top-1 accuracy on\nImageNet-1k, as compared to the standard training scheme. Notably, MULLER's\nperformance also scales with model size and training data size such as\nImageNet-21k and JFT, and it is widely applicable to multiple vision tasks,\nincluding image classification, object detection and segmentation, as well as\nimage quality assessment.", "published": "2023-04-06T04:39:21Z", "version": 1}, {"aid": "2304.02978", "authors": ["Yu Zhang", "Xiaoguang Di", "Junde Wu", "Rao Fu", "Yong Li", "Yue Wang", "Yanwu Xu", "Guohui Yang", "Chunhui Wang"], "title": "Simplifying Low-Light Image Enhancement Networks with Relative Loss Functions", "url": "http://arxiv.org/pdf/2304.02978v2", "summary": "Image enhancement is a common technique used to mitigate issues such as\nsevere noise, low brightness, low contrast, and color deviation in low-light\nimages. However, providing an optimal high-light image as a reference for\nlow-light image enhancement tasks is impossible, which makes the learning\nprocess more difficult than other image processing tasks. As a result, although\nseveral low-light image enhancement methods have been proposed, most of them\nare either too complex or insufficient in addressing all the issues in\nlow-light images. In this paper, to make the learning easier in low-light image\nenhancement, we introduce FLW-Net (Fast and LightWeight Network) and two\nrelative loss functions. Specifically, we first recognize the challenges of the\nneed for a large receptive field to obtain global contrast and the lack of an\nabsolute reference, which limits the simplification of network structures in\nthis task. Then, we propose an efficient global feature information extraction\ncomponent and two loss functions based on relative information to overcome\nthese challenges. Finally, we conducted comparative experiments to demonstrate\nthe effectiveness of the proposed method, and the results confirm that the\nproposed method can significantly reduce the complexity of supervised low-light\nimage enhancement networks while improving processing effect. The code is\navailable at \\url{https://github.com/hitzhangyu/FLW-Net}.", "published": "2023-04-06T10:05:54Z", "version": 2}, {"aid": "2304.03156", "authors": ["Sri Charan Kattamuru", "Kshitij Agrawal", "Shyam Prasad Adhikari", "Abhishek Bose", "Hemant Misra"], "title": "Patch-wise Features for Blur Image Classification", "url": "http://arxiv.org/pdf/2304.03156v1", "summary": "Images captured through smartphone cameras often suffer from degradation,\nblur being one of the major ones, posing a challenge in processing these images\nfor downstream tasks. In this paper we propose low-compute lightweight\npatch-wise features for image quality assessment. Using our method we can\ndiscriminate between blur vs sharp image degradation. To this end, we train a\ndecision-tree based XGBoost model on various intuitive image features like gray\nlevel variance, first and second order gradients, texture features like local\nbinary patterns. Experiments conducted on an open dataset show that the\nproposed low compute method results in 90.1% mean accuracy on the validation\nset, which is comparable to the accuracy of a compute-intensive VGG16 network\nwith 94% mean accuracy fine-tuned to this task. To demonstrate the\ngeneralizability of our proposed features and model we test the model on BHBID\ndataset and an internal dataset where we attain accuracy of 98% and 91%,\nrespectively. The proposed method is 10x faster than the VGG16 based model on\nCPU and scales linearly to the input image size making it suitable to be\nimplemented on low compute edge devices.", "published": "2023-04-06T15:39:11Z", "version": 1}, {"aid": "2304.04555", "authors": ["Seongmin Hong", "Se Young Chun"], "title": "Neural Diffeomorphic Non-uniform B-spline Flows", "url": "http://arxiv.org/pdf/2304.04555v2", "summary": "Normalizing flows have been successfully modeling a complex probability\ndistribution as an invertible transformation of a simple base distribution.\nHowever, there are often applications that require more than invertibility. For\ninstance, the computation of energies and forces in physics requires the second\nderivatives of the transformation to be well-defined and continuous. Smooth\nnormalizing flows employ infinitely differentiable transformation, but with the\nprice of slow non-analytic inverse transforms. In this work, we propose\ndiffeomorphic non-uniform B-spline flows that are at least twice continuously\ndifferentiable while bi-Lipschitz continuous, enabling efficient\nparametrization while retaining analytic inverse transforms based on a\nsufficient condition for diffeomorphism. Firstly, we investigate the sufficient\ncondition for Ck-2-diffeomorphic non-uniform kth-order B-spline\ntransformations. Then, we derive an analytic inverse transformation of the\nnon-uniform cubic B-spline transformation for neural diffeomorphic non-uniform\nB-spline flows. Lastly, we performed experiments on solving the force matching\nproblem in Boltzmann generators, demonstrating that our C2-diffeomorphic\nnon-uniform B-spline flows yielded solutions better than previous spline flows\nand faster than smooth normalizing flows. Our source code is publicly available\nat https://github.com/smhongok/Non-uniform-B-spline-Flow.", "published": "2023-04-07T05:34:18Z", "version": 2}, {"aid": "2304.03486", "authors": ["Subin Sahayam", "John Zakkam", "Umarani Jayaraman"], "title": "Can we learn better with hard samples?", "url": "http://arxiv.org/pdf/2304.03486v1", "summary": "In deep learning, mini-batch training is commonly used to optimize network\nparameters. However, the traditional mini-batch method may not learn the\nunder-represented samples and complex patterns in the data, leading to a longer\ntime for generalization. To address this problem, a variant of the traditional\nalgorithm has been proposed, which trains the network focusing on mini-batches\nwith high loss. The study evaluates the effectiveness of the proposed training\nusing various deep neural networks trained on three benchmark datasets\n(CIFAR-10, CIFAR-100, and STL-10). The deep neural networks used in the study\nare ResNet-18, ResNet-50, Efficient Net B4, EfficientNetV2-S, and\nMobilenetV3-S. The experimental results showed that the proposed method can\nsignificantly improve the test accuracy and speed up the convergence compared\nto the traditional mini-batch training method. Furthermore, we introduce a\nhyper-parameter delta ({\\delta}) that decides how many mini-batches are\nconsidered for training. Experiments on various values of {\\delta} found that\nthe performance of the proposed method for smaller {\\delta} values generally\nresults in similar test accuracy and faster generalization. We show that the\nproposed method generalizes in 26.47% less number of epochs than the\ntraditional mini-batch method in EfficientNet-B4 on STL-10. The proposed method\nalso improves the test top-1 accuracy by 7.26% in ResNet-18 on CIFAR-100.", "published": "2023-04-07T05:45:26Z", "version": 1}, {"aid": "2304.03532", "authors": ["Xinshun Wang", "Qiongjie Cui", "Chen Chen", "Shen Zhao", "Mengyuan Liu"], "title": "Graph-Guided MLP-Mixer for Skeleton-Based Human Motion Prediction", "url": "http://arxiv.org/pdf/2304.03532v2", "summary": "In recent years, Graph Convolutional Networks (GCNs) have been widely used in\nhuman motion prediction, but their performance remains unsatisfactory.\nRecently, MLP-Mixer, initially developed for vision tasks, has been leveraged\ninto human motion prediction as a promising alternative to GCNs, which achieves\nboth better performance and better efficiency than GCNs. Unlike GCNs, which can\nexplicitly capture human skeleton's bone-joint structure by representing it as\na graph with edges and nodes, MLP-Mixer relies on fully connected layers and\nthus cannot explicitly model such graph-like structure of human's. To break\nthis limitation of MLP-Mixer's, we propose \\textit{Graph-Guided Mixer}, a novel\napproach that equips the original MLP-Mixer architecture with the capability to\nmodel graph structure. By incorporating graph guidance, our\n\\textit{Graph-Guided Mixer} can effectively capture and utilize the specific\nconnectivity patterns within human skeleton's graph representation. In this\npaper, first we uncover a theoretical connection between MLP-Mixer and GCN that\nis unexplored in existing research. Building on this theoretical connection,\nnext we present our proposed \\textit{Graph-Guided Mixer}, explaining how the\noriginal MLP-Mixer architecture is reinvented to incorporate guidance from\ngraph structure. Then we conduct an extensive evaluation on the Human3.6M,\nAMASS, and 3DPW datasets, which shows that our method achieves state-of-the-art\nperformance.", "published": "2023-04-07T08:11:16Z", "version": 2}, {"aid": "2304.03720", "authors": ["Peyman Morteza"], "title": "Representer Theorems for Metric and Preference Learning: A Geometric Perspective", "url": "http://arxiv.org/pdf/2304.03720v1", "summary": "We explore the metric and preference learning problem in Hilbert spaces. We\nobtain a novel representer theorem for the simultaneous task of metric and\npreference learning. Our key observation is that the representer theorem can be\nformulated with respect to the norm induced by the inner product inherent in\nthe problem structure. Additionally, we demonstrate how our framework can be\napplied to the task of metric learning from triplet comparisons and show that\nit leads to a simple and self-contained representer theorem for this task. In\nthe case of Reproducing Kernel Hilbert Spaces (RKHS), we demonstrate that the\nsolution to the learning problem can be expressed using kernel terms, akin to\nclassical representer theorems.", "published": "2023-04-07T16:34:25Z", "version": 1}, {"aid": "2304.03937", "authors": ["Yulin Liu", "Haoran Liu", "Yingda Yin", "Yang Wang", "Baoquan Chen", "He Wang"], "title": "Delving into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling", "url": "http://arxiv.org/pdf/2304.03937v1", "summary": "Normalizing flows (NFs) provide a powerful tool to construct an expressive\ndistribution by a sequence of trackable transformations of a base distribution\nand form a probabilistic model of underlying data. Rotation, as an important\nquantity in computer vision, graphics, and robotics, can exhibit many\nambiguities when occlusion and symmetry occur and thus demands such\nprobabilistic models. Though much progress has been made for NFs in Euclidean\nspace, there are no effective normalizing flows without discontinuity or\nmany-to-one mapping tailored for SO(3) manifold. Given the unique non-Euclidean\nproperties of the rotation manifold, adapting the existing NFs to SO(3)\nmanifold is non-trivial. In this paper, we propose a novel normalizing flow on\nSO(3) by combining a Mobius transformation-based coupling layer and a\nquaternion affine transformation. With our proposed rotation normalizing flows,\none can not only effectively express arbitrary distributions on SO(3), but also\nconditionally build the target distribution given input observations. Extensive\nexperiments show that our rotation normalizing flows significantly outperform\nthe baselines on both unconditional and conditional tasks.", "published": "2023-04-08T06:52:02Z", "version": 1}, {"aid": "2304.04048", "authors": ["Maxim Khomiakov", "Michael Riis Andersen", "Jes Frellsen"], "title": "Polygonizer: An auto-regressive building delineator", "url": "http://arxiv.org/pdf/2304.04048v1", "summary": "In geospatial planning, it is often essential to represent objects in a\nvectorized format, as this format easily translates to downstream tasks such as\nweb development, graphics, or design. While these problems are frequently\naddressed using semantic segmentation, which requires additional\npost-processing to vectorize objects in a non-trivial way, we present an\nImage-to-Sequence model that allows for direct shape inference and is ready for\nvector-based workflows out of the box. We demonstrate the model's performance\nin various ways, including perturbations to the image input that correspond to\nvariations or artifacts commonly encountered in remote sensing applications.\nOur model outperforms prior works when using ground truth bounding boxes (one\nobject per image), achieving the lowest maximum tangent angle error.", "published": "2023-04-08T15:36:48Z", "version": 1}, {"aid": "2304.04271", "authors": ["Karan Aggarwal", "Jaideep Srivastava"], "title": "Embarrassingly Simple MixUp for Time-series", "url": "http://arxiv.org/pdf/2304.04271v1", "summary": "Labeling time series data is an expensive task because of domain expertise\nand dynamic nature of the data. Hence, we often have to deal with limited\nlabeled data settings. Data augmentation techniques have been successfully\ndeployed in domains like computer vision to exploit the use of existing labeled\ndata. We adapt one of the most commonly used technique called MixUp, in the\ntime series domain. Our proposed, MixUp++ and LatentMixUp++, use simple\nmodifications to perform interpolation in raw time series and classification\nmodel's latent space, respectively. We also extend these methods with\nsemi-supervised learning to exploit unlabeled data. We observe significant\nimprovements of 1\\% - 15\\% on time series classification on two public\ndatasets, for both low labeled data as well as high labeled data regimes, with\nLatentMixUp++.", "published": "2023-04-09T16:34:06Z", "version": 1}, {"aid": "2304.05361", "authors": ["Yusheng Huang", "Jiexing Qi", "Xinbing Wang", "Zhouhan Lin"], "title": "Asymmetric Polynomial Loss For Multi-Label Classification", "url": "http://arxiv.org/pdf/2304.05361v1", "summary": "Various tasks are reformulated as multi-label classification problems, in\nwhich the binary cross-entropy (BCE) loss is frequently utilized for optimizing\nwell-designed models. However, the vanilla BCE loss cannot be tailored for\ndiverse tasks, resulting in a suboptimal performance for different models.\nBesides, the imbalance between redundant negative samples and rare positive\nsamples could degrade the model performance. In this paper, we propose an\neffective Asymmetric Polynomial Loss (APL) to mitigate the above issues.\nSpecifically, we first perform Taylor expansion on BCE loss. Then we ameliorate\nthe coefficients of polynomial functions. We further employ the asymmetric\nfocusing mechanism to decouple the gradient contribution from the negative and\npositive samples. Moreover, we validate that the polynomial coefficients can\nrecalibrate the asymmetric focusing hyperparameters. Experiments on relation\nextraction, text classification, and image classification show that our APL\nloss can consistently improve performance without extra training burden.", "published": "2023-04-10T14:35:47Z", "version": 1}, {"aid": "2304.04820", "authors": ["Ze Wang", "Jiang Wang", "Zicheng Liu", "Qiang Qiu"], "title": "Binary Latent Diffusion", "url": "http://arxiv.org/pdf/2304.04820v1", "summary": "In this paper, we show that a binary latent space can be explored for compact\nyet expressive image representations. We model the bi-directional mappings\nbetween an image and the corresponding latent binary representation by training\nan auto-encoder with a Bernoulli encoding distribution. On the one hand, the\nbinary latent space provides a compact discrete image representation of which\nthe distribution can be modeled more efficiently than pixels or continuous\nlatent representations. On the other hand, we now represent each image patch as\na binary vector instead of an index of a learned cookbook as in discrete image\nrepresentations with vector quantization. In this way, we obtain binary latent\nrepresentations that allow for better image quality and high-resolution image\nrepresentations without any multi-stage hierarchy in the latent space. In this\nbinary latent space, images can now be generated effectively using a binary\nlatent diffusion model tailored specifically for modeling the prior over the\nbinary image representations. We present both conditional and unconditional\nimage generation experiments with multiple datasets, and show that the proposed\nmethod performs comparably to state-of-the-art methods while dramatically\nimproving the sampling efficiency to as few as 16 steps without using any\ntest-time acceleration. The proposed framework can also be seamlessly scaled to\n$1024 \\times 1024$ high-resolution image generation without resorting to latent\nhierarchy or multi-stage refinements.", "published": "2023-04-10T19:03:28Z", "version": 1}, {"aid": "2304.04824", "authors": ["Hanjing Wang", "Dhiraj Joshi", "Shiqiang Wang", "Qiang Ji"], "title": "Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning", "url": "http://arxiv.org/pdf/2304.04824v1", "summary": "Predictions made by deep learning models are prone to data perturbations,\nadversarial attacks, and out-of-distribution inputs. To build a trusted AI\nsystem, it is therefore critical to accurately quantify the prediction\nuncertainties. While current efforts focus on improving uncertainty\nquantification accuracy and efficiency, there is a need to identify uncertainty\nsources and take actions to mitigate their effects on predictions. Therefore,\nwe propose to develop explainable and actionable Bayesian deep learning methods\nto not only perform accurate uncertainty quantification but also explain the\nuncertainties, identify their sources, and propose strategies to mitigate the\nuncertainty impacts. Specifically, we introduce a gradient-based uncertainty\nattribution method to identify the most problematic regions of the input that\ncontribute to the prediction uncertainty. Compared to existing methods, the\nproposed UA-Backprop has competitive accuracy, relaxed assumptions, and high\nefficiency. Moreover, we propose an uncertainty mitigation strategy that\nleverages the attribution results as attention to further improve the model\nperformance. Both qualitative and quantitative evaluations are conducted to\ndemonstrate the effectiveness of our proposed methods.", "published": "2023-04-10T19:14:15Z", "version": 1}, {"aid": "2304.04970", "authors": ["Cheng Xin", "Soham Mukherjee", "Shreyas N. Samaga", "Tamal K. Dey"], "title": "GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning", "url": "http://arxiv.org/pdf/2304.04970v2", "summary": "$1$-parameter persistent homology, a cornerstone in Topological Data Analysis\n(TDA), studies the evolution of topological features such as connected\ncomponents and cycles hidden in data. It has been applied to enhance the\nrepresentation power of deep learning models, such as Graph Neural Networks\n(GNNs). To enrich the representations of topological features, here we propose\nto study $2$-parameter persistence modules induced by bi-filtration functions.\nIn order to incorporate these representations into machine learning models, we\nintroduce a novel vector representation called Generalized Rank Invariant\nLandscape (GRIL) for $2$-parameter persistence modules. We show that this\nvector representation is $1$-Lipschitz stable and differentiable with respect\nto underlying filtration functions and can be easily integrated into machine\nlearning models to augment encoding topological features. We present an\nalgorithm to compute the vector representation efficiently. We also test our\nmethods on synthetic and benchmark graph datasets, and compare the results with\nprevious vector representations of $1$-parameter and $2$-parameter persistence\nmodules. Further, we augment GNNs with GRIL features and observe an increase in\nperformance indicating that GRIL can capture additional features enriching\nGNNs. We make the complete code for the proposed method available at\nhttps://github.com/soham0209/mpml-graph.", "published": "2023-04-11T04:30:58Z", "version": 2}, {"aid": "2304.05055", "authors": ["Wei Ju", "Zheng Fang", "Yiyang Gu", "Zequn Liu", "Qingqing Long", "Ziyue Qiao", "Yifang Qin", "Jianhao Shen", "Fang Sun", "Zhiping Xiao", "Junwei Yang", "Jingyang Yuan", "Yusheng Zhao", "Yifan Wang", "Xiao Luo", "Ming Zhang"], "title": "A Comprehensive Survey on Deep Graph Representation Learning", "url": "http://arxiv.org/pdf/2304.05055v3", "summary": "Graph representation learning aims to effectively encode high-dimensional\nsparse graph-structured data into low-dimensional dense vectors, which is a\nfundamental task that has been widely studied in a range of fields, including\nmachine learning and data mining. Classic graph embedding methods follow the\nbasic idea that the embedding vectors of interconnected nodes in the graph can\nstill maintain a relatively close distance, thereby preserving the structural\ninformation between the nodes in the graph. However, this is sub-optimal due\nto: (i) traditional methods have limited model capacity which limits the\nlearning performance; (ii) existing techniques typically rely on unsupervised\nlearning strategies and fail to couple with the latest learning paradigms;\n(iii) representation learning and downstream tasks are dependent on each other\nwhich should be jointly enhanced. With the remarkable success of deep learning,\ndeep graph representation learning has shown great potential and advantages\nover shallow (traditional) methods, there exist a large number of deep graph\nrepresentation learning techniques have been proposed in the past decade,\nespecially graph neural networks. In this survey, we conduct a comprehensive\nsurvey on current deep graph representation learning algorithms by proposing a\nnew taxonomy of existing state-of-the-art literature. Specifically, we\nsystematically summarize the essential components of graph representation\nlearning and categorize existing approaches by the ways of graph neural network\narchitectures and the most recent advanced learning paradigms. Moreover, this\nsurvey also provides the practical and promising applications of deep graph\nrepresentation learning. Last but not least, we state new perspectives and\nsuggest challenging directions which deserve further investigations in the\nfuture.", "published": "2023-04-11T08:23:52Z", "version": 3}, {"aid": "2304.05077", "authors": ["Johannes Kleiner", "Tim Ludwig"], "title": "If consciousness is dynamically relevant, artificial intelligence isn't conscious", "url": "http://arxiv.org/pdf/2304.05077v2", "summary": "We demonstrate that if consciousness is relevant for the temporal evolution\nof a system's states--that is, if it is dynamically relevant--then AI systems\ncannot be conscious. That is because AI systems run on CPUs, GPUs, TPUs or\nother processors which have been designed and verified to adhere to\ncomputational dynamics that systematically preclude or suppress deviations. The\ndesign and verification preclude or suppress, in particular, potential\nconsciousness-related dynamical effects, so that if consciousness is\ndynamically relevant, AI systems cannot be conscious.", "published": "2023-04-11T09:21:17Z", "version": 2}, {"aid": "2304.05187", "authors": ["Jeremy Bernstein", "Chris Mingard", "Kevin Huang", "Navid Azizan", "Yisong Yue"], "title": "Automatic Gradient Descent: Deep Learning without Hyperparameters", "url": "http://arxiv.org/pdf/2304.05187v1", "summary": "The architecture of a deep neural network is defined explicitly in terms of\nthe number of layers, the width of each layer and the general network topology.\nExisting optimisation frameworks neglect this information in favour of implicit\narchitectural information (e.g. second-order methods) or architecture-agnostic\ndistance functions (e.g. mirror descent). Meanwhile, the most popular optimiser\nin practice, Adam, is based on heuristics. This paper builds a new framework\nfor deriving optimisation algorithms that explicitly leverage neural\narchitecture. The theory extends mirror descent to non-convex composite\nobjective functions: the idea is to transform a Bregman divergence to account\nfor the non-linear structure of neural architecture. Working through the\ndetails for deep fully-connected networks yields automatic gradient descent: a\nfirst-order optimiser without any hyperparameters. Automatic gradient descent\ntrains both fully-connected and convolutional networks out-of-the-box and at\nImageNet scale. A PyTorch implementation is available at\nhttps://github.com/jxbz/agd and also in Appendix B. Overall, the paper supplies\na rigorous theoretical foundation for a next-generation of\narchitecture-dependent optimisers that work automatically and without\nhyperparameters.", "published": "2023-04-11T12:45:52Z", "version": 1}, {"aid": "2304.05310", "authors": ["Qunxi Zhu", "Yao Guo", "Wei Lin"], "title": "Neural Delay Differential Equations: System Reconstruction and Image Classification", "url": "http://arxiv.org/pdf/2304.05310v1", "summary": "Neural Ordinary Differential Equations (NODEs), a framework of\ncontinuous-depth neural networks, have been widely applied, showing exceptional\nefficacy in coping with representative datasets. Recently, an augmented\nframework has been developed to overcome some limitations that emerged in the\napplication of the original framework. In this paper, we propose a new class of\ncontinuous-depth neural networks with delay, named Neural Delay Differential\nEquations (NDDEs). To compute the corresponding gradients, we use the adjoint\nsensitivity method to obtain the delayed dynamics of the adjoint. Differential\nequations with delays are typically seen as dynamical systems of infinite\ndimension that possess more fruitful dynamics. Compared to NODEs, NDDEs have a\nstronger capacity of nonlinear representations. We use several illustrative\nexamples to demonstrate this outstanding capacity. Firstly, we successfully\nmodel the delayed dynamics where the trajectories in the lower-dimensional\nphase space could be mutually intersected and even chaotic in a model-free or\nmodel-based manner. Traditional NODEs, without any argumentation, are not\ndirectly applicable for such modeling. Secondly, we achieve lower loss and\nhigher accuracy not only for the data produced synthetically by complex models\nbut also for the CIFAR10, a well-known image dataset. Our results on the NDDEs\ndemonstrate that appropriately articulating the elements of dynamical systems\ninto the network design is truly beneficial in promoting network performance.", "published": "2023-04-11T16:09:28Z", "version": 1}, {"aid": "2304.05676", "authors": ["Gr\u00e9gory Faye", "Guilhem Fouilh\u00e9", "Rufin VanRullen"], "title": "Mathematical derivation of wave propagation properties in hierarchical neural networks with predictive coding feedback dynamics", "url": "http://arxiv.org/pdf/2304.05676v1", "summary": "Sensory perception (e.g. vision) relies on a hierarchy of cortical areas, in\nwhich neural activity propagates in both directions, to convey information not\nonly about sensory inputs but also about cognitive states, expectations and\npredictions. At the macroscopic scale, neurophysiological experiments have\ndescribed the corresponding neural signals as both forward and\nbackward-travelling waves, sometimes with characteristic oscillatory\nsignatures. It remains unclear, however, how such activity patterns relate to\nspecific functional properties of the perceptual apparatus. Here, we present a\nmathematical framework, inspired by neural network models of predictive coding,\nto systematically investigate neural dynamics in a hierarchical perceptual\nsystem. We show that stability of the system can be systematically derived from\nthe values of hyper-parameters controlling the different signals (related to\nbottom-up inputs, top-down prediction and error correction). Similarly, it is\npossible to determine in which direction, and at what speed neural activity\npropagates in the system. Different neural assemblies (reflecting distinct\neigenvectors of the connectivity matrices) can simultaneously and independently\ndisplay different properties in terms of stability, propagation speed or\ndirection. We also derive continuous-limit versions of the system, both in time\nand in neural space. Finally, we analyze the possible influence of transmission\ndelays between layers, and reveal the emergence of oscillations at biologically\nplausible frequencies.", "published": "2023-04-12T07:53:22Z", "version": 1}, {"aid": "2304.05864", "authors": ["Thomas Wimmer", "Vladimir Golkov", "Hoai Nam Dang", "Moritz Zaiss", "Andreas Maier", "Daniel Cremers"], "title": "Scale-Equivariant Deep Learning for 3D Data", "url": "http://arxiv.org/pdf/2304.05864v1", "summary": "The ability of convolutional neural networks (CNNs) to recognize objects\nregardless of their position in the image is due to the\ntranslation-equivariance of the convolutional operation. Group-equivariant CNNs\ntransfer this equivariance to other transformations of the input. Dealing\nappropriately with objects and object parts of different scale is challenging,\nand scale can vary for multiple reasons such as the underlying object size or\nthe resolution of the imaging modality. In this paper, we propose a\nscale-equivariant convolutional network layer for three-dimensional data that\nguarantees scale-equivariance in 3D CNNs. Scale-equivariance lifts the burden\nof having to learn each possible scale separately, allowing the neural network\nto focus on higher-level learning goals, which leads to better results and\nbetter data-efficiency. We provide an overview of the theoretical foundations\nand scientific work on scale-equivariant neural networks in the two-dimensional\ndomain. We then transfer the concepts from 2D to the three-dimensional space\nand create a scale-equivariant convolutional layer for 3D data. Using the\nproposed scale-equivariant layer, we create a scale-equivariant U-Net for\nmedical image segmentation and compare it with a non-scale-equivariant baseline\nmethod. Our experiments demonstrate the effectiveness of the proposed method in\nachieving scale-equivariance for 3D medical image analysis. We publish our code\nat https://github.com/wimmerth/scale-equivariant-3d-convnet for further\nresearch and application.", "published": "2023-04-12T13:56:12Z", "version": 1}, {"aid": "2304.05919", "authors": ["Haochen Wang", "Kaiyou Song", "Junsong Fan", "Yuxi Wang", "Jin Xie", "Zhaoxiang Zhang"], "title": "Hard Patches Mining for Masked Image Modeling", "url": "http://arxiv.org/pdf/2304.05919v1", "summary": "Masked image modeling (MIM) has attracted much research attention due to its\npromising potential for learning scalable visual representations. In typical\napproaches, models usually focus on predicting specific contents of masked\npatches, and their performances are highly related to pre-defined mask\nstrategies. Intuitively, this procedure can be considered as training a student\n(the model) on solving given problems (predict masked patches). However, we\nargue that the model should not only focus on solving given problems, but also\nstand in the shoes of a teacher to produce a more challenging problem by\nitself. To this end, we propose Hard Patches Mining (HPM), a brand-new\nframework for MIM pre-training. We observe that the reconstruction loss can\nnaturally be the metric of the difficulty of the pre-training task. Therefore,\nwe introduce an auxiliary loss predictor, predicting patch-wise losses first\nand deciding where to mask next. It adopts a relative relationship learning\nstrategy to prevent overfitting to exact reconstruction loss values.\nExperiments under various settings demonstrate the effectiveness of HPM in\nconstructing masked images. Furthermore, we empirically find that solely\nintroducing the loss prediction objective leads to powerful representations,\nverifying the efficacy of the ability to be aware of where is hard to\nreconstruct.", "published": "2023-04-12T15:38:23Z", "version": 1}, {"aid": "2304.05939", "authors": ["Gustav Bredell", "Kyriakos Flouris", "Krishna Chaitanya", "Ertunc Erdil", "Ender Konukoglu"], "title": "Explicitly Minimizing the Blur Error of Variational Autoencoders", "url": "http://arxiv.org/pdf/2304.05939v1", "summary": "Variational autoencoders (VAEs) are powerful generative modelling methods,\nhowever they suffer from blurry generated samples and reconstructions compared\nto the images they have been trained on. Significant research effort has been\nspent to increase the generative capabilities by creating more flexible models\nbut often flexibility comes at the cost of higher complexity and computational\ncost. Several works have focused on altering the reconstruction term of the\nevidence lower bound (ELBO), however, often at the expense of losing the\nmathematical link to maximizing the likelihood of the samples under the modeled\ndistribution. Here we propose a new formulation of the reconstruction term for\nthe VAE that specifically penalizes the generation of blurry images while at\nthe same time still maximizing the ELBO under the modeled distribution. We show\nthe potential of the proposed loss on three different data sets, where it\noutperforms several recently proposed reconstruction losses for VAEs.", "published": "2023-04-12T16:03:36Z", "version": 1}, {"aid": "2304.06729", "authors": ["Marcel Binz", "Ishita Dasgupta", "Akshay Jagadish", "Matthew Botvinick", "Jane X. Wang", "Eric Schulz"], "title": "Meta-Learned Models of Cognition", "url": "http://arxiv.org/pdf/2304.06729v1", "summary": "Meta-learning is a framework for learning learning algorithms through\nrepeated interactions with an environment as opposed to designing them by hand.\nIn recent years, this framework has established itself as a promising tool for\nbuilding models of human cognition. Yet, a coherent research program around\nmeta-learned models of cognition is still missing. The purpose of this article\nis to synthesize previous work in this field and establish such a research\nprogram. We rely on three key pillars to accomplish this goal. We first point\nout that meta-learning can be used to construct Bayes-optimal learning\nalgorithms. This result not only implies that any behavioral phenomenon that\ncan be explained by a Bayesian model can also be explained by a meta-learned\nmodel but also allows us to draw strong connections to the rational analysis of\ncognition. We then discuss several advantages of the meta-learning framework\nover traditional Bayesian methods. In particular, we argue that meta-learning\ncan be applied to situations where Bayesian inference is impossible and that it\nenables us to make rational models of cognition more realistic, either by\nincorporating limited computational resources or neuroscientific knowledge.\nFinally, we reexamine prior studies from psychology and neuroscience that have\napplied meta-learning and put them into the context of these new insights. In\nsummary, our work highlights that meta-learning considerably extends the scope\nof rational analysis and thereby of cognitive theories more generally.", "published": "2023-04-12T16:30:51Z", "version": 1}, {"aid": "2304.06345", "authors": ["Shanshan Zhong", "Zhongzhan Huang", "Wushao Wen", "Jinghui Qin", "Liang Lin"], "title": "ASR: Attention-alike Structural Re-parameterization", "url": "http://arxiv.org/pdf/2304.06345v3", "summary": "The structural re-parameterization (SRP) technique is a novel deep learning\ntechnique that achieves interconversion between different network architectures\nthrough equivalent parameter transformations. This technique enables the\nmitigation of the extra costs for performance improvement during training, such\nas parameter size and inference time, through these transformations during\ninference, and therefore SRP has great potential for industrial and practical\napplications. The existing SRP methods have successfully considered many\ncommonly used architectures, such as normalizations, pooling methods, and\nmulti-branch convolution. However, the widely used attention modules which\ndrastically slow inference speed cannot be directly implemented by SRP due to\nthese modules usually act on the backbone network in a multiplicative manner\nand the modules' output is input-dependent during inference, which limits the\napplication scenarios of SRP. In this paper, we conduct extensive experiments\nfrom a statistical perspective and discover an interesting phenomenon Stripe\nObservation, which reveals that channel attention values quickly approach some\nconstant vectors during training. This observation inspires us to propose a\nsimple-yet-effective attention-alike structural re-parameterization (ASR) that\nallows us to achieve SRP for a given network while enjoying the effectiveness\nof the attention mechanism. Extensive experiments conducted on several standard\nbenchmarks demonstrate the effectiveness of ASR in generally improving the\nperformance of existing backbone networks, attention modules, and SRP methods\nwithout any elaborated model crafting. We also analyze the limitations and\nprovide experimental and theoretical evidence for the strong robustness of the\nproposed ASR.", "published": "2023-04-13T08:52:34Z", "version": 3}, {"aid": "2304.06670", "authors": ["Chris Mingard", "Henry Rees", "Guillermo Valle-P\u00e9rez", "Ard A. Louis"], "title": "Do deep neural networks have an inbuilt Occam's razor?", "url": "http://arxiv.org/pdf/2304.06670v1", "summary": "The remarkable performance of overparameterized deep neural networks (DNNs)\nmust arise from an interplay between network architecture, training algorithms,\nand structure in the data. To disentangle these three components, we apply a\nBayesian picture, based on the functions expressed by a DNN, to supervised\nlearning. The prior over functions is determined by the network, and is varied\nby exploiting a transition between ordered and chaotic regimes. For Boolean\nfunction classification, we approximate the likelihood using the error spectrum\nof functions on data. When combined with the prior, this accurately predicts\nthe posterior, measured for DNNs trained with stochastic gradient descent. This\nanalysis reveals that structured data, combined with an intrinsic Occam's\nrazor-like inductive bias towards (Kolmogorov) simple functions that is strong\nenough to counteract the exponential growth of the number of functions with\ncomplexity, is a key to the success of DNNs.", "published": "2023-04-13T16:58:21Z", "version": 1}, {"aid": "2304.09751", "authors": ["Yichun Li", "Yi Li", "Rajesh Nair", "Syed Mohsen Naqvi"], "title": "Skeleton-based action analysis for ADHD diagnosis", "url": "http://arxiv.org/pdf/2304.09751v1", "summary": "Attention Deficit Hyperactivity Disorder (ADHD) is a common neurobehavioral\ndisorder worldwide. While extensive research has focused on machine learning\nmethods for ADHD diagnosis, most research relies on high-cost equipment, e.g.,\nMRI machine and EEG patch. Therefore, low-cost diagnostic methods based on the\naction characteristics of ADHD are desired. Skeleton-based action recognition\nhas gained attention due to the action-focused nature and robustness. In this\nwork, we propose a novel ADHD diagnosis system with a skeleton-based action\nrecognition framework, utilizing a real multi-modal ADHD dataset and\nstate-of-the-art detection algorithms. Compared to conventional methods, the\nproposed method shows cost-efficiency and significant performance improvement,\nmaking it more accessible for a broad range of initial ADHD diagnoses. Through\nthe experiment results, the proposed method outperforms the conventional\nmethods in accuracy and AUC. Meanwhile, our method is widely applicable for\nmass screening.", "published": "2023-04-14T13:07:27Z", "version": 1}, {"aid": "2304.07689", "authors": ["Zhiyuan Li", "Ziru Liu", "Anna Zou", "Anca L. Ralescu"], "title": "Learning Empirical Bregman Divergence for Uncertain Distance Representation", "url": "http://arxiv.org/pdf/2304.07689v3", "summary": "Deep metric learning techniques have been used for visual representation in\nvarious supervised and unsupervised learning tasks through learning embeddings\nof samples with deep networks. However, classic approaches, which employ a\nfixed distance metric as a similarity function between two embeddings, may lead\nto suboptimal performance for capturing the complex data distribution. The\nBregman divergence generalizes measures of various distance metrics and arises\nthroughout many fields of deep metric learning. In this paper, we first show\nhow deep metric learning loss can arise from the Bregman divergence. We then\nintroduce a novel method for learning empirical Bregman divergence directly\nfrom data based on parameterizing the convex function underlying the Bregman\ndivergence with a deep learning setting. We further experimentally show that\nour approach performs effectively on five popular public datasets compared to\nother SOTA deep metric learning methods, particularly for pattern recognition\nproblems.", "published": "2023-04-16T04:16:28Z", "version": 3}, {"aid": "2304.08914", "authors": ["Peifeng Gao", "Qianqian Xu", "Peisong Wen", "Huiyang Shao", "Zhiyong Yang", "Qingming Huang"], "title": "A Study of Neural Collapse Phenomenon: Grassmannian Frame, Symmetry and Generalization", "url": "http://arxiv.org/pdf/2304.08914v2", "summary": "In this paper, we extend original Neural Collapse Phenomenon by proving\nGeneralized Neural Collapse hypothesis. We obtain Grassmannian Frame structure\nfrom the optimization and generalization of classification. This structure\nmaximally separates features of every two classes on a sphere and does not\nrequire a larger feature dimension than the number of classes. Out of curiosity\nabout the symmetry of Grassmannian Frame, we conduct experiments to explore if\nmodels with different Grassmannian Frames have different performance. As a\nresult, we discover the Symmetric Generalization phenomenon. We provide a\ntheorem to explain Symmetric Generalization of permutation. However, the\nquestion of why different directions of features can lead to such different\ngeneralization is still open for future investigation.", "published": "2023-04-18T11:35:14Z", "version": 2}, {"aid": "2304.09276", "authors": ["Jo\u00e3o Flach", "Luis C. Lamb"], "title": "A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming", "url": "http://arxiv.org/pdf/2304.09276v1", "summary": "Over the last decades, deep neural networks based-models became the dominant\nparadigm in machine learning. Further, the use of artificial neural networks in\nsymbolic learning has been seen as increasingly relevant recently. To study the\ncapabilities of neural networks in the symbolic AI domain, researchers have\nexplored the ability of deep neural networks to learn mathematical\nconstructions, such as addition and multiplication, logic inference, such as\ntheorem provers, and even the execution of computer programs. The latter is\nknown to be too complex a task for neural networks. Therefore, the results were\nnot always successful, and often required the introduction of biased elements\nin the learning process, in addition to restricting the scope of possible\nprograms to be executed. In this work, we will analyze the ability of neural\nnetworks to learn how to execute programs as a whole. To do so, we propose a\ndifferent approach. Instead of using an imperative programming language, with\ncomplex structures, we use the Lambda Calculus ({\\lambda}-Calculus), a simple,\nbut Turing-Complete mathematical formalism, which serves as the basis for\nmodern functional programming languages and is at the heart of computability\ntheory. We will introduce the use of integrated neural learning and lambda\ncalculi formalization. Finally, we explore execution of a program in\n{\\lambda}-Calculus is based on reductions, we will show that it is enough to\nlearn how to perform these reductions so that we can execute any program.\nKeywords: Machine Learning, Lambda Calculus, Neurosymbolic AI, Neural Networks,\nTransformer Model, Sequence-to-Sequence Models, Computational Models", "published": "2023-04-18T20:30:16Z", "version": 1}, {"aid": "2304.09856", "authors": ["Xianbiao Qi", "Jianan Wang", "Yihao Chen", "Yukai Shi", "Lei Zhang"], "title": "LipsFormer: Introducing Lipschitz Continuity to Vision Transformers", "url": "http://arxiv.org/pdf/2304.09856v1", "summary": "We present a Lipschitz continuous Transformer, called LipsFormer, to pursue\ntraining stability both theoretically and empirically for Transformer-based\nmodels. In contrast to previous practical tricks that address training\ninstability by learning rate warmup, layer normalization, attention\nformulation, and weight initialization, we show that Lipschitz continuity is a\nmore essential property to ensure training stability. In LipsFormer, we replace\nunstable Transformer component modules with Lipschitz continuous counterparts:\nCenterNorm instead of LayerNorm, spectral initialization instead of Xavier\ninitialization, scaled cosine similarity attention instead of dot-product\nattention, and weighted residual shortcut. We prove that these introduced\nmodules are Lipschitz continuous and derive an upper bound on the Lipschitz\nconstant of LipsFormer. Our experiments show that LipsFormer allows stable\ntraining of deep Transformer architectures without the need of careful learning\nrate tuning such as warmup, yielding a faster convergence and better\ngeneralization. As a result, on the ImageNet 1K dataset, LipsFormer-Swin-Tiny\nbased on Swin Transformer training for 300 epochs can obtain 82.7\\% without any\nlearning rate warmup. Moreover, LipsFormer-CSwin-Tiny, based on CSwin, training\nfor 300 epochs achieves a top-1 accuracy of 83.5\\% with 4.7G FLOPs and 24M\nparameters. The code will be released at\n\\url{https://github.com/IDEA-Research/LipsFormer}.", "published": "2023-04-19T17:59:39Z", "version": 1}, {"aid": "2306.01804", "authors": ["Felipe Nuti", "Tim Franzmeyer", "Jo\u00e3o F. Henriques"], "title": "Extracting Reward Functions from Diffusion Models", "url": "http://arxiv.org/pdf/2306.01804v2", "summary": "Diffusion models have achieved remarkable results in image generation, and\nhave similarly been used to learn high-performing policies in sequential\ndecision-making tasks. Decision-making diffusion models can be trained on\nlower-quality data, and then be steered with a reward function to generate\nnear-optimal trajectories. We consider the problem of extracting a reward\nfunction by comparing a decision-making diffusion model that models low-reward\nbehavior and one that models high-reward behavior; a setting related to inverse\nreinforcement learning. We first define the notion of a relative reward\nfunction of two diffusion models and show conditions under which it exists and\nis unique. We then devise a practical learning algorithm for extracting it by\naligning the gradients of a reward function -- parametrized by a neural network\n-- to the difference in outputs of both diffusion models. Our method finds\ncorrect reward functions in navigation environments, and we demonstrate that\nsteering the base model with the learned reward functions results in\nsignificantly increased performance in standard locomotion benchmarks. Finally,\nwe demonstrate that our approach generalizes beyond sequential decision-making\nby learning a reward-like function from two large-scale image generation\ndiffusion models. The extracted reward function successfully assigns lower\nrewards to harmful images.", "published": "2023-06-01T17:59:12Z", "version": 2}, {"aid": "2309.14405", "authors": ["Yuan Gong", "Alexander H. Liu", "Hongyin Luo", "Leonid Karlinsky", "James Glass"], "title": "Joint Audio and Speech Understanding", "url": "http://arxiv.org/pdf/2309.14405v3", "summary": "Humans are surrounded by audio signals that include both speech and\nnon-speech sounds. The recognition and understanding of speech and non-speech\naudio events, along with a profound comprehension of the relationship between\nthem, constitute fundamental cognitive capabilities. For the first time, we\nbuild a machine learning model, called LTU-AS, that has a conceptually similar\nuniversal audio perception and advanced reasoning ability. Specifically, by\nintegrating Whisper as a perception module and LLaMA as a reasoning module,\nLTU-AS can simultaneously recognize and jointly understand spoken text, speech\nparalinguistics, and non-speech audio events - almost everything perceivable\nfrom audio signals.", "published": "2023-09-25T17:59:05Z", "version": 3}, {"aid": "2310.20360", "authors": ["Arnulf Jentzen", "Benno Kuckuck", "Philippe von Wurstemberger"], "title": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory", "url": "http://arxiv.org/pdf/2310.20360v2", "summary": "This book aims to provide an introduction to the topic of deep learning\nalgorithms. We review essential components of deep learning algorithms in full\nmathematical detail including different artificial neural network (ANN)\narchitectures (such as fully-connected feedforward ANNs, convolutional ANNs,\nrecurrent ANNs, residual ANNs, and ANNs with batch normalization) and different\noptimization algorithms (such as the basic stochastic gradient descent (SGD)\nmethod, accelerated methods, and adaptive methods). We also cover several\ntheoretical aspects of deep learning algorithms such as approximation\ncapacities of ANNs (including a calculus for ANNs), optimization theory\n(including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In\nthe last part of the book some deep learning approximation methods for PDEs are\nreviewed including physics-informed neural networks (PINNs) and deep Galerkin\nmethods. We hope that this book will be useful for students and scientists who\ndo not yet have any background in deep learning at all and would like to gain a\nsolid foundation as well as for practitioners who would like to obtain a firmer\nmathematical understanding of the objects and methods considered in deep\nlearning.", "published": "2023-10-31T11:01:23Z", "version": 2}, {"aid": "2311.01223", "authors": ["Zhengbang Zhu", "Hanye Zhao", "Haoran He", "Yichao Zhong", "Shenyu Zhang", "Haoquan Guo", "Tingting Chen", "Weinan Zhang"], "title": "Diffusion Models for Reinforcement Learning: A Survey", "url": "http://arxiv.org/pdf/2311.01223v4", "summary": "Diffusion models surpass previous generative models in sample quality and\ntraining stability. Recent works have shown the advantages of diffusion models\nin improving reinforcement learning (RL) solutions. This survey aims to provide\nan overview of this emerging field and hopes to inspire new avenues of\nresearch. First, we examine several challenges encountered by RL algorithms.\nThen, we present a taxonomy of existing methods based on the roles of diffusion\nmodels in RL and explore how the preceding challenges are addressed. We further\noutline successful applications of diffusion models in various RL-related\ntasks. Finally, we conclude the survey and offer insights into future research\ndirections. We are actively maintaining a GitHub repository for papers and\nother related resources in utilizing diffusion models in RL:\nhttps://github.com/apexrl/Diff4RLSurvey.", "published": "2023-11-02T13:23:39Z", "version": 4}, {"aid": "2311.01412", "authors": ["Abdellah Rahmani", "Pascal Frossard"], "title": "Causal Temporal Regime Structure Learning", "url": "http://arxiv.org/pdf/2311.01412v3", "summary": "Understanding causal relationships in multivariate time series is essential\nfor predicting and controlling dynamic systems in fields like economics,\nneuroscience, and climate science. However, existing causal discovery methods\noften assume stationarity, limiting their effectiveness when time series\nconsist of sequential regimes, consecutive temporal segments with unknown\nboundaries and changing causal structures. In this work, we firstly introduce a\nframework to describe and model such time series. Then, we present CASTOR, a\nnovel method that concurrently learns the Directed Acyclic Graph (DAG) for each\nregime while determining the number of regimes and their sequential\narrangement. CASTOR optimizes the data log-likelihood using an\nexpectation-maximization algorithm, alternating between assigning regime\nindices (expectation step) and inferring causal relationships in each regime\n(maximization step). We establish the identifiability of the regimes and DAGs\nwithin our framework. Extensive experiments show that CASTOR consistently\noutperforms existing causal discovery models in detecting different regimes and\nlearning their DAGs across various settings, including linear and nonlinear\ncausal relationships, on both synthetic and real world datasets.", "published": "2023-11-02T17:26:49Z", "version": 3}, {"aid": "2311.13694", "authors": ["Sreejith Sreekumar", "Mario Berta"], "title": "Limit Distribution Theory for Quantum Divergences", "url": "http://arxiv.org/pdf/2311.13694v3", "summary": "Estimation of quantum relative entropy and its R\\'{e}nyi generalizations is a\nfundamental statistical task in quantum information theory, physics, and\nbeyond. While several estimators of these divergences have been proposed in the\nliterature along with their computational complexities explored, a limit\ndistribution theory which characterizes the asymptotic fluctuations of the\nestimation error is still premature. As our main contribution, we characterize\nthese asymptotic distributions in terms of Fr\\'{e}chet derivatives of\nelementary operator-valued functions. We achieve this by leveraging an operator\nversion of Taylor's theorem and identifying the regularity conditions needed.\nAs an application of our results, we consider an estimator of quantum relative\nentropy based on Pauli tomography of quantum states and show that the resulting\nasymptotic distribution is a centered normal, with its variance characterized\nin terms of the Pauli operators and states. We utilize the knowledge of the\naforementioned limit distribution to obtain asymptotic performance guarantees\nfor a multi-hypothesis testing problem.", "published": "2023-11-22T21:06:41Z", "version": 3}, {"aid": "2311.17643", "authors": ["Alexander Becker", "Rodrigo Caye Daudt", "Dominik Narnhofer", "Torben Peters", "Nando Metzger", "Jan Dirk Wegner", "Konrad Schindler"], "title": "Thera: Aliasing-Free Arbitrary-Scale Super-Resolution with Neural Heat Fields", "url": "http://arxiv.org/pdf/2311.17643v3", "summary": "Recent approaches to arbitrary-scale single image super-resolution (ASR) use\nneural fields to represent continuous signals that can be sampled at arbitrary\nresolutions. However, point-wise queries of neural fields do not naturally\nmatch the point spread function (PSF) of pixels, which may cause aliasing in\nthe super-resolved image. Existing methods attempt to mitigate this by\napproximating an integral version of the field at each scaling factor,\ncompromising both fidelity and generalization. In this work, we introduce\nneural heat fields, a novel neural field formulation that inherently models a\nphysically exact PSF. Our formulation enables analytically correct\nanti-aliasing at any desired output resolution, and -- unlike supersampling --\nat no additional cost. Building on this foundation, we propose Thera, an\nend-to-end ASR method that substantially outperforms existing approaches, while\nbeing more parameter-efficient and offering strong theoretical guarantees. The\nproject page is at https://therasr.github.io.", "published": "2023-11-29T14:01:28Z", "version": 3}, {"aid": "2312.07547", "authors": ["Karl J. Friston", "Tommaso Salvatori", "Takuya Isomura", "Alexander Tschantz", "Alex Kiefer", "Tim Verbelen", "Magnus Koudahl", "Aswin Paul", "Thomas Parr", "Adeel Razi", "Brett Kagan", "Christopher L. Buckley", "Maxwell J. D. Ramstead"], "title": "Active Inference and Intentional Behaviour", "url": "http://arxiv.org/pdf/2312.07547v2", "summary": "Recent advances in theoretical biology suggest that basal cognition and\nsentient behaviour are emergent properties of in vitro cell cultures and\nneuronal networks, respectively. Such neuronal networks spontaneously learn\nstructured behaviours in the absence of reward or reinforcement. In this paper,\nwe characterise this kind of self-organisation through the lens of the free\nenergy principle, i.e., as self-evidencing. We do this by first discussing the\ndefinitions of reactive and sentient behaviour in the setting of active\ninference, which describes the behaviour of agents that model the consequences\nof their actions. We then introduce a formal account of intentional behaviour,\nthat describes agents as driven by a preferred endpoint or goal in latent\nstate-spaces. We then investigate these forms of (reactive, sentient, and\nintentional) behaviour using simulations. First, we simulate the aforementioned\nin vitro experiments, in which neuronal cultures spontaneously learn to play\nPong, by implementing nested, free energy minimising processes. The simulations\nare then used to deconstruct the ensuing predictive behaviour, leading to the\ndistinction between merely reactive, sentient, and intentional behaviour, with\nthe latter formalised in terms of inductive planning. This distinction is\nfurther studied using simple machine learning benchmarks (navigation in a grid\nworld and the Tower of Hanoi problem), that show how quickly and efficiently\nadaptive behaviour emerges under an inductive form of active inference.", "published": "2023-12-06T09:38:35Z", "version": 2}, {"aid": "2312.05290", "authors": ["Chen Li", "Bipin Rajendran"], "title": "Noise Adaptor in Spiking Neural Networks", "url": "http://arxiv.org/pdf/2312.05290v1", "summary": "Recent strides in low-latency spiking neural network (SNN) algorithms have\ndrawn significant interest, particularly due to their event-driven computing\nnature and fast inference capability. One of the most efficient ways to\nconstruct a low-latency SNN is by converting a pre-trained, low-bit artificial\nneural network (ANN) into an SNN. However, this conversion process faces two\nmain challenges: First, converting SNNs from low-bit ANNs can lead to\n``occasional noise\" -- the phenomenon where occasional spikes are generated in\nspiking neurons where they should not be -- during inference, which\nsignificantly lowers SNN accuracy. Second, although low-latency SNNs initially\nshow fast improvements in accuracy with time steps, these accuracy growths soon\nplateau, resulting in their peak accuracy lagging behind both full-precision\nANNs and traditional ``long-latency SNNs'' that prioritize precision over\nspeed.\n  In response to these two challenges, this paper introduces a novel technique\nnamed ``noise adaptor.'' Noise adaptor can model occasional noise during\ntraining and implicitly optimize SNN accuracy, particularly at high simulation\ntimes $T$. Our research utilizes the ResNet model for a comprehensive analysis\nof the impact of the noise adaptor on low-latency SNNs. The results demonstrate\nthat our method outperforms the previously reported quant-ANN-to-SNN conversion\ntechnique. We achieved an accuracy of 95.95\\% within 4 time steps on CIFAR-10\nusing ResNet-18, and an accuracy of 74.37\\% within 64 time steps on ImageNet\nusing ResNet-50. Remarkably, these results were obtained without resorting to\nany noise correction methods during SNN inference, such as negative spikes or\ntwo-stage SNN simulations. Our approach significantly boosts the peak accuracy\nof low-latency SNNs, bringing them on par with the accuracy of full-precision\nANNs. Code will be open source.", "published": "2023-12-08T16:57:01Z", "version": 1}, {"aid": "2312.05431", "authors": ["Yuewei Yang", "Xiaoliang Dai", "Jialiang Wang", "Peizhao Zhang", "Hongbo Zhang"], "title": "Efficient Quantization Strategies for Latent Diffusion Models", "url": "http://arxiv.org/pdf/2312.05431v1", "summary": "Latent Diffusion Models (LDMs) capture the dynamic evolution of latent\nvariables over time, blending patterns and multimodality in a generative\nsystem. Despite the proficiency of LDM in various applications, such as\ntext-to-image generation, facilitated by robust text encoders and a variational\nautoencoder, the critical need to deploy large generative models on edge\ndevices compels a search for more compact yet effective alternatives. Post\nTraining Quantization (PTQ), a method to compress the operational size of deep\nlearning models, encounters challenges when applied to LDM due to temporal and\nstructural complexities. This study proposes a quantization strategy that\nefficiently quantize LDMs, leveraging Signal-to-Quantization-Noise Ratio (SQNR)\nas a pivotal metric for evaluation. By treating the quantization discrepancy as\nrelative noise and identifying sensitive part(s) of a model, we propose an\nefficient quantization approach encompassing both global and local strategies.\nThe global quantization process mitigates relative quantization noise by\ninitiating higher-precision quantization on sensitive blocks, while local\ntreatments address specific challenges in quantization-sensitive and\ntime-sensitive modules. The outcomes of our experiments reveal that the\nimplementation of both global and local treatments yields a highly efficient\nand effective Post Training Quantization (PTQ) of LDMs.", "published": "2023-12-09T01:47:16Z", "version": 1}, {"aid": "2312.05486", "authors": ["Bowen Sun", "Shibao Zheng"], "title": "FreeFlow: A Comprehensive Understanding on Diffusion Probabilistic Models via Optimal Transport", "url": "http://arxiv.org/pdf/2312.05486v1", "summary": "The blooming diffusion probabilistic models (DPMs) have garnered significant\ninterest due to their impressive performance and the elegant inspiration they\ndraw from physics. While earlier DPMs relied upon the Markovian assumption,\nrecent methods based on differential equations have been rapidly applied to\nenhance the efficiency and capabilities of these models. However, a theoretical\ninterpretation encapsulating these diverse algorithms is insufficient yet\npressingly required to guide further development of DPMs. In response to this\nneed, we present FreeFlow, a framework that provides a thorough explanation of\nthe diffusion formula as time-dependent optimal transport, where the\nevolutionary pattern of probability density is given by the gradient flows of a\nfunctional defined in Wasserstein space. Crucially, our framework necessitates\na unified description that not only clarifies the subtle mechanism of DPMs but\nalso indicates the roots of some defects through creative involvement of\nLagrangian and Eulerian views to understand the evolution of probability flow.\nWe particularly demonstrate that the core equation of FreeFlow condenses all\nstochastic and deterministic DPMs into a single case, showcasing the\nexpansibility of our method. Furthermore, the Riemannian geometry employed in\nour work has the potential to bridge broader subjects in mathematics, which\nenable the involvement of more profound tools for the establishment of more\noutstanding and generalized models in the future.", "published": "2023-12-09T07:24:40Z", "version": 1}, {"aid": "2312.05491", "authors": ["Vivek Miglani", "Aobo Yang", "Aram H. Markosyan", "Diego Garcia-Olano", "Narine Kokhlikyan"], "title": "Using Captum to Explain Generative Language Models", "url": "http://arxiv.org/pdf/2312.05491v1", "summary": "Captum is a comprehensive library for model explainability in PyTorch,\noffering a range of methods from the interpretability literature to enhance\nusers' understanding of PyTorch models. In this paper, we introduce new\nfeatures in Captum that are specifically designed to analyze the behavior of\ngenerative language models. We provide an overview of the available\nfunctionalities and example applications of their potential for understanding\nlearned associations within generative language models.", "published": "2023-12-09T07:35:24Z", "version": 1}, {"aid": "2312.05583", "authors": ["Peiyan Hu", "Yue Wang", "Zhi-Ming Ma"], "title": "Better Neural PDE Solvers Through Data-Free Mesh Movers", "url": "http://arxiv.org/pdf/2312.05583v2", "summary": "Recently, neural networks have been extensively employed to solve partial\ndifferential equations (PDEs) in physical system modeling. While major studies\nfocus on learning system evolution on predefined static mesh discretizations,\nsome methods utilize reinforcement learning or supervised learning techniques\nto create adaptive and dynamic meshes, due to the dynamic nature of these\nsystems. However, these approaches face two primary challenges: (1) the need\nfor expensive optimal mesh data, and (2) the change of the solution space's\ndegree of freedom and topology during mesh refinement. To address these\nchallenges, this paper proposes a neural PDE solver with a neural mesh adapter.\nTo begin with, we introduce a novel data-free neural mesh adaptor, called\nData-free Mesh Mover (DMM), with two main innovations. Firstly, it is an\noperator that maps the solution to adaptive meshes and is trained using the\nMonge-Amp\\`ere equation without optimal mesh data. Secondly, it dynamically\nchanges the mesh by moving existing nodes rather than adding or deleting nodes\nand edges. Theoretical analysis shows that meshes generated by DMM have the\nlowest interpolation error bound. Based on DMM, to efficiently and accurately\nmodel dynamic systems, we develop a moving mesh based neural PDE solver\n(MM-PDE) that embeds the moving mesh with a two-branch architecture and a\nlearnable interpolation framework to preserve information within the data.\nEmpirical experiments demonstrate that our method generates suitable meshes and\nconsiderably enhances accuracy when modeling widely considered PDE systems. The\ncode can be found at: https://github.com/Peiyannn/MM-PDE.git.", "published": "2023-12-09T14:05:28Z", "version": 2}, {"aid": "2312.07243", "authors": ["Enshu Liu", "Xuefei Ning", "Huazhong Yang", "Yu Wang"], "title": "A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2312.07243v1", "summary": "Recent years have witnessed the rapid progress and broad application of\ndiffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as\nsolving an ordinary differential equation (ODE). Despite the promising\nperformance, the generation of DPMs usually consumes much time due to the large\nnumber of function evaluations (NFE). Though recent works have accelerated the\nsampling to around 20 steps with high-order solvers, the sample quality with\nless than 10 NFE can still be improved. In this paper, we propose a unified\nsampling framework (USF) to study the optional strategies for solver. Under\nthis framework, we further reveal that taking different solving strategies at\ndifferent timesteps may help further decrease the truncation error, and a\ncarefully designed \\emph{solver schedule} has the potential to improve the\nsample quality by a large margin. Therefore, we propose a new sampling\nframework based on the exponential integral formulation that allows free\nchoices of solver strategy at each step and design specific decisions for the\nframework. Moreover, we propose $S^3$, a predictor-based search method that\nautomatically optimizes the solver schedule to get a better time-quality\ntrade-off of sampling. We demonstrate that $S^3$ can find outstanding solver\nschedules which outperform the state-of-the-art sampling methods on CIFAR-10,\nCelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID\nwith 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA\nmethod significantly. We further apply $S^3$ to Stable-Diffusion model and get\nan acceleration ratio of 2$\\times$, showing the feasibility of sampling in very\nfew steps without retraining the neural network.", "published": "2023-12-12T13:19:40Z", "version": 1}, {"aid": "2312.07971", "authors": ["Zhiyuan Ma", "zhihuan yu", "Jianjun Li", "Bowen Zhou"], "title": "LMD: Faster Image Reconstruction with Latent Masking Diffusion", "url": "http://arxiv.org/pdf/2312.07971v1", "summary": "As a class of fruitful approaches, diffusion probabilistic models (DPMs) have\nshown excellent advantages in high-resolution image reconstruction. On the\nother hand, masked autoencoders (MAEs), as popular self-supervised vision\nlearners, have demonstrated simpler and more effective image reconstruction and\ntransfer capabilities on downstream tasks. However, they all require extremely\nhigh training costs, either due to inherent high temporal-dependence (i.e.,\nexcessively long diffusion steps) or due to artificially low spatial-dependence\n(i.e., human-formulated high mask ratio, such as 0.75). To the end, this paper\npresents LMD, a faster image reconstruction framework with latent masking\ndiffusion. First, we propose to project and reconstruct images in latent space\nthrough a pre-trained variational autoencoder, which is theoretically more\nefficient than in the pixel-based space. Then, we combine the advantages of\nMAEs and DPMs to design a progressive masking diffusion model, which gradually\nincreases the masking proportion by three different schedulers and reconstructs\nthe latent features from simple to difficult, without sequentially performing\ndenoising diffusion as in DPMs or using fixed high masking ratio as in MAEs, so\nas to alleviate the high training time-consumption predicament. Our approach\nallows for learning high-capacity models and accelerate their training (by 3x\nor more) and barely reduces the original accuracy. Inference speed in\ndownstream tasks also significantly outperforms the previous approaches.", "published": "2023-12-13T08:36:51Z", "version": 1}, {"aid": "2312.08107", "authors": ["Yorgos Felekis", "Fabio Massimo Zennaro", "Nicola Branchini", "Theodoros Damoulas"], "title": "Causal Optimal Transport of Abstractions", "url": "http://arxiv.org/pdf/2312.08107v1", "summary": "Causal abstraction (CA) theory establishes formal criteria for relating\nmultiple structural causal models (SCMs) at different levels of granularity by\ndefining maps between them. These maps have significant relevance for\nreal-world challenges such as synthesizing causal evidence from multiple\nexperimental environments, learning causally consistent representations at\ndifferent resolutions, and linking interventions across multiple SCMs. In this\nwork, we propose COTA, the first method to learn abstraction maps from\nobservational and interventional data without assuming complete knowledge of\nthe underlying SCMs. In particular, we introduce a multi-marginal Optimal\nTransport (OT) formulation that enforces do-calculus causal constraints,\ntogether with a cost function that relies on interventional information. We\nextensively evaluate COTA on synthetic and real world problems, and showcase\nits advantages over non-causal, independent and aggregated COTA formulations.\nFinally, we demonstrate the efficiency of our method as a data augmentation\ntool by comparing it against the state-of-the-art CA learning framework, which\nassumes fully specified SCMs, on a real-world downstream task.", "published": "2023-12-13T12:54:34Z", "version": 1}, {"aid": "2401.12736", "authors": ["Dachong Li", "Li Li", "Zhuangzhuang Chen", "Jianqiang Li"], "title": "$ShiftwiseConv:$ Small Convolutional Kernel with Large Kernel Effect", "url": "http://arxiv.org/pdf/2401.12736v2", "summary": "Large kernels make standard convolutional neural networks (CNNs) great again\nover transformer architectures in various vision tasks. Nonetheless, recent\nstudies meticulously designed around increasing kernel size have shown\ndiminishing returns or stagnation in performance. Thus, the hidden factors of\nlarge kernel convolution that affect model performance remain unexplored. In\nthis paper, we reveal that the key hidden factors of large kernels can be\nsummarized as two separate components: extracting features at a certain\ngranularity and fusing features by multiple pathways. To this end, we leverage\nthe multi-path long-distance sparse dependency relationship to enhance feature\nutilization via the proposed Shiftwise (SW) convolution operator with a pure\nCNN architecture. In a wide range of vision tasks such as classification,\nsegmentation, and detection, SW surpasses state-of-the-art transformers and CNN\narchitectures, including SLaK and UniRepLKNet. More importantly, our\nexperiments demonstrate that $3 \\times 3$ convolutions can replace large\nconvolutions in existing large kernel CNNs to achieve comparable effects, which\nmay inspire follow-up works. Code and all the models at\nhttps://github.com/lidc54/shift-wiseConv.", "published": "2024-01-23T13:13:45Z", "version": 2}, {"aid": "2402.14327", "authors": ["Delong Chen", "Samuel Cahyawijaya", "Jianfeng Liu", "Baoyuan Wang", "Pascale Fung"], "title": "Subobject-level Image Tokenization", "url": "http://arxiv.org/pdf/2402.14327v3", "summary": "Patch-based image tokenization ignores the morphology of the visual world,\nlimiting effective and efficient learning of image understanding. Inspired by\nsubword tokenization, we introduce subobject-level adaptive token segmentation\nand explore several approaches, including superpixel, SAM, and a proposed\nEfficient and PanOptiC (EPOC) image tokenizer. Our EPOC combines boundary\ndetection -- a simple task that can be handled well by a compact model -- with\nwatershed segmentation, which inherently guarantees no pixels are left\nunsegmented. Intrinsic evaluations across 5 datasets demonstrate that EPOC's\nsegmentation aligns well with human annotations of both object- and part-level\nvisual morphology, producing more monosemantic tokens and offering substantial\nefficiency advantages. For extrinsic evaluation, we designed a token embedding\nthat handles arbitrary-shaped tokens, and trained VLMs with different\ntokenizers on 4 datasets of object recognition and detailed captioning. The\nresults reveal that subobject tokenization enables faster convergence and\nbetter generalization while using fewer visual tokens.", "published": "2024-02-22T06:47:44Z", "version": 3}, {"aid": "2403.08632", "authors": ["Zhuang Liu", "Kaiming He"], "title": "A Decade's Battle on Dataset Bias: Are We There Yet?", "url": "http://arxiv.org/pdf/2403.08632v2", "summary": "We revisit the \"dataset classification\" experiment suggested by Torralba &\nEfros (2011) a decade ago, in the new era with large-scale, diverse, and\nhopefully less biased datasets as well as more capable neural network\narchitectures. Surprisingly, we observe that modern neural networks can achieve\nexcellent accuracy in classifying which dataset an image is from: e.g., we\nreport 84.7% accuracy on held-out validation data for the three-way\nclassification problem consisting of the YFCC, CC, and DataComp datasets. Our\nfurther experiments show that such a dataset classifier could learn semantic\nfeatures that are generalizable and transferable, which cannot be explained by\nmemorization. We hope our discovery will inspire the community to rethink\nissues involving dataset bias.", "published": "2024-03-13T15:46:37Z", "version": 2}, {"aid": "2404.09032", "authors": ["Maria Manuel Clementino", "Dirk Hofmann", "Walter Tholen"], "title": "Cauchy convergence in V-normed categories", "url": "http://arxiv.org/pdf/2404.09032v2", "summary": "Building on the notion of normed category as suggested by Lawvere, we\nintroduce notions of Cauchy convergence and cocompleteness which differ from\nproposals in previous works. Key to our approach is to treat them\nconsequentially as categories enriched in the monoidal-closed category of\nnormed sets. Our notions largely lead to the anticipated outcomes when\nconsidering individual metric spaces as small normed categories, but they can\nbe challenging when considering some large categories, like those of\nsemi-normed or normed vector spaces and all linear maps, or of generalized\nmetric spaces and all mappings. These are the key example categories discussed\nin detail in this paper. Working with a general commutative quantale V as a\nvalue recipient for norms, rather than only with Lawvere's quantale of the\nextended real half-line, we observe that the categorically atypical structure\ngap between objects and morphisms in the example categories is already present\nin the underlying normed category of the enriching category of V-normed sets.\nTo show that this normed category and, in fact, all presheaf categories over\nit, are Cauchy cocomplete, we assume the quantale V to satisfy a couple of\nlight alternative extra properties. Of utmost importance to the general theory\nis the fact that our notion of normed colimit is subsumed by the notion of\nweighted colimit of enriched category theory. With this theory we are able to\nprove that all V-normed categories have correct-size Cauchy cocompletions. We\nalso prove a Banach Fixed Point Theorem for contractive endofunctors of Cauchy\ncocomplete normed categories.", "published": "2024-04-13T16:03:09Z", "version": 2}, {"aid": "2405.05966", "authors": ["Juri Opitz", "Shira Wein", "Nathan Schneider"], "title": "Natural Language Processing RELIES on Linguistics", "url": "http://arxiv.org/pdf/2405.05966v4", "summary": "Large Language Models (LLMs) have become capable of generating highly fluent\ntext in certain languages, without modules specially designed to capture\ngrammar or semantic coherence. What does this mean for the future of linguistic\nexpertise in NLP? We highlight several aspects in which NLP (still) relies on\nlinguistics, or where linguistic thinking can illuminate new directions. We\nargue our case around the acronym RELIES that encapsulates six major facets\nwhere linguistics contributes to NLP: Resources, Evaluation, Low-resource\nsettings, Interpretability, Explanation, and the Study of language. This list\nis not exhaustive, nor is linguistics the main point of reference for every\neffort under these themes; but at a macro level, these facets highlight the\nenduring importance of studying machine systems vis-\\`a-vis systems of human\nlanguage.", "published": "2024-05-09T17:59:32Z", "version": 4}, {"aid": "2405.15932", "authors": ["Soumyabrata Kundu", "Risi Kondor"], "title": "Steerable Transformers", "url": "http://arxiv.org/pdf/2405.15932v2", "summary": "In this work we introduce Steerable Transformers, an extension of the Vision\nTransformer mechanism that maintains equivariance to the special Euclidean\ngroup $\\mathrm{SE}(d)$. We propose an equivariant attention mechanism that\noperates on features extracted by steerable convolutions. Operating in Fourier\nspace, our network utilizes Fourier space non-linearities. Our experiments in\nboth two and three dimensions show that adding steerable transformer layers to\nsteerable convolutional networks enhances performance.", "published": "2024-05-24T20:43:19Z", "version": 2}, {"aid": "2406.04303", "authors": ["Benedikt Alkin", "Maximilian Beck", "Korbinian P\u00f6ppel", "Sepp Hochreiter", "Johannes Brandstetter"], "title": "Vision-LSTM: xLSTM as Generic Vision Backbone", "url": "http://arxiv.org/pdf/2406.04303v3", "summary": "Transformers are widely used as generic backbones in computer vision, despite\ninitially introduced for natural language processing. Recently, the Long\nShort-Term Memory (LSTM) has been extended to a scalable and performant\narchitecture - the xLSTM - which overcomes long-standing LSTM limitations via\nexponential gating and parallelizable matrix memory structure. In this report,\nwe introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to\ncomputer vision. ViL comprises a stack of xLSTM blocks where odd blocks process\nthe sequence of patch tokens from top to bottom while even blocks go from\nbottom to top. Experiments show that ViL holds promise to be further deployed\nas new generic backbone for computer vision architectures.", "published": "2024-06-06T17:49:21Z", "version": 3}, {"aid": "2406.09588", "authors": ["Yulong Yang", "Felix O'Mahony", "Christine Allen-Blanchette"], "title": "Learning Color Equivariant Representations", "url": "http://arxiv.org/pdf/2406.09588v5", "summary": "In this paper, we introduce group convolutional neural networks (GCNNs)\nequivariant to color variation. GCNNs have been designed for a variety of\ngeometric transformations from 2D and 3D rotation groups, to semi-groups such\nas scale. Despite the improved interpretability, accuracy and generalizability\nof these architectures, GCNNs have seen limited application in the context of\nperceptual quantities. Notably, the recent CEConv network uses a GCNN to\nachieve equivariance to hue transformations by convolving input images with a\nhue rotated RGB filter. However, this approach leads to invalid RGB values\nwhich break equivariance and degrade performance. We resolve these issues with\na lifting layer that transforms the input image directly, thereby circumventing\nthe issue of invalid RGB values and improving equivariance error by over three\norders of magnitude. Moreover, we extend the notion of color equivariance to\ninclude equivariance to saturation and luminance shift. Our hue-, saturation-,\nluminance- and color-equivariant networks achieve strong generalization to\nout-of-distribution perceptual variations and improved sample efficiency over\nconventional architectures. We demonstrate the utility of our approach on\nsynthetic and real world datasets where we consistently outperform competitive\nbaselines.", "published": "2024-06-13T21:02:03Z", "version": 5}, {"aid": "2406.13474", "authors": ["Junhan Kim", "Ho-young Kim", "Eulrang Cho", "Chungman Lee", "Joonyoung Kim", "Yongkweon Jeon"], "title": "BoA: Attention-aware Post-training Quantization without Backpropagation", "url": "http://arxiv.org/pdf/2406.13474v2", "summary": "Post-training quantization (PTQ) is a promising solution for deploying large\nlanguage models (LLMs) on resource-constrained devices. Early methods developed\nfor smaller networks like ResNet rely on gradient-based optimization, which\nbecomes impractical for hyper-scale LLMs with billions of parameters. While\nrecently proposed backpropagation-free or transformation-based methods\nalleviate this issue, their performance remains limited by either a lack of\ninter-layer dependency consideration or the use of naive nearest-rounding-based\ninteger weight assignment to save the heavy computational cost of weight\noptimization. We thus introduce a novel backpropagation-free PTQ algorithm that\noptimizes integer weights by considering inter-layer dependencies. The key\ninnovation is the development of attention-aware Hessian matrices that capture\ninter-layer interactions within the attention module. Extensive experiments\ndemonstrate that our approach not only outperforms existing weight quantization\nmethods but also shows good synergy with conventional methods to suppress\nactivation outliers, leading to state-of-the-art weight-activation quantization\nperformance.", "published": "2024-06-19T11:53:21Z", "version": 2}, {"aid": "2407.01163", "authors": ["Luca Pinchetti", "Chang Qi", "Oleh Lokshyn", "Gaspard Olivers", "Cornelius Emde", "Mufeng Tang", "Amine M'Charrak", "Simon Frieder", "Bayar Menzat", "Rafal Bogacz", "Thomas Lukasiewicz", "Tommaso Salvatori"], "title": "Benchmarking Predictive Coding Networks -- Made Simple", "url": "http://arxiv.org/pdf/2407.01163v2", "summary": "In this work, we tackle the problems of efficiency and scalability for\npredictive coding networks (PCNs) in machine learning. To do so, we propose a\nlibrary, called PCX, that focuses on performance and simplicity, and use it to\nimplement a large set of standard benchmarks for the community to use for their\nexperiments. As most works in the field propose their own tasks and\narchitectures, do not compare one against each other, and focus on small-scale\ntasks, a simple and fast open-source library and a comprehensive set of\nbenchmarks would address all these concerns. Then, we perform extensive tests\non such benchmarks using both existing algorithms for PCNs, as well as\nadaptations of other methods popular in the bio-plausible deep learning\ncommunity. All this has allowed us to (i) test architectures much larger than\ncommonly used in the literature, on more complex datasets; (ii)~reach new\nstate-of-the-art results in all of the tasks and datasets provided;\n(iii)~clearly highlight what the current limitations of PCNs are, allowing us\nto state important future research directions. With the hope of galvanizing\ncommunity efforts towards one of the main open problems in the field,\nscalability, we release code, tests, and benchmarks. Link to the library:\nhttps://github.com/liukidar/pcx", "published": "2024-07-01T10:33:44Z", "version": 2}, {"aid": "2408.13376", "authors": ["Georgios Bakirtzis", "Michail Savvas", "Ruihan Zhao", "Sandeep Chinchali", "Ufuk Topcu"], "title": "Reduce, Reuse, Recycle: Categories for Compositional Reinforcement Learning", "url": "http://arxiv.org/pdf/2408.13376v3", "summary": "In reinforcement learning, conducting task composition by forming cohesive,\nexecutable sequences from multiple tasks remains challenging. However, the\nability to (de)compose tasks is a linchpin in developing robotic systems\ncapable of learning complex behaviors. Yet, compositional reinforcement\nlearning is beset with difficulties, including the high dimensionality of the\nproblem space, scarcity of rewards, and absence of system robustness after task\ncomposition. To surmount these challenges, we view task composition through the\nprism of category theory -- a mathematical discipline exploring structures and\ntheir compositional relationships. The categorical properties of Markov\ndecision processes untangle complex tasks into manageable sub-tasks, allowing\nfor strategical reduction of dimensionality, facilitating more tractable reward\nstructures, and bolstering system robustness. Experimental results support the\ncategorical theory of reinforcement learning by enabling skill reduction,\nreuse, and recycling when learning complex robotic arm tasks.", "published": "2024-08-23T21:23:22Z", "version": 3}, {"aid": "2408.16916", "authors": ["Atsunobu Kotani", "Ren Ng"], "title": "A Computational Framework for Modeling Emergence of Color Vision in the Human Brain", "url": "http://arxiv.org/pdf/2408.16916v2", "summary": "It is a mystery how the brain decodes color vision purely from the optic\nnerve signals it receives, with a core inferential challenge being how it\ndisentangles internal perception with the correct color dimensionality from the\nunknown encoding properties of the eye. In this paper, we introduce a\ncomputational framework for modeling this emergence of human color vision by\nsimulating both the eye and the cortex. Existing research often overlooks how\nthe cortex develops color vision or represents color space internally, assuming\nthat the color dimensionality is known a priori; however, we argue that the\nvisual cortex has the capability and the challenge of inferring the color\ndimensionality purely from fluctuations in the optic nerve signals. To validate\nour theory, we introduce a simulation engine for biological eyes based on\nestablished vision science and generate optic nerve signals resulting from\nlooking at natural images. Further, we propose a bio-plausible model of\ncortical learning based on self-supervised prediction of optic nerve signal\nfluctuations under natural eye motions. We show that this model naturally\nlearns to generate color vision by disentangling retinal invariants from the\nsensory signals. When the retina contains N types of color photoreceptors, our\nsimulation shows that N-dimensional color vision naturally emerges, verified\nthrough formal colorimetry. Using this framework, we also present the first\nsimulation work that successfully boosts the color dimensionality, as observed\nin gene therapy on squirrel monkeys, and demonstrates the possibility of\nenhancing human color vision from 3D to 4D.", "published": "2024-08-29T21:27:06Z", "version": 2}, {"aid": "2410.06424", "authors": ["Christopher Fifty", "Ronald G. Junkins", "Dennis Duan", "Aniketh Iyengar", "Jerry W. Liu", "Ehsan Amid", "Sebastian Thrun", "Christopher R\u00e9"], "title": "Restructuring Vector Quantization with the Rotation Trick", "url": "http://arxiv.org/pdf/2410.06424v2", "summary": "Vector Quantized Variational AutoEncoders (VQ-VAEs) are designed to compress\na continuous input to a discrete latent space and reconstruct it with minimal\ndistortion. They operate by maintaining a set of vectors -- often referred to\nas the codebook -- and quantizing each encoder output to the nearest vector in\nthe codebook. However, as vector quantization is non-differentiable, the\ngradient to the encoder flows around the vector quantization layer rather than\nthrough it in a straight-through approximation. This approximation may be\nundesirable as all information from the vector quantization operation is lost.\nIn this work, we propose a way to propagate gradients through the vector\nquantization layer of VQ-VAEs. We smoothly transform each encoder output into\nits corresponding codebook vector via a rotation and rescaling linear\ntransformation that is treated as a constant during backpropagation. As a\nresult, the relative magnitude and angle between encoder output and codebook\nvector becomes encoded into the gradient as it propagates through the vector\nquantization layer and back to the encoder. Across 11 different VQ-VAE training\nparadigms, we find this restructuring improves reconstruction metrics, codebook\nutilization, and quantization error. Our code is available at\nhttps://github.com/cfifty/rotation_trick.", "published": "2024-10-08T23:39:34Z", "version": 2}, {"aid": "2410.11112", "authors": ["Alan T. L. Bacellar", "Zachary Susskind", "Mauricio Breternitz Jr.", "Eugene John", "Lizy K. John", "Priscila M. V. Lima", "Felipe M. G. Fran\u00e7a"], "title": "Differentiable Weightless Neural Networks", "url": "http://arxiv.org/pdf/2410.11112v5", "summary": "We introduce the Differentiable Weightless Neural Network (DWN), a model\nbased on interconnected lookup tables. Training of DWNs is enabled by a novel\nExtended Finite Difference technique for approximate differentiation of binary\nvalues. We propose Learnable Mapping, Learnable Reduction, and Spectral\nRegularization to further improve the accuracy and efficiency of these models.\nWe evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware\naccelerator, where they demonstrate superior latency, throughput, energy\nefficiency, and model area compared to state-of-the-art solutions, (2) a\nlow-power microcontroller, where they achieve preferable accuracy to XGBoost\nwhile subject to stringent memory constraints, and (3) ultra-low-cost chips,\nwhere they consistently outperform small models in both accuracy and projected\nhardware area. DWNs also compare favorably against leading approaches for\ntabular datasets, with higher average rank. Overall, our work positions DWNs as\na pioneering solution for edge-compatible high-throughput neural networks.", "published": "2024-10-14T21:43:48Z", "version": 5}, {"aid": "2410.12346", "authors": ["Guanzhou Lan", "Qianli Ma", "Yuqi Yang", "Zhigang Wang", "Dong Wang", "Xuelong Li", "Bin Zhao"], "title": "Efficient Diffusion as Low Light Enhancer", "url": "http://arxiv.org/pdf/2410.12346v2", "summary": "The computational burden of the iterative sampling process remains a major\nchallenge in diffusion-based Low-Light Image Enhancement (LLIE). Current\nacceleration methods, whether training-based or training-free, often lead to\nsignificant performance degradation, highlighting the trade-off between\nperformance and efficiency. In this paper, we identify two primary factors\ncontributing to performance degradation: fitting errors and the inference gap.\nOur key insight is that fitting errors can be mitigated by linearly\nextrapolating the incorrect score functions, while the inference gap can be\nreduced by shifting the Gaussian flow to a reflectance-aware residual space.\nBased on the above insights, we design Reflectance-Aware Trajectory Refinement\n(RATR) module, a simple yet effective module to refine the teacher trajectory\nusing the reflectance component of images. Following this, we introduce\n\\textbf{Re}flectance-aware \\textbf{D}iffusion with \\textbf{Di}stilled\n\\textbf{T}rajectory (\\textbf{ReDDiT}), an efficient and flexible distillation\nframework tailored for LLIE. Our framework achieves comparable performance to\nprevious diffusion-based methods with redundant steps in just 2 steps while\nestablishing new state-of-the-art (SOTA) results with 8 or 4 steps.\nComprehensive experimental evaluations on 10 benchmark datasets validate the\neffectiveness of our method, consistently outperforming existing SOTA methods.", "published": "2024-10-16T08:07:18Z", "version": 2}, {"aid": "2410.14634", "authors": ["Sandeep Nagar", "Girish Varma"], "title": "Parallel Backpropagation for Inverse of a Convolution with Application to Normalizing Flows", "url": "http://arxiv.org/pdf/2410.14634v3", "summary": "The inverse of an invertible convolution is an important operation that comes\nup in Normalizing Flows, Image Deblurring, etc. The naive algorithm for\nbackpropagation of this operation using Gaussian elimination has running time\n$O(n^3)$ where $n$ is the number of pixels in the image. We give a fast\nparallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square\nimage and provide a GPU implementation of the same. Inverse of Convolutions are\nusually used in Normalizing Flows in the sampling pass, making them slow. We\npropose to use the Inverse of Convolutions in the forward (image to latent\nvector) pass of the Normalizing flow. Since the sampling pass is the inverse of\nthe forward pass, it will use convolutions only, resulting in efficient\nsampling times. We use our parallel backpropagation algorithm to optimize the\ninverse of the convolution layer, resulting in fast training times. We\nimplement this approach in various Normalizing Flow backbones, resulting in our\nInverse-Flow models. We benchmark Inverse-Flow on standard datasets and show\nsignificantly improved sampling times with similar bits per dimension compared\nto previous models.", "published": "2024-10-18T17:35:33Z", "version": 3}, {"aid": "2410.20587", "authors": ["Peter Holderrieth", "Marton Havasi", "Jason Yim", "Neta Shaul", "Itai Gat", "Tommi Jaakkola", "Brian Karrer", "Ricky T. Q. Chen", "Yaron Lipman"], "title": "Generator Matching: Generative modeling with arbitrary Markov processes", "url": "http://arxiv.org/pdf/2410.20587v3", "summary": "We introduce Generator Matching, a modality-agnostic framework for generative\nmodeling using arbitrary Markov processes. Generators characterize the\ninfinitesimal evolution of a Markov process, which we leverage for generative\nmodeling in a similar vein to flow matching: we construct conditional\ngenerators which generate single data points, then learn to approximate the\nmarginal generator which generates the full data distribution. We show that\nGenerator Matching unifies various generative modeling methods, including\ndiffusion models, flow matching and discrete diffusion models. Furthermore, it\nexpands the design space to new and unexplored Markov processes such as jump\nprocesses. Finally, Generator Matching enables the construction of\nsuperpositions of Markov generative models and enables the construction of\nmultimodal models in a rigorous manner. We empirically validate our method on\nimage and multimodal generation, e.g. showing that superposition with a jump\nprocess improves performance.", "published": "2024-10-27T20:47:29Z", "version": 3}, {"aid": "2410.22494", "authors": ["Davide Barbarossa"], "title": "An excursion into Dialectica and Differentiation", "url": "http://arxiv.org/pdf/2410.22494v2", "summary": "G\\\"odel's Dialectica has been introduced and developed in the tradition of\nthe so-called functional interpretations. Only recently has it been related\nwith the a priori unrelated notion of differentiation, by taking a\nprogram-theoretic approach. We revisit the deep connection between these two\nnotions in order to understand its structural reasons, as well as to express it\nin an arguably more natural way by following a geometric intuition. More\nspecifically, we give a logical relation between a Dialectica transformed term\nand its reverse differential in a differential category and, then, we phrase\nthe Dialectica program transformation in the language of lenses, often used\nindeed in Automatic Differentiation in order to model reverse differentiation.\nWe illustrate how this clarifies why Dialectica behaves as a differentiable\nprogram transformation, and what the limits of this correspondence are.", "published": "2024-10-29T19:33:22Z", "version": 2}, {"aid": "2411.00201", "authors": ["Nidhal Jegham", "Chan Young Koh", "Marwan Abdelatti", "Abdeltawab Hendawi"], "title": "YOLO Evolution: A Comprehensive Benchmark and Architectural Review of YOLOv12, YOLO11, and Their Previous Versions", "url": "http://arxiv.org/pdf/2411.00201v4", "summary": "This study presents a comprehensive benchmark analysis of various YOLO (You\nOnly Look Once) algorithms. It represents the first comprehensive experimental\nevaluation of YOLOv3 to the latest version, YOLOv12, on various object\ndetection challenges. The challenges considered include varying object sizes,\ndiverse aspect ratios, and small-sized objects of a single class, ensuring a\ncomprehensive assessment across datasets with distinct challenges. To ensure a\nrobust evaluation, we employ a comprehensive set of metrics, including\nPrecision, Recall, Mean Average Precision (mAP), Processing Time, GFLOPs count,\nand Model Size. Our analysis highlights the distinctive strengths and\nlimitations of each YOLO version. For example: YOLOv9 demonstrates substantial\naccuracy but struggles with detecting small objects and efficiency whereas\nYOLOv10 exhibits relatively lower accuracy due to architectural choices that\naffect its performance in overlapping object detection but excels in speed and\nefficiency. Additionally, the YOLO11 family consistently shows superior\nperformance maintaining a remarkable balance of accuracy and efficiency.\nHowever, YOLOv12 delivered underwhelming results, with its complex architecture\nintroducing computational overhead without significant performance gains. These\nresults provide critical insights for both industry and academia, facilitating\nthe selection of the most suitable YOLO algorithm for diverse applications and\nguiding future enhancements.", "published": "2024-10-31T20:45:00Z", "version": 4}, {"aid": "2411.17711", "authors": ["Yue Wang", "Xu Cao", "Yaojun Hu", "Haochao Ying", "Hongxia Xu", "Ruijia Wu", "James Matthew Rehg", "Jimeng Sun", "Jian Wu", "Jintai Chen"], "title": "AnyECG: Foundational Models for Multitask Cardiac Analysis in Real-World Settings", "url": "http://arxiv.org/pdf/2411.17711v2", "summary": "Electrocardiogram (ECG), a non-invasive and affordable tool for cardiac\nmonitoring, is highly sensitive in detecting acute heart attacks. However, due\nto the lengthy nature of ECG recordings, numerous machine learning methods have\nbeen developed for automated heart disease detection to reduce human workload.\nDespite these efforts, performance remains suboptimal. A key obstacle is the\ninherent complexity of ECG data, which includes heterogeneity (e.g., varying\nsampling rates), high levels of noise, demographic-related pattern shifts, and\nintricate rhythm-event associations. To overcome these challenges, this paper\nintroduces AnyECG, a foundational model designed to extract robust\nrepresentations from any real-world ECG data. Specifically, a tailored ECG\nTokenizer encodes each fixed-duration ECG fragment into a token and, guided by\nproxy tasks, converts noisy, continuous ECG features into discrete, compact,\nand clinically meaningful local rhythm codes. These codes encapsulate basic\nmorphological, frequency, and demographic information (e.g., sex), effectively\nmitigating signal noise. We further pre-train the AnyECG to learn rhythmic\npattern associations across ECG tokens, enabling the capture of cardiac event\nsemantics. By being jointly pre-trained on diverse ECG data sources, AnyECG is\ncapable of generalizing across a wide range of downstream tasks where ECG\nsignals are recorded from various devices and scenarios. The experimental\nresults show that AnyECG achieves an average performance improvement of 6%\nacross four critical tasks-anomaly detection, arrhythmia classification,\ncorrupted lead generation, and ultra-long ECG recognition. AnyECG learns common\nECG rhythm from data and significantly outperforms state-of-the-art methods in\neach of these tasks.", "published": "2024-11-17T17:32:58Z", "version": 2}, {"aid": "2411.13625", "authors": ["Rebecca Maria Kuntz", "Heinrich von Campe", "Tobias R\u00f6spel", "Maximilian Philipp Herzog", "Bj\u00f6rn Malte Sch\u00e4fer"], "title": "Partition function approach to non-Gaussian likelihoods: information theory and state variables for Bayesian inference", "url": "http://arxiv.org/pdf/2411.13625v2", "summary": "The significance of statistical physics concepts such as entropy extends far\nbeyond classical thermodynamics. We interpret the similarity between partitions\nin statistical mechanics and partitions in Bayesian inference as an\narticulation of a result by Jaynes (1957), who clarified that thermodynamics is\nin essence a theory of information. In this, every sampling process has a\nmechanical analogue. Consequently, the divide between ensembles of samplers in\nparameter space and sampling from a mechanical system in thermodynamic\nequilibrium would be artificial. Based on this realisation, we construct a\ncontinuous modelling of a Bayes update akin to a transition between\nthermodynamic ensembles. This leads to an information theoretic interpretation\nof Jazinsky's equality, relating the expenditure of work to the influence of\ndata via the likelihood. We propose one way to transfer the vocabulary and the\nformalism of thermodynamics (energy, work, heat) and statistical mechanics\n(partition functions) to statistical inference, starting from Bayes' law.\nDifferent kinds of inference processes are discussed and relative entropies are\nshown to follow from suitably constructed partitions as an analytical\nformulation of sampling processes. Lastly, we propose an effective dimension as\na measure of system complexity. A numerical example from cosmology is put\nforward to illustrate these results.", "published": "2024-11-20T13:59:28Z", "version": 2}, {"aid": "2411.13765", "authors": ["Andrei Zlotchevski", "Linan Chen"], "title": "Schr\u00f6dinger Bridge Problem for Jump Diffusions", "url": "http://arxiv.org/pdf/2411.13765v2", "summary": "The Schr\\\"odinger bridge problem (SBP) seeks to find the measure\n$\\hat{\\mathbf{P}}$ on a certain path space which interpolates between\nstate-space distributions $\\rho_0$ at time $0$ and $\\rho_T$ at time $T$ while\nminimizing the KL divergence (relative entropy) to a reference path measure\n$\\mathbf{R}$. In this work, we tackle the SBP in the case when $\\mathbf{R}$ is\nthe path measure of a jump diffusion. Under mild assumptions, with both the\noperator theory approach and the stochastic calculus techniques, we establish\nan $h$-transform theory for jump diffusions and devise an approximation method\nto achieve the jump-diffusion SBP solution $\\hat{\\mathbf{P}}$ as the\nstrong-convergence limit of a sequence of harmonic $h$-transforms. To the best\nof our knowledge, these results are novel in the study of SBP. Moreover, the\n$h$-transform framework and the approximation method developed in this work are\nrobust and applicable to a relatively general class of jump diffusions. In\naddition, we examine the SBP of particular types of jump diffusions under\nadditional regularity conditions and extend the existing results on the SBP\nfrom the diffusion case to the jump-diffusion setting.", "published": "2024-11-21T00:28:59Z", "version": 2}, {"aid": "2411.16155", "authors": ["Toyotaro Suzumura", "Hiroki Kanezashi", "Shotaro Akahori"], "title": "Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning", "url": "http://arxiv.org/pdf/2411.16155v2", "summary": "In diagnosing neurological disorders from electroencephalography (EEG) data,\nfoundation models such as Transformers have been employed to capture temporal\ndynamics. Additionally, Graph Neural Networks (GNNs) are critical for\nrepresenting the spatial relationships among EEG sensors. However, fine-tuning\nthese large-scale models for both temporal and spatial features can be\nprohibitively large in computational cost, especially under the limited\navailability of labeled EEG datasets. We propose EEG-GraphAdapter (EGA), a\nparameter-efficient fine-tuning (PEFT) approach designed to address these\nchallenges. EGA is integrated into a pre-trained temporal backbone model as a\nGNN-based module, freezing the backbone and allowing only the adapter to be\nfine-tuned. This enables the effective acquisition of EEG spatial\nrepresentations, significantly reducing computational overhead and data\nrequirements. Experimental evaluations on two healthcare-related downstream\ntasks-Major Depressive Disorder (MDD) and Abnormality Detection (TUAB)-show\nthat EGA improves performance by up to 16.1% in F1-score compared with the\nbackbone BENDR model, highlighting its potential for scalable and accurate\nEEG-based predictions.", "published": "2024-11-25T07:30:52Z", "version": 2}, {"aid": "2412.02482", "authors": ["Andreas C. Schneider", "Valentin Neuhaus", "David A. Ehrlich", "Abdullah Makkeh", "Alexander S. Ecker", "Viola Priesemann", "Michael Wibral"], "title": "What should a neuron aim for? Designing local objective functions based on information theory", "url": "http://arxiv.org/pdf/2412.02482v3", "summary": "In modern deep neural networks, the learning dynamics of the individual\nneurons is often obscure, as the networks are trained via global optimization.\nConversely, biological systems build on self-organized, local learning,\nachieving robustness and efficiency with limited global information. We here\nshow how self-organization between individual artificial neurons can be\nachieved by designing abstract bio-inspired local learning goals. These goals\nare parameterized using a recent extension of information theory, Partial\nInformation Decomposition (PID), which decomposes the information that a set of\ninformation sources holds about an outcome into unique, redundant and\nsynergistic contributions. Our framework enables neurons to locally shape the\nintegration of information from various input classes, i.e. feedforward,\nfeedback, and lateral, by selecting which of the three inputs should contribute\nuniquely, redundantly or synergistically to the output. This selection is\nexpressed as a weighted sum of PID terms, which, for a given problem, can be\ndirectly derived from intuitive reasoning or via numerical optimization,\noffering a window into understanding task-relevant local information\nprocessing. Achieving neuron-level interpretability while enabling strong\nperformance using local learning, our work advances a principled\ninformation-theoretic foundation for local learning strategies.", "published": "2024-12-03T14:45:46Z", "version": 3}, {"aid": "2412.02865", "authors": ["Trung-Anh Dang", "Vincent Nguyen", "Ngoc-Son Vu", "Christel Vrain"], "title": "Memory-efficient Continual Learning with Neural Collapse Contrastive", "url": "http://arxiv.org/pdf/2412.02865v3", "summary": "Contrastive learning has significantly improved representation quality,\nenhancing knowledge transfer across tasks in continual learning (CL). However,\ncatastrophic forgetting remains a key challenge, as contrastive based methods\nprimarily focus on \"soft relationships\" or \"softness\" between samples, which\nshift with changing data distributions and lead to representation overlap\nacross tasks. Recently, the newly identified Neural Collapse phenomenon has\nshown promise in CL by focusing on \"hard relationships\" or \"hardness\" between\nsamples and fixed prototypes. However, this approach overlooks \"softness\",\ncrucial for capturing intra-class variability, and this rigid focus can also\npull old class representations toward current ones, increasing forgetting.\nBuilding on these insights, we propose Focal Neural Collapse Contrastive\n(FNC^2), a novel representation learning loss that effectively balances both\nsoft and hard relationships. Additionally, we introduce the Hardness-Softness\nDistillation (HSD) loss to progressively preserve the knowledge gained from\nthese relationships across tasks. Our method outperforms state-of-the-art\napproaches, particularly in minimizing memory reliance. Remarkably, even\nwithout the use of memory, our approach rivals rehearsal-based methods,\noffering a compelling solution for data privacy concerns.", "published": "2024-12-03T22:00:12Z", "version": 3}, {"aid": "2412.05343", "authors": ["Marien Renaud", "Arthur Leclaire", "Nicolas Papadakis"], "title": "Equivariant Denoisers for Image Restoration", "url": "http://arxiv.org/pdf/2412.05343v2", "summary": "One key ingredient of image restoration is to define a realistic prior on\nclean images to complete the missing information in the observation.\nState-of-the-art restoration methods rely on a neural network to encode this\nprior. Moreover, typical image distributions are invariant to some set of\ntransformations, such as rotations or flips. However, most deep architectures\nare not designed to represent an invariant image distribution. Recent works\nhave proposed to overcome this difficulty by including equivariance properties\nwithin a Plug-and-Play paradigm. In this work, we propose a unified framework\nnamed Equivariant Regularization by Denoising (ERED) based on equivariant\ndenoisers and stochastic optimization. We analyze the convergence of this\nalgorithm and discuss its practical benefit.", "published": "2024-12-06T10:22:00Z", "version": 2}, {"aid": "2412.07904", "authors": ["Stephen Robbins"], "title": "Score Change of Variables", "url": "http://arxiv.org/pdf/2412.07904v3", "summary": "We derive a general change of variables formula for score functions, showing\nthat for a smooth, invertible transformation $\\mathbf{y} = \\phi(\\mathbf{x})$,\nthe transformed score function $\\nabla_{\\mathbf{y}} \\log q(\\mathbf{y})$ can be\nexpressed directly in terms of $\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})$. Using\nthis result, we develop two applications: First, we establish a reverse-time\nIt\\^o lemma for score-based diffusion models, allowing the use of\n$\\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x})$ to reverse an SDE in the transformed\nspace without directly learning $\\nabla_{\\mathbf{y}} \\log q_t(\\mathbf{y})$.\nThis approach enables training diffusion models in one space but sampling in\nanother, effectively decoupling the forward and reverse processes. Second, we\nintroduce generalized sliced score matching, extending traditional sliced score\nmatching from linear projections to arbitrary smooth transformations. This\nprovides greater flexibility in high-dimensional density estimation. We\ndemonstrate these theoretical advances through applications to diffusion on the\nprobability simplex and empirically compare our generalized score matching\napproach against traditional sliced score matching methods.", "published": "2024-12-10T20:27:15Z", "version": 3}, {"aid": "2412.10958", "authors": ["Hao Chen", "Ze Wang", "Xiang Li", "Ximeng Sun", "Fangyi Chen", "Jiang Liu", "Jindong Wang", "Bhiksha Raj", "Zicheng Liu", "Emad Barsoum"], "title": "SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer", "url": "http://arxiv.org/pdf/2412.10958v3", "summary": "Efficient image tokenization with high compression ratios remains a critical\nchallenge for training generative models. We present SoftVQ-VAE, a continuous\nimage tokenizer that leverages soft categorical posteriors to aggregate\nmultiple codewords into each latent token, substantially increasing the\nrepresentation capacity of the latent space. When applied to Transformer-based\narchitectures, our approach compresses 256x256 and 512x512 images using as few\nas 32 or 64 1-dimensional tokens. Not only does SoftVQ-VAE show consistent and\nhigh-quality reconstruction, more importantly, it also achieves\nstate-of-the-art and significantly faster image generation results across\ndifferent denoising-based generative models. Remarkably, SoftVQ-VAE improves\ninference throughput by up to 18x for generating 256x256 images and 55x for\n512x512 images while achieving competitive FID scores of 1.78 and 2.21 for\nSiT-XL. It also improves the training efficiency of the generative models by\nreducing the number of training iterations by 2.3x while maintaining comparable\nperformance. With its fully-differentiable design and semantic-rich latent\nspace, our experiment demonstrates that SoftVQ-VAE achieves efficient\ntokenization without compromising generation quality, paving the way for more\nefficient generative models. Code and model are released.", "published": "2024-12-14T20:29:29Z", "version": 3}, {"aid": "2412.13148", "authors": ["Chao Ma", "Wenbo Gong", "Meyer Scetbon", "Edward Meeds"], "title": "SWAN: SGD with Normalization and Whitening Enables Stateless LLM Training", "url": "http://arxiv.org/pdf/2412.13148v3", "summary": "Adaptive optimizers such as Adam (Kingma & Ba, 2015) have been central to the\nsuccess of large language models. However, they often require to maintain\noptimizer states throughout training, which can result in memory requirements\nseveral times greater than the model footprint. This overhead imposes\nconstraints on scalability and computational efficiency. Stochastic Gradient\nDescent (SGD), in contrast, is a stateless optimizer, as it does not track\nstate variables during training. Consequently, it achieves optimal memory\nefficiency. However, its capability in LLM training is limited (Zhao et al.,\n2024b). In this work, we show that pre-processing SGD in a stateless manner can\nachieve the same performance as the Adam optimizer for LLM training, while\ndrastically reducing the memory cost. Specifically, we propose to pre-process\nthe instantaneous stochastic gradients using normalization and whitening. We\nshow that normalization stabilizes gradient distributions, and whitening\ncounteracts the local curvature of the loss landscape. This results in SWAN\n(SGD with Whitening And Normalization), a stochastic optimizer that eliminates\nthe need to store any optimizer states. Empirically, SWAN has the same memory\nfootprint as SGD, achieving $\\approx 50\\%$ reduction on total end-to-end memory\ncompared to Adam. In language modeling tasks, SWAN demonstrates comparable or\neven better performance than Adam: when pre-training the LLaMA model with 350M\nand 1.3B parameters, SWAN achieves a 2x speedup by reaching the same evaluation\nperplexity using half as many tokens.", "published": "2024-12-17T18:13:18Z", "version": 3}, {"aid": "2501.02950", "authors": ["Samuel J. Gershman", "Ila Fiete", "Kazuki Irie"], "title": "Key-value memory in the brain", "url": "http://arxiv.org/pdf/2501.02950v2", "summary": "Classical models of memory in psychology and neuroscience rely on\nsimilarity-based retrieval of stored patterns, where similarity is a function\nof retrieval cues and the stored patterns. While parsimonious, these models do\nnot allow distinct representations for storage and retrieval, despite their\ndistinct computational demands. Key-value memory systems, in contrast,\ndistinguish representations used for storage (values) and those used for\nretrieval (keys). This allows key-value memory systems to optimize\nsimultaneously for fidelity in storage and discriminability in retrieval. We\nreview the computational foundations of key-value memory, its role in modern\nmachine learning systems, related ideas from psychology and neuroscience,\napplications to a number of empirical puzzles, and possible biological\nimplementations.", "published": "2025-01-06T11:46:40Z", "version": 2}, {"aid": "2501.09038", "authors": ["Saman Motamed", "Laura Culp", "Kevin Swersky", "Priyank Jaini", "Robert Geirhos"], "title": "Do generative video models understand physical principles?", "url": "http://arxiv.org/pdf/2501.09038v3", "summary": "AI video generation is undergoing a revolution, with quality and realism\nadvancing rapidly. These advances have led to a passionate scientific debate:\nDo video models learn \"world models\" that discover laws of physics -- or,\nalternatively, are they merely sophisticated pixel predictors that achieve\nvisual realism without understanding the physical principles of reality? We\naddress this question by developing Physics-IQ, a comprehensive benchmark\ndataset that can only be solved by acquiring a deep understanding of various\nphysical principles, like fluid dynamics, optics, solid mechanics, magnetism\nand thermodynamics. We find that across a range of current models (Sora,\nRunway, Pika, Lumiere, Stable Video Diffusion, and VideoPoet), physical\nunderstanding is severely limited, and unrelated to visual realism. At the same\ntime, some test cases can already be successfully solved. This indicates that\nacquiring certain physical principles from observation alone may be possible,\nbut significant challenges remain. While we expect rapid advances ahead, our\nwork demonstrates that visual realism does not imply physical understanding.\nOur project page is at https://physics-iq.github.io; code at\nhttps://github.com/google-deepmind/physics-IQ-benchmark.", "published": "2025-01-14T20:59:37Z", "version": 3}, {"aid": "2501.10091", "authors": ["Christian Rahe", "Walid Maalej"], "title": "How Do Programming Students Use Generative AI?", "url": "http://arxiv.org/pdf/2501.10091v2", "summary": "Programming students have a widespread access to powerful Generative AI tools\nlike ChatGPT. While this can help understand the learning material and assist\nwith exercises, educators are voicing more and more concerns about an\noverreliance on generated outputs and lack of critical thinking skills. It is\nthus important to understand how students actually use generative AI and what\nimpact this could have on their learning behavior. To this end, we conducted a\nstudy including an exploratory experiment with 37 programming students, giving\nthem monitored access to ChatGPT while solving a code authoring exercise. The\ntask was not directly solvable by ChatGPT and required code comprehension and\nreasoning. While only 23 of the students actually opted to use the chatbot, the\nmajority of those eventually prompted it to simply generate a full solution. We\nobserved two prevalent usage strategies: to seek knowledge about general\nconcepts and to directly generate solutions. Instead of using the bot to\ncomprehend the code and their own mistakes, students often got trapped in a\nvicious cycle of submitting wrong generated code and then asking the bot for a\nfix. Those who self-reported using generative AI regularly were more likely to\nprompt the bot to generate a solution. Our findings indicate that concerns\nabout potential decrease in programmers' agency and productivity with\nGenerative AI are justified. We discuss how researchers and educators can\nrespond to the potential risk of students uncritically over-relying on\nGenerative AI. We also discuss potential modifications to our study design for\nlarge-scale replications.", "published": "2025-01-17T10:25:41Z", "version": 2}, {"aid": "2501.11566", "authors": ["Arthur Dehgan", "Hamza Abdelhedi", "Vanessa Hadid", "Irina Rish", "Karim Jerbi"], "title": "Artificial Neural Networks for Magnetoencephalography: A review of an emerging field", "url": "http://arxiv.org/pdf/2501.11566v2", "summary": "Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that\nmeasures the intricate brain dynamics underlying cognitive processes with an\nunparalleled combination of high temporal and spatial precision. MEG data\nanalytics has always relied on advanced signal processing and mathematical and\nstatistical tools for various tasks ranging from data cleaning to probing the\nsignals' rich dynamics and estimating the neural sources underlying the\nsurface-level recordings. Like in most domains, the surge in Artificial\nIntelligence (AI) has led to the increased use of Machine Learning (ML) methods\nfor MEG data classification. More recently, an emerging trend in this field is\nusing Artificial Neural Networks (ANNs) to address many MEG-related tasks. This\nreview provides a comprehensive overview of how ANNs are being used with MEG\ndata from three vantage points: First, we review work that employs ANNs for MEG\nsignal classification, i.e., for brain decoding. Second, we report on work that\nhas used ANNs as putative models of information processing in the human brain.\nFinally, we examine studies that use ANNs as techniques to tackle\nmethodological questions in MEG, including artifact correction and source\nestimation. Furthermore, we assess the current strengths and limitations of\nusing ANNs with MEG and discuss future challenges and opportunities in this\nfield. Finally, by establishing a detailed portrait of the field and providing\npractical recommendations for the future, this review seeks to provide a\nhelpful reference for both seasoned MEG researchers and newcomers to the field\nwho are interested in using ANNs to enhance the exploration of the complex\ndynamics of the human brain with MEG.", "published": "2025-01-20T16:17:12Z", "version": 2}, {"aid": "2502.06034", "authors": ["Mozes Jacobs", "Roberto C. Budzinski", "Lyle Muller", "Demba Ba", "T. Anderson Keller"], "title": "Traveling Waves Integrate Spatial Information Through Time", "url": "http://arxiv.org/pdf/2502.06034v3", "summary": "Traveling waves of neural activity are widely observed in the brain, but\ntheir precise computational function remains unclear. One prominent hypothesis\nis that they enable the transfer and integration of spatial information across\nneural populations. However, few computational models have explored how\ntraveling waves might be harnessed to perform such integrative processing.\nDrawing inspiration from the famous \"Can one hear the shape of a drum?\" problem\n-- which highlights how normal modes of wave dynamics encode geometric\ninformation -- we investigate whether similar principles can be leveraged in\nartificial neural networks. Specifically, we introduce convolutional recurrent\nneural networks that learn to produce traveling waves in their hidden states in\nresponse to visual stimuli, enabling spatial integration. By then treating\nthese wave-like activation sequences as visual representations themselves, we\nobtain a powerful representational space that outperforms local feed-forward\nnetworks on tasks requiring global spatial context. In particular, we observe\nthat traveling waves effectively expand the receptive field of locally\nconnected neurons, supporting long-range encoding and communication of\ninformation. We demonstrate that models equipped with this mechanism solve\nvisual semantic segmentation tasks demanding global integration, significantly\noutperforming local feed-forward models and rivaling non-local U-Net models\nwith fewer parameters. As a first step toward traveling-wave-based\ncommunication and visual representation in artificial networks, our findings\nsuggest wave-dynamics may provide efficiency and training stability benefits,\nwhile simultaneously offering a new framework for connecting models to\nbiological recordings of neural activity.", "published": "2025-02-09T21:14:27Z", "version": 3}, {"aid": "2502.06910", "authors": ["Songtao Huang", "Zhen Zhao", "Can Li", "Lei Bai"], "title": "TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting", "url": "http://arxiv.org/pdf/2502.06910v2", "summary": "Real-world time series often have multiple frequency components that are\nintertwined with each other, making accurate time series forecasting\nchallenging. Decomposing the mixed frequency components into multiple single\nfrequency components is a natural choice. However, the information density of\npatterns varies across different frequencies, and employing a uniform modeling\napproach for different frequency components can lead to inaccurate\ncharacterization. To address this challenges, inspired by the flexibility of\nthe recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency\nDecomposition Learning architecture (TimeKAN) to address the complex\nforecasting challenges caused by multiple frequency mixtures. Specifically,\nTimeKAN mainly consists of three components: Cascaded Frequency Decomposition\n(CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and\nFrequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to\nobtain series representations for each frequency band. Benefiting from the high\nflexibility of KAN, we design a novel M-KAN block to learn and represent\nspecific temporal patterns within each frequency band. Finally, Frequency\nMixing blocks is used to recombine the frequency bands into the original\nformat. Extensive experimental results across multiple real-world time series\ndatasets demonstrate that TimeKAN achieves state-of-the-art performance as an\nextremely lightweight architecture. Code is available at\nhttps://github.com/huangst21/TimeKAN.", "published": "2025-02-10T03:51:26Z", "version": 2}, {"aid": "2502.17460", "authors": ["B\u00e1lint T\u00f3th", "Dominik Senti", "Thorir Mar Ingolfsson", "Jeffrey Zweidler", "Alexandre Elsig", "Luca Benini", "Yawei Li"], "title": "Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation", "url": "http://arxiv.org/pdf/2502.17460v1", "summary": "Blood pressure (BP) is a key indicator of cardiovascular health. As\nhypertension remains a global cause of morbidity and mortality, accurate,\ncontinuous, and non-invasive BP monitoring is therefore of paramount\nimportance. Photoplethysmography (PPG) and electrocardiography (ECG) can\npotentially enable continuous BP monitoring, yet training accurate and robust\nmachine learning (ML) models remains challenging due to variability in data\nquality and patient-specific factors. Recently, multiple research groups\nexplored Electroencephalographic (EEG)--based foundation models and\ndemonstrated their exceptional ability to learn rich temporal resolution.\nConsidering the morphological similarities between different biosignals, the\nquestion arises of whether a model pre-trained on one modality can effectively\nbe exploited to improve the accuracy of a different signal type. In this work,\nwe take an initial step towards generalized biosignal foundation models by\ninvestigating whether model representations learned from abundant EEG data can\neffectively be transferred to ECG/PPG data solely with fine-tuning, without the\nneed for large-scale additional pre-training, for the BP estimation task.\nEvaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach\nachieves near state-of-the-art accuracy for diastolic BP (mean absolute error\nof 1.57 mmHg) and surpasses by 1.5x the accuracy of prior works for systolic BP\n(mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8\nquantization, reducing the smallest model size by over 3.5x (from 13.73 MB down\nto 3.83 MB) while preserving performance, thereby enabling unobtrusive,\nreal-time BP monitoring on resource-constrained wearable devices.", "published": "2025-02-10T13:33:12Z", "version": 1}, {"aid": "2502.17462", "authors": ["Francesco Stefano Carzaniga", "Gary Tom Hoppeler", "Michael Hersche", "Kaspar Anton Schindler", "Abbas Rahimi"], "title": "The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG", "url": "http://arxiv.org/pdf/2502.17462v1", "summary": "All data modalities are not created equal, even when the signal they measure\ncomes from the same source. In the case of the brain, two of the most important\ndata modalities are the scalp electroencephalogram (EEG), and the intracranial\nelectroencephalogram (iEEG). They are used by human experts, supported by deep\nlearning (DL) models, to accomplish a variety of tasks, such as seizure\ndetection and motor imagery classification. Although the differences between\nEEG and iEEG are well understood by human experts, the performance of DL models\nacross these two modalities remains under-explored. To help characterize the\nimportance of clean data on the performance of DL models, we propose\nBrainCodec, a high-fidelity EEG and iEEG neural compressor. We find that\ntraining BrainCodec on iEEG and then transferring to EEG yields higher\nreconstruction quality than training on EEG directly. In addition, we also find\nthat training BrainCodec on both EEG and iEEG improves fidelity when\nreconstructing EEG. Our work indicates that data sources with higher SNR, such\nas iEEG, provide better performance across the board also in the medical\ntime-series domain. BrainCodec also achieves up to a 64x compression on iEEG\nand EEG without a notable decrease in quality. BrainCodec markedly surpasses\ncurrent state-of-the-art compression models both in final compression ratio and\nin reconstruction fidelity. We also evaluate the fidelity of the compressed\nsignals objectively on a seizure detection and a motor imagery task performed\nby standard DL models. Here, we find that BrainCodec achieves a reconstruction\nfidelity high enough to ensure no performance degradation on the downstream\ntasks. Finally, we collect the subjective assessment of an expert neurologist,\nthat confirms the high reconstruction quality of BrainCodec in a realistic\nscenario. The code is available at\nhttps://github.com/IBM/eeg-ieeg-brain-compressor.", "published": "2025-02-10T15:05:06Z", "version": 1}, {"aid": "2502.07828", "authors": ["Herbert Roitblat"], "title": "Some things to know about achieving artificial general intelligence", "url": "http://arxiv.org/pdf/2502.07828v1", "summary": "Current and foreseeable GenAI models are not capable of achieving artificial\ngeneral intelligence because they are burdened with anthropogenic debt. They\ndepend heavily on human input to provide well-structured problems,\narchitecture, and training data. They cast every problem as a language pattern\nlearning problem and are thus not capable of the kind of autonomy needed to\nachieve artificial general intelligence. Current models succeed at their tasks\nbecause people solve most of the problems to which these models are directed,\nleaving only simple computations for the model to perform, such as gradient\ndescent. Another barrier is the need to recognize that there are multiple kinds\nof problems, some of which cannot be solved by available computational methods\n(for example, \"insight problems\"). Current methods for evaluating models\n(benchmarks and tests) are not adequate to identify the generality of the\nsolutions, because it is impossible to infer the means by which a problem was\nsolved from the fact of its solution. A test could be passed, for example, by a\ntest-specific or a test-general method. It is a logical fallacy (affirming the\nconsequent) to infer a method of solution from the observation of success.", "published": "2025-02-10T20:10:26Z", "version": 1}, {"aid": "2502.07247", "authors": ["Nir Lahav", "Zachariah A. Neemeh"], "title": "A Relativistic Theory of Consciousness (shortened version)", "url": "http://arxiv.org/pdf/2502.07247v3", "summary": "This paper is a shortened version of the full paper that was published in the\njournal Frontiers of Psychology in May 2022. In recent decades, the scientific\nstudy of consciousness has significantly increased our understanding of this\nelusive phenomenon. Yet, despite critical development in our understanding of\nthe functional side of consciousness, we still lack a fundamental theory\nregarding its phenomenal aspect. The phenomenal aspect of consciousness is the\nfirst-person answer to what it is like question, and it has thus far proved\nrecalcitrant to direct scientific investigation. The question of how the brain,\nor any cognitive system, can create conscious experience out of neural\nrepresentations poses a great conundrum to science. Naturalistic dualists argue\nthat it is composed of a primitive, private, nonreductive element of reality.\nIllusionists, on the other hand, argue that it is merely a cognitive illusion.\nWe contend that both the dualist and illusionist positions are flawed because\nthey tacitly assume consciousness to be an absolute property that does not\ndepend on the observer. We developed a conceptual and a mathematical argument\nfor a relativistic theory of consciousness in which a system either has or does\nnot have phenomenal consciousness with respect to some observer. According to\nthe theory, Phenomenal consciousness is neither private nor delusional, just\nrelativistic. In the frame of reference of the cognitive system, it will be\nobservable (first-person perspective) and in other frame of reference it will\nnot (third-person perspective). These two cognitive frames of reference are\nboth correct, just as in the case of an observer that claims to be at rest\nwhile another will claim that the observer has constant velocity. Neither\nobserver position can be privileged, as they both describe the same underlying\nreality.", "published": "2025-02-11T04:29:43Z", "version": 3}, {"aid": "2502.09885", "authors": ["YongKyung Oh", "Seungsu Kam", "Jonghun Lee", "Dong-Young Lim", "Sungil Kim", "Alex Bui"], "title": "Comprehensive Review of Neural Differential Equations for Time Series Analysis", "url": "http://arxiv.org/pdf/2502.09885v1", "summary": "Time series modeling and analysis has become critical in various domains.\nConventional methods such as RNNs and Transformers, while effective for\ndiscrete-time and regularly sampled data, face significant challenges in\ncapturing the continuous dynamics and irregular sampling patterns inherent in\nreal-world scenarios. Neural Differential Equations (NDEs) represent a paradigm\nshift by combining the flexibility of neural networks with the mathematical\nrigor of differential equations. This paper presents a comprehensive review of\nNDE-based methods for time series analysis, including neural ordinary\ndifferential equations, neural controlled differential equations, and neural\nstochastic differential equations. We provide a detailed discussion of their\nmathematical formulations, numerical methods, and applications, highlighting\ntheir ability to model continuous-time dynamics. Furthermore, we address key\nchallenges and future research directions. This survey serves as a foundation\nfor researchers and practitioners seeking to leverage NDEs for advanced time\nseries analysis.", "published": "2025-02-14T03:21:04Z", "version": 1}, {"aid": "2502.09956", "authors": ["Belinda Mo", "Kyssen Yu", "Joshua Kazdan", "Proud Mpala", "Lisa Yu", "Chris Cundy", "Charilaos Kanatsoulis", "Sanmi Koyejo"], "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "url": "http://arxiv.org/pdf/2502.09956v1", "summary": "Recent interest in building foundation models for KGs has highlighted a\nfundamental challenge: knowledge-graph data is relatively scarce. The\nbest-known KGs are primarily human-labeled, created by pattern-matching, or\nextracted using early NLP techniques. While human-generated KGs are in short\nsupply, automatically extracted KGs are of questionable quality. We present a\nsolution to this data scarcity problem in the form of a text-to-KG generator\n(KGGen), a package that uses language models to create high-quality graphs from\nplaintext. Unlike other KG extractors, KGGen clusters related entities to\nreduce sparsity in extracted KGs. KGGen is available as a Python library\n(\\texttt{pip install kg-gen}), making it accessible to everyone. Along with\nKGGen, we release the first benchmark, Measure of of Information in Nodes and\nEdges (MINE), that tests an extractor's ability to produce a useful KG from\nplain text. We benchmark our new tool against existing extractors and\ndemonstrate far superior performance.", "published": "2025-02-14T07:28:08Z", "version": 1}, {"aid": "2502.10368", "authors": ["John H. Selby", "Maria E. Stasinou", "Matt Wilson", "Bob Coecke"], "title": "Generalised Process Theories", "url": "http://arxiv.org/pdf/2502.10368v1", "summary": "Process theories provide a powerful framework for describing compositional\nstructures across diverse fields, from quantum mechanics to computational\nlinguistics. Traditionally, they have been formalized using symmetric monoidal\ncategories (SMCs). However, various generalizations, including time-neutral,\nhigher-order, and enriched process theories, do not naturally conform to this\nstructure. In this work, we propose an alternative formalization using operad\nalgebras, motivated by recent results connecting SMCs to operadic structures,\nwhich captures a broader class of process theories. By leveraging the\nstring-diagrammatic language, we provide an accessible yet rigorous formulation\nthat unifies and extends traditional process-theoretic approaches. Our operadic\nframework not only recovers standard process theories as a special case but\nalso enables new insights into quantum foundations and compositional\nstructures. This work paves the way for further investigations into the\nalgebraic and operational properties of generalised process theories within an\noperadic setting.", "published": "2025-02-14T18:47:07Z", "version": 1}, {"aid": "2502.11089", "authors": ["Jingyang Yuan", "Huazuo Gao", "Damai Dai", "Junyu Luo", "Liang Zhao", "Zhengyan Zhang", "Zhenda Xie", "Y. X. Wei", "Lean Wang", "Zhiping Xiao", "Yuqing Wang", "Chong Ruan", "Ming Zhang", "Wenfeng Liang", "Wangding Zeng"], "title": "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention", "url": "http://arxiv.org/pdf/2502.11089v2", "summary": "Long-context modeling is crucial for next-generation language models, yet the\nhigh computational cost of standard attention mechanisms poses significant\ncomputational challenges. Sparse attention offers a promising direction for\nimproving efficiency while maintaining model capabilities. We present NSA, a\nNatively trainable Sparse Attention mechanism that integrates algorithmic\ninnovations with hardware-aligned optimizations to achieve efficient\nlong-context modeling. NSA employs a dynamic hierarchical sparse strategy,\ncombining coarse-grained token compression with fine-grained token selection to\npreserve both global context awareness and local precision. Our approach\nadvances sparse attention design with two key innovations: (1) We achieve\nsubstantial speedups through arithmetic intensity-balanced algorithm design,\nwith implementation optimizations for modern hardware. (2) We enable end-to-end\ntraining, reducing pretraining computation without sacrificing model\nperformance. As shown in Figure 1, experiments show the model pretrained with\nNSA maintains or exceeds Full Attention models across general benchmarks,\nlong-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves\nsubstantial speedups over Full Attention on 64k-length sequences across\ndecoding, forward propagation, and backward propagation, validating its\nefficiency throughout the model lifecycle.", "published": "2025-02-16T11:53:44Z", "version": 2}, {"aid": "2502.13161", "authors": ["Maxwell J. D. Ramstead", "Candice Pattisapu", "Jason Fox", "Jeff Beck"], "title": "Noumenal Labs White Paper: How To Build A Brain", "url": "http://arxiv.org/pdf/2502.13161v1", "summary": "This white paper describes some of the design principles for artificial or\nmachine intelligence that guide efforts at Noumenal Labs. These principles are\ndrawn from both nature and from the means by which we come to represent and\nunderstand it. The end goal of research and development in this field should be\nto design machine intelligences that augment our understanding of the world and\nenhance our ability to act in it, without replacing us. In the first two\nsections, we examine the core motivation for our approach: resolving the\ngrounding problem. We argue that the solution to the grounding problem rests in\nthe design of models grounded in the world that we inhabit, not mere word\nmodels. A machine super intelligence that is capable of significantly enhancing\nour understanding of the human world must represent the world as we do and be\ncapable of generating new knowledge, building on what we already know. In other\nwords, it must be properly grounded and explicitly designed for rational,\nempirical inquiry, modeled after the scientific method. A primary implication\nof this design principle is that agents must be capable of engaging\nautonomously in causal physics discovery. We discuss the pragmatic implications\nof this approach, and in particular, the use cases in realistic 3D world\nmodeling and multimodal, multidimensional time series analysis.", "published": "2025-02-16T18:15:37Z", "version": 1}, {"aid": "2502.11492", "authors": ["Kung-Hsiang Huang", "Can Qin", "Haoyi Qiu", "Philippe Laban", "Shafiq Joty", "Caiming Xiong", "Chien-Sheng Wu"], "title": "Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding", "url": "http://arxiv.org/pdf/2502.11492v2", "summary": "Vision Language Models (VLMs) have achieved remarkable progress in multimodal\ntasks, yet they often struggle with visual arithmetic, seemingly simple\ncapabilities like object counting or length comparison, which are essential for\nrelevant complex tasks like chart understanding and geometric reasoning. In\nthis work, we first investigate the root causes of this deficiency through a\nsuite of probing tasks focusing on basic visual arithmetic. Our analysis\nreveals that while pre-trained vision encoders typically capture sufficient\ninformation, the text decoder often fails to decode it correctly for arithmetic\nreasoning. To address this, we propose CogAlign, a novel post-training strategy\ninspired by Piaget's theory of cognitive development. CogAlign trains VLMs to\nrecognize invariant properties under visual transformations. We demonstrate\nthat this approach significantly improves the performance of three diverse VLMs\non our proposed probing tasks. Furthermore, CogAlign enhances performance by an\naverage of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching\nsupervised fine-tuning methods while requiring only 60% less training data.\nThese results highlight the effectiveness and generalizability of CogAlign in\nimproving fundamental visual arithmetic capabilities and their transfer to\ndownstream tasks.", "published": "2025-02-17T06:54:49Z", "version": 2}, {"aid": "2502.12048", "authors": ["Shreya Shukla", "Jose Torres", "Abhijit Mishra", "Jacek Gwizdka", "Shounak Roychowdhury"], "title": "A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond", "url": "http://arxiv.org/pdf/2502.12048v2", "summary": "Integration of Brain-Computer Interfaces (BCIs) and Generative Artificial\nIntelligence (GenAI) has opened new frontiers in brain signal decoding,\nenabling assistive communication, neural representation learning, and\nmultimodal integration. BCIs, particularly those leveraging\nElectroencephalography (EEG), provide a non-invasive means of translating\nneural activity into meaningful outputs. Recent advances in deep learning,\nincluding Generative Adversarial Networks (GANs) and Transformer-based Large\nLanguage Models (LLMs), have significantly improved EEG-based generation of\nimages, text, and speech. This paper provides a literature review of the\nstate-of-the-art in EEG-based multimodal generation, focusing on (i)\nEEG-to-image generation through GANs, Variational Autoencoders (VAEs), and\nDiffusion Models, and (ii) EEG-to-text generation leveraging Transformer based\nlanguage models and contrastive learning methods. Additionally, we discuss the\nemerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. We\nhighlight key datasets, use cases, challenges, and EEG feature encoding methods\nthat underpin generative approaches. By providing a structured overview of\nEEG-based generative AI, this survey aims to equip researchers and\npractitioners with insights to advance neural decoding, enhance assistive\ntechnologies, and expand the frontiers of brain-computer interaction.", "published": "2025-02-17T17:16:41Z", "version": 2}, {"aid": "2502.12298", "authors": ["Aditya Ranganath", "Mukesh Singhal", "Roummel Marcia"], "title": "Symmetric Rank-One Quasi-Newton Methods for Deep Learning Using Cubic Regularization", "url": "http://arxiv.org/pdf/2502.12298v1", "summary": "Stochastic gradient descent and other first-order variants, such as Adam and\nAdaGrad, are commonly used in the field of deep learning due to their\ncomputational efficiency and low-storage memory requirements. However, these\nmethods do not exploit curvature information. Consequently, iterates can\nconverge to saddle points or poor local minima. On the other hand, Quasi-Newton\nmethods compute Hessian approximations which exploit this information with a\ncomparable computational budget. Quasi-Newton methods re-use previously\ncomputed iterates and gradients to compute a low-rank structured update. The\nmost widely used quasi-Newton update is the L-BFGS, which guarantees a positive\nsemi-definite Hessian approximation, making it suitable in a line search\nsetting. However, the loss functions in DNNs are non-convex, where the Hessian\nis potentially non-positive definite. In this paper, we propose using a\nlimited-memory symmetric rank-one quasi-Newton approach which allows for\nindefinite Hessian approximations, enabling directions of negative curvature to\nbe exploited. Furthermore, we use a modified adaptive regularized cubics\napproach, which generates a sequence of cubic subproblems that have closed-form\nsolutions with suitable regularization choices. We investigate the performance\nof our proposed method on autoencoders and feed-forward neural network models\nand compare our approach to state-of-the-art first-order adaptive stochastic\nmethods as well as other quasi-Newton methods.x", "published": "2025-02-17T20:20:11Z", "version": 1}, {"aid": "2502.12524", "authors": ["Yunjie Tian", "Qixiang Ye", "David Doermann"], "title": "YOLOv12: Attention-Centric Real-Time Object Detectors", "url": "http://arxiv.org/pdf/2502.12524v1", "summary": "Enhancing the network architecture of the YOLO framework has been crucial for\na long time, but has focused on CNN-based improvements despite the proven\nsuperiority of attention mechanisms in modeling capabilities. This is because\nattention-based models cannot match the speed of CNN-based models. This paper\nproposes an attention-centric YOLO framework, namely YOLOv12, that matches the\nspeed of previous CNN-based ones while harnessing the performance benefits of\nattention mechanisms. YOLOv12 surpasses all popular real-time object detectors\nin accuracy with competitive speed. For example, YOLOv12-N achieves 40.6% mAP\nwith an inference latency of 1.64 ms on a T4 GPU, outperforming advanced\nYOLOv10-N / YOLOv11-N by 2.1%/1.2% mAP with a comparable speed. This advantage\nextends to other model scales. YOLOv12 also surpasses end-to-end real-time\ndetectors that improve DETR, such as RT-DETR / RT-DETRv2: YOLOv12-S beats\nRT-DETR-R18 / RT-DETRv2-R18 while running 42% faster, using only 36% of the\ncomputation and 45% of the parameters. More comparisons are shown in Figure 1.", "published": "2025-02-18T04:20:14Z", "version": 1}, {"aid": "2502.12567", "authors": ["Chao Yang", "Yong Fan", "Cheng Lu", "Zhijing Yang"], "title": "DeltaDiff: A Residual-Guided Diffusion Model for Enhanced Image Super-Resolution", "url": "http://arxiv.org/pdf/2502.12567v1", "summary": "Recently, the application of diffusion models in super-resolution tasks has\nbecome a popular research direction. Existing work is focused on fully\nmigrating diffusion models to SR tasks. The diffusion model is proposed in the\nfield of image generation, so in order to make the generated results diverse,\nthe diffusion model combines random Gaussian noise and distributed sampling to\nincrease the randomness of the model.\n  However, the essence of super-resolution tasks requires the model to generate\nhigh-resolution images with fidelity. Excessive addition of random factors can\nresult in the model generating detailed information that does not belong to the\nHR image. To address this issue, we propose a new diffusion model called\nDeltadiff, which uses only residuals between images for diffusion, making the\nentire diffusion process more stable. The experimental results show that our\nmethod surpasses state-of-the-art models and generates results with better\nfidelity. Our code and model are publicly available at\nhttps://github.com/continueyang/DeltaDiff", "published": "2025-02-18T06:07:14Z", "version": 1}, {"aid": "2502.13200", "authors": ["Alana Santana", "Paula P. Costa", "Esther L. Colombini"], "title": "Learning To Explore With Predictive World Model Via Self-Supervised Learning", "url": "http://arxiv.org/pdf/2502.13200v1", "summary": "Autonomous artificial agents must be able to learn behaviors in complex\nenvironments without humans to design tasks and rewards. Designing these\nfunctions for each environment is not feasible, thus, motivating the\ndevelopment of intrinsic reward functions. In this paper, we propose using\nseveral cognitive elements that have been neglected for a long time to build an\ninternal world model for an intrinsically motivated agent. Our agent performs\nsatisfactory iterations with the environment, learning complex behaviors\nwithout needing previously designed reward functions. We used 18 Atari games to\nevaluate what cognitive skills emerge in games that require reactive and\ndeliberative behaviors. Our results show superior performance compared to the\nstate-of-the-art in many test cases with dense and sparse rewards.", "published": "2025-02-18T18:39:23Z", "version": 1}, {"aid": "2502.13128", "authors": ["Zihan Liu", "Shuangrui Ding", "Zhixiong Zhang", "Xiaoyi Dong", "Pan Zhang", "Yuhang Zang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "title": "SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation", "url": "http://arxiv.org/pdf/2502.13128v1", "summary": "Text-to-song generation, the task of creating vocals and accompaniment from\ntextual inputs, poses significant challenges due to domain complexity and data\nscarcity. Existing approaches often employ multi-stage generation procedures,\nresulting in cumbersome training and inference pipelines. In this paper, we\npropose SongGen, a fully open-source, single-stage auto-regressive transformer\ndesigned for controllable song generation. The proposed model facilitates\nfine-grained control over diverse musical attributes, including lyrics and\ntextual descriptions of instrumentation, genre, mood, and timbre, while also\noffering an optional three-second reference clip for voice cloning. Within a\nunified auto-regressive framework, SongGen supports two output modes: mixed\nmode, which generates a mixture of vocals and accompaniment directly, and\ndual-track mode, which synthesizes them separately for greater flexibility in\ndownstream applications. We explore diverse token pattern strategies for each\nmode, leading to notable improvements and valuable insights. Furthermore, we\ndesign an automated data preprocessing pipeline with effective quality control.\nTo foster community engagement and future research, we will release our model\nweights, training code, annotated data, and preprocessing pipeline. The\ngenerated samples are showcased on our project page at\nhttps://liuzh-19.github.io/SongGen/ , and the code will be available at\nhttps://github.com/LiuZH-19/SongGen .", "published": "2025-02-18T18:52:21Z", "version": 1}, {"aid": "2502.13729", "authors": ["Takashi Morita"], "title": "Emergence of the Primacy Effect in Structured State-Space Models", "url": "http://arxiv.org/pdf/2502.13729v2", "summary": "Human and animal memory for sequentially presented items is well-documented\nto be more accurate for those at the beginning and end of the sequence,\nphenomena known as the primacy and recency effects, respectively. By contrast,\nartificial neural network (ANN) models are typically designed with a memory\nthat decays monotonically over time. Accordingly, ANNs are expected to show the\nrecency effect but not the primacy effect. Contrary to this theoretical\nexpectation, however, the present study reveals a counterintuitive finding: a\nrecently developed ANN architecture, called structured state-space models,\nexhibits the primacy effect when trained and evaluated on a synthetic task that\nmirrors psychological memory experiments. Given that this model was originally\ndesigned for recovering neuronal activity patterns observed in biological\nbrains, this result provides a novel perspective on the psychological primacy\neffect while also posing a non-trivial puzzle for the current theories in\nmachine learning.", "published": "2025-02-19T13:55:32Z", "version": 2}, {"aid": "2502.13810", "authors": ["Matthew Pugh", "Jo Grundy", "Corina Cirstea", "Nick Harris"], "title": "Learning Is a Kan Extension", "url": "http://arxiv.org/pdf/2502.13810v1", "summary": "Previous work has demonstrated that efficient algorithms exist for computing\nKan extensions and that some Kan extensions have interesting similarities to\nvarious machine learning algorithms. This paper closes the gap by proving that\nall error minimisation algorithms may be presented as a Kan extension. This\nresult provides a foundation for future work to investigate the optimisation of\nmachine learning algorithms through their presentation as Kan extensions. A\ncorollary of this representation of error-minimising algorithms is a\npresentation of error from the perspective of lossy and lossless\ntransformations of data.", "published": "2025-02-19T15:25:44Z", "version": 1}, {"aid": "2502.14941", "authors": ["Mika Bohinen", "Paolo Perrone"], "title": "Categorical algebra of conditional probability", "url": "http://arxiv.org/pdf/2502.14941v1", "summary": "In the field of categorical probability, one uses concepts and techniques\nfrom category theory, such as monads and monoidal categories, to study the\nstructures of probability and statistics. In this paper, we connect some ideas\nfrom categorical algebra, namely weakly cartesian functors and natural\ntransformations, to the idea of conditioning in probability theory, using\nMarkov categories and probability monads. First of all, we show that under some\nconditions, the monad associated to a Markov category with conditionals has a\nweakly cartesian functor and weakly cartesian multiplication (a condition known\nas Beck-Chevalley, or BC). In particular, we show that this is the case for the\nGiry monad on standard Borel spaces. We then connect this theory to existing\nresults on statistical experiments. We show that for deterministic statistical\nexperiments, the so-called standard measure construction (which can be seen as\na generalization of the \"hyper-normalizations\" introduced by Jacobs) satisfies\na universal property, allowing an equivalent definition which does not rely on\nthe existence of conditionals.", "published": "2025-02-20T17:33:55Z", "version": 1}, {"aid": "2502.14831", "authors": ["Ivan Skorokhodov", "Sharath Girish", "Benran Hu", "Willi Menapace", "Yanyu Li", "Rameen Abdal", "Sergey Tulyakov", "Aliaksandr Siarohin"], "title": "Improving the Diffusability of Autoencoders", "url": "http://arxiv.org/pdf/2502.14831v2", "summary": "Latent diffusion models have emerged as the leading approach for generating\nhigh-quality images and videos, utilizing compressed latent representations to\nreduce the computational burden of the diffusion process. While recent\nadvancements have primarily focused on scaling diffusion backbones and\nimproving autoencoder reconstruction quality, the interaction between these\ncomponents has received comparatively less attention. In this work, we perform\na spectral analysis of modern autoencoders and identify inordinate\nhigh-frequency components in their latent spaces, which are especially\npronounced in the autoencoders with a large bottleneck channel size. We\nhypothesize that this high-frequency component interferes with the\ncoarse-to-fine nature of the diffusion synthesis process and hinders the\ngeneration quality. To mitigate the issue, we propose scale equivariance: a\nsimple regularization strategy that aligns latent and RGB spaces across\nfrequencies by enforcing scale equivariance in the decoder. It requires minimal\ncode changes and only up to 20K autoencoder fine-tuning steps, yet\nsignificantly improves generation quality, reducing FID by 19% for image\ngeneration on ImageNet-1K 256x256 and FVD by at least 44% for video generation\non Kinetics-700 17x256x256.", "published": "2025-02-20T18:45:44Z", "version": 2}, {"aid": "2502.14993", "authors": ["Aaron David Fairbanks", "Peter Selinger"], "title": "On Traces in Categories of Contractions (Extended Abstract)", "url": "http://arxiv.org/pdf/2502.14993v1", "summary": "Traced monoidal categories are used to model processes that can feed their\noutputs back to their own inputs, abstracting iteration. The category of finite\ndimensional Hilbert spaces with the direct sum tensor is not traced. But\nsurprisingly, in 2014, Bartha showed that the monoidal subcategory of\nisometries is traced. The same holds for coisometries, unitary maps, and\ncontractions. This suggests the possibility of feeding outputs of quantum\nprocesses back to their own inputs, analogous to iteration. In this paper, we\nshow that Bartha's result is not specifically tied to Hilbert spaces, but works\nin any dagger additive category with Moore-Penrose pseudoinverses (a natural\ndagger-categorical generalization of inverses).", "published": "2025-02-20T19:34:03Z", "version": 1}, {"aid": "2502.15276", "authors": ["Aaron D. Ames", "Joe Moeller", "Paulo Tabuada"], "title": "Categorical Lyapunov Theory I: Stability of Flows", "url": "http://arxiv.org/pdf/2502.15276v1", "summary": "Lyapunov's theorem provides a fundamental characterization of the stability\nof dynamical systems. This paper presents a categorical framework for Lyapunov\ntheory, generalizing stability analysis with Lyapunov functions categorically.\nCore to our approach is the set of axioms underlying a setting for stability,\nwhich give the necessary ingredients for ``doing Lyapunov theory'' in a\ncategory of interest. With these minimal assumptions, we define the stability\nof equilibria, formulate Lyapunov morphisms, and demonstrate that the existence\nof Lyapunov morphisms is necessary and sufficient for establishing the\nstability of flows. To illustrate these constructions, we show how classical\nnotions of stability, e.g., for continuous and discrete time dynamical systems,\nare captured by this categorical framework for Lyapunov theory. Finally, to\ndemonstrate the extensibility of our framework, we illustrate how enriched\ncategories, e.g., Lawvere metric spaces, yield settings for stability enabling\none to ``do Lyapunov theory'' in enriched categories.", "published": "2025-02-21T08:04:57Z", "version": 1}, {"aid": "2502.15503", "authors": ["Haidong Wang", "Pengfei Xiao", "Ao Liu", "Jianhua Zhang", "Qia Shan"], "title": "BAN: Neuroanatomical Aligning in Auditory Recognition between Artificial Neural Network and Human Cortex", "url": "http://arxiv.org/pdf/2502.15503v1", "summary": "Drawing inspiration from neurosciences, artificial neural networks (ANNs)\nhave evolved from shallow architectures to highly complex, deep structures,\nyielding exceptional performance in auditory recognition tasks. However,\ntraditional ANNs often struggle to align with brain regions due to their\nexcessive depth and lack of biologically realistic features, like recurrent\nconnection. To address this, a brain-like auditory network (BAN) is introduced,\nwhich incorporates four neuroanatomically mapped areas and recurrent\nconnection, guided by a novel metric called the brain-like auditory score\n(BAS). BAS serves as a benchmark for evaluating the similarity between BAN and\nhuman auditory recognition pathway. We further propose that specific areas in\nthe cerebral cortex, mainly the middle and medial superior temporal (T2/T3)\nareas, correspond to the designed network structure, drawing parallels with the\nbrain's auditory perception pathway. Our findings suggest that the\nneuroanatomical similarity in the cortex and auditory classification abilities\nof the ANN are well-aligned. In addition to delivering excellent performance on\na music genre classification task, the BAN demonstrates a high BAS score. In\nconclusion, this study presents BAN as a recurrent, brain-inspired ANN,\nrepresenting the first model that mirrors the cortical pathway of auditory\nrecognition.", "published": "2025-02-21T14:57:01Z", "version": 1}, {"aid": "2502.15681", "authors": ["Yilun Xu", "Weili Nie", "Arash Vahdat"], "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching", "url": "http://arxiv.org/pdf/2502.15681v2", "summary": "Sampling from diffusion models involves a slow iterative process that hinders\ntheir practical deployment, especially for interactive applications. To\naccelerate generation speed, recent approaches distill a multi-step diffusion\nmodel into a single-step student generator via variational score distillation,\nwhich matches the distribution of samples generated by the student to the\nteacher's distribution. However, these approaches use the reverse\nKullback-Leibler (KL) divergence for distribution matching which is known to be\nmode seeking. In this paper, we generalize the distribution matching approach\nusing a novel $f$-divergence minimization framework, termed $f$-distill, that\ncovers different divergences with different trade-offs in terms of mode\ncoverage and training variance. We derive the gradient of the $f$-divergence\nbetween the teacher and student distributions and show that it is expressed as\nthe product of their score differences and a weighting function determined by\ntheir density ratio. This weighting function naturally emphasizes samples with\nhigher density in the teacher distribution, when using a less mode-seeking\ndivergence. We observe that the popular variational score distillation approach\nusing the reverse-KL divergence is a special case within our framework.\nEmpirically, we demonstrate that alternative $f$-divergences, such as\nforward-KL and Jensen-Shannon divergences, outperform the current best\nvariational score distillation methods across image generation tasks. In\nparticular, when using Jensen-Shannon divergence, $f$-distill achieves current\nstate-of-the-art one-step generation performance on ImageNet64 and zero-shot\ntext-to-image generation on MS-COCO. Project page:\nhttps://research.nvidia.com/labs/genair/f-distill", "published": "2025-02-21T18:59:20Z", "version": 2}, {"aid": "2502.18516", "authors": ["Runze Jiang", "Pengjian Shang"], "title": "Gradient entropy (GradEn): The two dimensional version of slope entropy for image analysis", "url": "http://arxiv.org/pdf/2502.18516v1", "summary": "Information theory and Shannon entropy are essential for quantifying\nirregularity in complex systems or signals. Recently, two-dimensional entropy\nmethods, such as two-dimensional sample entropy, distribution entropy, and\npermutation entropy, have been proposed for analyzing 2D texture or image data.\nThis paper introduces Gradient entropy (GradEn), an extension of slope entropy\nto 2D, which considers both symbolic patterns and amplitude information,\nenabling better feature extraction from image data. We evaluate GradEn with\nsimulated data, including 2D colored noise, 2D mixed processes, and the\nlogistic map. Results show the ability of GradEn to distinguish images with\nvarious characteristics while maintaining low computational cost. Real-world\ndatasets, consist of texture, fault gear, and railway corrugation signals,\ndemonstrate the superior performance of GradEn in classification tasks compared\nto other 2D entropy methods. In conclusion, GradEn is an effective tool for\nimage characterization, offering a novel approach for image processing and\nrecognition.", "published": "2025-02-23T02:05:01Z", "version": 1}, {"aid": "2502.16861", "authors": ["Weiyu Guo", "Guoying Sun", "JianXiang He", "Tong Shao", "Shaoguang Wang", "Ziyang Chen", "Meisheng Hong", "Ying Sun", "Hui Xiong"], "title": "A Survey of fMRI to Image Reconstruction", "url": "http://arxiv.org/pdf/2502.16861v1", "summary": "Functional magnetic resonance imaging (fMRI) based image reconstruction plays\na pivotal role in decoding human perception, with applications in neuroscience\nand brain-computer interfaces. While recent advancements in deep learning and\nlarge-scale datasets have driven progress, challenges such as data scarcity,\ncross-subject variability, and low semantic consistency persist. To address\nthese issues, we introduce the concept of fMRI-to-Image Learning (fMRI2Image)\nand present the first systematic review in this field. This review highlights\nkey challenges, categorizes methodologies such as fMRI signal encoding, feature\nmapping, and image generator. Finally, promising research directions are\nproposed to advance this emerging frontier, providing a reference for future\nstudies.", "published": "2025-02-24T05:53:04Z", "version": 1}, {"aid": "2502.17327", "authors": ["Inbar Gat", "Sigal Raab", "Guy Tevet", "Yuval Reshef", "Amit H. Bermano", "Daniel Cohen-Or"], "title": "AnyTop: Character Animation Diffusion with Any Topology", "url": "http://arxiv.org/pdf/2502.17327v1", "summary": "Generating motion for arbitrary skeletons is a longstanding challenge in\ncomputer graphics, remaining largely unexplored due to the scarcity of diverse\ndatasets and the irregular nature of the data. In this work, we introduce\nAnyTop, a diffusion model that generates motions for diverse characters with\ndistinct motion dynamics, using only their skeletal structure as input. Our\nwork features a transformer-based denoising network, tailored for arbitrary\nskeleton learning, integrating topology information into the traditional\nattention mechanism. Additionally, by incorporating textual joint descriptions\ninto the latent feature representation, AnyTop learns semantic correspondences\nbetween joints across diverse skeletons. Our evaluation demonstrates that\nAnyTop generalizes well, even with as few as three training examples per\ntopology, and can produce motions for unseen skeletons as well. Furthermore,\nour model's latent space is highly informative, enabling downstream tasks such\nas joint correspondence, temporal segmentation and motion editing. Our webpage,\nhttps://anytop2025.github.io/Anytop-page, includes links to videos and code.", "published": "2025-02-24T17:00:36Z", "version": 1}, {"aid": "2502.18553", "authors": ["Zohar Ringel", "Noa Rubin", "Edo Mor", "Moritz Helias", "Inbar Seroussi"], "title": "Applications of Statistical Field Theory in Deep Learning", "url": "http://arxiv.org/pdf/2502.18553v2", "summary": "Deep learning algorithms have made incredible strides in the past decade yet\ndue to the complexity of these algorithms, the science of deep learning remains\nin its early stages. Being an experimentally driven field, it is natural to\nseek a theory of deep learning within the physics paradigm. As deep learning is\nlargely about learning functions and distributions over functions, statistical\nfield theory, a rich and versatile toolbox for tackling complex distributions\nover functions (fields) is an obvious choice of formalism. Research efforts\ncarried out in the past few years have demonstrated the ability of field theory\nto provide useful insights on generalization, implicit bias, and feature\nlearning effects. Here we provide a pedagogical review of this emerging line of\nresearch.", "published": "2025-02-25T18:19:06Z", "version": 2}, {"aid": "2502.20272", "authors": ["Qingsen Yan", "Yixu Feng", "Cheng Zhang", "Guansong Pang", "Kangbiao Shi", "Peng Wu", "Wei Dong", "Jinqiu Sun", "Yanning Zhang"], "title": "HVI: A New Color Space for Low-light Image Enhancement", "url": "http://arxiv.org/pdf/2502.20272v2", "summary": "Low-Light Image Enhancement (LLIE) is a crucial computer vision task that\naims to restore detailed visual information from corrupted low-light images.\nMany existing LLIE methods are based on standard RGB (sRGB) space, which often\nproduce color bias and brightness artifacts due to inherent high color\nsensitivity in sRGB. While converting the images using Hue, Saturation and\nValue (HSV) color space helps resolve the brightness issue, it introduces\nsignificant red and black noise artifacts. To address this issue, we propose a\nnew color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined\nby polarized HS maps and learnable intensity. The former enforces small\ndistances for red coordinates to remove the red artifacts, while the latter\ncompresses the low-light regions to remove the black artifacts. To fully\nleverage the chromatic and intensity information, a novel Color and Intensity\nDecoupling Network (CIDNet) is further introduced to learn accurate photometric\nmapping function under different lighting conditions in the HVI space.\nComprehensive results from benchmark and ablation experiments show that the\nproposed HVI color space with CIDNet outperforms the state-of-the-art methods\non 10 datasets. The code is available at https://github.com/Fediory/HVI-CIDNet.", "published": "2025-02-27T16:59:51Z", "version": 2}, {"aid": "2503.00240", "authors": ["Marius F. R. Juston", "William R. Norris", "Dustin Nottage", "Ahmet Soylemezoglu"], "title": "1-Lipschitz Network Initialization for Certifiably Robust Classification Applications: A Decay Problem", "url": "http://arxiv.org/pdf/2503.00240v1", "summary": "This paper discusses the weight parametrization of two standard 1-Lipschitz\nnetwork structure methodologies, the Almost-Orthogonal-Layers (AOL) and the\nSDP-based Lipschitz Layers (SLL), and derives their impact on the\ninitialization for deep 1-Lipschitz feedforward networks in addition to\ndiscussing underlying issues surrounding this initialization. These networks\nare mainly used in certifiably robust classification applications to combat\nadversarial attacks by limiting the effects of perturbations on the output\nclassification result. An exact and an upper bound for the parameterized weight\nvariance was calculated assuming a standard Normal distribution initialization;\nadditionally, an upper bound was computed assuming a Generalized Normal\nDistribution, generalizing the proof for Uniform, Laplace, and Normal\ndistribution weight initializations. It is demonstrated that the weight\nvariance holds no bearing on the output variance distribution and that only the\ndimension of the weight matrices matters. Additionally, this paper demonstrates\nthat the weight initialization always causes deep 1-Lipschitz networks to decay\nto zero.", "published": "2025-02-28T23:02:04Z", "version": 1}, {"aid": "2503.00301", "authors": ["Zihan Huang", "Wei Fang", "Tong Bu", "Peng Xue", "Zecheng Hao", "Wenxuan Liu", "Yuanhong Tang", "Zhaofei Yu", "Tiejun Huang"], "title": "Differential Coding for Training-Free ANN-to-SNN Conversion", "url": "http://arxiv.org/pdf/2503.00301v1", "summary": "Spiking Neural Networks (SNNs) exhibit significant potential due to their low\nenergy consumption. Converting Artificial Neural Networks (ANNs) to SNNs is an\nefficient way to achieve high-performance SNNs. However, many conversion\nmethods are based on rate coding, which requires numerous spikes and longer\ntime-steps compared to directly trained SNNs, leading to increased energy\nconsumption and latency. This article introduces differential coding for\nANN-to-SNN conversion, a novel coding scheme that reduces spike counts and\nenergy consumption by transmitting changes in rate information rather than\nrates directly, and explores its application across various layers.\nAdditionally, the threshold iteration method is proposed to optimize thresholds\nbased on activation distribution when converting Rectified Linear Units (ReLUs)\nto spiking neurons. Experimental results on various Convolutional Neural\nNetworks (CNNs) and Transformers demonstrate that the proposed differential\ncoding significantly improves accuracy while reducing energy consumption,\nparticularly when combined with the threshold iteration method, achieving\nstate-of-the-art performance.", "published": "2025-03-01T02:17:35Z", "version": 1}, {"aid": "2503.00511", "authors": ["Manuel Baltieri", "Martin Biehl", "Matteo Capucci", "Nathaniel Virgo"], "title": "A Bayesian Interpretation of the Internal Model Principle", "url": "http://arxiv.org/pdf/2503.00511v1", "summary": "The internal model principle, originally proposed in the theory of control of\nlinear systems, nowadays represents a more general class of results in control\ntheory and cybernetics. The central claim of these results is that, under\nsuitable assumptions, if a system (a controller) can regulate against a class\nof external inputs (from the environment), it is because the system contains a\nmodel of the system causing these inputs, which can be used to generate signals\ncounteracting them. Similar claims on the role of internal models appear also\nin cognitive science, especially in modern Bayesian treatments of cognitive\nagents, often suggesting that a system (a human subject, or some other agent)\nmodels its environment to adapt against disturbances and perform goal-directed\nbehaviour. It is however unclear whether the Bayesian internal models discussed\nin cognitive science bear any formal relation to the internal models invoked in\nstandard treatments of control theory. Here, we first review the internal model\nprinciple and present a precise formulation of it using concepts inspired by\ncategorical systems theory. This leads to a formal definition of `model'\ngeneralising its use in the internal model principle. Although this notion of\nmodel is not a priori related to the notion of Bayesian reasoning, we show that\nit can be seen as a special case of possibilistic Bayesian filtering. This\nresult is based on a recent line of work formalising, using Markov categories,\na notion of `interpretation', describing when a system can be interpreted as\nperforming Bayesian filtering on an outside world in a consistent way.", "published": "2025-03-01T14:29:39Z", "version": 1}, {"aid": "2503.01115", "authors": ["Zhipeng Huang", "Shaobin Zhuang", "Canmiao Fu", "Binxin Yang", "Ying Zhang", "Chong Sun", "Zhizheng Zhang", "Yali Wang", "Chen Li", "Zheng-Jun Zha"], "title": "WeGen: A Unified Model for Interactive Multimodal Generation as We Chat", "url": "http://arxiv.org/pdf/2503.01115v2", "summary": "Existing multimodal generative models fall short as qualified design\ncopilots, as they often struggle to generate imaginative outputs once\ninstructions are less detailed or lack the ability to maintain consistency with\nthe provided references. In this work, we introduce WeGen, a model that unifies\nmultimodal generation and understanding, and promotes their interplay in\niterative generation. It can generate diverse results with high creativity for\nless detailed instructions. And it can progressively refine prior generation\nresults or integrating specific contents from references following the\ninstructions in its chat with users. During this process, it is capable of\npreserving consistency in the parts that the user is already satisfied with. To\nthis end, we curate a large-scale dataset, extracted from Internet videos,\ncontaining rich object dynamics and auto-labeled dynamics descriptions by\nadvanced foundation models to date. These two information are interleaved into\na single sequence to enable WeGen to learn consistency-aware generation where\nthe specified dynamics are generated while the consistency of unspecified\ncontent is preserved aligned with instructions. Besides, we introduce a prompt\nself-rewriting mechanism to enhance generation diversity. Extensive experiments\ndemonstrate the effectiveness of unifying multimodal understanding and\ngeneration in WeGen and show it achieves state-of-the-art performance across\nvarious visual generation benchmarks. These also demonstrate the potential of\nWeGen as a user-friendly design copilot as desired. The code and models will be\navailable at https://github.com/hzphzp/WeGen.", "published": "2025-03-03T02:50:07Z", "version": 2}, {"aid": "2503.01565", "authors": ["Yuheng Xu", "Shijie Yang", "Xin Liu", "Jie Liu", "Jie Tang", "Gangshan Wu"], "title": "AutoLUT: LUT-Based Image Super-Resolution with Automatic Sampling and Adaptive Residual Learning", "url": "http://arxiv.org/pdf/2503.01565v2", "summary": "In recent years, the increasing popularity of Hi-DPI screens has driven a\nrising demand for high-resolution images. However, the limited computational\npower of edge devices poses a challenge in deploying complex super-resolution\nneural networks, highlighting the need for efficient methods. While prior works\nhave made significant progress, they have not fully exploited pixel-level\ninformation. Moreover, their reliance on fixed sampling patterns limits both\naccuracy and the ability to capture fine details in low-resolution images. To\naddress these challenges, we introduce two plug-and-play modules designed to\ncapture and leverage pixel information effectively in Look-Up Table (LUT) based\nsuper-resolution networks. Our method introduces Automatic Sampling\n(AutoSample), a flexible LUT sampling approach where sampling weights are\nautomatically learned during training to adapt to pixel variations and expand\nthe receptive field without added inference cost. We also incorporate Adaptive\nResidual Learning (AdaRL) to enhance inter-layer connections, enabling detailed\ninformation flow and improving the network's ability to reconstruct fine\ndetails. Our method achieves significant performance improvements on both MuLUT\nand SPF-LUT while maintaining similar storage sizes. Specifically, for MuLUT,\nwe achieve a PSNR improvement of approximately +0.20 dB improvement on average\nacross five datasets. For SPF-LUT, with more than a 50% reduction in storage\nspace and about a 2/3 reduction in inference time, our method still maintains\nperformance comparable to the original. The code is available at\nhttps://github.com/SuperKenVery/AutoLUT.", "published": "2025-03-03T14:09:36Z", "version": 2}, {"aid": "2503.01776", "authors": ["Tiansheng Wen", "Yifei Wang", "Zequn Zeng", "Zhong Peng", "Yudi Su", "Xinyang Liu", "Bo Chen", "Hongwei Liu", "Stefanie Jegelka", "Chenyu You"], "title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation", "url": "http://arxiv.org/pdf/2503.01776v2", "summary": "Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep", "published": "2025-03-03T17:59:48Z", "version": 2}, {"aid": "2503.02477", "authors": ["Dario Stein"], "title": "Random Variables, Conditional Independence and Categories of Abstract Sample Spaces", "url": "http://arxiv.org/pdf/2503.02477v1", "summary": "Two high-level \"pictures\" of probability theory have emerged: one that takes\nas central the notion of random variable, and one that focuses on distributions\nand probability channels (Markov kernels). While the channel-based picture has\nbeen successfully axiomatized, and widely generalized, using the notion of\nMarkov category, the categorical semantics of the random variable picture\nremain less clear. Simpson's probability sheaves are a recent approach, in\nwhich probabilistic concepts like random variables are allowed vary over a site\nof sample spaces. Simpson has identified rich structure on these sites, most\nnotably an abstract notion of conditional independence, and given examples\nranging from probability over databases to nominal sets. We aim bring this\ndevelopment together with the generality and abstraction of Markov categories:\nWe show that for any suitable Markov category, a category of sample spaces can\nbe defined which satisfies Simpson's axioms, and that a theory of probability\nsheaves can be developed purely synthetically in this setting. We recover\nSimpson's examples in a uniform fashion from well-known Markov categories, and\nconsider further generalizations.", "published": "2025-03-04T10:42:00Z", "version": 1}, {"aid": "2503.07641", "authors": ["Niklas M. Melton", "Leonardo Enzo Brito da Silva", "Sasha Petrenko", "Donald. C. Wunsch II"], "title": "Deep ARTMAP: Generalized Hierarchical Learning with Adaptive Resonance Theory", "url": "http://arxiv.org/pdf/2503.07641v1", "summary": "This paper presents Deep ARTMAP, a novel extension of the ARTMAP architecture\nthat generalizes the self-consistent modular ART (SMART) architecture to enable\nhierarchical learning (supervised and unsupervised) across arbitrary\ntransformations of data. The Deep ARTMAP framework operates as a divisive\nclustering mechanism, supporting an arbitrary number of modules with\ncustomizable granularity within each module. Inter-ART modules regulate the\nclustering at each layer, permitting unsupervised learning while enforcing a\none-to-many mapping from clusters in one layer to the next. While Deep ARTMAP\nreduces to both ARTMAP and SMART in particular configurations, it offers\nsignificantly enhanced flexibility, accommodating a broader range of data\ntransformations and learning modalities.", "published": "2025-03-05T22:23:17Z", "version": 1}, {"aid": "2503.06242", "authors": ["\u0141ukasz Struski", "Micha\u0142 B. Bednarczyk", "Igor T. Podolak", "Jacek Tabor"], "title": "LapSum -- One Method to Differentiate Them All: Ranking, Sorting and Top-k Selection", "url": "http://arxiv.org/pdf/2503.06242v1", "summary": "We present a novel technique for constructing differentiable order-type\noperations, including soft ranking, soft top-k selection, and soft\npermutations. Our approach leverages an efficient closed-form formula for the\ninverse of the function LapSum, defined as the sum of Laplace distributions.\nThis formulation ensures low computational and memory complexity in selecting\nthe highest activations, enabling losses and gradients to be computed in\n$O(n\\log{}n)$ time. Through extensive experiments, we demonstrate that our\nmethod outperforms state-of-the-art techniques for high-dimensional vectors and\nlarge $k$ values. Furthermore, we provide efficient implementations for both\nCPU and CUDA environments, underscoring the practicality and scalability of our\nmethod for large-scale ranking and differentiable ordering problems.", "published": "2025-03-08T14:53:36Z", "version": 1}, {"aid": "2503.07565", "authors": ["Linqi Zhou", "Stefano Ermon", "Jiaming Song"], "title": "Inductive Moment Matching", "url": "http://arxiv.org/pdf/2503.07565v3", "summary": "Diffusion models and Flow Matching generate high-quality samples but are slow\nat inference, and distilling them into few-step models often leads to\ninstability and extensive tuning. To resolve these trade-offs, we propose\nInductive Moment Matching (IMM), a new class of generative models for one- or\nfew-step sampling with a single-stage training procedure. Unlike distillation,\nIMM does not require pre-training initialization and optimization of two\nnetworks; and unlike Consistency Models, IMM guarantees distribution-level\nconvergence and remains stable under various hyperparameters and standard model\narchitectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID\nusing only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98\non CIFAR-10 for a model trained from scratch.", "published": "2025-03-10T17:37:39Z", "version": 3}, {"aid": "2503.09817", "authors": ["Jesse Farebrother", "Matteo Pirotta", "Andrea Tirinzoni", "R\u00e9mi Munos", "Alessandro Lazaric", "Ahmed Touati"], "title": "Temporal Difference Flows", "url": "http://arxiv.org/pdf/2503.09817v1", "summary": "Predictive models of the future are fundamental for an agent's ability to\nreason and plan. A common strategy learns a world model and unrolls it\nstep-by-step at inference, where small errors can rapidly compound. Geometric\nHorizon Models (GHMs) offer a compelling alternative by directly making\npredictions of future states, avoiding cumulative inference errors. While GHMs\ncan be conveniently learned by a generative analog to temporal difference (TD)\nlearning, existing methods are negatively affected by bootstrapping predictions\nat train time and struggle to generate high-quality predictions at long\nhorizons. This paper introduces Temporal Difference Flows (TD-Flow), which\nleverages the structure of a novel Bellman equation on probability paths\nalongside flow-matching techniques to learn accurate GHMs at over 5x the\nhorizon length of prior methods. Theoretically, we establish a new convergence\nresult and primarily attribute TD-Flow's efficacy to reduced gradient variance\nduring training. We further show that similar arguments can be extended to\ndiffusion-based methods. Empirically, we validate TD-Flow across a diverse set\nof domains on both generative metrics and downstream tasks including policy\nevaluation. Moreover, integrating TD-Flow with recent behavior foundation\nmodels for planning over pre-trained policies demonstrates substantial\nperformance gains, underscoring its promise for long-horizon decision-making.", "published": "2025-03-12T20:30:07Z", "version": 1}, {"aid": "2503.10144", "authors": ["Han Kim", "Hyungjoon Soh", "Vipul Periwal", "Junghyo Jo"], "title": "Multiplicative Learning", "url": "http://arxiv.org/pdf/2503.10144v1", "summary": "Efficient training of artificial neural networks remains a key challenge in\ndeep learning. Backpropagation (BP), the standard learning algorithm, relies on\ngradient descent and typically requires numerous iterations for convergence. In\nthis study, we introduce Expectation Reflection (ER), a novel learning approach\nthat updates weights multiplicatively based on the ratio of observed to\npredicted outputs. Unlike traditional methods, ER maintains consistency without\nrequiring ad hoc loss functions or learning rate hyperparameters. We extend ER\nto multilayer networks and demonstrate its effectiveness in performing image\nclassification tasks. Notably, ER achieves optimal weight updates in a single\niteration. Additionally, we reinterpret ER as a modified form of gradient\ndescent incorporating the inverse mapping of target propagation. These findings\nsuggest that ER provides an efficient and scalable alternative for training\nneural networks.", "published": "2025-03-13T08:14:00Z", "version": 1}, {"aid": "2503.11718", "authors": ["Gabriele D'Acunto", "Claudio Battiloro"], "title": "The Relativity of Causal Knowledge", "url": "http://arxiv.org/pdf/2503.11718v1", "summary": "Recent advances in artificial intelligence reveal the limits of purely\npredictive systems and call for a shift toward causal and collaborative\nreasoning. Drawing inspiration from the revolution of Grothendieck in\nmathematics, we introduce the relativity of causal knowledge, which posits\nstructural causal models (SCMs) are inherently imperfect, subjective\nrepresentations embedded within networks of relationships. By leveraging\ncategory theory, we arrange SCMs into a functor category and show that their\nobservational and interventional probability measures naturally form convex\nstructures. This result allows us to encode non-intervened SCMs with convex\nspaces of probability measures. Next, using sheaf theory, we construct the\nnetwork sheaf and cosheaf of causal knowledge. These structures enable the\ntransfer of causal knowledge across the network while incorporating\ninterventional consistency and the perspective of the subjects, ultimately\nleading to the formal, mathematical definition of relative causal knowledge.", "published": "2025-03-13T16:24:48Z", "version": 1}, {"aid": "2503.10518", "authors": ["Andrew Knight"], "title": "Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness", "url": "http://arxiv.org/pdf/2503.10518v1", "summary": "This paper presents a novel information-theoretic proof demonstrating that\nthe human brain as currently understood cannot function as a classical digital\ncomputer. Through systematic quantification of distinguishable conscious states\nand their historical dependencies, we establish that the minimum information\nrequired to specify a conscious state exceeds the physical information capacity\nof the human brain by a significant factor. Our analysis calculates the\nbit-length requirements for representing consciously distinguishable sensory\n\"stimulus frames\" and demonstrates that consciousness exhibits mandatory\ntemporal-historical dependencies that multiply these requirements beyond the\nbrain's storage capabilities. This mathematical approach offers new insights\ninto the fundamental limitations of computational models of consciousness and\nsuggests that non-classical information processing mechanisms may be necessary\nto account for conscious experience.", "published": "2025-03-13T16:27:42Z", "version": 1}, {"aid": "2503.10522", "authors": ["Zeyue Tian", "Yizhu Jin", "Zhaoyang Liu", "Ruibin Yuan", "Xu Tan", "Qifeng Chen", "Wei Xue", "Yike Guo"], "title": "AudioX: Diffusion Transformer for Anything-to-Audio Generation", "url": "http://arxiv.org/pdf/2503.10522v1", "summary": "Audio and music generation have emerged as crucial tasks in many\napplications, yet existing approaches face significant limitations: they\noperate in isolation without unified capabilities across modalities, suffer\nfrom scarce high-quality, multi-modal training data, and struggle to\neffectively integrate diverse inputs. In this work, we propose AudioX, a\nunified Diffusion Transformer model for Anything-to-Audio and Music Generation.\nUnlike previous domain-specific models, AudioX can generate both general audio\nand music with high quality, while offering flexible natural language control\nand seamless processing of various modalities including text, video, image,\nmusic, and audio. Its key innovation is a multi-modal masked training strategy\nthat masks inputs across modalities and forces the model to learn from masked\ninputs, yielding robust and unified cross-modal representations. To address\ndata scarcity, we curate two comprehensive datasets: vggsound-caps with 190K\naudio captions based on the VGGSound dataset, and V2M-caps with 6 million music\ncaptions derived from the V2M dataset. Extensive experiments demonstrate that\nAudioX not only matches or outperforms state-of-the-art specialized models, but\nalso offers remarkable versatility in handling diverse input modalities and\ngeneration tasks within a unified architecture. The code and datasets will be\navailable at https://zeyuet.github.io/AudioX/", "published": "2025-03-13T16:30:59Z", "version": 1}, {"aid": "2503.10868", "authors": ["Niyousha Najmaei", "Niels van der Weide", "Benedikt Ahrens", "Paige Randall North"], "title": "A Type Theory for Comprehension Categories with Applications to Subtyping", "url": "http://arxiv.org/pdf/2503.10868v1", "summary": "In this paper we develop a type theory that we show is an internal language\nfor comprehension categories. This type theory is closely related to\nMartin-L\\\"of type theory (MLTT). Indeed, semantics of MLTT are often given in\ncomprehension categories, albeit usually only in discrete or full ones. As we\nexplain, requiring a comprehension category to be full or discrete can be\nunderstood as removing one `dimension' of morphisms. Thus, in our syntax, we\nrecover this extra dimension. We show that this extra dimension can be used to\nencode subtyping in a natural way. Important instances of non-full\ncomprehension categories include ones used for constructive or univalent\nintensional models of MLTT and directed type theory, and so our syntax is a\nmore faithful internal language for these than is MLTT.", "published": "2025-03-13T20:34:37Z", "version": 1}, {"aid": "2503.10875", "authors": ["Hai-Vy Nguyen", "Fabrice Gamboa", "Sixin Zhang", "Reda Chhaibi", "Serge Gratton", "Thierry Giaccone"], "title": "Convolutional Rectangular Attention Module", "url": "http://arxiv.org/pdf/2503.10875v1", "summary": "In this paper, we introduce a novel spatial attention module, that can be\nintegrated to any convolutional network. This module guides the model to pay\nattention to the most discriminative part of an image. This enables the model\nto attain a better performance by an end-to-end training. In standard\napproaches, a spatial attention map is generated in a position-wise fashion. We\nobserve that this results in very irregular boundaries. This could make it\ndifficult to generalize to new samples. In our method, the attention region is\nconstrained to be rectangular. This rectangle is parametrized by only 5\nparameters, allowing for a better stability and generalization to new samples.\nIn our experiments, our method systematically outperforms the position-wise\ncounterpart. Thus, this provides us a novel useful spatial attention mechanism\nfor convolutional models. Besides, our module also provides the\ninterpretability concerning the ``where to look\" question, as it helps to know\nthe part of the input on which the model focuses to produce the prediction.", "published": "2025-03-13T20:41:36Z", "version": 1}, {"aid": "2503.10963", "authors": ["Tom de Jong", "Nicolai Kraus", "Simona Paoli", "Sti\u00e9phen Pradal"], "title": "A study of Kock's fat Delta", "url": "http://arxiv.org/pdf/2503.10963v1", "summary": "Motivated by the study of weak identity structures in higher category theory\nwe explore the fat Delta category, a modification of the simplex category\nintroduced by J. Kock. We provide a comprehensive study of fat Delta via the\ntheory of monads with arities, and use these results to show that fat Delta is\na hypermoment category in the sense of C. Berger. Specifically, by proving that\nthe free relative semicategory monad is strongly cartesian and identifying a\ndense generator, the theory of monads with arities immediately gives rise to\nthe nerve theorem. We characterise the essential image of the nerve via the\nSegal condition, and show that fat Delta possesses an active-inert\nfactorisation system. Building on these results, we also establish an\nisomorphism between two presentations of fat Delta and show that it is a\nstrongly unital and extensional hypermoment category.", "published": "2025-03-14T00:14:04Z", "version": 1}, {"aid": "2503.11224", "authors": ["Xingtai Lv", "Youbang Sun", "Kaiyan Zhang", "Shang Qu", "Xuekai Zhu", "Yuchen Fan", "Yi Wu", "Ermo Hua", "Xinwei Long", "Ning Ding", "Bowen Zhou"], "title": "Technologies on Effectiveness and Efficiency: A Survey of State Spaces Models", "url": "http://arxiv.org/pdf/2503.11224v1", "summary": "State Space Models (SSMs) have emerged as a promising alternative to the\npopular transformer-based models and have been increasingly gaining attention.\nCompared to transformers, SSMs excel at tasks with sequential data or longer\ncontexts, demonstrating comparable performances with significant efficiency\ngains. In this survey, we provide a coherent and systematic overview for SSMs,\nincluding their theoretical motivations, mathematical formulations, comparison\nwith existing model classes, and various applications. We divide the SSM series\ninto three main sections, providing a detailed introduction to the original\nSSM, the structured SSM represented by S4, and the selective SSM typified by\nMamba. We put an emphasis on technicality, and highlight the various key\ntechniques introduced to address the effectiveness and efficiency of SSMs. We\nhope this manuscript serves as an introduction for researchers to explore the\ntheoretical foundations of SSMs.", "published": "2025-03-14T09:20:31Z", "version": 1}, {"aid": "2503.13051", "authors": ["Kai Uwe Barthel", "Florian Barthel", "Peter Eisert"], "title": "Permutation Learning with Only N Parameters: From SoftSort to Self-Organizing Gaussians", "url": "http://arxiv.org/pdf/2503.13051v1", "summary": "Sorting and permutation learning are key concepts in optimization and machine\nlearning, especially when organizing high-dimensional data into meaningful\nspatial layouts. The Gumbel-Sinkhorn method, while effective, requires N*N\nparameters to determine a full permutation matrix, making it computationally\nexpensive for large datasets. Low-rank matrix factorization approximations\nreduce memory requirements to 2MN (with M << N), but they still struggle with\nvery large problems. SoftSort, by providing a continuous relaxation of the\nargsort operator, allows differentiable 1D sorting, but it faces challenges\nwith multidimensional data and complex permutations. In this paper, we present\na novel method for learning permutations using only N parameters, which\ndramatically reduces storage costs. Our approach builds on SoftSort, but\nextends it by iteratively shuffling the N indices of the elements to be sorted\nthrough a separable learning process. This modification significantly improves\nsorting quality, especially for multidimensional data and complex optimization\ncriteria, and outperforms pure SoftSort. Our method offers improved memory\nefficiency and scalability compared to existing approaches, while maintaining\nhigh-quality permutation learning. Its dramatically reduced memory requirements\nmake it particularly well-suited for large-scale optimization tasks, such as\n\"Self-Organizing Gaussians\", where efficient and scalable permutation learning\nis critical.", "published": "2025-03-17T10:55:55Z", "version": 1}, {"aid": "2503.14376", "authors": ["Maximilian Beck", "Korbinian P\u00f6ppel", "Phillip Lippe", "Sepp Hochreiter"], "title": "Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels", "url": "http://arxiv.org/pdf/2503.14376v1", "summary": "Linear RNNs with gating recently demonstrated competitive performance\ncompared to Transformers in language modeling. Although their linear compute\nscaling in sequence length offers theoretical runtime advantages over\nTransformers, realizing these benefits in practice requires optimized custom\nkernels, as Transformers rely on the highly efficient Flash Attention kernels.\nLeveraging the chunkwise-parallel formulation of linear RNNs, Flash Linear\nAttention (FLA) shows that linear RNN kernels are faster than Flash Attention,\nby parallelizing over chunks of the input sequence. However, since the chunk\nsize of FLA is limited, many intermediate states must be materialized in GPU\nmemory. This leads to low arithmetic intensity and causes high memory\nconsumption and IO cost, especially for long-context pre-training. In this\nwork, we present Tiled Flash Linear Attention (TFLA), a novel kernel algorithm\nfor linear RNNs, that enables arbitrary large chunk sizes by introducing an\nadditional level of sequence parallelization within each chunk. First, we apply\nTFLA to the xLSTM with matrix memory, the mLSTM. Second, we propose an mLSTM\nvariant with sigmoid input gate and reduced computation for even faster kernel\nruntimes at equal language modeling performance. In our speed benchmarks, we\nshow that our new mLSTM kernels based on TFLA outperform highly optimized Flash\nAttention, Linear Attention and Mamba kernels, setting a new state of the art\nfor efficient long-context sequence modeling primitives.", "published": "2025-03-18T16:09:47Z", "version": 1}, {"aid": "1907.11891", "authors": ["Mingtian Zhang", "Thomas Bird", "Raza Habib", "Tianlin Xu", "David Barber"], "title": "Variational f-divergence Minimization", "url": "http://arxiv.org/pdf/1907.11891v2", "summary": "Probabilistic models are often trained by maximum likelihood, which\ncorresponds to minimizing a specific f-divergence between the model and data\ndistribution. In light of recent successes in training Generative Adversarial\nNetworks, alternative non-likelihood training criteria have been proposed.\nWhilst not necessarily statistically efficient, these alternatives may better\nmatch user requirements such as sharp image generation. A general variational\nmethod for training probabilistic latent variable models using maximum\nlikelihood is well established; however, how to train latent variable models\nusing other f-divergences is comparatively unknown. We discuss a variational\napproach that, when combined with the recently introduced Spread Divergence,\ncan be applied to train a large class of latent variable models using any\nf-divergence.", "published": "2019-07-27T10:32:08Z", "version": 2}, {"aid": "2005.10963", "authors": ["Yongxin Chen", "Tryphon T. Georgiou", "Michele Pavon"], "title": "Stochastic control liaisons: Richard Sinkhorn meets Gaspard Monge on a Schroedinger bridge", "url": "http://arxiv.org/pdf/2005.10963v3", "summary": "In 1931/32, Schroedinger studied a hot gas Gedankenexperiment, an instance of\nlarge deviations of the empirical distribution and an early example of the\nso-called maximum entropy inference method. This so-called Schroedinger bridge\nproblem (SBP) was recently recognized as a regularization of the\nMonge-Kantorovich Optimal Mass Transport (OMT), leading to effective\ncomputation of the latter. Specifically, OMT with quadratic cost may be viewed\nas a zero-temperature limit of SBP, which amounts to minimization of the\nHelmholtz's free energy over probability distributions constrained to possess\ngiven marginals. The problem features a delicate compromise, mediated by a\ntemperature parameter, between minimizing the internal energy and maximizing\nthe entropy. These concepts are central to a rapidly expanding area of modern\nscience dealing with the so-called {\\em Sinkhorn algorithm} which appears as a\nspecial case of an algorithm first studied by the French analyst Robert Fortet\nin 1938/40 specifically for Schroedinger bridges. Due to the constraint on\nend-point distributions, dynamic programming is not a suitable tool to attack\nthese problems. Instead, Fortet's iterative algorithm and its discrete\ncounterpart, the Sinkhorn iteration, permit computation by iteratively solving\nthe so-called {\\em Schroedinger system}. In both the continuous as well as the\ndiscrete-time and space settings, {\\em stochastic control} provides a\nreformulation and dynamic versions of these problems. The formalism behind\nthese control problems have attracted attention as they lead to a variety of\nnew applications in spacecraft guidance, control of robot or biological swarms,\nsensing, active cooling, network routing as well as in computer and data\nscience. This multifacet and versatile framework, intertwining SBP and OMT,\nprovides the substrate for a historical and technical overview of the field\ntaken up in this paper.", "published": "2020-05-22T01:34:56Z", "version": 3}, {"aid": "2303.16852", "authors": ["Yuyang Shi", "Valentin De Bortoli", "Andrew Campbell", "Arnaud Doucet"], "title": "Diffusion Schr\u00f6dinger Bridge Matching", "url": "http://arxiv.org/pdf/2303.16852v3", "summary": "Solving transport problems, i.e. finding a map transporting one given\ndistribution to another, has numerous applications in machine learning. Novel\nmass transport methods motivated by generative modeling have recently been\nproposed, e.g. Denoising Diffusion Models (DDMs) and Flow Matching Models\n(FMMs) implement such a transport through a Stochastic Differential Equation\n(SDE) or an Ordinary Differential Equation (ODE). However, while it is\ndesirable in many applications to approximate the deterministic dynamic Optimal\nTransport (OT) map which admits attractive properties, DDMs and FMMs are not\nguaranteed to provide transports close to the OT map. In contrast,\nSchr\\\"odinger bridges (SBs) compute stochastic dynamic mappings which recover\nentropy-regularized versions of OT. Unfortunately, existing numerical methods\napproximating SBs either scale poorly with dimension or accumulate errors\nacross iterations. In this work, we introduce Iterative Markovian Fitting\n(IMF), a new methodology for solving SB problems, and Diffusion Schr\\\"odinger\nBridge Matching (DSBM), a novel numerical algorithm for computing IMF iterates.\nDSBM significantly improves over previous SB numerics and recovers as\nspecial/limiting cases various recent transport methods. We demonstrate the\nperformance of DSBM on a variety of problems.", "published": "2023-03-29T16:59:22Z", "version": 3}, {"aid": "2304.13534", "authors": ["Benjamin J. Zhang", "Markos A. Katsoulakis"], "title": "A mean-field games laboratory for generative modeling", "url": "http://arxiv.org/pdf/2304.13534v5", "summary": "We demonstrate the versatility of mean-field games (MFGs) as a mathematical\nframework for explaining, enhancing, and designing generative models. In\ngenerative flows, a Lagrangian formulation is used where each particle\n(generated sample) aims to minimize a loss function over its simulated path.\nThe loss, however, is dependent on the paths of other particles, which leads to\na competition among the population of particles. The asymptotic behavior of\nthis competition yields a mean-field game. We establish connections between\nMFGs and major classes of generative flows and diffusions including\ncontinuous-time normalizing flows, score-based generative models (SGM), and\nWasserstein gradient flows. Furthermore, we study the mathematical properties\nof each generative model by studying their associated MFG's optimality\ncondition, which is a set of coupled forward-backward nonlinear partial\ndifferential equations. The mathematical structure described by the MFG\noptimality conditions identifies the inductive biases of generative flows. We\ninvestigate the well-posedness and structure of normalizing flows, unravel the\nmathematical structure of SGMs, and derive a MFG formulation of Wasserstein\ngradient flows. From an algorithmic perspective, the optimality conditions\nyields Hamilton-Jacobi-Bellman (HJB) regularizers for enhanced training of\ngenerative models. In particular, we propose and demonstrate an HJB-regularized\nSGM with improved performance over standard SGMs. We present this framework as\nan MFG laboratory which serves as a platform for revealing new avenues of\nexperimentation and invention of generative models.", "published": "2023-04-26T13:08:50Z", "version": 5}, {"aid": "2307.01050", "authors": ["Francisco Vargas", "Shreyas Padhy", "Denis Blessing", "Nikolas N\u00fcsken"], "title": "Transport meets Variational Inference: Controlled Monte Carlo Diffusions", "url": "http://arxiv.org/pdf/2307.01050v12", "summary": "Connecting optimal transport and variational inference, we present a\nprincipled and systematic framework for sampling and generative modelling\ncentred around divergences on path space. Our work culminates in the\ndevelopment of the \\emph{Controlled Monte Carlo Diffusion} sampler (CMCD) for\nBayesian computation, a score-based annealing technique that crucially adapts\nboth forward and backward dynamics in a diffusion model. On the way, we clarify\nthe relationship between the EM-algorithm and iterative proportional fitting\n(IPF) for Schr{\\\"o}dinger bridges, deriving as well a regularised objective\nthat bypasses the iterative bottleneck of standard IPF-updates. Finally, we\nshow that CMCD has a strong foundation in the Jarzinsky and Crooks identities\nfrom statistical physics, and that it convincingly outperforms competing\napproaches across a wide array of experiments.", "published": "2023-07-03T14:28:36Z", "version": 12}, {"aid": "2309.16948", "authors": ["Linqi Zhou", "Aaron Lou", "Samar Khanna", "Stefano Ermon"], "title": "Denoising Diffusion Bridge Models", "url": "http://arxiv.org/pdf/2309.16948v3", "summary": "Diffusion models are powerful generative models that map noise to data using\nstochastic processes. However, for many applications such as image editing, the\nmodel input comes from a distribution that is not random noise. As such,\ndiffusion models must rely on cumbersome methods like guidance or projected\nsampling to incorporate this information in the generative process. In our\nwork, we propose Denoising Diffusion Bridge Models (DDBMs), a natural\nalternative to this paradigm based on diffusion bridges, a family of processes\nthat interpolate between two paired distributions given as endpoints. Our\nmethod learns the score of the diffusion bridge from data and maps from one\nendpoint distribution to the other by solving a (stochastic) differential\nequation based on the learned score. Our method naturally unifies several\nclasses of generative models, such as score-based diffusion models and\nOT-Flow-Matching, allowing us to adapt existing design and architectural\nchoices to our more general problem. Empirically, we apply DDBMs to challenging\nimage datasets in both pixel and latent space. On standard image translation\nproblems, DDBMs achieve significant improvement over baseline methods, and,\nwhen we reduce the problem to image generation by setting the source\ndistribution to random noise, DDBMs achieve comparable FID scores to\nstate-of-the-art methods despite being built for a more general task.", "published": "2023-09-29T03:24:24Z", "version": 3}, {"aid": "2405.13731", "authors": ["Qijia Jiang", "David Nabergoj"], "title": "Control, Transport and Sampling: Towards Better Loss Design", "url": "http://arxiv.org/pdf/2405.13731v2", "summary": "Leveraging connections between diffusion-based sampling, optimal transport,\nand stochastic optimal control through their shared links to the Schr\\\"odinger\nbridge problem, we propose novel objective functions that can be used to\ntransport $\\nu$ to $\\mu$, consequently sample from the target $\\mu$, via\noptimally controlled dynamics. We highlight the importance of the pathwise\nperspective and the role various optimality conditions on the path measure can\nplay for the design of valid training losses, the careful choice of which offer\nnumerical advantages in implementation. Basing the formalism on Schr\\\"odinger\nbridge comes with the additional practical capability of baking in inductive\nbias when it comes to Neural Network training.", "published": "2024-05-22T15:24:48Z", "version": 2}, {"aid": "2405.15885", "authors": ["Kaiwen Zheng", "Guande He", "Jianfei Chen", "Fan Bao", "Jun Zhu"], "title": "Diffusion Bridge Implicit Models", "url": "http://arxiv.org/pdf/2405.15885v6", "summary": "Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion\nmodels for interpolating between two arbitrary paired distributions given as\nendpoints. Despite their promising performance in tasks like image translation,\nDDBMs require a computationally intensive sampling process that involves the\nsimulation of a (stochastic) differential equation through hundreds of network\nevaluations. In this work, we take the first step in fast sampling of DDBMs\nwithout extra training, motivated by the well-established recipes in diffusion\nmodels. We generalize DDBMs via a class of non-Markovian diffusion bridges\ndefined on the discretized timesteps concerning sampling, which share the same\nmarginal distributions and training objectives, give rise to generative\nprocesses ranging from stochastic to deterministic, and result in diffusion\nbridge implicit models (DBIMs). DBIMs are not only up to 25$\\times$ faster than\nthe vanilla sampler of DDBMs but also induce a novel, simple, and insightful\nform of ordinary differential equation (ODE) which inspires high-order\nnumerical solvers. Moreover, DBIMs maintain the generation diversity in a\ndistinguished way, by using a booting noise in the initial sampling step, which\nenables faithful encoding, reconstruction, and semantic interpolation in image\ntranslation tasks. Code is available at\nhttps://github.com/thu-ml/DiffusionBridge.", "published": "2024-05-24T19:08:30Z", "version": 6}, {"aid": "2405.20630", "authors": ["Byoungwoo Park", "Jungwon Choi", "Sungbin Lim", "Juho Lee"], "title": "Stochastic Optimal Control for Diffusion Bridges in Function Spaces", "url": "http://arxiv.org/pdf/2405.20630v5", "summary": "Recent advancements in diffusion models and diffusion bridges primarily focus\non finite-dimensional spaces, yet many real-world problems necessitate\noperations in infinite-dimensional function spaces for more natural and\ninterpretable formulations. In this paper, we present a theory of stochastic\noptimal control (SOC) tailored to infinite-dimensional spaces, aiming to extend\ndiffusion-based algorithms to function spaces. Specifically, we demonstrate how\nDoob's $h$-transform, the fundamental tool for constructing diffusion bridges,\ncan be derived from the SOC perspective and expanded to infinite dimensions.\nThis expansion presents a challenge, as infinite-dimensional spaces typically\nlack closed-form densities. Leveraging our theory, we establish that solving\nthe optimal control problem with a specific objective function choice is\nequivalent to learning diffusion-based generative models. We propose two\napplications: (1) learning bridges between two infinite-dimensional\ndistributions and (2) generative models for sampling from an\ninfinite-dimensional distribution. Our approach proves effective for diverse\nproblems involving continuous function space representations, such as\nresolution-free images, time-series data, and probability density functions.", "published": "2024-05-31T05:42:47Z", "version": 5}, {"aid": "2502.05749", "authors": ["Kaizhen Zhu", "Mokai Pan", "Yuexin Ma", "Yanwei Fu", "Jingyi Yu", "Jingya Wang", "Ye Shi"], "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control", "url": "http://arxiv.org/pdf/2502.05749v5", "summary": "Recent advances in diffusion bridge models leverage Doob's $h$-transform to\nestablish fixed endpoints between distributions, demonstrating promising\nresults in image translation and restoration tasks. However, these approaches\nfrequently produce blurred or excessively smoothed image details and lack a\ncomprehensive theoretical foundation to explain these shortcomings. To address\nthese limitations, we propose UniDB, a unified framework for diffusion bridges\nbased on Stochastic Optimal Control (SOC). UniDB formulates the problem through\nan SOC-based optimization and derives a closed-form solution for the optimal\ncontroller, thereby unifying and generalizing existing diffusion bridge models.\nWe demonstrate that existing diffusion bridges employing Doob's $h$-transform\nconstitute a special case of our framework, emerging when the terminal penalty\ncoefficient in the SOC cost function tends to infinity. By incorporating a\ntunable terminal penalty coefficient, UniDB achieves an optimal balance between\ncontrol costs and terminal penalties, substantially improving detail\npreservation and output quality. Notably, UniDB seamlessly integrates with\nexisting diffusion bridge models, requiring only minimal code modifications.\nExtensive experiments across diverse image restoration tasks validate the\nsuperiority and adaptability of the proposed framework. Our code is available\nat https://github.com/UniDB-SOC/UniDB/.", "published": "2025-02-09T02:43:57Z", "version": 5}, {"aid": "2505.12097", "authors": ["Ricardo Baptista", "Panagiota Birmpa", "Markos A. Katsoulakis", "Luc Rey-Bellet", "Benjamin J. Zhang"], "title": "Proximal optimal transport divergences", "url": "http://arxiv.org/pdf/2505.12097v1", "summary": "We introduce proximal optimal transport divergence, a novel discrepancy\nmeasure that interpolates between information divergences and optimal transport\ndistances via an infimal convolution formulation. This divergence provides a\nprincipled foundation for optimal transport proximals and proximal optimization\nmethods frequently used in generative modeling. We explore its mathematical\nproperties, including smoothness, boundedness, and computational tractability,\nand establish connections to primal-dual formulation and adversarial learning.\nBuilding on the Benamou-Brenier dynamic formulation of optimal transport cost,\nwe also establish a dynamic formulation for proximal OT divergences. The\nresulting dynamic formulation is a first order mean-field game whose optimality\nconditions are governed by a pair of nonlinear partial differential equations,\na backward Hamilton-Jacobi and a forward continuity partial differential\nequations. Our framework generalizes existing approaches while offering new\ninsights and computational tools for generative modeling, distributional\noptimization, and gradient-based learning in probability spaces.", "published": "2025-05-17T17:48:11Z", "version": 1}, {"aid": "2505.21528", "authors": ["Mokai Pan", "Kaizhen Zhu", "Yuexin Ma", "Yanwei Fu", "Jingyi Yu", "Jingya Wang", "Ye Shi"], "title": "UniDB++: Fast Sampling of Unified Diffusion Bridge", "url": "http://arxiv.org/pdf/2505.21528v1", "summary": "Diffusion Bridges enable transitions between arbitrary distributions, with\nthe Unified Diffusion Bridge (UniDB) framework achieving high-fidelity image\ngeneration via a Stochastic Optimal Control (SOC) formulation. However, UniDB's\nreliance on iterative Euler sampling methods results in slow, computationally\nexpensive inference, while existing acceleration techniques for diffusion or\ndiffusion bridge models fail to address its unique challenges: missing terminal\nmean constraints and SOC-specific penalty coefficients in its SDEs. We present\nUniDB++, a training-free sampling algorithm that significantly improves upon\nthese limitations. The method's key advancement comes from deriving exact\nclosed-form solutions for UniDB's reverse-time SDEs, effectively reducing the\nerror accumulation inherent in Euler approximations and enabling high-quality\ngeneration with up to 20$\\times$ fewer sampling steps. This method is further\ncomplemented by replacing conventional noise prediction with a more stable data\nprediction model, along with an SDE-Corrector mechanism that maintains\nperceptual quality for low-step regimes (5-10 steps). Additionally, we\ndemonstrate that UniDB++ aligns with existing diffusion bridge acceleration\nmethods by evaluating their update rules, and UniDB++ can recover DBIMs as\nspecial cases under some theoretical conditions. Experiments demonstrate\nUniDB++'s state-of-the-art performance in image restoration tasks,\noutperforming Euler-based methods in fidelity and speed while reducing\ninference time significantly. This work bridges the gap between theoretical\ngenerality and practical efficiency in SOC-driven diffusion bridge models. Our\ncode is available at https://github.com/2769433owo/UniDB-plusplus.", "published": "2025-05-23T15:03:02Z", "version": 1}]