[{"aid": "1510.04390", "authors": ["Manolis C. Tsakiris", "Rene Vidal"], "title": "Dual Principal Component Pursuit", "url": "http://arxiv.org/pdf/1510.04390v5", "summary": "We consider the problem of learning a linear subspace from data corrupted by outliers. Classical approaches are typically designed for the case in which the subspace dimension is small relative to the ambient dimension. Our approach works with a dual representation of the subspace and hence aims to find its orthogonal complement; as such, it is particularly suitable for subspaces whose dimension is close to the ambient dimension (subspaces of high relative dimension). We pose the problem of computing normal vectors to the inlier subspace as a non-convex $\\ell_1$ minimization problem on the sphere, which we call Dual Principal Component Pursuit (DPCP) problem. We provide theoretical guarantees under which every global solution to DPCP is a vector in the orthogonal complement of the inlier subspace. Moreover, we relax the non-convex DPCP problem to a recursion of linear programs whose solutions are shown to converge in a finite number of steps to a vector orthogonal to the subspace. In particular, when the inlier subspace is a hyperplane, the solutions to the recursion of linear programs converge to the global minimum of the non-convex DPCP problem in a finite number of steps. We also propose algorithms based on alternating minimization and iteratively re-weighted least squares, which are suitable for dealing with large-scale data. Experiments on synthetic data show that the proposed methods are able to handle more outliers and higher relative dimensions than current state-of-the-art methods, while experiments in the context of the three-view geometry problem in computer vision suggest that the proposed methods can be a useful or even superior alternative to traditional RANSAC-based approaches for computer vision and other applications.", "published": "2015-10-15T03:50:01Z", "version": 5}, {"aid": "1511.00255", "authors": ["Carina Curto", "Nora Youngs"], "title": "Neural ring homomorphisms and maps between neural codes", "url": "http://arxiv.org/pdf/1511.00255v3", "summary": "Neural codes are binary codes that are used for information processing and representation in the brain. In previous work, we have shown how an algebraic structure, called the {\\it neural ring}, can be used to efficiently encode geometric and combinatorial properties of a neural code [1]. In this work, we consider maps between neural codes and the associated homomorphisms of their neural rings. In order to ensure that these maps are meaningful and preserve relevant structure, we find that we need additional constraints on the ring homomorphisms. This motivates us to define {\\it neural ring homomorphisms}. Our main results characterize all code maps corresponding to neural ring homomorphisms as compositions of 5 elementary code maps. As an application, we find that neural ring homomorphisms behave nicely with respect to convexity. In particular, if $\\mathcal{C}$ and $\\mathcal{D}$ are convex codes, the existence of a surjective code map $\\mathcal{C}\\rightarrow \\mathcal{D}$ with a corresponding neural ring homomorphism implies that the minimal embedding dimensions satisfy $d(\\mathcal{D}) \\leq d(\\mathcal{C})$.", "published": "2015-11-01T14:29:03Z", "version": 3}, {"aid": "1511.08861", "authors": ["Hang Zhao", "Orazio Gallo", "Iuri Frosio", "Jan Kautz"], "title": "Loss Functions for Neural Networks for Image Processing", "url": "http://arxiv.org/pdf/1511.08861v3", "summary": "Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is L2. In this paper, we bring attention to alternative choices for image restoration. In particular, we show the importance of perceptually-motivated losses when the resulting image is to be evaluated by a human observer. We compare the performance of several losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged.", "published": "2015-11-28T02:02:44Z", "version": 3}, {"aid": "1512.07030", "authors": ["Xiaojie Jin", "Chunyan Xu", "Jiashi Feng", "Yunchao Wei", "Junjun Xiong", "Shuicheng Yan"], "title": "Deep Learning with S-shaped Rectified Linear Activation Units", "url": "http://arxiv.org/pdf/1512.07030v1", "summary": "Rectified linear activation units are important components for state-of-the-art deep convolutional networks. In this paper, we propose a novel S-shaped rectified linear activation unit (SReLU) to learn both convex and non-convex functions, imitating the multiple function forms given by the two fundamental laws, namely the Webner-Fechner law and the Stevens law, in psychophysics and neural sciences. Specifically, SReLU consists of three piecewise linear functions, which are formulated by four learnable parameters. The SReLU is learned jointly with the training of the whole deep network through back propagation. During the training phase, to initialize SReLU in different layers, we propose a \"freezing\" method to degenerate SReLU into a predefined leaky rectified linear unit in the initial several training epochs and then adaptively learn the good initial values. SReLU can be universally used in the existing deep networks with negligible additional parameters and computation cost. Experiments with two popular CNN architectures, Network in Network and GoogLeNet on scale-various benchmarks including CIFAR10, CIFAR100, MNIST and ImageNet demonstrate that SReLU achieves remarkable improvement compared to other activation functions.", "published": "2015-12-22T10:54:26Z", "version": 1}, {"aid": "1602.08199", "authors": ["Makoto Naruse", "Song-Ju Kim", "Masashi Aono", "Martin Berthel", "Aur\u00e9lien Drezet", "Serge Huant", "Hirokazu Hori"], "title": "Category Theoretic Analysis of Photon-based Decision Making", "url": "http://arxiv.org/pdf/1602.08199v3", "summary": "Decision making is a vital function in this age of machine learning and artificial intelligence, yet its physical realization and theoretical fundamentals are still not completely understood. In our former study, we demonstrated that single-photons can be used to make decisions in uncertain, dynamically changing environments. The two-armed bandit problem was successfully solved using the dual probabilistic and particle attributes of single photons. In this study, we present a category theoretic modeling and analysis of single-photon-based decision making, including a quantitative analysis that is in agreement with the experimental results. A category theoretic model reveals the complex interdependencies of subject matter entities in a simplified manner, even in dynamically changing environments. In particular, the octahedral and braid structures in triangulated categories provide a better understanding and quantitative metrics of the underlying mechanisms of a single-photon decision maker. This study provides both insight and a foundation for analyzing more complex and uncertain problems, to further machine learning and artificial intelligence.", "published": "2016-02-26T05:28:42Z", "version": 3}, {"aid": "1603.08253", "authors": ["Devon Merrill"], "title": "Negative Learning Rates and P-Learning", "url": "http://arxiv.org/pdf/1603.08253v3", "summary": "We present a method of training a differentiable function approximator for a regression task using negative examples. We effect this training using negative learning rates. We also show how this method can be used to perform direct policy learning in a reinforcement learning setting.", "published": "2016-03-27T20:02:13Z", "version": 3}, {"aid": "1606.06160", "authors": ["Shuchang Zhou", "Yuxin Wu", "Zekun Ni", "Xinyu Zhou", "He Wen", "Yuheng Zou"], "title": "DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients", "url": "http://arxiv.org/pdf/1606.06160v3", "summary": "We propose DoReFa-Net, a method to train convolutional neural networks that have low bitwidth weights and activations using low bitwidth parameter gradients. In particular, during backward pass, parameter gradients are stochastically quantized to low bitwidth numbers before being propagated to convolutional layers. As convolutions during forward/backward passes can now operate on low bitwidth weights and activations/gradients respectively, DoReFa-Net can use bit convolution kernels to accelerate both training and inference. Moreover, as bit convolutions can be efficiently implemented on CPU, FPGA, ASIC and GPU, DoReFa-Net opens the way to accelerate training of low bitwidth neural network on these hardware. Our experiments on SVHN and ImageNet datasets prove that DoReFa-Net can achieve comparable prediction accuracy as 32-bit counterparts. For example, a DoReFa-Net derived from AlexNet that has 1-bit weights, 2-bit activations, can be trained from scratch using 6-bit gradients to get 46.1\\% top-1 accuracy on ImageNet validation set. The DoReFa-Net AlexNet model is released publicly.", "published": "2016-06-20T15:02:31Z", "version": 3}, {"aid": "1607.06450", "authors": ["Jimmy Lei Ba", "Jamie Ryan Kiros", "Geoffrey E. Hinton"], "title": "Layer Normalization", "url": "http://arxiv.org/pdf/1607.06450v1", "summary": "Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.", "published": "2016-07-21T19:57:52Z", "version": 1}, {"aid": "1611.02302", "authors": ["Mario Mastriani"], "title": "Quantum spectral analysis: frequency in time, with applications to signal and image processing", "url": "http://arxiv.org/pdf/1611.02302v8", "summary": "A quantum time-dependent spectrum analysis, or simply, quantum spectral analysis (QSA) is presented in this work, and it is based on Schrodinger equation, which is a partial differential equation that describes how the quantum state of a non-relativistic physical system changes with time. In classic world is named frequency in time (FIT), which is presented here in opposition and as a complement of traditional spectral analysis frequency-dependent based on Fourier theory. Besides, FIT is a metric, which assesses the impact of the flanks of a signal on its frequency spectrum, which is not taken into account by Fourier theory and even less in real time. Even more, and unlike all derived tools from Fourier Theory (i.e., continuous, discrete, fast, short-time, fractional and quantum Fourier Transform, as well as, Gabor) FIT has the following advantages: a) compact support with excellent energy output treatment, b) low computational cost, O(N) for signals and O(N2) for images, c) it does not have phase uncertainties (indeterminate phase for magnitude = 0) as Discrete and Fast Fourier Transform (DFT, FFT, respectively), d) among others. In fact, FIT constitutes one side of a triangle (which from now on is closed) and it consists of the original signal in time, spectral analysis based on Fourier Theory and FIT. Thus a toolbox is completed, which it is essential for all applications of Digital Signal Processing (DSP) and Digital Image Processing (DIP); and, even, in the latter, FIT allows edge detection (which is called flank detection in case of signals), denoising, despeckling, compression, and superresolution of still images. Such applications include signals intelligence and imagery intelligence. On the other hand, we will present other DIP tools, which are also derived from the Schrodinger equation.", "published": "2016-10-11T18:37:33Z", "version": 8}, {"aid": "1611.01773", "authors": ["Yong Guo", "Jian Chen", "Qing Du", "Anton Van Den Hengel", "Qinfeng Shi", "Mingkui Tan"], "title": "The Shallow End: Empowering Shallower Deep-Convolutional Networks through Auxiliary Outputs", "url": "http://arxiv.org/pdf/1611.01773v6", "summary": "Depth is one of the key factors behind the success of convolutional neural networks (CNNs). Since ResNet, we are able to train very deep CNNs as the gradient vanishing issue has been largely addressed by the introduction of skip connections. However, we observe that, when the depth is very large, the intermediate layers (especially shallow layers) may fail to receive sufficient supervision from the loss due to the severe transformation through a long backpropagation path. As a result, the representation power of intermediate layers can be very weak and the model becomes very redundant with limited performance. In this paper, we first investigate the supervision vanishing issue in existing backpropagation (BP) methods. And then, we propose to address it via an effective method, called Multi-way BP (MW-BP), which relies on multiple auxiliary losses added to the intermediate layers of the network. The proposed MW-BP method can be applied to most deep architectures with slight modifications, such as ResNet and MobileNet. Our method often gives rise to much more compact models (denoted by \"Mw+Architecture\") than existing methods. For example, MwResNet-44 with 44 layers performs better than ResNet-110 with 110 layers on CIFAR-10 and CIFAR-100. More critically, the resultant models even outperform the light models obtained by state-of-the-art model compression methods. Last, our method inherently produces multiple compact models with different depths at the same time, which is helpful for model selection.", "published": "2016-11-06T13:20:06Z", "version": 6}, {"aid": "1612.09375", "authors": ["Tom Leinster"], "title": "Basic Category Theory", "url": "http://arxiv.org/pdf/1612.09375v2", "summary": "This short introductory category theory textbook is for readers with relatively little mathematical background (e.g. the first half of an undergraduate mathematics degree). At its heart is the concept of a universal property, important throughout mathematics. After a chapter introducing the basic definitions, separate chapters present three ways of expressing universal properties: via adjoint functors, representable functors, and limits. A final chapter ties the three together.   For each new categorical concept, a generous supply of examples is provided, taken from different parts of mathematics. At points where the leap in abstraction is particularly great (such as the Yoneda lemma), the reader will find careful and extensive explanations.", "published": "2016-12-30T03:02:01Z", "version": 2}, {"aid": "1701.02434", "authors": ["Michael Betancourt"], "title": "A Conceptual Introduction to Hamiltonian Monte Carlo", "url": "http://arxiv.org/pdf/1701.02434v2", "summary": "Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.", "published": "2017-01-10T04:26:06Z", "version": 2}, {"aid": "1701.07875", "authors": ["Martin Arjovsky", "Soumith Chintala", "L\u00e9on Bottou"], "title": "Wasserstein GAN", "url": "http://arxiv.org/pdf/1701.07875v3", "summary": "We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.", "published": "2017-01-26T21:10:29Z", "version": 3}, {"aid": "1703.00443", "authors": ["Brandon Amos", "J. Zico Kolter"], "title": "OptNet: Differentiable Optimization as a Layer in Neural Networks", "url": "http://arxiv.org/pdf/1703.00443v5", "summary": "This paper presents OptNet, a network architecture that integrates optimization problems (here, specifically in the form of quadratic programs) as individual layers in larger end-to-end trainable deep networks. These layers encode constraints and complex dependencies between the hidden states that traditional convolutional and fully-connected layers often cannot capture. We explore the foundations for such an architecture: we show how techniques from sensitivity analysis, bilevel optimization, and implicit differentiation can be used to exactly differentiate through these layers and with respect to layer parameters; we develop a highly efficient solver for these layers that exploits fast GPU-based batch solves within a primal-dual interior point method, and which provides backpropagation gradients with virtually no additional cost on top of the solve; and we highlight the application of these approaches in several problems. In one notable example, the method is learns to play mini-Sudoku (4x4) given just input and output games, with no a-priori information about the rules of the game; this highlights the ability of OptNet to learn hard constraints better than other neural architectures.", "published": "2017-03-01T18:58:48Z", "version": 5}, {"aid": "1703.01203", "authors": ["A. N. Gorban", "I. Y. Tyukin"], "title": "Stochastic Separation Theorems", "url": "http://arxiv.org/pdf/1703.01203v3", "summary": "The problem of non-iterative one-shot and non-destructive correction of unavoidable mistakes arises in all Artificial Intelligence applications in the real world. Its solution requires robust separation of samples with errors from samples where the system works properly. We demonstrate that in (moderately) high dimension this separation could be achieved with probability close to one by linear discriminants. Surprisingly, separation of a new image from a very large set of known images is almost always possible even in moderately high dimensions by linear functionals, and coefficients of these functionals can be found explicitly. Based on fundamental properties of measure concentration, we show that for $M<a\\exp(b{n})$ random $M$-element sets in $\\mathbb{R}^n$ are linearly separable with probability $p$, $p>1-\\vartheta$, where $1>\\vartheta>0$ is a given small constant. Exact values of $a,b>0$ depend on the probability distribution that determines how the random $M$-element sets are drawn, and on the constant $\\vartheta$. These {\\em stochastic separation theorems} provide a new instrument for the development, analysis, and assessment of machine learning methods and algorithms in high dimension. Theoretical statements are illustrated with numerical examples.", "published": "2017-03-03T15:27:38Z", "version": 3}, {"aid": "1705.11190", "authors": ["Xerxes D. Arsiwalla", "Ricard Sole", "Clement Moulin-Frier", "Ivan Herreros", "Marti Sanchez-Fibla", "Paul Verschure"], "title": "The Morphospace of Consciousness", "url": "http://arxiv.org/pdf/1705.11190v3", "summary": "We construct a complexity-based morphospace to study systems-level properties of conscious & intelligent systems. The axes of this space label 3 complexity types: autonomous, cognitive & social. Given recent proposals to synthesize consciousness, a generic complexity-based conceptualization provides a useful framework for identifying defining features of conscious & synthetic systems. Based on current clinical scales of consciousness that measure cognitive awareness and wakefulness, we take a perspective on how contemporary artificially intelligent machines & synthetically engineered life forms measure on these scales. It turns out that awareness & wakefulness can be associated to computational & autonomous complexity respectively. Subsequently, building on insights from cognitive robotics, we examine the function that consciousness serves, & argue the role of consciousness as an evolutionary game-theoretic strategy. This makes the case for a third type of complexity for describing consciousness: social complexity. Having identified these complexity types, allows for a representation of both, biological & synthetic systems in a common morphospace. A consequence of this classification is a taxonomy of possible conscious machines. We identify four types of consciousness, based on embodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii) group consciousness (resulting from group interactions), & (iv) simulated consciousness (embodied by virtual agents within a simulated reality). This taxonomy helps in the investigation of comparative signatures of consciousness across domains, in order to highlight design principles necessary to engineer conscious machines. This is particularly relevant in the light of recent developments at the crossroads of cognitive neuroscience, biomedical engineering, artificial intelligence & biomimetics.", "published": "2017-05-31T17:45:39Z", "version": 3}, {"aid": "1706.10283", "authors": ["Davis W Blalock", "John V Guttag"], "title": "Bolt: Accelerated Data Mining with Fast Vector Compression", "url": "http://arxiv.org/pdf/1706.10283v1", "summary": "Vectors of data are at the heart of machine learning and data mining. Recently, vector quantization methods have shown great promise in reducing both the time and space costs of operating on vectors. We introduce a vector quantization algorithm that can compress vectors over 12x faster than existing techniques while also accelerating approximate vector operations such as distance and dot product computations by up to 10x. Because it can encode over 2GB of vectors per second, it makes vector quantization cheap enough to employ in many more circumstances. For example, using our technique to compute approximate dot products in a nested loop can multiply matrices faster than a state-of-the-art BLAS implementation, even when our algorithm must first compress the matrices.   In addition to showing the above speedups, we demonstrate that our approach can accelerate nearest neighbor search and maximum inner product search by over 100x compared to floating point operations and up to 10x compared to other vector quantization methods. Our approximate Euclidean distance and dot product computations are not only faster than those of related algorithms with slower encodings, but also faster than Hamming distance computations, which have direct hardware support on the tested platforms. We also assess the errors of our algorithm's approximate distances and dot products, and find that it is competitive with existing, slower vector quantization algorithms.", "published": "2017-06-30T17:31:59Z", "version": 1}, {"aid": "1707.05649", "authors": ["Leo Kozachkov", "Konstantinos P. Michmizos"], "title": "Sequence learning in Associative Neuronal-Astrocytic Network", "url": "http://arxiv.org/pdf/1707.05649v2", "summary": "The neuronal paradigm of studying the brain has left us with limitations in both our understanding of how neurons process information to achieve biological intelligence and how such knowledge may be translated into artificial intelligence and its most brain-derived branch, neuromorphic computing. Overturning our fundamental assumptions of how the brain works, the recent exploration of astrocytes is revealing that these long-neglected brain cells dynamically regulate learning by interacting with neuronal activity at the synaptic level. Following recent experimental evidence, we designed an associative, Hopfield-type, neuronal-astrocytic network and analyzed the dynamics of the interaction between neurons and astrocytes. We show that astrocytes were sufficient to trigger transitions between learned memories in the neuronal component of the network. Further, we mathematically derived the timing of the transitions that was governed by the dynamics of the calcium-dependent slow-currents in the astrocytic processes. Overall, we provide a brain-morphic mechanism for sequence learning that is inspired by, and aligns with, recent experimental findings. To evaluate our model, we emulated astrocytic atrophy and showed that memory recall becomes significantly impaired after a critical point of affected astrocytes was reached. This brain-inspired and brain-validated approach supports our ongoing efforts to incorporate non-neuronal computing elements in neuromorphic information processing.", "published": "2017-07-16T18:16:27Z", "version": 2}, {"aid": "1707.06347", "authors": ["John Schulman", "Filip Wolski", "Prafulla Dhariwal", "Alec Radford", "Oleg Klimov"], "title": "Proximal Policy Optimization Algorithms", "url": "http://arxiv.org/pdf/1707.06347v2", "summary": "We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a \"surrogate\" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.", "published": "2017-07-20T02:32:33Z", "version": 2}, {"aid": "1707.09669", "authors": ["Xiaobin Chang", "Tao Xiang", "Timothy M. Hospedales"], "title": "Scalable and Effective Deep CCA via Soft Decorrelation", "url": "http://arxiv.org/pdf/1707.09669v2", "summary": "Recently the widely used multi-view learning model, Canonical Correlation Analysis (CCA) has been generalised to the non-linear setting via deep neural networks. Existing deep CCA models typically first decorrelate the feature dimensions of each view before the different views are maximally correlated in a common latent space. This feature decorrelation is achieved by enforcing an exact decorrelation constraint; these models are thus computationally expensive due to the matrix inversion or SVD operations required for exact decorrelation at each training iteration. Furthermore, the decorrelation step is often separated from the gradient descent based optimisation, resulting in sub-optimal solutions. We propose a novel deep CCA model Soft CCA to overcome these problems. Specifically, exact decorrelation is replaced by soft decorrelation via a mini-batch based Stochastic Decorrelation Loss (SDL) to be optimised jointly with the other training objectives. Extensive experiments show that the proposed soft CCA is more effective and efficient than existing deep CCA models. In addition, our SDL loss can be applied to other deep models beyond multi-view learning, and obtains superior performance compared to existing decorrelation losses.", "published": "2017-07-30T20:53:54Z", "version": 2}, {"aid": "1708.04020", "authors": ["Natalia Z. Bielczyk", "Sebo Uithol", "Tim van Mourik", "Paul Anderson", "Jeffrey C. Glennon", "Jan K. Buitelaar"], "title": "Disentangling causal webs in the brain using functional Magnetic Resonance Imaging: A review of current approaches", "url": "http://arxiv.org/pdf/1708.04020v4", "summary": "In the past two decades, functional Magnetic Resonance Imaging has been used to relate neuronal network activity to cognitive processing and behaviour. Recently this approach has been augmented by algorithms that allow us to infer causal links between component populations of neuronal networks. Multiple inference procedures have been proposed to approach this research question but so far, each method has limitations when it comes to establishing whole-brain connectivity patterns. In this work, we discuss eight ways to infer causality in fMRI research: Bayesian Nets, Dynamical Causal Modelling, Granger Causality, Likelihood Ratios, LiNGAM, Patel's Tau, Structural Equation Modelling, and Transfer Entropy. We finish with formulating some recommendations for the future directions in this area.", "published": "2017-08-14T07:13:17Z", "version": 4}, {"aid": "1708.05714", "authors": ["Mark Inman"], "title": "A Stronger Foundation for Computer Science and P=NP", "url": "http://arxiv.org/pdf/1708.05714v2", "summary": "This article describes a Turing machine which can solve for $\\beta^{'}$ which is RE-complete. RE-complete problems are proven to be undecidable by Turing's accepted proof on the Entscheidungsproblem. Thus, constructing a machine which decides over $\\beta^{'}$ implies inconsistency in ZFC. We then discover that unrestricted use of the axiom of substitution can lead to hidden assumptions in a certain class of proofs by contradiction. These hidden assumptions create an implied axiom of incompleteness for ZFC. Later, we offer a restriction on the axiom of substitution by introducing a new axiom which prevents impredicative tautologies from producing theorems. Our discovery in regards to these foundational arguments, disproves the SPACE hierarchy theorem which allows us to solve the P vs NP problem using a TIME-SPACE equivalence oracle.", "published": "2017-08-18T22:36:07Z", "version": 2}, {"aid": "1708.07120", "authors": ["Leslie N. Smith", "Nicholay Topin"], "title": "Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates", "url": "http://arxiv.org/pdf/1708.07120v3", "summary": "In this paper, we describe a phenomenon, which we named \"super-convergence\", where neural networks can be trained an order of magnitude faster than with standard training methods. The existence of super-convergence is relevant to understanding why deep networks generalize well. One of the key elements of super-convergence is training with one learning rate cycle and a large maximum learning rate. A primary insight that allows super-convergence training is that large learning rates regularize the training, hence requiring a reduction of all other forms of regularization in order to preserve an optimal regularization balance. We also derive a simplification of the Hessian Free optimization method to compute an estimate of the optimal learning rate. Experiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet datasets, and resnet, wide-resnet, densenet, and inception architectures. In addition, we show that super-convergence provides a greater boost in performance relative to standard training when the amount of labeled training data is limited. The architectures and code to replicate the figures in this paper are available at github.com/lnsmith54/super-convergence. See http://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of super-convergence to win the DAWNBench challenge (see https://dawn.cs.stanford.edu/benchmark/).", "published": "2017-08-23T17:51:57Z", "version": 3}, {"aid": "1709.02341", "authors": ["Kai Ueltzh\u00f6ffer"], "title": "Deep Active Inference", "url": "http://arxiv.org/pdf/1709.02341v5", "summary": "This work combines the free energy principle from cognitive neuroscience and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the \"deep active inference\" agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal directed behaviour can be implemented by defining appropriate priors on the latent states in the agent's model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent's beliefs about the environment and its interaction therewith.", "published": "2017-09-07T16:36:52Z", "version": 5}, {"aid": "1709.06196", "authors": ["Zachary Sunberg", "Mykel Kochenderfer"], "title": "Online algorithms for POMDPs with continuous state, action, and observation spaces", "url": "http://arxiv.org/pdf/1709.06196v6", "summary": "Online solvers for partially observable Markov decision processes have been applied to problems with large discrete state spaces, but continuous state, action, and observation spaces remain a challenge. This paper begins by investigating double progressive widening (DPW) as a solution to this challenge. However, we prove that this modification alone is not sufficient because the belief representations in the search tree collapse to a single particle causing the algorithm to converge to a policy that is suboptimal regardless of the computation time. This paper proposes and evaluates two new algorithms, POMCPOW and PFT-DPW, that overcome this deficiency by using weighted particle filtering. Simulation results show that these modifications allow the algorithms to be successful where previous approaches fail.", "published": "2017-09-18T22:57:30Z", "version": 6}, {"aid": "1709.06247", "authors": ["Gangming Zhao", "Zhaoxiang Zhang", "He Guan", "Peng Tang", "Jingdong Wang"], "title": "Rethink ReLU to Training Better CNNs", "url": "http://arxiv.org/pdf/1709.06247v2", "summary": "Most of convolutional neural networks share the same characteristic: each convolutional layer is followed by a nonlinear activation layer where Rectified Linear Unit (ReLU) is the most widely used. In this paper, we argue that the designed structure with the equal ratio between these two layers may not be the best choice since it could result in the poor generalization ability. Thus, we try to investigate a more suitable method on using ReLU to explore the better network architectures. Specifically, we propose a proportional module to keep the ratio between convolution and ReLU amount to be N:M (N>M). The proportional module can be applied in almost all networks with no extra computational cost to improve the performance. Comprehensive experimental results indicate that the proposed method achieves better performance on different benchmarks with different network architectures, thus verify the superiority of our work.", "published": "2017-09-19T04:27:56Z", "version": 2}, {"aid": "1710.02298", "authors": ["Matteo Hessel", "Joseph Modayil", "Hado van Hasselt", "Tom Schaul", "Georg Ostrovski", "Will Dabney", "Dan Horgan", "Bilal Piot", "Mohammad Azar", "David Silver"], "title": "Rainbow: Combining Improvements in Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1710.02298v1", "summary": "The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.", "published": "2017-10-06T07:45:46Z", "version": 1}, {"aid": "1710.10328", "authors": ["Lixin Fan"], "title": "Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU with Generalized Hamming Network", "url": "http://arxiv.org/pdf/1710.10328v1", "summary": "We revisit fuzzy neural network with a cornerstone notion of generalized hamming distance, which provides a novel and theoretically justified framework to re-interpret many useful neural network techniques in terms of fuzzy logic. In particular, we conjecture and empirically illustrate that, the celebrated batch normalization (BN) technique actually adapts the normalized bias such that it approximates the rightful bias induced by the generalized hamming distance. Once the due bias is enforced analytically, neither the optimization of bias terms nor the sophisticated batch normalization is needed. Also in the light of generalized hamming distance, the popular rectified linear units (ReLU) can be treated as setting a minimal hamming distance threshold between network inputs and weights. This thresholding scheme, on the one hand, can be improved by introducing double thresholding on both extremes of neuron outputs. On the other hand, ReLUs turn out to be non-essential and can be removed from networks trained for simple tasks like MNIST classification. The proposed generalized hamming network (GHN) as such not only lends itself to rigorous analysis and interpretation within the fuzzy logic theory but also demonstrates fast learning speed, well-controlled behaviour and state-of-the-art performances on a variety of learning tasks.", "published": "2017-10-27T20:48:57Z", "version": 1}, {"aid": "1711.00937", "authors": ["Aaron van den Oord", "Oriol Vinyals", "Koray Kavukcuoglu"], "title": "Neural Discrete Representation Learning", "url": "http://arxiv.org/pdf/1711.00937v2", "summary": "Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of \"posterior collapse\" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.", "published": "2017-11-02T21:14:44Z", "version": 2}, {"aid": "1711.05246", "authors": ["Sean Welleck", "Zixin Yao", "Yu Gai", "Jialin Mao", "Zheng Zhang", "Kyunghyun Cho"], "title": "Loss Functions for Multiset Prediction", "url": "http://arxiv.org/pdf/1711.05246v2", "summary": "We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.", "published": "2017-11-14T18:43:22Z", "version": 2}, {"aid": "1711.08141", "authors": ["Bichen Wu", "Alvin Wan", "Xiangyu Yue", "Peter Jin", "Sicheng Zhao", "Noah Golmant", "Amir Gholaminejad", "Joseph Gonzalez", "Kurt Keutzer"], "title": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions", "url": "http://arxiv.org/pdf/1711.08141v2", "summary": "Neural networks rely on convolutions to aggregate spatial information. However, spatial convolutions are expensive in terms of model size and computation, both of which grow quadratically with respect to kernel size. In this paper, we present a parameter-free, FLOP-free \"shift\" operation as an alternative to spatial convolutions. We fuse shifts and point-wise convolutions to construct end-to-end trainable shift-based modules, with a hyperparameter characterizing the tradeoff between accuracy and efficiency. To demonstrate the operation's efficacy, we replace ResNet's 3x3 convolutions with shift-based modules for improved CIFAR10 and CIFAR100 accuracy using 60% fewer parameters; we additionally demonstrate the operation's resilience to parameter reduction on ImageNet, outperforming ResNet family members. We finally show the shift operation's applicability across domains, achieving strong performance with fewer parameters on classification, face verification and style transfer.", "published": "2017-11-22T05:52:19Z", "version": 2}, {"aid": "1711.08393", "authors": ["Zuxuan Wu", "Tushar Nagarajan", "Abhishek Kumar", "Steven Rennie", "Larry S. Davis", "Kristen Grauman", "Rogerio Feris"], "title": "BlockDrop: Dynamic Inference Paths in Residual Networks", "url": "http://arxiv.org/pdf/1711.08393v4", "summary": "Very deep convolutional neural networks offer excellent recognition results, yet their computational expense limits their impact for many real-world applications. We introduce BlockDrop, an approach that learns to dynamically choose which layers of a deep network to execute during inference so as to best reduce total computation without degrading prediction accuracy. Exploiting the robustness of Residual Networks (ResNets) to layer dropping, our framework selects on-the-fly which residual blocks to evaluate for a given novel image. In particular, given a pretrained ResNet, we train a policy network in an associative reinforcement learning setting for the dual reward of utilizing a minimal number of blocks while preserving recognition accuracy. We conduct extensive experiments on CIFAR and ImageNet. The results provide strong quantitative and qualitative evidence that these learned policies not only accelerate inference but also encode meaningful visual information. Built upon a ResNet-101 model, our method achieves a speedup of 20\\% on average, going as high as 36\\% for some images, while maintaining the same 76.4\\% top-1 accuracy on ImageNet.", "published": "2017-11-22T17:01:59Z", "version": 4}, {"aid": "1711.10563", "authors": ["Ronald Kemker", "Christopher Kanan"], "title": "FearNet: Brain-Inspired Model for Incremental Learning", "url": "http://arxiv.org/pdf/1711.10563v2", "summary": "Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This violates the assumptions that underlie methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting. Arguably, the best method for incremental class learning is iCaRL, but it requires storing training examples for each class, making it challenging to scale. Here, we propose FearNet for incremental class learning. FearNet is a generative model that does not store previous examples, making it memory efficient. FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex. Memory consolidation is inspired by mechanisms that occur during sleep. FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall. FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.", "published": "2017-11-28T21:26:15Z", "version": 2}, {"aid": "1712.02408", "authors": ["Hongyu Xu", "Xutao Lv", "Xiaoyu Wang", "Zhou Ren", "Navaneeth Bodla", "Rama Chellappa"], "title": "Deep Regionlets for Object Detection", "url": "http://arxiv.org/pdf/1712.02408v3", "summary": "In this paper, we propose a novel object detection framework named \"Deep Regionlets\" by establishing a bridge between deep neural networks and conventional detection schema for accurate generic object detection. Motivated by the abilities of regionlets for modeling object deformation and multiple aspect ratios, we incorporate regionlets into an end-to-end trainable deep learning framework. The deep regionlets framework consists of a region selection network and a deep regionlet learning module. Specifically, given a detection bounding box proposal, the region selection network provides guidance on where to select regions to learn the features from. The regionlet learning module focuses on local feature selection and transformation to alleviate local variations. To this end, we first realize non-rectangular region selection within the detection framework to accommodate variations in object appearance. Moreover, we design a \"gating network\" within the regionlet leaning module to enable soft regionlet selection and pooling. The Deep Regionlets framework is trained end-to-end without additional efforts. We perform ablation studies and conduct extensive experiments on the PASCAL VOC and Microsoft COCO datasets. The proposed framework outperforms state-of-the-art algorithms, such as RetinaNet and Mask R-CNN, even without additional segmentation labels.", "published": "2017-12-06T21:05:21Z", "version": 3}, {"aid": "1712.02616", "authors": ["Samuel Rota Bul\u00f2", "Lorenzo Porzi", "Peter Kontschieder"], "title": "In-Place Activated BatchNorm for Memory-Optimized Training of DNNs", "url": "http://arxiv.org/pdf/1712.02616v3", "summary": "In this work we present In-Place Activated Batch Normalization (InPlace-ABN) - a novel approach to drastically reduce the training memory footprint of modern deep neural networks in a computationally efficient way. Our solution substitutes the conventionally used succession of BatchNorm + Activation layers with a single plugin layer, hence avoiding invasive framework surgery while providing straightforward applicability for existing deep learning frameworks. We obtain memory savings of up to 50% by dropping intermediate results and by recovering required information during the backward pass through the inversion of stored forward results, with only minor increase (0.8-2%) in computation time. Also, we demonstrate how frequently used checkpointing approaches can be made computationally as efficient as InPlace-ABN. In our experiments on image classification, we demonstrate on-par results on ImageNet-1k with state-of-the-art approaches. On the memory-demanding task of semantic segmentation, we report results for COCO-Stuff, Cityscapes and Mapillary Vistas, obtaining new state-of-the-art results on the latter without additional training data but in a single-scale and -model scenario. Code can be found at https://github.com/mapillary/inplace_abn .", "published": "2017-12-07T13:43:45Z", "version": 3}, {"aid": "1712.03333", "authors": ["Heejin Jeong", "Clark Zhang", "George J. Pappas", "Daniel D. Lee"], "title": "Assumed Density Filtering Q-learning", "url": "http://arxiv.org/pdf/1712.03333v4", "summary": "While off-policy temporal difference (TD) methods have widely been used in reinforcement learning due to their efficiency and simple implementation, their Bayesian counterparts have not been utilized as frequently. One reason is that the non-linear max operation in the Bellman optimality equation makes it difficult to define conjugate distributions over the value functions. In this paper, we introduce a novel Bayesian approach to off-policy TD methods, called as ADFQ, which updates beliefs on state-action values, Q, through an online Bayesian inference method known as Assumed Density Filtering. We formulate an efficient closed-form solution for the value update by approximately estimating analytic parameters of the posterior of the Q-beliefs. Uncertainty measures in the beliefs not only are used in exploration but also provide a natural regularization for the value update considering all next available actions. ADFQ converges to Q-learning as the uncertainty measures of the Q-beliefs decrease and improves common drawbacks of other Bayesian RL algorithms such as computational complexity. We extend ADFQ with a neural network. Our empirical results demonstrate that ADFQ outperforms comparable algorithms on various Atari 2600 games, with drastic improvements in highly stochastic domains or domains with a large action space.", "published": "2017-12-09T02:18:05Z", "version": 4}, {"aid": "1712.03747", "authors": ["Jose Bernal", "Kaisar Kushibar", "Daniel S. Asfaw", "Sergi Valverde", "Arnau Oliver", "Robert Mart\u00ed", "Xavier Llad\u00f3"], "title": "Deep convolutional neural networks for brain image analysis on magnetic resonance imaging: a review", "url": "http://arxiv.org/pdf/1712.03747v3", "summary": "In recent years, deep convolutional neural networks (CNNs) have shown record-shattering performance in a variety of computer vision problems, such as visual object recognition, detection and segmentation. These methods have also been utilised in medical image analysis domain for lesion segmentation, anatomical segmentation and classification. We present an extensive literature review of CNN techniques applied in brain magnetic resonance imaging (MRI) analysis, focusing on the architectures, pre-processing, data-preparation and post-processing strategies available in these works. The aim of this study is three-fold. Our primary goal is to report how different CNN architectures have evolved, discuss state-of-the-art strategies, condense their results obtained using public datasets and examine their pros and cons. Second, this paper is intended to be a detailed reference of the research activity in deep CNN for brain MRI analysis. Finally, we present a perspective on the future of CNNs in which we hint some of the research directions in subsequent years.", "published": "2017-12-11T12:25:30Z", "version": 3}, {"aid": "1712.04323", "authors": ["Claudio Gallicchio", "Alessio Micheli"], "title": "Deep Echo State Network (DeepESN): A Brief Survey", "url": "http://arxiv.org/pdf/1712.04323v4", "summary": "The study of deep recurrent neural networks (RNNs) and, in particular, of deep Reservoir Computing (RC) is gaining an increasing research attention in the neural networks community. The recently introduced Deep Echo State Network (DeepESN) model opened the way to an extremely efficient approach for designing deep neural networks for temporal data. At the same time, the study of DeepESNs allowed to shed light on the intrinsic properties of state dynamics developed by hierarchical compositions of recurrent layers, i.e. on the bias of depth in RNNs architectural design. In this paper, we summarize the advancements in the development, analysis and applications of DeepESNs.", "published": "2017-12-12T14:50:51Z", "version": 4}, {"aid": "1712.05577", "authors": ["George Philipp", "Dawn Song", "Jaime G. Carbonell"], "title": "The exploding gradient problem demystified - definition, prevalence, impact, origin, tradeoffs, and solutions", "url": "http://arxiv.org/pdf/1712.05577v4", "summary": "Whereas it is believed that techniques such as Adam, batch normalization and, more recently, SeLU nonlinearities \"solve\" the exploding gradient problem, we show that this is not the case in general and that in a range of popular MLP architectures, exploding gradients exist and that they limit the depth to which networks can be effectively trained, both in theory and in practice. We explain why exploding gradients occur and highlight the *collapsing domain problem*, which can arise in architectures that avoid exploding gradients.   ResNets have significantly lower gradients and thus can circumvent the exploding gradient problem, enabling the effective training of much deeper networks. We show this is a direct consequence of the Pythagorean equation. By noticing that *any neural network is a residual network*, we devise the *residual trick*, which reveals that introducing skip connections simplifies the network mathematically, and that this simplicity may be the major cause for their success.", "published": "2017-12-15T08:25:51Z", "version": 4}, {"aid": "1712.05812", "authors": ["Stuart Armstrong", "S\u00f6ren Mindermann"], "title": "Occam's razor is insufficient to infer the preferences of irrational agents", "url": "http://arxiv.org/pdf/1712.05812v6", "summary": "Inverse reinforcement learning (IRL) attempts to infer human rewards or preferences from observed behavior. Since human planning systematically deviates from rationality, several approaches have been tried to account for specific human shortcomings. However, the general problem of inferring the reward function of an agent of unknown rationality has received little attention. Unlike the well-known ambiguity problems in IRL, this one is practically relevant but cannot be resolved by observing the agent's policy in enough environments. This paper shows (1) that a No Free Lunch result implies it is impossible to uniquely decompose a policy into a planning algorithm and reward function, and (2) that even with a reasonable simplicity prior/Occam's razor on the set of decompositions, we cannot distinguish between the true decomposition and others that lead to high regret. To address this, we need simple `normative' assumptions, which cannot be deduced exclusively from observations.", "published": "2017-12-15T19:05:01Z", "version": 6}, {"aid": "1712.06145", "authors": ["Dong-Qing Zhang"], "title": "clcNet: Improving the Efficiency of Convolutional Neural Network using Channel Local Convolutions", "url": "http://arxiv.org/pdf/1712.06145v3", "summary": "Depthwise convolution and grouped convolution has been successfully applied to improve the efficiency of convolutional neural network (CNN). We suggest that these models can be considered as special cases of a generalized convolution operation, named channel local convolution(CLC), where an output channel is computed using a subset of the input channels. This definition entails computation dependency relations between input and output channels, which can be represented by a channel dependency graph(CDG). By modifying the CDG of grouped convolution, a new CLC kernel named interlaced grouped convolution (IGC) is created. Stacking IGC and GC kernels results in a convolution block (named CLC Block) for approximating regular convolution. By resorting to the CDG as an analysis tool, we derive the rule for setting the meta-parameters of IGC and GC and the framework for minimizing the computational cost. A new CNN model named clcNet is then constructed using CLC blocks, which shows significantly higher computational efficiency and fewer parameters compared to state-of-the-art networks, when being tested using the ImageNet-1K dataset. Source code is available at https://github.com/dqzhang17/clcnet.torch .", "published": "2017-12-17T17:07:54Z", "version": 3}, {"aid": "1712.06391", "authors": ["Xudong Mao", "Qing Li", "Haoran Xie", "Raymond Y. K. Lau", "Zhen Wang", "Stephen Paul Smolley"], "title": "On the Effectiveness of Least Squares Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1712.06391v2", "summary": "Unsupervised learning with generative adversarial networks (GANs) has proven to be hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss for both the discriminator and the generator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson $\\chi^2$ divergence. We also show that the derived objective function that yields minimizing the Pearson $\\chi^2$ divergence performs better than the classical one of using least squares for classification. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stably during the learning process. For evaluating the image quality, we conduct both qualitative and quantitative experiments, and the experimental results show that LSGANs can generate higher quality images than regular GANs. Furthermore, we evaluate the stability of LSGANs in two groups. One is to compare between LSGANs and regular GANs without gradient penalty. We conduct three experiments, including Gaussian mixture distribution, difficult architectures, and a newly proposed method --- datasets with small variability, to illustrate the stability of LSGANs. The other one is to compare between LSGANs with gradient penalty (LSGANs-GP) and WGANs with gradient penalty (WGANs-GP). The experimental results show that LSGANs-GP succeed in training for all the difficult architectures used in WGANs-GP, including 101-layer ResNet.", "published": "2017-12-18T13:36:09Z", "version": 2}, {"aid": "1801.03454", "authors": ["Ruth Fong", "Andrea Vedaldi"], "title": "Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters in Deep Neural Networks", "url": "http://arxiv.org/pdf/1801.03454v2", "summary": "In an effort to understand the meaning of the intermediate representations captured by deep networks, recent papers have tried to associate specific semantic concepts to individual neural network filter responses, where interesting correlations are often found, largely by focusing on extremal filter responses. In this paper, we show that this approach can favor easy-to-interpret cases that are not necessarily representative of the average behavior of a representation.   A more realistic but harder-to-study hypothesis is that semantic representations are distributed, and thus filters must be studied in conjunction. In order to investigate this idea while enabling systematic visualization and quantification of multiple filter responses, we introduce the Net2Vec framework, in which semantic concepts are mapped to vectorial embeddings based on corresponding filter responses. By studying such embeddings, we are able to show that 1., in most cases, multiple filters are required to code for a concept, that 2., often filters are not concept specific and help encode multiple concepts, and that 3., compared to single filter activations, filter embeddings are able to better characterize the meaning of a representation and its relationship to other concepts.", "published": "2018-01-10T17:01:36Z", "version": 2}, {"aid": "1801.04406", "authors": ["Lars Mescheder", "Andreas Geiger", "Sebastian Nowozin"], "title": "Which Training Methods for GANs do actually Converge?", "url": "http://arxiv.org/pdf/1801.04406v4", "summary": "Recent work has shown local convergence of GAN training for absolutely continuous data and generator distributions. In this paper, we show that the requirement of absolute continuity is necessary: we describe a simple yet prototypical counterexample showing that in the more realistic case of distributions that are not absolutely continuous, unregularized GAN training is not always convergent. Furthermore, we discuss regularization strategies that were recently proposed to stabilize GAN training. Our analysis shows that GAN training with instance noise or zero-centered gradient penalties converges. On the other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number of discriminator updates per generator update do not always converge to the equilibrium point. We discuss these results, leading us to a new explanation for the stability problems of GAN training. Based on our analysis, we extend our convergence results to more general GANs and prove local convergence for simplified gradient penalties even if the generator and data distribution lie on lower dimensional manifolds. We find these penalties to work well in practice and use them to learn high-resolution generative image models for a variety of datasets with little hyperparameter tuning.", "published": "2018-01-13T09:42:26Z", "version": 4}, {"aid": "1801.04520", "authors": ["Dipan K. Pal", "Marios Savvides"], "title": "Non-Parametric Transformation Networks", "url": "http://arxiv.org/pdf/1801.04520v6", "summary": "ConvNets, through their architecture, only enforce invariance to translation. In this paper, we introduce a new class of deep convolutional architectures called Non-Parametric Transformation Networks (NPTNs) which can learn \\textit{general} invariances and symmetries directly from data. NPTNs are a natural generalization of ConvNets and can be optimized directly using gradient descent. Unlike almost all previous works in deep architectures, they make no assumption regarding the structure of the invariances present in the data and in that aspect are flexible and powerful. We also model ConvNets and NPTNs under a unified framework called Transformation Networks (TN), which yields a better understanding of the connection between the two. We demonstrate the efficacy of NPTNs on data such as MNIST with extreme transformations and CIFAR10 where they outperform baselines, and further outperform several recent algorithms on ETH-80. They do so while having the same number of parameters. We also show that they are more effective than ConvNets in modelling symmetries and invariances from data, without the explicit knowledge of the added arbitrary nuisance transformations. Finally, we replace ConvNets with NPTNs within Capsule Networks and show that this enables Capsule Nets to perform even better.", "published": "2018-01-14T06:48:45Z", "version": 6}, {"aid": "1801.06432", "authors": ["Mehdi Bahri", "Yannis Panagakis", "Stefanos Zafeiriou"], "title": "Robust Kronecker Component Analysis", "url": "http://arxiv.org/pdf/1801.06432v2", "summary": "Dictionary learning and component analysis models are fundamental for learning compact representations that are relevant to a given task (feature extraction, dimensionality reduction, denoising, etc.). The model complexity is encoded by means of specific structure, such as sparsity, low-rankness, or nonnegativity. Unfortunately, approaches like K-SVD - that learn dictionaries for sparse coding via Singular Value Decomposition (SVD) - are hard to scale to high-volume and high-dimensional visual data, and fragile in the presence of outliers. Conversely, robust component analysis methods such as the Robust Principal Component Analysis (RPCA) are able to recover low-complexity (e.g., low-rank) representations from data corrupted with noise of unknown magnitude and support, but do not provide a dictionary that respects the structure of the data (e.g., images), and also involve expensive computations. In this paper, we propose a novel Kronecker-decomposable component analysis model, coined as Robust Kronecker Component Analysis (RKCA), that combines ideas from sparse dictionary learning and robust component analysis. RKCA has several appealing properties, including robustness to gross corruption; it can be used for low-rank modeling, and leverages separability to solve significantly smaller problems. We design an efficient learning algorithm by drawing links with a restricted form of tensor factorization, and analyze its optimality and low-rankness properties. The effectiveness of the proposed approach is demonstrated on real-world applications, namely background subtraction and image denoising and completion, by performing a thorough comparison with the current state of the art.", "published": "2018-01-18T18:01:50Z", "version": 2}, {"aid": "1801.06434", "authors": ["Ido Freeman", "Lutz Roese-Koerner", "Anton Kummert"], "title": "EffNet: An Efficient Structure for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1801.06434v6", "summary": "With the ever increasing application of Convolutional Neural Networks to customer products the need emerges for models to efficiently run on embedded, mobile hardware. Slimmer models have therefore become a hot research topic with various approaches which vary from binary networks to revised convolution layers. We offer our contribution to the latter and propose a novel convolution block which significantly reduces the computational burden while surpassing the current state-of-the-art. Our model, dubbed EffNet, is optimised for models which are slim to begin with and is created to tackle issues in existing models such as MobileNet and ShuffleNet.", "published": "2018-01-19T14:57:23Z", "version": 6}, {"aid": "1801.06724", "authors": ["Eli Schwartz", "Raja Giryes", "Alex M. Bronstein"], "title": "DeepISP: Towards Learning an End-to-End Image Processing Pipeline", "url": "http://arxiv.org/pdf/1801.06724v2", "summary": "We present DeepISP, a full end-to-end deep neural model of the camera image signal processing (ISP) pipeline. Our model learns a mapping from the raw low-light mosaiced image to the final visually compelling image and encompasses low-level tasks such as demosaicing and denoising as well as higher-level tasks such as color correction and image adjustment. The training and evaluation of the pipeline were performed on a dedicated dataset containing pairs of low-light and well-lit images captured by a Samsung S7 smartphone camera in both raw and processed JPEG formats. The proposed solution achieves state-of-the-art performance in objective evaluation of PSNR on the subtask of joint denoising and demosaicing. For the full end-to-end pipeline, it achieves better visual quality compared to the manufacturer ISP, in both a subjective human assessment and when rated by a deep model trained for assessing image quality.", "published": "2018-01-20T20:41:05Z", "version": 2}, {"aid": "1801.07211", "authors": ["Ayan Kumar Bhunia", "Abir Bhowmick", "Ankan Kumar Bhunia", "Aishik Konwer", "Prithaj Banerjee", "Partha Pratim Roy", "Umapada Pal"], "title": "Handwriting Trajectory Recovery using End-to-End Deep Encoder-Decoder Network", "url": "http://arxiv.org/pdf/1801.07211v4", "summary": "In this paper, we introduce a novel technique to recover the pen trajectory of offline characters which is a crucial step for handwritten character recognition. Generally, online acquisition approach has more advantage than its offline counterpart as the online technique keeps track of the pen movement. Hence, pen tip trajectory retrieval from offline text can bridge the gap between online and offline methods. Our proposed framework employs sequence to sequence model which consists of an encoder-decoder LSTM module. Our encoder module consists of Convolutional LSTM network, which takes an offline character image as the input and encodes the feature sequence to a hidden representation. The output of the encoder is fed to a decoder LSTM and we get the successive coordinate points from every time step of the decoder LSTM. Although the sequence to sequence model is a popular paradigm in various computer vision and language translation tasks, the main contribution of our work lies in designing an end-to-end network for a decade old popular problem in Document Image Analysis community. Tamil, Telugu and Devanagari characters of LIPI Toolkit dataset are used for our experiments. Our proposed method has achieved superior performance compared to the other conventional approaches.", "published": "2018-01-22T17:25:05Z", "version": 4}, {"aid": "1801.07648", "authors": ["Elie Aljalbout", "Vladimir Golkov", "Yawar Siddiqui", "Maximilian Strobel", "Daniel Cremers"], "title": "Clustering with Deep Learning: Taxonomy and New Methods", "url": "http://arxiv.org/pdf/1801.07648v2", "summary": "Clustering methods based on deep neural networks have proven promising for clustering real-world data because of their high representational power. In this paper, we propose a systematic taxonomy of clustering methods that utilize deep neural networks. We base our taxonomy on a comprehensive review of recent work and validate the taxonomy in a case study. In this case study, we show that the taxonomy enables researchers and practitioners to systematically create new clustering methods by selectively recombining and replacing distinct aspects of previous methods with the goal of overcoming their individual limitations. The experimental evaluation confirms this and shows that the method created for the case study achieves state-of-the-art clustering quality and surpasses it in some cases.", "published": "2018-01-23T16:41:03Z", "version": 2}, {"aid": "1801.09858", "authors": ["Xiaoxiao Wang", "Xiao Liang", "Zhoufan Jiang", "Benedictor Alexander Nguchu", "Yawen Zhou", "Yanming Wang", "Huijuan Wang", "Yu Li", "Yuying Zhu", "Feng Wu", "Jia-Hong Gao", "Benching Qiu"], "title": "Decoding and mapping task states of the human brain via deep learning", "url": "http://arxiv.org/pdf/1801.09858v3", "summary": "Support vector machine (SVM) based multivariate pattern analysis (MVPA) has delivered promising performance in decoding specific task states based on functional magnetic resonance imaging (fMRI) of the human brain. Conventionally, the SVM-MVPA requires careful feature selection/extraction according to expert knowledge. In this study, we propose a deep neural network (DNN) for directly decoding multiple brain task states from fMRI signals of the brain without any burden for feature handcrafts. We trained and tested the DNN classifier using task fMRI data from the Human Connectome Project's S1200 dataset (N=1034). In tests to verify its performance, the proposed classification method identified seven tasks with an average accuracy of 93.7%. We also showed the general applicability of the DNN for transfer learning to small datasets (N=43), a situation encountered in typical neuroscience research. The proposed method achieved an average accuracy of 89.0% and 94.7% on a working memory task and a motor classification task, respectively, higher than the accuracy of 69.2% and 68.6% obtained by the SVM-MVPA. A network visualization analysis showed that the DNN automatically detected features from areas of the brain related to each task. Without incurring the burden of handcrafting the features, the proposed deep decoding method can classify brain task states highly accurately, and is a powerful tool for fMRI researchers.", "published": "2018-01-30T05:58:18Z", "version": 3}, {"aid": "1802.02172", "authors": ["Alexander N. Gorban", "Bogdan Grechuk", "Ivan Y. Tyukin"], "title": "Augmented Artificial Intelligence: a Conceptual Framework", "url": "http://arxiv.org/pdf/1802.02172v3", "summary": "All artificial Intelligence (AI) systems make errors. These errors are unexpected, and differ often from the typical human mistakes (\"non-human\" errors). The AI errors should be corrected without damage of existing skills and, hopefully, avoiding direct human expertise. This paper presents an initial summary report of project taking new and systematic approach to improving the intellectual effectiveness of the individual AI by communities of AIs. We combine some ideas of learning in heterogeneous multiagent systems with new and original mathematical approaches for non-iterative corrections of errors of legacy AI systems. The mathematical foundations of AI non-destructive correction are presented and a series of new stochastic separation theorems is proven. These theorems provide a new instrument for the development, analysis, and assessment of machine learning methods and algorithms in high dimension. They demonstrate that in high dimensions and even for exponentially large samples, linear classifiers in their classical Fisher's form are powerful enough to separate errors from correct responses with high probability and to provide efficient solution to the non-destructive corrector problem. In particular, we prove some hypotheses formulated in our paper `Stochastic Separation Theorems' (Neural Networks, 94, 255--259, 2017), and answer one general problem published by Donoho and Tanner in 2009.", "published": "2018-02-06T19:05:27Z", "version": 3}, {"aid": "1802.02375", "authors": ["Yoshihiro Yamada", "Masakazu Iwamura", "Takuya Akiba", "Koichi Kise"], "title": "ShakeDrop Regularization for Deep Residual Learning", "url": "http://arxiv.org/pdf/1802.02375v3", "summary": "Overfitting is a crucial problem in deep neural networks, even in the latest network architectures. In this paper, to relieve the overfitting effect of ResNet and its improvements (i.e., Wide ResNet, PyramidNet, and ResNeXt), we propose a new regularization method called ShakeDrop regularization. ShakeDrop is inspired by Shake-Shake, which is an effective regularization method, but can be applied to ResNeXt only. ShakeDrop is more effective than Shake-Shake and can be applied not only to ResNeXt but also ResNet, Wide ResNet, and PyramidNet. An important key is to achieve stability of training. Because effective regularization often causes unstable training, we introduce a training stabilizer, which is an unusual use of an existing regularizer. Through experiments under various conditions, we demonstrate the conditions under which ShakeDrop works well.", "published": "2018-02-07T10:23:54Z", "version": 3}, {"aid": "1802.02952", "authors": ["Shoaib Ahmed Siddiqui", "Dominik Mercier", "Mohsin Munir", "Andreas Dengel", "Sheraz Ahmed"], "title": "TSViz: Demystification of Deep Learning Models for Time-Series Analysis", "url": "http://arxiv.org/pdf/1802.02952v3", "summary": "This paper presents a novel framework for demystification of convolutional deep learning models for time-series analysis. This is a step towards making informed/explainable decisions in the domain of time-series, powered by deep learning. There have been numerous efforts to increase the interpretability of image-centric deep neural network models, where the learned features are more intuitive to visualize. Visualization in time-series domain is much more complicated as there is no direct interpretation of the filters and inputs as compared to the image modality. In addition, little or no concentration has been devoted for the development of such tools in the domain of time-series in the past. TSViz provides possibilities to explore and analyze a network from different dimensions at different levels of abstraction which includes identification of parts of the input that were responsible for a prediction (including per filter saliency), importance of different filters present in the network for a particular prediction, notion of diversity present in the network through filter clustering, understanding of the main sources of variation learnt by the network through inverse optimization, and analysis of the network's robustness against adversarial noise. As a sanity check for the computed influence values, we demonstrate results regarding pruning of neural networks based on the computed influence information. These representations allow to understand the network features so that the acceptability of deep networks for time-series data can be enhanced. This is extremely important in domains like finance, industry 4.0, self-driving cars, health-care, counter-terrorism etc., where reasons for reaching a particular prediction are equally important as the prediction itself. We assess the proposed framework for interpretability with a set of desirable properties essential for any method.", "published": "2018-02-08T16:29:49Z", "version": 3}, {"aid": "1802.05160", "authors": ["Xiaolin Wu", "Xi Zhang", "Xiao Shu"], "title": "Cognitive Deficit of Deep Learning in Numerosity", "url": "http://arxiv.org/pdf/1802.05160v4", "summary": "Subitizing, or the sense of small natural numbers, is an innate cognitive function of humans and primates; it responds to visual stimuli prior to the development of any symbolic skills, language or arithmetic. Given successes of deep learning (DL) in tasks of visual intelligence and given the primitivity of number sense, a tantalizing question is whether DL can comprehend numbers and perform subitizing. But somewhat disappointingly, extensive experiments of the type of cognitive psychology demonstrate that the examples-driven black box DL cannot see through superficial variations in visual representations and distill the abstract notion of natural number, a task that children perform with high accuracy and confidence. The failure is apparently due to the learning method not the CNN computational machinery itself. A recurrent neural network capable of subitizing does exist, which we construct by encoding a mechanism of mathematical morphology into the CNN convolutional kernels. Also, we investigate, using subitizing as a test bed, the ways to aid the black box DL by cognitive priors derived from human insight. Our findings are mixed and interesting, pointing to both cognitive deficit of pure DL, and some measured successes of boosting DL by predetermined cognitive implements. This case study of DL in cognitive computing is meaningful for visual numerosity represents a minimum level of human intelligence.", "published": "2018-02-09T15:01:52Z", "version": 4}, {"aid": "1802.03596", "authors": ["Fengwei Zhou", "Bin Wu", "Zhenguo Li"], "title": "Deep Meta-Learning: Learning to Learn in the Concept Space", "url": "http://arxiv.org/pdf/1802.03596v1", "summary": "Few-shot learning remains challenging for meta-learning that learns a learning algorithm (meta-learner) from many related tasks. In this work, we argue that this is due to the lack of a good representation for meta-learning, and propose deep meta-learning to integrate the representation power of deep learning into meta-learning. The framework is composed of three modules, a concept generator, a meta-learner, and a concept discriminator, which are learned jointly. The concept generator, e.g. a deep residual net, extracts a representation for each instance that captures its high-level concept, on which the meta-learner performs few-shot learning, and the concept discriminator recognizes the concepts. By learning to learn in the concept space rather than in the complicated instance space, deep meta-learning can substantially improve vanilla meta-learning, which is demonstrated on various few-shot image recognition problems. For example, on 5-way-1-shot image recognition on CIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to 58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%, and improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%, respectively.", "published": "2018-02-10T14:18:08Z", "version": 1}, {"aid": "1802.03654", "authors": ["Yonathan Efroni", "Gal Dalal", "Bruno Scherrer", "Shie Mannor"], "title": "Beyond the One Step Greedy Approach in Reinforcement Learning", "url": "http://arxiv.org/pdf/1802.03654v3", "summary": "The famous Policy Iteration algorithm alternates between policy improvement and policy evaluation. Implementations of this algorithm with several variants of the latter evaluation stage, e.g, $n$-step and trace-based returns, have been analyzed in previous works. However, the case of multiple-step lookahead policy improvement, despite the recent increase in empirical evidence of its strength, has to our knowledge not been carefully analyzed yet. In this work, we introduce the first such analysis. Namely, we formulate variants of multiple-step policy improvement, derive new algorithms using these definitions and prove their convergence. Moreover, we show that recent prominent Reinforcement Learning algorithms are, in fact, instances of our framework. We thus shed light on their empirical success and give a recipe for deriving new algorithms for future study.", "published": "2018-02-10T22:22:03Z", "version": 3}, {"aid": "1802.03996", "authors": ["Xiang Zhang", "Lina Yao", "Xianzhi Wang", "Wenjie Zhang", "Shuai Zhang", "Yunhao Liu"], "title": "Know Your Mind: Adaptive Brain Signal Classification with Reinforced Attentive Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1802.03996v5", "summary": "Electroencephalography (EEG) signals reflect activities on certain brain areas. Effective classification of time-varying EEG signals is still challenging. First, EEG signal processing and feature engineering are time-consuming and highly rely on expert knowledge. In addition, most existing studies focus on domain-specific classification algorithms which may not be applicable to other domains. Moreover, the EEG signal usually has a low signal-to-noise ratio and can be easily corrupted. In this regard, we propose a generic EEG signal classification framework that accommodates a wide range of applications to address the aforementioned issues. The proposed framework develops a reinforced selective attention model to automatically choose the distinctive information among the raw EEG signals. A convolutional mapping operation is employed to dynamically transform the selected information to an over-complete feature space, wherein implicit spatial dependency of EEG samples distribution is able to be uncovered. We demonstrate the effectiveness of the proposed framework using three representative scenarios: intention recognition with motor imagery EEG, person identification, and neurological diagnosis. Three widely used public datasets and a local dataset are used for our evaluation. The experiments show that our framework outperforms the state-of-the-art baselines and achieves the accuracy of more than 97% on all the datasets with low latency and good resilience of handling complex EEG signals across various domains. These results confirm the suitability of the proposed generic approach for a range of problems in the realm of Brain-Computer Interface applications.", "published": "2018-02-12T11:59:40Z", "version": 5}, {"aid": "1802.05098", "authors": ["Jakob Foerster", "Gregory Farquhar", "Maruan Al-Shedivat", "Tim Rockt\u00e4schel", "Eric P. Xing", "Shimon Whiteson"], "title": "DiCE: The Infinitely Differentiable Monte-Carlo Estimator", "url": "http://arxiv.org/pdf/1802.05098v3", "summary": "The score function estimator is widely used for estimating gradients of stochastic objectives in stochastic computation graphs (SCG), eg, in reinforcement learning and meta-learning. While deriving the first-order gradient estimators by differentiating a surrogate loss (SL) objective is computationally and conceptually simple, using the same approach for higher-order derivatives is more challenging. Firstly, analytically deriving and implementing such estimators is laborious and not compliant with automatic differentiation. Secondly, repeatedly applying SL to construct new objectives for each order derivative involves increasingly cumbersome graph manipulations. Lastly, to match the first-order gradient under differentiation, SL treats part of the cost as a fixed sample, which we show leads to missing and wrong terms for estimators of higher-order derivatives. To address all these shortcomings in a unified way, we introduce DiCE, which provides a single objective that can be differentiated repeatedly, generating correct estimators of derivatives of any order in SCGs. Unlike SL, DiCE relies on automatic differentiation for performing the requisite graph manipulations. We verify the correctness of DiCE both through a proof and numerical evaluation of the DiCE derivative estimates. We also use DiCE to propose and evaluate a novel approach for multi-agent learning. Our code is available at https://www.github.com/alshedivat/lola.", "published": "2018-02-14T14:05:54Z", "version": 3}, {"aid": "1802.05384", "authors": ["Thibault Groueix", "Matthew Fisher", "Vladimir G. Kim", "Bryan C. Russell", "Mathieu Aubry"], "title": "AtlasNet: A Papier-M\u00e2ch\u00e9 Approach to Learning 3D Surface Generation", "url": "http://arxiv.org/pdf/1802.05384v3", "summary": "We introduce a method for learning to generate the surface of 3D shapes. Our approach represents a 3D shape as a collection of parametric surface elements and, in contrast to methods generating voxel grids or point clouds, naturally infers a surface representation of the shape. Beyond its novelty, our new shape generation framework, AtlasNet, comes with significant advantages, such as improved precision and generalization capabilities, and the possibility to generate a shape of arbitrary resolution without memory issues. We demonstrate these benefits and compare to strong baselines on the ShapeNet benchmark for two applications: (i) auto-encoding shapes, and (ii) single-view reconstruction from a still image. We also provide results showing its potential for other applications, such as morphing, parametrization, super-resolution, matching, and co-segmentation.", "published": "2018-02-15T02:07:30Z", "version": 3}, {"aid": "1802.05584", "authors": ["Il Yong Chun", "Jeffrey A. Fessler"], "title": "Convolutional Analysis Operator Learning: Acceleration and Convergence", "url": "http://arxiv.org/pdf/1802.05584v7", "summary": "Convolutional operator learning is gaining attention in many signal processing and computer vision applications. Learning kernels has mostly relied on so-called patch-domain approaches that extract and store many overlapping patches across training signals. Due to memory demands, patch-domain methods have limitations when learning kernels from large datasets -- particularly with multi-layered structures, e.g., convolutional neural networks -- or when applying the learned kernels to high-dimensional signal recovery problems. The so-called convolution approach does not store many overlapping patches, and thus overcomes the memory problems particularly with careful algorithmic designs; it has been studied within the \"synthesis\" signal model, e.g., convolutional dictionary learning. This paper proposes a new convolutional analysis operator learning (CAOL) framework that learns an analysis sparsifying regularizer with the convolution perspective, and develops a new convergent Block Proximal Extrapolated Gradient method using a Majorizer (BPEG-M) to solve the corresponding block multi-nonconvex problems. To learn diverse filters within the CAOL framework, this paper introduces an orthogonality constraint that enforces a tight-frame filter condition, and a regularizer that promotes diversity between filters. Numerical experiments show that, with sharp majorizers, BPEG-M significantly accelerates the CAOL convergence rate compared to the state-of-the-art block proximal gradient (BPG) method. Numerical experiments for sparse-view computational tomography show that a convolutional sparsifying regularizer learned via CAOL significantly improves reconstruction quality compared to a conventional edge-preserving regularizer. Using more and wider kernels in a learned regularizer better preserves edges in reconstructed images.", "published": "2018-02-15T14:51:38Z", "version": 7}, {"aid": "1802.09904", "authors": ["Hector Zenil", "Narsis A. Kiani", "Allan A. Zea", "Jesper Tegn\u00e9r"], "title": "Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism", "url": "http://arxiv.org/pdf/1802.09904v8", "summary": "Complex data usually results from the interaction of objects produced by different generating mechanisms. Here we introduce a universal, unsupervised and parameter-free model-oriented approach, based upon the seminal concept of algorithmic probability, that decomposes an observation into its most likely algorithmic generative sources. Our approach uses a causal calculus to infer model representations. We demonstrate its ability to deconvolve interacting mechanisms regardless of whether the resultant objects are strings, space-time evolution diagrams, images or networks. While this is mostly a conceptual contribution and a novel framework, we provide numerical evidence evaluating the ability of our methods to separate data from observations produced by discrete dynamical systems such as cellular automata and complex networks. We think that these separating techniques can contribute to tackling the challenge of causation, thus complementing other statistically oriented approaches.", "published": "2018-02-18T08:06:13Z", "version": 8}, {"aid": "1802.06891", "authors": ["Matthew Fellows", "Kamil Ciosek", "Shimon Whiteson"], "title": "Fourier Policy Gradients", "url": "http://arxiv.org/pdf/1802.06891v2", "summary": "We propose a new way of deriving policy gradient updates for reinforcement learning. Our technique, based on Fourier analysis, recasts integrals that arise with expected policy gradients as convolutions and turns them into multiplications. The obtained analytical solutions allow us to capture the low variance benefits of EPG in a broad range of settings. For the critic, we treat trigonometric and radial basis functions, two function families with the universal approximation property. The choice of policy can be almost arbitrary, including mixtures or hybrid continuous-discrete probability distributions. Moreover, we derive a general family of sample-based estimators for stochastic policy gradients, which unifies existing results on sample-based approximation. We believe that this technique has the potential to shape the next generation of policy gradient approaches, powered by analytical results.", "published": "2018-02-19T22:28:56Z", "version": 2}, {"aid": "1802.06955", "authors": ["Md Zahangir Alom", "Mahmudul Hasan", "Chris Yakopcic", "Tarek M. Taha", "Vijayan K. Asari"], "title": "Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation", "url": "http://arxiv.org/pdf/1802.06955v5", "summary": "Deep learning (DL) based semantic segmentation methods have been providing state-of-the-art performance in the last few years. More specifically, these techniques have been successfully applied to medical image classification, segmentation, and detection tasks. One deep learning technique, U-Net, has become one of the most popular for these applications. In this paper, we propose a Recurrent Convolutional Neural Network (RCNN) based on U-Net as well as a Recurrent Residual Convolutional Neural Network (RRCNN) based on U-Net models, which are named RU-Net and R2U-Net respectively. The proposed models utilize the power of U-Net, Residual Network, as well as RCNN. There are several advantages of these proposed architectures for segmentation tasks. First, a residual unit helps when training deep architecture. Second, feature accumulation with recurrent residual convolutional layers ensures better feature representation for segmentation tasks. Third, it allows us to design better U-Net architecture with same number of network parameters with better performance for medical image segmentation. The proposed models are tested on three benchmark datasets such as blood vessel segmentation in retina images, skin cancer segmentation, and lung lesion segmentation. The experimental results show superior performance on segmentation tasks compared to equivalent models including U-Net and residual U-Net (ResU-Net).", "published": "2018-02-20T03:59:39Z", "version": 5}, {"aid": "1802.07303", "authors": ["Mengran Gou", "Fei Xiong", "Octavia Camps", "Mario Sznaier"], "title": "MoNet: Moments Embedding Network", "url": "http://arxiv.org/pdf/1802.07303v2", "summary": "Bilinear pooling has been recently proposed as a feature encoding layer, which can be used after the convolutional layers of a deep network, to improve performance in multiple vision tasks. Different from conventional global average pooling or fully connected layer, bilinear pooling gathers 2nd order information in a translation invariant fashion. However, a serious drawback of this family of pooling layers is their dimensionality explosion. Approximate pooling methods with compact properties have been explored towards resolving this weakness. Additionally, recent results have shown that significant performance gains can be achieved by adding 1st order information and applying matrix normalization to regularize unstable higher order information. However, combining compact pooling with matrix normalization and other order information has not been explored until now. In this paper, we unify bilinear pooling and the global Gaussian embedding layers through the empirical moment matrix. In addition, we propose a novel sub-matrix square-root layer, which can be used to normalize the output of the convolution layer directly and mitigate the dimensionality problem with off-the-shelf compact pooling methods. Our experiments on three widely used fine-grained classification datasets illustrate that our proposed architecture, MoNet, can achieve similar or better performance than with the state-of-art G2DeNet. Furthermore, when combined with compact pooling technique, MoNet obtains comparable performance with encoded features with 96% less dimensions.", "published": "2018-02-20T19:54:58Z", "version": 2}, {"aid": "1802.08797", "authors": ["Yulun Zhang", "Yapeng Tian", "Yu Kong", "Bineng Zhong", "Yun Fu"], "title": "Residual Dense Network for Image Super-Resolution", "url": "http://arxiv.org/pdf/1802.08797v2", "summary": "A very deep convolutional neural network (CNN) has recently achieved great success for image super-resolution (SR) and offered hierarchical features as well. However, most deep CNN based SR models do not make full use of the hierarchical features from the original low-resolution (LR) images, thereby achieving relatively-low performance. In this paper, we propose a novel residual dense network (RDN) to address this problem in image SR. We fully exploit the hierarchical features from all the convolutional layers. Specifically, we propose residual dense block (RDB) to extract abundant local features via dense connected convolutional layers. RDB further allows direct connections from the state of preceding RDB to all the layers of current RDB, leading to a contiguous memory (CM) mechanism. Local feature fusion in RDB is then used to adaptively learn more effective features from preceding and current local features and stabilizes the training of wider network. After fully obtaining dense local features, we use global feature fusion to jointly and adaptively learn global hierarchical features in a holistic way. Extensive experiments on benchmark datasets with different degradation models show that our RDN achieves favorable performance against state-of-the-art methods.", "published": "2018-02-24T04:40:06Z", "version": 2}, {"aid": "1802.08831", "authors": ["Mai Zhu", "Bo Chang", "Chong Fu"], "title": "Convolutional Neural Networks combined with Runge-Kutta Methods", "url": "http://arxiv.org/pdf/1802.08831v7", "summary": "A convolutional neural network can be constructed using numerical methods for solving dynamical systems, since the forward pass of the network can be regarded as a trajectory of a dynamical system. However, existing models based on numerical solvers cannot avoid the iterations of implicit methods, which makes the models inefficient at inference time. In this paper, we reinterpret the pre-activation Residual Networks (ResNets) and their variants from the dynamical systems view. We consider that the iterations of implicit Runge-Kutta methods are fused into the training of these models. Moreover, we propose a novel approach to constructing network models based on high-order Runge-Kutta methods in order to achieve higher efficiency. Our proposed models are referred to as the Runge-Kutta Convolutional Neural Networks (RKCNNs). The RKCNNs are evaluated on multiple benchmark datasets. The experimental results show that RKCNNs are vastly superior to other dynamical system network models: they achieve higher accuracy with much fewer resources. They also expand the family of network models based on numerical methods for dynamical systems.", "published": "2018-02-24T10:31:24Z", "version": 7}, {"aid": "1802.09030", "authors": ["Uri Patish", "Shimon Ullman"], "title": "Cakewalk Sampling", "url": "http://arxiv.org/pdf/1802.09030v2", "summary": "We study the task of finding good local optima in combinatorial optimization problems. Although combinatorial optimization is NP-hard in general, locally optimal solutions are frequently used in practice. Local search methods however typically converge to a limited set of optima that depend on their initialization. Sampling methods on the other hand can access any valid solution, and thus can be used either directly or alongside methods of the former type as a way for finding good local optima. Since the effectiveness of this strategy depends on the sampling distribution, we derive a robust learning algorithm that adapts sampling distributions towards good local optima of arbitrary objective functions. As a first use case, we empirically study the efficiency in which sampling methods can recover locally maximal cliques in undirected graphs. Not only do we show how our adaptive sampler outperforms related methods, we also show how it can even approach the performance of established clique algorithms. As a second use case, we consider how greedy algorithms can be combined with our adaptive sampler, and we demonstrate how this leads to superior performance in k-medoid clustering. Together, these findings suggest that our adaptive sampler can provide an effective strategy to combinatorial optimization problems that arise in practice.", "published": "2018-02-25T16:15:32Z", "version": 2}, {"aid": "1802.09766", "authors": ["Rana Ali Amjad", "Bernhard C. Geiger"], "title": "Learning Representations for Neural Network-Based Classification Using the Information Bottleneck Principle", "url": "http://arxiv.org/pdf/1802.09766v6", "summary": "In this theory paper, we investigate training deep neural networks (DNNs) for classification via minimizing the information bottleneck (IB) functional. We show that the resulting optimization problem suffers from two severe issues: First, for deterministic DNNs, either the IB functional is infinite for almost all values of network parameters, making the optimization problem ill-posed, or it is piecewise constant, hence not admitting gradient-based optimization methods. Second, the invariance of the IB functional under bijections prevents it from capturing properties of the learned representation that are desirable for classification, such as robustness and simplicity. We argue that these issues are partly resolved for stochastic DNNs, DNNs that include a (hard or soft) decision rule, or by replacing the IB functional with related, but more well-behaved cost functions. We conclude that recent successes reported about training DNNs using the IB framework must be attributed to such solutions. As a side effect, our results indicate limitations of the IB framework for the analysis of DNNs. We also note that rather than trying to repair the inherent problems in the IB functional, a better approach may be to design regularizers on latent representation enforcing the desired properties directly.", "published": "2018-02-27T08:24:19Z", "version": 6}, {"aid": "1802.10055", "authors": ["Jaejun Yoo", "Abdul Wahab", "Jong Chul Ye"], "title": "A Mathematical Framework for Deep Learning in Elastic Source Imaging", "url": "http://arxiv.org/pdf/1802.10055v3", "summary": "An inverse elastic source problem with sparse measurements is of concern. A generic mathematical framework is proposed which incorporates a low- dimensional manifold regularization in the conventional source reconstruction algorithms thereby enhancing their performance with sparse datasets. It is rigorously established that the proposed framework is equivalent to the so-called \\emph{deep convolutional framelet expansion} in machine learning literature for inverse problems. Apposite numerical examples are furnished to substantiate the efficacy of the proposed framework.", "published": "2018-02-27T18:14:00Z", "version": 3}, {"aid": "1802.10204", "authors": ["Atefeh Shahroudnejad", "Arash Mohammadi", "Konstantinos N. Plataniotis"], "title": "Improved Explainability of Capsule Networks: Relevance Path by Agreement", "url": "http://arxiv.org/pdf/1802.10204v1", "summary": "Recent advancements in signal processing and machine learning domains have resulted in an extensive surge of interest in deep learning models due to their unprecedented performance and high accuracy for different and challenging problems of significant engineering importance. However, when such deep learning architectures are utilized for making critical decisions such as the ones that involve human lives (e.g., in medical applications), it is of paramount importance to understand, trust, and in one word \"explain\" the rational behind deep models' decisions. Currently, deep learning models are typically considered as black-box systems, which do not provide any clue on their internal processing actions. Although some recent efforts have been initiated to explain behavior and decisions of deep networks, explainable artificial intelligence (XAI) domain is still in its infancy. In this regard, we consider capsule networks (referred to as CapsNets), which are novel deep structures; recently proposed as an alternative counterpart to convolutional neural networks (CNNs), and posed to change the future of machine intelligence. In this paper, we investigate and analyze structures and behaviors of the CapsNets and illustrate potential explainability properties of such networks. Furthermore, we show possibility of transforming deep learning architectures in to transparent networks via incorporation of capsules in different layers instead of convolution layers of the CNNs.", "published": "2018-02-27T23:08:17Z", "version": 1}, {"aid": "1803.00094", "authors": ["Quynh Nguyen", "Mahesh Chandra Mukkamala", "Matthias Hein"], "title": "Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions", "url": "http://arxiv.org/pdf/1803.00094v3", "summary": "In the recent literature the important role of depth in deep learning has been emphasized. In this paper we argue that sufficient width of a feedforward network is equally important by answering the simple question under which conditions the decision regions of a neural network are connected. It turns out that for a class of activation functions including leaky ReLU, neural networks having a pyramidal structure, that is no layer has more hidden units than the input dimension, produce necessarily connected decision regions. This implies that a sufficiently wide hidden layer is necessary to guarantee that the network can produce disconnected decision regions. We discuss the implications of this result for the construction of neural networks, in particular the relation to the problem of adversarial manipulation of classifiers.", "published": "2018-02-28T21:28:28Z", "version": 3}, {"aid": "1803.00197", "authors": ["Xingyu Chen", "Junzhi Yu", "Zhengxing Wu"], "title": "Temporally Identity-Aware SSD with Attentional LSTM", "url": "http://arxiv.org/pdf/1803.00197v4", "summary": "Temporal object detection has attracted significant attention, but most popular detection methods cannot leverage rich temporal information in videos. Very recently, many algorithms have been developed for video detection task, yet very few approaches can achieve \\emph{real-time online} object detection in videos. In this paper, based on attention mechanism and convolutional long short-term memory (ConvLSTM), we propose a temporal single-shot detector (TSSD) for real-world detection. Distinct from previous methods, we take aim at temporally integrating pyramidal feature hierarchy using ConvLSTM, and design a novel structure including a low-level temporal unit as well as a high-level one (LH-TU) for multi-scale feature maps. Moreover, we develop a creative temporal analysis unit, namely, attentional ConvLSTM (AC-LSTM), in which a temporal attention mechanism is specially tailored for background suppression and scale suppression while a ConvLSTM integrates attention-aware features across time. An association loss and a multi-step training are designed for temporal coherence. Besides, an online tubelet analysis (OTA) is exploited for identification. Our framework is evaluated on ImageNet VID dataset and 2DMOT15 dataset. Extensive comparisons on the detection and tracking capability validate the superiority of the proposed approach. Consequently, the developed TSSD-OTA achieves a fast speed and an overall competitive performance in terms of detection and tracking. Finally, a real-world maneuver is conducted for underwater object grasping. The source code is publicly available at https://github.com/SeanChenxy/TSSD-OTA.", "published": "2018-03-01T03:48:07Z", "version": 4}, {"aid": "1803.00702", "authors": ["Emad M. Grais", "Dominic Ward", "Mark D. Plumbley"], "title": "Raw Multi-Channel Audio Source Separation using Multi-Resolution Convolutional Auto-Encoders", "url": "http://arxiv.org/pdf/1803.00702v1", "summary": "Supervised multi-channel audio source separation requires extracting useful spectral, temporal, and spatial features from the mixed signals. The success of many existing systems is therefore largely dependent on the choice of features used for training. In this work, we introduce a novel multi-channel, multi-resolution convolutional auto-encoder neural network that works on raw time-domain signals to determine appropriate multi-resolution features for separating the singing-voice from stereo music. Our experimental results show that the proposed method can achieve multi-channel audio source separation without the need for hand-crafted features or any pre- or post-processing.", "published": "2018-03-02T03:47:47Z", "version": 1}, {"aid": "1803.00830", "authors": ["Ruijia Xu", "Ziliang Chen", "Wangmeng Zuo", "Junjie Yan", "Liang Lin"], "title": "Deep Cocktail Network: Multi-source Unsupervised Domain Adaptation with Category Shift", "url": "http://arxiv.org/pdf/1803.00830v1", "summary": "Unsupervised domain adaptation (UDA) conventionally assumes labeled source samples coming from a single underlying source distribution. Whereas in practical scenario, labeled data are typically collected from diverse sources. The multiple sources are different not only from the target but also from each other, thus, domain adaptater should not be modeled in the same way. Moreover, those sources may not completely share their categories, which further brings a new transfer challenge called category shift. In this paper, we propose a deep cocktail network (DCTN) to battle the domain and category shifts among multiple sources. Motivated by the theoretical results in \\cite{mansour2009domain}, the target distribution can be represented as the weighted combination of source distributions, and, the multi-source unsupervised domain adaptation via DCTN is then performed as two alternating steps: i) It deploys multi-way adversarial learning to minimize the discrepancy between the target and each of the multiple source domains, which also obtains the source-specific perplexity scores to denote the possibilities that a target sample belongs to different source domains. ii) The multi-source category classifiers are integrated with the perplexity scores to classify target sample, and the pseudo-labeled target samples together with source samples are utilized to update the multi-source category classifier and the feature extractor. We evaluate DCTN in three domain adaptation benchmarks, which clearly demonstrate the superiority of our framework.", "published": "2018-03-02T12:58:51Z", "version": 1}, {"aid": "1803.01164", "authors": ["Md Zahangir Alom", "Tarek M. Taha", "Christopher Yakopcic", "Stefan Westberg", "Paheding Sidike", "Mst Shamima Nasrin", "Brian C Van Esesn", "Abdul A S. Awwal", "Vijayan K. Asari"], "title": "The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches", "url": "http://arxiv.org/pdf/1803.01164v2", "summary": "Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].", "published": "2018-03-03T13:46:40Z", "version": 2}, {"aid": "1803.01216", "authors": ["Matthias Rottmann", "Karsten Kahl", "Hanno Gottschalk"], "title": "Deep Bayesian Active Semi-Supervised Learning", "url": "http://arxiv.org/pdf/1803.01216v1", "summary": "In many applications the process of generating label information is expensive and time consuming. We present a new method that combines active and semi-supervised deep learning to achieve high generalization performance from a deep convolutional neural network with as few known labels as possible. In a setting where a small amount of labeled data as well as a large amount of unlabeled data is available, our method first learns the labeled data set. This initialization is followed by an expectation maximization algorithm, where further training reduces classification entropy on the unlabeled data by targeting a low entropy fit which is consistent with the labeled data. In addition the algorithm asks at a specified frequency an oracle for labels of data with entropy above a certain entropy quantile. Using this active learning component we obtain an agile labeling process that achieves high accuracy, but requires only a small amount of known labels. For the MNIST dataset we report an error rate of 2.06% using only 300 labels and 1.06% for 1000 labels. These results are obtained without employing any special network architecture or data augmentation.", "published": "2018-03-03T19:13:40Z", "version": 1}, {"aid": "1803.01364", "authors": ["Arief Koesdwiady", "Fakhri Karray"], "title": "SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary Time Series Prediction", "url": "http://arxiv.org/pdf/1803.01364v2", "summary": "This paper presents a practical approach for detecting non-stationarity in time series prediction. This method is called SAFE and works by monitoring the evolution of the spectral contents of time series through a distance function. This method is designed to work in combination with state-of-the-art machine learning methods in real time by informing the online predictors to perform necessary adaptation when a non-stationarity presents. We also propose an algorithm to proportionally include some past data in the adaption process to overcome the Catastrophic Forgetting problem. To validate our hypothesis and test the effectiveness of our approach, we present comprehensive experiments in different elements of the approach involving artificial and real-world datasets. The experiments show that the proposed method is able to significantly save computational resources in term of processor or GPU cycles while maintaining high prediction performances.", "published": "2018-03-04T14:55:33Z", "version": 2}, {"aid": "1803.01417", "authors": ["Yuhua Chen", "Feng Shi", "Anthony G. Christodoulou", "Zhengwei Zhou", "Yibin Xie", "Debiao Li"], "title": "Efficient and Accurate MRI Super-Resolution using a Generative Adversarial Network and 3D Multi-Level Densely Connected Network", "url": "http://arxiv.org/pdf/1803.01417v3", "summary": "High-resolution (HR) magnetic resonance images (MRI) provide detailed anatomical information important for clinical application and quantitative image analysis. However, HR MRI conventionally comes at the cost of longer scan time, smaller spatial coverage, and lower signal-to-noise ratio (SNR). Recent studies have shown that single image super-resolution (SISR), a technique to recover HR details from one single low-resolution (LR) input image, could provide high-quality image details with the help of advanced deep convolutional neural networks (CNN). However, deep neural networks consume memory heavily and run slowly, especially in 3D settings. In this paper, we propose a novel 3D neural network design, namely a multi-level densely connected super-resolution network (mDCSRN) with generative adversarial network (GAN)-guided training. The mDCSRN quickly trains and inferences and the GAN promotes realistic output hardly distinguishable from original HR images. Our results from experiments on a dataset with 1,113 subjects show that our new architecture beats other popular deep learning methods in recovering 4x resolution-downgraded im-ages and runs 6x faster.", "published": "2018-03-04T20:45:06Z", "version": 3}, {"aid": "1803.01449", "authors": ["Sohil Atul Shah", "Vladlen Koltun"], "title": "Deep Continuous Clustering", "url": "http://arxiv.org/pdf/1803.01449v1", "summary": "Clustering high-dimensional datasets is hard because interpoint distances become less informative in high-dimensional spaces. We present a clustering algorithm that performs nonlinear dimensionality reduction and clustering jointly. The data is embedded into a lower-dimensional space by a deep autoencoder. The autoencoder is optimized as part of the clustering process. The resulting network produces clustered data. The presented approach does not rely on prior knowledge of the number of ground-truth clusters. Joint nonlinear dimensionality reduction and clustering are formulated as optimization of a global continuous objective. We thus avoid discrete reconfigurations of the objective that characterize prior clustering algorithms. Experiments on datasets from multiple domains demonstrate that the presented algorithm outperforms state-of-the-art clustering schemes, including recent methods that use deep networks.", "published": "2018-03-05T01:15:38Z", "version": 1}, {"aid": "1803.01489", "authors": ["Ahmed Hefny", "Zita Marinho", "Wen Sun", "Siddhartha Srinivasa", "Geoffrey Gordon"], "title": "Recurrent Predictive State Policy Networks", "url": "http://arxiv.org/pdf/1803.01489v1", "summary": "We introduce Recurrent Predictive State Policy (RPSP) networks, a recurrent architecture that brings insights from predictive state representations to reinforcement learning in partially observable environments. Predictive state policy networks consist of a recursive filter, which keeps track of a belief about the state of the environment, and a reactive policy that directly maps beliefs to actions, to maximize the cumulative reward. The recursive filter leverages predictive state representations (PSRs) (Rosencrantz and Gordon, 2004; Sun et al., 2016) by modeling predictive state-- a prediction of the distribution of future observations conditioned on history and future actions. This representation gives rise to a rich class of statistically consistent algorithms (Hefny et al., 2018) to initialize the recursive filter. Predictive state serves as an equivalent representation of a belief state. Therefore, the policy component of the RPSP-network can be purely reactive, simplifying training while still allowing optimal behaviour. Moreover, we use the PSR interpretation during training as well, by incorporating prediction error in the loss function. The entire network (recursive filter and reactive policy) is still differentiable and can be trained using gradient based methods. We optimize our policy using a combination of policy gradient based on rewards (Williams, 1992) and gradient descent based on prediction error. We show the efficacy of RPSP-networks under partial observability on a set of robotic control tasks from OpenAI Gym. We empirically show that RPSP-networks perform well compared with memory-preserving networks such as GRUs, as well as finite memory models, being the overall best performing method.", "published": "2018-03-05T03:59:48Z", "version": 1}, {"aid": "1803.01719", "authors": ["Boris Hanin", "David Rolnick"], "title": "How to Start Training: The Effect of Initialization and Architecture", "url": "http://arxiv.org/pdf/1803.01719v3", "summary": "We identify and study two common failure modes for early training in deep ReLU nets. For each we give a rigorous proof of when it occurs and how to avoid it, for fully connected and residual architectures. The first failure mode, exploding/vanishing mean activation length, can be avoided by initializing weights from a symmetric distribution with variance 2/fan-in and, for ResNets, by correctly weighting the residual modules. We prove that the second failure mode, exponentially large variance of activation length, never occurs in residual nets once the first failure mode is avoided. In contrast, for fully connected nets, we prove that this failure mode can happen and is avoided by keeping constant the sum of the reciprocals of layer widths. We demonstrate empirically the effectiveness of our theoretical results in predicting when networks are able to start training. In particular, we note that many popular initializations fail our criteria, whereas correct initialization and architecture allows much deeper networks to be trained.", "published": "2018-03-05T15:17:50Z", "version": 3}, {"aid": "1803.01837", "authors": ["Chen-Hsuan Lin", "Ersin Yumer", "Oliver Wang", "Eli Shechtman", "Simon Lucey"], "title": "ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing", "url": "http://arxiv.org/pdf/1803.01837v1", "summary": "We address the problem of finding realistic geometric corrections to a foreground object such that it appears natural when composited into a background image. To achieve this, we propose a novel Generative Adversarial Network (GAN) architecture that utilizes Spatial Transformer Networks (STNs) as the generator, which we call Spatial Transformer GANs (ST-GANs). ST-GANs seek image realism by operating in the geometric warp parameter space. In particular, we exploit an iterative STN warping scheme and propose a sequential training strategy that achieves better results compared to naive training of a single generator. One of the key advantages of ST-GAN is its applicability to high-resolution images indirectly since the predicted warp parameters are transferable between reference frames. We demonstrate our approach in two applications: (1) visualizing how indoor furniture (e.g. from product images) might be perceived in a room, (2) hallucinating how accessories like glasses would look when matched with real portraits.", "published": "2018-03-05T18:59:01Z", "version": 1}, {"aid": "1803.02129", "authors": ["Felix Altenberger", "Claus Lenz"], "title": "A Non-Technical Survey on Deep Convolutional Neural Network Architectures", "url": "http://arxiv.org/pdf/1803.02129v1", "summary": "Artificial neural networks have recently shown great results in many disciplines and a variety of applications, including natural language understanding, speech processing, games and image data generation. One particular application in which the strong performance of artificial neural networks was demonstrated is the recognition of objects in images, where deep convolutional neural networks are commonly applied. In this survey, we give a comprehensive introduction to this topic (object recognition with deep convolutional neural networks), with a strong focus on the evolution of network architectures. Therefore, we aim to compress the most important concepts in this field in a simple and non-technical manner to allow for future researchers to have a quick general understanding.   This work is structured as follows:   1. We will explain the basic ideas of (convolutional) neural networks and deep learning and examine their usage for three object recognition tasks: image classification, object localization and object detection.   2. We give a review on the evolution of deep convolutional neural networks by providing an extensive overview of the most important network architectures presented in chronological order of their appearances.", "published": "2018-03-06T11:40:46Z", "version": 1}, {"aid": "1803.02579", "authors": ["Abhijit Guha Roy", "Nassir Navab", "Christian Wachinger"], "title": "Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks", "url": "http://arxiv.org/pdf/1803.02579v2", "summary": "Fully convolutional neural networks (F-CNNs) have set the state-of-the-art in image segmentation for a plethora of applications. Architectural innovations within F-CNNs have mainly focused on improving spatial encoding or network connectivity to aid gradient flow. In this paper, we explore an alternate direction of recalibrating the feature maps adaptively, to boost meaningful features, while suppressing weak ones. We draw inspiration from the recently proposed squeeze & excitation (SE) module for channel recalibration of feature maps for image classification. Towards this end, we introduce three variants of SE modules for image segmentation, (i) squeezing spatially and exciting channel-wise (cSE), (ii) squeezing channel-wise and exciting spatially (sSE) and (iii) concurrent spatial and channel squeeze & excitation (scSE). We effectively incorporate these SE modules within three different state-of-the-art F-CNNs (DenseNet, SD-Net, U-Net) and observe consistent improvement of performance across all architectures, while minimally effecting model complexity. Evaluations are performed on two challenging applications: whole brain segmentation on MRI scans (Multi-Atlas Labelling Challenge Dataset) and organ segmentation on whole body contrast enhanced CT scans (Visceral Dataset).", "published": "2018-03-07T10:22:06Z", "version": 2}, {"aid": "1803.02735", "authors": ["Muhammad Haris", "Greg Shakhnarovich", "Norimichi Ukita"], "title": "Deep Back-Projection Networks For Super-Resolution", "url": "http://arxiv.org/pdf/1803.02735v1", "summary": "The feed-forward architectures of recently proposed deep super-resolution networks learn representations of low-resolution inputs, and the non-linear mapping from those to high-resolution output. However, this approach does not fully address the mutual dependencies of low- and high-resolution images. We propose Deep Back-Projection Networks (DBPN), that exploit iterative up- and down-sampling layers, providing an error feedback mechanism for projection errors at each stage. We construct mutually-connected up- and down-sampling stages each of which represents different types of image degradation and high-resolution components. We show that extending this idea to allow concatenation of features across up- and down-sampling stages (Dense DBPN) allows us to reconstruct further improve super-resolution, yielding superior results and in particular establishing new state of the art results for large scaling factors such as 8x across multiple data sets.", "published": "2018-03-07T16:05:35Z", "version": 1}, {"aid": "1803.02742", "authors": ["Qiuyu Zhu", "Ruixin Zhang"], "title": "HENet:A Highly Efficient Convolutional Neural Networks Optimized for Accuracy, Speed and Storage", "url": "http://arxiv.org/pdf/1803.02742v2", "summary": "In order to enhance the real-time performance of convolutional neural networks(CNNs), more and more researchers are focusing on improving the efficiency of CNN. Based on the analysis of some CNN architectures, such as ResNet, DenseNet, ShuffleNet and so on, we combined their advantages and proposed a very efficient model called Highly Efficient Networks(HENet). The new architecture uses an unusual way to combine group convolution and channel shuffle which was mentioned in ShuffleNet. Inspired by ResNet and DenseNet, we also proposed a new way to use element-wise addition and concatenation connection with each block. In order to make greater use of feature maps, pooling operations are removed from HENet. The experiments show that our model's efficiency is more than 1 times higher than ShuffleNet on many open source datasets, such as CIFAR-10/100 and SVHN.", "published": "2018-03-07T16:18:51Z", "version": 2}, {"aid": "1803.02811", "authors": ["Adam Stooke", "Pieter Abbeel"], "title": "Accelerated Methods for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1803.02811v2", "summary": "Deep reinforcement learning (RL) has achieved many recent successes, yet experiment turn-around time remains a key bottleneck in research and in practice. We investigate how to optimize existing deep RL algorithms for modern computers, specifically for a combination of CPUs and GPUs. We confirm that both policy gradient and Q-value learning algorithms can be adapted to learn using many parallel simulator instances. We further find it possible to train using batch sizes considerably larger than are standard, without negatively affecting sample complexity or final performance. We leverage these facts to build a unified framework for parallelization that dramatically hastens experiments in both classes of algorithm. All neural network computations use GPUs, accelerating both data collection and training. Our results include using an entire DGX-1 to learn successful strategies in Atari games in mere minutes, using both synchronous and asynchronous algorithms.", "published": "2018-03-07T18:39:12Z", "version": 2}, {"aid": "1803.02865", "authors": ["Xiaoxia Wu", "Rachel Ward", "L\u00e9on Bottou"], "title": "WNGrad: Learn the Learning Rate in Gradient Descent", "url": "http://arxiv.org/pdf/1803.02865v2", "summary": "Adjusting the learning rate schedule in stochastic gradient methods is an important unresolved problem which requires tuning in practice. If certain parameters of the loss function such as smoothness or strong convexity constants are known, theoretical learning rate schedules can be applied. However, in practice, such parameters are not known, and the loss function of interest is not convex in any case. The recently proposed batch normalization reparametrization is widely adopted in most neural network architectures today because, among other advantages, it is robust to the choice of Lipschitz constant of the gradient in loss function, allowing one to set a large learning rate without worry. Inspired by batch normalization, we propose a general nonlinear update rule for the learning rate in batch and stochastic gradient descent so that the learning rate can be initialized at a high value, and is subsequently decreased according to gradient observations along the way. The proposed method is shown to achieve robustness to the relationship between the learning rate and the Lipschitz constant, and near-optimal convergence rates in both the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch setting, and $O(1/\\sqrt{T})$ for convex loss in the stochastic setting). We also show through numerical evidence that such robustness of the proposed method extends to highly nonconvex and possibly non-smooth loss function in deep learning problems.Our analysis establishes some first theoretical understanding into the observed robustness for batch normalization and weight normalization.", "published": "2018-03-07T20:30:35Z", "version": 2}, {"aid": "1803.03816", "authors": ["Mostafa Gamal", "Mennatullah Siam", "Moemen Abdel-Razek"], "title": "ShuffleSeg: Real-time Semantic Segmentation Network", "url": "http://arxiv.org/pdf/1803.03816v2", "summary": "Real-time semantic segmentation is of significant importance for mobile and robotics related applications. We propose a computationally efficient segmentation network which we term as ShuffleSeg. The proposed architecture is based on grouped convolution and channel shuffling in its encoder for improving the performance. An ablation study of different decoding methods is compared including Skip architecture, UNet, and Dilation Frontend. Interesting insights on the speed and accuracy tradeoff is discussed. It is shown that skip architecture in the decoding method provides the best compromise for the goal of real-time performance, while it provides adequate accuracy by utilizing higher resolution feature maps for a more accurate segmentation. ShuffleSeg is evaluated on CityScapes and compared against the state of the art real-time segmentation networks. It achieves 2x GFLOPs reduction, while it provides on par mean intersection over union of 58.3% on CityScapes test set. ShuffleSeg runs at 15.7 frames per second on NVIDIA Jetson TX2, which makes it of great potential for real-time applications.", "published": "2018-03-10T14:28:45Z", "version": 2}, {"aid": "1803.04792", "authors": ["Youcheng Sun", "Xiaowei Huang", "Daniel Kroening", "James Sharp", "Matthew Hill", "Rob Ashmore"], "title": "Testing Deep Neural Networks", "url": "http://arxiv.org/pdf/1803.04792v4", "summary": "Deep neural networks (DNNs) have a wide range of applications, and software employing them must be thoroughly tested, especially in safety-critical domains. However, traditional software test coverage metrics cannot be applied directly to DNNs. In this paper, inspired by the MC/DC coverage criterion, we propose a family of four novel test criteria that are tailored to structural features of DNNs and their semantics. We validate the criteria by demonstrating that the generated test inputs guided via our proposed coverage criteria are able to capture undesired behaviours in a DNN. Test cases are generated using a symbolic approach and a gradient-based heuristic search. By comparing them with existing methods, we show that our criteria achieve a balance between their ability to find bugs (proxied using adversarial examples) and the computational cost of test case generation. Our experiments are conducted on state-of-the-art DNNs obtained using popular open source datasets, including MNIST, CIFAR-10 and ImageNet.", "published": "2018-03-10T23:19:13Z", "version": 4}, {"aid": "1803.04848", "authors": ["Esther Derman", "Daniel J. Mankowitz", "Timothy A. Mann", "Shie Mannor"], "title": "Soft-Robust Actor-Critic Policy-Gradient", "url": "http://arxiv.org/pdf/1803.04848v2", "summary": "Robust Reinforcement Learning aims to derive optimal behavior that accounts for model uncertainty in dynamical systems. However, previous studies have shown that by considering the worst case scenario, robust policies can be overly conservative. Our soft-robust framework is an attempt to overcome this issue. In this paper, we present a novel Soft-Robust Actor-Critic algorithm (SR-AC). It learns an optimal policy with respect to a distribution over an uncertainty set and stays robust to model uncertainty but avoids the conservativeness of robust strategies. We show the convergence of SR-AC and test the efficiency of our approach on different domains by comparing it against regular learning methods and their robust formulations.", "published": "2018-03-11T09:43:20Z", "version": 2}, {"aid": "1803.04249", "authors": ["Jiaxin Li", "Ben M. Chen", "Gim Hee Lee"], "title": "SO-Net: Self-Organizing Network for Point Cloud Analysis", "url": "http://arxiv.org/pdf/1803.04249v4", "summary": "This paper presents SO-Net, a permutation invariant architecture for deep learning with orderless point clouds. The SO-Net models the spatial distribution of point cloud by building a Self-Organizing Map (SOM). Based on the SOM, SO-Net performs hierarchical feature extraction on individual points and SOM nodes, and ultimately represents the input point cloud by a single feature vector. The receptive field of the network can be systematically adjusted by conducting point-to-node k nearest neighbor search. In recognition tasks such as point cloud reconstruction, classification, object part segmentation and shape retrieval, our proposed network demonstrates performance that is similar with or better than state-of-the-art approaches. In addition, the training speed is significantly faster than existing point cloud recognition networks because of the parallelizability and simplicity of the proposed architecture. Our code is available at the project website. https://github.com/lijx10/SO-Net", "published": "2018-03-12T13:49:14Z", "version": 4}, {"aid": "1803.04469", "authors": ["He Huang", "Philip S. Yu", "Changhu Wang"], "title": "An Introduction to Image Synthesis with Generative Adversarial Nets", "url": "http://arxiv.org/pdf/1803.04469v2", "summary": "There has been a drastic growth of research in Generative Adversarial Nets (GANs) in the past few years. Proposed in 2014, GAN has been applied to various applications such as computer vision and natural language processing, and achieves impressive performance. Among the many applications of GAN, image synthesis is the most well-studied one, and research in this area has already demonstrated the great potential of using GAN in image synthesis. In this paper, we provide a taxonomy of methods used in image synthesis, review different models for text-to-image synthesis and image-to-image translation, and discuss some evaluation metrics as well as possible future research directions in image synthesis with GAN.", "published": "2018-03-12T19:14:35Z", "version": 2}, {"aid": "1803.04488", "authors": ["Faisal Alshargi", "Saeedeh Shekarpour", "Tommaso Soru", "Amit Sheth"], "title": "Concept2vec: Metrics for Evaluating Quality of Embeddings for Ontological Concepts", "url": "http://arxiv.org/pdf/1803.04488v3", "summary": "Although there is an emerging trend towards generating embeddings for primarily unstructured data and, recently, for structured data, no systematic suite for measuring the quality of embeddings has been proposed yet. This deficiency is further sensed with respect to embeddings generated for structured data because there are no concrete evaluation metrics measuring the quality of the encoded structure as well as semantic patterns in the embedding space. In this paper, we introduce a framework containing three distinct tasks concerned with the individual aspects of ontological concepts: (i) the categorization aspect, (ii) the hierarchical aspect, and (iii) the relational aspect. Then, in the scope of each task, a number of intrinsic metrics are proposed for evaluating the quality of the embeddings. Furthermore, w.r.t. this framework, multiple experimental studies were run to compare the quality of the available embedding models. Employing this framework in future research can reduce misjudgment and provide greater insight about quality comparisons of embeddings for ontological concepts. We positioned our sampled data and code at https://github.com/alshargi/Concept2vec under GNU General Public License v3.0.", "published": "2018-03-12T19:46:10Z", "version": 3}, {"aid": "1803.04585", "authors": ["David Manheim", "Scott Garrabrant"], "title": "Categorizing Variants of Goodhart's Law", "url": "http://arxiv.org/pdf/1803.04585v4", "summary": "There are several distinct failure modes for overoptimization of systems on the basis of metrics. This occurs when a metric which can be used to improve a system is used to an extent that further optimization is ineffective or harmful, and is sometimes termed Goodhart's Law. This class of failure is often poorly understood, partly because terminology for discussing them is ambiguous, and partly because discussion using this ambiguous terminology ignores distinctions between different failure modes of this general type. This paper expands on an earlier discussion by Garrabrant, which notes there are \"(at least) four different mechanisms\" that relate to Goodhart's Law. This paper is intended to explore these mechanisms further, and specify more clearly how they occur. This discussion should be helpful in better understanding these types of failures in economic regulation, in public policy, in machine learning, and in Artificial Intelligence alignment. The importance of Goodhart effects depends on the amount of power directed towards optimizing the proxy, and so the increased optimization power offered by artificial intelligence makes it especially critical for that field.", "published": "2018-03-13T01:15:39Z", "version": 4}, {"aid": "1803.04626", "authors": ["Roey Mechrez", "Itamar Talmi", "Firas Shama", "Lihi Zelnik-Manor"], "title": "Maintaining Natural Image Statistics with the Contextual Loss", "url": "http://arxiv.org/pdf/1803.04626v3", "summary": "Maintaining natural image statistics is a crucial factor in restoration and generation of realistic looking images. When training CNNs, photorealism is usually attempted by adversarial training (GAN), that pushes the output images to lie on the manifold of natural images. GANs are very powerful, but not perfect. They are hard to train and the results still often suffer from artifacts. In this paper we propose a complementary approach, that could be applied with or without GAN, whose goal is to train a feed-forward CNN to maintain natural internal statistics. We look explicitly at the distribution of features in an image and train the network to generate images with natural feature distributions. Our approach reduces by orders of magnitude the number of images required for training and achieves state-of-the-art results on both single-image super-resolution, and high-resolution surface normal estimation.", "published": "2018-03-13T05:19:26Z", "version": 3}, {"aid": "1803.04831", "authors": ["Shuai Li", "Wanqing Li", "Chris Cook", "Ce Zhu", "Yanbo Gao"], "title": "Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN", "url": "http://arxiv.org/pdf/1803.04831v3", "summary": "Recurrent neural networks (RNNs) have been widely used for processing sequential data. However, RNNs are commonly difficult to train due to the well-known gradient vanishing and exploding problems and hard to learn long-term patterns. Long short-term memory (LSTM) and gated recurrent unit (GRU) were developed to address these problems, but the use of hyperbolic tangent and the sigmoid action functions results in gradient decay over layers. Consequently, construction of an efficiently trainable deep network is challenging. In addition, all the neurons in an RNN layer are entangled together and their behaviour is hard to interpret. To address these problems, a new type of RNN, referred to as independently recurrent neural network (IndRNN), is proposed in this paper, where neurons in the same layer are independent of each other and they are connected across layers. We have shown that an IndRNN can be easily regulated to prevent the gradient exploding and vanishing problems while allowing the network to learn long-term dependencies. Moreover, an IndRNN can work with non-saturated activation functions such as relu (rectified linear unit) and be still trained robustly. Multiple IndRNNs can be stacked to construct a network that is deeper than the existing RNNs. Experimental results have shown that the proposed IndRNN is able to process very long sequences (over 5000 time steps), can be used to construct very deep networks (21 layers used in the experiment) and still be trained robustly. Better performances have been achieved on various tasks by using IndRNNs compared with the traditional RNN and LSTM. The code is available at https://github.com/Sunnydreamrain/IndRNN_Theano_Lasagne.", "published": "2018-03-13T14:27:42Z", "version": 3}, {"aid": "1803.04988", "authors": ["Kai Xu", "Dawei Li", "Nick Cassimatis", "Xiaolong Wang"], "title": "LCANet: End-to-End Lipreading with Cascaded Attention-CTC", "url": "http://arxiv.org/pdf/1803.04988v1", "summary": "Machine lipreading is a special type of automatic speech recognition (ASR) which transcribes human speech by visually interpreting the movement of related face regions including lips, face, and tongue. Recently, deep neural network based lipreading methods show great potential and have exceeded the accuracy of experienced human lipreaders in some benchmark datasets. However, lipreading is still far from being solved, and existing methods tend to have high error rates on the wild data. In this paper, we propose LCANet, an end-to-end deep neural network based lipreading system. LCANet encodes input video frames using a stacked 3D convolutional neural network (CNN), highway network and bidirectional GRU network. The encoder effectively captures both short-term and long-term spatio-temporal information. More importantly, LCANet incorporates a cascaded attention-CTC decoder to generate output texts. By cascading CTC with attention, it partially eliminates the defect of the conditional independence assumption of CTC within the hidden neural layers, and this yields notably performance improvement as well as faster convergence. The experimental results show the proposed system achieves a 1.3% CER and 3.0% WER on the GRID corpus database, leading to a 12.3% improvement compared to the state-of-the-art methods.", "published": "2018-03-13T18:04:10Z", "version": 1}, {"aid": "1803.05026", "authors": ["Wenqi Wang", "Vaneet Aggarwal", "Shuchin Aeron"], "title": "Principal Component Analysis with Tensor Train Subspace", "url": "http://arxiv.org/pdf/1803.05026v1", "summary": "Tensor train is a hierarchical tensor network structure that helps alleviate the curse of dimensionality by parameterizing large-scale multidimensional data via a set of network of low-rank tensors. Associated with such a construction is a notion of Tensor Train subspace and in this paper we propose a TT-PCA algorithm for estimating this structured subspace from the given data. By maintaining low rank tensor structure, TT-PCA is more robust to noise comparing with PCA or Tucker-PCA. This is borne out numerically by testing the proposed approach on the Extended YaleFace Dataset B.", "published": "2018-03-13T19:58:46Z", "version": 1}, {"aid": "1803.05049", "authors": ["Sergio Hernandez Cerezo", "Guillem Duran Ballester"], "title": "Fractal AI: A fragile theory of intelligence", "url": "http://arxiv.org/pdf/1803.05049v5", "summary": "Fractal AI is a theory for general artificial intelligence. It allows deriving new mathematical tools that constitute the foundations for a new kind of stochastic calculus, by modelling information using cellular automaton-like structures instead of smooth functions. In the repository included we are presenting a new Agent, derived from the first principles of the theory, which is capable of solving Atari games several orders of magnitude more efficiently than other similar techniques, like Monte Carlo Tree Search. The code provided shows how it is now possible to beat some of the current State of The Art benchmarks on Atari games, without previous learning and using less than 1000 samples to calculate each one of the actions when standard MCTS uses 3 Million samples. Among other things, Fractal AI makes it possible to generate a huge database of top performing examples with a very little amount of computation required, transforming Reinforcement Learning into a supervised problem. The algorithm presented is capable of solving the exploration vs exploitation dilemma on both the discrete and continuous cases, while maintaining control over any aspect of the behaviour of the Agent. From a general approach, new techniques presented here have direct applications to other areas such as Non-equilibrium thermodynamics, chemistry, quantum physics, economics, information theory, and non-linear control theory.", "published": "2018-03-13T21:17:26Z", "version": 5}, {"aid": "1803.05788", "authors": ["Zihao Liu", "Tao Liu", "Wujie Wen", "Lei Jiang", "Jie Xu", "Yanzhi Wang", "Gang Quan"], "title": "DeepN-JPEG: A Deep Neural Network Favorable JPEG-based Image Compression Framework", "url": "http://arxiv.org/pdf/1803.05788v1", "summary": "As one of most fascinating machine learning techniques, deep neural network (DNN) has demonstrated excellent performance in various intelligent tasks such as image classification. DNN achieves such performance, to a large extent, by performing expensive training over huge volumes of training data. To reduce the data storage and transfer overhead in smart resource-limited Internet-of-Thing (IoT) systems, effective data compression is a \"must-have\" feature before transferring real-time produced dataset for training or classification. While there have been many well-known image compression approaches (such as JPEG), we for the first time find that a human-visual based image compression approach such as JPEG compression is not an optimized solution for DNN systems, especially with high compression ratios. To this end, we develop an image compression framework tailored for DNN applications, named \"DeepN-JPEG\", to embrace the nature of deep cascaded information process mechanism of DNN architecture. Extensive experiments, based on \"ImageNet\" dataset with various state-of-the-art DNNs, show that \"DeepN-JPEG\" can achieve ~3.5x higher compression rate over the popular JPEG solution while maintaining the same accuracy level for image recognition, demonstrating its great potential of storage and power efficiency in DNN-based smart IoT system design.", "published": "2018-03-14T02:18:55Z", "version": 1}, {"aid": "1803.05215", "authors": ["Filippos Kokkinos", "Stamatios Lefkimmiatis"], "title": "Deep Image Demosaicking using a Cascade of Convolutional Residual Denoising Networks", "url": "http://arxiv.org/pdf/1803.05215v4", "summary": "Demosaicking and denoising are among the most crucial steps of modern digital camera pipelines and their joint treatment is a highly ill-posed inverse problem where at-least two-thirds of the information are missing and the rest are corrupted by noise. This poses a great challenge in obtaining meaningful reconstructions and a special care for the efficient treatment of the problem is required. While there are several machine learning approaches that have been recently introduced to deal with joint image demosaicking-denoising, in this work we propose a novel deep learning architecture which is inspired by powerful classical image regularization methods and large-scale convex optimization techniques. Consequently, our derived network is more transparent and has a clear interpretation compared to alternative competitive deep learning approaches. Our extensive experiments demonstrate that our network outperforms any previous approaches on both noisy and noise-free data. This improvement in reconstruction quality is attributed to the principled way we design our network architecture, which also requires fewer trainable parameters than the current state-of-the-art deep network solution. Finally, we show that our network has the ability to generalize well even when it is trained on small datasets, while keeping the overall number of trainable parameters low.", "published": "2018-03-14T11:44:08Z", "version": 4}, {"aid": "1803.05407", "authors": ["Pavel Izmailov", "Dmitrii Podoprikhin", "Timur Garipov", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": "Averaging Weights Leads to Wider Optima and Better Generalization", "url": "http://arxiv.org/pdf/1803.05407v3", "summary": "Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.", "published": "2018-03-14T17:09:27Z", "version": 3}, {"aid": "1803.05536", "authors": ["Zhen-Hua Feng", "Patrik Huber", "Josef Kittler", "Peter JB Hancock", "Xiao-Jun Wu", "Qijun Zhao", "Paul Koppen", "Matthias R\u00e4tsch"], "title": "Evaluation of Dense 3D Reconstruction from 2D Face Images in the Wild", "url": "http://arxiv.org/pdf/1803.05536v2", "summary": "This paper investigates the evaluation of dense 3D face reconstruction from a single 2D image in the wild. To this end, we organise a competition that provides a new benchmark dataset that contains 2000 2D facial images of 135 subjects as well as their 3D ground truth face scans. In contrast to previous competitions or challenges, the aim of this new benchmark dataset is to evaluate the accuracy of a 3D dense face reconstruction algorithm using real, accurate and high-resolution 3D ground truth face scans. In addition to the dataset, we provide a standard protocol as well as a Python script for the evaluation. Last, we report the results obtained by three state-of-the-art 3D face reconstruction systems on the new benchmark dataset. The competition is organised along with the 2018 13th IEEE Conference on Automatic Face & Gesture Recognition.", "published": "2018-03-14T23:12:12Z", "version": 2}, {"aid": "1803.05619", "authors": ["Huikai Wu", "Shuai Zheng", "Junge Zhang", "Kaiqi Huang"], "title": "Fast End-to-End Trainable Guided Filter", "url": "http://arxiv.org/pdf/1803.05619v2", "summary": "Dense pixel-wise image prediction has been advanced by harnessing the capabilities of Fully Convolutional Networks (FCNs). One central issue of FCNs is the limited capacity to handle joint upsampling. To address the problem, we present a novel building block for FCNs, namely guided filtering layer, which is designed for efficiently generating a high-resolution output given the corresponding low-resolution one and a high-resolution guidance map. Such a layer contains learnable parameters, which can be integrated with FCNs and jointly optimized through end-to-end training. To further take advantage of end-to-end training, we plug in a trainable transformation function for generating the task-specific guidance map. Based on the proposed layer, we present a general framework for pixel-wise image prediction, named deep guided filtering network (DGF). The proposed network is evaluated on five image processing tasks. Experiments on MIT-Adobe FiveK Dataset demonstrate that DGF runs 10-100 times faster and achieves the state-of-the-art performance. We also show that DGF helps to improve the performance of multiple computer vision tasks.", "published": "2018-03-15T07:31:24Z", "version": 2}, {"aid": "1803.05863", "authors": ["Alexander G. Ororbia", "Ankur Mali", "Jian Wu", "Scott O'Connell", "David Miller", "C. Lee Giles"], "title": "Learned Neural Iterative Decoding for Lossy Image Compression Systems", "url": "http://arxiv.org/pdf/1803.05863v3", "summary": "For lossy image compression systems, we develop an algorithm, iterative refinement, to improve the decoder's reconstruction compared to standard decoding techniques. Specifically, we propose a recurrent neural network approach for nonlinear, iterative decoding. Our decoder, which works with any encoder, employs self-connected memory units that make use of causal and non-causal spatial context information to progressively reduce reconstruction error over a fixed number of steps. We experiment with variants of our estimator and find that iterative refinement consistently creates lower distortion images of higher perceptual quality compared to other approaches. Specifically, on the Kodak Lossless True Color Image Suite, we observe as much as a 0.871 decibel (dB) gain over JPEG, a 1.095 dB gain over JPEG 2000, and a 0.971 dB gain over a competitive neural model.", "published": "2018-03-15T16:58:45Z", "version": 3}, {"aid": "1803.06189", "authors": ["Xinwei He", "Yang Zhou", "Zhichao Zhou", "Song Bai", "Xiang Bai"], "title": "Triplet-Center Loss for Multi-View 3D Object Retrieval", "url": "http://arxiv.org/pdf/1803.06189v1", "summary": "Most existing 3D object recognition algorithms focus on leveraging the strong discriminative power of deep learning models with softmax loss for the classification of 3D data, while learning discriminative features with deep metric learning for 3D object retrieval is more or less neglected. In the paper, we study variants of deep metric learning losses for 3D object retrieval, which did not receive enough attention from this area. First , two kinds of representative losses, triplet loss and center loss, are introduced which could learn more discriminative features than traditional classification loss. Then, we propose a novel loss named triplet-center loss, which can further enhance the discriminative power of the features. The proposed triplet-center loss learns a center for each class and requires that the distances between samples and centers from the same class are closer than those from different classes. Extensive experimental results on two popular 3D object retrieval benchmarks and two widely-adopted sketch-based 3D shape retrieval benchmarks consistently demonstrate the effectiveness of our proposed loss, and significant improvements have been achieved compared with the state-of-the-arts.", "published": "2018-03-16T12:31:24Z", "version": 1}, {"aid": "1803.06199", "authors": ["Martin Simon", "Stefan Milz", "Karl Amende", "Horst-Michael Gross"], "title": "Complex-YOLO: Real-time 3D Object Detection on Point Clouds", "url": "http://arxiv.org/pdf/1803.06199v2", "summary": "Lidar based 3D object detection is inevitable for autonomous driving, because it directly links to environmental understanding and therefore builds the base for prediction and motion planning. The capacity of inferencing highly sparse 3D data in real-time is an ill-posed problem for lots of other application areas besides automated vehicles, e.g. augmented reality, personal robotics or industrial automation. We introduce Complex-YOLO, a state of the art real-time 3D object detection network on point clouds only. In this work, we describe a network that expands YOLOv2, a fast 2D standard object detector for RGB images, by a specific complex regression strategy to estimate multi-class 3D boxes in Cartesian space. Thus, we propose a specific Euler-Region-Proposal Network (E-RPN) to estimate the pose of the object by adding an imaginary and a real fraction to the regression network. This ends up in a closed complex space and avoids singularities, which occur by single angle estimations. The E-RPN supports to generalize well during training. Our experiments on the KITTI benchmark suite show that we outperform current leading methods for 3D object detection specifically in terms of efficiency. We achieve state of the art results for cars, pedestrians and cyclists by being more than five times faster than the fastest competitor. Further, our model is capable of estimating all eight KITTI-classes, including Vans, Trucks or sitting pedestrians simultaneously with high accuracy.", "published": "2018-03-16T12:54:40Z", "version": 2}, {"aid": "1803.06288", "authors": ["David J. Heeger", "Wayne E. Mackey"], "title": "ORGaNICs: A Theory of Working Memory in Brains and Machines", "url": "http://arxiv.org/pdf/1803.06288v4", "summary": "Working memory is a cognitive process that is responsible for temporarily holding and manipulating information. Most of the empirical neuroscience research on working memory has focused on measuring sustained activity in prefrontal cortex (PFC) and/or parietal cortex during simple delayed-response tasks, and most of the models of working memory have been based on neural integrators. But working memory means much more than just holding a piece of information online. We describe a new theory of working memory, based on a recurrent neural circuit that we call ORGaNICs (Oscillatory Recurrent GAted Neural Integrator Circuits). ORGaNICs are a variety of Long Short Term Memory units (LSTMs), imported from machine learning and artificial intelligence. ORGaNICs can be used to explain the complex dynamics of delay-period activity in prefrontal cortex (PFC) during a working memory task. The theory is analytically tractable so that we can characterize the dynamics, and the theory provides a means for reading out information from the dynamically varying responses at any point in time, in spite of the complex dynamics. ORGaNICs can be implemented with a biophysical (electrical circuit) model of pyramidal cells, combined with shunting inhibition via a thalamocortical loop. Although introduced as a computational theory of working memory, ORGaNICs are also applicable to models of sensory processing, motor preparation and motor control. ORGaNICs offer computational advantages compared to other varieties of LSTMs that are commonly used in AI applications. Consequently, ORGaNICs are a framework for canonical computation in brains and machines.", "published": "2018-03-16T16:04:09Z", "version": 4}, {"aid": "1803.06329", "authors": ["Diego Marcos", "Devis Tuia", "Benjamin Kellenberger", "Lisa Zhang", "Min Bai", "Renjie Liao", "Raquel Urtasun"], "title": "Learning deep structured active contours end-to-end", "url": "http://arxiv.org/pdf/1803.06329v1", "summary": "The world is covered with millions of buildings, and precisely knowing each instance's position and extents is vital to a multitude of applications. Recently, automated building footprint segmentation models have shown superior detection accuracy thanks to the usage of Convolutional Neural Networks (CNN). However, even the latest evolutions struggle to precisely delineating borders, which often leads to geometric distortions and inadvertent fusion of adjacent building instances. We propose to overcome this issue by exploiting the distinct geometric properties of buildings. To this end, we present Deep Structured Active Contours (DSAC), a novel framework that integrates priors and constraints into the segmentation process, such as continuous boundaries, smooth edges, and sharp corners. To do so, DSAC employs Active Contour Models (ACM), a family of constraint- and prior-based polygonal models. We learn ACM parameterizations per instance using a CNN, and show how to incorporate all components in a structured output model, making DSAC trainable end-to-end. We evaluate DSAC on three challenging building instance segmentation datasets, where it compares favorably against state-of-the-art. Code will be made available.", "published": "2018-03-16T17:30:37Z", "version": 1}, {"aid": "1803.06407", "authors": ["Calvin Murdock", "Ming-Fang Chang", "Simon Lucey"], "title": "Deep Component Analysis via Alternating Direction Neural Networks", "url": "http://arxiv.org/pdf/1803.06407v1", "summary": "Despite a lack of theoretical understanding, deep neural networks have achieved unparalleled performance in a wide range of applications. On the other hand, shallow representation learning with component analysis is associated with rich intuition and theory, but smaller capacity often limits its usefulness. To bridge this gap, we introduce Deep Component Analysis (DeepCA), an expressive multilayer model formulation that enforces hierarchical structure through constraints on latent variables in each layer. For inference, we propose a differentiable optimization algorithm implemented using recurrent Alternating Direction Neural Networks (ADNNs) that enable parameter learning using standard backpropagation. By interpreting feed-forward networks as single-iteration approximations of inference in our model, we provide both a novel theoretical perspective for understanding them and a practical technique for constraining predictions with prior knowledge. Experimentally, we demonstrate performance improvements on a variety of tasks, including single-image depth prediction with sparse output constraints.", "published": "2018-03-16T21:40:02Z", "version": 1}, {"aid": "1803.06500", "authors": ["Joseph Corneli", "Ursula Martin", "Dave Murray-Rust", "Gabriela Rino Nesin", "Alison Pease"], "title": "Argumentation theory for mathematical argument", "url": "http://arxiv.org/pdf/1803.06500v2", "summary": "To adequately model mathematical arguments the analyst must be able to represent the mathematical objects under discussion and the relationships between them, as well as inferences drawn about these objects and relationships as the discourse unfolds. We introduce a framework with these properties, which has been used to analyse mathematical dialogues and expository texts. The framework can recover salient elements of discourse at, and within, the sentence level, as well as the way mathematical content connects to form larger argumentative structures. We show how the framework might be used to support computational reasoning, and argue that it provides a more natural way to examine the process of proving theorems than do Lamport's structured proofs.", "published": "2018-03-17T13:20:37Z", "version": 2}, {"aid": "1803.06744", "authors": ["Purushotham Kamath", "Abhishek Singh", "Debo Dutta"], "title": "Fast Neural Architecture Construction using EnvelopeNets", "url": "http://arxiv.org/pdf/1803.06744v3", "summary": "Fast Neural Architecture Construction (NAC) is a method to construct deep network architectures by pruning and expansion of a base network. In recent years, several automated search methods for neural network architectures have been proposed using methods such as evolutionary algorithms and reinforcement learning. These methods use a single scalar objective function (usually accuracy) that is evaluated after a full training and evaluation cycle. In contrast NAC directly compares the utility of different filters using statistics derived from filter featuremaps reach a state where the utility of different filters within a network can be compared and hence can be used to construct networks. The training epochs needed for filters within a network to reach this state is much less than the training epochs needed for the accuracy of a network to stabilize. NAC exploits this finding to construct convolutional neural nets (CNNs) with close to state of the art accuracy, in < 1 GPU day, faster than most of the current neural architecture search methods. The constructed networks show close to state of the art performance on the image classification problem on well known datasets (CIFAR-10, ImageNet) and consistently show better performance than hand constructed and randomly generated networks of the same depth, operators and approximately the same number of parameters.", "published": "2018-03-18T21:28:03Z", "version": 3}, {"aid": "1803.06802", "authors": ["Qianyi Wu", "Juyong Zhang", "Yu-Kun Lai", "Jianmin Zheng", "Jianfei Cai"], "title": "Alive Caricature from 2D to 3D", "url": "http://arxiv.org/pdf/1803.06802v3", "summary": "Caricature is an art form that expresses subjects in abstract, simple and exaggerated view. While many caricatures are 2D images, this paper presents an algorithm for creating expressive 3D caricatures from 2D caricature images with a minimum of user interaction. The key idea of our approach is to introduce an intrinsic deformation representation that has a capacity of extrapolation enabling us to create a deformation space from standard face dataset, which maintains face constraints and meanwhile is sufficiently large for producing exaggerated face models. Built upon the proposed deformation representation, an optimization model is formulated to find the 3D caricature that captures the style of the 2D caricature image automatically. The experiments show that our approach has better capability in expressing caricatures than those fitting approaches directly using classical parametric face models such as 3DMM and FaceWareHouse. Moreover, our approach is based on standard face datasets and avoids constructing complicated 3D caricature training set, which provides great flexibility in real applications.", "published": "2018-03-19T04:47:16Z", "version": 3}, {"aid": "1803.06815", "authors": ["Sachin Mehta", "Mohammad Rastegari", "Anat Caspi", "Linda Shapiro", "Hannaneh Hajishirzi"], "title": "ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation", "url": "http://arxiv.org/pdf/1803.06815v3", "summary": "We introduce a fast and efficient convolutional neural network, ESPNet, for semantic segmentation of high resolution images under resource constraints. ESPNet is based on a new convolutional module, efficient spatial pyramid (ESP), which is efficient in terms of computation, memory, and power. ESPNet is 22 times faster (on a standard GPU) and 180 times smaller than the state-of-the-art semantic segmentation network PSPNet, while its category-wise accuracy is only 8% less. We evaluated ESPNet on a variety of semantic segmentation datasets including Cityscapes, PASCAL VOC, and a breast biopsy whole slide image dataset. Under the same constraints on memory and computation, ESPNet outperforms all the current efficient CNN networks such as MobileNet, ShuffleNet, and ENet on both standard metrics and our newly introduced performance metrics that measure efficiency on edge devices. Our network can process high resolution images at a rate of 112 and 9 frames per second on a standard GPU and edge device, respectively.", "published": "2018-03-19T06:42:47Z", "version": 3}, {"aid": "1803.06904", "authors": ["Seyed Majid Azimi", "Peter Fischer", "Marco K\u00f6rner", "Peter Reinartz"], "title": "Aerial LaneNet: Lane Marking Semantic Segmentation in Aerial Imagery using Wavelet-Enhanced Cost-sensitive Symmetric Fully Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1803.06904v2", "summary": "The knowledge about the placement and appearance of lane markings is a prerequisite for the creation of maps with high precision, necessary for autonomous driving, infrastructure monitoring, lane-wise traffic management, and urban planning. Lane markings are one of the important components of such maps. Lane markings convey the rules of roads to drivers. While these rules are learned by humans, an autonomous driving vehicle should be taught to learn them to localize itself. Therefore, accurate and reliable lane marking semantic segmentation in the imagery of roads and highways is needed to achieve such goals. We use airborne imagery which can capture a large area in a short period of time by introducing an aerial lane marking dataset. In this work, we propose a Symmetric Fully Convolutional Neural Network enhanced by Wavelet Transform in order to automatically carry out lane marking segmentation in aerial imagery. Due to a heavily unbalanced problem in terms of number of lane marking pixels compared with background pixels, we use a customized loss function as well as a new type of data augmentation step. We achieve a very high accuracy in pixel-wise localization of lane markings without using 3rd-party information. In this work, we introduce the first high-quality dataset used within our experiments which contains a broad range of situations and classes of lane markings representative of current transportation systems. This dataset will be publicly available and hence, it can be used as the benchmark dataset for future algorithms within this domain.", "published": "2018-03-19T13:32:27Z", "version": 2}, {"aid": "1803.06959", "authors": ["Ari S. Morcos", "David G. T. Barrett", "Neil C. Rabinowitz", "Matthew Botvinick"], "title": "On the importance of single directions for generalization", "url": "http://arxiv.org/pdf/1803.06959v4", "summary": "Despite their ability to memorize large datasets, deep neural networks often achieve good generalization performance. However, the differences between the learned solutions of networks which generalize and those which do not remain unclear. Additionally, the tuning properties of single directions (defined as the activation of a single unit or some linear combination of units in response to some input) have been highlighted, but their importance has not been evaluated. Here, we connect these lines of inquiry to demonstrate that a network's reliance on single directions is a good predictor of its generalization performance, across networks trained on datasets with different fractions of corrupted labels, across ensembles of networks trained on datasets with unmodified labels, across different hyperparameters, and over the course of training. While dropout only regularizes this quantity up to a point, batch normalization implicitly discourages single direction reliance, in part by decreasing the class selectivity of individual units. Finally, we find that class selectivity is a poor predictor of task importance, suggesting not only that networks which generalize well minimize their dependence on individual units by reducing their selectivity, but also that individually selective units may not be necessary for strong network performance.", "published": "2018-03-19T14:42:19Z", "version": 4}, {"aid": "1803.07055", "authors": ["Horia Mania", "Aurelia Guy", "Benjamin Recht"], "title": "Simple random search provides a competitive approach to reinforcement learning", "url": "http://arxiv.org/pdf/1803.07055v1", "summary": "A common belief in model-free reinforcement learning is that methods based on random search in the parameter space of policies exhibit significantly worse sample complexity than those that explore the space of actions. We dispel such beliefs by introducing a random search method for training static, linear policies for continuous control problems, matching state-of-the-art sample efficiency on the benchmark MuJoCo locomotion tasks. Our method also finds a nearly optimal controller for a challenging instance of the Linear Quadratic Regulator, a classical problem in control theory, when the dynamics are not known. Computationally, our random search algorithm is at least 15 times more efficient than the fastest competing model-free methods on these benchmarks. We take advantage of this computational efficiency to evaluate the performance of our method over hundreds of random seeds and many different hyperparameter configurations for each benchmark task. Our simulations highlight a high variability in performance in these benchmark tasks, suggesting that commonly used estimations of sample efficiency do not adequately evaluate the performance of RL algorithms.", "published": "2018-03-19T17:35:14Z", "version": 1}, {"aid": "1803.07066", "authors": ["Jiayuan Gu", "Han Hu", "Liwei Wang", "Yichen Wei", "Jifeng Dai"], "title": "Learning Region Features for Object Detection", "url": "http://arxiv.org/pdf/1803.07066v1", "summary": "While most steps in the modern object detection methods are learnable, the region feature extraction step remains largely hand-crafted, featured by RoI pooling methods. This work proposes a general viewpoint that unifies existing region feature extraction methods and a novel method that is end-to-end learnable. The proposed method removes most heuristic choices and outperforms its RoI pooling counterparts. It moves further towards fully learnable object detection.", "published": "2018-03-19T17:58:50Z", "version": 1}, {"aid": "1803.07469", "authors": ["Daniel Barath", "Jana Noskova", "Jiri Matas"], "title": "MAGSAC: marginalizing sample consensus", "url": "http://arxiv.org/pdf/1803.07469v2", "summary": "A method called, sigma-consensus, is proposed to eliminate the need for a user-defined inlier-outlier threshold in RANSAC. Instead of estimating the noise sigma, it is marginalized over a range of noise scales. The optimized model is obtained by weighted least-squares fitting where the weights come from the marginalization over sigma of the point likelihoods of being inliers. A new quality function is proposed not requiring sigma and, thus, a set of inliers to determine the model quality. Also, a new termination criterion for RANSAC is built on the proposed marginalization approach. Applying sigma-consensus, MAGSAC is proposed with no need for a user-defined sigma and improving the accuracy of robust estimation significantly. It is superior to the state-of-the-art in terms of geometric accuracy on publicly available real-world datasets for epipolar geometry (F and E) and homography estimation. In addition, applying sigma-consensus only once as a post-processing step to the RANSAC output always improved the model quality on a wide range of vision problems without noticeable deterioration in processing time, adding a few milliseconds. The source code is at https://github.com/danini/magsac.", "published": "2018-03-20T15:01:11Z", "version": 2}, {"aid": "1803.07482", "authors": ["Ethan Knight", "Osher Lerner"], "title": "Natural Gradient Deep Q-learning", "url": "http://arxiv.org/pdf/1803.07482v2", "summary": "We present a novel algorithm to train a deep Q-learning agent using natural-gradient techniques. We compare the original deep Q-network (DQN) algorithm to its natural-gradient counterpart, which we refer to as NGDQN, on a collection of classic control domains. Without employing target networks, NGDQN significantly outperforms DQN without target networks, and performs no worse than DQN with target networks, suggesting that NGDQN stabilizes training and can help reduce the need for additional hyperparameter tuning. We also find that NGDQN is less sensitive to hyperparameter optimization relative to DQN. Together these results suggest that natural-gradient techniques can improve value-function optimization in deep reinforcement learning.", "published": "2018-03-20T15:22:52Z", "version": 2}, {"aid": "1803.07517", "authors": ["Gabrielle Ras", "Marcel van Gerven", "Pim Haselager"], "title": "Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges", "url": "http://arxiv.org/pdf/1803.07517v2", "summary": "Issues regarding explainable AI involve four components: users, laws & regulations, explanations and algorithms. Together these components provide a context in which explanation methods can be evaluated regarding their adequacy. The goal of this chapter is to bridge the gap between expert users and lay users. Different kinds of users are identified and their concerns revealed, relevant statements from the General Data Protection Regulation are analyzed in the context of Deep Neural Networks (DNNs), a taxonomy for the classification of existing explanation methods is introduced, and finally, the various classes of explanation methods are analyzed to verify if user concerns are justified. Overall, it is clear that (visual) explanations can be given about various aspects of the influence of the input on the output. However, it is noted that explanation methods or interfaces for lay users are missing and we speculate which criteria these methods / interfaces should satisfy. Finally it is noted that two important concerns are difficult to address with explanation methods: the concern about bias in datasets that leads to biased DNNs, as well as the suspicion about unfair outcomes.", "published": "2018-03-20T16:44:47Z", "version": 2}, {"aid": "1803.07624", "authors": ["Jialin Wu", "Dai Li", "Yu Yang", "Chandrajit Bajaj", "Xiangyang Ji"], "title": "Dynamic Filtering with Large Sampling Field for ConvNets", "url": "http://arxiv.org/pdf/1803.07624v3", "summary": "We propose a dynamic filtering strategy with large sampling field for ConvNets (LS-DFN), where the position-specific kernels learn from not only the identical position but also multiple sampled neighbor regions. During sampling, residual learning is introduced to ease training and an attention mechanism is applied to fuse features from different samples. Such multiple samples enlarge the kernels' receptive fields significantly without requiring more parameters. While LS-DFN inherits the advantages of DFN, namely avoiding feature map blurring by position-wise kernels while keeping translation invariance, it also efficiently alleviates the overfitting issue caused by much more parameters than normal CNNs. Our model is efficient and can be trained end-to-end via standard back-propagation. We demonstrate the merits of our LS-DFN on both sparse and dense prediction tasks involving object detection, semantic segmentation, and flow estimation. Our results show LS-DFN enjoys stronger recognition abilities in object detection and semantic segmentation tasks on VOC benchmark and sharper responses in flow estimation on FlyingChairs dataset compared to strong baselines.", "published": "2018-03-20T19:52:16Z", "version": 3}, {"aid": "1803.07712", "authors": ["Furui Liu", "Laiwan Chan"], "title": "Causal Inference on Discrete Data via Estimating Distance Correlations", "url": "http://arxiv.org/pdf/1803.07712v3", "summary": "In this paper, we deal with the problem of inferring causal directions when the data is on discrete domain. By considering the distribution of the cause $P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as independent random variables, we propose to infer the causal direction via comparing the distance correlation between $P(X)$ and $P(Y|X)$ with the distance correlation between $P(Y)$ and $P(X|Y)$. We infer \"$X$ causes $Y$\" if the dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments are performed to show the performance of the proposed method.", "published": "2018-03-21T01:39:08Z", "version": 3}, {"aid": "1803.07980", "authors": ["Tianchen Zhao"], "title": "Information Theoretic Interpretation of Deep learning", "url": "http://arxiv.org/pdf/1803.07980v2", "summary": "We interpret part of the experimental results of Shwartz-Ziv and Tishby [2017]. Inspired by these results, we established a conjecture of the dynamics of the machinary of deep neural network. This conjecture can be used to explain the counterpart result by Saxe et al. [2018].", "published": "2018-03-21T16:03:29Z", "version": 2}, {"aid": "1803.08337", "authors": ["Sebastian Palacio", "Joachim Folz", "J\u00f6rn Hees", "Federico Raue", "Damian Borth", "Andreas Dengel"], "title": "What do Deep Networks Like to See?", "url": "http://arxiv.org/pdf/1803.08337v1", "summary": "We propose a novel way to measure and understand convolutional neural networks by quantifying the amount of input signal they let in. To do this, an autoencoder (AE) was fine-tuned on gradients from a pre-trained classifier with fixed parameters. We compared the reconstructed samples from AEs that were fine-tuned on a set of image classifiers (AlexNet, VGG16, ResNet-50, and Inception~v3) and found substantial differences. The AE learns which aspects of the input space to preserve and which ones to ignore, based on the information encoded in the backpropagated gradients. Measuring the changes in accuracy when the signal of one classifier is used by a second one, a relation of total order emerges. This order depends directly on each classifier's input signal but it does not correlate with classification accuracy or network size. Further evidence of this phenomenon is provided by measuring the normalized mutual information between original images and auto-encoded reconstructions from different fine-tuned AEs. These findings break new ground in the area of neural network understanding, opening a new way to reason, debug, and interpret their results. We present four concrete examples in the literature where observations can now be explained in terms of the input signal that a model uses.", "published": "2018-03-22T13:10:47Z", "version": 1}, {"aid": "1803.08375", "authors": ["Abien Fred Agarap"], "title": "Deep Learning using Rectified Linear Units (ReLU)", "url": "http://arxiv.org/pdf/1803.08375v2", "summary": "We introduce the use of rectified linear units (ReLU) as the classification function in a deep neural network (DNN). Conventionally, ReLU is used as an activation function in DNNs, with Softmax function as their classification function. However, there have been several studies on using a classification function other than Softmax, and this study is an addition to those. We accomplish this by taking the activation of the penultimate layer $h_{n - 1}$ in a neural network, then multiply it by weight parameters $\\theta$ to get the raw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$, i.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide class predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.", "published": "2018-03-22T14:30:17Z", "version": 2}, {"aid": "1803.08450", "authors": ["St\u00e9phane Lathuili\u00e8re", "Pablo Mesejo", "Xavier Alameda-Pineda", "Radu Horaud"], "title": "A Comprehensive Analysis of Deep Regression", "url": "http://arxiv.org/pdf/1803.08450v3", "summary": "Deep learning revolutionized data science, and recently its popularity has grown exponentially, as did the amount of papers employing deep networks. Vision tasks, such as human pose estimation, did not escape from this trend. There is a large number of deep models, where small changes in the network architecture, or in the data pre-processing, together with the stochastic nature of the optimization procedures, produce notably different results, making extremely difficult to sift methods that significantly outperform others. This situation motivates the current study, in which we perform a systematic evaluation and statistical analysis of vanilla deep regression, i.e. convolutional neural networks with a linear regression top layer. This is the first comprehensive analysis of deep regression techniques. We perform experiments on four vision problems, and report confidence intervals for the median performance as well as the statistical significance of the results, if any. Surprisingly, the variability due to different data pre-processing procedures generally eclipses the variability due to modifications in the network architecture. Our results reinforce the hypothesis according to which, in general, a general-purpose network (e.g. VGG-16 or ResNet-50) adequately tuned can yield results close to the state-of-the-art without having to resort to more complex and ad-hoc regression models.", "published": "2018-03-22T16:46:39Z", "version": 3}, {"aid": "1803.08494", "authors": ["Yuxin Wu", "Kaiming He"], "title": "Group Normalization", "url": "http://arxiv.org/pdf/1803.08494v3", "summary": "Batch Normalization (BN) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- BN's error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits BN's usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization (GN) as a simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization. GN's computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN-based counterparts for object detection and segmentation in COCO, and for video classification in Kinetics, showing that GN can effectively replace the powerful BN in a variety of tasks. GN can be easily implemented by a few lines of code in modern libraries.", "published": "2018-03-22T17:57:16Z", "version": 3}, {"aid": "1803.08607", "authors": ["Tao Sheng", "Chen Feng", "Shaojie Zhuo", "Xiaopeng Zhang", "Liang Shen", "Mickey Aleksic"], "title": "A Quantization-Friendly Separable Convolution for MobileNets", "url": "http://arxiv.org/pdf/1803.08607v3", "summary": "As deep learning (DL) is being rapidly pushed to edge computing, researchers invented various ways to make inference computation more efficient on mobile/IoT devices, such as network pruning, parameter compression, and etc. Quantization, as one of the key approaches, can effectively offload GPU, and make it possible to deploy DL on fixed-point pipeline. Unfortunately, not all existing networks design are friendly to quantization. For example, the popular lightweight MobileNetV1, while it successfully reduces parameter size and computation latency with separable convolution, our experiment shows its quantized models have large accuracy gap against its float point models. To resolve this, we analyzed the root cause of quantization loss and proposed a quantization-friendly separable convolution architecture. By evaluating the image classification task on ImageNet2012 dataset, our modified MobileNetV1 model can archive 8-bit inference top-1 accuracy in 68.03%, almost closed the gap to the float pipeline.", "published": "2018-03-22T23:06:38Z", "version": 3}, {"aid": "1803.08664", "authors": ["Namhyuk Ahn", "Byungkon Kang", "Kyung-Ah Sohn"], "title": "Fast, Accurate, and Lightweight Super-Resolution with Cascading Residual Network", "url": "http://arxiv.org/pdf/1803.08664v5", "summary": "In recent years, deep learning methods have been successfully applied to single-image super-resolution tasks. Despite their great performances, deep learning methods cannot be easily applied to real-world applications due to the requirement of heavy computation. In this paper, we address this issue by proposing an accurate and lightweight deep network for image super-resolution. In detail, we design an architecture that implements a cascading mechanism upon a residual network. We also present variant models of the proposed cascading residual network to further improve efficiency. Our extensive experiments show that even with much fewer parameters and operations, our models achieve performance comparable to that of state-of-the-art methods.", "published": "2018-03-23T06:07:20Z", "version": 5}, {"aid": "1803.08834", "authors": ["Isma Hadji", "Richard P. Wildes"], "title": "What Do We Understand About Convolutional Networks?", "url": "http://arxiv.org/pdf/1803.08834v1", "summary": "This document will review the most prominent proposals using multilayer convolutional architectures. Importantly, the various components of a typical convolutional network will be discussed through a review of different approaches that base their design decisions on biological findings and/or sound theoretical bases. In addition, the different attempts at understanding ConvNets via visualizations and empirical studies will be reviewed. The ultimate goal is to shed light on the role of each layer of processing involved in a ConvNet architecture, distill what we currently understand about ConvNets and highlight critical open problems.", "published": "2018-03-23T15:22:01Z", "version": 1}, {"aid": "1803.08887", "authors": ["Ngoc-Trung Tran", "Tuan-Anh Bui", "Ngai-Man Cheung"], "title": "Dist-GAN: An Improved GAN using Distance Constraints", "url": "http://arxiv.org/pdf/1803.08887v3", "summary": "We introduce effective training algorithms for Generative Adversarial Networks (GAN) to alleviate mode collapse and gradient vanishing. In our system, we constrain the generator by an Autoencoder (AE). We propose a formulation to consider the reconstructed samples from AE as \"real\" samples for the discriminator. This couples the convergence of the AE with that of the discriminator, effectively slowing down the convergence of discriminator and reducing gradient vanishing. Importantly, we propose two novel distance constraints to improve the generator. First, we propose a latent-data distance constraint to enforce compatibility between the latent sample distances and the corresponding data sample distances. We use this constraint to explicitly prevent the generator from mode collapse. Second, we propose a discriminator-score distance constraint to align the distribution of the generated samples with that of the real samples through the discriminator score. We use this constraint to guide the generator to synthesize samples that resemble the real ones. Our proposed GAN using these distance constraints, namely Dist-GAN, can achieve better results than state-of-the-art methods across benchmark datasets: synthetic, MNIST, MNIST-1K, CelebA, CIFAR-10 and STL-10 datasets. Our code is published here (https://github.com/tntrung/gan) for research.", "published": "2018-03-23T17:06:26Z", "version": 3}, {"aid": "1803.09010", "authors": ["Timnit Gebru", "Jamie Morgenstern", "Briana Vecchione", "Jennifer Wortman Vaughan", "Hanna Wallach", "Hal Daum\u00e9 III", "Kate Crawford"], "title": "Datasheets for Datasets", "url": "http://arxiv.org/pdf/1803.09010v8", "summary": "The machine learning community currently has no standardized process for documenting datasets, which can lead to severe consequences in high-stakes domains. To address this gap, we propose datasheets for datasets. In the electronics industry, every component, no matter how simple or complex, is accompanied with a datasheet that describes its operating characteristics, test results, recommended uses, and other information. By analogy, we propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on. Datasheets for datasets will facilitate better communication between dataset creators and dataset consumers, and encourage the machine learning community to prioritize transparency and accountability.", "published": "2018-03-23T23:22:18Z", "version": 8}, {"aid": "1803.09165", "authors": ["Renata Khasanova", "Jan Wassenberg", "Jyrki Alakuijala"], "title": "Noise generation for compression algorithms", "url": "http://arxiv.org/pdf/1803.09165v1", "summary": "In various Computer Vision and Signal Processing applications, noise is typically perceived as a drawback of the image capturing system that ought to be removed. We, on the other hand, claim that image noise, just as texture, is important for visual perception and, therefore, critical for lossy compression algorithms that tend to make decompressed images look less realistic by removing small image details. In this paper we propose a physically and biologically inspired technique that learns a noise model at the encoding step of the compression algorithm and then generates the appropriate amount of additive noise at the decoding step. Our method can significantly increase the realism of the decompressed image at the cost of few bytes of additional memory space regardless of the original image size. The implementation of our method is open-sourced and available at https://github.com/google/pik.", "published": "2018-03-24T21:19:29Z", "version": 1}, {"aid": "1803.09218", "authors": ["Dong-Qing Zhang"], "title": "Image Recognition Using Scale Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1803.09218v1", "summary": "Convolutional Neural Network(CNN) has been widely used for image recognition with great success. However, there are a number of limitations of the current CNN based image recognition paradigm. First, the receptive field of CNN is generally fixed, which limits its recognition capacity when the input image is very large. Second, it lacks the computational scalability for dealing with images with different sizes. Third, it is quite different from human visual system for image recognition, which involves both feadforward and recurrent proprocessing. This paper proposes a different paradigm of image recognition, which can take advantages of variable scales of the input images, has more computational scalabilities, and is more similar to image recognition by human visual system. It is based on recurrent neural network (RNN) defined on image scale with an embeded base CNN, which is named Scale Recurrent Neural Network(SRNN). This RNN based approach makes it easier to deal with images with variable sizes, and allows us to borrow existing RNN techniques, such as LSTM and GRU, to further enhance the recognition accuracy. Our experiments show that the recognition accuracy of a base CNN can be significantly boosted using the proposed SRNN models. It also significantly outperforms the scale ensemble method, which integrate the results of performing CNN to the input image at different scales, although the computational overhead of using SRNN is negligible.", "published": "2018-03-25T09:16:55Z", "version": 1}, {"aid": "1803.09263", "authors": ["Kangxue Yin", "Hui Huang", "Daniel Cohen-Or", "Hao Zhang"], "title": "P2P-NET: Bidirectional Point Displacement Net for Shape Transform", "url": "http://arxiv.org/pdf/1803.09263v4", "summary": "We introduce P2P-NET, a general-purpose deep neural network which learns geometric transformations between point-based shape representations from two domains, e.g., meso-skeletons and surfaces, partial and complete scans, etc. The architecture of the P2P-NET is that of a bi-directional point displacement network, which transforms a source point set to a target point set with the same cardinality, and vice versa, by applying point-wise displacement vectors learned from data. P2P-NET is trained on paired shapes from the source and target domains, but without relying on point-to-point correspondences between the source and target point sets. The training loss combines two uni-directional geometric losses, each enforcing a shape-wise similarity between the predicted and the target point sets, and a cross-regularization term to encourage consistency between displacement vectors going in opposite directions. We develop and present several different applications enabled by our general-purpose bidirectional P2P-NET to highlight the effectiveness, versatility, and potential of our network in solving a variety of point-based shape transformation problems.", "published": "2018-03-25T14:30:51Z", "version": 4}, {"aid": "1803.09760", "authors": ["Andrew Jaegle", "Oleh Rybkin", "Konstantinos G. Derpanis", "Kostas Daniilidis"], "title": "Predicting the Future with Transformational States", "url": "http://arxiv.org/pdf/1803.09760v1", "summary": "An intelligent observer looks at the world and sees not only what is, but what is moving and what can be moved. In other words, the observer sees how the present state of the world can transform in the future. We propose a model that predicts future images by learning to represent the present state and its transformation given only a sequence of images. To do so, we introduce an architecture with a latent state composed of two components designed to capture (i) the present image state and (ii) the transformation between present and future states, respectively. We couple this latent state with a recurrent neural network (RNN) core that predicts future frames by transforming past states into future states by applying the accumulated state transformation with a learned operator. We describe how this model can be integrated into an encoder-decoder convolutional neural network (CNN) architecture that uses weighted residual connections to integrate representations of the past with representations of the future. Qualitatively, our approach generates image sequences that are stable and capture realistic motion over multiple predicted frames, without requiring adversarial training. Quantitatively, our method achieves prediction results comparable to state-of-the-art results on standard image prediction benchmarks (Moving MNIST, KTH, and UCF101).", "published": "2018-03-26T18:00:07Z", "version": 1}, {"aid": "1803.09820", "authors": ["Leslie N. Smith"], "title": "A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay", "url": "http://arxiv.org/pdf/1803.09820v2", "summary": "Although deep learning has produced dazzling successes for applications of image, speech, and video processing in the past few years, most trainings are with suboptimal hyper-parameters, requiring unnecessarily long training times. Setting the hyper-parameters remains a black art that requires years of experience to acquire. This report proposes several efficient ways to set the hyper-parameters that significantly reduce training time and improves performance. Specifically, this report shows how to examine the training validation/test loss function for subtle clues of underfitting and overfitting and suggests guidelines for moving toward the optimal balance point. Then it discusses how to increase/decrease the learning rate/momentum to speed up training. Our experiments show that it is crucial to balance every manner of regularization for each dataset and architecture. Weight decay is used as a sample regularizer to show how its optimal value is tightly coupled with the learning rates and momentums. Files to help replicate the results reported here are available.", "published": "2018-03-26T20:05:59Z", "version": 2}, {"aid": "1803.09845", "authors": ["Jiasen Lu", "Jianwei Yang", "Dhruv Batra", "Devi Parikh"], "title": "Neural Baby Talk", "url": "http://arxiv.org/pdf/1803.09845v1", "summary": "We introduce a novel framework for image captioning that can produce natural language explicitly grounded in entities that object detectors find in the image. Our approach reconciles classical slot filling approaches (that are generally better grounded in images) with modern neural captioning approaches (that are generally more natural sounding and accurate). Our approach first generates a sentence `template' with slot locations explicitly tied to specific image regions. These slots are then filled in by visual concepts identified in the regions by object detectors. The entire architecture (sentence template generation and slot filling with object detectors) is end-to-end differentiable. We verify the effectiveness of our proposed model on different image captioning tasks. On standard image captioning and novel object captioning, our model reaches state-of-the-art on both COCO and Flickr30k datasets. We also demonstrate that our model has unique advantages when the train and test distributions of scene compositions -- and hence language priors of associated captions -- are different. Code has been made available at: https://github.com/jiasenlu/NeuralBabyTalk", "published": "2018-03-27T01:59:56Z", "version": 1}, {"aid": "1803.10227", "authors": ["Ashley D. Edwards", "Laura Downs", "James C. Davidson"], "title": "Forward-Backward Reinforcement Learning", "url": "http://arxiv.org/pdf/1803.10227v1", "summary": "Goals for reinforcement learning problems are typically defined through hand-specified rewards. To design such problems, developers of learning algorithms must inherently be aware of what the task goals are, yet we often require agents to discover them on their own without any supervision beyond these sparse rewards. While much of the power of reinforcement learning derives from the concept that agents can learn with little guidance, this requirement greatly burdens the training process. If we relax this one restriction and endow the agent with knowledge of the reward function, and in particular of the goal, we can leverage backwards induction to accelerate training. To achieve this, we propose training a model to learn to take imagined reversal steps from known goal states. Rather than training an agent exclusively to determine how to reach a goal while moving forwards in time, our approach travels backwards to jointly predict how we got there. We evaluate our work in Gridworld and Towers of Hanoi and empirically demonstrate that it yields better performance than standard DDQN.", "published": "2018-03-27T04:33:08Z", "version": 1}, {"aid": "1803.09926", "authors": ["Zheng Qin", "Zhaoning Zhang", "Dongsheng Li", "Yiming Zhang", "Yuxing Peng"], "title": "Diagonalwise Refactorization: An Efficient Training Method for Depthwise Convolutions", "url": "http://arxiv.org/pdf/1803.09926v1", "summary": "Depthwise convolutions provide significant performance benefits owing to the reduction in both parameters and mult-adds. However, training depthwise convolution layers with GPUs is slow in current deep learning frameworks because their implementations cannot fully utilize the GPU capacity. To address this problem, in this paper we present an efficient method (called diagonalwise refactorization) for accelerating the training of depthwise convolution layers. Our key idea is to rearrange the weight vectors of a depthwise convolution into a large diagonal weight matrix so as to convert the depthwise convolution into one single standard convolution, which is well supported by the cuDNN library that is highly-optimized for GPU computations. We have implemented our training method in five popular deep learning frameworks. Evaluation results show that our proposed method gains $15.4\\times$ training speedup on Darknet, $8.4\\times$ on Caffe, $5.4\\times$ on PyTorch, $3.5\\times$ on MXNet, and $1.4\\times$ on TensorFlow, compared to their original implementations of depthwise convolutions.", "published": "2018-03-27T07:06:54Z", "version": 1}, {"aid": "1803.10071", "authors": ["Tong Zhang", "Wenming Zheng", "Zhen Cui", "Yang Li"], "title": "Tensor graph convolutional neural network", "url": "http://arxiv.org/pdf/1803.10071v1", "summary": "In this paper, we propose a novel tensor graph convolutional neural network (TGCNN) to conduct convolution on factorizable graphs, for which here two types of problems are focused, one is sequential dynamic graphs and the other is cross-attribute graphs. Especially, we propose a graph preserving layer to memorize salient nodes of those factorized subgraphs, i.e. cross graph convolution and graph pooling. For cross graph convolution, a parameterized Kronecker sum operation is proposed to generate a conjunctive adjacency matrix characterizing the relationship between every pair of nodes across two subgraphs. Taking this operation, then general graph convolution may be efficiently performed followed by the composition of small matrices, which thus reduces high memory and computational burden. Encapsuling sequence graphs into a recursive learning, the dynamics of graphs can be efficiently encoded as well as the spatial layout of graphs. To validate the proposed TGCNN, experiments are conducted on skeleton action datasets as well as matrix completion dataset. The experiment results demonstrate that our method can achieve more competitive performance with the state-of-the-art methods.", "published": "2018-03-27T13:34:05Z", "version": 1}, {"aid": "1803.10470", "authors": ["Jaan Aru", "Raul Vicente"], "title": "What deep learning can tell us about higher cognitive functions like mindreading?", "url": "http://arxiv.org/pdf/1803.10470v2", "summary": "Can deep learning (DL) guide our understanding of computations happening in biological brain? We will first briefly consider how DL has contributed to the research on visual object recognition. In the main part we will assess whether DL could also help us to clarify the computations underlying higher cognitive functions such as Theory of Mind. In addition, we will compare the objectives and learning signals of brains and machines, leading us to conclude that simply scaling up the current DL algorithms will most likely not lead to human level Theory of Mind.", "published": "2018-03-28T08:58:49Z", "version": 2}, {"aid": "1803.10743", "authors": ["Taco S. Cohen", "Mario Geiger", "Maurice Weiler"], "title": "Intertwiners between Induced Representations (with Applications to the Theory of Equivariant Neural Networks)", "url": "http://arxiv.org/pdf/1803.10743v2", "summary": "Group equivariant and steerable convolutional neural networks (regular and steerable G-CNNs) have recently emerged as a very effective model class for learning from signal data such as 2D and 3D images, video, and other data where symmetries are present. In geometrical terms, regular G-CNNs represent data in terms of scalar fields (\"feature channels\"), whereas the steerable G-CNN can also use vector or tensor fields (\"capsules\") to represent data. In algebraic terms, the feature spaces in regular G-CNNs transform according to a regular representation of the group G, whereas the feature spaces in Steerable G-CNNs transform according to the more general induced representations of G. In order to make the network equivariant, each layer in a G-CNN is required to intertwine between the induced representations associated with its input and output space.   In this paper we present a general mathematical framework for G-CNNs on homogeneous spaces like Euclidean space or the sphere. We show, using elementary methods, that the layers of an equivariant network are convolutional if and only if the input and output feature spaces transform according to an induced representation. This result, which follows from G.W. Mackey's abstract theory on induced representations, establishes G-CNNs as a universal class of equivariant network architectures, and generalizes the important recent work of Kondor & Trivedi on the intertwiners between regular representations.", "published": "2018-03-28T17:30:26Z", "version": 2}, {"aid": "1803.10794", "authors": ["Matthias M\u00fcller", "Adel Bibi", "Silvio Giancola", "Salman Al-Subaihi", "Bernard Ghanem"], "title": "TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild", "url": "http://arxiv.org/pdf/1803.10794v1", "summary": "Despite the numerous developments in object tracking, further development of current tracking algorithms is limited by small and mostly saturated datasets. As a matter of fact, data-hungry trackers based on deep-learning currently rely on object detection datasets due to the scarcity of dedicated large-scale tracking datasets. In this work, we present TrackingNet, the first large-scale dataset and benchmark for object tracking in the wild. We provide more than 30K videos with more than 14 million dense bounding box annotations. Our dataset covers a wide selection of object classes in broad and diverse context. By releasing such a large-scale dataset, we expect deep trackers to further improve and generalize. In addition, we introduce a new benchmark composed of 500 novel videos, modeled with a distribution similar to our training dataset. By sequestering the annotation of the test set and providing an online evaluation server, we provide a fair benchmark for future development of object trackers. Deep trackers fine-tuned on a fraction of our dataset improve their performance by up to 1.6% on OTB100 and up to 1.7% on TrackingNet Test. We provide an extensive benchmark on TrackingNet by evaluating more than 20 trackers. Our results suggest that object tracking in the wild is far from being solved.", "published": "2018-03-28T18:30:17Z", "version": 1}, {"aid": "1803.10827", "authors": ["Kiana Ehsani", "Hessam Bagherinezhad", "Joseph Redmon", "Roozbeh Mottaghi", "Ali Farhadi"], "title": "Who Let The Dogs Out? Modeling Dog Behavior From Visual Data", "url": "http://arxiv.org/pdf/1803.10827v2", "summary": "We introduce the task of directly modeling a visually intelligent agent. Computer vision typically focuses on solving various subtasks related to visual intelligence. We depart from this standard approach to computer vision; instead we directly model a visually intelligent agent. Our model takes visual information as input and directly predicts the actions of the agent. Toward this end we introduce DECADE, a large-scale dataset of ego-centric videos from a dog's perspective as well as her corresponding movements. Using this data we model how the dog acts and how the dog plans her movements. We show under a variety of metrics that given just visual input we can successfully model this intelligent agent in many situations. Moreover, the representation learned by our model encodes distinct information compared to representations trained on image classification, and our learned representation can generalize to other domains. In particular, we show strong results on the task of walkable surface estimation by using this dog modeling task as representation learning.", "published": "2018-03-28T19:43:33Z", "version": 2}, {"aid": "1803.10981", "authors": ["Ian P. Gent", "Ciaran McCreesh", "Ian Miguel", "Neil C. A. Moore", "Peter Nightingale", "Patrick Prosser", "Chris Unsworth"], "title": "A Review of Literature on Parallel Constraint Solving", "url": "http://arxiv.org/pdf/1803.10981v1", "summary": "As multicore computing is now standard, it seems irresponsible for constraints researchers to ignore the implications of it. Researchers need to address a number of issues to exploit parallelism, such as: investigating which constraint algorithms are amenable to parallelisation; whether to use shared memory or distributed computation; whether to use static or dynamic decomposition; and how to best exploit portfolios and cooperating search. We review the literature, and see that we can sometimes do quite well, some of the time, on some instances, but we are far from a general solution. Yet there seems to be little overall guidance that can be given on how best to exploit multicore computers to speed up constraint solving. We hope at least that this survey will provide useful pointers to future researchers wishing to correct this situation.   Under consideration in Theory and Practice of Logic Programming (TPLP).", "published": "2018-03-29T09:34:09Z", "version": 1}, {"aid": "1803.11261", "authors": ["Kush R. Varshney"], "title": "How an Electrical Engineer Became an Artificial Intelligence Researcher, a Multiphase Active Contours Analysis", "url": "http://arxiv.org/pdf/1803.11261v1", "summary": "This essay examines how what is considered to be artificial intelligence (AI) has changed over time and come to intersect with the expertise of the author. Initially, AI developed on a separate trajectory, both topically and institutionally, from pattern recognition, neural information processing, decision and control systems, and allied topics by focusing on symbolic systems within computer science departments rather than on continuous systems in electrical engineering departments. The separate evolutions continued throughout the author's lifetime, with some crossover in reinforcement learning and graphical models, but were shocked into converging by the virality of deep learning, thus making an electrical engineer into an AI researcher. Now that this convergence has happened, opportunity exists to pursue an agenda that combines learning and reasoning bridged by interpretable machine learning models.", "published": "2018-03-29T21:11:32Z", "version": 1}, {"aid": "1803.11370", "authors": ["Akito Takeki", "Daiki Ikami", "Go Irie", "Kiyoharu Aizawa"], "title": "Parallel Grid Pooling for Data Augmentation", "url": "http://arxiv.org/pdf/1803.11370v1", "summary": "Convolutional neural network (CNN) architectures utilize downsampling layers, which restrict the subsequent layers to learn spatially invariant features while reducing computational costs. However, such a downsampling operation makes it impossible to use the full spectrum of input features. Motivated by this observation, we propose a novel layer called parallel grid pooling (PGP) which is applicable to various CNN models. PGP performs downsampling without discarding any intermediate feature. It works as data augmentation and is complementary to commonly used data augmentation techniques. Furthermore, we demonstrate that a dilated convolution can naturally be represented using PGP operations, which suggests that the dilated convolution can also be regarded as a type of data augmentation technique. Experimental results based on popular image classification benchmarks demonstrate the effectiveness of the proposed method. Code is available at: https://github.com/akitotakeki", "published": "2018-03-30T07:25:00Z", "version": 1}, {"aid": "1803.11405", "authors": ["Rohit Keshari", "Mayank Vatsa", "Richa Singh", "Afzel Noore"], "title": "Learning Structure and Strength of CNN Filters for Small Sample Size Training", "url": "http://arxiv.org/pdf/1803.11405v1", "summary": "Convolutional Neural Networks have provided state-of-the-art results in several computer vision problems. However, due to a large number of parameters in CNNs, they require a large number of training samples which is a limiting factor for small sample size problems. To address this limitation, we propose SSF-CNN which focuses on learning the structure and strength of filters. The structure of the filter is initialized using a dictionary-based filter learning algorithm and the strength of the filter is learned using the small sample training data. The architecture provides the flexibility of training with both small and large training databases and yields good accuracies even with small size training data. The effectiveness of the algorithm is first demonstrated on MNIST, CIFAR10, and NORB databases, with a varying number of training samples. The results show that SSF-CNN significantly reduces the number of parameters required for training while providing high accuracies the test databases. On small sample size problems such as newborn face recognition and Omniglot, it yields state-of-the-art results. Specifically, on the IIITD Newborn Face Database, the results demonstrate improvement in rank-1 identification accuracy by at least 10%.", "published": "2018-03-30T10:34:33Z", "version": 1}, {"aid": "1804.00326", "authors": ["Arsha Nagrani", "Samuel Albanie", "Andrew Zisserman"], "title": "Seeing Voices and Hearing Faces: Cross-modal biometric matching", "url": "http://arxiv.org/pdf/1804.00326v2", "summary": "We introduce a seemingly impossible task: given only an audio clip of someone speaking, decide which of two face images is the speaker. In this paper we study this, and a number of related cross-modal tasks, aimed at answering the question: how much can we infer from the voice about the face and vice versa? We study this task \"in the wild\", employing the datasets that are now publicly available for face recognition from static images (VGGFace) and speaker identification from audio (VoxCeleb). These provide training and testing scenarios for both static and dynamic testing of cross-modal matching. We make the following contributions: (i) we introduce CNN architectures for both binary and multi-way cross-modal face and audio matching, (ii) we compare dynamic testing (where video information is available, but the audio is not from the same video) with static testing (where only a single still image is available), and (iii) we use human testing as a baseline to calibrate the difficulty of the task. We show that a CNN can indeed be trained to solve this task in both the static and dynamic scenarios, and is even well above chance on 10-way classification of the face given the voice. The CNN matches human performance on easy examples (e.g. different gender across faces) but exceeds human performance on more challenging examples (e.g. faces with the same gender, age and nationality).", "published": "2018-04-01T18:02:41Z", "version": 2}, {"aid": "1804.00586", "authors": ["Jianwen Xie", "Zilong Zheng", "Ruiqi Gao", "Wenguan Wang", "Song-Chun Zhu", "Ying Nian Wu"], "title": "Learning Descriptor Networks for 3D Shape Synthesis and Analysis", "url": "http://arxiv.org/pdf/1804.00586v1", "summary": "This paper proposes a 3D shape descriptor network, which is a deep convolutional energy-based model, for modeling volumetric shape patterns. The maximum likelihood training of the model follows an \"analysis by synthesis\" scheme and can be interpreted as a mode seeking and mode shifting process. The model can synthesize 3D shape patterns by sampling from the probability distribution via MCMC such as Langevin dynamics. The model can be used to train a 3D generator network via MCMC teaching. The conditional version of the 3D shape descriptor net can be used for 3D object recovery and 3D object super-resolution. Experiments demonstrate that the proposed model can generate realistic 3D shape patterns and can be useful for 3D shape analysis.", "published": "2018-04-02T15:15:34Z", "version": 1}, {"aid": "1804.00863", "authors": ["Maxim Maximov", "Laura Leal-Taix\u00e9", "Mario Fritz", "Tobias Ritschel"], "title": "Deep Appearance Maps", "url": "http://arxiv.org/pdf/1804.00863v3", "summary": "We propose a deep representation of appearance, i. e., the relation of color, surface orientation, viewer position, material and illumination. Previous approaches have useddeep learning to extract classic appearance representationsrelating to reflectance model parameters (e. g., Phong) orillumination (e. g., HDR environment maps). We suggest todirectly represent appearance itself as a network we call aDeep Appearance Map (DAM). This is a 4D generalizationover 2D reflectance maps, which held the view direction fixed. First, we show how a DAM can be learned from images or video frames and later be used to synthesize appearance, given new surface orientations and viewer positions. Second, we demonstrate how another network can be used to map from an image or video frames to a DAM network to reproduce this appearance, without using a lengthy optimization such as stochastic gradient descent (learning-to-learn). Finally, we show the example of an appearance estimation-and-segmentation task, mapping from an image showingmultiple materials to multiple deep appearance maps.", "published": "2018-04-03T08:17:38Z", "version": 3}, {"aid": "1804.00946", "authors": ["Wenjie Pei", "David M. J. Tax"], "title": "Unsupervised Learning of Sequence Representations by Autoencoders", "url": "http://arxiv.org/pdf/1804.00946v2", "summary": "Sequence data is challenging for machine learning approaches, because the lengths of the sequences may vary between samples. In this paper, we present an unsupervised learning model for sequence data, called the Integrated Sequence Autoencoder (ISA), to learn a fixed-length vectorial representation by minimizing the reconstruction error. Specifically, we propose to integrate two classical mechanisms for sequence reconstruction which takes into account both the global silhouette information and the local temporal dependencies. Furthermore, we propose a stop feature that serves as a temporal stamp to guide the reconstruction process, which results in a higher-quality representation. The learned representation is able to effectively summarize not only the apparent features, but also the underlying and high-level style information. Take for example a speech sequence sample: our ISA model can not only recognize the spoken text (apparent feature), but can also discriminate the speaker who utters the audio (more high-level style). One promising application of the ISA model is that it can be readily used in the semi-supervised learning scenario, in which a large amount of unlabeled data is leveraged to extract high-quality sequence representations and thus to improve the performance of the subsequent supervised learning tasks on limited labeled data.", "published": "2018-04-03T13:12:45Z", "version": 2}, {"aid": "1804.01050", "authors": ["Garoe Dorta", "Sara Vicente", "Lourdes Agapito", "Neill D. F. Campbell", "Ivor Simpson"], "title": "Training VAEs Under Structured Residuals", "url": "http://arxiv.org/pdf/1804.01050v3", "summary": "Variational auto-encoders (VAEs) are a popular and powerful deep generative model. Previous works on VAEs have assumed a factorized likelihood model, whereby the output uncertainty of each pixel is assumed to be independent. This approximation is clearly limited as demonstrated by observing a residual image from a VAE reconstruction, which often possess a high level of structure. This paper demonstrates a novel scheme to incorporate a structured Gaussian likelihood prediction network within the VAE that allows the residual correlations to be modeled. Our novel architecture, with minimal increase in complexity, incorporates the covariance matrix prediction within the VAE. We also propose a new mechanism for allowing structured uncertainty on color images. Furthermore, we provide a scheme for effectively training this model, and include some suggestions for improving performance in terms of efficiency or modeling longer range correlations.", "published": "2018-04-03T16:04:22Z", "version": 3}, {"aid": "1804.01128", "authors": ["Luis Piloto", "Ari Weinstein", "Dhruva TB", "Arun Ahuja", "Mehdi Mirza", "Greg Wayne", "David Amos", "Chia-chun Hung", "Matt Botvinick"], "title": "Probing Physics Knowledge Using Tools from Developmental Psychology", "url": "http://arxiv.org/pdf/1804.01128v1", "summary": "In order to build agents with a rich understanding of their environment, one key objective is to endow them with a grasp of intuitive physics; an ability to reason about three-dimensional objects, their dynamic interactions, and responses to forces. While some work on this problem has taken the approach of building in components such as ready-made physics engines, other research aims to extract general physical concepts directly from sensory data. In the latter case, one challenge that arises is evaluating the learning system. Research on intuitive physics knowledge in children has long employed a violation of expectations (VOE) method to assess children's mastery of specific physical concepts. We take the novel step of applying this method to artificial learning systems. In addition to introducing the VOE technique, we describe a set of probe datasets inspired by classic test stimuli from developmental psychology. We test a baseline deep learning system on this battery, as well as on a physics learning dataset (\"IntPhys\") recently posed by another research group. Our results show how the VOE technique may provide a useful tool for tracking physics knowledge in future research.", "published": "2018-04-03T18:47:46Z", "version": 1}, {"aid": "1804.01144", "authors": ["Carlos Gershenson", "Vito Trianni", "Justin Werfel", "Hiroki Sayama"], "title": "Self-Organization and Artificial Life: A Review", "url": "http://arxiv.org/pdf/1804.01144v1", "summary": "Self-organization has been an important concept within a number of disciplines, which Artificial Life (ALife) also has heavily utilized since its inception. The term and its implications, however, are often confusing or misinterpreted. In this work, we provide a mini-review of self-organization and its relationship with ALife, aiming at initiating discussions on this important topic with the interested audience. We first articulate some fundamental aspects of self-organization, outline its usage, and review its applications to ALife within its soft, hard, and wet domains. We also provide perspectives for further research.", "published": "2018-04-03T19:44:09Z", "version": 1}, {"aid": "1804.01159", "authors": ["Rajeev Ranjan", "Ankan Bansal", "Hongyu Xu", "Swami Sankaranarayanan", "Jun-Cheng Chen", "Carlos D. Castillo", "Rama Chellappa"], "title": "Crystal Loss and Quality Pooling for Unconstrained Face Verification and Recognition", "url": "http://arxiv.org/pdf/1804.01159v2", "summary": "In recent years, the performance of face verification and recognition systems based on deep convolutional neural networks (DCNNs) has significantly improved. A typical pipeline for face verification includes training a deep network for subject classification with softmax loss, using the penultimate layer output as the feature descriptor, and generating a cosine similarity score given a pair of face images or videos. The softmax loss function does not optimize the features to have higher similarity score for positive pairs and lower similarity score for negative pairs, which leads to a performance gap. In this paper, we propose a new loss function, called Crystal Loss, that restricts the features to lie on a hypersphere of a fixed radius. The loss can be easily implemented using existing deep learning frameworks. We show that integrating this simple step in the training pipeline significantly improves the performance of face verification and recognition systems. We achieve state-of-the-art performance for face verification and recognition on challenging LFW, IJB-A, IJB-B and IJB-C datasets over a large range of false alarm rates (10-1 to 10-7).", "published": "2018-04-03T20:30:25Z", "version": 2}, {"aid": "1804.01193", "authors": ["Bart Jacobs", "Fabio Zanasi"], "title": "The Logical Essentials of Bayesian Reasoning", "url": "http://arxiv.org/pdf/1804.01193v2", "summary": "This chapter offers an accessible introduction to the channel-based approach to Bayesian probability theory. This framework rests on algebraic and logical foundations, inspired by the methodologies of programming language semantics. It offers a uniform, structured and expressive language for describing Bayesian phenomena in terms of familiar programming concepts, like channel, predicate transformation and state transformation. The introduction also covers inference in Bayesian networks, which will be modelled by a suitable calculus of string diagrams.", "published": "2018-04-03T23:55:41Z", "version": 2}, {"aid": "1804.01508", "authors": ["Ole-Christoffer Granmo"], "title": "The Tsetlin Machine -- A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic", "url": "http://arxiv.org/pdf/1804.01508v15", "summary": "Although simple individually, artificial neurons provide state-of-the-art performance when interconnected in deep networks. Arguably, the Tsetlin Automaton is an even simpler and more versatile learning mechanism, capable of solving the multi-armed bandit problem. Merely by means of a single integer as memory, it learns the optimal action in stochastic environments through increment and decrement operations. In this paper, we introduce the Tsetlin Machine, which solves complex pattern recognition problems with propositional formulas, composed by a collective of Tsetlin Automata. To eliminate the longstanding problem of vanishing signal-to-noise ratio, the Tsetlin Machine orchestrates the automata using a novel game. Further, both inputs, patterns, and outputs are expressed as bits, while recognition and learning rely on bit manipulation, simplifying computation. Our theoretical analysis establishes that the Nash equilibria of the game align with the propositional formulas that provide optimal pattern recognition accuracy. This translates to learning without local optima, only global ones. In five benchmarks, the Tsetlin Machine provides competitive accuracy compared with SVMs, Decision Trees, Random Forests, Naive Bayes Classifier, Logistic Regression, and Neural Networks. We further demonstrate how the propositional formulas facilitate interpretation. In conclusion, we believe the combination of high accuracy, interpretability, and computational simplicity makes the Tsetlin Machine a promising tool for a wide range of domains.", "published": "2018-04-04T16:52:34Z", "version": 15}, {"aid": "1804.02307", "authors": ["Ganesh Sundaramoorthi", "Anthony Yezzi"], "title": "Accelerated Optimization in the PDE Framework: Formulations for the Manifold of Diffeomorphisms", "url": "http://arxiv.org/pdf/1804.02307v2", "summary": "We consider the problem of optimization of cost functionals on the infinite-dimensional manifold of diffeomorphisms. We present a new class of optimization methods, valid for any optimization problem setup on the space of diffeomorphisms by generalizing Nesterov accelerated optimization to the manifold of diffeomorphisms. While our framework is general for infinite dimensional manifolds, we specifically treat the case of diffeomorphisms, motivated by optical flow problems in computer vision. This is accomplished by building on a recent variational approach to a general class of accelerated optimization methods by Wibisono, Wilson and Jordan, which applies in finite dimensions. We generalize that approach to infinite dimensional manifolds. We derive the surprisingly simple continuum evolution equations, which are partial differential equations, for accelerated gradient descent, and relate it to simple mechanical principles from fluid mechanics. Our approach has natural connections to the optimal mass transport problem. This is because one can think of our approach as an evolution of an infinite number of particles endowed with mass (represented with a mass density) that moves in an energy landscape. The mass evolves with the optimization variable, and endows the particles with dynamics. This is different than the finite dimensional case where only a single particle moves and hence the dynamics does not depend on the mass. We derive the theory, compute the PDEs for accelerated optimization, and illustrate the behavior of these new accelerated optimization schemes.", "published": "2018-04-04T19:58:03Z", "version": 2}, {"aid": "1804.01654", "authors": ["Nanyang Wang", "Yinda Zhang", "Zhuwen Li", "Yanwei Fu", "Wei Liu", "Yu-Gang Jiang"], "title": "Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images", "url": "http://arxiv.org/pdf/1804.01654v2", "summary": "We propose an end-to-end deep learning architecture that produces a 3D shape in triangular mesh from a single color image. Limited by the nature of deep neural network, previous methods usually represent a 3D shape in volume or point cloud, and it is non-trivial to convert them to the more ready-to-use mesh model. Unlike the existing methods, our network represents 3D mesh in a graph-based convolutional neural network and produces correct geometry by progressively deforming an ellipsoid, leveraging perceptual features extracted from the input image. We adopt a coarse-to-fine strategy to make the whole deformation procedure stable, and define various of mesh related losses to capture properties of different levels to guarantee visually appealing and physically accurate 3D geometry. Extensive experiments show that our method not only qualitatively produces mesh model with better details, but also achieves higher 3D shape estimation accuracy compared to the state-of-the-art.", "published": "2018-04-05T02:24:03Z", "version": 2}, {"aid": "1804.01661", "authors": ["Xin Yu", "Zhiding Yu", "Srikumar Ramalingam"], "title": "Learning Strict Identity Mappings in Deep Residual Networks", "url": "http://arxiv.org/pdf/1804.01661v5", "summary": "A family of super deep networks, referred to as residual networks or ResNet, achieved record-beating performance in various visual tasks such as image recognition, object detection, and semantic segmentation. The ability to train very deep networks naturally pushed the researchers to use enormous resources to achieve the best performance. Consequently, in many applications super deep residual networks were employed for just a marginal improvement in performance. In this paper, we propose epsilon-ResNet that allows us to automatically discard redundant layers, which produces responses that are smaller than a threshold epsilon, with a marginal or no loss in performance. The epsilon-ResNet architecture can be achieved using a few additional rectified linear units in the original ResNet. Our method does not use any additional variables nor numerous trials like other hyper-parameter optimization techniques. The layer selection is achieved using a single training process and the evaluation is performed on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. In some instances, we achieve about 80% reduction in the number of parameters.", "published": "2018-04-05T03:19:53Z", "version": 5}, {"aid": "1804.02276", "authors": ["Fay\u00e7al Ait Aoudia", "Jakob Hoydis"], "title": "End-to-End Learning of Communications Systems Without a Channel Model", "url": "http://arxiv.org/pdf/1804.02276v3", "summary": "The idea of end-to-end learning of communications systems through neural network -based autoencoders has the shortcoming that it requires a differentiable channel model. We present in this paper a novel learning algorithm which alleviates this problem. The algorithm iterates between supervised training of the receiver and reinforcement learning -based training of the transmitter. We demonstrate that this approach works as well as fully supervised methods on additive white Gaussian noise (AWGN) and Rayleigh block-fading (RBF) channels. Surprisingly, while our method converges slower on AWGN channels than supervised training, it converges faster on RBF channels. Our results are a first step towards learning of communications systems over any type of channel without prior assumptions.", "published": "2018-04-06T14:01:00Z", "version": 3}, {"aid": "1804.02477", "authors": ["Abhinav Verma", "Vijayaraghavan Murali", "Rishabh Singh", "Pushmeet Kohli", "Swarat Chaudhuri"], "title": "Programmatically Interpretable Reinforcement Learning", "url": "http://arxiv.org/pdf/1804.02477v3", "summary": "We present a reinforcement learning framework, called Programmatically Interpretable Reinforcement Learning (PIRL), that is designed to generate interpretable and verifiable agent policies. Unlike the popular Deep Reinforcement Learning (DRL) paradigm, which represents policies by neural networks, PIRL represents policies using a high-level, domain-specific programming language. Such programmatic policies have the benefits of being more easily interpreted than neural networks, and being amenable to verification by symbolic methods. We propose a new method, called Neurally Directed Program Search (NDPS), for solving the challenging nonsmooth optimization problem of finding a programmatic policy with maximal reward. NDPS works by first learning a neural policy network using DRL, and then performing a local search over programmatic policies that seeks to minimize a distance from this neural \"oracle\". We evaluate NDPS on the task of learning to drive a simulated car in the TORCS car-racing environment. We demonstrate that NDPS is able to discover human-readable policies that pass some significant performance bars. We also show that PIRL policies can have smoother trajectories, and can be more easily transferred to environments not encountered during training, than corresponding policies discovered by DRL.", "published": "2018-04-06T22:17:18Z", "version": 3}, {"aid": "1804.02698", "authors": ["Takumi Ichimura", "Daisuke Igaue"], "title": "Hierarchical Modular Reinforcement Learning Method and Knowledge Acquisition of State-Action Rule for Multi-target Problem", "url": "http://arxiv.org/pdf/1804.02698v1", "summary": "Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered learning where Profit Sharing works to plan a prey position in the higher layer and Q-learning method trains the state-actions to the target in the lower layer. In this paper, we expanded HMRL to multi-target problem to take the distance between targets to the consideration. The function, called `AT field', can estimate the interests for an agent according to the distance between 2 agents and the advantage/disadvantage of the other agent. Moreover, the knowledge related to state-action rules is extracted by C4.5. The action under the situation is decided by using the acquired knowledge. To verify the effectiveness of proposed method, some experimental results are reported.", "published": "2018-04-08T14:39:13Z", "version": 1}, {"aid": "1804.02767", "authors": ["Joseph Redmon", "Ali Farhadi"], "title": "YOLOv3: An Incremental Improvement", "url": "http://arxiv.org/pdf/1804.02767v1", "summary": "We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/", "published": "2018-04-08T22:27:57Z", "version": 1}, {"aid": "1804.02913", "authors": ["Kuldeep Purohit", "Anshul Shah", "A. N. Rajagopalan"], "title": "Bringing Alive Blurred Moments", "url": "http://arxiv.org/pdf/1804.02913v2", "summary": "We present a solution for the goal of extracting a video from a single motion blurred image to sequentially reconstruct the clear views of a scene as beheld by the camera during the time of exposure. We first learn motion representation from sharp videos in an unsupervised manner through training of a convolutional recurrent video autoencoder network that performs a surrogate task of video reconstruction. Once trained, it is employed for guided training of a motion encoder for blurred images. This network extracts embedded motion information from the blurred image to generate a sharp video in conjunction with the trained recurrent video decoder. As an intermediate step, we also design an efficient architecture that enables real-time single image deblurring and outperforms competing methods across all factors: accuracy, speed, and compactness. Experiments on real scenes and standard datasets demonstrate the superiority of our framework over the state-of-the-art and its ability to generate a plausible sequence of temporally consistent sharp frames.", "published": "2018-04-09T11:14:32Z", "version": 2}, {"aid": "1804.02952", "authors": ["J. H. van Hateren"], "title": "A theory of consciousness: computation, algorithm, and neurobiological realization", "url": "http://arxiv.org/pdf/1804.02952v4", "summary": "The most enigmatic aspect of consciousness is the fact that it is felt, as a subjective sensation. The theory proposed here aims to explain this particular aspect. The theory encompasses both the computation that is presumably involved and the way in which that computation may be realized in the brain's neurobiology. It is assumed that the brain makes an internal estimate of an individual's own evolutionary fitness, which can be shown to produce a special, distinct form of causation. Communicating components of the fitness estimate (either for external or internal use) requires inverting them. Such inversion can be performed by the thalamocortical feedback loop in the mammalian brain, if that loop is operating in a switched, dual-stage mode. A first (nonconscious) stage produces forward estimates, whereas the second (conscious) stage inverts those estimates. It is argued that inversion produces another special, distinct form of causation, which is spatially localized and is plausibly sensed as the feeling of consciousness.", "published": "2018-04-09T13:02:35Z", "version": 4}, {"aid": "1804.02967", "authors": ["Jose Dolz", "Karthik Gopinath", "Jing Yuan", "Herve Lombaert", "Christian Desrosiers", "Ismail Ben Ayed"], "title": "HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation", "url": "http://arxiv.org/pdf/1804.02967v2", "summary": "Recently, dense connections have attracted substantial attention in computer vision because they facilitate gradient flow and implicit deep supervision during training. Particularly, DenseNet, which connects each layer to every other layer in a feed-forward fashion, has shown impressive performances in natural image classification tasks. We propose HyperDenseNet, a 3D fully convolutional neural network that extends the definition of dense connectivity to multi-modal segmentation problems. Each imaging modality has a path, and dense connections occur not only between the pairs of layers within the same path, but also between those across different paths. This contrasts with the existing multi-modal CNN approaches, in which modeling several modalities relies entirely on a single joint layer (or level of abstraction) for fusion, typically either at the input or at the output of the network. Therefore, the proposed network has total freedom to learn more complex combinations between the modalities, within and in-between all the levels of abstraction, which increases significantly the learning representation. We report extensive evaluations over two different and highly competitive multi-modal brain tissue segmentation challenges, iSEG 2017 and MRBrainS 2013, with the former focusing on 6-month infant data and the latter on adult images. HyperDenseNet yielded significant improvements over many state-of-the-art segmentation networks, ranking at the top on both benchmarks. We further provide a comprehensive experimental analysis of features re-use, which confirms the importance of hyper-dense connections in multi-modal representation learning. Our code is publicly available at https://www.github.com/josedolz/HyperDenseNet.", "published": "2018-04-09T13:26:13Z", "version": 2}, {"aid": "1804.02969", "authors": ["Tom\u00e1\u0161 Kliegr", "\u0160t\u011bp\u00e1n Bahn\u00edk", "Johannes F\u00fcrnkranz"], "title": "A review of possible effects of cognitive biases on the interpretation of rule-based machine learning models", "url": "http://arxiv.org/pdf/1804.02969v7", "summary": "While the interpretability of machine learning models is often equated with their mere syntactic comprehensibility, we think that interpretability goes beyond that, and that human interpretability should also be investigated from the point of view of cognitive science. The goal of this paper is to discuss to what extent cognitive biases may affect human understanding of interpretable machine learning models, in particular of logical rules discovered from data. Twenty cognitive biases are covered, as are possible debiasing techniques that can be adopted by designers of machine learning algorithms and software. Our review transfers results obtained in cognitive psychology to the domain of machine learning, aiming to bridge the current gap between these two areas. It needs to be followed by empirical studies specifically focused on the machine learning domain.", "published": "2018-04-09T13:28:56Z", "version": 7}, {"aid": "1804.03313", "authors": ["Liyao Gao"], "title": "Cortex Neural Network: learning with Neural Network groups", "url": "http://arxiv.org/pdf/1804.03313v1", "summary": "Neural Network has been successfully applied to many real-world problems, such as image recognition and machine translation. However, for the current architecture of neural networks, it is hard to perform complex cognitive tasks, for example, to process the image and audio inputs together. Cortex, as an important architecture in the brain, is important for animals to perform the complex cognitive task. We view the architecture of Cortex in the brain as a missing part in the design of the current artificial neural network. In this paper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is an upper architecture of neural networks which motivated from cerebral cortex in the brain to handle different tasks in the same learning system. It is able to identify different tasks and solve them with different methods. In our implementation, the Cortex Neural Network is able to process different cognitive tasks and perform reflection to get a higher accuracy. We provide a series of experiments to examine the capability of the cortex architecture on traditional neural networks. Our experiments proved its ability on the Cortex Neural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the same time, which can promisingly reduce the loss by 40%.", "published": "2018-04-10T02:33:47Z", "version": 1}, {"aid": "1804.03368", "authors": ["Dong Gong", "Zhen Zhang", "Qinfeng Shi", "Anton van den Hengel", "Chunhua Shen", "Yanning Zhang"], "title": "Learning Deep Gradient Descent Optimization for Image Deconvolution", "url": "http://arxiv.org/pdf/1804.03368v2", "summary": "As an integral component of blind image deblurring, non-blind deconvolution removes image blur with a given blur kernel, which is essential but difficult due to the ill-posed nature of the inverse problem. The predominant approach is based on optimization subject to regularization functions that are either manually designed, or learned from examples. Existing learning based methods have shown superior restoration quality but are not practical enough due to their restricted and static model design. They solely focus on learning a prior and require to know the noise level for deconvolution. We address the gap between the optimization-based and learning-based approaches by learning a universal gradient descent optimizer. We propose a Recurrent Gradient Descent Network (RGDN) by systematically incorporating deep neural networks into a fully parameterized gradient descent scheme. A hyper-parameter-free update unit shared across steps is used to generate updates from the current estimates, based on a convolutional neural network. By training on diverse examples, the Recurrent Gradient Descent Network learns an implicit image prior and a universal update rule through recursive supervision. The learned optimizer can be repeatedly used to improve the quality of diverse degenerated observations. The proposed method possesses strong interpretability and high generalization. Extensive experiments on synthetic benchmarks and challenging real-world images demonstrate that the proposed deep optimization method is effective and robust to produce favorable results as well as practical for real-world image deblurring applications.", "published": "2018-04-10T06:58:12Z", "version": 2}, {"aid": "1804.03439", "authors": ["Wojciech Skaba"], "title": "Evaluating Actuators in a Purely Information-Theory Based Reward Model", "url": "http://arxiv.org/pdf/1804.03439v1", "summary": "AGINAO builds its cognitive engine by applying self-programming techniques to create a hierarchy of interconnected codelets - the tiny pieces of code executed on a virtual machine. These basic processing units are evaluated for their applicability and fitness with a notion of reward calculated from self-information gain of binary partitioning of the codelet's input state-space. This approach, however, is useless for the evaluation of actuators. Instead, a model is proposed in which actuators are evaluated by measuring the impact that an activation of an effector, and consequently the feedback from the robot sensors, has on average reward received by the processing units.", "published": "2018-04-10T10:34:36Z", "version": 1}, {"aid": "1804.04512", "authors": ["Baptiste Wicht", "Jean Hennebert", "Andreas Fischer"], "title": "DLL: A Blazing Fast Deep Neural Network Library", "url": "http://arxiv.org/pdf/1804.04512v1", "summary": "Deep Learning Library (DLL) is a new library for machine learning with deep neural networks that focuses on speed. It supports feed-forward neural networks such as fully-connected Artificial Neural Networks (ANNs) and Convolutional Neural Networks (CNNs). It also has very comprehensive support for Restricted Boltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this work was to propose and evaluate novel software engineering strategies with potential to accelerate runtime for training and inference. Such strategies are mostly independent of the underlying deep learning algorithms. On three different datasets and for four different neural network models, we compared DLL to five popular deep learning frameworks. Experimentally, it is shown that the proposed framework is systematically and significantly faster on CPU and GPU. In terms of classification performance, similar accuracies as the other frameworks are reported.", "published": "2018-04-11T13:56:07Z", "version": 1}, {"aid": "1804.03999", "authors": ["Ozan Oktay", "Jo Schlemper", "Loic Le Folgoc", "Matthew Lee", "Mattias Heinrich", "Kazunari Misawa", "Kensaku Mori", "Steven McDonagh", "Nils Y Hammerla", "Bernhard Kainz", "Ben Glocker", "Daniel Rueckert"], "title": "Attention U-Net: Learning Where to Look for the Pancreas", "url": "http://arxiv.org/pdf/1804.03999v3", "summary": "We propose a novel attention gate (AG) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes. Models trained with AGs implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a specific task. This enables us to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks (CNNs). AGs can be easily integrated into standard CNN architectures such as the U-Net model with minimal computational overhead while increasing the model sensitivity and prediction accuracy. The proposed Attention U-Net architecture is evaluated on two large CT abdominal datasets for multi-class image segmentation. Experimental results show that AGs consistently improve the prediction performance of U-Net across different datasets and training sizes while preserving computational efficiency. The code for the proposed architecture is publicly available.", "published": "2018-04-11T14:13:03Z", "version": 3}, {"aid": "1804.04020", "authors": ["Keiller Nogueira", "Mauro Dalla Mura", "Jocelyn Chanussot", "William R. Schwartz", "Jefersson A. dos Santos"], "title": "Dynamic Multi-Context Segmentation of Remote Sensing Images based on Convolutional Networks", "url": "http://arxiv.org/pdf/1804.04020v3", "summary": "Semantic segmentation requires methods capable of learning high-level features while dealing with large volume of data. Towards such goal, Convolutional Networks can learn specific and adaptable features based on the data. However, these networks are not capable of processing a whole remote sensing image, given its huge size. To overcome such limitation, the image is processed using fixed size patches. The definition of the input patch size is usually performed empirically (evaluating several sizes) or imposed (by network constraint). Both strategies suffer from drawbacks and could not lead to the best patch size. To alleviate this problem, several works exploited multi-context information by combining networks or layers. This process increases the number of parameters resulting in a more difficult model to train. In this work, we propose a novel technique to perform semantic segmentation of remote sensing images that exploits a multi-context paradigm without increasing the number of parameters while defining, in training time, the best patch size. The main idea is to train a dilated network with distinct patch sizes, allowing it to capture multi-context characteristics from heterogeneous contexts. While processing these varying patches, the network provides a score for each patch size, helping in the definition of the best size for the current scenario. A systematic evaluation of the proposed algorithm is conducted using four high-resolution remote sensing datasets with very distinct properties. Our results show that the proposed algorithm provides improvements in pixelwise classification accuracy when compared to state-of-the-art methods.", "published": "2018-04-11T14:32:15Z", "version": 3}, {"aid": "1804.04192", "authors": ["Naifan Zhuang", "The Duc Kieu", "Guo-Jun Qi", "Kien A. Hua"], "title": "Deep Differential Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1804.04192v1", "summary": "Due to the special gating schemes of Long Short-Term Memory (LSTM), LSTMs have shown greater potential to process complex sequential information than the traditional Recurrent Neural Network (RNN). The conventional LSTM, however, fails to take into consideration the impact of salient spatio-temporal dynamics present in the sequential input data. This problem was first addressed by the differential Recurrent Neural Network (dRNN), which uses a differential gating scheme known as Derivative of States (DoS). DoS uses higher orders of internal state derivatives to analyze the change in information gain caused by the salient motions between the successive frames. The weighted combination of several orders of DoS is then used to modulate the gates in dRNN. While each individual order of DoS is good at modeling a certain level of salient spatio-temporal sequences, the sum of all the orders of DoS could distort the detected motion patterns. To address this problem, we propose to control the LSTM gates via individual orders of DoS and stack multiple levels of LSTM cells in an increasing order of state derivatives. The proposed model progressively builds up the ability of the LSTM gates to detect salient dynamical patterns in deeper stacked layers modeling higher orders of DoS, and thus the proposed LSTM model is termed deep differential Recurrent Neural Network (d2RNN). The effectiveness of the proposed model is demonstrated on two publicly available human activity datasets: NUS-HGA and Violent-Flows. The proposed model outperforms both LSTM and non-LSTM based state-of-the-art algorithms.", "published": "2018-04-11T20:02:25Z", "version": 1}, {"aid": "1804.04235", "authors": ["Noam Shazeer", "Mitchell Stern"], "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost", "url": "http://arxiv.org/pdf/1804.04235v1", "summary": "In several recently proposed stochastic optimization methods (e.g. RMSProp, Adam, Adadelta), parameter updates are scaled by the inverse square roots of exponential moving averages of squared past gradients. Maintaining these per-parameter second-moment estimators requires memory equal to the number of parameters. For the case of neural network weight matrices, we propose maintaining only the per-row and per-column sums of these moving averages, and estimating the per-parameter second moments based on these sums. We demonstrate empirically that this method produces similar results to the baseline. Secondly, we show that adaptive methods can produce larger-than-desired updates when the decay rate of the second moment accumulator is too slow. We propose update clipping and a gradually increasing decay rate scheme as remedies. Combining these methods and dropping momentum, we achieve comparable results to the published Adam regime in training the Transformer model on the WMT 2014 English-German machine translation task, while using very little auxiliary storage in the optimizer. Finally, we propose scaling the parameter updates based on the scale of the parameters themselves.", "published": "2018-04-11T21:42:32Z", "version": 1}, {"aid": "1804.04438", "authors": ["Avraham Ruderman", "Neil C. Rabinowitz", "Ari S. Morcos", "Daniel Zoran"], "title": "Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs", "url": "http://arxiv.org/pdf/1804.04438v2", "summary": "Many of our core assumptions about how neural networks operate remain empirically untested. One common assumption is that convolutional neural networks need to be stable to small translations and deformations to solve image recognition tasks. For many years, this stability was baked into CNN architectures by incorporating interleaved pooling layers. Recently, however, interleaved pooling has largely been abandoned. This raises a number of questions: Are our intuitions about deformation stability right at all? Is it important? Is pooling necessary for deformation invariance? If not, how is deformation invariance achieved in its absence? In this work, we rigorously test these questions, and find that deformation stability in convolutional networks is more nuanced than it first appears: (1) Deformation invariance is not a binary property, but rather that different tasks require different degrees of deformation stability at different layers. (2) Deformation stability is not a fixed property of a network and is heavily adjusted over the course of training, largely through the smoothness of the convolutional filters. (3) Interleaved pooling layers are neither necessary nor sufficient for achieving the optimal form of deformation stability for natural image classification. (4) Pooling confers too much deformation stability for image classification at initialization, and during training, networks have to learn to counteract this inductive bias. Together, these findings provide new insights into the role of interleaved pooling and deformation invariance in CNNs, and demonstrate the importance of rigorous empirical testing of even our most basic assumptions about the working of neural networks.", "published": "2018-04-12T11:44:05Z", "version": 2}, {"aid": "1804.04694", "authors": ["Patrick Esser", "Ekaterina Sutter", "Bj\u00f6rn Ommer"], "title": "A Variational U-Net for Conditional Appearance and Shape Generation", "url": "http://arxiv.org/pdf/1804.04694v1", "summary": "Deep generative models have demonstrated great performance in image synthesis. However, results deteriorate in case of spatial deformations, since they generate images of objects directly, rather than modeling the intricate interplay of their inherent shape and appearance. We present a conditional U-Net for shape-guided image generation, conditioned on the output of a variational autoencoder for appearance. The approach is trained end-to-end on images, without requiring samples of the same object with varying pose or appearance. Experiments show that the model enables conditional image generation and transfer. Therefore, either shape or appearance can be retained from a query image, while freely altering the other. Moreover, appearance can be sampled due to its stochastic latent representation, while preserving shape. In quantitative and qualitative experiments on COCO, DeepFashion, shoes, Market-1501 and handbags, the approach demonstrates significant improvements over the state-of-the-art.", "published": "2018-04-12T19:05:57Z", "version": 1}, {"aid": "1804.05012", "authors": ["Peter L. Bartlett", "Steven N. Evans", "Philip M. Long"], "title": "Representing smooth functions as compositions of near-identity functions with implications for deep network optimization", "url": "http://arxiv.org/pdf/1804.05012v2", "summary": "We show that any smooth bi-Lipschitz $h$ can be represented exactly as a composition $h_m \\circ ... \\circ h_1$ of functions $h_1,...,h_m$ that are close to the identity in the sense that each $\\left(h_i-\\mathrm{Id}\\right)$ is Lipschitz, and the Lipschitz constant decreases inversely with the number $m$ of functions composed. This implies that $h$ can be represented to any accuracy by a deep residual network whose nonlinear layers compute functions with a small Lipschitz constant. Next, we consider nonlinear regression with a composition of near-identity nonlinear maps. We show that, regarding Fr\\'echet derivatives with respect to the $h_1,...,h_m$, any critical point of a quadratic criterion in this near-identity region must be a global minimizer. In contrast, if we consider derivatives with respect to parameters of a fixed-size residual network with sigmoid activation functions, we show that there are near-identity critical points that are suboptimal, even in the realizable case. Informally, this means that functional gradient methods for residual networks cannot get stuck at suboptimal critical points corresponding to near-identity layers, whereas parametric gradient methods for sigmoidal residual networks suffer from suboptimal critical points in the near-identity region.", "published": "2018-04-13T16:24:17Z", "version": 2}, {"aid": "1804.05181", "authors": ["Saeid Asgari Taghanaki", "Aicha Bentaieb", "Anmol Sharma", "S. Kevin Zhou", "Yefeng Zheng", "Bogdan Georgescu", "Puneet Sharma", "Sasa Grbic", "Zhoubing Xu", "Dorin Comaniciu", "Ghassan Hamarneh"], "title": "Select, Attend, and Transfer: Light, Learnable Skip Connections", "url": "http://arxiv.org/pdf/1804.05181v3", "summary": "Skip connections in deep networks have improved both segmentation and classification performance by facilitating the training of deeper network architectures, and reducing the risks for vanishing gradients. They equip encoder-decoder-like networks with richer feature representations, but at the cost of higher memory usage, computation, and possibly resulting in transferring non-discriminative feature maps. In this paper, we focus on improving skip connections used in segmentation networks (e.g., U-Net, V-Net, and The One Hundred Layers Tiramisu (DensNet) architectures). We propose light, learnable skip connections which learn to first select the most discriminative channels and then attend to the most discriminative regions of the selected feature maps. The output of the proposed skip connections is a unique feature map which not only reduces the memory usage and network parameters to a high extent, but also improves segmentation accuracy. We evaluate the proposed method on three different 2D and volumetric datasets and demonstrate that the proposed light, learnable skip connections can outperform the traditional heavy skip connections in terms of segmentation accuracy, memory usage, and number of network parameters.", "published": "2018-04-14T07:30:15Z", "version": 3}, {"aid": "1804.05340", "authors": ["Wenqi Liu", "Kun Zeng"], "title": "SparseNet: A Sparse DenseNet for Image Classification", "url": "http://arxiv.org/pdf/1804.05340v1", "summary": "Deep neural networks have made remarkable progresses on various computer vision tasks. Recent works have shown that depth, width and shortcut connections of networks are all vital to their performances. In this paper, we introduce a method to sparsify DenseNet which can reduce connections of a L-layer DenseNet from O(L^2) to O(L), and thus we can simultaneously increase depth, width and connections of neural networks in a more parameter-efficient and computation-efficient way. Moreover, an attention module is introduced to further boost our network's performance. We denote our network as SparseNet. We evaluate SparseNet on datasets of CIFAR(including CIFAR10 and CIFAR100) and SVHN. Experiments show that SparseNet can obtain improvements over the state-of-the-art on CIFAR10 and SVHN. Furthermore, while achieving comparable performances as DenseNet on these datasets, SparseNet is x2.6 smaller and x3.7 faster than the original DenseNet.", "published": "2018-04-15T11:29:30Z", "version": 1}, {"aid": "1804.05839", "authors": ["Jason Dai", "Yiheng Wang", "Xin Qiu", "Ding Ding", "Yao Zhang", "Yanzhang Wang", "Xianyan Jia", "Cherry Zhang", "Yan Wan", "Zhichao Li", "Jiao Wang", "Shengsheng Huang", "Zhongyuan Wu", "Yang Wang", "Yuhao Yang", "Bowen She", "Dongjie Shi", "Qi Lu", "Kai Huang", "Guoqiong Song"], "title": "BigDL: A Distributed Deep Learning Framework for Big Data", "url": "http://arxiv.org/pdf/1804.05839v4", "summary": "This paper presents BigDL (a distributed deep learning framework for Apache Spark), which has been used by a variety of users in the industry for building deep learning applications on production big data platforms. It allows deep learning applications to run on the Apache Hadoop/Spark cluster so as to directly process the production data, and as a part of the end-to-end data analysis pipeline for deployment and management. Unlike existing deep learning frameworks, BigDL implements distributed, data parallel training directly on top of the functional compute model (with copy-on-write and coarse-grained operations) of Spark. We also share real-world experience and \"war stories\" of users that have adopted BigDL to address their challenges(i.e., how to easily build end-to-end data analysis and deep learning pipelines for their production data).", "published": "2018-04-16T12:04:03Z", "version": 4}, {"aid": "1804.06114", "authors": ["Cong Chen", "Kim Batselier", "Ching-Yun Ko", "Ngai Wong"], "title": "A Support Tensor Train Machine", "url": "http://arxiv.org/pdf/1804.06114v1", "summary": "There has been growing interest in extending traditional vector-based machine learning techniques to their tensor forms. An example is the support tensor machine (STM) that utilizes a rank-one tensor to capture the data structure, thereby alleviating the overfitting and curse of dimensionality problems in the conventional support vector machine (SVM). However, the expressive power of a rank-one tensor is restrictive for many real-world data. To overcome this limitation, we introduce a support tensor train machine (STTM) by replacing the rank-one tensor in an STM with a tensor train. Experiments validate and confirm the superiority of an STTM over the SVM and STM.", "published": "2018-04-17T08:59:13Z", "version": 1}, {"aid": "1804.06458", "authors": ["Guillaume Baudart", "Martin Hirzel", "Louis Mandel"], "title": "Deep Probabilistic Programming Languages: A Qualitative Study", "url": "http://arxiv.org/pdf/1804.06458v1", "summary": "Deep probabilistic programming languages try to combine the advantages of deep learning with those of probabilistic programming languages. If successful, this would be a big step forward in machine learning and programming languages. Unfortunately, as of now, this new crop of languages is hard to use and understand. This paper addresses this problem directly by explaining deep probabilistic programming languages and indirectly by characterizing their current strengths and weaknesses.", "published": "2018-04-17T20:03:25Z", "version": 1}, {"aid": "1804.06655", "authors": ["Mei Wang", "Weihong Deng"], "title": "Deep Face Recognition: A Survey", "url": "http://arxiv.org/pdf/1804.06655v9", "summary": "Deep learning applies multiple processing layers to learn representations of data with multiple levels of feature extraction. This emerging technique has reshaped the research landscape of face recognition (FR) since 2014, launched by the breakthroughs of DeepFace and DeepID. Since then, deep learning technique, characterized by the hierarchical architecture to stitch together pixels into invariant face representation, has dramatically improved the state-of-the-art performance and fostered successful real-world applications. In this survey, we provide a comprehensive review of the recent developments on deep FR, covering broad topics on algorithm designs, databases, protocols, and application scenes. First, we summarize different network architectures and loss functions proposed in the rapid evolution of the deep FR methods. Second, the related face processing methods are categorized into two classes: \"one-to-many augmentation\" and \"many-to-one normalization\". Then, we summarize and compare the commonly used databases for both model training and evaluation. Third, we review miscellaneous scenes in deep FR, such as cross-factor, heterogenous, multiple-media and industrial scenes. Finally, the technical challenges and several promising directions are highlighted.", "published": "2018-04-18T11:20:32Z", "version": 9}, {"aid": "1804.07090", "authors": ["Amartya Sanyal", "Varun Kanade", "Philip H. S. Torr", "Puneet K. Dokania"], "title": "Robustness via Deep Low-Rank Representations", "url": "http://arxiv.org/pdf/1804.07090v5", "summary": "We investigate the effect of the dimensionality of the representations learned in Deep Neural Networks (DNNs) on their robustness to input perturbations, both adversarial and random. To achieve low dimensionality of learned representations, we propose an easy-to-use, end-to-end trainable, low-rank regularizer (LR) that can be applied to any intermediate layer representation of a DNN. This regularizer forces the feature representations to (mostly) lie in a low-dimensional linear subspace. We perform a wide range of experiments that demonstrate that the LR indeed induces low rank on the representations, while providing modest improvements to accuracy as an added benefit. Furthermore, the learned features make the trained model significantly more robust to input perturbations such as Gaussian and adversarial noise (even without adversarial training). Lastly, the low-dimensionality means that the learned features are highly compressible; thus discriminative features of the data can be stored using very little memory. Our experiments indicate that models trained using the LR learn robust classifiers by discovering subspaces that avoid non-robust features. Algorithmically, the LR is scalable, generic, and straightforward to implement into existing deep learning frameworks.", "published": "2018-04-19T11:17:41Z", "version": 5}, {"aid": "1804.07345", "authors": ["Sanjeel Parekh", "Slim Essid", "Alexey Ozerov", "Ngoc Q. K. Duong", "Patrick P\u00e9rez", "Ga\u00ebl Richard"], "title": "Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events", "url": "http://arxiv.org/pdf/1804.07345v2", "summary": "Audio-visual representation learning is an important task from the perspective of designing machines with the ability to understand complex events. To this end, we propose a novel multimodal framework that instantiates multiple instance learning. We show that the learnt representations are useful for classifying events and localizing their characteristic audio-visual elements. The system is trained using only video-level event labels without any timing information. An important feature of our method is its capacity to learn from unsynchronized audio-visual events. We achieve state-of-the-art results on a large-scale dataset of weakly-labeled audio event videos. Visualizations of localized visual regions and audio segments substantiate our system's efficacy, especially when dealing with noisy situations where modality-specific cues appear asynchronously.", "published": "2018-04-19T19:33:11Z", "version": 2}, {"aid": "1804.07612", "authors": ["Dominic Masters", "Carlo Luschi"], "title": "Revisiting Small Batch Training for Deep Neural Networks", "url": "http://arxiv.org/pdf/1804.07612v1", "summary": "Modern deep neural network training is typically based on mini-batch stochastic gradient optimization. While the use of large mini-batches increases the available computational parallelism, small batch training has been shown to provide improved generalization performance and allows a significantly smaller memory footprint, which might also be exploited to improve machine throughput.   In this paper, we review common assumptions on learning rate scaling and training duration, as a basis for an experimental comparison of test performance for different mini-batch sizes. We adopt a learning rate that corresponds to a constant average weight update per gradient calculation (i.e., per unit cost of computation), and point out that this results in a variance of the weight updates that increases linearly with the mini-batch size $m$.   The collected experimental results for the CIFAR-10, CIFAR-100 and ImageNet datasets show that increasing the mini-batch size progressively reduces the range of learning rates that provide stable convergence and acceptable test performance. On the other hand, small mini-batch sizes provide more up-to-date gradient calculations, which yields more stable and reliable training. The best performance has been consistently obtained for mini-batch sizes between $m = 2$ and $m = 32$, which contrasts with recent work advocating the use of mini-batch sizes in the thousands.", "published": "2018-04-20T13:44:12Z", "version": 1}, {"aid": "1804.07851", "authors": ["Ida H\u00e4ggstr\u00f6m", "C. Ross Schmidtlein", "Gabriele Campanella", "Thomas J. Fuchs"], "title": "DeepPET: A deep encoder-decoder network for directly solving the PET reconstruction inverse problem", "url": "http://arxiv.org/pdf/1804.07851v2", "summary": "Positron emission tomography (PET) is a cornerstone of modern radiology. The ability to detect cancer and metastases in whole body scans fundamentally changed cancer diagnosis and treatment. One of the main bottlenecks in the clinical application is the time it takes to reconstruct the anatomical image from the deluge of data in PET imaging. State-of-the art methods based on expectation maximization can take hours for a single patient and depend on manual fine-tuning. This results not only in financial burden for hospitals but more importantly leads to less efficient patient handling, evaluation, and ultimately diagnosis and treatment for patients. To overcome this problem we present a novel PET image reconstruction technique based on a deep convolutional encoder-decoder network, that takes PET sinogram data as input and directly outputs full PET images. Using realistic simulated data, we demonstrate that our network is able to reconstruct images >100 times faster, and with comparable image quality (in terms of root mean squared error) relative to conventional iterative reconstruction techniques.", "published": "2018-04-20T22:44:00Z", "version": 2}, {"aid": "1804.08010", "authors": ["Qibin Zheng", "Xingchun Diao", "Jianjun Cao", "Xiaolei Zhou", "Yi Liu", "Hongmei Li"], "title": "Multi-Modal Coreference Resolution with the Correlation between Space Structures", "url": "http://arxiv.org/pdf/1804.08010v2", "summary": "Multi-modal data is becoming more common in big data background. Finding the semantically similar objects from different modality is one of the heart problems of multi-modal learning. Most of the current methods try to learn the inter-modal correlation with extrinsic supervised information, while intrinsic structural information of each modality is neglected. The performance of these methods heavily depends on the richness of training samples. However, obtaining the multi-modal training samples is still a labor and cost intensive work. In this paper, we bring a extrinsic correlation between the space structures of each modalities in coreference resolution. With this correlation, a semi-supervised learning model for multi-modal coreference resolution is proposed. We firstly extract high-level features of images and text, then compute the distances of each object from some reference points to build the space structure of each modality. With a shared reference point set, the space structures of each modality are correlated. We employ the correlation to build a commonly shared space that the semantic distance between multi-modal objects can be computed directly. The experiments on two multi-modal datasets show that our model performs better than the existing methods with insufficient training data.", "published": "2018-04-21T19:15:19Z", "version": 2}, {"aid": "1804.08039", "authors": ["Wen Wei", "Emilie Poirion", "Benedetta Bodini", "Stanley Durrleman", "Nicholas Ayache", "Bruno Stankoff", "Olivier Colliot"], "title": "Learning Myelin Content in Multiple Sclerosis from Multimodal MRI through Adversarial Training", "url": "http://arxiv.org/pdf/1804.08039v2", "summary": "Multiple sclerosis (MS) is a demyelinating disease of the central nervous system (CNS). A reliable measure of the tissue myelin content is therefore essential for the understanding of the physiopathology of MS, tracking progression and assessing treatment efficacy. Positron emission tomography (PET) with $[^{11} \\mbox{C}] \\mbox{PIB}$ has been proposed as a promising biomarker for measuring myelin content changes in-vivo in MS. However, PET imaging is expensive and invasive due to the injection of a radioactive tracer. On the contrary, magnetic resonance imaging (MRI) is a non-invasive, widely available technique, but existing MRI sequences do not provide, to date, a reliable, specific, or direct marker of either demyelination or remyelination. In this work, we therefore propose Sketcher-Refiner Generative Adversarial Networks (GANs) with specifically designed adversarial loss functions to predict the PET-derived myelin content map from a combination of MRI modalities. The prediction problem is solved by a sketch-refinement process in which the sketcher generates the preliminary anatomical and physiological information and the refiner refines and generates images reflecting the tissue myelin content in the human brain. We evaluated the ability of our method to predict myelin content at both global and voxel-wise levels. The evaluation results show that the demyelination in lesion regions and myelin content in normal-appearing white matter (NAWM) can be well predicted by our method. The method has the potential to become a useful tool for clinical management of patients with MS.", "published": "2018-04-21T22:23:51Z", "version": 2}, {"aid": "1804.08042", "authors": ["Najeeb Khan", "Jawad Shah", "Ian Stavness"], "title": "Bridgeout: stochastic bridge regularization for deep neural networks", "url": "http://arxiv.org/pdf/1804.08042v1", "summary": "A major challenge in training deep neural networks is overfitting, i.e. inferior performance on unseen test examples compared to performance on training examples. To reduce overfitting, stochastic regularization methods have shown superior performance compared to deterministic weight penalties on a number of image recognition tasks. Stochastic methods such as Dropout and Shakeout, in expectation, are equivalent to imposing a ridge and elastic-net penalty on the model parameters, respectively. However, the choice of the norm of weight penalty is problem dependent and is not restricted to $\\{L_1,L_2\\}$. Therefore, in this paper we propose the Bridgeout stochastic regularization technique and prove that it is equivalent to an $L_q$ penalty on the weights, where the norm $q$ can be learned as a hyperparameter from data. Experimental results show that Bridgeout results in sparse model weights, improved gradients and superior classification performance compared to Dropout and Shakeout on synthetic and real datasets.", "published": "2018-04-21T23:27:24Z", "version": 1}, {"aid": "1804.08071", "authors": ["Weiyang Liu", "Zhen Liu", "Zhiding Yu", "Bo Dai", "Rongmei Lin", "Yisen Wang", "James M. Rehg", "Le Song"], "title": "Decoupled Networks", "url": "http://arxiv.org/pdf/1804.08071v1", "summary": "Inner product-based convolution has been a central component of convolutional neural networks (CNNs) and the key to learning visual representations. Inspired by the observation that CNN-learned features are naturally decoupled with the norm of features corresponding to the intra-class variation and the angle corresponding to the semantic difference, we propose a generic decoupled learning framework which models the intra-class variation and semantic difference independently. Specifically, we first reparametrize the inner product to a decoupled form and then generalize it to the decoupled convolution operator which serves as the building block of our decoupled networks. We present several effective instances of the decoupled convolution operator. Each decoupled operator is well motivated and has an intuitive geometric interpretation. Based on these decoupled operators, we further propose to directly learn the operator from data. Extensive experiments show that such decoupled reparameterization renders significant performance gain with easier convergence and stronger robustness.", "published": "2018-04-22T05:26:08Z", "version": 1}, {"aid": "1804.08139", "authors": ["Renjie Zheng", "Junkun Chen", "Xipeng Qiu"], "title": "Same Representation, Different Attentions: Shareable Sentence Representation Learning from Multiple Tasks", "url": "http://arxiv.org/pdf/1804.08139v1", "summary": "Distributed representation plays an important role in deep learning based natural language processing. However, the representation of a sentence often varies in different tasks, which is usually learned from scratch and suffers from the limited amounts of training data. In this paper, we claim that a good sentence representation should be invariant and can benefit the various subsequent tasks. To achieve this purpose, we propose a new scheme of information sharing for multi-task learning. More specifically, all tasks share the same sentence representation and each task can select the task-specific information from the shared sentence representation with attention mechanism. The query vector of each task's attention could be either static parameters or generated dynamically. We conduct extensive experiments on 16 different text classification tasks, which demonstrate the benefits of our architecture.", "published": "2018-04-22T17:13:06Z", "version": 1}, {"aid": "1804.08150", "authors": ["Amirhossein Tavanaei", "Masoud Ghodrati", "Saeed Reza Kheradpisheh", "Timothee Masquelier", "Anthony S. Maida"], "title": "Deep Learning in Spiking Neural Networks", "url": "http://arxiv.org/pdf/1804.08150v4", "summary": "In recent years, deep learning has been a revolution in the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained in a supervised manner using backpropagation. Huge amounts of labeled examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and arguably the only viable option if one wants to understand how the brain computes. SNNs are also more hardware friendly and energy-efficient than ANNs, and are thus appealing for technology, especially for portable devices. However, training deep SNNs remains a challenge. Spiking neurons' transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy, but also computational cost and hardware friendliness. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while the SNNs typically require much fewer operations.", "published": "2018-04-22T18:27:34Z", "version": 4}, {"aid": "1804.08378", "authors": ["Nicolas Weber", "Florian Schmidt", "Mathias Niepert", "Felipe Huici"], "title": "BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First Parallelism", "url": "http://arxiv.org/pdf/1804.08378v1", "summary": "Neural network frameworks such as PyTorch and TensorFlow are the workhorses of numerous machine learning applications ranging from object recognition to machine translation. While these frameworks are versatile and straightforward to use, the training of and inference in deep neural networks is resource (energy, compute, and memory) intensive. In contrast to recent works focusing on algorithmic enhancements, we introduce BrainSlug, a framework that transparently accelerates neural network workloads by changing the default layer-by-layer processing to a depth-first approach, reducing the amount of data required by the computations and thus improving the performance of the available hardware caches. BrainSlug achieves performance improvements of up to 41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the user as they do not require hardware changes and only need tiny adjustments to the software.", "published": "2018-04-23T12:49:04Z", "version": 1}, {"aid": "1804.09949", "authors": ["Adam Bielski", "Tomasz Trzcinski"], "title": "Pay Attention to Virality: understanding popularity of social media videos with the attention mechanism", "url": "http://arxiv.org/pdf/1804.09949v1", "summary": "Predicting popularity of social media videos before they are published is a challenging task, mainly due to the complexity of content distribution network as well as the number of factors that play part in this process. As solving this task provides tremendous help for media content creators, many successful methods were proposed to solve this problem with machine learning. In this work, we change the viewpoint and postulate that it is not only the predicted popularity that matters, but also, maybe even more importantly, understanding of how individual parts influence the final popularity score. To that end, we propose to combine the Grad-CAM visualization method with a soft attention mechanism. Our preliminary results show that this approach allows for more intuitive interpretation of the content impact on video popularity, while achieving competitive results in terms of prediction accuracy.", "published": "2018-04-26T09:06:06Z", "version": 1}, {"aid": "1804.10167", "authors": ["Maxim Sharaev", "Alexander Andreev", "Alexey Artemov", "Alexander Bernstein", "Evgeny Burnaev", "Ekaterina Kondratyeva", "Svetlana Sushchinskaya", "Renat Akzhigitov"], "title": "fMRI: preprocessing, classification and pattern recognition", "url": "http://arxiv.org/pdf/1804.10167v1", "summary": "As machine learning continues to gain momentum in the neuroscience community, we witness the emergence of novel applications such as diagnostics, characterization, and treatment outcome prediction for psychiatric and neurological disorders, for instance, epilepsy and depression. Systematic research into these mental disorders increasingly involves drawing clinical conclusions on the basis of data-driven approaches; to this end, structural and functional neuroimaging serve as key source modalities. Identification of informative neuroimaging markers requires establishing a comprehensive preparation pipeline for data which may be severely corrupted by artifactual signal fluctuations. In this work, we review a large body of literature to provide ample evidence for the advantages of pattern recognition approaches in clinical applications, overview advanced graph-based pattern recognition approaches, and propose a noise-aware neuroimaging data processing pipeline. To demonstrate the effectiveness of our approach, we provide results from a pilot study, which show a significant improvement in classification accuracy, indicating a promising research direction.", "published": "2018-04-26T16:48:52Z", "version": 1}, {"aid": "1804.10172", "authors": ["Andrew Gritsevskiy", "Maksym Korablyov"], "title": "Capsule networks for low-data transfer learning", "url": "http://arxiv.org/pdf/1804.10172v1", "summary": "We propose a capsule network-based architecture for generalizing learning to new data with few examples. Using both generative and non-generative capsule networks with intermediate routing, we are able to generalize to new information over 25 times faster than a similar convolutional neural network. We train the networks on the multiMNIST dataset lacking one digit. After the networks reach their maximum accuracy, we inject 1-100 examples of the missing digit into the training set, and measure the number of batches needed to return to a comparable level of accuracy. We then discuss the improvement in low-data transfer learning that capsule networks bring, and propose future directions for capsule research.", "published": "2018-04-26T17:01:12Z", "version": 1}, {"aid": "1804.11214", "authors": ["Yiming Xu", "Diego Klabjan"], "title": "k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural Networks and Memory Networks", "url": "http://arxiv.org/pdf/1804.11214v4", "summary": "k-Nearest Neighbors is one of the most fundamental but effective classification models. In this paper, we propose two families of models built on a sequence to sequence model and a memory network model to mimic the k-Nearest Neighbors model, which generate a sequence of labels, a sequence of out-of-sample feature vectors and a final label for classification, and thus they could also function as oversamplers. We also propose 'out-of-core' versions of our models which assume that only a small portion of data can be loaded into memory. Computational experiments show that our models on structured datasets outperform k-Nearest Neighbors, a feed-forward neural network, XGBoost, lightGBM, random forest and a memory network, due to the fact that our models must produce additional output and not just the label. On image and text datasets, the performance of our model is close to many state-of-the-art deep models. As an oversampler on imbalanced datasets, the sequence to sequence kNN model often outperforms Synthetic Minority Over-sampling Technique and Adaptive Synthetic Sampling.", "published": "2018-04-27T15:13:29Z", "version": 4}, {"aid": "1805.01352", "authors": ["Yangfan Hu", "Huajin Tang", "Gang Pan"], "title": "Spiking Deep Residual Network", "url": "http://arxiv.org/pdf/1805.01352v2", "summary": "Spiking neural networks (SNNs) have received significant attention for their biological plausibility. SNNs theoretically have at least the same computational power as traditional artificial neural networks (ANNs). They possess potential of achieving energy-efficiency while keeping comparable performance to deep neural networks (DNNs). However, it is still a big challenge to train a very deep SNN. In this paper, we propose an efficient approach to build a spiking version of deep residual network (ResNet). ResNet is considered as a kind of the state-of-the-art convolutional neural networks (CNNs). We employ the idea of converting a trained ResNet to a network of spiking neurons, named Spiking ResNet (S-ResNet). We propose a shortcut conversion model to appropriately scale continuous-valued activations to match firing rates in SNN, and a compensation mechanism to reduce the error caused by discretisation. Experimental results demonstrate that, compared with the state-of-the-art SNN approaches, the proposed Spiking ResNet achieves the best performance on CIFAR-10, CIFAR-100, and ImageNet 2012. Our work is the first time to build a SNN deeper than 40, with comparable performance to ANNs on a large-scale dataset.", "published": "2018-04-28T06:44:13Z", "version": 2}, {"aid": "1804.11191", "authors": ["Zhuwei Qin", "Fuxun Yu", "Chenchen Liu", "Xiang Chen"], "title": "How convolutional neural network see the world - A survey of convolutional neural network visualization methods", "url": "http://arxiv.org/pdf/1804.11191v2", "summary": "Nowadays, the Convolutional Neural Networks (CNNs) have achieved impressive performance on many computer vision related tasks, such as object detection, image recognition, image retrieval, etc. These achievements benefit from the CNNs outstanding capability to learn the input features with deep layers of neuron structures and iterative training process. However, these learned features are hard to identify and interpret from a human vision perspective, causing a lack of understanding of the CNNs internal working mechanism. To improve the CNN interpretability, the CNN visualization is well utilized as a qualitative analysis method, which translates the internal features into visually perceptible patterns. And many CNN visualization works have been proposed in the literature to interpret the CNN in perspectives of network structure, operation, and semantic concept. In this paper, we expect to provide a comprehensive survey of several representative CNN visualization methods, including Activation Maximization, Network Inversion, Deconvolutional Neural Networks (DeconvNet), and Network Dissection based visualization. These methods are presented in terms of motivations, algorithms, and experiment results. Based on these visualization methods, we also discuss their practical applications to demonstrate the significance of the CNN interpretability in areas of network design, optimization, security enhancement, etc.", "published": "2018-04-30T13:47:11Z", "version": 2}, {"aid": "1805.00907", "authors": ["Nadav Rotem", "Jordan Fix", "Saleem Abdulrasool", "Garret Catron", "Summer Deng", "Roman Dzhabarov", "Nick Gibson", "James Hegeman", "Meghan Lele", "Roman Levenstein", "Jack Montgomery", "Bert Maher", "Satish Nadathur", "Jakob Olesen", "Jongsoo Park", "Artem Rakhov", "Misha Smelyanskiy", "Man Wang"], "title": "Glow: Graph Lowering Compiler Techniques for Neural Networks", "url": "http://arxiv.org/pdf/1805.00907v3", "summary": "This paper presents the design of Glow, a machine learning compiler for heterogeneous hardware. It is a pragmatic approach to compilation that enables the generation of highly optimized code for multiple targets. Glow lowers the traditional neural network dataflow graph into a two-phase strongly-typed intermediate representation. The high-level intermediate representation allows the optimizer to perform domain-specific optimizations. The lower-level instruction-based address-only intermediate representation allows the compiler to perform memory-related optimizations, such as instruction scheduling, static memory allocation and copy elimination. At the lowest level, the optimizer performs machine-specific code generation to take advantage of specialized hardware features. Glow features a lowering phase which enables the compiler to support a high number of input operators as well as a large number of hardware targets by eliminating the need to implement all operators on all targets. The lowering phase is designed to reduce the input space and allow new hardware backends to focus on a small number of linear algebra primitives.", "published": "2018-05-02T17:04:53Z", "version": 3}, {"aid": "1805.01385", "authors": ["Yang Liu"], "title": "Research on the Brain-inspired Cross-modal Neural Cognitive Computing Framework", "url": "http://arxiv.org/pdf/1805.01385v2", "summary": "To address modeling problems of brain-inspired intelligence, this thesis is focused on researching in the semantic-oriented framework design for multimedia and multimodal information. The Multimedia Neural Cognitive Computing (MNCC) model was designed based on the nervous mechanism and cognitive architecture. Furthermore, the semantic-oriented hierarchical Cross-modal Neural Cognitive Computing (CNCC) framework was proposed based on MNCC model, and formal description and analysis for CNCC framework was given. It would effectively improve the performance of semantic processing for multimedia and cross-modal information, and has far-reaching significance for exploration and realization brain-inspired computing.", "published": "2018-05-03T15:51:51Z", "version": 2}, {"aid": "1805.01452", "authors": ["Dimitrios Kollias", "Stefanos Zafeiriou"], "title": "A Multi-component CNN-RNN Approach for Dimensional Emotion Recognition in-the-wild", "url": "http://arxiv.org/pdf/1805.01452v5", "summary": "This paper presents our approach to the One-Minute Gradual-Emotion Recognition (OMG-Emotion) Challenge, focusing on dimensional emotion recognition through visual analysis of the provided emotion videos. The approach is based on a Convolutional and Recurrent (CNN-RNN) deep neural architecture we have developed for the relevant large AffWild Emotion Database. We extended and adapted this architecture, by letting a combination of multiple features generated in the CNN component be explored by RNN subnets. Our target has been to obtain best performance on the OMG-Emotion visual validation data set, while learning the respective visual training data set. Extended experimentation has led to best architectures for the estimation of the values of the valence and arousal emotion dimensions over these data sets.", "published": "2018-05-03T17:54:44Z", "version": 5}, {"aid": "1805.01890", "authors": ["Kamran Kowsari", "Mojtaba Heidarysafa", "Donald E. Brown", "Kiana Jafari Meimandi", "Laura E. Barnes"], "title": "RMDL: Random Multimodel Deep Learning for Classification", "url": "http://arxiv.org/pdf/1805.01890v2", "summary": "The continually increasing number of complex datasets each year necessitates ever improving machine learning methods for robust and accurate categorization of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. RDML can accept as input a variety data to include text, video, images, and symbolic. This paper describes RMDL and shows test results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB, and 20newsgroup. These test results show that RDML produces consistently better performance than standard methods over a broad range of data types and classification problems.", "published": "2018-05-03T19:36:43Z", "version": 2}, {"aid": "1805.01978", "authors": ["Zhirong Wu", "Yuanjun Xiong", "Stella Yu", "Dahua Lin"], "title": "Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination", "url": "http://arxiv.org/pdf/1805.01978v1", "summary": "Neural net classifiers trained on data with annotated class labels can also capture apparent visual similarity among categories without being directed to do so. We study whether this observation can be extended beyond the conventional domain of supervised learning: Can we learn a good feature representation that captures apparent similarity among instances, instead of classes, by merely asking the feature to be discriminative of individual instances? We formulate this intuition as a non-parametric classification problem at the instance-level, and use noise-contrastive estimation to tackle the computational challenges imposed by the large number of instance classes. Our experimental results demonstrate that, under unsupervised learning settings, our method surpasses the state-of-the-art on ImageNet classification by a large margin. Our method is also remarkable for consistently improving test performance with more training data and better network architectures. By fine-tuning the learned feature, we further obtain competitive results for semi-supervised learning and object detection tasks. Our non-parametric model is highly compact: With 128 features per image, our method requires only 600MB storage for a million images, enabling fast nearest neighbour retrieval at the run time.", "published": "2018-05-05T00:47:01Z", "version": 1}, {"aid": "1805.03225", "authors": ["Siddharth Mahendran", "Haider Ali", "Rene Vidal"], "title": "A Mixed Classification-Regression Framework for 3D Pose Estimation from 2D Images", "url": "http://arxiv.org/pdf/1805.03225v1", "summary": "3D pose estimation from a single 2D image is an important and challenging task in computer vision with applications in autonomous driving, robot manipulation and augmented reality. Since 3D pose is a continuous quantity, a natural formulation for this task is to solve a pose regression problem. However, since pose regression methods return a single estimate of the pose, they have difficulties handling multimodal pose distributions (e.g. in the case of symmetric objects). An alternative formulation, which can capture multimodal pose distributions, is to discretize the pose space into bins and solve a pose classification problem. However, pose classification methods can give large pose estimation errors depending on the coarseness of the discretization. In this paper, we propose a mixed classification-regression framework that uses a classification network to produce a discrete multimodal pose estimate and a regression network to produce a continuous refinement of the discrete estimate. The proposed framework can accommodate different architectures and loss functions, leading to multiple classification-regression models, some of which achieve state-of-the-art performance on the challenging Pascal3D+ dataset.", "published": "2018-05-08T18:32:04Z", "version": 1}, {"aid": "1805.03300", "authors": ["Joseph Y. Cheng", "Feiyu Chen", "Marcus T. Alley", "John M. Pauly", "Shreyas S. Vasanawala"], "title": "Highly Scalable Image Reconstruction using Deep Neural Networks with Bandpass Filtering", "url": "http://arxiv.org/pdf/1805.03300v2", "summary": "To increase the flexibility and scalability of deep neural networks for image reconstruction, a framework is proposed based on bandpass filtering. For many applications, sensing measurements are performed indirectly. For example, in magnetic resonance imaging, data are sampled in the frequency domain. The introduction of bandpass filtering enables leveraging known imaging physics while ensuring that the final reconstruction is consistent with actual measurements to maintain reconstruction accuracy. We demonstrate this flexible architecture for reconstructing subsampled datasets of MRI scans. The resulting high subsampling rates increase the speed of MRI acquisitions and enable the visualization rapid hemodynamics.", "published": "2018-05-08T21:42:53Z", "version": 2}, {"aid": "1806.01775", "authors": ["F. Liu", "C. Liu", "F. Bi"], "title": "A Memristor based Unsupervised Neuromorphic System Towards Fast and Energy-Efficient GAN", "url": "http://arxiv.org/pdf/1806.01775v4", "summary": "Deep Learning has gained immense success in pushing today's artificial intelligence forward. To solve the challenge of limited labeled data in the supervised learning world, unsupervised learning has been proposed years ago while low accuracy hinters its realistic applications. Generative adversarial network (GAN) emerges as an unsupervised learning approach with promising accuracy and are under extensively study. However, the execution of GAN is extremely memory and computation intensive and results in ultra-low speed and high-power consumption. In this work, we proposed a holistic solution for fast and energy-efficient GAN computation through a memristor-based neuromorphic system. First, we exploited a hardware and software co-design approach to map the computation blocks in GAN efficiently. We also proposed an efficient data flow for optimal parallelism training and testing, depending on the computation correlations between different computing blocks. To compute the unique and complex loss of GAN, we developed a diff-block with optimized accuracy and performance. The experiment results on big data show that our design achieves 2.8x speedup and 6.1x energy-saving compared with the traditional GPU accelerator, as well as 5.5x speedup and 1.4x energy-saving compared with the previous FPGA-based accelerator.", "published": "2018-05-09T02:45:38Z", "version": 4}, {"aid": "1805.03714", "authors": ["Vitaly Kuznetsov", "Zelda Mariet"], "title": "Foundations of Sequence-to-Sequence Modeling for Time Series", "url": "http://arxiv.org/pdf/1805.03714v2", "summary": "The availability of large amounts of time series data, paired with the performance of deep-learning algorithms on a broad class of problems, has recently led to significant interest in the use of sequence-to-sequence models for time series forecasting. We provide the first theoretical analysis of this time series forecasting framework. We include a comparison of sequence-to-sequence modeling to classical time series models, and as such our theory can serve as a quantitative guide for practitioners choosing between different modeling methodologies.", "published": "2018-05-09T20:03:37Z", "version": 2}, {"aid": "1805.04514", "authors": ["Kenny Young", "Baoxiang Wang", "Matthew E. Taylor"], "title": "Metatrace Actor-Critic: Online Step-size Tuning by Meta-gradient Descent for Reinforcement Learning Control", "url": "http://arxiv.org/pdf/1805.04514v2", "summary": "Reinforcement learning (RL) has had many successes in both \"deep\" and \"shallow\" settings. In both cases, significant hyperparameter tuning is often required to achieve good performance. Furthermore, when nonlinear function approximation is used, non-stationarity in the state representation can lead to learning instability. A variety of techniques exist to combat this --- most notably large experience replay buffers or the use of multiple parallel actors. These techniques come at the cost of moving away from the online RL problem as it is traditionally formulated (i.e., a single agent learning online without maintaining a large database of training examples). Meta-learning can potentially help with both these issues by tuning hyperparameters online and allowing the algorithm to more robustly adjust to non-stationarity in a problem. This paper applies meta-gradient descent to derive a set of step-size tuning algorithms specifically for online RL control with eligibility traces. Our novel technique, Metatrace, makes use of an eligibility trace analogous to methods like $TD(\\lambda)$. We explore tuning both a single scalar step-size and a separate step-size for each learned parameter. We evaluate Metatrace first for control with linear function approximation in the classic mountain car problem and then in a noisy, non-stationary version. Finally, we apply Metatrace for control with nonlinear function approximation in 5 games in the Arcade Learning Environment where we explore how it impacts learning speed and robustness to initial step-size choice. Results show that the meta-step-size parameter of Metatrace is easy to set, Metatrace can speed learning, and Metatrace can allow an RL algorithm to deal with non-stationarity in the learning task.", "published": "2018-05-10T20:00:50Z", "version": 2}, {"aid": "1805.04419", "authors": ["Le Pham Tuyen", "Ngo Anh Vien", "Abu Layek", "TaeChoong Chung"], "title": "Deep Hierarchical Reinforcement Learning Algorithm in Partially Observable Markov Decision Processes", "url": "http://arxiv.org/pdf/1805.04419v1", "summary": "In recent years, reinforcement learning has achieved many remarkable successes due to the growing adoption of deep learning techniques and the rapid growth in computing power. Nevertheless, it is well-known that flat reinforcement learning algorithms are often not able to learn well and data-efficient in tasks having hierarchical structures, e.g. consisting of multiple subtasks. Hierarchical reinforcement learning is a principled approach that is able to tackle these challenging tasks. On the other hand, many real-world tasks usually have only partial observability in which state measurements are often imperfect and partially observable. The problems of RL in such settings can be formulated as a partially observable Markov decision process (POMDP). In this paper, we study hierarchical RL in POMDP in which the tasks have only partial observability and possess hierarchical properties. We propose a hierarchical deep reinforcement learning approach for learning in hierarchical POMDP. The deep hierarchical RL algorithm is proposed to apply to both MDP and POMDP learning. We evaluate the proposed algorithm on various challenging hierarchical POMDP.", "published": "2018-05-11T14:30:21Z", "version": 1}, {"aid": "1805.04590", "authors": ["Akash Bapat", "Jan-Michael Frahm"], "title": "The Domain Transform Solver", "url": "http://arxiv.org/pdf/1805.04590v1", "summary": "We present a framework for edge-aware optimization that is an order of magnitude faster than the state of the art while having comparable performance. Our key insight is that the optimization can be formulated by leveraging properties of the domain transform, a method for edge-aware filtering that defines a distance-preserving 1D mapping of the input space. This enables our method to improve performance for a variety of problems including stereo, depth super-resolution, and render from defocus, while keeping the computational complexity linear in the number of pixels. Our method is highly parallelizable and adaptable, and it has demonstrable scalability with respect to image resolution.", "published": "2018-05-11T20:57:46Z", "version": 1}, {"aid": "1805.04770", "authors": ["Tommaso Furlanello", "Zachary C. Lipton", "Michael Tschannen", "Laurent Itti", "Anima Anandkumar"], "title": "Born Again Neural Networks", "url": "http://arxiv.org/pdf/1805.04770v2", "summary": "Knowledge Distillation (KD) consists of transferring \u201cknowledge\u201d from one machine learning model (the teacher) to another (the student). Commonly, the teacher is a high-capacity model with formidable performance, while the student is more compact. By transferring knowledge, one hopes to benefit from the student\u2019s compactness, without sacrificing too much performance. We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these Born-Again Networks (BANs), outperform their teachers significantly, both on computer vision and language modeling tasks. Our experiments with BANs based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate the essential components of KD, demonstrating the effect of the teacher outputs on both predicted and non-predicted classes.", "published": "2018-05-12T19:48:50Z", "version": 2}, {"aid": "1805.04955", "authors": ["Thomas Stepleton", "Razvan Pascanu", "Will Dabney", "Siddhant M. Jayakumar", "Hubert Soyer", "Remi Munos"], "title": "Low-pass Recurrent Neural Networks - A memory architecture for longer-term correlation discovery", "url": "http://arxiv.org/pdf/1805.04955v1", "summary": "Reinforcement learning (RL) agents performing complex tasks must be able to remember observations and actions across sizable time intervals. This is especially true during the initial learning stages, when exploratory behaviour can increase the delay between specific actions and their effects. Many new or popular approaches for learning these distant correlations employ backpropagation through time (BPTT), but this technique requires storing observation traces long enough to span the interval between cause and effect. Besides memory demands, learning dynamics like vanishing gradients and slow convergence due to infrequent weight updates can reduce BPTT's practicality; meanwhile, although online recurrent network learning is a developing topic, most approaches are not efficient enough to use as replacements. We propose a simple, effective memory strategy that can extend the window over which BPTT can learn without requiring longer traces. We explore this approach empirically on a few tasks and discuss its implications.", "published": "2018-05-13T21:35:08Z", "version": 1}, {"aid": "1805.06020", "authors": ["Tambet Matiisen", "Aqeel Labash", "Daniel Majoral", "Jaan Aru", "Raul Vicente"], "title": "Do deep reinforcement learning agents model intentions?", "url": "http://arxiv.org/pdf/1805.06020v2", "summary": "Inferring other agents' mental states such as their knowledge, beliefs and intentions is thought to be essential for effective interactions with other agents. Recently, multiagent systems trained via deep reinforcement learning have been shown to succeed in solving different tasks, but it remains unclear how each agent modeled or represented other agents in their environment. In this work we test whether deep reinforcement learning agents explicitly represent other agents' intentions (their specific aims or goals) during a task in which the agents had to coordinate the covering of different spots in a 2D environment. In particular, we tracked over time the performance of a linear decoder trained to predict the final goal of all agents from the hidden state of each agent's neural network controller. We observed that the hidden layers of agents represented explicit information about other agents' goals, i.e. the target landmark they ended up covering. We also performed a series of experiments, in which some agents were replaced by others with fixed goals, to test the level of generalization of the trained agents. We noticed that during the training phase the agents developed a differential preference for each goal, which hindered generalization. To alleviate the above problem, we propose simple changes to the MADDPG training algorithm which leads to better generalization against unseen agents. We believe that training protocols promoting more active intention reading mechanisms, e.g. by preventing simple symmetry-breaking solutions, is a promising direction towards achieving a more robust generalization in different cooperative and competitive tasks.", "published": "2018-05-15T20:15:05Z", "version": 2}, {"aid": "1805.12069", "authors": ["Eray \u00d6zkural"], "title": "Omega: An Architecture for AI Unification", "url": "http://arxiv.org/pdf/1805.12069v1", "summary": "We introduce the open-ended, modular, self-improving Omega AI unification architecture which is a refinement of Solomonoff's Alpha architecture, as considered from first principles. The architecture embodies several crucial principles of general intelligence including diversity of representations, diversity of data types, integrated memory, modularity, and higher-order cognition. We retain the basic design of a fundamental algorithmic substrate called an \"AI kernel\" for problem solving and basic cognitive functions like memory, and a larger, modular architecture that re-uses the kernel in many ways. Omega includes eight representation languages and six classes of neural networks, which are briefly introduced. The architecture is intended to initially address data science automation, hence it includes many problem solving methods for statistical tasks. We review the broad software architecture, higher-order cognition, self-improvement, modular neural architectures, intelligent agents, the process and memory hierarchy, hardware abstraction, peer-to-peer computing, and data abstraction facility.", "published": "2018-05-16T22:08:28Z", "version": 1}, {"aid": "1805.06621", "authors": ["Tom\u00e1s Angles", "St\u00e9phane Mallat"], "title": "Generative networks as inverse problems with Scattering transforms", "url": "http://arxiv.org/pdf/1805.06621v1", "summary": "Generative Adversarial Nets (GANs) and Variational Auto-Encoders (VAEs) provide impressive image generations from Gaussian white noise, but the underlying mathematics are not well understood. We compute deep convolutional network generators by inverting a fixed embedding operator. Therefore, they do not require to be optimized with a discriminator or an encoder. The embedding is Lipschitz continuous to deformations so that generators transform linear interpolations between input white noise vectors into deformations between output images. This embedding is computed with a wavelet Scattering transform. Numerical experiments demonstrate that the resulting Scattering generators have similar properties as GANs or VAEs, without learning a discriminative network or an encoder.", "published": "2018-05-17T07:12:18Z", "version": 1}, {"aid": "1805.06753", "authors": ["Guangzeng Xie", "Yitan Wang", "Shuchang Zhou", "Zhihua Zhang"], "title": "Interpolatron: Interpolation or Extrapolation Schemes to Accelerate Optimization for Deep Neural Networks", "url": "http://arxiv.org/pdf/1805.06753v1", "summary": "In this paper we explore acceleration techniques for large scale nonconvex optimization problems with special focuses on deep neural networks. The extrapolation scheme is a classical approach for accelerating stochastic gradient descent for convex optimization, but it does not work well for nonconvex optimization typically. Alternatively, we propose an interpolation scheme to accelerate nonconvex optimization and call the method Interpolatron. We explain motivation behind Interpolatron and conduct a thorough empirical analysis. Empirical results on DNNs of great depths (e.g., 98-layer ResNet and 200-layer ResNet) on CIFAR-10 and ImageNet show that Interpolatron can converge much faster than the state-of-the-art methods such as the SGD with momentum and Adam. Furthermore, Anderson's acceleration, in which mixing coefficients are computed by least-squares estimation, can also be used to improve the performance. Both Interpolatron and Anderson's acceleration are easy to implement and tune. We also show that Interpolatron has linear convergence rate under certain regularity assumptions.", "published": "2018-05-17T13:29:33Z", "version": 1}, {"aid": "1805.07071", "authors": ["Pengju Liu", "Hongzhi Zhang", "Kai Zhang", "Liang Lin", "Wangmeng Zuo"], "title": "Multi-level Wavelet-CNN for Image Restoration", "url": "http://arxiv.org/pdf/1805.07071v2", "summary": "The tradeoff between receptive field size and efficiency is a crucial issue in low level vision. Plain convolutional networks (CNNs) generally enlarge the receptive field at the expense of computational cost. Recently, dilated filtering has been adopted to address this issue. But it suffers from gridding effect, and the resulting receptive field is only a sparse sampling of input image with checkerboard patterns. In this paper, we present a novel multi-level wavelet CNN (MWCNN) model for better tradeoff between receptive field size and computational efficiency. With the modified U-Net architecture, wavelet transform is introduced to reduce the size of feature maps in the contracting subnetwork. Furthermore, another convolutional layer is further used to decrease the channels of feature maps. In the expanding subnetwork, inverse wavelet transform is then deployed to reconstruct the high resolution feature maps. Our MWCNN can also be explained as the generalization of dilated filtering and subsampling, and can be applied to many image restoration tasks. The experimental results clearly show the effectiveness of MWCNN for image denoising, single image super-resolution, and JPEG image artifacts removal.", "published": "2018-05-18T06:59:00Z", "version": 2}, {"aid": "1805.07249", "authors": ["Shrihari Vasudevan"], "title": "Dynamic learning rate using Mutual Information", "url": "http://arxiv.org/pdf/1805.07249v2", "summary": "This paper demonstrates dynamic hyper-parameter setting, for deep neural network training, using Mutual Information (MI). The specific hyper-parameter studied in this paper is the learning rate. MI between the output layer and true outcomes is used to dynamically set the learning rate of the network through the training cycle; the idea is also extended to layer-wise setting of learning rate. Two approaches are demonstrated - tracking relative change in mutual information and, additionally tracking its value relative to a reference measure. The paper does not attempt to recommend a specific learning rate policy. Experiments demonstrate that mutual information may be effectively used to dynamically set learning rate and achieve competitive to better outcomes in competitive to better time.", "published": "2018-05-18T14:46:20Z", "version": 2}, {"aid": "1805.07281", "authors": ["Rushil Anirudh", "Jayaraman J. Thiagarajan", "Bhavya Kailkhura", "Timo Bremer"], "title": "An Unsupervised Approach to Solving Inverse Problems using Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1805.07281v2", "summary": "Solving inverse problems continues to be a challenge in a wide array of applications ranging from deblurring, image inpainting, source separation etc. Most existing techniques solve such inverse problems by either explicitly or implicitly finding the inverse of the model. The former class of techniques require explicit knowledge of the measurement process which can be unrealistic, and rely on strong analytical regularizers to constrain the solution space, which often do not generalize well. The latter approaches have had remarkable success in part due to deep learning, but require a large collection of source-observation pairs, which can be prohibitively expensive. In this paper, we propose an unsupervised technique to solve inverse problems with generative adversarial networks (GANs). Using a pre-trained GAN in the space of source signals, we show that one can reliably recover solutions to under determined problems in a `blind' fashion, i.e., without knowledge of the measurement process. We solve this by making successive estimates on the model and the solution in an iterative fashion. We show promising results in three challenging applications -- blind source separation, image deblurring, and recovering an image from its edge map, and perform better than several baselines.", "published": "2018-05-18T15:23:01Z", "version": 2}, {"aid": "1805.07477", "authors": ["Alireza Zaeemzadeh", "Nazanin Rahnavard", "Mubarak Shah"], "title": "Norm-Preservation: Why Residual Networks Can Become Extremely Deep?", "url": "http://arxiv.org/pdf/1805.07477v5", "summary": "Augmenting neural networks with skip connections, as introduced in the so-called ResNet architecture, surprised the community by enabling the training of networks of more than 1,000 layers with significant performance gains. This paper deciphers ResNet by analyzing the effect of skip connections, and puts forward new theoretical results on the advantages of identity skip connections in neural networks. We prove that the skip connections in the residual blocks facilitate preserving the norm of the gradient, and lead to stable back-propagation, which is desirable from optimization perspective. We also show that, perhaps surprisingly, as more residual blocks are stacked, the norm-preservation of the network is enhanced. Our theoretical arguments are supported by extensive empirical evidence. Can we push for extra norm-preservation? We answer this question by proposing an efficient method to regularize the singular values of the convolution operator and making the ResNet's transition layers extra norm-preserving. Our numerical investigations demonstrate that the learning dynamics and the classification performance of ResNet can be improved by making it even more norm preserving. Our results and the introduced modification for ResNet, referred to as Procrustes ResNets, can be used as a guide for training deeper networks and can also inspire new deeper architectures.", "published": "2018-05-18T23:37:17Z", "version": 5}, {"aid": "1805.07732", "authors": ["Chao Qu", "Shie Mannor", "Huan Xu"], "title": "Nonlinear Distributional Gradient Temporal-Difference Learning", "url": "http://arxiv.org/pdf/1805.07732v3", "summary": "We devise a distributional variant of gradient temporal-difference (TD) learning. Distributional reinforcement learning has been demonstrated to outperform the regular one in the recent study \\citep{bellemare2017distributional}. In the policy evaluation setting, we design two new algorithms called distributional GTD2 and distributional TDC using the Cram{\\'e}r distance on the distributional version of the Bellman error objective function, which inherits advantages of both the nonlinear gradient TD algorithms and the distributional RL approach. In the control setting, we propose the distributional Greedy-GQ using the similar derivation. We prove the asymptotic almost-sure convergence of distributional GTD2 and TDC to a local optimal solution for general smooth function approximators, which includes neural networks that have been widely used in recent study to solve the real-life RL problems. In each step, the computational complexities of above three algorithms are linear w.r.t.\\ the number of the parameters of the function approximator, thus can be implemented efficiently for neural networks.", "published": "2018-05-20T08:43:05Z", "version": 3}, {"aid": "1805.08239", "authors": ["Joshua I. Glaser", "Ari S. Benjamin", "Roozbeh Farhoodi", "Konrad P. Kording"], "title": "The Roles of Supervised Machine Learning in Systems Neuroscience", "url": "http://arxiv.org/pdf/1805.08239v2", "summary": "Over the last several years, the use of machine learning (ML) in neuroscience has been rapidly increasing. Here, we review ML's contributions, both realized and potential, across several areas of systems neuroscience. We describe four primary roles of ML within neuroscience: 1) creating solutions to engineering problems, 2) identifying predictive variables, 3) setting benchmarks for simple models of the brain, and 4) serving itself as a model for the brain. The breadth and ease of its applicability suggests that machine learning should be in the toolbox of most systems neuroscientists.", "published": "2018-05-21T18:11:26Z", "version": 2}, {"aid": "1805.08522", "authors": ["Guillermo Valle-P\u00e9rez", "Chico Q. Camargo", "Ard A. Louis"], "title": "Deep learning generalizes because the parameter-function map is biased towards simple functions", "url": "http://arxiv.org/pdf/1805.08522v5", "summary": "Deep neural networks (DNNs) generalize remarkably well without explicit regularization even in the strongly over-parametrized regime where classical learning theory would instead predict that they would severely overfit. While many proposals for some kind of implicit regularization have been made to rationalise this success, there is no consensus for the fundamental reason why DNNs do not strongly overfit. In this paper, we provide a new explanation. By applying a very general probability-complexity bound recently derived from algorithmic information theory (AIT), we argue that the parameter-function map of many DNNs should be exponentially biased towards simple functions. We then provide clear evidence for this strong simplicity bias in a model DNN for Boolean functions, as well as in much larger fully connected and convolutional networks applied to CIFAR10 and MNIST. As the target functions in many real problems are expected to be highly structured, this intrinsic simplicity bias helps explain why deep networks generalize well on real world problems. This picture also facilitates a novel PAC-Bayes approach where the prior is taken over the DNN input-output function space, rather than the more conventional prior over parameter space. If we assume that the training algorithm samples parameters close to uniformly within the zero-error region then the PAC-Bayes theorem can be used to guarantee good expected generalization for target functions producing high-likelihood training sets. By exploiting recently discovered connections between DNNs and Gaussian processes to estimate the marginal likelihood, we produce relatively tight generalization PAC-Bayes error bounds which correlate well with the true error on realistic datasets such as MNIST and CIFAR10 and for architectures including convolutional and fully connected networks.", "published": "2018-05-22T11:51:36Z", "version": 5}, {"aid": "1805.08651", "authors": ["Aapo Hyvarinen", "Hiroaki Sasaki", "Richard E. Turner"], "title": "Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning", "url": "http://arxiv.org/pdf/1805.08651v3", "summary": "Nonlinear ICA is a fundamental problem for unsupervised representation learning, emphasizing the capacity to recover the underlying latent variables generating the data (i.e., identifiability). Recently, the very first identifiability proofs for nonlinear ICA have been proposed, leveraging the temporal structure of the independent components. Here, we propose a general framework for nonlinear ICA, which, as a special case, can make use of temporal structure. It is based on augmenting the data by an auxiliary variable, such as the time index, the history of the time series, or any other available information. We propose to learn nonlinear ICA by discriminating between true augmented data, or data in which the auxiliary variable has been randomized. This enables the framework to be implemented algorithmically through logistic regression, possibly in a neural network. We provide a comprehensive proof of the identifiability of the model as well as the consistency of our estimation method. The approach not only provides a general theoretical framework combining and generalizing previously proposed nonlinear ICA models and algorithms, but also brings practical advantages.", "published": "2018-05-22T15:01:22Z", "version": 3}, {"aid": "1805.08819", "authors": ["Drew Linsley", "Dan Shiebler", "Sven Eberhardt", "Thomas Serre"], "title": "Learning what and where to attend", "url": "http://arxiv.org/pdf/1805.08819v4", "summary": "Most recent gains in visual recognition have originated from the inclusion of attention mechanisms in deep convolutional networks (DCNs). Because these networks are optimized for object recognition, they learn where to attend using only a weak form of supervision derived from image class labels. Here, we demonstrate the benefit of using stronger supervisory signals by teaching DCNs to attend to image regions that humans deem important for object recognition. We first describe a large-scale online experiment (ClickMe) used to supplement ImageNet with nearly half a million human-derived \"top-down\" attention maps. Using human psychophysics, we confirm that the identified top-down features from ClickMe are more diagnostic than \"bottom-up\" saliency features for rapid image categorization. As a proof of concept, we extend a state-of-the-art attention network and demonstrate that adding ClickMe supervision significantly improves its accuracy and yields visual features that are more interpretable and more similar to those used by human observers.", "published": "2018-05-22T19:12:47Z", "version": 4}, {"aid": "1805.08899", "authors": ["Bojian Zheng", "Abhishek Tiwari", "Nandita Vijaykumar", "Gennady Pekhimenko"], "title": "Echo: Compiler-based GPU Memory Footprint Reduction for LSTM RNN Training", "url": "http://arxiv.org/pdf/1805.08899v5", "summary": "The Long-Short-Term-Memory Recurrent Neural Networks (LSTM RNNs) are a popular class of machine learning models for analyzing sequential data. Their training on modern GPUs, however, is limited by the GPU memory capacity. Our profiling results of the LSTM RNN-based Neural Machine Translation (NMT) model reveal that feature maps of the attention and RNN layers form the memory bottleneck and runtime is unevenly distributed across different layers when training on GPUs. Based on these two observations, we propose to recompute the feature maps rather than stashing them persistently in the GPU memory.   While the idea of feature map recomputation has been considered before, existing solutions fail to deliver satisfactory footprint reduction, as they do not address two key challenges. For each feature map recomputation to be effective and efficient, its effect on (1) the total memory footprint, and (2) the total execution time has to be carefully estimated. To this end, we propose *Echo*, a new compiler-based optimization scheme that addresses the first challenge with a practical mechanism that estimates the memory benefits of recomputation over the entire computation graph, and the second challenge by non-conservatively estimating the recomputation overhead leveraging layer specifics. *Echo* reduces the GPU memory footprint automatically and transparently without any changes required to the training source code, and is effective for models beyond LSTM RNNs.   We evaluate *Echo* on numerous state-of-the-art machine learning workloads on real systems with modern GPUs and observe footprint reduction ratios of 1.89X on average and 3.13X maximum. Such reduction can be converted into faster training with a larger batch size, savings in GPU energy consumption (e.g., training with one GPU as fast as with four), and/or an increase in the maximum number of layers under the same GPU memory budget.", "published": "2018-05-22T23:01:25Z", "version": 5}, {"aid": "1805.09975", "authors": ["Daniel McDuff", "Ashish Kapoor"], "title": "Visceral Machines: Risk-Aversion in Reinforcement Learning with Intrinsic Physiological Rewards", "url": "http://arxiv.org/pdf/1805.09975v2", "summary": "As people learn to navigate the world, autonomic nervous system (e.g., \"fight or flight\") responses provide intrinsic feedback about the potential consequence of action choices (e.g., becoming nervous when close to a cliff edge or driving fast around a bend.) Physiological changes are correlated with these biological preparations to protect one-self from danger. We present a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. Our hypothesis is that such reward functions can circumvent the challenges associated with sparse and skewed rewards in reinforcement learning settings and can help improve sample efficiency. We test this in a simulated driving environment and show that it can increase the speed of learning and reduce the number of collisions during the learning stage.", "published": "2018-05-25T04:22:31Z", "version": 2}, {"aid": "1805.10863", "authors": ["Patrick McClure", "Charles Y. Zheng", "Jakub R. Kaczmarzyk", "John A. Lee", "Satrajit S. Ghosh", "Dylan Nielson", "Peter Bandettini", "Francisco Pereira"], "title": "Distributed Weight Consolidation: A Brain Segmentation Case Study", "url": "http://arxiv.org/pdf/1805.10863v9", "summary": "Collecting the large datasets needed to train deep neural networks can be very difficult, particularly for the many applications for which sharing and pooling data is complicated by practical, ethical, or legal concerns. However, it may be the case that derivative datasets or predictive models developed within individual sites can be shared and combined with fewer restrictions. Training on distributed data and combining the resulting networks is often viewed as continual learning, but these methods require networks to be trained sequentially. In this paper, we introduce distributed weight consolidation (DWC), a continual learning method to consolidate the weights of separate neural networks, each trained on an independent dataset. We evaluated DWC with a brain segmentation case study, where we consolidated dilated convolutional neural networks trained on independent structural magnetic resonance imaging (sMRI) datasets from different sites. We found that DWC led to increased performance on test sets from the different sites, while maintaining generalization performance for a very large and completely independent multi-site dataset, compared to an ensemble baseline.", "published": "2018-05-28T10:50:11Z", "version": 9}, {"aid": "1806.07370", "authors": ["Yunho Jeon", "Junmo Kim"], "title": "Constructing Fast Network through Deconstruction of Convolution", "url": "http://arxiv.org/pdf/1806.07370v5", "summary": "Convolutional neural networks have achieved great success in various vision tasks; however, they incur heavy resource costs. By using deeper and wider networks, network accuracy can be improved rapidly. However, in an environment with limited resources (e.g., mobile applications), heavy networks may not be usable. This study shows that naive convolution can be deconstructed into a shift operation and pointwise convolution. To cope with various convolutions, we propose a new shift operation called active shift layer (ASL) that formulates the amount of shift as a learnable function with shift parameters. This new layer can be optimized end-to-end through backpropagation and it can provide optimal shift values. Finally, we apply this layer to a light and fast network that surpasses existing state-of-the-art networks.", "published": "2018-05-28T10:54:27Z", "version": 5}, {"aid": "1805.11144", "authors": ["Daniel Rasmussen"], "title": "NengoDL: Combining deep learning and neuromorphic modelling methods", "url": "http://arxiv.org/pdf/1805.11144v3", "summary": "NengoDL is a software framework designed to combine the strengths of neuromorphic modelling and deep learning. NengoDL allows users to construct biologically detailed neural models, intermix those models with deep learning elements (such as convolutional networks), and then efficiently simulate those models in an easy-to-use, unified framework. In addition, NengoDL allows users to apply deep learning training methods to optimize the parameters of biological neural models. In this paper we present basic usage examples, benchmarking, and details on the key implementation elements of NengoDL. More details can be found at https://www.nengo.ai/nengo-dl .", "published": "2018-05-28T19:36:45Z", "version": 3}, {"aid": "1805.11704", "authors": ["Arna Ghosh", "Fabien dal Maso", "Marc Roig", "Georgios D Mitsis", "Marie-H\u00e9l\u00e8ne Boudrias"], "title": "Deep Semantic Architecture with discriminative feature visualization for neuroimage analysis", "url": "http://arxiv.org/pdf/1805.11704v2", "summary": "Neuroimaging data analysis often involves \\emph{a-priori} selection of data features to study the underlying neural activity. Since this could lead to sub-optimal feature selection and thereby prevent the detection of subtle patterns in neural activity, data-driven methods have recently gained popularity for optimizing neuroimaging data analysis pipelines and thereby, improving our understanding of neural mechanisms. In this context, we developed a deep convolutional architecture that can identify discriminating patterns in neuroimaging data and applied it to electroencephalography (EEG) recordings collected from 25 subjects performing a hand motor task before and after a rest period or a bout of exercise. The deep network was trained to classify subjects into exercise and control groups based on differences in their EEG signals. Subsequently, we developed a novel method termed the cue-combination for Class Activation Map (ccCAM), which enabled us to identify discriminating spatio-temporal features within definite frequency bands (23--33 Hz) and assess the effects of exercise on the brain. Additionally, the proposed architecture allowed the visualization of the differences in the propagation of underlying neural activity across the cortex between the two groups, for the first time in our knowledge. Our results demonstrate the feasibility of using deep network architectures for neuroimaging analysis in different contexts such as, for the identification of robust brain biomarkers to better characterize and potentially treat neurological disorders.", "published": "2018-05-29T20:55:09Z", "version": 2}, {"aid": "1805.11706", "authors": ["Quan Vuong", "Yiming Zhang", "Keith W. Ross"], "title": "Supervised Policy Update for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1805.11706v4", "summary": "We propose a new sample-efficient methodology, called Supervised Policy Update (SPU), for deep reinforcement learning. Starting with data generated by the current policy, SPU formulates and solves a constrained optimization problem in the non-parameterized proximal policy space. Using supervised regression, it then converts the optimal non-parameterized policy to a parameterized policy, from which it draws new samples. The methodology is general in that it applies to both discrete and continuous action spaces, and can handle a wide variety of proximity constraints for the non-parameterized optimization problem. We show how the Natural Policy Gradient and Trust Region Policy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization (PPO) problem can be addressed by this methodology. The SPU implementation is much simpler than TRPO. In terms of sample efficiency, our extensive experiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and outperforms PPO in Atari video game tasks.", "published": "2018-05-29T20:57:19Z", "version": 4}, {"aid": "1805.11718", "authors": ["Sidharth Gupta", "Konik Kothari", "Maarten V. de Hoop", "Ivan Dokmani\u0107"], "title": "Random mesh projectors for inverse problems", "url": "http://arxiv.org/pdf/1805.11718v3", "summary": "We propose a new learning-based approach to solve ill-posed inverse problems in imaging. We address the case where ground truth training samples are rare and the problem is severely ill-posed - both because of the underlying physics and because we can only get few measurements. This setting is common in geophysical imaging and remote sensing. We show that in this case the common approach to directly learn the mapping from the measured data to the reconstruction becomes unstable. Instead, we propose to first learn an ensemble of simpler mappings from the data to projections of the unknown image into random piecewise-constant subspaces. We then combine the projections to form a final reconstruction by solving a deconvolution-like problem. We show experimentally that the proposed method is more robust to measurement noise and corruptions not seen during training than a directly learned inverse.", "published": "2018-05-29T21:36:05Z", "version": 3}, {"aid": "1805.12177", "authors": ["Aharon Azulay", "Yair Weiss"], "title": "Why do deep convolutional networks generalize so poorly to small image transformations?", "url": "http://arxiv.org/pdf/1805.12177v4", "summary": "Convolutional Neural Networks (CNNs) are commonly assumed to be invariant to small image transformations: either because of the convolutional architecture or because they were trained using data augmentation. Recently, several authors have shown that this is not the case: small translations or rescalings of the input image can drastically change the network's prediction. In this paper, we quantify this phenomena and ask why neither the convolutional architecture nor data augmentation are sufficient to achieve the desired invariance. Specifically, we show that the convolutional architecture does not give invariance since architectures ignore the classical sampling theorem, and data augmentation does not give invariance because the CNNs learn to be invariant to transformations only for images that are very similar to typical images from the training set. We discuss two possible solutions to this problem: (1) antialiasing the intermediate representations and (2) increasing data augmentation and show that they provide only a partial solution at best. Taken together, our results indicate that the problem of insuring invariance to small image transformations in neural networks while preserving high accuracy remains unsolved.", "published": "2018-05-30T18:56:33Z", "version": 4}, {"aid": "1806.00153", "authors": ["Juyoung Lee", "Yoseob Han", "Jae-Kyun Ryu", "Jang-Yeon Park", "Jong Chul Ye"], "title": "k-Space Deep Learning for Reference-free EPI Ghost Correction", "url": "http://arxiv.org/pdf/1806.00153v3", "summary": "Nyquist ghost artifacts in EPI are originated from phase mismatch between the even and odd echoes. However, conventional correction methods using reference scans often produce erroneous results especially in high-field MRI due to the non-linear and time-varying local magnetic field changes. Recently, it was shown that the problem of ghost correction can be reformulated as k-space interpolation problem that can be solved using structured low-rank Hankel matrix approaches. Another recent work showed that data driven Hankel matrix decomposition can be reformulated to exhibit similar structures as deep convolutional neural network. By synergistically combining these findings, we propose a k-space deep learning approach that immediately corrects the phase mismatch without a reference scan in both accelerated and non-accelerated EPI acquisitions. To take advantage of the even and odd-phase directional redundancy, the k-space data is divided into two channels configured with even and odd phase encodings. The redundancies between coils are also exploited by stacking the multi-coil k-space data into additional input channels. Then, our k-space ghost correction network is trained to learn the interpolation kernel to estimate the missing virtual k-space data. For the accelerated EPI data, the same neural network is trained to directly estimate the interpolation kernels for missing k-space data from both ghost and subsampling. Reconstruction results using 3T and 7T in-vivo data showed that the proposed method outperformed the image quality compared to the existing methods, and the computing time is much faster.The proposed k-space deep learning for EPI ghost correction is highly robust and fast, and can be combined with acceleration, so that it can be used as a promising correction tool for high-field MRI without changing the current acquisition protocol.", "published": "2018-06-01T01:01:27Z", "version": 3}, {"aid": "1806.02375", "authors": ["Johan Bjorck", "Carla Gomes", "Bart Selman", "Kilian Q. Weinberger"], "title": "Understanding Batch Normalization", "url": "http://arxiv.org/pdf/1806.02375v4", "summary": "Batch normalization (BN) is a technique to normalize activations in intermediate layers of deep neural networks. Its tendency to improve accuracy and speed up training have established BN as a favorite technique in deep learning. Yet, despite its enormous success, there remains little consensus on the exact reason and mechanism behind these improvements. In this paper we take a step towards a better understanding of BN, following an empirical approach. We conduct several experiments, and show that BN primarily enables training with larger learning rates, which is the cause for faster convergence and better generalization. For networks without BN we demonstrate how large gradient updates can result in diverging loss and activations growing uncontrollably with network depth, which limits possible learning rates. BN avoids this problem by constantly correcting activations to be zero-mean and of unit standard deviation, which enables larger gradient steps, yields faster convergence and may help bypass sharp local minima. We further show various ways in which gradients and activations of deep unnormalized networks are ill-behaved. We contrast our results against recent findings in random matrix theory, shedding new light on classical initialization schemes and their consequences.", "published": "2018-06-01T03:57:56Z", "version": 4}, {"aid": "1806.00523", "authors": ["Kashyap Chitta"], "title": "Targeted Kernel Networks: Faster Convolutions with Attentive Regularization", "url": "http://arxiv.org/pdf/1806.00523v2", "summary": "We propose Attentive Regularization (AR), a method to constrain the activation maps of kernels in Convolutional Neural Networks (CNNs) to specific regions of interest (ROIs). Each kernel learns a location of specialization along with its weights through standard backpropagation. A differentiable attention mechanism requiring no additional supervision is used to optimize the ROIs. Traditional CNNs of different types and structures can be modified with this idea into equivalent Targeted Kernel Networks (TKNs), while keeping the network size nearly identical. By restricting kernel ROIs, we reduce the number of sliding convolutional operations performed throughout the network in its forward pass, speeding up both training and inference. We evaluate our proposed architecture on both synthetic and natural tasks across multiple domains. TKNs obtain significant improvements over baselines, requiring less computation (around an order of magnitude) while achieving superior performance.", "published": "2018-06-01T19:46:16Z", "version": 2}, {"aid": "1806.00952", "authors": ["Navid Azizan", "Babak Hassibi"], "title": "Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization", "url": "http://arxiv.org/pdf/1806.00952v4", "summary": "Stochastic descent methods (of the gradient and mirror varieties) have become increasingly popular in optimization. In fact, it is now widely recognized that the success of deep learning is not only due to the special deep architecture of the models, but also due to the behavior of the stochastic descent methods used, which play a key role in reaching \"good\" solutions that generalize well to unseen data. In an attempt to shed some light on why this is the case, we revisit some minimax properties of stochastic gradient descent (SGD) for the square loss of linear models---originally developed in the 1990's---and extend them to general stochastic mirror descent (SMD) algorithms for general loss functions and nonlinear models. In particular, we show that there is a fundamental identity which holds for SMD (and SGD) under very general conditions, and which implies the minimax optimality of SMD (and SGD) for sufficiently small step size, and for a general class of loss functions and general nonlinear models. We further show that this identity can be used to naturally establish other properties of SMD (and SGD), namely convergence and implicit regularization for over-parameterized linear models (in what is now being called the \"interpolating regime\"), some of which have been shown in certain cases in prior literature. We also argue how this identity can be used in the so-called \"highly over-parameterized\" nonlinear setting (where the number of parameters far exceeds the number of data points) to provide insights into why SMD (and SGD) may have similar convergence and implicit regularization properties for deep learning.", "published": "2018-06-04T04:53:00Z", "version": 4}, {"aid": "1806.01363", "authors": ["Giuseppe Cuccu", "Julian Togelius", "Philippe Cudre-Mauroux"], "title": "Playing Atari with Six Neurons", "url": "http://arxiv.org/pdf/1806.01363v2", "summary": "Deep reinforcement learning, applied to vision-based problems like Atari games, maps pixels directly to actions; internally, the deep neural network bears the responsibility of both extracting useful information and making decisions based on it. By separating the image processing from decision-making, one could better understand the complexity of each task, as well as potentially find smaller policy representations that are easier for humans to understand and may generalize better. To this end, we propose a new method for learning policies and compact state representations separately but simultaneously for policy approximation in reinforcement learning. State representations are generated by an encoder based on two novel algorithms: Increasing Dictionary Vector Quantization makes the encoder capable of growing its dictionary size over time, to address new observations as they appear in an open-ended online-learning context; Direct Residuals Sparse Coding encodes observations by disregarding reconstruction error minimization, and aiming instead for highest information inclusion. The encoder autonomously selects observations online to train on, in order to maximize code sparsity. As the dictionary size increases, the encoder produces increasingly larger inputs for the neural network: this is addressed by a variation of the Exponential Natural Evolution Strategies algorithm which adapts its probability distribution dimensionality along the run. We test our system on a selection of Atari games using tiny neural networks of only 6 to 18 neurons (depending on the game's controls). These are still capable of achieving results comparable---and occasionally superior---to state-of-the-art techniques which use two orders of magnitude more neurons.", "published": "2018-06-04T20:09:43Z", "version": 2}, {"aid": "1806.01376", "authors": ["Jian Ren", "Jianchao Yang", "Ning Xu", "David J. Foran"], "title": "Factorized Adversarial Networks for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/1806.01376v1", "summary": "In this paper, we propose Factorized Adversarial Networks (FAN) to solve unsupervised domain adaptation problems for image classification tasks. Our networks map the data distribution into a latent feature space, which is factorized into a domain-specific subspace that contains domain-specific characteristics and a task-specific subspace that retains category information, for both source and target domains, respectively. Unsupervised domain adaptation is achieved by adversarial training to minimize the discrepancy between the distributions of two task-specific subspaces from source and target domains. We demonstrate that the proposed approach outperforms state-of-the-art methods on multiple benchmark datasets used in the literature for unsupervised domain adaptation. Furthermore, we collect two real-world tagging datasets that are much larger than existing benchmark datasets, and get significant improvement upon baselines, proving the practical value of our approach.", "published": "2018-06-04T20:39:13Z", "version": 1}, {"aid": "1806.01387", "authors": ["Christian Guckelsberger", "Christoph Salge", "Julian Togelius"], "title": "New And Surprising Ways to Be Mean. Adversarial NPCs with Coupled Empowerment Minimisation", "url": "http://arxiv.org/pdf/1806.01387v1", "summary": "Creating Non-Player Characters (NPCs) that can react robustly to unforeseen player behaviour or novel game content is difficult and time-consuming. This hinders the design of believable characters, and the inclusion of NPCs in games that rely heavily on procedural content generation. We have previously addressed this challenge by means of empowerment, a model of intrinsic motivation, and demonstrated how a coupled empowerment maximisation (CEM) policy can yield generic, companion-like behaviour. In this paper, we extend the CEM framework with a minimisation policy to give rise to adversarial behaviour. We conduct a qualitative, exploratory study in a dungeon-crawler game, demonstrating that CEM can exploit the affordances of different content facets in adaptive adversarial behaviour without modifications to the policy. Changes to the level design, underlying mechanics and our character's actions do not threaten our NPC's robustness, but yield new and surprising ways to be mean.", "published": "2018-06-04T21:02:49Z", "version": 1}, {"aid": "1806.01423", "authors": ["Hananel Hazan", "Daniel J. Saunders", "Hassaan Khan", "Darpan T. Sanghavi", "Hava T. Siegelmann", "Robert Kozma"], "title": "BindsNET: A machine learning-oriented spiking neural networks library in Python", "url": "http://arxiv.org/pdf/1806.01423v2", "summary": "The development of spiking neural network simulation software is a critical component enabling the modeling of neural systems and the development of biologically inspired algorithms. Existing software frameworks support a wide range of neural functionality, software abstraction levels, and hardware devices, yet are typically not suitable for rapid prototyping or application to problems in the domain of machine learning. In this paper, we describe a new Python package for the simulation of spiking neural networks, specifically geared towards machine learning and reinforcement learning. Our software, called BindsNET, enables rapid building and simulation of spiking networks and features user-friendly, concise syntax. BindsNET is built on top of the PyTorch deep neural networks library, enabling fast CPU and GPU computation for large spiking networks. The BindsNET framework can be adjusted to meet the needs of other existing computing and hardware environments, e.g., TensorFlow. We also provide an interface into the OpenAI gym library, allowing for training and evaluation of spiking networks on reinforcement learning problems. We argue that this package facilitates the use of spiking networks for large-scale machine learning experimentation, and show some simple examples of how we envision BindsNET can be used in practice. BindsNET code is available at https://github.com/Hananel-Hazan/bindsnet", "published": "2018-06-04T23:09:52Z", "version": 2}, {"aid": "1806.01502", "authors": ["Yen Yu", "Acer Y. C. Chang", "Ryota Kanai"], "title": "Boredom-driven curious learning by Homeo-Heterostatic Value Gradients", "url": "http://arxiv.org/pdf/1806.01502v1", "summary": "This paper presents the Homeo-Heterostatic Value Gradients (HHVG) algorithm as a formal account on the constructive interplay between boredom and curiosity which gives rise to effective exploration and superior forward model learning. We envisaged actions as instrumental in agent's own epistemic disclosure. This motivated two central algorithmic ingredients: devaluation and devaluation progress, both underpin agent's cognition concerning intrinsically generated rewards. The two serve as an instantiation of homeostatic and heterostatic intrinsic motivation. A key insight from our algorithm is that the two seemingly opposite motivations can be reconciled---without which exploration and information-gathering cannot be effectively carried out. We supported this claim with empirical evidence, showing that boredom-enabled agents consistently outperformed other curious or explorative agent variants in model building benchmarks based on self-assisted experience accumulation.", "published": "2018-06-05T05:34:46Z", "version": 1}, {"aid": "1806.01547", "authors": ["Ankita Shukla", "Gullal Singh Cheema", "Saket Anand"], "title": "Semi-Supervised Clustering with Neural Networks", "url": "http://arxiv.org/pdf/1806.01547v2", "summary": "Clustering using neural networks has recently demonstrated promising performance in machine learning and computer vision applications. However, the performance of current approaches is limited either by unsupervised learning or their dependence on large set of labeled data samples. In this paper, we propose ClusterNet that uses pairwise semantic constraints from very few labeled data samples (<5% of total data) and exploits the abundant unlabeled data to drive the clustering approach. We define a new loss function that uses pairwise semantic similarity between objects combined with constrained k-means clustering to efficiently utilize both labeled and unlabeled data in the same framework. The proposed network uses convolution autoencoder to learn a latent representation that groups data into k specified clusters, while also learning the cluster centers simultaneously. We evaluate and compare the performance of ClusterNet on several datasets and state of the art deep clustering approaches.", "published": "2018-06-05T08:23:42Z", "version": 2}, {"aid": "1806.01655", "authors": ["Vinayak Kumar", "Vaibhav Singh", "P. K. Srijith", "Andreas Damianou"], "title": "Deep Gaussian Processes with Convolutional Kernels", "url": "http://arxiv.org/pdf/1806.01655v1", "summary": "Deep Gaussian processes (DGPs) provide a Bayesian non-parametric alternative to standard parametric deep learning models. A DGP is formed by stacking multiple GPs resulting in a well-regularized composition of functions. The Bayesian framework that equips the model with attractive properties, such as implicit capacity control and predictive uncertainty, makes it at the same time challenging to combine with a convolutional structure. This has hindered the application of DGPs in computer vision tasks, an area where deep parametric models (i.e. CNNs) have made breakthroughs. Standard kernels used in DGPs such as radial basis functions (RBFs) are insufficient for handling pixel variability in raw images. In this paper, we build on the recent convolutional GP to develop Convolutional DGP (CDGP) models which effectively capture image level features through the use of convolution kernels, therefore opening up the way for applying DGPs to computer vision tasks. Our model learns local spatial influence and outperforms strong GP based baselines on multi-class image classification. We also consider various constructions of convolution kernel over the image patches, analyze the computational trade-offs and provide an efficient framework for convolutional DGP models. The experimental results on image data such as MNIST, rectangles-image, CIFAR10 and Caltech101 demonstrate the effectiveness of the proposed approaches.", "published": "2018-06-05T12:41:14Z", "version": 1}, {"aid": "1806.01709", "authors": ["Leonidas A. A. Doumas", "Guillermo Puebla", "Andrea E. Martin"], "title": "Human-like generalization in a machine through predicate learning", "url": "http://arxiv.org/pdf/1806.01709v3", "summary": "Humans readily generalize, applying prior knowledge to novel situations and stimuli. Advances in machine learning and artificial intelligence have begun to approximate and even surpass human performance, but machine systems reliably struggle to generalize information to untrained situations. We describe a neural network model that is trained to play one video game (Breakout) and demonstrates one-shot generalization to a new game (Pong). The model generalizes by learning representations that are functionally and formally symbolic from training data, without feedback, and without requiring that structured representations be specified a priori. The model uses unsupervised comparison to discover which characteristics of the input are invariant, and to learn relational predicates; it then applies these predicates to arguments in a symbolic fashion, using oscillatory regularities in network firing to dynamically bind predicates to arguments. We argue that models of human cognition must account for far-reaching and flexible generalization, and that in order to do so, models must be able to discover symbolic representations from unstructured data, a process we call predicate learning. Only then can models begin to adequately explain where human-like representations come from, why human cognition is the way it is, and why it continues to differ from machine intelligence in crucial ways.", "published": "2018-06-05T14:21:20Z", "version": 3}, {"aid": "1806.01756", "authors": ["Daniel T Chang"], "title": "Concept-Oriented Deep Learning", "url": "http://arxiv.org/pdf/1806.01756v1", "summary": "Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We propose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and conceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of CODL including concept graph, concept representations, concept exemplars, and concept representation learning systems supporting incremental and continual learning.", "published": "2018-06-05T15:50:30Z", "version": 1}, {"aid": "1806.01910", "authors": ["Robert Peharz", "Antonio Vergari", "Karl Stelzner", "Alejandro Molina", "Martin Trapp", "Kristian Kersting", "Zoubin Ghahramani"], "title": "Probabilistic Deep Learning using Random Sum-Product Networks", "url": "http://arxiv.org/pdf/1806.01910v2", "summary": "The need for consistent treatment of uncertainty has recently triggered increased interest in probabilistic deep learning methods. However, most current approaches have severe limitations when it comes to inference, since many of these models do not even permit to evaluate exact data likelihoods. Sum-product networks (SPNs), on the other hand, are an excellent architecture in that regard, as they allow to efficiently evaluate likelihoods, as well as arbitrary marginalization and conditioning tasks. Nevertheless, SPNs have not been fully explored as serious deep learning models, likely due to their special structural requirements, which complicate learning. In this paper, we make a drastic simplification and use random SPN structures which are trained in a \"classical deep learning manner\", i.e. employing automatic differentiation, SGD, and GPU support. The resulting models, called RAT-SPNs, yield prediction results comparable to deep neural networks, while still being interpretable as generative model and maintaining well-calibrated uncertainties. This property makes them highly robust under missing input features and enables them to naturally detect outliers and peculiar samples.", "published": "2018-06-05T19:44:44Z", "version": 2}, {"aid": "1806.02003", "authors": ["Abhejit Rajagopal", "Shivkumar Chandrasekaran", "Hrushikesh N. Mhaskar"], "title": "Deep Algorithms: designs for networks", "url": "http://arxiv.org/pdf/1806.02003v1", "summary": "A new design methodology for neural networks that is guided by traditional algorithm design is presented. To prove our point, we present two heuristics and demonstrate an algorithmic technique for incorporating additional weights in their signal-flow graphs. We show that with training the performance of these networks can not only exceed the performance of the initial network, but can match the performance of more-traditional neural network architectures. A key feature of our approach is that these networks are initialized with parameters that provide a known performance threshold for the architecture on a given task.", "published": "2018-06-06T04:39:37Z", "version": 1}, {"aid": "1806.02336", "authors": ["Naoyuki Ichimura"], "title": "Spatial Frequency Loss for Learning Convolutional Autoencoders", "url": "http://arxiv.org/pdf/1806.02336v1", "summary": "This paper presents a learning method for convolutional autoencoders (CAEs) for extracting features from images. CAEs can be obtained by utilizing convolutional neural networks to learn an approximation to the identity function in an unsupervised manner. The loss function based on the pixel loss (PL) that is the mean squared error between the pixel values of original and reconstructed images is the common choice for learning. However, using the loss function leads to blurred reconstructed images. A method for learning CAEs using a loss function computed from features reflecting spatial frequencies is proposed to mitigate the problem. The blurs in reconstructed images show lack of high spatial frequency components mainly constituting edges and detailed textures that are important features for tasks such as object detection and spatial matching. In order to evaluate the lack of components, a convolutional layer with a Laplacian filter bank as weights is added to CAEs and the mean squared error of features in a subband, called the spatial frequency loss (SFL), is computed from the outputs of each filter. The learning is performed using a loss function based on the SFL. Empirical evaluation demonstrates that using the SFL reduces the blurs in reconstructed images.", "published": "2018-06-06T08:34:12Z", "version": 1}, {"aid": "1806.02091", "authors": ["Andreas Makoto Hein", "H\u00e9l\u00e8ne Condat"], "title": "Can Machines Design? An Artificial General Intelligence Approach", "url": "http://arxiv.org/pdf/1806.02091v4", "summary": "Can machines design? Can they come up with creative solutions to problems and build tools and artifacts across a wide range of domains? Recent advances in the field of computational creativity and formal Artificial General Intelligence (AGI) provide frameworks for machines with the general ability to design. In this paper we propose to integrate a formal computational creativity framework into the G\\\"odel machine framework. We call the resulting framework design G\\\"odel machine. Such a machine could solve a variety of design problems by generating novel concepts. In addition, it could change the way these concepts are generated by modifying itself. The design G\\\"odel machine is able to improve its initial design program, once it has proven that a modification would increase its return on the utility function. Finally, we sketch out a specific version of the design G\\\"odel machine which specifically addresses the design of complex software and hardware systems. Future work aims at the development of a more formal version of the design G\\\"odel machine and a proof of concept implementation.", "published": "2018-06-06T09:41:58Z", "version": 4}, {"aid": "1806.03961", "authors": ["Liangbo He", "Hao Sun"], "title": "Attention Incorporate Network: A network can adapt various data size", "url": "http://arxiv.org/pdf/1806.03961v1", "summary": "In traditional neural networks for image processing, the inputs of the neural networks should be the same size such as 224*224*3. But how can we train the neural net model with different input size? A common way to do is image deformation which accompany a problem of information loss (e.g. image crop or wrap). Sequence model(RNN, LSTM, etc.) can accept different size of input like text and audio. But one disadvantage for sequence model is that the previous information will become more fragmentary during the transfer in time step, it will make the network hard to train especially for long sequential data. In this paper we propose a new network structure called Attention Incorporate Network(AIN). It solve the problem of different size of inputs including: images, text, audio, and extract the key features of the inputs by attention mechanism, pay different attention depends on the importance of the features not rely on the data size. Experimentally, AIN achieve a higher accuracy, better convergence comparing to the same size of other network structure", "published": "2018-06-06T11:09:35Z", "version": 1}, {"aid": "1806.02137", "authors": ["Abel Torres Montoya"], "title": "A New Framework for Machine Intelligence: Concepts and Prototype", "url": "http://arxiv.org/pdf/1806.02137v1", "summary": "Machine learning (ML) and artificial intelligence (AI) have become hot topics in many information processing areas, from chatbots to scientific data analysis. At the same time, there is uncertainty about the possibility of extending predominant ML technologies to become general solutions with continuous learning capabilities. Here, a simple, yet comprehensive, theoretical framework for intelligent systems is presented. A combination of Mirror Compositional Representations (MCR) and a Solution-Critic Loop (SCL) is proposed as a generic approach for different types of problems. A prototype implementation is presented for document comparison using English Wikipedia corpus.", "published": "2018-06-06T12:06:33Z", "version": 1}, {"aid": "1806.02296", "authors": ["Edward T. Reehorst", "Philip Schniter"], "title": "Regularization by Denoising: Clarifications and New Interpretations", "url": "http://arxiv.org/pdf/1806.02296v4", "summary": "Regularization by Denoising (RED), as recently proposed by Romano, Elad, and Milanfar, is powerful image-recovery framework that aims to minimize an explicit regularization objective constructed from a plug-in image-denoising function. Experimental evidence suggests that the RED algorithms are state-of-the-art. We claim, however, that explicit regularization does not explain the RED algorithms. In particular, we show that many of the expressions in the paper by Romano et al. hold only when the denoiser has a symmetric Jacobian, and we demonstrate that such symmetry does not occur with practical denoisers such as non-local means, BM3D, TNRD, and DnCNN. To explain the RED algorithms, we propose a new framework called Score-Matching by Denoising (SMD), which aims to match a \"score\" (i.e., the gradient of a log-prior). We then show tight connections between SMD, kernel density estimation, and constrained minimum mean-squared error denoising. Furthermore, we interpret the RED algorithms from Romano et al. and propose new algorithms with acceleration and convergence guarantees. Finally, we show that the RED algorithms seek a consensus equilibrium solution, which facilitates a comparison to plug-and-play ADMM.", "published": "2018-06-06T16:49:59Z", "version": 4}, {"aid": "1806.02508", "authors": ["Chen Chen", "Qizhen Weng", "Wei Wang", "Baochun Li", "Bo Li"], "title": "Semi-Dynamic Load Balancing: Efficient Distributed Learning in Non-Dedicated Environments", "url": "http://arxiv.org/pdf/1806.02508v2", "summary": "Machine learning (ML) models are increasingly trained in clusters with non-dedicated workers possessing heterogeneous resources. In such scenarios, model training efficiency can be negatively affected by stragglers -- workers that run much slower than others. Efficient model training requires eliminating such stragglers, yet for modern ML workloads, existing load balancing strategies are inefficient and even infeasible. In this paper, we propose a novel strategy called semi-dynamic load balancing to eliminate stragglers of distributed ML workloads. The key insight is that ML workers shall be load-balanced at iteration boundaries, being non-intrusive to intra-iteration execution. We develop LB-BSP based on such an insight, which is an integrated worker coordination mechanism that adapts workers' load to their instantaneous processing capabilities by right-sizing the sample batches at the synchronization barriers. We have custom-designed the batch sizing algorithm respectively for CPU and GPU clusters based on their own characteristics. LB-BSP has been implemented as a Python module for ML frameworks like TensorFlow and PyTorch. Our EC2 deployment confirms that LB-BSP is practical, effective and light-weight, and is able to accelerating distributed training by up to $54\\%$.", "published": "2018-06-07T04:15:58Z", "version": 2}, {"aid": "1806.02623", "authors": ["Jie Zhang", "Yan Wang", "Jie Tang", "Ming Ding"], "title": "Spectral Network Embedding: A Fast and Scalable Method via Sparsity", "url": "http://arxiv.org/pdf/1806.02623v2", "summary": "Network embedding aims to learn low-dimensional representations of nodes in a network, while the network structure and inherent properties are preserved. It has attracted tremendous attention recently due to significant progress in downstream network learning tasks, such as node classification, link prediction, and visualization. However, most existing network embedding methods suffer from the expensive computations due to the large volume of networks. In this paper, we propose a $10\\times \\sim 100\\times$ faster network embedding method, called Progle, by elegantly utilizing the sparsity property of online networks and spectral analysis. In Progle, we first construct a \\textit{sparse} proximity matrix and train the network embedding efficiently via sparse matrix decomposition. Then we introduce a network propagation pattern via spectral analysis to incorporate local and global structure information into the embedding. Besides, this model can be generalized to integrate network information into other insufficiently trained embeddings at speed. Benefiting from sparse spectral network embedding, our experiment on four different datasets shows that Progle outperforms or is comparable to state-of-the-art unsupervised comparison approaches---DeepWalk, LINE, node2vec, GraRep, and HOPE, regarding accuracy, while is $10\\times$ faster than the fastest word2vec-based method. Finally, we validate the scalability of Progle both in real large-scale networks and multiple scales of synthetic networks.", "published": "2018-06-07T11:38:34Z", "version": 2}, {"aid": "1806.02942", "authors": ["Yu Li", "Zhongxiao Li", "Lizhong Ding", "Yijie Pan", "Chao Huang", "Yuhui Hu", "Wei Chen", "Xin Gao"], "title": "SupportNet: solving catastrophic forgetting in class incremental learning with support data", "url": "http://arxiv.org/pdf/1806.02942v3", "summary": "A plain well-trained deep learning model often does not have the ability to learn new knowledge without forgetting the previously learned knowledge, which is known as catastrophic forgetting. Here we propose a novel method, SupportNet, to efficiently and effectively solve the catastrophic forgetting problem in the class incremental learning scenario. SupportNet combines the strength of deep learning and support vector machine (SVM), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training so that the model can review the essential information of the old data when learning the new information. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. We validate our method with comprehensive experiments on various tasks, which show that SupportNet drastically outperforms the state-of-the-art incremental learning methods and even reaches similar performance as the deep learning model trained from scratch on both old and new data. Our program is accessible at: https://github.com/lykaust15/SupportNet", "published": "2018-06-08T01:58:51Z", "version": 3}, {"aid": "1806.03751", "authors": ["Michael Hauser", "Sean Gunn", "Samer Saab Jr", "Asok Ray"], "title": "State Space Representations of Deep Neural Networks", "url": "http://arxiv.org/pdf/1806.03751v3", "summary": "This paper deals with neural networks as dynamical systems governed by differential or difference equations. It shows that the introduction of skip connections into network architectures, such as residual networks and dense networks, turns a system of static equations into a system of dynamical equations with varying levels of smoothness on the layer-wise transformations. Closed form solutions for the state space representations of general dense networks, as well as $k^{th}$ order smooth networks, are found in general settings. Furthermore, it is shown that imposing $k^{th}$ order smoothness on a network architecture with $d$-many nodes per layer increases the state space dimension by a multiple of $k$, and so the effective embedding dimension of the data manifold is $k \\cdot d$-many dimensions. It follows that network architectures of these types reduce the number of parameters needed to maintain the same embedding dimension by a factor of $k^2$ when compared to an equivalent first-order, residual network, significantly motivating the development of network architectures of these types. Numerical simulations were run to validate parts of the developed theory.", "published": "2018-06-11T00:26:13Z", "version": 3}, {"aid": "1806.06927", "authors": ["Jaehong Kim", "Sangyeul Lee", "Sungwan Kim", "Moonsu Cha", "Jung Kwon Lee", "Youngduck Choi", "Yongseok Choi", "Dong-Yeon Cho", "Jiwon Kim"], "title": "Auto-Meta: Automated Gradient Based Meta Learner Search", "url": "http://arxiv.org/pdf/1806.06927v2", "summary": "Fully automating machine learning pipelines is one of the key challenges of current artificial intelligence research, since practical machine learning often requires costly and time-consuming human-powered processes such as model design, algorithm development, and hyperparameter tuning. In this paper, we verify that automated architecture search synergizes with the effect of gradient-based meta learning. We adopt the progressive neural architecture search \\cite{liu:pnas_google:DBLP:journals/corr/abs-1712-00559} to find optimal architectures for meta-learners. The gradient based meta-learner whose architecture was automatically found achieved state-of-the-art results on the 5-shot 5-way Mini-ImageNet classification problem with $74.65\\%$ accuracy, which is $11.54\\%$ improvement over the result obtained by the first gradient-based meta-learner called MAML \\cite{finn:maml:DBLP:conf/icml/FinnAL17}. To our best knowledge, this work is the first successful neural architecture search implementation in the context of meta learning.", "published": "2018-06-11T04:28:02Z", "version": 2}, {"aid": "1806.06928", "authors": ["Risto Vuorio", "Dong-Yeon Cho", "Daejoong Kim", "Jiwon Kim"], "title": "Meta Continual Learning", "url": "http://arxiv.org/pdf/1806.06928v1", "summary": "Using neural networks in practical settings would benefit from the ability of the networks to learn new tasks throughout their lifetimes without forgetting the previous tasks. This ability is limited in the current deep neural networks by a problem called catastrophic forgetting, where training on new tasks tends to severely degrade performance on previous tasks. One way to lessen the impact of the forgetting problem is to constrain parameters that are important to previous tasks to stay close to the optimal parameters. Recently, multiple competitive approaches for computing the importance of the parameters with respect to the previous tasks have been presented. In this paper, we propose a learning to optimize algorithm for mitigating catastrophic forgetting. Instead of trying to formulate a new constraint function ourselves, we propose to train another neural network to predict parameter update steps that respect the importance of parameters to the previous tasks. In the proposed meta-training scheme, the update predictor is trained to minimize loss on a combination of current and past tasks. We show experimentally that the proposed approach works in the continual learning setting.", "published": "2018-06-11T06:49:54Z", "version": 1}, {"aid": "1806.03891", "authors": ["Juil Sock", "Kwang In Kim", "Caner Sahin", "Tae-Kyun Kim"], "title": "Multi-Task Deep Networks for Depth-Based 6D Object Pose and Joint Registration in Crowd Scenarios", "url": "http://arxiv.org/pdf/1806.03891v1", "summary": "In bin-picking scenarios, multiple instances of an object of interest are stacked in a pile randomly, and hence, the instances are inherently subjected to the challenges: severe occlusion, clutter, and similar-looking distractors. Most existing methods are, however, for single isolated object instances, while some recent methods tackle crowd scenarios as post-refinement which accounts multiple object relations. In this paper, we address recovering 6D poses of multiple instances in bin-picking scenarios in depth modality by multi-task learning in deep neural networks. Our architecture jointly learns multiple sub-tasks: 2D detection, depth, and 3D pose estimation of individual objects; and joint registration of multiple objects. For training data generation, depth images of physically plausible object pose configurations are generated by a 3D object model in a physics simulation, which yields diverse occlusion patterns to learn. We adopt a state-of-the-art object detector, and 2D offsets are further estimated via a network to refine misaligned 2D detections. The depth and 3D pose estimator is designed to generate multiple hypotheses per detection. This allows the joint registration network to learn occlusion patterns and remove physically implausible pose hypotheses. We apply our architecture on both synthetic (our own and Sileane dataset) and real (a public Bin-Picking dataset) data, showing that it significantly outperforms state-of-the-art methods by 15-31% in average precision.", "published": "2018-06-11T10:05:42Z", "version": 1}, {"aid": "1806.04734", "authors": ["Eli Schwartz", "Leonid Karlinsky", "Joseph Shtok", "Sivan Harary", "Mattias Marder", "Rogerio Feris", "Abhishek Kumar", "Raja Giryes", "Alex M. Bronstein"], "title": "Delta-encoder: an effective sample synthesis method for few-shot object recognition", "url": "http://arxiv.org/pdf/1806.04734v3", "summary": "Learning to classify new categories based on just one or a few examples is a long-standing challenge in modern computer vision. In this work, we proposes a simple yet effective method for few-shot (and one-shot) object recognition. Our approach is based on a modified auto-encoder, denoted Delta-encoder, that learns to synthesize new samples for an unseen category just by seeing few examples from it. The synthesized samples are then used to train a classifier. The proposed approach learns to both extract transferable intra-class deformations, or \"deltas\", between same-class pairs of training examples, and to apply those deltas to the few provided examples of a novel class (unseen during training) in order to efficiently synthesize samples from that new class. The proposed method improves over the state-of-the-art in one-shot object-recognition and compares favorably in the few-shot case. Upon acceptance code will be made available.", "published": "2018-06-12T19:31:11Z", "version": 3}, {"aid": "1806.04808", "authors": ["Guansong Pang", "Longbing Cao", "Ling Chen", "Huan Liu"], "title": "Learning Representations of Ultrahigh-dimensional Data for Random Distance-based Outlier Detection", "url": "http://arxiv.org/pdf/1806.04808v1", "summary": "Learning expressive low-dimensional representations of ultrahigh-dimensional data, e.g., data with thousands/millions of features, has been a major way to enable learning methods to address the curse of dimensionality. However, existing unsupervised representation learning methods mainly focus on preserving the data regularity information and learning the representations independently of subsequent outlier detection methods, which can result in suboptimal and unstable performance of detecting irregularities (i.e., outliers).   This paper introduces a ranking model-based framework, called RAMODO, to address this issue. RAMODO unifies representation learning and outlier detection to learn low-dimensional representations that are tailored for a state-of-the-art outlier detection approach - the random distance-based approach. This customized learning yields more optimal and stable representations for the targeted outlier detectors. Additionally, RAMODO can leverage little labeled data as prior knowledge to learn more expressive and application-relevant representations. We instantiate RAMODO to an efficient method called REPEN to demonstrate the performance of RAMODO.   Extensive empirical results on eight real-world ultrahigh dimensional data sets show that REPEN (i) enables a random distance-based detector to obtain significantly better AUC performance and two orders of magnitude speedup; (ii) performs substantially better and more stably than four state-of-the-art representation learning methods; and (iii) leverages less than 1% labeled data to achieve up to 32% AUC improvement.", "published": "2018-06-13T00:53:56Z", "version": 1}, {"aid": "1806.04854", "authors": ["Mohammad Emtiyaz Khan", "Didrik Nielsen", "Voot Tangkaratt", "Wu Lin", "Yarin Gal", "Akash Srivastava"], "title": "Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam", "url": "http://arxiv.org/pdf/1806.04854v3", "summary": "Uncertainty computation in deep learning is essential to design robust and reliable systems. Variational inference (VI) is a promising approach for such computation, but requires more effort to implement and execute compared to maximum-likelihood methods. In this paper, we propose new natural-gradient algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms can be implemented within the Adam optimizer by perturbing the network weights during gradient evaluations, and uncertainty estimates can be cheaply obtained by using the vector that adapts the learning rate. This requires lower memory, computation, and implementation effort than existing VI methods, while obtaining uncertainty estimates of comparable quality. Our empirical results confirm this and further suggest that the weight-perturbation in our algorithm could be useful for exploration in reinforcement learning and stochastic optimization.", "published": "2018-06-13T05:45:22Z", "version": 3}, {"aid": "1806.05034", "authors": ["Simon A. A. Kohl", "Bernardino Romera-Paredes", "Clemens Meyer", "Jeffrey De Fauw", "Joseph R. Ledsam", "Klaus H. Maier-Hein", "S. M. Ali Eslami", "Danilo Jimenez Rezende", "Olaf Ronneberger"], "title": "A Probabilistic U-Net for Segmentation of Ambiguous Images", "url": "http://arxiv.org/pdf/1806.05034v4", "summary": "Many real-world vision problems suffer from inherent ambiguities. In clinical applications for example, it might not be clear from a CT scan alone which particular region is cancer tissue. Therefore a group of graders typically produces a set of diverse but plausible segmentations. We consider the task of learning a distribution over segmentations given an input. To this end we propose a generative segmentation model based on a combination of a U-Net with a conditional variational autoencoder that is capable of efficiently producing an unlimited number of plausible hypotheses. We show on a lung abnormalities segmentation task and on a Cityscapes segmentation task that our model reproduces the possible segmentation variants as well as the frequencies with which they occur, doing so significantly better than published approaches. These models could have a high impact in real-world applications, such as being used as clinical decision-making algorithms accounting for multiple plausible semantic segmentation hypotheses to provide possible diagnoses and recommend further actions to resolve the present ambiguities.", "published": "2018-06-13T13:47:04Z", "version": 4}, {"aid": "1806.05226", "authors": ["Artur Jordao", "Antonio C. Nazare Jr.", "Jessica Sena", "William Robson Schwartz"], "title": "Human Activity Recognition Based on Wearable Sensor Data: A Standardization of the State-of-the-Art", "url": "http://arxiv.org/pdf/1806.05226v3", "summary": "Human activity recognition based on wearable sensor data has been an attractive research topic due to its application in areas such as healthcare and smart environments. In this context, many works have presented remarkable results using accelerometer, gyroscope and magnetometer data to represent the activities categories. However, current studies do not consider important issues that lead to skewed results, making it hard to assess the quality of sensor-based human activity recognition and preventing a direct comparison of previous works. These issues include the samples generation processes and the validation protocols used. We emphasize that in other research areas, such as image classification and object detection, these issues are already well-defined, which brings more efforts towards the application. Inspired by this, we conduct an extensive set of experiments that analyze different sample generation processes and validation protocols to indicate the vulnerable points in human activity recognition based on wearable sensor data. For this purpose, we implement and evaluate several top-performance methods, ranging from handcrafted-based approaches to convolutional neural networks. According to our study, most of the experimental evaluations that are currently employed are not adequate to perform the activity recognition in the context of wearable sensor data, in which the recognition accuracy drops considerably when compared to an appropriate evaluation approach. To the best of our knowledge, this is the first study that tackles essential issues that compromise the understanding of the performance in human activity recognition based on wearable sensor data.", "published": "2018-06-13T19:07:29Z", "version": 3}, {"aid": "1806.05234", "authors": ["Daniele Funaro"], "title": "Understanding the Meaning of Understanding", "url": "http://arxiv.org/pdf/1806.05234v2", "summary": "Can we train a machine to detect if another machine has understood a concept? In principle, this is possible by conducting tests on the subject of that concept. However we want this procedure to be done by avoiding direct questions. In other words, we would like to isolate the absolute meaning of an abstract idea by putting it into a class of equivalence, hence without adopting straight definitions or showing how this idea \"works\" in practice. We discuss the metaphysical implications hidden in the above question, with the aim of providing a plausible reference framework.", "published": "2018-06-13T19:26:55Z", "version": 2}, {"aid": "1806.05759", "authors": ["Ari S. Morcos", "Maithra Raghu", "Samy Bengio"], "title": "Insights on representational similarity in neural networks with canonical correlation", "url": "http://arxiv.org/pdf/1806.05759v3", "summary": "Comparing different neural network representations and determining how representations evolve over time remain challenging open questions in our understanding of the function of neural networks. Comparing representations in neural networks is fundamentally difficult as the structure of representations varies greatly, even across groups of networks trained on identical tasks, and over the course of training. Here, we develop projection weighted CCA (Canonical Correlation Analysis) as a tool for understanding neural networks, building off of SVCCA, a recently proposed method (Raghu et al., 2017). We first improve the core method, showing how to differentiate between signal and noise, and then apply this technique to compare across a group of CNNs, demonstrating that networks which generalize converge to more similar representations than networks which memorize, that wider networks converge to more similar solutions than narrow networks, and that trained networks with identical topology but different learning rates converge to distinct clusters with diverse representations. We also investigate the representational dynamics of RNNs, across both training and sequential timesteps, finding that RNNs converge in a bottom-up pattern over the course of training and that the hidden state is highly variable over the course of a sequence, even when accounting for linear transforms. Together, these results provide new insights into the function of CNNs and RNNs, and demonstrate the utility of using CCA to understand representations.", "published": "2018-06-14T22:34:11Z", "version": 3}, {"aid": "1806.05978", "authors": ["Kumar Shridhar", "Felix Laumann", "Marcus Liwicki"], "title": "Uncertainty Estimations by Softplus normalization in Bayesian Convolutional Neural Networks with Variational Inference", "url": "http://arxiv.org/pdf/1806.05978v6", "summary": "We introduce a novel uncertainty estimation for classification tasks for Bayesian convolutional neural networks with variational inference. By normalizing the output of a Softplus function in the final layer, we estimate aleatoric and epistemic uncertainty in a coherent manner. The intractable posterior probability distributions over weights are inferred by Bayes by Backprop. Firstly, we demonstrate how this reliable variational inference method can serve as a fundamental construct for various network architectures. On multiple datasets in supervised learning settings (MNIST, CIFAR-10, CIFAR-100), this variational inference method achieves performances equivalent to frequentist inference in identical architectures, while the two desiderata, a measure for uncertainty and regularization are incorporated naturally. Secondly, we examine how our proposed measure for aleatoric and epistemic uncertainties is derived and validate it on the aforementioned datasets.", "published": "2018-06-15T13:55:18Z", "version": 6}, {"aid": "1806.06575", "authors": ["Thu Nguyen-Phuoc", "Chuan Li", "Stephen Balaban", "Yong-Liang Yang"], "title": "RenderNet: A deep convolutional network for differentiable rendering from 3D shapes", "url": "http://arxiv.org/pdf/1806.06575v3", "summary": "Traditional computer graphics rendering pipeline is designed for procedurally generating 2D quality images from 3D shapes with high performance. The non-differentiability due to discrete operations such as visibility computation makes it hard to explicitly correlate rendering parameters and the resulting image, posing a significant challenge for inverse rendering tasks. Recent work on differentiable rendering achieves differentiability either by designing surrogate gradients for non-differentiable operations or via an approximate but differentiable renderer. These methods, however, are still limited when it comes to handling occlusion, and restricted to particular rendering effects. We present RenderNet, a differentiable rendering convolutional network with a novel projection unit that can render 2D images from 3D shapes. Spatial occlusion and shading calculation are automatically encoded in the network. Our experiments show that RenderNet can successfully learn to implement different shaders, and can be used in inverse rendering tasks to estimate shape, pose, lighting and texture from a single image.", "published": "2018-06-18T09:45:33Z", "version": 3}, {"aid": "1806.06986", "authors": ["Zhe Wu", "Navaneeth Bodla", "Bharat Singh", "Mahyar Najibi", "Rama Chellappa", "Larry S. Davis"], "title": "Soft Sampling for Robust Object Detection", "url": "http://arxiv.org/pdf/1806.06986v2", "summary": "We study the robustness of object detection under the presence of missing annotations. In this setting, the unlabeled object instances will be treated as background, which will generate an incorrect training signal for the detector. Interestingly, we observe that after dropping 30% of the annotations (and labeling them as background), the performance of CNN-based object detectors like Faster-RCNN only drops by 5% on the PASCAL VOC dataset. We provide a detailed explanation for this result. To further bridge the performance gap, we propose a simple yet effective solution, called Soft Sampling. Soft Sampling re-weights the gradients of RoIs as a function of overlap with positive instances. This ensures that the uncertain background regions are given a smaller weight compared to the hardnegatives. Extensive experiments on curated PASCAL VOC datasets demonstrate the effectiveness of the proposed Soft Sampling method at different annotation drop rates. Finally, we show that on OpenImagesV3, which is a real-world dataset with missing annotations, Soft Sampling outperforms standard detection baselines by over 3%.", "published": "2018-06-18T23:40:14Z", "version": 2}, {"aid": "1806.07108", "authors": ["Qiqi Zhang", "Ying Liu"], "title": "Improving brain computer interface performance by data augmentation with conditional Deep Convolutional Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1806.07108v2", "summary": "One of the big restrictions in brain computer interface field is the very limited training samples, it is difficult to build a reliable and usable system with such limited data. Inspired by generative adversarial networks, we propose a conditional Deep Convolutional Generative Adversarial (cDCGAN) Networks method to generate more artificial EEG signal automatically for data augmentation to improve the performance of convolutional neural networks in brain computer interface field and overcome the small training dataset problems. We evaluate the proposed cDCGAN method on BCI competition dataset of motor imagery. The results show that the generated artificial EEG data from Gaussian noise can learn the features from raw EEG data and has no less than the classification accuracy of raw EEG data in the testing dataset. Also by using generated artificial data can effectively improve classification accuracy at the same model with limited training data.", "published": "2018-06-19T08:49:50Z", "version": 2}, {"aid": "1806.07366", "authors": ["Ricky T. Q. Chen", "Yulia Rubanova", "Jesse Bettencourt", "David Duvenaud"], "title": "Neural Ordinary Differential Equations", "url": "http://arxiv.org/pdf/1806.07366v5", "summary": "We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.", "published": "2018-06-19T17:50:12Z", "version": 5}, {"aid": "1806.07685", "authors": ["Ivo D\u00fcntsch", "G\u00fcnther Gediga", "Hui Wang"], "title": "Approximation by filter functions", "url": "http://arxiv.org/pdf/1806.07685v1", "summary": "In this exploratory article, we draw attention to the common formal ground among various estimators such as the belief functions of evidence theory and their relatives, approximation quality of rough set theory, and contextual probability. The unifying concept will be a general filter function composed of a basic probability and a weighting which varies according to the problem at hand. To compare the various filter functions we conclude with a simulation study with an example from the area of item response theory.", "published": "2018-06-20T12:09:52Z", "version": 1}, {"aid": "1806.07908", "authors": ["Moacir Antonelli Ponti", "Gabriel B. Paranhos da Costa"], "title": "Como funciona o Deep Learning", "url": "http://arxiv.org/pdf/1806.07908v1", "summary": "Deep Learning methods are currently the state-of-the-art in many problems which can be tackled via machine learning, in particular classification problems. However there is still lack of understanding on how those methods work, why they work and what are the limitations involved in using them. In this chapter we will describe in detail the transition from shallow to deep networks, include examples of code on how to implement them, as well as the main issues one faces when training a deep network. Afterwards, we introduce some theoretical background behind the use of deep models, and discuss their limitations.", "published": "2018-06-20T18:04:09Z", "version": 1}, {"aid": "1806.07996", "authors": ["Dominique Beaini", "Sofiane Achiche", "Yann-Seing Law-Kam Cio", "Maxime Raison"], "title": "Novel Convolution Kernels for Computer Vision and Shape Analysis based on Electromagnetism", "url": "http://arxiv.org/pdf/1806.07996v1", "summary": "Computer vision is a growing field with a lot of new applications in automation and robotics, since it allows the analysis of images and shapes for the generation of numerical or analytical information. One of the most used method of information extraction is image filtering through convolution kernels, with each kernel specialized for specific applications. The objective of this paper is to present a novel convolution kernels, based on principles of electromagnetic potentials and fields, for a general use in computer vision and to demonstrate its usage for shape and stroke analysis. Such filtering possesses unique geometrical properties that can be interpreted using well understood physics theorems. Therefore, this paper focuses on the development of the electromagnetic kernels and on their application on images for shape and stroke analysis. It also presents several interesting features of electromagnetic kernels, such as resolution, size and orientation independence, robustness to noise and deformation, long distance stroke interaction and ability to work with 3D images", "published": "2018-06-20T21:31:00Z", "version": 1}, {"aid": "1806.07998", "authors": ["Christian Kerskens", "David Lopez Perez"], "title": "Experimental evidence of non-classical brain functions", "url": "http://arxiv.org/pdf/1806.07998v6", "summary": "Recent proposals in quantum gravity have suggested that unknown systems can mediate entanglement between two known quantum systems, if and only if the mediator itself is non-classical. This approach may be applicable to the brain, where speculations about quantum operations in consciousness and cognition have a long history. Proton spins of bulk water, which most likely interfere with any brain function, can act as the known quantum systems. If an unknown mediator exists, then NMR methods based on multiple quantum coherence (MQC) can act as entanglement witness. However, there are doubts that today's NMR signals can contain quantum correlations in general, and specifically in the brain environment. Here, we used a witness protocol based on zero quantum coherence (ZQC) whereby we minimised the classical signals to circumvent the NMR detection limits for quantum correlation. For short repetitive periods, we found evoked signals in most parts of the brain, whereby the temporal appearance resembled heartbeat-evoked potentials (HEPs). We found that those signals had no correlates with any classical NMR contrast. Similar to HEPs, the evoked signal depended on conscious awareness. Consciousness-related or electrophysiological signals are unknown in NMR. Remarkably, these signals only appeared if the local properties of the magnetisation were reduced. Our findings suggest that we may have witnessed entanglement mediated by consciousness-related brain functions. Those brain functions must then operate non-classically, which would mean that consciousness is non-classical.", "published": "2018-06-20T21:43:44Z", "version": 6}, {"aid": "1806.08065", "authors": ["Devendra Singh Chaplot", "Christopher MacLellan", "Ruslan Salakhutdinov", "Kenneth Koedinger"], "title": "Learning Cognitive Models using Neural Networks", "url": "http://arxiv.org/pdf/1806.08065v1", "summary": "A cognitive model of human learning provides information about skills a learner must acquire to perform accurately in a task domain. Cognitive models of learning are not only of scientific interest, but are also valuable in adaptive online tutoring systems. A more accurate model yields more effective tutoring through better instructional decisions. Prior methods of automated cognitive model discovery have typically focused on well-structured domains, relied on student performance data or involved substantial human knowledge engineering. In this paper, we propose Cognitive Representation Learner (CogRL), a novel framework to learn accurate cognitive models in ill-structured domains with no data and little to no human knowledge engineering. Our contribution is two-fold: firstly, we show that representations learnt using CogRL can be used for accurate automatic cognitive model discovery without using any student performance data in several ill-structured domains: Rumble Blocks, Chinese Character, and Article Selection. This is especially effective and useful in domains where an accurate human-authored cognitive model is unavailable or authoring a cognitive model is difficult. Secondly, for domains where a cognitive model is available, we show that representations learned through CogRL can be used to get accurate estimates of skill difficulty and learning rate parameters without using any student performance data. These estimates are shown to highly correlate with estimates using student performance data on an Article Selection dataset.", "published": "2018-06-21T04:43:35Z", "version": 1}, {"aid": "1806.08523", "authors": ["Phongtharin Vinayavekhin", "Subhajit Chaudhury", "Asim Munawar", "Don Joven Agravante", "Giovanni De Magistris", "Daiki Kimura", "Ryuki Tachibana"], "title": "Focusing on What is Relevant: Time-Series Learning and Understanding using Attention", "url": "http://arxiv.org/pdf/1806.08523v1", "summary": "This paper is a contribution towards interpretability of the deep learning models in different applications of time-series. We propose a temporal attention layer that is capable of selecting the relevant information to perform various tasks, including data completion, key-frame detection and classification. The method uses the whole input sequence to calculate an attention value for each time step. This results in more focused attention values and more plausible visualisation than previous methods. We apply the proposed method to three different tasks. Experimental results show that the proposed network produces comparable results to a state of the art. In addition, the network provides better interpretability of the decision, that is, it generates more significant attention weight to related frames compared to similar techniques attempted in the past.", "published": "2018-06-22T07:16:08Z", "version": 1}, {"aid": "1806.08672", "authors": ["Rita Kuznetsova", "Oleg Bakhteev", "Alexandr Ogaltsov"], "title": "Variational learning across domains with triplet information", "url": "http://arxiv.org/pdf/1806.08672v2", "summary": "The work investigates deep generative models, which allow us to use training data from one domain to build a model for another domain. We propose the Variational Bi-domain Triplet Autoencoder (VBTA) that learns a joint distribution of objects from different domains. We extend the VBTAs objective function by the relative constraints or triplets that sampled from the shared latent space across domains. In other words, we combine the deep generative models with a metric learning ideas in order to improve the final objective with the triplets information. The performance of the VBTA model is demonstrated on different tasks: image-to-image translation, bi-directional image generation and cross-lingual document classification.", "published": "2018-06-22T13:58:42Z", "version": 2}, {"aid": "1806.08894", "authors": ["Seyed Sajad Mousavi", "Michael Schukat", "Enda Howley"], "title": "Deep Reinforcement Learning: An Overview", "url": "http://arxiv.org/pdf/1806.08894v1", "summary": "In recent years, a specific machine learning method called deep learning has gained huge attraction, as it has obtained astonishing results in broad applications such as pattern recognition, speech recognition, computer vision, and natural language processing. Recent research has also been shown that deep learning techniques can be combined with reinforcement learning methods to learn useful representations for the problems with high dimensional raw data input. This chapter reviews the recent advances in deep reinforcement learning with a focus on the most used deep architectures such as autoencoders, convolutional neural networks and recurrent neural networks which have successfully been come together with the reinforcement learning framework.", "published": "2018-06-23T02:18:26Z", "version": 1}, {"aid": "1806.09055", "authors": ["Hanxiao Liu", "Karen Simonyan", "Yiming Yang"], "title": "DARTS: Differentiable Architecture Search", "url": "http://arxiv.org/pdf/1806.09055v2", "summary": "This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space, our method is based on the continuous relaxation of the architecture representation, allowing efficient search of the architecture using gradient descent. Extensive experiments on CIFAR-10, ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques. Our implementation has been made publicly available to facilitate further research on efficient architecture search algorithms.", "published": "2018-06-24T00:06:13Z", "version": 2}, {"aid": "1806.09141", "authors": ["Raanan Y. Rohekar", "Shami Nisimov", "Yaniv Gurwicz", "Guy Koren", "Gal Novik"], "title": "Constructing Deep Neural Networks by Bayesian Network Structure Learning", "url": "http://arxiv.org/pdf/1806.09141v3", "summary": "We introduce a principled approach for unsupervised structure learning of deep neural networks. We propose a new interpretation for depth and inter-layer connectivity where conditional independencies in the input distribution are encoded hierarchically in the network structure. Thus, the depth of the network is determined inherently. The proposed method casts the problem of neural network structure learning as a problem of Bayesian network structure learning. Then, instead of directly learning the discriminative structure, it learns a generative graph, constructs its stochastic inverse, and then constructs a discriminative graph. We prove that conditional-dependency relations among the latent variables in the generative graph are preserved in the class-conditional discriminative graph. We demonstrate on image classification benchmarks that the deepest layers (convolutional and dense) of common networks can be replaced by significantly smaller learned structures, while maintaining classification accuracy---state-of-the-art on tested benchmarks. Our structure learning algorithm requires a small computational cost and runs efficiently on a standard desktop CPU.", "published": "2018-06-24T13:05:06Z", "version": 3}, {"aid": "1806.10282", "authors": ["Haifeng Jin", "Qingquan Song", "Xia Hu"], "title": "Auto-Keras: An Efficient Neural Architecture Search System", "url": "http://arxiv.org/pdf/1806.10282v3", "summary": "Neural architecture search (NAS) has been proposed to automatically tune deep neural networks, but existing search algorithms, e.g., NASNet, PNAS, usually suffer from expensive computational cost. Network morphism, which keeps the functionality of a neural network while changing its neural architecture, could be helpful for NAS by enabling more efficient training during the search. In this paper, we propose a novel framework enabling Bayesian optimization to guide the network morphism for efficient neural architecture search. The framework develops a neural network kernel and a tree-structured acquisition function optimization algorithm to efficiently explores the search space. Intensive experiments on real-world benchmark datasets have been done to demonstrate the superior performance of the developed framework over the state-of-the-art methods. Moreover, we build an open-source AutoML system based on our method, namely Auto-Keras. The system runs in parallel on CPU and GPU, with an adaptive search strategy for different GPU memory limits.", "published": "2018-06-27T03:18:35Z", "version": 3}, {"aid": "1806.10342", "authors": ["Yi-Jie Huang", "Qi Dou", "Zi-Xian Wang", "Li-Zhi Liu", "Ying Jin", "Chao-Feng Li", "Lisheng Wang", "Hao Chen", "Rui-Hua Xu"], "title": "3D RoI-aware U-Net for Accurate and Efficient Colorectal Tumor Segmentation", "url": "http://arxiv.org/pdf/1806.10342v5", "summary": "Segmentation of colorectal cancerous regions from 3D Magnetic Resonance (MR) images is a crucial procedure for radiotherapy which conventionally requires accurate delineation of tumour boundaries at an expense of labor, time and reproducibility. While deep learning based methods serve good baselines in 3D image segmentation tasks, small applicable patch size limits effective receptive field and degrades segmentation performance. In addition, Regions of interest (RoIs) localization from large whole volume 3D images serves as a preceding operation that brings about multiple benefits in terms of speed, target completeness, reduction of false positives. Distinct from sliding window or non-joint localization-segmentation based models, we propose a novel multitask framework referred to as 3D RoI-aware U-Net (3D RU-Net), for RoI localization and in-region segmentation where the two tasks share one backbone encoder network. With the region proposals from the encoder, we crop multi-level RoI in-region features from the encoder to form a GPU memory-efficient decoder for detailpreserving segmentation and therefore enlarged applicable volume size and effective receptive field. To effectively train the model, we designed a Dice formulated loss function for the global-to-local multi-task learning procedure. Based on the efficiency gains, we went on to ensemble models with different receptive fields to achieve even higher performance costing minor extra computational expensiveness. Extensive experiments were conducted on 64 cancerous cases with a four-fold cross-validation, and the results showed significant superiority in terms of accuracy and efficiency over conventional frameworks. In conclusion, the proposed method has a huge potential for extension to other 3D object segmentation tasks from medical images due to its inherent generalizability. The code for the proposed method is publicly available.", "published": "2018-06-27T08:42:58Z", "version": 5}, {"aid": "1806.10779", "authors": ["Ping Luo", "Jiamin Ren", "Zhanglin Peng", "Ruimao Zhang", "Jingyu Li"], "title": "Differentiable Learning-to-Normalize via Switchable Normalization", "url": "http://arxiv.org/pdf/1806.10779v5", "summary": "We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network. SN employs three distinct scopes to compute statistics (means and variances) including a channel, a layer, and a minibatch. SN switches between them by learning their importance weights in an end-to-end manner. It has several good properties. First, it adapts to various network architectures and tasks (see Fig.1). Second, it is robust to a wide range of batch sizes, maintaining high performance even when small minibatch is presented (e.g. 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike group normalization that searches the number of groups as a hyper-parameter. Without bells and whistles, SN outperforms its counterparts on various challenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, and Kinetics. Analyses of SN are also presented. We hope SN will help ease the usage and understand the normalization techniques in deep learning. The code of SN has been made available in https://github.com/switchablenorms/.", "published": "2018-06-28T05:55:57Z", "version": 5}, {"aid": "1806.11169", "authors": ["J. Tilak Ratnanather", "Sylvain Arguill\u00e8re", "Kwame S. Kutten", "Peter Hubka", "Andrej Kral", "Laurent Younes"], "title": "3D Normal Coordinate Systems for Cortical Areas", "url": "http://arxiv.org/pdf/1806.11169v3", "summary": "A surface-based diffeomorphic algorithm to generate 3D coordinate grids in the cortical ribbon is described. In the grid, normal coordinate lines are generated by the diffeomorphic evolution from the grey/white (inner) surface to the grey/csf (outer) surface. Specifically, the cortical ribbon is described by two triangulated surfaces with open boundaries. Conceptually, the inner surface sits on top of the white matter structure and the outer on top of the gray matter. It is assumed that the cortical ribbon consists of cortical columns which are orthogonal to the white matter surface. This might be viewed as a consequence of the development of the columns in the embryo. It is also assumed that the columns are orthogonal to the outer surface so that the resultant vector field is orthogonal to the evolving surface. Then the distance of the normal lines from the vector field such that the inner surface evolves diffeomorphically towards the outer one can be construed as a measure of thickness. Applications are described for the auditory cortices in human adults and cats with normal hearing or hearing loss. The approach offers great potential for cortical morphometry.", "published": "2018-06-28T20:16:57Z", "version": 3}, {"aid": "1806.11379", "authors": ["Tomaso Poggio", "Qianli Liao", "Brando Miranda", "Andrzej Banburski", "Xavier Boix", "Jack Hidary"], "title": "Theory IIIb: Generalization in Deep Networks", "url": "http://arxiv.org/pdf/1806.11379v1", "summary": "A main puzzle of deep neural networks (DNNs) revolves around the apparent absence of \"overfitting\", defined in this paper as follows: the expected error does not get worse when increasing the number of neurons or of iterations of gradient descent. This is surprising because of the large capacity demonstrated by DNNs to fit randomly labeled data and the absence of explicit regularization. Recent results by Srebro et al. provide a satisfying solution of the puzzle for linear networks used in binary classification. They prove that minimization of loss functions such as the logistic, the cross-entropy and the exp-loss yields asymptotic, \"slow\" convergence to the maximum margin solution for linearly separable datasets, independently of the initial conditions. Here we prove a similar result for nonlinear multilayer DNNs near zero minima of the empirical loss. The result holds for exponential-type losses but not for the square loss. In particular, we prove that the weight matrix at each layer of a deep network converges to a minimum norm solution up to a scale factor (in the separable case). Our analysis of the dynamical system corresponding to gradient descent of a multilayer network suggests a simple criterion for ranking the generalization performance of different zero minimizers of the empirical loss.", "published": "2018-06-29T12:39:08Z", "version": 1}, {"aid": "1807.00082", "authors": ["Thomas Dean", "Maurice Chiang", "Marcus Gomez", "Nate Gruver", "Yousef Hindy", "Michelle Lam", "Peter Lu", "Sophia Sanchez", "Rohun Saxena", "Michael Smith", "Lucy Wang", "Catherine Wong"], "title": "Amanuensis: The Programmer's Apprentice", "url": "http://arxiv.org/pdf/1807.00082v2", "summary": "This document provides an overview of the material covered in a course taught at Stanford in the spring quarter of 2018. The course draws upon insight from cognitive and systems neuroscience to implement hybrid connectionist and symbolic reasoning systems that leverage and extend the state of the art in machine learning by integrating human and machine intelligence. As a concrete example we focus on digital assistants that learn from continuous dialog with an expert software engineer while providing initial value as powerful analytical, computational and mathematical savants. Over time these savants learn cognitive strategies (domain-relevant problem solving skills) and develop intuitions (heuristics and the experience necessary for applying them) by learning from their expert associates. By doing so these savants elevate their innate analytical skills allowing them to partner on an equal footing as versatile collaborators - effectively serving as cognitive extensions and digital prostheses, thereby amplifying and emulating their human partner's conceptually-flexible thinking patterns and enabling improved access to and control over powerful computing resources.", "published": "2018-06-29T22:59:08Z", "version": 2}, {"aid": "1807.00196", "authors": ["Pedro A. Ortega", "Shane Legg"], "title": "Modeling Friends and Foes", "url": "http://arxiv.org/pdf/1807.00196v1", "summary": "How can one detect friendly and adversarial behavior from raw data? Detecting whether an environment is a friend, a foe, or anything in between, remains a poorly understood yet desirable ability for safe and robust agents. This paper proposes a definition of these environmental \"attitudes\" based on an characterization of the environment's ability to react to the agent's private strategy. We define an objective function for a one-shot game that allows deriving the environment's probability distribution under friendly and adversarial assumptions alongside the agent's optimal strategy. Furthermore, we present an algorithm to compute these equilibrium strategies, and show experimentally that both friendly and adversarial environments possess non-trivial optimal strategies.", "published": "2018-06-30T16:07:43Z", "version": 1}, {"aid": "1807.00962", "authors": ["Olga Krestinskaya", "Alex Pappachen James", "Leon O. Chua"], "title": "Neuro-memristive Circuits for Edge Computing: A review", "url": "http://arxiv.org/pdf/1807.00962v2", "summary": "The volume, veracity, variability, and velocity of data produced from the ever-increasing network of sensors connected to Internet pose challenges for power management, scalability, and sustainability of cloud computing infrastructure. Increasing the data processing capability of edge computing devices at lower power requirements can reduce several overheads for cloud computing solutions. This paper provides the review of neuromorphic CMOS-memristive architectures that can be integrated into edge computing devices. We discuss why the neuromorphic architectures are useful for edge devices and show the advantages, drawbacks and open problems in the field of neuro-memristive circuits for edge computing.", "published": "2018-07-01T04:07:23Z", "version": 2}, {"aid": "1807.00284", "authors": ["Benteng Ma", "Yong Xia"], "title": "Autonomous Deep Learning: A Genetic DCNN Designer for Image Classification", "url": "http://arxiv.org/pdf/1807.00284v1", "summary": "Recent years have witnessed the breakthrough success of deep convolutional neural networks (DCNNs) in image classification and other vision applications. Although freeing users from the troublesome handcrafted feature extraction by providing a uniform feature extraction-classification framework, DCNNs still require a handcrafted design of their architectures. In this paper, we propose the genetic DCNN designer, an autonomous learning algorithm can generate a DCNN architecture automatically based on the data available for a specific image classification problem. We first partition a DCNN into multiple stacked meta convolutional blocks and fully connected blocks, each containing the operations of convolution, pooling, fully connection, batch normalization, activation and drop out, and thus convert the architecture into an integer vector. Then, we use refined evolutionary operations, including selection, mutation and crossover to evolve a population of DCNN architectures. Our results on the MNIST, Fashion-MNIST, EMNISTDigit, EMNIST-Letter, CIFAR10 and CIFAR100 datasets suggest that the proposed genetic DCNN designer is able to produce automatically DCNN architectures, whose performance is comparable to, if not better than, that of stateof- the-art DCNN models", "published": "2018-07-01T07:11:54Z", "version": 1}, {"aid": "1807.00401", "authors": ["James Max Kanter", "Benjamin Schreck", "Kalyan Veeramachaneni"], "title": "Machine learning 2.0 : Engineering Data Driven AI Products", "url": "http://arxiv.org/pdf/1807.00401v1", "summary": "ML 2.0: In this paper, we propose a paradigm shift from the current practice of creating machine learning models - which requires months-long discovery, exploration and \"feasibility report\" generation, followed by re-engineering for deployment - in favor of a rapid, 8-week process of development, understanding, validation and deployment that can executed by developers or subject matter experts (non-ML experts) using reusable APIs. This accomplishes what we call a \"minimum viable data-driven model,\" delivering a ready-to-use machine learning model for problems that haven't been solved before using machine learning. We provide provisions for the refinement and adaptation of the \"model,\" with strict enforcement and adherence to both the scaffolding/abstractions and the process. We imagine that this will bring forth the second phase in machine learning, in which discovery is subsumed by more targeted goals of delivery and impact.", "published": "2018-07-01T21:50:58Z", "version": 1}, {"aid": "1807.00412", "authors": ["Alex Kendall", "Jeffrey Hawke", "David Janz", "Przemyslaw Mazur", "Daniele Reda", "John-Mark Allen", "Vinh-Dieu Lam", "Alex Bewley", "Amar Shah"], "title": "Learning to Drive in a Day", "url": "http://arxiv.org/pdf/1807.00412v2", "summary": "We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.", "published": "2018-07-01T22:47:08Z", "version": 2}, {"aid": "1807.00456", "authors": ["Chengxi Ye", "Chinmaya Devaraj", "Michael Maynord", "Cornelia Ferm\u00fcller", "Yiannis Aloimonos"], "title": "Evenly Cascaded Convolutional Networks", "url": "http://arxiv.org/pdf/1807.00456v2", "summary": "We introduce Evenly Cascaded convolutional Network (ECN), a neural network taking inspiration from the cascade algorithm of wavelet analysis. ECN employs two feature streams - a low-level and high-level steam. At each layer these streams interact, such that low-level features are modulated using advanced perspectives from the high-level stream. ECN is evenly structured through resizing feature map dimensions by a consistent ratio, which removes the burden of ad-hoc specification of feature map dimensions. ECN produces easily interpretable features maps, a result whose intuition can be understood in the context of scale-space theory. We demonstrate that ECN's design facilitates the training process through providing easily trainable shortcuts. We report new state-of-the-art results for small networks, without the need for additional treatment such as pruning or compression - a consequence of ECN's simple structure and direct training. A 6-layered ECN design with under 500k parameters achieves 95.24% and 78.99% accuracy on CIFAR-10 and CIFAR-100 datasets, respectively, outperforming the current state-of-the-art on small parameter networks, and a 3 million parameter ECN produces results competitive to the state-of-the-art.", "published": "2018-07-02T04:12:16Z", "version": 2}, {"aid": "1807.00737", "authors": ["Rui Zhao", "Volker Tresp"], "title": "Learning Goal-Oriented Visual Dialog via Tempered Policy Gradient", "url": "http://arxiv.org/pdf/1807.00737v5", "summary": "Learning goal-oriented dialogues by means of deep reinforcement learning has recently become a popular research topic. However, commonly used policy-based dialogue agents often end up focusing on simple utterances and suboptimal policies. To mitigate this problem, we propose a class of novel temperature-based extensions for policy gradient methods, which are referred to as Tempered Policy Gradients (TPGs). On a recent AI-testbed, i.e., the GuessWhat?! game, we achieve significant improvements with two innovations. The first one is an extension of the state-of-the-art solutions with Seq2Seq and Memory Network structures that leads to an improvement of 7%. The second one is the application of our newly developed TPG methods, which improves the performance additionally by around 5% and, even more importantly, helps produce more convincing utterances.", "published": "2018-07-02T15:14:43Z", "version": 5}, {"aid": "1807.03215", "authors": ["Fenglei Fan", "Ge Wang"], "title": "Fuzzy Logic Interpretation of Quadratic Networks", "url": "http://arxiv.org/pdf/1807.03215v3", "summary": "Over past several years, deep learning has achieved huge successes in various applications. However, such a data-driven approach is often criticized for lack of interpretability. Recently, we proposed artificial quadratic neural networks consisting of second-order neurons in potentially many layers. In each second-order neuron, a quadratic function is used in the place of the inner product in a traditional neuron, and then undergoes a nonlinear activation. With a single second-order neuron, any fuzzy logic operation, such as XOR, can be implemented. In this sense, any deep network constructed with quadratic neurons can be interpreted as a deep fuzzy logic system. Since traditional neural networks and second-order counterparts can represent each other and fuzzy logic operations are naturally implemented in second-order neural networks, it is plausible to explain how a deep neural network works with a second-order network as the system model. In this paper, we generalize and categorize fuzzy logic operations implementable with individual second-order neurons, and then perform statistical/information theoretic analyses of exemplary quadratic neural networks.", "published": "2018-07-04T12:45:25Z", "version": 3}, {"aid": "1807.01898", "authors": ["Jen-Yu Liu", "Yi-Hsuan Yang"], "title": "Denoising Auto-encoder with Recurrent Skip Connections and Residual Regression for Music Source Separation", "url": "http://arxiv.org/pdf/1807.01898v1", "summary": "Convolutional neural networks with skip connections have shown good performance in music source separation. In this work, we propose a denoising Auto-encoder with Recurrent skip Connections (ARC). We use 1D convolution along the temporal axis of the time-frequency feature map in all layers of the fully-convolutional network. The use of 1D convolution makes it possible to apply recurrent layers to the intermediate outputs of the convolution layers. In addition, we also propose an enhancement network and a residual regression method to further improve the separation result. The recurrent skip connections, the enhancement module, and the residual regression all improve the separation quality. The ARC model with residual regression achieves 5.74 siganl-to-distoration ratio (SDR) in vocals with MUSDB in SiSEC 2018. We also evaluate the ARC model alone on the older dataset DSD100 (used in SiSEC 2016) and it achieves 5.91 SDR in vocals.", "published": "2018-07-05T08:54:32Z", "version": 1}, {"aid": "1807.02155", "authors": ["Guangzhi Tang", "Konstantinos P. Michmizos"], "title": "Gridbot: An autonomous robot controlled by a Spiking Neural Network mimicking the brain's navigational system", "url": "http://arxiv.org/pdf/1807.02155v1", "summary": "It is true that the \"best\" neural network is not necessarily the one with the most \"brain-like\" behavior. Understanding biological intelligence, however, is a fundamental goal for several distinct disciplines. Translating our understanding of intelligence to machines is a fundamental problem in robotics. Propelled by new advancements in Neuroscience, we developed a spiking neural network (SNN) that draws from mounting experimental evidence that a number of individual neurons is associated with spatial navigation. By following the brain's structure, our model assumes no initial all-to-all connectivity, which could inhibit its translation to a neuromorphic hardware, and learns an uncharted territory by mapping its identified components into a limited number of neural representations, through spike-timing dependent plasticity (STDP). In our ongoing effort to employ a bioinspired SNN-controlled robot to real-world spatial mapping applications, we demonstrate here how an SNN may robustly control an autonomous robot in mapping and exploring an unknown environment, while compensating for its own intrinsic hardware imperfections, such as partial or total loss of visual input.", "published": "2018-07-05T19:09:45Z", "version": 1}, {"aid": "1807.03858", "authors": ["Yuping Luo", "Huazhe Xu", "Yuanzhi Li", "Yuandong Tian", "Trevor Darrell", "Tengyu Ma"], "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees", "url": "http://arxiv.org/pdf/1807.03858v5", "summary": "Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However, the theoretical understanding of such methods has been rather limited. This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward. The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires \\textit{no explicit} uncertainty quantification. Instantiating our framework with simplification gives a variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO). Experiments demonstrate that SLBO achieves state-of-the-art performance when only one million or fewer samples are permitted on a range of continuous control benchmark tasks.", "published": "2018-07-10T20:53:04Z", "version": 5}, {"aid": "1807.04001", "authors": ["Benjamin Bruno Meier", "Ismail Elezi", "Mohammadreza Amirian", "Oliver Durr", "Thilo Stadelmann"], "title": "Learning Neural Models for End-to-End Clustering", "url": "http://arxiv.org/pdf/1807.04001v1", "summary": "We propose a novel end-to-end neural network architecture that, once trained, directly outputs a probabilistic clustering of a batch of input examples in one pass. It estimates a distribution over the number of clusters $k$, and for each $1 \\leq k \\leq k_\\mathrm{max}$, a distribution over the individual cluster assignment for each data point. The network is trained in advance in a supervised fashion on separate data to learn grouping by any perceptual similarity criterion based on pairwise labels (same/different group). It can then be applied to different data containing different groups. We demonstrate promising performance on high-dimensional data like images (COIL-100) and speech (TIMIT). We call this ``learning to cluster'' and show its conceptual difference to deep metric learning, semi-supervise clustering and other related approaches while having the advantage of performing learnable clustering fully end-to-end.", "published": "2018-07-11T08:45:45Z", "version": 1}, {"aid": "1807.04050", "authors": ["Roberto Annunziata", "Christos Sagonas", "Jacques Cal\u00ec"], "title": "DeSTNet: Densely Fused Spatial Transformer Networks", "url": "http://arxiv.org/pdf/1807.04050v2", "summary": "Modern Convolutional Neural Networks (CNN) are extremely powerful on a range of computer vision tasks. However, their performance may degrade when the data is characterised by large intra-class variability caused by spatial transformations. The Spatial Transformer Network (STN) is currently the method of choice for providing CNNs the ability to remove those transformations and improve performance in an end-to-end learning framework. In this paper, we propose Densely Fused Spatial Transformer Network (DeSTNet), which, to our best knowledge, is the first dense fusion pattern for combining multiple STNs. Specifically, we show how changing the connectivity pattern of multiple STNs from sequential to dense leads to more powerful alignment modules. Extensive experiments on three benchmarks namely, MNIST, GTSRB, and IDocDB show that the proposed technique outperforms related state-of-the-art methods (i.e., STNs and CSTNs) both in terms of accuracy and robustness.", "published": "2018-07-11T10:06:32Z", "version": 2}, {"aid": "1807.04445", "authors": ["Pengfei Zhang", "Jianru Xue", "Cuiling Lan", "Wenjun Zeng", "Zhanning Gao", "Nanning Zheng"], "title": "Adding Attentiveness to the Neurons in Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1807.04445v1", "summary": "Recurrent neural networks (RNNs) are capable of modeling the temporal dynamics of complex sequential information. However, the structures of existing RNN neurons mainly focus on controlling the contributions of current and historical information but do not explore the different importance levels of different elements in an input vector of a time slot. We propose adding a simple yet effective Element-wiseAttention Gate (EleAttG) to an RNN block (e.g., all RNN neurons in a network layer) that empowers the RNN neurons to have the attentiveness capability. For an RNN block, an EleAttG is added to adaptively modulate the input by assigning different levels of importance, i.e., attention, to each element/dimension of the input. We refer to an RNN block equipped with an EleAttG as an EleAtt-RNN block. Specifically, the modulation of the input is content adaptive and is performed at fine granularity, being element-wise rather than input-wise. The proposed EleAttG, as an additional fundamental unit, is general and can be applied to any RNN structures, e.g., standard RNN, Long Short-Term Memory (LSTM), or Gated Recurrent Unit (GRU). We demonstrate the effectiveness of the proposed EleAtt-RNN by applying it to the action recognition tasks on both 3D human skeleton data and RGB videos. Experiments show that adding attentiveness through EleAttGs to RNN blocks significantly boosts the power of RNNs.", "published": "2018-07-12T06:59:36Z", "version": 1}, {"aid": "1807.05076", "authors": ["Tsendsuren Munkhdalai", "Adam Trischler"], "title": "Metalearning with Hebbian Fast Weights", "url": "http://arxiv.org/pdf/1807.05076v1", "summary": "We unify recent neural approaches to one-shot learning with older ideas of associative memory in a model for metalearning. Our model learns jointly to represent data and to bind class labels to representations in a single shot. It builds representations via slow weights, learned across tasks through SGD, while fast weights constructed by a Hebbian learning rule implement one-shot binding for each new task. On the Omniglot, Mini-ImageNet, and Penn Treebank one-shot learning benchmarks, our model achieves state-of-the-art results.", "published": "2018-07-12T14:40:06Z", "version": 1}, {"aid": "1807.04798", "authors": ["Florian Dubost", "Gerda Bortsova", "Hieab Adams", "M. Arfan Ikram", "Wiro Niessen", "Meike Vernooij", "Marleen de Bruijne"], "title": "Hydranet: Data Augmentation for Regression Neural Networks", "url": "http://arxiv.org/pdf/1807.04798v3", "summary": "Deep learning techniques are often criticized to heavily depend on a large quantity of labeled data. This problem is even more challenging in medical image analysis where the annotator expertise is often scarce. We propose a novel data-augmentation method to regularize neural network regressors that learn from a single global label per image. The principle of the method is to create new samples by recombining existing ones. We demonstrate the performance of our algorithm on two tasks: estimation of the number of enlarged perivascular spaces in the basal ganglia, and estimation of white matter hyperintensities volume. We show that the proposed method improves the performance over more basic data augmentation. The proposed method reached an intraclass correlation coefficient between ground truth and network predictions of 0.73 on the first task and 0.84 on the second task, only using between 25 and 30 scans with a single global label per scan for training. With the same number of training scans, more conventional data augmentation methods could only reach intraclass correlation coefficients of 0.68 on the first task, and 0.79 on the second task.", "published": "2018-07-12T19:30:21Z", "version": 3}, {"aid": "1807.05214", "authors": ["Zhixin Lu", "Danielle S. Bassett"], "title": "Invertible generalized synchronization: A putative mechanism for implicit learning in biological and artificial neural systems", "url": "http://arxiv.org/pdf/1807.05214v2", "summary": "Regardless of the marked differences between biological and artificial neural systems, one fundamental similarity is that they are essentially dynamical systems that can learn to imitate other dynamical systems, without knowing their governing equations. The brain is able to learn the dynamic nature of the physical world via experience; analogously, artificial neural systems can learn the long-term behavior of complex dynamical systems from data. Yet, precisely how this implicit learning occurs remains unknown. Here, we draw inspiration from human neuroscience and from reservoir computing to propose a first-principles framework explicating putative mechanisms of implicit learning. Specifically, we show that an arbitrary dynamical system implicitly learns other dynamical attractors by embedding them into its own phase space through invertible generalized synchronization. By sustaining the embedding through fine-tuned feedback loops, the arbitrary dynamical system can imitate the attractor dynamics it has learned. To evaluate the mechanism's relevance, we construct several distinct neural network models that adaptively learn and imitate multiple attractors. We observe and explain the emergence of 5 distinct phenomena reminiscent of cognitive functions: (i) imitating a dynamical system purely from learning the time series, (ii) learning multiple attractors by a single system, (iii) switching among the imitations of multiple attractors, either spontaneously or driven by external cues, (iv) filling-in missing variables from incomplete observations of a learned dynamical system, and (v) deciphering superimposed input from different dynamical systems. Collectively, our findings support the notion that artificial and biological neural networks can learn the dynamic nature of their environment, and systems within their environment, through the mechanism of invertible generalized synchronization.", "published": "2018-07-13T00:50:52Z", "version": 2}, {"aid": "1807.05196", "authors": ["Lars Kunze", "Nick Hawes", "Tom Duckett", "Marc Hanheide", "Tom\u00e1\u0161 Krajn\u00edk"], "title": "Artificial Intelligence for Long-Term Robot Autonomy: A Survey", "url": "http://arxiv.org/pdf/1807.05196v1", "summary": "Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e. weeks, months, or years) poses many challenges. Some of these have been investigated by sub-disciplines of Artificial Intelligence (AI) including navigation & mapping, perception, knowledge representation & reasoning, planning, interaction, and learning. The different sub-disciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this paper, we survey and discuss AI techniques as 'enablers' for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.", "published": "2018-07-13T17:32:32Z", "version": 1}, {"aid": "1807.05511", "authors": ["Zhong-Qiu Zhao", "Peng Zheng", "Shou-tao Xu", "Xindong Wu"], "title": "Object Detection with Deep Learning: A Review", "url": "http://arxiv.org/pdf/1807.05511v2", "summary": "Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.", "published": "2018-07-15T08:16:03Z", "version": 2}, {"aid": "1807.05520", "authors": ["Mathilde Caron", "Piotr Bojanowski", "Armand Joulin", "Matthijs Douze"], "title": "Deep Clustering for Unsupervised Learning of Visual Features", "url": "http://arxiv.org/pdf/1807.05520v2", "summary": "Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, k-means, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a significant margin on all the standard benchmarks.", "published": "2018-07-15T09:41:39Z", "version": 2}, {"aid": "1807.06521", "authors": ["Sanghyun Woo", "Jongchan Park", "Joon-Young Lee", "In So Kweon"], "title": "CBAM: Convolutional Block Attention Module", "url": "http://arxiv.org/pdf/1807.06521v2", "summary": "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available.", "published": "2018-07-17T16:05:59Z", "version": 2}, {"aid": "1807.06613", "authors": ["Maximilian H\u00fcttenrauch", "Adrian \u0160o\u0161i\u0107", "Gerhard Neumann"], "title": "Deep Reinforcement Learning for Swarm Systems", "url": "http://arxiv.org/pdf/1807.06613v3", "summary": "Recently, deep reinforcement learning (RL) methods have been applied successfully to multi-agent scenarios. Typically, these methods rely on a concatenation of agent states to represent the information content required for decentralized decision making. However, concatenation scales poorly to swarm systems with a large number of homogeneous agents as it does not exploit the fundamental properties inherent to these systems: (i) the agents in the swarm are interchangeable and (ii) the exact number of agents in the swarm is irrelevant. Therefore, we propose a new state representation for deep multi-agent RL based on mean embeddings of distributions. We treat the agents as samples of a distribution and use the empirical mean embedding as input for a decentralized policy. We define different feature spaces of the mean embedding using histograms, radial basis functions and a neural network learned end-to-end. We evaluate the representation on two well known problems from the swarm literature (rendezvous and pursuit evasion), in a globally and locally observable setup. For the local setup we furthermore introduce simple communication protocols. Of all approaches, the mean embedding representation using neural network features enables the richest information exchange between neighboring agents facilitating the development of more complex collective strategies.", "published": "2018-07-17T18:27:03Z", "version": 3}, {"aid": "1807.06699", "authors": ["Ryutaro Tanno", "Kai Arulkumaran", "Daniel C. Alexander", "Antonio Criminisi", "Aditya Nori"], "title": "Adaptive Neural Trees", "url": "http://arxiv.org/pdf/1807.06699v5", "summary": "Deep neural networks and decision trees operate on largely separate paradigms; typically, the former performs representation learning with pre-specified architectures, while the latter is characterised by learning hierarchies over pre-specified features with data-driven architectures. We unite the two via adaptive neural trees (ANTs) that incorporates representation learning into edges, routing functions and leaf nodes of a decision tree, along with a backpropagation-based training algorithm that adaptively grows the architecture from primitive modules (e.g., convolutional layers). We demonstrate that, whilst achieving competitive performance on classification and regression datasets, ANTs benefit from (i) lightweight inference via conditional computation, (ii) hierarchical separation of features useful to the task e.g. learning meaningful class associations, such as separating natural vs. man-made objects, and (iii) a mechanism to adapt the architecture to the size and complexity of the training dataset.", "published": "2018-07-17T23:01:35Z", "version": 5}, {"aid": "1807.07281", "authors": ["Wei Ping", "Kainan Peng", "Jitong Chen"], "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech", "url": "http://arxiv.org/pdf/1807.07281v3", "summary": "In this work, we propose a new solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we introduce the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet (Ping et al., 2018). We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model.", "published": "2018-07-19T08:15:41Z", "version": 3}, {"aid": "1807.07320", "authors": ["Pau Rodr\u00edguez", "Josep M. Gonfaus", "Guillem Cucurull", "F. Xavier Roca", "Jordi Gonz\u00e0lez"], "title": "Attend and Rectify: a Gated Attention Mechanism for Fine-Grained Recovery", "url": "http://arxiv.org/pdf/1807.07320v2", "summary": "We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. It learns to attend to lower-level feature activations without requiring part annotations and uses these activations to update and rectify the output likelihood distribution. In contrast to other approaches, the proposed mechanism is modular, architecture-independent and efficient both in terms of parameters and computation required. Experiments show that networks augmented with our approach systematically improve their classification accuracy and become more robust to clutter. As a result, Wide Residual Networks augmented with our proposal surpasses the state of the art classification accuracies in CIFAR-10, the Adience gender recognition task, Stanford dogs, and UEC Food-100.", "published": "2018-07-19T09:52:36Z", "version": 2}, {"aid": "1807.10583", "authors": ["Bishesh Khanal", "Alberto Gomez", "Nicolas Toussaint", "Steven McDonagh", "Veronika Zimmer", "Emily Skelton", "Jacqueline Matthew", "Daniel Grzech", "Robert Wright", "Chandni Gupta", "Benjamin Hou", "Daniel Rueckert", "Julia A. Schnabel", "Bernhard Kainz"], "title": "EchoFusion: Tracking and Reconstruction of Objects in 4D Freehand Ultrasound Imaging without External Trackers", "url": "http://arxiv.org/pdf/1807.10583v1", "summary": "Ultrasound (US) is the most widely used fetal imaging technique. However, US images have limited capture range, and suffer from view dependent artefacts such as acoustic shadows. Compounding of overlapping 3D US acquisitions into a high-resolution volume can extend the field of view and remove image artefacts, which is useful for retrospective analysis including population based studies. However, such volume reconstructions require information about relative transformations between probe positions from which the individual volumes were acquired. In prenatal US scans, the fetus can move independently from the mother, making external trackers such as electromagnetic or optical tracking unable to track the motion between probe position and the moving fetus. We provide a novel methodology for image-based tracking and volume reconstruction by combining recent advances in deep learning and simultaneous localisation and mapping (SLAM). Tracking semantics are established through the use of a Residual 3D U-Net and the output is fed to the SLAM algorithm. As a proof of concept, experiments are conducted on US volumes taken from a whole body fetal phantom, and from the heads of real fetuses. For the fetal head segmentation, we also introduce a novel weak annotation approach to minimise the required manual effort for ground truth annotation. We evaluate our method qualitatively, and quantitatively with respect to tissue discrimination accuracy and tracking robustness.", "published": "2018-07-19T12:07:50Z", "version": 1}, {"aid": "1807.07559", "authors": ["Amelia Jim\u00e9nez-S\u00e1nchez", "Shadi Albarqouni", "Diana Mateus"], "title": "Capsule Networks against Medical Imaging Data Challenges", "url": "http://arxiv.org/pdf/1807.07559v1", "summary": "A key component to the success of deep learning is the availability of massive amounts of training data. Building and annotating large datasets for solving medical image classification problems is today a bottleneck for many applications. Recently, capsule networks were proposed to deal with shortcomings of Convolutional Neural Networks (ConvNets). In this work, we compare the behavior of capsule networks against ConvNets under typical datasets constraints of medical image analysis, namely, small amounts of annotated data and class-imbalance. We evaluate our experiments on MNIST, Fashion-MNIST and medical (histological and retina images) publicly available datasets. Our results suggest that capsule networks can be trained with less amount of data for the same or better performance and are more robust to an imbalanced class distribution, which makes our approach very promising for the medical imaging community.", "published": "2018-07-19T17:56:37Z", "version": 1}, {"aid": "1807.07984", "authors": ["John Boaz Lee", "Ryan A. Rossi", "Sungchul Kim", "Nesreen K. Ahmed", "Eunyee Koh"], "title": "Attention Models in Graphs: A Survey", "url": "http://arxiv.org/pdf/1807.07984v1", "summary": "Graph-structured data arise naturally in many different application domains. By representing data as graphs, we can capture entities (i.e., nodes) as well as their relationships (i.e., edges) with each other. Many useful insights can be derived from graph-structured data as demonstrated by an ever-growing body of work focused on graph mining. However, in the real-world, graphs can be both large - with many complex patterns - and noisy which can pose a problem for effective graph mining. An effective way to deal with this issue is to incorporate \"attention\" into graph mining solutions. An attention mechanism allows a method to focus on task-relevant parts of the graph, helping it to make better decisions. In this work, we conduct a comprehensive and focused survey of the literature on the emerging field of graph attention models. We introduce three intuitive taxonomies to group existing work. These are based on problem setting (type of input and output), the type of attention mechanism used, and the task (e.g., graph classification, link prediction, etc.). We motivate our taxonomies through detailed examples and use each to survey competing approaches from a unique standpoint. Finally, we highlight several challenges in the area and discuss promising directions for future work.", "published": "2018-07-20T18:11:07Z", "version": 1}, {"aid": "1807.08018", "authors": ["Houman Safaai", "Arno Onken", "Christopher D. Harvey", "Stefano Panzeri"], "title": "Information estimation using nonparametric copulas", "url": "http://arxiv.org/pdf/1807.08018v2", "summary": "Estimation of mutual information between random variables has become crucial in a range of fields, from physics to neuroscience to finance. Estimating information accurately over a wide range of conditions relies on the development of flexible methods to describe statistical dependencies among variables, without imposing potentially invalid assumptions on the data. Such methods are needed in cases that lack prior knowledge of their statistical properties and that have limited sample numbers. Here we propose a powerful and generally applicable information estimator based on non-parametric copulas. This estimator, called the non-parametric copula-based estimator (NPC), is tailored to take into account detailed stochastic relationships in the data independently of the data's marginal distributions. The NPC estimator can be used both for continuous and discrete numerical variables and thus provides a single framework for the mutual information estimation of both continuous and discrete data. By extensive validation on artificial samples drawn from various statistical distributions, we found that the NPC estimator compares well against commonly used alternatives. Unlike methods not based on copulas, it allows an estimation of information that is robust to changes of the details of the marginal distributions. Unlike parametric copula methods, it remains accurate regardless of the precise form of the interactions between the variables. In addition, the NPC estimator had accurate information estimates even at low sample numbers, in comparison to alternative estimators. The NPC estimator therefore provides a good balance between general applicability to arbitrarily shaped statistical dependencies in the data and shows accurate and robust performance when working with small sample sizes.", "published": "2018-07-20T20:17:59Z", "version": 2}, {"aid": "1807.08169", "authors": ["Matiur Rahman Minar", "Jibon Naher"], "title": "Recent Advances in Deep Learning: An Overview", "url": "http://arxiv.org/pdf/1807.08169v1", "summary": "Deep Learning is one of the newest trends in Machine Learning and Artificial Intelligence research. It is also one of the most popular scientific research trends now-a-days. Deep learning methods have brought revolutionary advances in computer vision and machine learning. Every now and then, new and new deep learning techniques are being born, outperforming state-of-the-art machine learning and even existing deep learning techniques. In recent years, the world has seen many major breakthroughs in this field. Since deep learning is evolving at a huge speed, its kind of hard to keep track of the regular advances especially for new researchers. In this paper, we are going to briefly discuss about recent advances in Deep Learning for past few years.", "published": "2018-07-21T15:40:10Z", "version": 1}, {"aid": "1807.08291", "authors": ["Novanto Yudistira", "Takio Kurita"], "title": "Correlation Net: Spatiotemporal multimodal deep learning for action recognition", "url": "http://arxiv.org/pdf/1807.08291v6", "summary": "This paper describes a network that captures multimodal correlations over arbitrary timestamps. The proposed scheme operates as a complementary, extended network over a multimodal convolutional neural network (CNN). Spatial and temporal streams are required for action recognition by a deep CNN, but overfitting reduction and fusing these two streams remain open problems. The existing fusion approach averages the two streams. Here we propose a correlation network with a Shannon fusion for learning a pre-trained CNN. A Long-range video may consist of spatiotemporal correlations over arbitrary times, which can be captured by forming the correlation network from simple fully connected layers. This approach was found to complement the existing network fusion methods. The importance of multimodal correlation is validated in comparison experiments on the UCF-101 and HMDB-51 datasets. The multimodal correlation enhanced the accuracy of the video recognition results.", "published": "2018-07-22T14:48:32Z", "version": 6}, {"aid": "1807.10641", "authors": ["Chuanqi Tan", "Fuchun Sun", "Wenchang Zhang", "Jianhua Chen", "Chunfang Liu"], "title": "Multimodal Classification with Deep Convolutional-Recurrent Neural Networks for Electroencephalography", "url": "http://arxiv.org/pdf/1807.10641v1", "summary": "Electroencephalography (EEG) has become the most significant input signal for brain computer interface (BCI) based systems. However, it is very difficult to obtain satisfactory classification accuracy due to traditional methods can not fully exploit multimodal information. Herein, we propose a novel approach to modeling cognitive events from EEG data by reducing it to a video classification problem, which is designed to preserve the multimodal information of EEG. In addition, optical flow is introduced to represent the variant information of EEG. We train a deep neural network (DNN) with convolutional neural network (CNN) and recurrent neural network (RNN) for the EEG classification task by using EEG video and optical flow. The experiments demonstrate that our approach has many advantages, such as more robustness and more accuracy in EEG classification tasks. According to our approach, we designed a mixed BCI-based rehabilitation support system to help stroke patients perform some basic operations.", "published": "2018-07-24T03:33:43Z", "version": 1}, {"aid": "1807.09511", "authors": ["Xiaoran Xu", "Songpeng Zu", "Yuan Zhang", "Hanning Zhou", "Wei Feng"], "title": "Backprop-Q: Generalized Backpropagation for Stochastic Computation Graphs", "url": "http://arxiv.org/pdf/1807.09511v2", "summary": "In real-world scenarios, it is appealing to learn a model carrying out stochastic operations internally, known as stochastic computation graphs (SCGs), rather than learning a deterministic mapping. However, standard backpropagation is not applicable to SCGs. We attempt to address this issue from the angle of cost propagation, with local surrogate costs, called Q-functions, constructed and learned for each stochastic node in an SCG. Then, the SCG can be trained based on these surrogate costs using standard backpropagation. We propose the entire framework as a solution to generalize backpropagation for SCGs, which resembles an actor-critic architecture but based on a graph. For broad applicability, we study a variety of SCG structures from one cost to multiple costs. We utilize recent advances in reinforcement learning (RL) and variational Bayes (VB), such as off-policy critic learning and unbiased-and-low-variance gradient estimation, and review them in the context of SCGs. The generalized backpropagation extends transported learning signals beyond gradients between stochastic nodes while preserving the benefit of backpropagating gradients through deterministic nodes. Experimental suggestions and concerns are listed to help design and test any specific model using this framework.", "published": "2018-07-25T10:06:24Z", "version": 2}, {"aid": "1807.09536", "authors": ["Francisco M. Castro", "Manuel J. Mar\u00edn-Jim\u00e9nez", "Nicol\u00e1s Guil", "Cordelia Schmid", "Karteek Alahari"], "title": "End-to-End Incremental Learning", "url": "http://arxiv.org/pdf/1807.09536v2", "summary": "Although deep learning approaches have stood out in recent years due to their state-of-the-art results, they continue to suffer from catastrophic forgetting, a dramatic decrease in overall performance when training with new classes added incrementally. This is due to current neural network architectures requiring the entire dataset, consisting of all the samples from the old as well as the new classes, to update the model -a requirement that becomes easily unsustainable as the number of classes grows. We address this issue with our approach to learn deep neural networks incrementally, using new data and only a small exemplar set corresponding to samples from the old classes. This is based on a loss composed of a distillation measure to retain the knowledge acquired from the old classes, and a cross-entropy loss to learn the new classes. Our incremental training is achieved while keeping the entire framework end-to-end, i.e., learning the data representation and the classifier jointly, unlike recent methods with no such guarantees. We evaluate our method extensively on the CIFAR-100 and ImageNet (ILSVRC 2012) image classification datasets, and show state-of-the-art performance.", "published": "2018-07-25T11:38:25Z", "version": 2}, {"aid": "1807.10117", "authors": ["G. Zhang", "H. Li"], "title": "Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)", "url": "http://arxiv.org/pdf/1807.10117v2", "summary": "Recently, self-normalizing neural networks (SNNs) have been proposed with the intention to avoid batch or weight normalization. The key step in SNNs is to properly scale the exponential linear unit (referred to as SELU) to inherently incorporate normalization based on central limit theory. SELU is a monotonically increasing function, where it has an approximately constant negative output for large negative input. In this work, we propose a new activation function to break the monotonicity property of SELU while still preserving the self-normalizing property. Differently from SELU, the new function introduces a bump-shaped function in the region of negative input by regularizing a linear function with a scaled exponential function, which is referred to as a scaled exponentially-regularized linear unit (SERLU). The bump-shaped function has approximately zero response to large negative input while being able to push the output of SERLU towards zero mean statistically. To effectively combat over-fitting, we develop a so-called shift-dropout for SERLU, which includes standard dropout as a special case. Experimental results on MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provide consistently promising results in comparison to other 5 activation functions including ELU, SELU, Swish, Leakly ReLU and ReLU.", "published": "2018-07-26T13:33:49Z", "version": 2}, {"aid": "1807.10119", "authors": ["Yuzhe Ma", "Ran Chen", "Wei Li", "Fanhua Shang", "Wenjian Yu", "Minsik Cho", "Bei Yu"], "title": "A Unified Approximation Framework for Compressing and Accelerating Deep Neural Networks", "url": "http://arxiv.org/pdf/1807.10119v3", "summary": "Deep neural networks (DNNs) have achieved significant success in a variety of real world applications, i.e., image classification. However, tons of parameters in the networks restrict the efficiency of neural networks due to the large model size and the intensive computation. To address this issue, various approximation techniques have been investigated, which seek for a light weighted network with little performance degradation in exchange of smaller model size or faster inference. Both low-rankness and sparsity are appealing properties for the network approximation. In this paper we propose a unified framework to compress the convolutional neural networks (CNNs) by combining these two properties, while taking the nonlinear activation into consideration. Each layer in the network is approximated by the sum of a structured sparse component and a low-rank component, which is formulated as an optimization problem. Then, an extended version of alternating direction method of multipliers (ADMM) with guaranteed convergence is presented to solve the relaxed optimization problem. Experiments are carried out on VGG-16, AlexNet and GoogLeNet with large image classification datasets. The results outperform previous work in terms of accuracy degradation, compression rate and speedup ratio. The proposed method is able to remarkably compress the model (with up to 4.9x reduction of parameters) at a cost of little loss or without loss on accuracy.", "published": "2018-07-26T13:36:19Z", "version": 3}, {"aid": "1807.10267", "authors": ["Anurag Ranjan", "Timo Bolkart", "Soubhik Sanyal", "Michael J. Black"], "title": "Generating 3D faces using Convolutional Mesh Autoencoders", "url": "http://arxiv.org/pdf/1807.10267v3", "summary": "Learned 3D representations of human faces are useful for computer vision problems such as 3D face tracking and reconstruction from images, as well as graphics applications such as character generation and animation. Traditional models learn a latent representation of a face using linear subspaces or higher-order tensor generalizations. Due to this linearity, they can not capture extreme deformations and non-linear expressions. To address this, we introduce a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. We introduce mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model. In a variational setting, our model samples diverse realistic 3D faces from a multivariate Gaussian distribution. Our training data consists of 20,466 meshes of extreme expressions captured over 12 different subjects. Despite limited training data, our trained model outperforms state-of-the-art face models with 50% lower reconstruction error, while using 75% fewer parameters. We also show that, replacing the expression space of an existing state-of-the-art face model with our autoencoder, achieves a lower reconstruction error. Our data, model and code are available at http://github.com/anuragranj/coma", "published": "2018-07-26T17:53:50Z", "version": 3}, {"aid": "1807.10726", "authors": ["Bowen Zhang", "Xifan Zhang", "Fan Cheng", "Deli Zhao"], "title": "Few Shot Learning with Simplex", "url": "http://arxiv.org/pdf/1807.10726v2", "summary": "Deep learning has made remarkable achievement in many fields. However, learning the parameters of neural networks usually demands a large amount of labeled data. The algorithms of deep learning, therefore, encounter difficulties when applied to supervised learning where only little data are available. This specific task is called few-shot learning. To address it, we propose a novel algorithm for few-shot learning using discrete geometry, in the sense that the samples in a class are modeled as a reduced simplex. The volume of the simplex is used for the measurement of class scatter. During testing, combined with the test sample and the points in the class, a new simplex is formed. Then the similarity between the test sample and the class can be quantized with the ratio of volumes of the new simplex to the original class simplex. Moreover, we present an approach to constructing simplices using local regions of feature maps yielded by convolutional neural networks. Experiments on Omniglot and miniImageNet verify the effectiveness of our simplex algorithm on few-shot learning.", "published": "2018-07-27T16:52:57Z", "version": 2}, {"aid": "1808.00158", "authors": ["Mirco Ravanelli", "Yoshua Bengio"], "title": "Speaker Recognition from Raw Waveform with SincNet", "url": "http://arxiv.org/pdf/1808.00158v3", "summary": "Deep learning is progressively gaining popularity as a viable alternative to i-vectors for speaker recognition. Promising results have been recently obtained with Convolutional Neural Networks (CNNs) when fed by raw speech samples directly. Rather than employing standard hand-crafted features, the latter CNNs learn low-level speech representations from waveforms, potentially allowing the network to better capture important narrow-band speaker characteristics such as pitch and formants. Proper design of the neural network is crucial to achieve this goal. This paper proposes a novel CNN architecture, called SincNet, that encourages the first convolutional layer to discover more meaningful filters. SincNet is based on parametrized sinc functions, which implement band-pass filters. In contrast to standard CNNs, that learn all elements of each filter, only low and high cutoff frequencies are directly learned from data with the proposed method. This offers a very compact and efficient way to derive a customized filter bank specifically tuned for the desired application. Our experiments, conducted on both speaker identification and speaker verification tasks, show that the proposed architecture converges faster and performs better than a standard CNN on raw waveforms.", "published": "2018-07-29T16:27:19Z", "version": 3}, {"aid": "1807.11091", "authors": ["Tianyun Zhang", "Shaokai Ye", "Kaiqi Zhang", "Xiaolong Ma", "Ning Liu", "Linfeng Zhang", "Jian Tang", "Kaisheng Ma", "Xue Lin", "Makan Fardad", "Yanzhi Wang"], "title": "StructADMM: A Systematic, High-Efficiency Framework of Structured Weight Pruning for DNNs", "url": "http://arxiv.org/pdf/1807.11091v3", "summary": "Weight pruning methods of DNNs have been demonstrated to achieve a good model pruning rate without loss of accuracy, thereby alleviating the significant computation/storage requirements of large-scale DNNs. Structured weight pruning methods have been proposed to overcome the limitation of irregular network structure and demonstrated actual GPU acceleration. However, in prior work the pruning rate (degree of sparsity) and GPU acceleration are limited (to less than 50%) when accuracy needs to be maintained. In this work,we overcome these limitations by proposing a unified, systematic framework of structured weight pruning for DNNs. It is a framework that can be used to induce different types of structured sparsity, such as filter-wise, channel-wise, and shape-wise sparsity, as well non-structured sparsity. The proposed framework incorporates stochastic gradient descent with ADMM, and can be understood as a dynamic regularization method in which the regularization target is analytically updated in each iteration. Without loss of accuracy on the AlexNet model, we achieve 2.58X and 3.65X average measured speedup on two GPUs, clearly outperforming the prior work. The average speedups reach 3.15X and 8.52X when allowing a moderate ac-curacy loss of 2%. In this case the model compression for convolutional layers is 15.0X, corresponding to 11.93X measured CPU speedup. Our experiments on ResNet model and on other data sets like UCF101 and CIFAR-10 demonstrate the consistently higher performance of our framework.", "published": "2018-07-29T18:07:04Z", "version": 3}, {"aid": "1807.11112", "authors": ["Huy Tu", "Vivek Nair"], "title": "Is One Hyperparameter Optimizer Enough?", "url": "http://arxiv.org/pdf/1807.11112v4", "summary": "Hyperparameter tuning is the black art of automatically finding a good combination of control parameters for a data miner. While widely applied in empirical Software Engineering, there has not been much discussion on which hyperparameter tuner is best for software analytics. To address this gap in the literature, this paper applied a range of hyperparameter optimizers (grid search, random search, differential evolution, and Bayesian optimization) to defect prediction problem. Surprisingly, no hyperparameter optimizer was observed to be `best' and, for one of the two evaluation measures studied here (F-measure), hyperparameter optimization, in 50\\% cases, was no better than using default configurations.   We conclude that hyperparameter optimization is more nuanced than previously believed. While such optimization can certainly lead to large improvements in the performance of classifiers used in software analytics, it remains to be seen which specific optimizers should be applied to a new dataset.", "published": "2018-07-29T21:26:12Z", "version": 4}, {"aid": "1807.11929", "authors": ["Mengmi Zhang", "Keng Teck Ma", "Shih-Cheng Yen", "Joo Hwee Lim", "Qi Zhao", "Jiashi Feng"], "title": "Egocentric Spatial Memory", "url": "http://arxiv.org/pdf/1807.11929v1", "summary": "Egocentric spatial memory (ESM) defines a memory system with encoding, storing, recognizing and recalling the spatial information about the environment from an egocentric perspective. We introduce an integrated deep neural network architecture for modeling ESM. It learns to estimate the occupancy state of the world and progressively construct top-down 2D global maps from egocentric views in a spatially extended environment. During the exploration, our proposed ESM model updates belief of the global map based on local observations using a recurrent neural network. It also augments the local mapping with a novel external memory to encode and store latent representations of the visited places over long-term exploration in large environments which enables agents to perform place recognition and hence, loop closure. Our proposed ESM network contributes in the following aspects: (1) without feature engineering, our model predicts free space based on egocentric views efficiently in an end-to-end manner; (2) different from other deep learning-based mapping system, ESMN deals with continuous actions and states which is vitally important for robotic control in real applications. In the experiments, we demonstrate its accurate and robust global mapping capacities in 3D virtual mazes and realistic indoor environments by comparing with several competitive baselines.", "published": "2018-07-31T17:27:19Z", "version": 1}, {"aid": "1808.00033", "authors": ["Mengnan Du", "Ninghao Liu", "Xia Hu"], "title": "Techniques for Interpretable Machine Learning", "url": "http://arxiv.org/pdf/1808.00033v3", "summary": "Interpretable machine learning tackles the important problem that humans cannot understand the behaviors of complex machine learning models and how these models arrive at a particular decision. Although many approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. We provide a survey covering existing techniques to increase the interpretability of machine learning models. We also discuss crucial issues that the community should consider in future work such as designing user-friendly explanations and developing comprehensive evaluation metrics to further push forward the area of interpretable machine learning.", "published": "2018-07-31T19:14:39Z", "version": 3}, {"aid": "1808.00193", "authors": ["Yukang Chen", "Gaofeng Meng", "Qian Zhang", "Shiming Xiang", "Chang Huang", "Lisen Mu", "Xinggang Wang"], "title": "Reinforced Evolutionary Neural Architecture Search", "url": "http://arxiv.org/pdf/1808.00193v3", "summary": "Neural Architecture Search (NAS) is an important yet challenging task in network design due to its high computational consumption. To address this issue, we propose the Reinforced Evolutionary Neural Architecture Search (RE- NAS), which is an evolutionary method with the reinforced mutation for NAS. Our method integrates reinforced mutation into an evolution algorithm for neural architecture exploration, in which a mutation controller is introduced to learn the effects of slight modifications and make mutation actions. The reinforced mutation controller guides the model population to evolve efficiently. Furthermore, as child models can inherit parameters from their parents during evolution, our method requires very limited computational resources. In experiments, we conduct the proposed search method on CIFAR-10 and obtain a powerful network architecture, RENASNet. This architecture achieves a competitive result on CIFAR-10. The explored network architecture is transferable to ImageNet and achieves a new state-of-the-art accuracy, i.e., 75.7% top-1 accuracy with 5.36M parameters on mobile ImageNet. We further test its performance on semantic segmentation with DeepLabv3 on the PASCAL VOC. RENASNet outperforms MobileNet-v1, MobileNet-v2 and NASNet. It achieves 75.83% mIOU without being pre-trained on COCO.", "published": "2018-08-01T06:53:53Z", "version": 3}, {"aid": "1808.00679", "authors": ["Irina Dolzhikova", "Khaled Salama", "Vipin Kizheppatt", "Alex Pappachen James"], "title": "Memristor-based Synaptic Sampling Machines", "url": "http://arxiv.org/pdf/1808.00679v1", "summary": "Synaptic Sampling Machine (SSM) is a type of neural network model that considers biological unreliability of the synapses. We propose the circuit design of the SSM neural network which is realized through the memristive-CMOS crossbar structure with the synaptic sampling cell (SSC) being used as a basic stochastic unit. The increase in the edge computing devices in the Internet of things era, drives the need for hardware acceleration for data processing and computing. The computational considerations of the processing speed and possibility for the real-time realization pushes the synaptic sampling algorithm that demonstrated promising results on software for hardware implementation.", "published": "2018-08-02T06:05:07Z", "version": 1}, {"aid": "1808.01174", "authors": ["Daniel Jakubovitz", "Raja Giryes", "Miguel R. D. Rodrigues"], "title": "Generalization Error in Deep Learning", "url": "http://arxiv.org/pdf/1808.01174v3", "summary": "Deep learning models have lately shown great performance in various fields such as computer vision, speech recognition, speech translation, and natural language processing. However, alongside their state-of-the-art performance, it is still generally unclear what is the source of their generalization ability. Thus, an important question is what makes deep neural networks able to generalize well from the training set to new data. In this article, we provide an overview of the existing theory and bounds for the characterization of the generalization error of deep neural networks, combining both classical and more recent theoretical and empirical results.", "published": "2018-08-03T12:57:12Z", "version": 3}, {"aid": "1808.01462", "authors": ["Eman Ahmed", "Alexandre Saint", "Abd El Rahman Shabayek", "Kseniya Cherenkova", "Rig Das", "Gleb Gusev", "Djamila Aouada", "Bjorn Ottersten"], "title": "A survey on Deep Learning Advances on Different 3D Data Representations", "url": "http://arxiv.org/pdf/1808.01462v2", "summary": "3D data is a valuable asset the computer vision filed as it provides rich information about the full geometry of sensed objects and scenes. Recently, with the availability of both large 3D datasets and computational power, it is today possible to consider applying deep learning to learn specific tasks on 3D data such as segmentation, recognition and correspondence. Depending on the considered 3D data representation, different challenges may be foreseen in using existent deep learning architectures. In this work, we provide a comprehensive overview about various 3D data representations highlighting the difference between Euclidean and non-Euclidean ones. We also discuss how Deep Learning methods are applied on each representation, analyzing the challenges to overcome.", "published": "2018-08-04T10:18:55Z", "version": 2}, {"aid": "1808.01556", "authors": ["Rongtian Ye", "Fangyu Liu", "Liqiang Zhang"], "title": "3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks", "url": "http://arxiv.org/pdf/1808.01556v1", "summary": "Standard 3D convolution operations require much larger amounts of memory and computation cost than 2D convolution operations. The fact has hindered the development of deep neural nets in many 3D vision tasks. In this paper, we investigate the possibility of applying depthwise separable convolutions in 3D scenario and introduce the use of 3D depthwise convolution. A 3D depthwise convolution splits a single standard 3D convolution into two separate steps, which would drastically reduce the number of parameters in 3D convolutions with more than one order of magnitude. We experiment with 3D depthwise convolution on popular CNN architectures and also compare it with a similar structure called pseudo-3D convolution. The results demonstrate that, with 3D depthwise convolutions, 3D vision tasks like classification and reconstruction can be carried out with more light-weighted neural networks while still delivering comparable performances.", "published": "2018-08-05T03:50:54Z", "version": 1}, {"aid": "1808.07004", "authors": ["J Gerard Wolff"], "title": "Mathematics as information compression via the matching and unification of patterns", "url": "http://arxiv.org/pdf/1808.07004v2", "summary": "This paper describes a novel perspective on the foundations of mathematics: how mathematics may be seen to be largely about 'information compression via the matching and unification of patterns' (ICMUP). ICMUP is itself a novel approach to information compression, couched in terms of non-mathematical primitives, as is necessary in any investigation of the foundations of mathematics. This new perspective on the foundations of mathematics has grown out of an extensive programme of research developing the \"SP Theory of Intelligence\" and its realisation in the \"SP Computer Model\", a system in which a generalised version of ICMUP -- the powerful concept of SP-multiple-alignment -- plays a central role. These ideas may be seen to be part of a \"Big Picture\" comprising six areas of interest, with information compression as a unifying theme. The paper describes the close relation between mathematics and information compression, and describes examples showing how variants of ICMUP may be seen in widely-used structures and operations in mathematics. Examples are also given to show how the mathematics-related disciplines of logic and computing may be understood as ICMUP. There are many potential benefits and applications of these ideas.", "published": "2018-08-05T09:17:06Z", "version": 2}, {"aid": "1808.01721", "authors": ["Bin Chen", "Wei Guo", "Bin Li", "Rober K. F. Teng", "Mingjun Dai", "Jianping Luo", "Hui Wang"], "title": "A Study of Deep Feature Fusion based Methods for Classifying Multi-lead ECG", "url": "http://arxiv.org/pdf/1808.01721v1", "summary": "An automatic classification method has been studied to effectively detect and recognize Electrocardiogram (ECG). Based on the synchronizing and orthogonal relationships of multiple leads, we propose a Multi-branch Convolution and Residual Network (MBCRNet) with three kinds of feature fusion methods for automatic detection of normal and abnormal ECG signals. Experiments are conducted on the Chinese Cardiovascular Disease Database (CCDD). Through 10-fold cross-validation, we achieve an average accuracy of 87.04% and a sensitivity of 89.93%, which outperforms previous methods under the same database. It is also shown that the multi-lead feature fusion network can improve the classification accuracy over the network only with the single lead features.", "published": "2018-08-06T03:23:53Z", "version": 1}, {"aid": "1808.01752", "authors": ["Chuanqi Tan", "Fuchun Sun", "Wenchang Zhang"], "title": "Deep Transfer Learning for EEG-based Brain Computer Interface", "url": "http://arxiv.org/pdf/1808.01752v1", "summary": "The electroencephalography classifier is the most important component of brain-computer interface based systems. There are two major problems hindering the improvement of it. First, traditional methods do not fully exploit multimodal information. Second, large-scale annotated EEG datasets are almost impossible to acquire because biological data acquisition is challenging and quality annotation is costly. Herein, we propose a novel deep transfer learning approach to solve these two problems. First, we model cognitive events based on EEG data by characterizing the data using EEG optical flow, which is designed to preserve multimodal EEG information in a uniform representation. Second, we design a deep transfer learning framework which is suitable for transferring knowledge by joint training, which contains a adversarial network and a special loss function. The experiments demonstrate that our approach, when applied to EEG classification tasks, has many advantages, such as robustness and accuracy.", "published": "2018-08-06T07:23:34Z", "version": 1}, {"aid": "1808.01834", "authors": ["Lingni Ma", "J\u00f6rg St\u00fcckler", "Tao Wu", "Daniel Cremers"], "title": "Detailed Dense Inference with Convolutional Neural Networks via Discrete Wavelet Transform", "url": "http://arxiv.org/pdf/1808.01834v1", "summary": "Dense pixelwise prediction such as semantic segmentation is an up-to-date challenge for deep convolutional neural networks (CNNs). Many state-of-the-art approaches either tackle the loss of high-resolution information due to pooling in the encoder stage, or use dilated convolutions or high-resolution lanes to maintain detailed feature maps and predictions. Motivated by the structural analogy between multi-resolution wavelet analysis and the pooling/unpooling layers of CNNs, we introduce discrete wavelet transform (DWT) into the CNN encoder-decoder architecture and propose WCNN. The high-frequency wavelet coefficients are computed at encoder, which are later used at the decoder to unpooled jointly with coarse-resolution feature maps through the inverse DWT. The DWT/iDWT is further used to develop two wavelet pyramids to capture the global context, where the multi-resolution DWT is applied to successively reduce the spatial resolution and increase the receptive field. Experiment with the Cityscape dataset, the proposed WCNNs are computationally efficient and yield improvements the accuracy for high-resolution dense pixelwise prediction.", "published": "2018-08-06T11:57:15Z", "version": 1}, {"aid": "1808.02350", "authors": ["Waleed Ali", "Sherif Abdelkarim", "Mohamed Zahran", "Mahmoud Zidan", "Ahmad El Sallab"], "title": "YOLO3D: End-to-end real-time 3D Oriented Object Bounding Box Detection from LiDAR Point Cloud", "url": "http://arxiv.org/pdf/1808.02350v1", "summary": "Object detection and classification in 3D is a key task in Automated Driving (AD). LiDAR sensors are employed to provide the 3D point cloud reconstruction of the surrounding environment, while the task of 3D object bounding box detection in real time remains a strong algorithmic challenge. In this paper, we build on the success of the one-shot regression meta-architecture in the 2D perspective image space and extend it to generate oriented 3D object bounding boxes from LiDAR point cloud. Our main contribution is in extending the loss function of YOLO v2 to include the yaw angle, the 3D box center in Cartesian coordinates and the height of the box as a direct regression problem. This formulation enables real-time performance, which is essential for automated driving. Our results are showing promising figures on KITTI benchmark, achieving real-time performance (40 fps) on Titan X GPU.", "published": "2018-08-07T13:19:24Z", "version": 1}, {"aid": "1808.02455", "authors": ["Hassan Ismail Fawaz", "Germain Forestier", "Jonathan Weber", "Lhassane Idoumghar", "Pierre-Alain Muller"], "title": "Data augmentation using synthetic data for time series classification with deep residual networks", "url": "http://arxiv.org/pdf/1808.02455v1", "summary": "Data augmentation in deep neural networks is the process of generating artificial data in order to reduce the variance of the classifier with the goal to reduce the number of errors. This idea has been shown to improve deep neural network's generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike in image recognition problems, data augmentation techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved, especially for small datasets that exhibit overfitting, when a data augmentation method is adopted. In this paper, we fill this gap by investigating the application of a recently proposed data augmentation technique based on the Dynamic Time Warping distance, for a deep learning model for TSC. To evaluate the potential of augmenting the training set, we performed extensive experiments using the UCR TSC benchmark. Our preliminary experiments reveal that data augmentation can drastically increase deep CNN's accuracy on some datasets and significantly improve the deep model's accuracy when the method is used in an ensemble approach.", "published": "2018-08-07T16:48:21Z", "version": 1}, {"aid": "1808.05464", "authors": ["He He", "Dongrui Wu"], "title": "Transfer Learning for Brain-Computer Interfaces: A Euclidean Space Data Alignment Approach", "url": "http://arxiv.org/pdf/1808.05464v2", "summary": "Objective: This paper targets a major challenge in developing practical EEG-based brain-computer interfaces (BCIs): how to cope with individual differences so that better learning performance can be obtained for a new subject, with minimum or even no subject-specific data? Methods: We propose a novel approach to align EEG trials from different subjects in the Euclidean space to make them more similar, and hence improve the learning performance for a new subject. Our approach has three desirable properties: 1) it aligns the EEG trials directly in the Euclidean space, and any signal processing, feature extraction and machine learning algorithms can then be applied to the aligned trials; 2) its computational cost is very low; and, 3) it is unsupervised and does not need any label information from the new subject. Results: Both offline and simulated online experiments on motor imagery classification and event-related potential classification verified that our proposed approach outperformed a state-of-the-art Riemannian space data alignment approach, and several approaches without data alignment. Conclusion: The proposed Euclidean space EEG data alignment approach can greatly facilitate transfer learning in BCIs. Significance: Our proposed approach is effective, efficient, and easy to implement. It could be an essential pre-processing step for EEG-based BCIs.", "published": "2018-08-08T23:06:43Z", "version": 2}, {"aid": "1808.04247", "authors": ["Trang Pham", "Truyen Tran", "Svetha Venkatesh"], "title": "Relational dynamic memory networks", "url": "http://arxiv.org/pdf/1808.04247v3", "summary": "Neural networks excel in detecting regular patterns but are less successful in representing and manipulating complex data structures, possibly due to the lack of an external memory. This has led to the recent development of a new line of architectures known as Memory-Augmented Neural Networks (MANNs), each of which consists of a neural network that interacts with an external memory matrix. However, this RAM-like memory matrix is unstructured and thus does not naturally encode structured objects. Here we design a new MANN dubbed Relational Dynamic Memory Network (RMDN) to bridge the gap. Like existing MANNs, RMDN has a neural controller but its memory is structured as multi-relational graphs. RMDN uses the memory to represent and manipulate graph-structured data in response to query; and as a neural network, RMDN is trainable from labeled data. Thus RMDN learns to answer queries about a set of graph-structured objects without explicit programming. We evaluate the capability of RMDN on several important prediction problems, including software vulnerability, molecular bioactivity and chemical-chemical interaction. Results demonstrate the efficacy of the proposed model.", "published": "2018-08-10T00:01:34Z", "version": 3}, {"aid": "1808.03578", "authors": ["Noah Frazier-Logue", "Stephen Jos\u00e9 Hanson"], "title": "Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning", "url": "http://arxiv.org/pdf/1808.03578v2", "summary": "Multi-layer neural networks have lead to remarkable performance on many kinds of benchmark tasks in text, speech and image processing. Nonlinear parameter estimation in hierarchical models is known to be subject to overfitting and misspecification. One approach to these estimation and related problems (local minima, colinearity, feature discovery etc.) is called Dropout (Hinton, et al 2012, Baldi et al 2016). The Dropout algorithm removes hidden units according to a Bernoulli random variable with probability $p$ prior to each update, creating random \"shocks\" to the network that are averaged over updates. In this paper we will show that Dropout is a special case of a more general model published originally in 1990 called the Stochastic Delta Rule, or SDR (Hanson, 1990). SDR redefines each weight in the network as a random variable with mean $\\mu_{w_{ij}}$ and standard deviation $\\sigma_{w_{ij}}$. Each weight random variable is sampled on each forward activation, consequently creating an exponential number of potential networks with shared weights. Both parameters are updated according to prediction error, thus resulting in weight noise injections that reflect a local history of prediction error and local model averaging. SDR therefore implements a more sensitive local gradient-dependent simulated annealing per weight converging in the limit to a Bayes optimal network. Tests on standard benchmarks (CIFAR) using a modified version of DenseNet shows the SDR outperforms standard Dropout in test error by approx. $17\\%$ with DenseNet-BC 250 on CIFAR-100 and approx. $12-14\\%$ in smaller networks. We also show that SDR reaches the same accuracy that Dropout attains in 100 epochs in as few as 35 epochs.", "published": "2018-08-10T15:06:05Z", "version": 2}, {"aid": "1808.04560", "authors": ["Chen Wei", "Wenjing Wang", "Wenhan Yang", "Jiaying Liu"], "title": "Deep Retinex Decomposition for Low-Light Enhancement", "url": "http://arxiv.org/pdf/1808.04560v1", "summary": "Retinex model is an effective tool for low-light image enhancement. It assumes that observed images can be decomposed into the reflectance and illumination. Most existing Retinex-based methods have carefully designed hand-crafted constraints and parameters for this highly ill-posed decomposition, which may be limited by model capacity when applied in various scenes. In this paper, we collect a LOw-Light dataset (LOL) containing low/normal-light image pairs and propose a deep Retinex-Net learned on this dataset, including a Decom-Net for decomposition and an Enhance-Net for illumination adjustment. In the training process for Decom-Net, there is no ground truth of decomposed reflectance and illumination. The network is learned with only key constraints including the consistent reflectance shared by paired low/normal-light images, and the smoothness of illumination. Based on the decomposition, subsequent lightness enhancement is conducted on illumination by an enhancement network called Enhance-Net, and for joint denoising there is a denoising operation on reflectance. The Retinex-Net is end-to-end trainable, so that the learned decomposition is by nature good for lightness adjustment. Extensive experiments demonstrate that our method not only achieves visually pleasing quality for low-light enhancement but also provides a good representation of image decomposition.", "published": "2018-08-14T07:20:55Z", "version": 1}, {"aid": "1808.04952", "authors": ["Yuqi Yang", "Shilin Liu", "Hao Pan", "Yang Liu", "Xin Tong"], "title": "PFCNN: Convolutional Neural Networks on 3D Surfaces Using Parallel Frames", "url": "http://arxiv.org/pdf/1808.04952v2", "summary": "Surface meshes are widely used shape representations and capture finer geometry data than point clouds or volumetric grids, but are challenging to apply CNNs directly due to their non-Euclidean structure. We use parallel frames on surface to define PFCNNs that enable effective feature learning on surface meshes by mimicking standard convolutions faithfully. In particular, the convolution of PFCNN not only maps local surface patches onto flat tangent planes, but also aligns the tangent planes such that they locally form a flat Euclidean structure, thus enabling recovery of standard convolutions. The alignment is achieved by the tool of locally flat connections borrowed from discrete differential geometry, which can be efficiently encoded and computed by parallel frame fields. In addition, the lack of canonical axis on surface is handled by sampling with the frame directions. Experiments show that for tasks including classification, segmentation and registration on deformable geometric domains, as well as semantic scene segmentation on rigid domains, PFCNNs achieve robust and superior performances without using sophisticated input features than state-of-the-art surface based CNNs.", "published": "2018-08-15T02:39:35Z", "version": 2}, {"aid": "1808.05779", "authors": ["Sangil Jung", "Changyong Son", "Seohyung Lee", "Jinwoo Son", "Youngjun Kwak", "Jae-Joon Han", "Sung Ju Hwang", "Changkyu Choi"], "title": "Learning to Quantize Deep Networks by Optimizing Quantization Intervals with Task Loss", "url": "http://arxiv.org/pdf/1808.05779v3", "summary": "Reducing bit-widths of activations and weights of deep networks makes it efficient to compute and store them in memory, which is crucial in their deployments to resource-limited devices, such as mobile phones. However, decreasing bit-widths with quantization generally yields drastically degraded accuracy. To tackle this problem, we propose to learn to quantize activations and weights via a trainable quantizer that transforms and discretizes them. Specifically, we parameterize the quantization intervals and obtain their optimal values by directly minimizing the task loss of the network. This quantization-interval-learning (QIL) allows the quantized networks to maintain the accuracy of the full-precision (32-bit) networks with bit-width as low as 4-bit and minimize the accuracy degeneration with further bit-width reduction (i.e., 3 and 2-bit). Moreover, our quantizer can be trained on a heterogeneous dataset, and thus can be used to quantize pretrained networks without access to their training data. We demonstrate the effectiveness of our trainable quantizer on ImageNet dataset with various network architectures such as ResNet-18, -34 and AlexNet, on which it outperforms existing methods to achieve the state-of-the-art accuracy.", "published": "2018-08-17T07:28:17Z", "version": 3}, {"aid": "1808.05839", "authors": ["Abdullah M. Zyarah", "Dhireesha Kudithipudi"], "title": "Neuromorphic Architecture for the Hierarchical Temporal Memory", "url": "http://arxiv.org/pdf/1808.05839v1", "summary": "A biomimetic machine intelligence algorithm, that holds promise in creating invariant representations of spatiotemporal input streams is the hierarchical temporal memory (HTM). This unsupervised online algorithm has been demonstrated on several machine-learning tasks, including anomaly detection. Significant effort has been made in formalizing and applying the HTM algorithm to different classes of problems. There are few early explorations of the HTM hardware architecture, especially for the earlier version of the spatial pooler of HTM algorithm. In this article, we present a full-scale HTM architecture for both spatial pooler and temporal memory. Synthetic synapse design is proposed to address the potential and dynamic interconnections occurring during learning. The architecture is interweaved with parallel cells and columns that enable high processing speed for the HTM. The proposed architecture is verified for two different datasets: MNIST and the European number plate font (EUNF), with and without the presence of noise. The spatial pooler architecture is synthesized on Xilinx ZYNQ-7, with 91.16% classification accuracy for MNIST and 90\\% accuracy for EUNF, with noise. For the temporal memory sequence prediction, first and second order predictions are observed for a 5-number long sequence generated from EUNF dataset and 95% accuracy is obtained. Moreover, the proposed hardware architecture offers 1364X speedup over the software realization. These results indicate that the proposed architecture can serve as a digital core to build the HTM in hardware and eventually as a standalone self-learning system.", "published": "2018-08-17T12:37:58Z", "version": 1}, {"aid": "1808.06414", "authors": ["Shuai Zhang", "Yi Tay", "Lina Yao", "Aixin Sun"], "title": "Next Item Recommendation with Self-Attention", "url": "http://arxiv.org/pdf/1808.06414v2", "summary": "In this paper, we propose a novel sequence-aware recommendation model. Our model utilizes self-attention mechanism to infer the item-item relationship from user's historical interactions. With self-attention, it is able to estimate the relative weights of each item in user interaction trajectories to learn better representations for user's transient interests. The model is finally trained in a metric learning framework, taking both short-term and long-term intentions into consideration. Experiments on a wide range of datasets on different domains demonstrate that our approach outperforms the state-of-the-art by a wide margin.", "published": "2018-08-20T12:21:23Z", "version": 2}, {"aid": "1808.06934", "authors": ["Alessandro Betti", "Marco Gori", "Giuseppe Marra"], "title": "Backpropagation and Biological Plausibility", "url": "http://arxiv.org/pdf/1808.06934v1", "summary": "By and large, Backpropagation (BP) is regarded as one of the most important neural computation algorithms at the basis of the progress in machine learning, including the recent advances in deep learning. However, its computational structure has been the source of many debates on its arguable biological plausibility. In this paper, it is shown that when framing supervised learning in the Lagrangian framework, while one can see a natural emergence of Backpropagation, biologically plausible local algorithms can also be devised that are based on the search for saddle points in the learning adjoint space composed of weights, neural outputs, and Lagrangian multipliers. This might open the doors to a truly novel class of learning algorithms where, because of the introduction of the notion of support neurons, the optimization scheme also plays a fundamental role in the construction of the architecture.", "published": "2018-08-21T14:41:56Z", "version": 1}, {"aid": "1808.07804", "authors": ["S\u00f6ren R. K\u00fcnzel", "Bradly C. Stadie", "Nikita Vemuri", "Varsha Ramakrishnan", "Jasjeet S. Sekhon", "Pieter Abbeel"], "title": "Transfer Learning for Estimating Causal Effects using Neural Networks", "url": "http://arxiv.org/pdf/1808.07804v1", "summary": "We develop new algorithms for estimating heterogeneous treatment effects, combining recent developments in transfer learning for neural networks with insights from the causal inference literature. By taking advantage of transfer learning, we are able to efficiently use different data sources that are related to the same underlying causal mechanisms. We compare our algorithms with those in the extant literature using extensive simulation studies based on large-scale voter persuasion experiments and the MNIST database. Our methods can perform an order of magnitude better than existing benchmarks while using a fraction of the data.", "published": "2018-08-23T15:27:14Z", "version": 1}, {"aid": "1809.00960", "authors": ["Yueyue Wang", "Liang Zhao", "Zhijian Song", "Manning Wang"], "title": "Organ at Risk Segmentation in Head and Neck CT Images by Using a Two-Stage Segmentation Framework Based on 3D U-Net", "url": "http://arxiv.org/pdf/1809.00960v2", "summary": "Accurate segmentation of organ at risk (OAR) play a critical role in the treatment planning of image guided radiation treatment of head and neck cancer. This segmentation task is challenging for both human and automatic algorithms because of the relatively large number of OARs to be segmented, the large variability of the size and morphology across different OARs, and the low contrast of between some OARs and the background. In this paper, we proposed a two-stage segmentation framework based on 3D U-Net. In this framework, the segmentation of each OAR is decomposed into two sub-tasks: locating a bounding box of the OAR and segment it from a small volume within the bounding box, and each sub-tasks is fulfilled by a dedicated 3D U-Net. The decomposition makes each of the two sub-tasks much easier, so that they can be better completed. We evaluated the proposed method and compared it to state-of-the-art methods by using the MICCAI 2015 Challenge dataset. In terms of the boundary-based metric 95HD, the proposed method ranked first in eight of all nine OARs and ranked second in the other OAR. In terms of the area-based metric DSC, the proposed method ranked first in six of the nine OARs and ranked second in the other three OARs with small difference with the first one.", "published": "2018-08-25T14:09:28Z", "version": 2}, {"aid": "1809.00961", "authors": ["Ram Krishna Pandey", "Nabagata Saha", "Samarjit Karmakar", "A G Ramakrishnan"], "title": "MSCE: An edge preserving robust loss function for improving super-resolution algorithms", "url": "http://arxiv.org/pdf/1809.00961v1", "summary": "With the recent advancement in the deep learning technologies such as CNNs and GANs, there is significant improvement in the quality of the images reconstructed by deep learning based super-resolution (SR) techniques. In this work, we propose a robust loss function based on the preservation of edges obtained by the Canny operator. This loss function, when combined with the existing loss function such as mean square error (MSE), gives better SR reconstruction measured in terms of PSNR and SSIM. Our proposed loss function guarantees improved performance on any existing algorithm using MSE loss function, without any increase in the computational complexity during testing.", "published": "2018-08-25T22:00:10Z", "version": 1}, {"aid": "1808.09062", "authors": ["Huayu Li"], "title": "Cognitive Consistency Routing Algorithm of Capsule-network", "url": "http://arxiv.org/pdf/1808.09062v3", "summary": "Artificial Neural Networks (ANNs) are computational models inspired by the central nervous system (especially the brain) of animals and are used to estimate or generate unknown approximation functions relied on large amounts of inputs. Capsule Neural Network (Sabour S, et al.[2017]) is a novel structure of Convolutional Neural Networks which simulates the visual processing system of human brain. In this paper, we introduce psychological theories which called Cognitive Consistency to optimize the routing algorithm of Capsnet to make it more close to the work pattern of human brain. It has been shown in the experiment that a progress had been made compared with the baseline.", "published": "2018-08-27T23:26:08Z", "version": 3}, {"aid": "1809.00982", "authors": ["D. D. N. De Silva", "S. Fernando", "I. T. S. Piyatilake", "A. V. S. Karunarathne"], "title": "Wavelet based edge feature enhancement for convolutional neural networks", "url": "http://arxiv.org/pdf/1809.00982v2", "summary": "Convolutional neural networks are able to perform a hierarchical learning process starting with local features. However, a limited attention is paid to enhancing such elementary level features like edges. We propose and evaluate two wavelet-based edge feature enhancement methods to preprocess the input images to convolutional neural networks. The first method develops feature enhanced representations by decomposing the input images using wavelet transform and limited reconstructing subsequently. The second method develops such feature enhanced inputs to the network using local modulus maxima of wavelet coefficients. For each method, we have developed a new preprocessing layer by implementing each purposed method and have appended to the network architecture. Our empirical evaluations demonstrate that the proposed methods are outperforming the baselines and previously published work with significant accuracy gains.", "published": "2018-08-29T06:13:01Z", "version": 2}, {"aid": "1808.10631", "authors": ["Olga Krestinskaya", "Khaled Nabil Salama", "Alex Pappachen James"], "title": "Learning in Memristive Neural Network Architectures using Analog Backpropagation Circuits", "url": "http://arxiv.org/pdf/1808.10631v1", "summary": "The on-chip implementation of learning algorithms would speed-up the training of neural networks in crossbar arrays. The circuit level design and implementation of backpropagation algorithm using gradient descent operation for neural network architectures is an open problem. In this paper, we proposed the analog backpropagation learning circuits for various memristive learning architectures, such as Deep Neural Network (DNN), Binary Neural Network (BNN), Multiple Neural Network (MNN), Hierarchical Temporal Memory (HTM) and Long-Short Term Memory (LSTM). The circuit design and verification is done using TSMC 180nm CMOS process models, and TiO2 based memristor models. The application level validations of the system are done using XOR problem, MNIST character and Yale face image databases", "published": "2018-08-31T08:31:15Z", "version": 1}, {"aid": "1809.00193", "authors": ["Tianyang Wang", "Jun Huan", "Bo Li"], "title": "Data Dropout: Optimizing Training Data for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1809.00193v2", "summary": "Deep learning models learn to fit training data while they are highly expected to generalize well to testing data. Most works aim at finding such models by creatively designing architectures and fine-tuning parameters. To adapt to particular tasks, hand-crafted information such as image prior has also been incorporated into end-to-end learning. However, very little progress has been made on investigating how an individual training sample will influence the generalization ability of a model. In other words, to achieve high generalization accuracy, do we really need all the samples in a training dataset? In this paper, we demonstrate that deep learning models such as convolutional neural networks may not favor all training samples, and generalization accuracy can be further improved by dropping those unfavorable samples. Specifically, the influence of removing a training sample is quantifiable, and we propose a Two-Round Training approach, aiming to achieve higher generalization accuracy. We locate unfavorable samples after the first round of training, and then retrain the model from scratch with the reduced training dataset in the second round. Since our approach is essentially different from fine-tuning or further training, the computational cost should not be a concern. Our extensive experimental results indicate that, with identical settings, the proposed approach can boost performance of the well-known networks on both high-level computer vision problems such as image classification, and low-level vision problems such as image denoising.", "published": "2018-09-01T14:24:36Z", "version": 2}, {"aid": "1809.00219", "authors": ["Xintao Wang", "Ke Yu", "Shixiang Wu", "Jinjin Gu", "Yihao Liu", "Chao Dong", "Chen Change Loy", "Yu Qiao", "Xiaoou Tang"], "title": "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1809.00219v2", "summary": "The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at https://github.com/xinntao/ESRGAN .", "published": "2018-09-01T16:21:03Z", "version": 2}, {"aid": "1809.00263", "authors": ["Qiangeng Xu", "Hanwang Zhang", "Weiyue Wang", "Peter N. Belhumeur", "Ulrich Neumann"], "title": "Stochastic Dynamics for Video Infilling", "url": "http://arxiv.org/pdf/1809.00263v5", "summary": "In this paper, we introduce a stochastic dynamics video infilling (SDVI) framework to generate frames between long intervals in a video. Our task differs from video interpolation which aims to produce transitional frames for a short interval between every two frames and increase the temporal resolution. Our task, namely video infilling, however, aims to infill long intervals with plausible frame sequences. Our framework models the infilling as a constrained stochastic generation process and sequentially samples dynamics from the inferred distribution. SDVI consists of two parts: (1) a bi-directional constraint propagation module to guarantee the spatial-temporal coherence among frames, (2) a stochastic sampling process to generate dynamics from the inferred distributions. Experimental results show that SDVI can generate clear frame sequences with varying contents. Moreover, motions in the generated sequence are realistic and able to transfer smoothly from the given start frame to the terminal frame. Our project site is https://xharlie.github.io/projects/project_sites/SDVI/video_results.html", "published": "2018-09-01T22:58:49Z", "version": 5}, {"aid": "1809.00564", "authors": ["Philippe Lemoisson", "Stefano A. Cerri"], "title": "ViewpointS: towards a Collective Brain", "url": "http://arxiv.org/pdf/1809.00564v1", "summary": "Tracing knowledge acquisition and linking learning events to interaction between peers is a major challenge of our times. We have conceived, designed and evaluated a new paradigm for constructing and using collective knowledge by Web interactions that we called ViewpointS. By exploiting the similarity with Edelman's Theory of Neuronal Group Selection (TNGS), we conjecture that it may be metaphorically considered a Collective Brain, especially effective in the case of trans-disciplinary representations. Far from being without doubts, in the paper we present the reasons (and the limits) of our proposal that aims to become a useful integrating tool for future quantitative explorations of individual as well as collective learning at different degrees of granu-larity. We are therefore challenging each of the current approaches: the logical one in the semantic Web, the statistical one in mining and deep learning, the social one in recommender systems based on authority and trust; not in each of their own preferred field of operation, rather in their integration weaknesses far from the holistic and dynamic behavior of the human brain.", "published": "2018-09-03T11:51:13Z", "version": 1}, {"aid": "1809.00832", "authors": ["Eunji Jeong", "Joo Seong Jeong", "Soojeong Kim", "Gyeong-In Yu", "Byung-Gon Chun"], "title": "Improving the Expressiveness of Deep Learning Frameworks with Recursion", "url": "http://arxiv.org/pdf/1809.00832v1", "summary": "Recursive neural networks have widely been used by researchers to handle applications with recursively or hierarchically structured data. However, embedded control flow deep learning frameworks such as TensorFlow, Theano, Caffe2, and MXNet fail to efficiently represent and execute such neural networks, due to lack of support for recursion. In this paper, we add recursion to the programming model of existing frameworks by complementing their design with recursive execution of dataflow graphs as well as additional APIs for recursive definitions. Unlike iterative implementations, which can only understand the topological index of each node in recursive data structures, our recursive implementation is able to exploit the recursive relationships between nodes for efficient execution based on parallel computation. We present an implementation on TensorFlow and evaluation results with various recursive neural network models, showing that our recursive implementation not only conveys the recursive nature of recursive neural networks better than other implementations, but also uses given resources more effectively to reduce training and inference time.", "published": "2018-09-04T08:31:21Z", "version": 1}, {"aid": "1809.00837", "authors": ["Dan Dai", "Zhiwen Yu", "Yang Hu", "Wenming Cao", "Mingnan Luo"], "title": "Metabolize Neural Network", "url": "http://arxiv.org/pdf/1809.00837v1", "summary": "The metabolism of cells is the most basic and important part of human function. Neural networks in deep learning stem from neuronal activity. It is self-evident that the significance of metabolize neuronal network(MetaNet) in model construction. In this study, we explore neuronal metabolism for shallow network from proliferation and autophagy two aspects. First, we propose different neuron proliferate methods that constructive the selfgrowing network in metabolism cycle. Proliferate neurons alleviate resources wasting and insufficient model learning problem when network initializes more or less parameters. Then combined with autophagy mechanism in the process of model self construction to ablate under-expressed neurons. The MetaNet can automatically determine the number of neurons during training, further, save more resource consumption. We verify the performance of the proposed methods on datasets: MNIST, Fashion-MNIST and CIFAR-10.", "published": "2018-09-04T08:42:52Z", "version": 1}, {"aid": "1809.00846", "authors": ["Ping Luo", "Xinjiang Wang", "Wenqi Shao", "Zhanglin Peng"], "title": "Towards Understanding Regularization in Batch Normalization", "url": "http://arxiv.org/pdf/1809.00846v4", "summary": "Batch Normalization (BN) improves both convergence and generalization in training neural networks. This work understands these phenomena theoretically. We analyze BN by using a basic block of neural networks, consisting of a kernel layer, a BN layer, and a nonlinear activation function. This basic network helps us understand the impacts of BN in three aspects. First, by viewing BN as an implicit regularizer, BN can be decomposed into population normalization (PN) and gamma decay as an explicit regularization. Second, learning dynamics of BN and the regularization show that training converged with large maximum and effective learning rate. Third, generalization of BN is explored by using statistical mechanics. Experiments demonstrate that BN in convolutional neural networks share the same traits of regularization as the above analyses.", "published": "2018-09-04T09:01:10Z", "version": 4}, {"aid": "1809.00858", "authors": ["Anthony Hunter"], "title": "Non-monotonic Reasoning in Deductive Argumentation", "url": "http://arxiv.org/pdf/1809.00858v1", "summary": "Argumentation is a non-monotonic process. This reflects the fact that argumentation involves uncertain information, and so new information can cause a change in the conclusions drawn. However, the base logic does not need to be non-monotonic. Indeed, most proposals for structured argumentation use a monotonic base logic (e.g. some form of modus ponens with a rule-based language, or classical logic). Nonetheless, there are issues in capturing defeasible reasoning in argumentation including choice of base logic and modelling of defeasible knowledge. And there are insights and tools to be harnessed for research in non-monontonic logics. We consider some of these issues in this paper.", "published": "2018-09-04T09:29:37Z", "version": 1}, {"aid": "1809.00916", "authors": ["Yuhui Yuan", "Lang Huang", "Jianyuan Guo", "Chao Zhang", "Xilin Chen", "Jingdong Wang"], "title": "OCNet: Object Context Network for Scene Parsing", "url": "http://arxiv.org/pdf/1809.00916v4", "summary": "In this paper, we address the semantic segmentation task with a new context aggregation scheme named \\emph{object context}, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise.   We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices.   To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling~\\citep{zhao2017pyramid} and atrous spatial pyramid pooling~\\citep{chen2018deeplab}. We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff", "published": "2018-09-04T12:22:10Z", "version": 4}, {"aid": "1809.01926", "authors": ["Alessio Burrello", "Kaspar Schindler", "Luca Benini", "Abbas Rahimi"], "title": "One-shot Learning for iEEG Seizure Detection Using End-to-end Binary Operations: Local Binary Patterns with Hyperdimensional Computing", "url": "http://arxiv.org/pdf/1809.01926v1", "summary": "This paper presents an efficient binarized algorithm for both learning and classification of human epileptic seizures from intracranial electroencephalography (iEEG). The algorithm combines local binary patterns with brain-inspired hyperdimensional computing to enable end-to-end learning and inference with binary operations. The algorithm first transforms iEEG time series from each electrode into local binary pattern codes. Then atomic high-dimensional binary vectors are used to construct composite representations of seizures across all electrodes. For the majority of our patients (10 out of 16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot learning) and perfectly generalizes on 27 further seizures. For other patients, the algorithm requires three to six seizures for learning. Overall, our algorithm surpasses the state-of-the-art methods for detecting 65 novel seizures with higher specificity and sensitivity, and lower memory footprint.", "published": "2018-09-06T11:39:12Z", "version": 1}, {"aid": "1809.02058", "authors": ["Chenshen Wu", "Luis Herranz", "Xialei Liu", "Yaxing Wang", "Joost van de Weijer", "Bogdan Raducanu"], "title": "Memory Replay GANs: learning to generate images from new categories without forgetting", "url": "http://arxiv.org/pdf/1809.02058v3", "summary": "Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories.", "published": "2018-09-06T15:45:36Z", "version": 3}, {"aid": "1809.02145", "authors": ["Alexia Jolicoeur-Martineau"], "title": "GANs beyond divergence minimization", "url": "http://arxiv.org/pdf/1809.02145v1", "summary": "Generative adversarial networks (GANs) can be interpreted as an adversarial game between two players, a discriminator D and a generator G, in which D learns to classify real from fake data and G learns to generate realistic data by \"fooling\" D into thinking that fake data is actually real data. Currently, a dominating view is that G actually learns by minimizing a divergence given that the general objective function is a divergence when D is optimal. However, this view has been challenged due to inconsistencies between theory and practice. In this paper, we discuss of the properties associated with most loss functions for G (e.g., saturating/non-saturating f-GAN, LSGAN, WGAN, etc.). We show that these loss functions are not divergences and do not have the same equilibrium as expected of divergences. This suggests that G does not need to minimize the same objective function as D maximize, nor maximize the objective of D after swapping real data with fake data (non-saturating GAN) but can instead use a wide range of possible loss functions to learn to generate realistic data. We define GANs through two separate and independent D maximization and G minimization steps. We generalize the generator step to four new classes of loss functions, most of which are actual divergences (while traditional G loss functions are not). We test a wide variety of loss functions from these four classes on a synthetic dataset and on CIFAR-10. We observe that most loss functions converge well and provide comparable data generation quality to non-saturating GAN, LSGAN, and WGAN-GP generator loss functions, whether we use divergences or non-divergences. These results suggest that GANs do not conform well to the divergence minimization theory and form a much broader range of models than previously assumed.", "published": "2018-09-06T18:00:26Z", "version": 1}, {"aid": "1809.02193", "authors": ["Andres Campero", "Aldo Pareja", "Tim Klinger", "Josh Tenenbaum", "Sebastian Riedel"], "title": "Logical Rule Induction and Theory Learning Using Neural Theorem Proving", "url": "http://arxiv.org/pdf/1809.02193v3", "summary": "A hallmark of human cognition is the ability to continually acquire and distill observations of the world into meaningful, predictive theories. In this paper we present a new mechanism for logical theory acquisition which takes a set of observed facts and learns to extract from them a set of logical rules and a small set of core facts which together entail the observations. Our approach is neuro-symbolic in the sense that the rule pred- icates and core facts are given dense vector representations. The rules are applied to the core facts using a soft unification procedure to infer additional facts. After k steps of forward inference, the consequences are compared to the initial observations and the rules and core facts are then encouraged towards representations that more faithfully generate the observations through inference. Our approach is based on a novel neural forward-chaining differentiable rule induction network. The rules are interpretable and learned compositionally from their predicates, which may be invented. We demonstrate the efficacy of our approach on a variety of ILP rule induction and domain theory learning datasets.", "published": "2018-09-06T19:49:20Z", "version": 3}, {"aid": "1809.02260", "authors": ["Brian Shay", "Patrick Brazil"], "title": "The Force of Proof by Which Any Argument Prevails", "url": "http://arxiv.org/pdf/1809.02260v1", "summary": "Jakob Bernoulli, working in the late 17th century, identified a gap in contemporary probability theory. He cautioned that it was inadequate to specify force of proof (probability of provability) for some kinds of uncertain arguments. After 300 years, this gap remains in present-day probability theory. We present axioms analogous to Kolmogorov's axioms for probability, specifying uncertainty that lies in an argument's inference/implication itself rather than in its premise and conclusion. The axioms focus on arguments spanning two Boolean algebras, but generalize the obligatory: \"force of proof of A implies B is the probability of B or not A\" in the case that the Boolean algebras are identical. We propose a categorical framework that relies on generalized probabilities (objects) to express uncertainty in premises, to mix with arguments (morphisms) to express uncertainty embedded directly in inference/implication. There is a direct application to Shafer's evidence theory (Dempster-Shafer theory), greatly expanding its scope for applications. Therefore, we can offer this framework not only as an optimal solution to a difficult historical puzzle, but also to advance the frontiers of contemporary artificial intelligence.   Keywords: force of proof, probability of provability, Ars Conjectandi, non additive probabilities, evidence theory.", "published": "2018-09-07T00:24:29Z", "version": 1}, {"aid": "1809.02441", "authors": ["Jangho Kim", "Jeesoo Kim", "Nojun Kwak"], "title": "StackNet: Stacking Parameters for Continual learning", "url": "http://arxiv.org/pdf/1809.02441v3", "summary": "Training a neural network for a classification task typically assumes that the data to train are given from the beginning. However, in the real world, additional data accumulate gradually and the model requires additional training without accessing the old training data. This usually leads to the catastrophic forgetting problem which is inevitable for the traditional training methodology of neural networks. In this paper, we propose a continual learning method that is able to learn additional tasks while retaining the performance of previously learned tasks by stacking parameters. Composed of two complementary components, the index module and the StackNet, our method estimates the index of the corresponding task for an input sample with the index module and utilizes a particular portion of StackNet with this index. The StackNet guarantees no degradation in the performance of the previously learned tasks and the index module shows high confidence in finding the origin of an input sample. Compared to the previous work of PackNet, our method is competitive and highly intuitive.", "published": "2018-09-07T12:39:13Z", "version": 3}, {"aid": "1809.02499", "authors": ["Hongyu Guo", "Yongyi Mao", "Richong Zhang"], "title": "MixUp as Locally Linear Out-Of-Manifold Regularization", "url": "http://arxiv.org/pdf/1809.02499v3", "summary": "MixUp is a recently proposed data-augmentation scheme, which linearly interpolates a random pair of training examples and correspondingly the one-hot representations of their labels. Training deep neural networks with such additional data is shown capable of significantly improving the predictive accuracy of the current art. The power of MixUp, however, is primarily established empirically and its working and effectiveness have not been explained in any depth. In this paper, we develop an understanding for MixUp as a form of \"out-of-manifold regularization\", which imposes certain \"local linearity\" constraints on the model's input space beyond the data manifold. This analysis enables us to identify a limitation of MixUp, which we call \"manifold intrusion\". In a nutshell, manifold intrusion in MixUp is a form of under-fitting resulting from conflicts between the synthetic labels of the mixed-up examples and the labels of original training data. Such a phenomenon usually happens when the parameters controlling the generation of mixing policies are not sufficiently fine-tuned on the training data. To address this issue, we propose a novel adaptive version of MixUp, where the mixing policies are automatically learned from the data using an additional network and objective function designed to avoid manifold intrusion. The proposed regularizer, AdaMixUp, is empirically evaluated on several benchmark datasets. Extensive experiments demonstrate that AdaMixUp improves upon MixUp when applied to the current art of deep classification models.", "published": "2018-09-07T14:26:17Z", "version": 3}, {"aid": "1809.02601", "authors": ["Junran Peng", "Lingxi Xie", "Zhaoxiang Zhang", "Tieniu Tan", "Jingdong Wang"], "title": "Accelerating Deep Neural Networks with Spatial Bottleneck Modules", "url": "http://arxiv.org/pdf/1809.02601v1", "summary": "This paper presents an efficient module named spatial bottleneck for accelerating the convolutional layers in deep neural networks. The core idea is to decompose convolution into two stages, which first reduce the spatial resolution of the feature map, and then restore it to the desired size. This operation decreases the sampling density in the spatial domain, which is independent yet complementary to network acceleration approaches in the channel domain. Using different sampling rates, we can tradeoff between recognition accuracy and model complexity.   As a basic building block, spatial bottleneck can be used to replace any single convolutional layer, or the combination of two convolutional layers. We empirically verify the effectiveness of spatial bottleneck by applying it to the deep residual networks. Spatial bottleneck achieves 2x and 1.4x speedup on the regular and channel-bottlenecked residual blocks, respectively, with the accuracies retained in recognizing low-resolution images, and even improved in recognizing high-resolution images.", "published": "2018-09-07T17:54:54Z", "version": 1}, {"aid": "1809.03783", "authors": ["Xiao-Yun Zhou", "Guang-Zhong Yang"], "title": "Normalization in Training U-Net for 2D Biomedical Semantic Segmentation", "url": "http://arxiv.org/pdf/1809.03783v3", "summary": "2D biomedical semantic segmentation is important for robotic vision in surgery. Segmentation methods based on Deep Convolutional Neural Network (DCNN) can out-perform conventional methods in terms of both accuracy and levels of automation. One common issue in training a DCNN for biomedical semantic segmentation is the internal covariate shift where the training of convolutional kernels is encumbered by the distribution change of input features, hence both the training speed and performance are decreased. Batch Normalization (BN) is the first proposed method for addressing internal covariate shift and is widely used. Instance Normalization (IN) and Layer Normalization (LN) have also been proposed. Group Normalization (GN) is proposed more recently and has not yet been applied to 2D biomedical semantic segmentation, however, no specific validations on GN were given. Most DCNNs for biomedical semantic segmentation adopt BN as the normalization method by default, without reviewing its performance. In this paper, four normalization methods - BN, IN, LN and GN are compared in details, specifically for 2D biomedical semantic segmentation. U-Net is adopted as the basic DCNN structure. Three datasets regarding the Right Ventricle (RV), aorta, and Left Ventricle (LV) are used for the validation. The results show that detailed subdivision of the feature map, i.e. GN with a large group number or IN, achieves higher accuracy. This accuracy improvement mainly comes from better model generalization. Codes are uploaded and maintained at Xiao-Yun Zhou's Github.", "published": "2018-09-11T10:27:45Z", "version": 3}, {"aid": "1809.04356", "authors": ["Hassan Ismail Fawaz", "Germain Forestier", "Jonathan Weber", "Lhassane Idoumghar", "Pierre-Alain Muller"], "title": "Deep learning for time series classification: a review", "url": "http://arxiv.org/pdf/1809.04356v4", "summary": "Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8,730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.", "published": "2018-09-12T10:55:33Z", "version": 4}, {"aid": "1809.04508", "authors": ["Zhisheng Zhong", "Tiancheng Shen", "Yibo Yang", "Zhouchen Lin", "Chao Zhang"], "title": "Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution", "url": "http://arxiv.org/pdf/1809.04508v3", "summary": "Convolutional neural networks (CNNs) have recently achieved great success in single-image super-resolution (SISR). However, these methods tend to produce over-smoothed outputs and miss some textural details. To solve these problems, we propose the Super-Resolution CliqueNet (SRCliqueNet) to reconstruct the high resolution (HR) image with better textural details in the wavelet domain. The proposed SRCliqueNet firstly extracts a set of feature maps from the low resolution (LR) image by the clique blocks group. Then we send the set of feature maps to the clique up-sampling module to reconstruct the HR image. The clique up-sampling module consists of four sub-nets which predict the high resolution wavelet coefficients of four sub-bands. Since we consider the edge feature properties of four sub-bands, the four sub-nets are connected to the others so that they can learn the coefficients of four sub-bands jointly. Finally we apply inverse discrete wavelet transform (IDWT) to the output of four sub-nets at the end of the clique up-sampling module to increase the resolution and reconstruct the HR image. Extensive quantitative and qualitative experiments on benchmark datasets show that our method achieves superior performance over the state-of-the-art methods.", "published": "2018-09-12T15:19:37Z", "version": 3}, {"aid": "1809.04673", "authors": ["Rishabh Iyer", "Nimit Acharya", "Tanuja Bompada", "Denis Charles", "Eren Manavoglu"], "title": "A Unified Batch Online Learning Framework for Click Prediction", "url": "http://arxiv.org/pdf/1809.04673v1", "summary": "We present a unified framework for Batch Online Learning (OL) for Click Prediction in Search Advertisement. Machine Learning models once deployed, show non-trivial accuracy and calibration degradation over time due to model staleness. It is therefore necessary to regularly update models, and do so automatically. This paper presents two paradigms of Batch Online Learning, one which incrementally updates the model parameters via an early stopping mechanism, and another which does so through a proximal regularization. We argue how both these schemes naturally trade-off between old and new data. We then theoretically and empirically show that these two seemingly different schemes are closely related. Through extensive experiments, we demonstrate the utility of of our OL framework; how the two OL schemes relate to each other and how they trade-off between the new and historical data. We then compare batch OL to full model retrains, and show how online learning is more robust to data issues. We also demonstrate the long term impact of Online Learning, the role of the initial Models in OL, the impact of delays in the update, and finally conclude with some implementation details and challenges in deploying a real world online learning system in production. While this paper mostly focuses on application of click prediction for search advertisement, we hope that the lessons learned here can be carried over to other problem domains.", "published": "2018-09-12T21:01:55Z", "version": 1}, {"aid": "1809.04711", "authors": ["Galin Georgiev"], "title": "Linear Algebra and Duality of Neural Networks", "url": "http://arxiv.org/pdf/1809.04711v2", "summary": "Bases, mappings, projections and metrics, natural for Neural network training, are introduced. Graph-theoretical interpretation is offered. Non-Gaussianity naturally emerges, even in relatively simple datasets. Training statistics, hierarchies and energies are analyzed, from physics point of view. Duality between observables (for example, pixels) and observations is established. Relationship between exact and numerical solutions is studied. Physics and financial mathematics interpretations of a key problem are offered. Examples support all new concepts.", "published": "2018-09-12T23:39:18Z", "version": 2}, {"aid": "1809.04765", "authors": ["Shu Liang", "Xiufeng Huang", "Xianyu Meng", "Kunyao Chen", "Linda G. Shapiro", "Ira Kemelmacher-Shlizerman"], "title": "Video to Fully Automatic 3D Hair Model", "url": "http://arxiv.org/pdf/1809.04765v1", "summary": "Imagine taking a selfie video with your mobile phone and getting as output a 3D model of your head (face and 3D hair strands) that can be later used in VR, AR, and any other domain. State of the art hair reconstruction methods allow either a single photo (thus compromising 3D quality) or multiple views, but they require manual user interaction (manual hair segmentation and capture of fixed camera views that span full 360 degree). In this paper, we describe a system that can completely automatically create a reconstruction from any video (even a selfie video), and we don't require specific views, since taking your -90 degree, 90 degree, and full back views is not feasible in a selfie capture.   In the core of our system, in addition to the automatization components, hair strands are estimated and deformed in 3D (rather than 2D as in state of the art) thus enabling superior results. We provide qualitative, quantitative, and Mechanical Turk human studies that support the proposed system, and show results on a diverse variety of videos (8 different celebrity videos, 9 selfie mobile videos, spanning age, gender, hair length, type, and styling).", "published": "2018-09-13T04:14:53Z", "version": 1}, {"aid": "1809.05127", "authors": ["Khushmeen Sakloth", "Wesley Beckner", "Jim Pfaendtner", "Garrett B. Goh"], "title": "IL-Net: Using Expert Knowledge to Guide the Design of Furcated Neural Networks", "url": "http://arxiv.org/pdf/1809.05127v1", "summary": "Deep neural networks (DNN) excel at extracting patterns. Through representation learning and automated feature engineering on large datasets, such models have been highly successful in computer vision and natural language applications. Designing optimal network architectures from a principled or rational approach however has been less than successful, with the best successful approaches utilizing an additional machine learning algorithm to tune the network hyperparameters. However, in many technical fields, there exist established domain knowledge and understanding about the subject matter. In this work, we develop a novel furcated neural network architecture that utilizes domain knowledge as high-level design principles of the network. We demonstrate proof-of-concept by developing IL-Net, a furcated network for predicting the properties of ionic liquids, which is a class of complex multi-chemicals entities. Compared to existing state-of-the-art approaches, we show that furcated networks can improve model accuracy by approximately 20-35%, without using additional labeled data. Lastly, we distill two key design principles for furcated networks that can be adapted to other domains.", "published": "2018-09-13T18:22:04Z", "version": 1}, {"aid": "1809.05676", "authors": ["Prabhat Nagarajan", "Garrett Warnell", "Peter Stone"], "title": "Deterministic Implementations for Reproducibility in Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1809.05676v5", "summary": "While deep reinforcement learning (DRL) has led to numerous successes in recent years, reproducing these successes can be extremely challenging. One reproducibility challenge particularly relevant to DRL is nondeterminism in the training process, which can substantially affect the results. Motivated by this challenge, we study the positive impacts of deterministic implementations in eliminating nondeterminism in training. To do so, we consider the particular case of the deep Q-learning algorithm, for which we produce a deterministic implementation by identifying and controlling all sources of nondeterminism in the training process. One by one, we then allow individual sources of nondeterminism to affect our otherwise deterministic implementation, and measure the impact of each source on the variance in performance. We find that individual sources of nondeterminism can substantially impact the performance of agent, illustrating the benefits of deterministic implementations. In addition, we also discuss the important role of deterministic implementations in achieving exact replicability of results.", "published": "2018-09-15T08:53:28Z", "version": 5}, {"aid": "1809.05910", "authors": ["Rana Hanocka", "Amir Hertz", "Noa Fish", "Raja Giryes", "Shachar Fleishman", "Daniel Cohen-Or"], "title": "MeshCNN: A Network with an Edge", "url": "http://arxiv.org/pdf/1809.05910v2", "summary": "Polygonal meshes provide an efficient representation for 3D shapes. They explicitly capture both shape surface and topology, and leverage non-uniformity to represent large flat regions as well as sharp, intricate features. This non-uniformity and irregularity, however, inhibits mesh analysis efforts using neural networks that combine convolution and pooling operations. In this paper, we utilize the unique properties of the mesh for a direct analysis of 3D shapes using MeshCNN, a convolutional neural network designed specifically for triangular meshes. Analogous to classic CNNs, MeshCNN combines specialized convolution and pooling layers that operate on the mesh edges, by leveraging their intrinsic geodesic connections. Convolutions are applied on edges and the four edges of their incident triangles, and pooling is applied via an edge collapse operation that retains surface topology, thereby, generating new mesh connectivity for the subsequent convolutions. MeshCNN learns which edges to collapse, thus forming a task-driven process where the network exposes and expands the important features while discarding the redundant ones. We demonstrate the effectiveness of our task-driven pooling on various learning tasks applied to 3D meshes.", "published": "2018-09-16T16:32:29Z", "version": 2}, {"aid": "1809.06367", "authors": ["Edouard Oyallon", "Sergey Zagoruyko", "Gabriel Huang", "Nikos Komodakis", "Simon Lacoste-Julien", "Matthew Blaschko", "Eugene Belilovsky"], "title": "Scattering Networks for Hybrid Representation Learning", "url": "http://arxiv.org/pdf/1809.06367v1", "summary": "Scattering networks are a class of designed Convolutional Neural Networks (CNNs) with fixed weights. We argue they can serve as generic representations for modelling images. In particular, by working in scattering space, we achieve competitive results both for supervised and unsupervised learning tasks, while making progress towards constructing more interpretable CNNs. For supervised learning, we demonstrate that the early layers of CNNs do not necessarily need to be learned, and can be replaced with a scattering network instead. Indeed, using hybrid architectures, we achieve the best results with predefined representations to-date, while being competitive with end-to-end learned CNNs. Specifically, even applying a shallow cascade of small-windowed scattering coefficients followed by 1$\\times$1-convolutions results in AlexNet accuracy on the ILSVRC2012 classification task. Moreover, by combining scattering networks with deep residual networks, we achieve a single-crop top-5 error of 11.4% on ILSVRC2012. Also, we show they can yield excellent performance in the small sample regime on CIFAR-10 and STL-10 datasets, exceeding their end-to-end counterparts, through their ability to incorporate geometrical priors. For unsupervised learning, scattering coefficients can be a competitive representation that permits image recovery. We use this fact to train hybrid GANs to generate images. Finally, we empirically analyze several properties related to stability and reconstruction of images from scattering coefficients.", "published": "2018-09-17T06:27:40Z", "version": 1}, {"aid": "1809.06205", "authors": ["Aristotelis Charalampous", "Sotirios Chatzis"], "title": "Quantum Statistics-Inspired Neural Attention", "url": "http://arxiv.org/pdf/1809.06205v2", "summary": "Sequence-to-sequence (encoder-decoder) models with attention constitute a cornerstone of deep learning research, as they have enabled unprecedented sequential data modeling capabilities. This effectiveness largely stems from the capacity of these models to infer salient temporal dynamics over long horizons; these are encoded into the obtained neural attention (NA) distributions. However, existing NA formulations essentially constitute point-wise selection mechanisms over the observed source sequences; that is, attention weights computation relies on the assumption that each source sequence element is independent of the rest. Unfortunately, although convenient, this assumption fails to account for higher-order dependencies which might be prevalent in real-world data. This paper addresses these limitations by leveraging Quantum-Statistical modeling arguments. Specifically, our work broadens the notion of NA, by attempting to account for the case that the NA model becomes inherently incapable of discerning between individual source elements; this is assumed to be the case due to higher-order temporal dynamics. On the contrary, we postulate that in some cases selection may be feasible only at the level of pairs of source sequence elements. To this end, we cast NA into inference of an attention density matrix (ADM) approximation. We derive effective training and inference algorithms, and evaluate our approach in the context of a machine translation (MT) application. We perform experiments with challenging benchmark datasets. As we show, our approach yields favorable outcomes in terms of several evaluation metrics.", "published": "2018-09-17T13:58:13Z", "version": 2}, {"aid": "1809.07009", "authors": ["Yuchi Huo", "Sung-Eui Yoon"], "title": "Light Field Neural Network", "url": "http://arxiv.org/pdf/1809.07009v2", "summary": "We introduce an optical neural network system made by off-the-shelf components. In order to test the evaluate the physical property of the proposed system, we are making a prototype. After further discussions with our cooperators, we are agreed that the prototype implementation may take longer time than we expected earlier. Therefore we reach a consensus on withdrawing the paper until the physical data is available.", "published": "2018-09-19T04:19:28Z", "version": 2}, {"aid": "1809.07217", "authors": ["M\u00e1rton V\u00e9ges", "Viktor Varga", "Andr\u00e1s L\u0151rincz"], "title": "3D Human Pose Estimation with Siamese Equivariant Embedding", "url": "http://arxiv.org/pdf/1809.07217v2", "summary": "In monocular 3D human pose estimation a common setup is to first detect 2D positions and then lift the detection into 3D coordinates. Many algorithms suffer from overfitting to camera positions in the training set. We propose a siamese architecture that learns a rotation equivariant hidden representation to reduce the need for data augmentation. Our method is evaluated on multiple databases with different base networks and shows a consistent improvement of error metrics. It achieves state-of-the-art cross-camera error rate among algorithms that use estimated 2D joint coordinates only.", "published": "2018-09-19T14:26:14Z", "version": 2}, {"aid": "1809.07435", "authors": ["Kristopher De Asis", "Brendan Bennett", "Richard S. Sutton"], "title": "Predicting Periodicity with Temporal Difference Learning", "url": "http://arxiv.org/pdf/1809.07435v1", "summary": "Temporal difference (TD) learning is an important approach in reinforcement learning, as it combines ideas from dynamic programming and Monte Carlo methods in a way that allows for online and incremental model-free learning. A key idea of TD learning is that it is learning predictive knowledge about the environment in the form of value functions, from which it can derive its behavior to address long-term sequential decision making problems. The agent's horizon of interest, that is, how immediate or long-term a TD learning agent predicts into the future, is adjusted through a discount rate parameter. In this paper, we introduce an alternative view on the discount rate, with insight from digital signal processing, to include complex-valued discounting. Our results show that setting the discount rate to appropriately chosen complex numbers allows for online and incremental estimation of the Discrete Fourier Transform (DFT) of a signal of interest with TD learning. We thereby extend the types of knowledge representable by value functions, which we show are particularly useful for identifying periodic effects in the reward sequence.", "published": "2018-09-20T00:07:27Z", "version": 1}, {"aid": "1809.07656", "authors": ["A. N. Gorban", "V. A. Makarov", "I. Y. Tyukin"], "title": "The unreasonable effectiveness of small neural ensembles in high-dimensional brain", "url": "http://arxiv.org/pdf/1809.07656v2", "summary": "Despite the widely-spread consensus on the brain complexity, sprouts of the single neuron revolution emerged in neuroscience in the 1970s. They brought many unexpected discoveries, including grandmother or concept cells and sparse coding of information in the brain.   In machine learning for a long time, the famous curse of dimensionality seemed to be an unsolvable problem. Nevertheless, the idea of the blessing of dimensionality becomes gradually more and more popular. Ensembles of non-interacting or weakly interacting simple units prove to be an effective tool for solving essentially multidimensional problems. This approach is especially useful for one-shot (non-iterative) correction of errors in large legacy artificial intelligence systems.   These simplicity revolutions in the era of complexity have deep fundamental reasons grounded in geometry of multidimensional data spaces. To explore and understand these reasons we revisit the background ideas of statistical physics. In the course of the 20th century they were developed into the concentration of measure theory. New stochastic separation theorems reveal the fine structure of the data clouds.   We review and analyse biological, physical, and mathematical problems at the core of the fundamental question: how can high-dimensional brain organise reliable and fast learning in high-dimensional world of data by simple tools?   Two critical applications are reviewed to exemplify the approach: one-shot correction of errors in intellectual systems and emergence of static and associative memories in ensembles of single neurons.", "published": "2018-09-20T14:53:11Z", "version": 2}, {"aid": "1809.07803", "authors": ["Axel Abels", "Diederik M. Roijers", "Tom Lenaerts", "Ann Now\u00e9", "Denis Steckelmacher"], "title": "Dynamic Weights in Multi-Objective Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1809.07803v2", "summary": "Many real-world decision problems are characterized by multiple conflicting objectives which must be balanced based on their relative importance. In the dynamic weights setting the relative importance changes over time and specialized algorithms that deal with such change, such as a tabular Reinforcement Learning (RL) algorithm by Natarajan and Tadepalli (2005), are required. However, this earlier work is not feasible for RL settings that necessitate the use of function approximators. We generalize across weight changes and high-dimensional inputs by proposing a multi-objective Q-network whose outputs are conditioned on the relative importance of objectives and we introduce Diverse Experience Replay (DER) to counter the inherent non-stationarity of the Dynamic Weights setting. We perform an extensive experimental evaluation and compare our methods to adapted algorithms from Deep Multi-Task/Multi-Objective Reinforcement Learning and show that our proposed network in combination with DER dominates these adapted algorithms across weight change scenarios and problem domains.", "published": "2018-09-20T18:52:15Z", "version": 2}, {"aid": "1810.08648", "authors": ["George Kyriakides", "Konstantinos Margaritis"], "title": "Towards automated neural design: An open source, distributed neural architecture research framework", "url": "http://arxiv.org/pdf/1810.08648v1", "summary": "NORD (Neural Operations Research & Development) is an open source distributed deep learning architectural research framework, based on PyTorch, MPI and Horovod. It aims to make research of deep architectures easier for experts of different domains, in order to accelerate the process of finding better architectures, as well as study the best architectures generated for different datasets. Although currently under heavy development, the framework aims to allow the easy implementation of different design and optimization method families (optimization algorithms, meta-heuristics, reinforcement learning etc.) as well as the fair comparison between them. Furthermore, due to the computational resources required in order to optimize and evaluate network architectures, it leverage the use of distributed computing, while aiming to minimize the researcher's overhead required to implement it. Moreover, it strives to make the creation of architectures more intuitive, by implementing network descriptors, allowing to separately define the architecture's nodes and connections. In this paper, we present the framework's current state of development, while presenting its basic concepts, providing simple examples as well as their experimental results.", "published": "2018-09-20T20:31:45Z", "version": 1}, {"aid": "1809.08229", "authors": ["Rohit Pardasani", "Utkarsh Shreemali"], "title": "Image Denoising and Super-Resolution using Residual Learning of Deep Convolutional Network", "url": "http://arxiv.org/pdf/1809.08229v1", "summary": "Image super-resolution and denoising are two important tasks in image processing that can lead to improvement in image quality. Image super-resolution is the task of mapping a low resolution image to a high resolution image whereas denoising is the task of learning a clean image from a noisy input. We propose and train a single deep learning network that we term as SuRDCNN (super-resolution and denoising convolutional neural network), to perform these two tasks simultaneously . Our model nearly replicates the architecture of existing state-of-the-art deep learning models for super-resolution and denoising. We use the proven strategy of residual learning, as supported by state-of-the-art networks in this domain. Our trained SuRDCNN is capable of super-resolving image in the presence of Gaussian noise, Poisson noise or any random combination of both of these noises.", "published": "2018-09-21T17:58:22Z", "version": 1}, {"aid": "1809.08458", "authors": ["Huasong Zhong", "Xianggen Liu", "Yihui He", "Yuchun Ma"], "title": "Shift-based Primitives for Efficient Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1809.08458v2", "summary": "We propose a collection of three shift-based primitives for building efficient compact CNN-based networks. These three primitives (channel shift, address shift, shortcut shift) can reduce the inference time on GPU while maintains the prediction accuracy. These shift-based primitives only moves the pointer but avoids memory copy, thus very fast. For example, the channel shift operation is 12.7x faster compared to channel shuffle in ShuffleNet but achieves the same accuracy. The address shift and channel shift can be merged into the point-wise group convolution and invokes only a single kernel call, taking little time to perform spatial convolution and channel shift. Shortcut shift requires no time to realize residual connection through allocating space in advance. We blend these shift-based primitives with point-wise group convolution and built two inference-efficient CNN architectures named AddressNet and Enhanced AddressNet. Experiments on CIFAR100 and ImageNet datasets show that our models are faster and achieve comparable or better accuracy.", "published": "2018-09-22T17:43:28Z", "version": 2}, {"aid": "1809.08590", "authors": ["Kaiyu Chen", "Yihan Dong", "Xipeng Qiu", "Zitian Chen"], "title": "Neural Arithmetic Expression Calculator", "url": "http://arxiv.org/pdf/1809.08590v1", "summary": "This paper presents a pure neural solver for arithmetic expression calculation (AEC) problem. Previous work utilizes the powerful capabilities of deep neural networks and attempts to build an end-to-end model to solve this problem. However, most of these methods can only deal with the additive operations. It is still a challenging problem to solve the complex expression calculation problem, which includes the adding, subtracting, multiplying, dividing and bracketing operations. In this work, we regard the arithmetic expression calculation as a hierarchical reinforcement learning problem. An arithmetic operation is decomposed into a series of sub-tasks, and each sub-task is dealt with by a skill module. The skill module could be a basic module performing elementary operations, or interactive module performing complex operations by invoking other skill models. With curriculum learning, our model can deal with a complex arithmetic expression calculation with the deep hierarchical structure of skill models. Experiments show that our model significantly outperforms the previous models for arithmetic expression calculation.", "published": "2018-09-23T13:05:28Z", "version": 1}, {"aid": "1809.09645", "authors": ["Kyongsik Yun", "Alexander Huyen", "Thomas Lu"], "title": "Deep Neural Networks for Pattern Recognition", "url": "http://arxiv.org/pdf/1809.09645v1", "summary": "In the field of pattern recognition research, the method of using deep neural networks based on improved computing hardware recently attracted attention because of their superior accuracy compared to conventional methods. Deep neural networks simulate the human visual system and achieve human equivalent accuracy in image classification, object detection, and segmentation. This chapter introduces the basic structure of deep neural networks that simulate human neural networks. Then we identify the operational processes and applications of conditional generative adversarial networks, which are being actively researched based on the bottom-up and top-down mechanisms, the most important functions of the human visual perception process. Finally, recent developments in training strategies for effective learning of complex deep neural networks are addressed.", "published": "2018-09-25T18:23:49Z", "version": 1}, {"aid": "1809.10635", "authors": ["Gido M. van de Ven", "Andreas S. Tolias"], "title": "Generative replay with feedback connections as a general strategy for continual learning", "url": "http://arxiv.org/pdf/1809.10635v2", "summary": "A major obstacle to developing artificial intelligence applications capable of true lifelong learning is that artificial neural networks quickly or catastrophically forget previously learned tasks when trained on a new one. Numerous methods for alleviating catastrophic forgetting are currently being proposed, but differences in evaluation protocols make it difficult to directly compare their performance. To enable more meaningful comparisons, here we identified three distinct scenarios for continual learning based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted MNIST task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as \"soft targets\") achieved superior performance in all three scenarios. Addressing the issue of efficiency, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback or backward connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.", "published": "2018-09-27T16:55:58Z", "version": 2}, {"aid": "1809.11130", "authors": ["Yanting Hu", "Jie Li", "Yuanfei Huang", "Xinbo Gao"], "title": "Channel-wise and Spatial Feature Modulation Network for Single Image Super-Resolution", "url": "http://arxiv.org/pdf/1809.11130v1", "summary": "The performance of single image super-resolution has achieved significant improvement by utilizing deep convolutional neural networks (CNNs). The features in deep CNN contain different types of information which make different contributions to image reconstruction. However, most CNN-based models lack discriminative ability for different types of information and deal with them equally, which results in the representational capacity of the models being limited. On the other hand, as the depth of neural networks grows, the long-term information coming from preceding layers is easy to be weaken or lost in late layers, which is adverse to super-resolving image. To capture more informative features and maintain long-term information for image super-resolution, we propose a channel-wise and spatial feature modulation (CSFM) network in which a sequence of feature-modulation memory (FMM) modules is cascaded with a densely connected structure to transform low-resolution features to high informative features. In each FMM module, we construct a set of channel-wise and spatial attention residual (CSAR) blocks and stack them in a chain structure to dynamically modulate multi-level features in a global-and-local manner. This feature modulation strategy enables the high contribution information to be enhanced and the redundant information to be suppressed. Meanwhile, for long-term information persistence, a gated fusion (GF) node is attached at the end of the FMM module to adaptively fuse hierarchical features and distill more effective information via the dense skip connections and the gating mechanism. Extensive quantitative and qualitative evaluations on benchmark datasets illustrate the superiority of our proposed method over the state-of-the-art methods.", "published": "2018-09-28T16:29:31Z", "version": 1}, {"aid": "1810.00091", "authors": ["Kun Wan", "Boyuan Feng", "Lingwei Xie", "Yufei Ding"], "title": "Reconciling Feature-Reuse and Overfitting in DenseNet with Specialized Dropout", "url": "http://arxiv.org/pdf/1810.00091v1", "summary": "Recently convolutional neural networks (CNNs) achieve great accuracy in visual recognition tasks. DenseNet becomes one of the most popular CNN models due to its effectiveness in feature-reuse. However, like other CNN models, DenseNets also face overfitting problem if not severer. Existing dropout method can be applied but not as effective due to the introduced nonlinear connections. In particular, the property of feature-reuse in DenseNet will be impeded, and the dropout effect will be weakened by the spatial correlation inside feature maps. To address these problems, we craft the design of a specialized dropout method from three aspects, dropout location, dropout granularity, and dropout probability. The insights attained here could potentially be applied as a general approach for boosting the accuracy of other CNN models with similar nonlinear connections. Experimental results show that DenseNets with our specialized dropout method yield better accuracy compared to vanilla DenseNet and state-of-the-art CNN models, and such accuracy boost increases with the model depth.", "published": "2018-09-28T21:42:38Z", "version": 1}, {"aid": "1810.00123", "authors": ["Jesse Farebrother", "Marlos C. Machado", "Michael Bowling"], "title": "Generalization and Regularization in DQN", "url": "http://arxiv.org/pdf/1810.00123v3", "summary": "Deep reinforcement learning algorithms have shown an impressive ability to learn complex control policies in high-dimensional tasks. However, despite the ever-increasing performance on popular benchmarks, policies learned by deep reinforcement learning algorithms can struggle to generalize when evaluated in remarkably similar environments. In this paper we propose a protocol to evaluate generalization in reinforcement learning through different modes of Atari 2600 games. With that protocol we assess the generalization capabilities of DQN, one of the most traditional deep reinforcement learning algorithms, and we provide evidence suggesting that DQN overspecializes to the training environment. We then comprehensively evaluate the impact of dropout and $\\ell_2$ regularization, as well as the impact of reusing learned representations to improve the generalization capabilities of DQN. Despite regularization being largely underutilized in deep reinforcement learning, we show that it can, in fact, help DQN learn more general features. These features can be reused and fine-tuned on similar tasks, considerably improving DQN's sample efficiency.", "published": "2018-09-29T00:52:34Z", "version": 3}, {"aid": "1810.01256", "authors": ["Guanxiong Zeng", "Yang Chen", "Bo Cui", "Shan Yu"], "title": "Continual Learning of Context-dependent Processing in Neural Networks", "url": "http://arxiv.org/pdf/1810.01256v3", "summary": "Deep neural networks (DNNs) are powerful tools in learning sophisticated but fixed mapping rules between inputs and outputs, thereby limiting their application in more complex and dynamic situations in which the mapping rules are not kept the same but changing according to different contexts. To lift such limits, we developed a novel approach involving a learning algorithm, called orthogonal weights modification (OWM), with the addition of a context-dependent processing (CDP) module. We demonstrated that with OWM to overcome the problem of catastrophic forgetting, and the CDP module to learn how to reuse a feature representation and a classifier for different contexts, a single network can acquire numerous context-dependent mapping rules in an online and continual manner, with as few as $\\sim$10 samples to learn each. This should enable highly compact systems to gradually learn myriad regularities of the real world and eventually behave appropriately within it.", "published": "2018-09-29T09:45:08Z", "version": 3}, {"aid": "1810.04511", "authors": ["Lili Meng", "Bo Zhao", "Bo Chang", "Gao Huang", "Wei Sun", "Frederich Tung", "Leonid Sigal"], "title": "Interpretable Spatio-temporal Attention for Video Action Recognition", "url": "http://arxiv.org/pdf/1810.04511v2", "summary": "Inspired by the observation that humans are able to process videos efficiently by only paying attention where and when it is needed, we propose an interpretable and easy plug-in spatial-temporal attention mechanism for video action recognition. For spatial attention, we learn a saliency mask to allow the model to focus on the most salient parts of the feature maps. For temporal attention, we employ a convolutional LSTM based attention mechanism to identify the most relevant frames from an input video. Further, we propose a set of regularizers to ensure that our attention mechanism attends to coherent regions in space and time. Our model not only improves video action recognition accuracy, but also localizes discriminative regions both spatially and temporally, despite being trained in a weakly-supervised manner with only classification labels (no bounding box labels or time frame temporal labels). We evaluate our approach on several public video action recognition datasets with ablation studies. Furthermore, we quantitatively and qualitatively evaluate our model's ability to localize discriminative regions spatially and critical frames temporally. Experimental results demonstrate the efficacy of our approach, showing superior or comparable accuracy with the state-of-the-art methods while increasing model interpretability.", "published": "2018-10-01T04:23:35Z", "version": 2}, {"aid": "1810.00826", "authors": ["Keyulu Xu", "Weihua Hu", "Jure Leskovec", "Stefanie Jegelka"], "title": "How Powerful are Graph Neural Networks?", "url": "http://arxiv.org/pdf/1810.00826v3", "summary": "Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.", "published": "2018-10-01T17:11:31Z", "version": 3}, {"aid": "1810.05723", "authors": ["Ron Banner", "Yury Nahshan", "Elad Hoffer", "Daniel Soudry"], "title": "Post-training 4-bit quantization of convolution networks for rapid-deployment", "url": "http://arxiv.org/pdf/1810.05723v3", "summary": "Convolutional neural networks require significant memory bandwidth and storage for intermediate computations, apart from substantial computing resources. Neural network quantization has significant benefits in reducing the amount of intermediate results, but it often requires the full datasets and time-consuming fine tuning to recover the accuracy lost after quantization. This paper introduces the first practical 4-bit post training quantization approach: it does not involve training the quantized model (fine-tuning), nor it requires the availability of the full dataset. We target the quantization of both activations and weights and suggest three complementary methods for minimizing quantization error at the tensor level, two of whom obtain a closed-form analytical solution. Combining these methods, our approach achieves accuracy that is just a few percents less the state-of-the-art baseline across a wide range of convolutional models. The source code to replicate all experiments is available on GitHub: \\url{https://github.com/submission2019/cnn-quantization}.", "published": "2018-10-02T15:10:44Z", "version": 3}, {"aid": "1810.01620", "authors": ["Wendi Xu", "Ming Zhang"], "title": "Towards WARSHIP: Combining Components of Brain-Inspired Computing of RSH for Image Super Resolution", "url": "http://arxiv.org/pdf/1810.01620v1", "summary": "Evolution of deep learning shows that some algorithmic tricks are more durable , while others are not. To the best of our knowledge, we firstly summarize 5 more durable and complete deep learning components for vision, that is, WARSHIP. Moreover, we give a biological overview of WARSHIP, emphasizing brain-inspired computing of WARSHIP. As a step towards WARSHIP, our case study of image super resolution combines 3 components of RSH to deploy a CNN model of WARSHIP-XZNet, which performs a happy medium between speed and performance.", "published": "2018-10-03T08:10:03Z", "version": 1}, {"aid": "1810.01622", "authors": ["Wendi Xu", "Ming Zhang"], "title": "Theory of Generative Deep Learning : Probe Landscape of Empirical Error via Norm Based Capacity Control", "url": "http://arxiv.org/pdf/1810.01622v1", "summary": "Despite its remarkable empirical success as a highly competitive branch of artificial intelligence, deep learning is often blamed for its widely known low interpretation and lack of firm and rigorous mathematical foundation. However, most theoretical endeavor is devoted in discriminative deep learning case, whose complementary part is generative deep learning. To the best of our knowledge, we firstly highlight landscape of empirical error in generative case to complete the full picture through exquisite design of image super resolution under norm based capacity control. Our theoretical advance in interpretation of the training dynamic is achieved from both mathematical and biological sides.", "published": "2018-10-03T08:10:51Z", "version": 1}, {"aid": "1810.01638", "authors": ["Huan Li", "Yibo Yang", "Dongmin Chen", "Zhouchen Lin"], "title": "Optimization Algorithm Inspired Deep Neural Network Structure Design", "url": "http://arxiv.org/pdf/1810.01638v1", "summary": "Deep neural networks have been one of the dominant machine learning approaches in recent years. Several new network structures are proposed and have better performance than the traditional feedforward neural network structure. Representative ones include the skip connection structure in ResNet and the dense connection structure in DenseNet. However, it still lacks a unified guidance for the neural network structure design. In this paper, we propose the hypothesis that the neural network structure design can be inspired by optimization algorithms and a faster optimization algorithm may lead to a better neural network structure. Specifically, we prove that the propagation in the feedforward neural network with the same linear transformation in different layers is equivalent to minimizing some function using the gradient descent algorithm. Based on this observation, we replace the gradient descent algorithm with the heavy ball algorithm and Nesterov's accelerated gradient descent algorithm, which are faster and inspire us to design new and better network structures. ResNet and DenseNet can be considered as two special cases of our framework. Numerical experiments on CIFAR-10, CIFAR-100 and ImageNet verify the advantage of our optimization algorithm inspired structures over ResNet and DenseNet.", "published": "2018-10-03T08:59:41Z", "version": 1}, {"aid": "1810.01868", "authors": ["\u0141ukasz Maziarka", "Marek \u015amieja", "Aleksandra Nowak", "Jacek Tabor", "\u0141ukasz Struski", "Przemys\u0142aw Spurek"], "title": "Set Aggregation Network as a Trainable Pooling Layer", "url": "http://arxiv.org/pdf/1810.01868v3", "summary": "Global pooling, such as max- or sum-pooling, is one of the key ingredients in deep neural networks used for processing images, texts, graphs and other types of structured data. Based on the recent DeepSets architecture proposed by Zaheer et al. (NIPS 2017), we introduce a Set Aggregation Network (SAN) as an alternative global pooling layer. In contrast to typical pooling operators, SAN allows to embed a given set of features to a vector representation of arbitrary size. We show that by adjusting the size of embedding, SAN is capable of preserving the whole information from the input. In experiments, we demonstrate that replacing global pooling layer by SAN leads to the improvement of classification accuracy. Moreover, it is less prone to overfitting and can be used as a regularizer.", "published": "2018-10-03T13:20:13Z", "version": 3}, {"aid": "1810.01829", "authors": ["Masayuki Tanaka"], "title": "Weighted Sigmoid Gate Unit for an Activation Function of Deep Neural Network", "url": "http://arxiv.org/pdf/1810.01829v1", "summary": "An activation function has crucial role in a deep neural network.   A simple rectified linear unit (ReLU) are widely used for the activation function.   In this paper, a weighted sigmoid gate unit (WiG) is proposed as the activation function.   The proposed WiG consists of a multiplication of inputs and the weighted sigmoid gate.   It is shown that the WiG includes the ReLU and same activation functions as a special case.   Many activation functions have been proposed to overcome the performance of the ReLU.   In the literature, the performance is mainly evaluated with an object recognition task.   The proposed WiG is evaluated with the object recognition task and the image restoration task.   Then, the expeirmental comparisons demonstrate the proposed WiG overcomes the existing activation functions including the ReLU.", "published": "2018-10-03T16:26:24Z", "version": 1}, {"aid": "1810.01989", "authors": ["Weiming Xiang", "Patrick Musau", "Ayana A. Wild", "Diego Manzanas Lopez", "Nathaniel Hamilton", "Xiaodong Yang", "Joel Rosenfeld", "Taylor T. Johnson"], "title": "Verification for Machine Learning, Autonomy, and Neural Networks Survey", "url": "http://arxiv.org/pdf/1810.01989v1", "summary": "This survey presents an overview of verification techniques for autonomous systems, with a focus on safety-critical autonomous cyber-physical systems (CPS) and subcomponents thereof. Autonomy in CPS is enabling by recent advances in artificial intelligence (AI) and machine learning (ML) through approaches such as deep neural networks (DNNs), embedded in so-called learning enabled components (LECs) that accomplish tasks from classification to control. Recently, the formal methods and formal verification community has developed methods to characterize behaviors in these LECs with eventual goals of formally verifying specifications for LECs, and this article presents a survey of many of these recent approaches.", "published": "2018-10-03T22:12:05Z", "version": 1}, {"aid": "1810.02328", "authors": ["Gerald Friedland", "Alfredo Metere", "Mario Krell"], "title": "A Practical Approach to Sizing Neural Networks", "url": "http://arxiv.org/pdf/1810.02328v1", "summary": "Memorization is worst-case generalization. Based on MacKay's information theoretic model of supervised machine learning, this article discusses how to practically estimate the maximum size of a neural network given a training data set. First, we present four easily applicable rules to analytically determine the capacity of neural network architectures. This allows the comparison of the efficiency of different network architectures independently of a task. Second, we introduce and experimentally validate a heuristic method to estimate the neural network capacity requirement for a given dataset and labeling. This allows an estimate of the required size of a neural network for a given problem. We conclude the article with a discussion on the consequences of sizing the network wrongly, which includes both increased computation effort for training as well as reduced generalization capability.", "published": "2018-10-04T17:20:39Z", "version": 1}, {"aid": "1810.02334", "authors": ["Kyle Hsu", "Sergey Levine", "Chelsea Finn"], "title": "Unsupervised Learning via Meta-Learning", "url": "http://arxiv.org/pdf/1810.02334v6", "summary": "A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods.", "published": "2018-10-04T17:29:17Z", "version": 6}, {"aid": "1810.02440", "authors": ["Alessandro Achille", "Glen Mbeng", "Stefano Soatto"], "title": "Dynamics and Reachability of Learning Tasks", "url": "http://arxiv.org/pdf/1810.02440v2", "summary": "We compute the transition probability between two learning tasks, and show that it decomposes into two factors. The first depends on the geometry of the loss landscape of a model trained on each task, independent of any particular model used. This is related to an information theoretic distance function, but is insufficient to predict success in transfer learning, as nearby tasks can be unreachable via fine-tuning. The second factor depends on the ease of traversing the path between two tasks. With this dynamic component, we derive strict lower bounds on the complexity necessary to learn a task starting from the solution to another, which is one of the most common forms of transfer learning.", "published": "2018-10-04T22:14:40Z", "version": 2}, {"aid": "1810.02513", "authors": ["Nataniel Ruiz", "Samuel Schulter", "Manmohan Chandraker"], "title": "Learning To Simulate", "url": "http://arxiv.org/pdf/1810.02513v2", "summary": "Simulation is a useful tool in situations where training data for machine learning models is costly to annotate or even hard to acquire. In this work, we propose a reinforcement learning-based method for automatically adjusting the parameters of any (non-differentiable) simulator, thereby controlling the distribution of synthesized data in order to maximize the accuracy of a model trained on that data. In contrast to prior art that hand-crafts these simulation parameters or adjusts only parts of the available parameters, our approach fully controls the simulator with the actual underlying goal of maximizing accuracy, rather than mimicking the real data distribution or randomly generating a large volume of data. We find that our approach (i) quickly converges to the optimal simulation parameters in controlled experiments and (ii) can indeed discover good sets of parameters for an image rendering simulator in actual computer vision applications.", "published": "2018-10-05T04:11:25Z", "version": 2}, {"aid": "1810.02525", "authors": ["Peter Henderson", "Joshua Romoff", "Joelle Pineau"], "title": "Where Did My Optimum Go?: An Empirical Analysis of Gradient Descent Optimization in Policy Gradient Methods", "url": "http://arxiv.org/pdf/1810.02525v1", "summary": "Recent analyses of certain gradient descent optimization methods have shown that performance can degrade in some settings - such as with stochasticity or implicit momentum. In deep reinforcement learning (Deep RL), such optimization methods are often used for training neural networks via the temporal difference error or policy gradient. As an agent improves over time, the optimization target changes and thus the loss landscape (and local optima) change. Due to the failure modes of those methods, the ideal choice of optimizer for Deep RL remains unclear. As such, we provide an empirical analysis of the effects that a wide range of gradient descent optimizers and their hyperparameters have on policy gradient methods, a subset of Deep RL algorithms, for benchmark continuous control tasks. We find that adaptive optimizers have a narrow window of effective learning rates, diverging in other cases, and that the effectiveness of momentum varies depending on the properties of the environment. Our analysis suggests that there is significant interplay between the dynamics of the environment and Deep RL algorithm properties which aren't necessarily accounted for by traditional adaptive gradient methods. We provide suggestions for optimal settings of current methods and further lines of research based on our findings.", "published": "2018-10-05T05:52:49Z", "version": 1}, {"aid": "1810.08669", "authors": ["G. Iacca", "F. Neri", "E. Mininno", "Y. S. Ong", "M. H. Lim"], "title": "Ockham's Razor in Memetic Computing: Three Stage Optimal Memetic Exploration", "url": "http://arxiv.org/pdf/1810.08669v1", "summary": "Memetic Computing is a subject in computer science which considers complex structures as the combination of simple agents, memes, whose evolutionary interactions lead to intelligent structures capable of problem-solving. This paper focuses on Memetic Computing optimization algorithms and proposes a counter-tendency approach for algorithmic design. Research in the field tends to go in the direction of improving existing algorithms by combining different methods or through the formulation of more complicated structures. Contrary to this trend, we instead focus on simplicity, proposing a structurally simple algorithm with emphasis on processing only one solution at a time. The proposed algorithm, namely Three Stage Optimal Memetic Exploration, is composed of three memes; the first stochastic and with a long search radius, the second stochastic and with a moderate search radius and the third deterministic and with a short search radius. The bottom-up combination of the three operators by means of a natural trial and error logic, generates a robust and efficient optimizer, capable of competing with modern complex and computationally expensive algorithms. This is suggestive of the fact that complexity in algorithmic structures can be unnecessary, if not detrimental, and that simple bottom-up approaches are likely to be competitive is here invoked as an extension to Memetic Computing basing on the philosophical concept of Ockham's Razor. An extensive experimental setup on various test problems and one digital signal processing application is presented. Numerical results show that the proposed approach, despite its simplicity and low computational cost displays a very good performance on several problems, and is competitive with sophisticated algorithms representing the-state-of-the-art in computational intelligence optimization.", "published": "2018-10-05T14:14:34Z", "version": 1}, {"aid": "1810.02786", "authors": ["C. -C. Jay Kuo", "Min Zhang", "Siyang Li", "Jiali Duan", "Yueru Chen"], "title": "Interpretable Convolutional Neural Networks via Feedforward Design", "url": "http://arxiv.org/pdf/1810.02786v2", "summary": "The model parameters of convolutional neural networks (CNNs) are determined by backpropagation (BP). In this work, we propose an interpretable feedforward (FF) design without any BP as a reference. The FF design adopts a data-centric approach. It derives network parameters of the current layer based on data statistics from the output of the previous layer in a one-pass manner. To construct convolutional layers, we develop a new signal transform, called the Saab (Subspace Approximation with Adjusted Bias) transform. It is a variant of the principal component analysis (PCA) with an added bias vector to annihilate activation's nonlinearity. Multiple Saab transforms in cascade yield multiple convolutional layers. As to fully-connected (FC) layers, we construct them using a cascade of multi-stage linear least squared regressors (LSRs). The classification and robustness (against adversarial attacks) performances of BP- and FF-designed CNNs applied to the MNIST and the CIFAR-10 datasets are compared. Finally, we comment on the relationship between BP and FF designs.", "published": "2018-10-05T16:44:49Z", "version": 2}, {"aid": "1810.04028", "authors": ["Hao Zhang", "Jianwei Ma"], "title": "Hartley Spectral Pooling for Deep Learning", "url": "http://arxiv.org/pdf/1810.04028v2", "summary": "In most convolution neural networks (CNNs), downsampling hidden layers is adopted for increasing computation efficiency and the receptive field size. Such operation is commonly so-called pooling. Maximation and averaging over sliding windows (max/average pooling), and plain downsampling in the form of strided convolution are popular pooling methods. Since the pooling is a lossy procedure, a motivation of our work is to design a new pooling approach for less lossy in the dimensionality reduction. Inspired by the Fourier spectral pooling(FSP) proposed by Rippel et. al. [1], we present the Hartley transform based spectral pooling method in CNNs. Compared with FSP, the proposed spectral pooling avoids the use of complex arithmetic for frequency representation and reduces the computation. Spectral pooling preserves more structure features for network's discriminability than max and average pooling. We empirically show that Hartley spectral pooling gives rise to the convergence of training CNNs on MNIST and CIFAR-10 datasets.", "published": "2018-10-07T06:57:01Z", "version": 2}, {"aid": "1810.03105", "authors": ["Fanhua Shang", "Licheng Jiao", "Kaiwen Zhou", "James Cheng", "Yan Ren", "Yufei Jin"], "title": "ASVRG: Accelerated Proximal SVRG", "url": "http://arxiv.org/pdf/1810.03105v2", "summary": "This paper proposes an accelerated proximal stochastic variance reduced gradient (ASVRG) method, in which we design a simple and effective momentum acceleration trick. Unlike most existing accelerated stochastic variance reduction methods such as Katyusha, ASVRG has only one additional variable and one momentum parameter. Thus, ASVRG is much simpler than those methods, and has much lower per-iteration complexity. We prove that ASVRG achieves the best known oracle complexities for both strongly convex and non-strongly convex objectives. In addition, we extend ASVRG to mini-batch and non-smooth settings. We also empirically verify our theoretical results and show that the performance of ASVRG is comparable with, and sometimes even better than that of the state-of-the-art stochastic methods.", "published": "2018-10-07T08:43:05Z", "version": 2}, {"aid": "1810.03422", "authors": ["Mikael Brudfors", "Yael Balbastre", "Parashkev Nachev", "John Ashburner"], "title": "MRI Super-Resolution using Multi-Channel Total Variation", "url": "http://arxiv.org/pdf/1810.03422v6", "summary": "This paper presents a generative model for super-resolution in routine clinical magnetic resonance images (MRI), of arbitrary orientation and contrast. The model recasts the recovery of high resolution images as an inverse problem, in which a forward model simulates the slice-select profile of the MR scanner. The paper introduces a prior based on multi-channel total variation for MRI super-resolution. Bias-variance trade-off is handled by estimating hyper-parameters from the low resolution input scans. The model was validated on a large database of brain images. The validation showed that the model can improve brain segmentation, that it can recover anatomical information between images of different MR contrasts, and that it generalises well to the large variability present in MR images of different subjects. The implementation is freely available at https://github.com/brudfors/spm_superres", "published": "2018-10-08T13:14:28Z", "version": 6}, {"aid": "1810.03946", "authors": ["Xiaobo Huang"], "title": "Convolutional Neural Networks In Convolution", "url": "http://arxiv.org/pdf/1810.03946v1", "summary": "Currently, increasingly deeper neural networks have been applied to improve their accuracy. In contrast, We propose a novel wider Convolutional Neural Networks (CNN) architecture, motivated by the Multi-column Deep Neural Networks and the Network In Network(NIN), aiming for higher accuracy without input data transmutation. In our architecture, namely \"CNN In Convolution\"(CNNIC), a small CNN, instead of the original generalized liner model(GLM) based filters, is convoluted as kernel on the original image, serving as feature extracting layer of this networks. And further classifications are then carried out by a global average pooling layer and a softmax layer. Dropout and orthonormal initialization are applied to overcome training difficulties including slow convergence and over-fitting. Persuasive classification performance is demonstrated on MNIST.", "published": "2018-10-09T12:59:12Z", "version": 1}, {"aid": "1810.04246", "authors": ["Mohammed Jabi", "Marco Pedersoli", "Amar Mitiche", "Ismail Ben Ayed"], "title": "Deep clustering: On the link between discriminative models and K-means", "url": "http://arxiv.org/pdf/1810.04246v2", "summary": "In the context of recent deep clustering studies, discriminative models dominate the literature and report the most competitive performances. These models learn a deep discriminative neural network classifier in which the labels are latent. Typically, they use multinomial logistic regression posteriors and parameter regularization, as is very common in supervised learning. It is generally acknowledged that discriminative objective functions (e.g., those based on the mutual information or the KL divergence) are more flexible than generative approaches (e.g., K-means) in the sense that they make fewer assumptions about the data distributions and, typically, yield much better unsupervised deep learning results. On the surface, several recent discriminative models may seem unrelated to K-means. This study shows that these models are, in fact, equivalent to K-means under mild conditions and common posterior models and parameter regularization. We prove that, for the commonly used logistic regression posteriors, maximizing the $L_2$ regularized mutual information via an approximate alternating direction method (ADM) is equivalent to a soft and regularized K-means loss. Our theoretical analysis not only connects directly several recent state-of-the-art discriminative models to K-means, but also leads to a new soft and regularized deep K-means algorithm, which yields competitive performance on several image clustering benchmarks.", "published": "2018-10-09T21:17:09Z", "version": 2}, {"aid": "1810.05077", "authors": ["Abdullah Alchihabi", "Omer Ekmekci", "Baran B. Kivilcim", "Sharlene D. Newman", "Fatos T. Yarman Vural"], "title": "On the Brain Networks of Complex Problem Solving", "url": "http://arxiv.org/pdf/1810.05077v1", "summary": "Complex problem solving is a high level cognitive process which has been thoroughly studied over the last decade. The Tower of London (TOL) is a task that has been widely used to study problem-solving. In this study, we aim to explore the underlying cognitive network dynamics among anatomical regions of complex problem solving and its sub-phases, namely planning and execution. A new brain network construction model establishing dynamic functional brain networks using fMRI is proposed. The first step of the model is a preprocessing pipeline that manages to decrease the spatial redundancy while increasing the temporal resolution of the fMRI recordings. Then, dynamic brain networks are estimated using artificial neural networks. The network properties of the estimated brain networks are studied in order to identify regions of interest, such as hubs and subgroups of densely connected brain regions. The major similarities and dissimilarities of the network structure of planning and execution phases are highlighted. Our findings show the hubs and clusters of densely interconnected regions during both subtasks. It is observed that there are more hubs during the planning phase compared to the execution phase, and the clusters are more strongly connected during planning compared to execution.", "published": "2018-10-10T09:22:21Z", "version": 1}, {"aid": "1810.05534", "authors": ["Robert E. Kent"], "title": "Conceptual Knowledge Markup Language: An Introduction", "url": "http://arxiv.org/pdf/1810.05534v1", "summary": "Conceptual Knowledge Markup Language (CKML) is an application of XML. Earlier versions of CKML followed rather exclusively the philosophy of Conceptual Knowledge Processing (CKP), a principled approach to knowledge representation and data analysis that \"advocates methods and instruments of conceptual knowledge processing which support people in their rational thinking, judgment and acting and promote critical discussion.\" The new version of CKML continues to follow this approach, but also incorporates various principles, insights and techniques from Information Flow (IF), the logical design of distributed systems. Among other things, this allows diverse communities of discourse to compare their own information structures, as coded in logical theories, with that of other communities that share a common generic ontology. CKML incorporates the CKP ideas of concept lattice and formal context, along with the IF ideas of classification (= formal context), infomorphism, theory, interpretation and local logic. Ontology Markup Language (OML), a subset of CKML that is a self-sufficient markup language in its own right, follows the principles and ideas of Conceptual Graphs (CG). OML is used for structuring the specifications and axiomatics of metadata into ontologies. OML incorporates the CG ideas of concept, conceptual relation, conceptual graph, conceptual context, participants and ontology. The link from OML to CKML is the process of conceptual scaling, which is the interpretive transformation of ontologically structured knowledge to conceptual structured knowledge.", "published": "2018-10-10T23:41:42Z", "version": 1}, {"aid": "1810.04805", "authors": ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"], "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "url": "http://arxiv.org/pdf/1810.04805v2", "summary": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.   BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).", "published": "2018-10-11T00:50:01Z", "version": 2}, {"aid": "1810.05017", "authors": ["Tom Le Paine", "Sergio G\u00f3mez Colmenarejo", "Ziyu Wang", "Scott Reed", "Yusuf Aytar", "Tobias Pfaff", "Matt W. Hoffman", "Gabriel Barth-Maron", "Serkan Cabi", "David Budden", "Nando de Freitas"], "title": "One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL", "url": "http://arxiv.org/pdf/1810.05017v1", "summary": "Humans are experts at high-fidelity imitation -- closely mimicking a demonstration, often in one attempt. Humans use this ability to quickly solve a task instance, and to bootstrap learning of new tasks. Achieving these abilities in autonomous agents is an open problem. In this paper, we introduce an off-policy RL algorithm (MetaMimic) to narrow this gap. MetaMimic can learn both (i) policies for high-fidelity one-shot imitation of diverse novel skills, and (ii) policies that enable the agent to solve tasks more efficiently than the demonstrators. MetaMimic relies on the principle of storing all experiences in a memory and replaying these to learn massive deep neural network policies by off-policy RL. This paper introduces, to the best of our knowledge, the largest existing neural networks for deep RL and shows that larger networks with normalization are needed to achieve one-shot high-fidelity imitation on a challenging manipulation task. The results also show that both types of policy can be learned from vision, in spite of the task rewards being sparse, and without access to demonstrator actions.", "published": "2018-10-11T13:46:18Z", "version": 1}, {"aid": "1810.05148", "authors": ["Roman Novak", "Lechao Xiao", "Jaehoon Lee", "Yasaman Bahri", "Greg Yang", "Jiri Hron", "Daniel A. Abolafia", "Jeffrey Pennington", "Jascha Sohl-Dickstein"], "title": "Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes", "url": "http://arxiv.org/pdf/1810.05148v4", "summary": "There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs). This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating the FCN, but by instead evaluating the corresponding GP. In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers, and achieve state of the art results on CIFAR10 for GPs without trainable kernels. We also introduce a Monte Carlo method to estimate the GP corresponding to a given neural network architecture, even in cases where the analytic form has too many terms to be computationally feasible.   Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs with and without weight sharing are identical. As a consequence, translation equivariance, beneficial in finite channel CNNs trained with stochastic gradient descent (SGD), is guaranteed to play no role in the Bayesian treatment of the infinite channel limit - a qualitative difference between the two regimes that is not present in the FCN case. We confirm experimentally, that while in some scenarios the performance of SGD-trained finite CNNs approaches that of the corresponding GPs as the channel count increases, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs, suggesting advantages from SGD training compared to fully Bayesian parameter estimation.", "published": "2018-10-11T17:49:41Z", "version": 4}, {"aid": "1810.05680", "authors": ["Ali Borji", "Hamed R. Tavakoli", "Zoya Bylinskii"], "title": "Bottom-up Attention, Models of", "url": "http://arxiv.org/pdf/1810.05680v3", "summary": "In this review, we examine the recent progress in saliency prediction and proposed several avenues for future research. In spite of tremendous efforts and huge progress, there is still room for improvement in terms finer-grained analysis of deep saliency models, evaluation measures, datasets, annotation methods, cognitive studies, and new applications. This chapter will appear in Encyclopedia of Computational Neuroscience.", "published": "2018-10-11T17:58:35Z", "version": 3}, {"aid": "1810.05220", "authors": ["Shreeraj Jadhav", "Saad Nadeem", "Arie Kaufman"], "title": "FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels", "url": "http://arxiv.org/pdf/1810.05220v2", "summary": "We present a volume exploration framework, FeatureLego, that uses a novel voxel clustering approach for efficient selection of semantic features. We partition the input volume into a set of compact super-voxels that represent the finest selection granularity. We then perform an exhaustive clustering of these super-voxels using a graph-based clustering method. Unlike the prevalent brute-force parameter sampling approaches, we propose an efficient algorithm to perform this exhaustive clustering. By computing an exhaustive set of clusters, we aim to capture as many boundaries as possible and ensure that the user has sufficient options for efficiently selecting semantically relevant features. Furthermore, we merge all the computed clusters into a single tree of meta-clusters that can be used for hierarchical exploration. We implement an intuitive user-interface to interactively explore volumes using our clustering approach. Finally, we show the effectiveness of our framework on multiple real-world datasets of different modalities.", "published": "2018-10-11T19:40:25Z", "version": 2}, {"aid": "1810.05270", "authors": ["Zhuang Liu", "Mingjie Sun", "Tinghui Zhou", "Gao Huang", "Trevor Darrell"], "title": "Rethinking the Value of Network Pruning", "url": "http://arxiv.org/pdf/1810.05270v2", "summary": "Network pruning is widely used for reducing the heavy inference cost of deep models in low-resource settings. A typical pruning algorithm is a three-stage pipeline, i.e., training (a large model), pruning and fine-tuning. During pruning, according to a certain criterion, redundant weights are pruned and important weights are kept to best preserve the accuracy. In this work, we make several surprising observations which contradict common beliefs. For all state-of-the-art structured pruning algorithms we examined, fine-tuning a pruned model only gives comparable or worse performance than training that model with randomly initialized weights. For pruning algorithms which assume a predefined target network architecture, one can get rid of the full pipeline and directly train the target network from scratch. Our observations are consistent for multiple network architectures, datasets, and tasks, which imply that: 1) training a large, over-parameterized model is often not necessary to obtain an efficient final model, 2) learned \"important\" weights of the large model are typically not useful for the small pruned model, 3) the pruned architecture itself, rather than a set of inherited \"important\" weights, is more crucial to the efficiency in the final model, which suggests that in some cases pruning can be useful as an architecture search paradigm. Our results suggest the need for more careful baseline evaluations in future research on structured pruning methods. We also compare with the \"Lottery Ticket Hypothesis\" (Frankle & Carbin 2019), and find that with optimal learning rate, the \"winning ticket\" initialization as used in Frankle & Carbin (2019) does not bring improvement over random initialization.", "published": "2018-10-11T22:15:28Z", "version": 2}, {"aid": "1810.05291", "authors": ["Jeremy Bernstein", "Jiawei Zhao", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "signSGD with Majority Vote is Communication Efficient And Fault Tolerant", "url": "http://arxiv.org/pdf/1810.05291v3", "summary": "Training neural networks on large datasets can be accelerated by distributing the workload over a network of machines. As datasets grow ever larger, networks of hundreds or thousands of machines become economically viable. The time cost of communicating gradients limits the effectiveness of using such large machine counts, as may the increased chance of network faults. We explore a particularly simple algorithm for robust, communication-efficient learning---signSGD. Workers transmit only the sign of their gradient vector to a server, and the overall update is decided by a majority vote. This algorithm uses $32\\times$ less communication per iteration than full-precision, distributed SGD. Under natural conditions verified by experiment, we prove that signSGD converges in the large and mini-batch settings, establishing convergence for a parameter regime of Adam as a byproduct. Aggregating sign gradients by majority vote means that no individual worker has too much power. We prove that unlike SGD, majority vote is robust when up to 50% of workers behave adversarially. The class of adversaries we consider includes as special cases those that invert or randomise their gradient estimate. On the practical side, we built our distributed training system in Pytorch. Benchmarking against the state of the art collective communications library (NCCL), our framework---with the parameter server housed entirely on one machine---led to a 25% reduction in time for training resnet50 on Imagenet when using 15 AWS p3.2xlarge machines.", "published": "2018-10-11T23:50:32Z", "version": 3}, {"aid": "1810.05331", "authors": ["Xitong Gao", "Yiren Zhao", "\u0141ukasz Dudziak", "Robert Mullins", "Cheng-zhong Xu"], "title": "Dynamic Channel Pruning: Feature Boosting and Suppression", "url": "http://arxiv.org/pdf/1810.05331v2", "summary": "Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we reduce this cost by exploiting the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutional layers. In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs. We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification. Experiments show that FBS can respectively provide $5\\times$ and $2\\times$ savings in compute on VGG-16 and ResNet-18, both with less than $0.6\\%$ top-5 accuracy loss.", "published": "2018-10-12T03:00:59Z", "version": 2}, {"aid": "1810.06985", "authors": ["Yasha Savelyev"], "title": "Non-computability of human intelligence", "url": "http://arxiv.org/pdf/1810.06985v8", "summary": "We revisit the question (most famously) initiated by Turing: can human intelligence be completely modeled by a Turing machine? We show that the answer is \\emph{no}, assuming a certain weak soundness hypothesis. More specifically we show that at least some meaningful thought processes of the brain cannot be Turing computable. In particular some physical processes are not Turing computable, which is not entirely expected. There are some similarities of our argument with the well known Lucas-Penrose argument, but we work purely on the level of Turing machines, and do not use G\\\"odel's incompleteness theorem or any direct analogue. Instead we construct directly and use a weak analogue of a G\\\"odel statement for a certain system which involves our human, this allows us to side-step some (possible) meta-logical issues with their argument.", "published": "2018-10-12T20:16:21Z", "version": 8}, {"aid": "1810.07632", "authors": ["Robert E. Kent"], "title": "Conceptual Collectives", "url": "http://arxiv.org/pdf/1810.07632v1", "summary": "The notions of formal contexts and concept lattices, although introduced by Wille only ten years ago, already have proven to be of great utility in various applications such as data analysis and knowledge representation. In this paper we give arguments that Wille's original notion of formal context, although quite appealing in its simplicity, now should be replaced by a more semantic notion. This new notion of formal context entails a modified approach to concept construction. We base our arguments for these new versions of formal context and concept construction upon Wille's philosophical attitude with reference to the intensional aspect of concepts. We give a brief development of the relational theory of formal contexts and concept construction, demonstrating the equivalence of \"concept-lattice construction\" of Wille with the well-known \"completion by cuts\" of MacNeille. Generalization and abstraction of these formal contexts offers a powerful approach to knowledge representation.", "published": "2018-10-14T19:11:19Z", "version": 1}, {"aid": "1810.06966", "authors": ["Victor Minden", "Cengiz Pehlevan", "Dmitri B. Chklovskii"], "title": "Biologically Plausible Online Principal Component Analysis Without Recurrent Neural Dynamics", "url": "http://arxiv.org/pdf/1810.06966v2", "summary": "Artificial neural networks that learn to perform Principal Component Analysis (PCA) and related tasks using strictly local learning rules have been previously derived based on the principle of similarity matching: similar pairs of inputs should map to similar pairs of outputs. However, the operation of these networks (and of similar networks) requires a fixed-point iteration to determine the output corresponding to a given input, which means that dynamics must operate on a faster time scale than the variation of the input. Further, during these fast dynamics such networks typically \"disable\" learning, updating synaptic weights only once the fixed-point iteration has been resolved. Here, we derive a network for PCA-based dimensionality reduction that avoids this fast fixed-point iteration. The key novelty of our approach is a modification of the similarity matching objective to encourage near-diagonality of a synaptic weight matrix. We then approximately invert this matrix using a Taylor series approximation, replacing the previous fast iterations. In the offline setting, our algorithm corresponds to a dynamical system, the stability of which we rigorously analyze. In the online setting (i.e., with stochastic gradients), we map our algorithm to a familiar neural network architecture and give numerical results showing that our method converges at a competitive rate. The computational complexity per iteration of our online algorithm is linear in the total degrees of freedom, which is in some sense optimal.", "published": "2018-10-16T13:06:38Z", "version": 2}, {"aid": "1810.10333", "authors": ["Adityanarayanan Radhakrishnan", "Karren Yang", "Mikhail Belkin", "Caroline Uhler"], "title": "Memorization in Overparameterized Autoencoders", "url": "http://arxiv.org/pdf/1810.10333v3", "summary": "The ability of deep neural networks to generalize well in the overparameterized regime has become a subject of significant research interest. We show that overparameterized autoencoders exhibit memorization, a form of inductive bias that constrains the functions learned through the optimization process to concentrate around the training examples, although the network could in principle represent a much larger function class. In particular, we prove that single-layer fully-connected autoencoders project data onto the (nonlinear) span of the training examples. In addition, we show that deep fully-connected autoencoders learn a map that is locally contractive at the training examples, and hence iterating the autoencoder results in convergence to the training examples. Finally, we prove that depth is necessary and provide empirical evidence that it is also sufficient for memorization in convolutional autoencoders. Understanding this inductive bias may shed light on the generalization properties of overparametrized deep neural networks that are currently unexplained by classical statistical theory.", "published": "2018-10-16T17:02:54Z", "version": 3}, {"aid": "1810.07307", "authors": ["Rafik Hadfi"], "title": "Solving Tree Problems with Category Theory", "url": "http://arxiv.org/pdf/1810.07307v1", "summary": "Artificial Intelligence (AI) has long pursued models, theories, and techniques to imbue machines with human-like general intelligence. Yet even the currently predominant data-driven approaches in AI seem to be lacking humans' unique ability to solve wide ranges of problems. This situation begs the question of the existence of principles that underlie general problem-solving capabilities. We approach this question through the mathematical formulation of analogies across different problems and solutions. We focus in particular on problems that could be represented as tree-like structures. Most importantly, we adopt a category-theoretic approach in formalising tree problems as categories, and in proving the existence of equivalences across apparently unrelated problem domains. We prove the existence of a functor between the category of tree problems and the category of solutions. We also provide a weaker version of the functor by quantifying equivalences of problem categories using a metric on tree problems.", "published": "2018-10-16T23:06:48Z", "version": 1}, {"aid": "1810.07528", "authors": ["David Gunning"], "title": "Machine Common Sense Concept Paper", "url": "http://arxiv.org/pdf/1810.07528v1", "summary": "This paper summarizes some of the technical background, research ideas, and possible development strategies for achieving machine common sense. Machine common sense has long been a critical-but-missing component of Artificial Intelligence (AI). Recent advances in machine learning have resulted in new AI capabilities, but in all of these applications, machine reasoning is narrow and highly specialized. Developers must carefully train or program systems for every situation. General commonsense reasoning remains elusive. The absence of common sense prevents intelligent systems from understanding their world, behaving reasonably in unforeseen situations, communicating naturally with people, and learning from new experiences. Its absence is perhaps the most significant barrier between the narrowly focused AI applications we have today and the more general, human-like AI systems we would like to build in the future. Machine common sense remains a broad, potentially unbounded problem in AI. There are a wide range of strategies that could be employed to make progress on this difficult challenge. This paper discusses two diverse strategies for focusing development on two different machine commonsense services: (1) a service that learns from experience, like a child, to construct computational models that mimic the core domains of child cognition for objects (intuitive physics), agents (intentional actors), and places (spatial navigation); and (2) service that learns from reading the Web, like a research librarian, to construct a commonsense knowledge repository capable of answering natural language and image-based questions about commonsense phenomena.", "published": "2018-10-17T13:31:41Z", "version": 1}, {"aid": "1810.07746", "authors": ["Evan M. Yu", "Mert R. Sabuncu"], "title": "A Convolutional Autoencoder Approach to Learn Volumetric Shape Representations for Brain Structures", "url": "http://arxiv.org/pdf/1810.07746v1", "summary": "We propose a novel machine learning strategy for studying neuroanatomical shape variation. Our model works with volumetric binary segmentation images, and requires no pre-processing such as the extraction of surface points or a mesh. The learned shape descriptor is invariant to affine transformations, including shifts, rotations and scaling. Thanks to the adopted autoencoder framework, inter-subject differences are automatically enhanced in the learned representation, while intra-subject variances are minimized. Our experimental results on a shape retrieval task showed that the proposed representation outperforms a state-of-the-art benchmark for brain structures extracted from MRI scans.", "published": "2018-10-17T19:34:59Z", "version": 1}, {"aid": "1810.07842", "authors": ["Nabila Abraham", "Naimul Mefraz Khan"], "title": "A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation", "url": "http://arxiv.org/pdf/1810.07842v1", "summary": "We propose a generalized focal loss function based on the Tversky index to address the issue of data imbalance in medical image segmentation. Compared to the commonly used Dice loss, our loss function achieves a better trade off between precision and recall when training on small structures such as lesions. To evaluate our loss function, we improve the attention U-Net model by incorporating an image pyramid to preserve contextual features. We experiment on the BUS 2017 dataset and ISIC 2018 dataset where lesions occupy 4.84% and 21.4% of the images area and improve segmentation accuracy when compared to the standard U-Net by 25.7% and 3.6%, respectively.", "published": "2018-10-18T00:07:33Z", "version": 1}, {"aid": "1810.07960", "authors": ["Bolun Zheng", "Rui Sun", "Xiang Tian", "Yaowu Chen"], "title": "S-Net: A Scalable Convolutional Neural Network for JPEG Compression Artifact Reduction", "url": "http://arxiv.org/pdf/1810.07960v1", "summary": "Recent studies have used deep residual convolutional neural networks (CNNs) for JPEG compression artifact reduction. This study proposes a scalable CNN called S-Net. Our approach effectively adjusts the network scale dynamically in a multitask system for real-time operation with little performance loss. It offers a simple and direct technique to evaluate the performance gains obtained with increasing network depth, and it is helpful for removing redundant network layers to maximize the network efficiency. We implement our architecture using the Keras framework with the TensorFlow backend on an NVIDIA K80 GPU server. We train our models on the DIV2K dataset and evaluate their performance on public benchmark datasets. To validate the generality and universality of the proposed method, we created and utilized a new dataset, called WIN143, for over-processed images evaluation. Experimental results indicate that our proposed approach outperforms other CNN-based methods and achieves state-of-the-art performance.", "published": "2018-10-18T09:21:44Z", "version": 1}, {"aid": "1810.08100", "authors": ["Lijun Wang", "Xiaohui Shen", "Jianming Zhang", "Oliver Wang", "Zhe Lin", "Chih-Yao Hsieh", "Sarah Kong", "Huchuan Lu"], "title": "DeepLens: Shallow Depth Of Field From A Single Image", "url": "http://arxiv.org/pdf/1810.08100v1", "summary": "We aim to generate high resolution shallow depth-of-field (DoF) images from a single all-in-focus image with controllable focal distance and aperture size. To achieve this, we propose a novel neural network model comprised of a depth prediction module, a lens blur module, and a guided upsampling module. All modules are differentiable and are learned from data. To train our depth prediction module, we collect a dataset of 2462 RGB-D images captured by mobile phones with a dual-lens camera, and use existing segmentation datasets to improve border prediction. We further leverage a synthetic dataset with known depth to supervise the lens blur and guided upsampling modules. The effectiveness of our system and training strategies are verified in the experiments. Our method can generate high-quality shallow DoF images at high resolution, and produces significantly fewer artifacts than the baselines and existing solutions for single image shallow DoF synthesis. Compared with the iPhone portrait mode, which is a state-of-the-art shallow DoF solution based on a dual-lens depth camera, our method generates comparable results, while allowing for greater flexibility to choose focal points and aperture size, and is not limited to one capture setup.", "published": "2018-10-18T15:14:41Z", "version": 1}, {"aid": "1810.08163", "authors": ["Steven Hansen", "Pablo Sprechmann", "Alexander Pritzel", "Andr\u00e9 Barreto", "Charles Blundell"], "title": "Fast deep reinforcement learning using online adjustments from the past", "url": "http://arxiv.org/pdf/1810.08163v1", "summary": "We propose Ephemeral Value Adjusments (EVA): a means of allowing deep reinforcement learning agents to rapidly adapt to experience in their replay buffer. EVA shifts the value predicted by a neural network with an estimate of the value function found by planning over experience tuples from the replay buffer near the current state. EVA combines a number of recent ideas around combining episodic memory-like structures into reinforcement learning agents: slot-based storage, content-based retrieval, and memory-based planning. We show that EVAis performant on a demonstration task and Atari games.", "published": "2018-10-18T17:00:20Z", "version": 1}, {"aid": "1810.08170", "authors": ["Daniel Rodr\u00edguez-Chavarr\u00eda", "Miguel A. Guti\u00e9rrez-Naranjo", "Joaqu\u00edn Borrego-D\u00edaz"], "title": "Logic Negation with Spiking Neural P Systems", "url": "http://arxiv.org/pdf/1810.08170v2", "summary": "Nowadays, the success of neural networks as reasoning systems is doubtless. Nonetheless, one of the drawbacks of such reasoning systems is that they work as black-boxes and the acquired knowledge is not human readable. In this paper, we present a new step in order to close the gap between connectionist and logic based reasoning systems. We show that two of the most used inference rules for obtaining negative information in rule based reasoning systems, the so-called Closed World Assumption and Negation as Finite Failure can be characterized by means of spiking neural P systems, a formal model of the third generation of neural networks born in the framework of membrane computing.", "published": "2018-10-18T17:22:30Z", "version": 2}, {"aid": "1810.08229", "authors": ["Qiaoying Huang", "Dong Yang", "Pengxiang Wu", "Hui Qu", "Jingru Yi", "Dimitris Metaxas"], "title": "MRI Reconstruction via Cascaded Channel-wise Attention Network", "url": "http://arxiv.org/pdf/1810.08229v2", "summary": "We consider an MRI reconstruction problem with input of k-space data at a very low undersampled rate. This can practically benefit patient due to reduced time of MRI scan, but it is also challenging since quality of reconstruction may be compromised. Currently, deep learning based methods dominate MRI reconstruction over traditional approaches such as Compressed Sensing, but they rarely show satisfactory performance in the case of low undersampled k-space data. One explanation is that these methods treat channel-wise features equally, which results in degraded representation ability of the neural network. To solve this problem, we propose a new model called MRI Cascaded Channel-wise Attention Network (MICCAN), highlighted by three components: (i) a variant of U-net with Channel-wise Attention (UCA) module, (ii) a long skip connection and (iii) a combined loss. Our model is able to attend to salient information by filtering irrelevant features and also concentrate on high-frequency information by enforcing low-frequency information bypassed to the final output. We conduct both quantitative evaluation and qualitative analysis of our method on a cardiac dataset. The experiment shows that our method achieves very promising results in terms of three common metrics on the MRI reconstruction with low undersampled k-space data.", "published": "2018-10-18T18:37:37Z", "version": 2}, {"aid": "1810.08831", "authors": ["Robert E. Kent"], "title": "Enriched Interpretation", "url": "http://arxiv.org/pdf/1810.08831v1", "summary": "The theory introduced, presented and developed in this paper, is concerned with an enriched extension of the theory of Rough Sets pioneered by Zdzislaw Pawlak. The enrichment discussed here is in the sense of valuated categories as developed by F.W. Lawvere. This paper relates Rough Sets to an abstraction of the theory of Fuzzy Sets pioneered by Lotfi Zadeh, and provides a natural foundation for \"soft computation\". To paraphrase Lotfi Zadeh, the impetus for the transition from a hard theory to a soft theory derives from the fact that both the generality of a theory and its applicability to real-world problems are substantially enhanced by replacing various hard concepts with their soft counterparts. Here we discuss the corresponding enriched notions for indiscernibility, subsets, upper/lower approximations, and rough sets. Throughout, we indicate linkages with the theory of Formal Concept Analysis pioneered by Rudolf Wille. We pay particular attention to the all-important notion of a \"linguistic variable\" - developing its enriched extension, comparing it with the notion of conceptual scale from Formal Concept Analysis, and discussing the pragmatic issues of its creation and use in the interpretation of data. These pragmatic issues are exemplified by the discovery, conceptual analysis, interpretation, and categorization of networked information resources in WAVE, the Web Analysis and Visualization Environment currently being developed for the management and interpretation of the universe of resource information distributed over the World-Wide Web.", "published": "2018-10-20T17:41:16Z", "version": 1}, {"aid": "1810.09028", "authors": ["Michael Schaarschmidt", "Sven Mika", "Kai Fricke", "Eiko Yoneki"], "title": "RLgraph: Modular Computation Graphs for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1810.09028v2", "summary": "Reinforcement learning (RL) tasks are challenging to implement, execute and test due to algorithmic instability, hyper-parameter sensitivity, and heterogeneous distributed communication patterns. We argue for the separation of logical component composition, backend graph definition, and distributed execution. To this end, we introduce RLgraph, a library for designing and executing reinforcement learning tasks in both static graph and define-by-run paradigms. The resulting implementations are robust, incrementally testable, and yield high performance across different deep learning frameworks and distributed backends.", "published": "2018-10-21T21:12:06Z", "version": 2}, {"aid": "1810.09038", "authors": ["Kenji Kawaguchi", "Yoshua Bengio"], "title": "Depth with Nonlinearity Creates No Bad Local Minima in ResNets", "url": "http://arxiv.org/pdf/1810.09038v3", "summary": "In this paper, we prove that depth with nonlinearity creates no bad local minima in a type of arbitrarily deep ResNets with arbitrary nonlinear activation functions, in the sense that the values of all local minima are no worse than the global minimum value of corresponding classical machine-learning models, and are guaranteed to further improve via residual representations. As a result, this paper provides an affirmative answer to an open question stated in a paper in the conference on Neural Information Processing Systems 2018. This paper advances the optimization theory of deep learning only for ResNets and not for other network architectures.", "published": "2018-10-21T22:38:32Z", "version": 3}, {"aid": "1810.10353", "authors": ["Yang Li", "Mengying Lei", "Xianrui Zhang", "Weigang Cui", "Yuzhu Guo", "Ting-Wen Huang", "Hua-Liang Wei"], "title": "Boosted Convolutional Neural Networks for Motor Imagery EEG Decoding with Multiwavelet-based Time-Frequency Conditional Granger Causality Analysis", "url": "http://arxiv.org/pdf/1810.10353v1", "summary": "Decoding EEG signals of different mental states is a challenging task for brain-computer interfaces (BCIs) due to nonstationarity of perceptual decision processes. This paper presents a novel boosted convolutional neural networks (ConvNets) decoding scheme for motor imagery (MI) EEG signals assisted by the multiwavelet-based time-frequency (TF) causality analysis. Specifically, multiwavelet basis functions are first combined with Geweke spectral measure to obtain high-resolution TF-conditional Granger causality (CGC) representations, where a regularized orthogonal forward regression (ROFR) algorithm is adopted to detect a parsimonious model with good generalization performance. The causality images for network input preserving time, frequency and location information of connectivity are then designed based on the TF-CGC distributions of alpha band multichannel EEG signals. Further constructed boosted ConvNets by using spatio-temporal convolutions as well as advances in deep learning including cropping and boosting methods, to extract discriminative causality features and classify MI tasks. Our proposed approach outperforms the competition winner algorithm with 12.15% increase in average accuracy and 74.02% decrease in associated inter subject standard deviation for the same binary classification on BCI competition-IV dataset-IIa. Experiment results indicate that the boosted ConvNets with causality images works well in decoding MI-EEG signals and provides a promising framework for developing MI-BCI systems.", "published": "2018-10-22T07:39:12Z", "version": 1}, {"aid": "1810.09136", "authors": ["Eric Nalisnick", "Akihiro Matsukawa", "Yee Whye Teh", "Dilan Gorur", "Balaji Lakshminarayanan"], "title": "Do Deep Generative Models Know What They Don't Know?", "url": "http://arxiv.org/pdf/1810.09136v3", "summary": "A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are widely viewed to be robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs. In this paper we challenge this assumption. We find that the density learned by flow-based models, VAEs, and PixelCNNs cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. Moreover, we find evidence of this phenomenon when pairing several popular image data sets: FashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN. To investigate this curious behavior, we focus analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find such behavior persists even when we restrict the flows to constant-volume transformations. These transformations admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature. Our results caution against using the density estimates from deep generative models to identify inputs similar to the training distribution until their behavior for out-of-distribution inputs is better understood.", "published": "2018-10-22T08:32:02Z", "version": 3}, {"aid": "1810.09391", "authors": ["Constantine Dovrolis"], "title": "A neuro-inspired architecture for unsupervised continual learning based on online clustering and hierarchical predictive coding", "url": "http://arxiv.org/pdf/1810.09391v1", "summary": "We propose that the Continual Learning desiderata can be achieved through a neuro-inspired architecture, grounded on Mountcastle's cortical column hypothesis. The proposed architecture involves a single module, called Self-Taught Associative Memory (STAM), which models the function of a cortical column. STAMs are repeated in multi-level hierarchies involving feedforward, lateral and feedback connections. STAM networks learn in an unsupervised manner, based on a combination of online clustering and hierarchical predictive coding. This short paper only presents the architecture and its connections with neuroscience. A mathematical formulation and experimental results will be presented in an extended version of this paper.", "published": "2018-10-22T16:27:21Z", "version": 1}, {"aid": "1810.09821", "authors": ["Qibin Hou", "Peng-Tao Jiang", "Yunchao Wei", "Ming-Ming Cheng"], "title": "Self-Erasing Network for Integral Object Attention", "url": "http://arxiv.org/pdf/1810.09821v1", "summary": "Recently, adversarial erasing for weakly-supervised object attention has been deeply studied due to its capability in localizing integral object regions. However, such a strategy raises one key problem that attention regions will gradually expand to non-object regions as training iterations continue, which significantly decreases the quality of the produced attention maps. To tackle such an issue as well as promote the quality of object attention, we introduce a simple yet effective Self-Erasing Network (SeeNet) to prohibit attentions from spreading to unexpected background regions. In particular, SeeNet leverages two self-erasing strategies to encourage networks to use reliable object and background cues for learning to attention. In this way, integral object regions can be effectively highlighted without including much more background regions. To test the quality of the generated attention maps, we employ the mined object regions as heuristic cues for learning semantic segmentation models. Experiments on Pascal VOC well demonstrate the superiority of our SeeNet over other state-of-the-art methods.", "published": "2018-10-23T12:53:56Z", "version": 1}, {"aid": "1810.09849", "authors": ["Zhengsu Chen Jianwei Niu Qi Tian"], "title": "DropFilter: Dropout for Convolutions", "url": "http://arxiv.org/pdf/1810.09849v1", "summary": "Using a large number of parameters , deep neural networks have achieved remarkable performance on computer vison and natural language processing tasks. However the networks usually suffer from overfitting by using too much parameters. Dropout is a widely use method to deal with overfitting. Although dropout can significantly regularize densely connected layers in neural networks, it leads to suboptimal results when using for convolutional layers. To track this problem, we propose DropFilter, a new dropout method for convolutional layers. DropFilter randomly suppresses the outputs of some filters. Because it is observed that co-adaptions are more likely to occurs inter filters rather than intra filters in convolutional layers. Using DropFilter, we remarkably improve the performance of convolutional networks on CIFAR and ImageNet.", "published": "2018-10-23T13:42:25Z", "version": 1}, {"aid": "1810.09945", "authors": ["Armin W. Thomas", "Hauke R. Heekeren", "Klaus-Robert M\u00fcller", "Wojciech Samek"], "title": "Analyzing Neuroimaging Data Through Recurrent Deep Learning Models", "url": "http://arxiv.org/pdf/1810.09945v2", "summary": "The application of deep learning (DL) models to neuroimaging data poses several challenges, due to the high dimensionality, low sample size and complex temporo-spatial dependency structure of these datasets. Even further, DL models act as as black-box models, impeding insight into the association of cognitive state and brain activity. To approach these challenges, we introduce the DeepLight framework, which utilizes long short-term memory (LSTM) based DL models to analyze whole-brain functional Magnetic Resonance Imaging (fMRI) data. To decode a cognitive state (e.g., seeing the image of a house), DeepLight separates the fMRI volume into a sequence of axial brain slices, which is then sequentially processed by an LSTM. To maintain interpretability, DeepLight adapts the layer-wise relevance propagation (LRP) technique. Thereby, decomposing its decoding decision into the contributions of the single input voxels to this decision. Importantly, the decomposition is performed on the level of single fMRI volumes, enabling DeepLight to study the associations between cognitive state and brain activity on several levels of data granularity, from the level of the group down to the level of single time points. To demonstrate the versatility of DeepLight, we apply it to a large fMRI dataset of the Human Connectome Project. We show that DeepLight outperforms conventional approaches of uni- and multivariate fMRI analysis in decoding the cognitive states and in identifying the physiologically appropriate brain regions associated with these states. We further demonstrate DeepLight's ability to study the fine-grained temporo-spatial variability of brain activity over sequences of single fMRI samples.", "published": "2018-10-23T16:23:27Z", "version": 2}, {"aid": "1810.10531", "authors": ["Andrew M. Saxe", "James L. McClelland", "Surya Ganguli"], "title": "A mathematical theory of semantic development in deep neural networks", "url": "http://arxiv.org/pdf/1810.10531v1", "summary": "An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: what are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep learning dynamics to give rise to these regularities.", "published": "2018-10-23T22:20:27Z", "version": 1}, {"aid": "1810.10126", "authors": ["Yang Li", "Lukasz Kaiser", "Samy Bengio", "Si Si"], "title": "Area Attention", "url": "http://arxiv.org/pdf/1810.10126v7", "summary": "Existing attention mechanisms are trained to attend to individual items in a collection (the memory) with a predefined, fixed granularity, e.g., a word token or an image grid. We propose area attention: a way to attend to areas in the memory, where each area contains a group of items that are structurally adjacent, e.g., spatially for a 2D memory such as images, or temporally for a 1D memory such as natural language sentences. Importantly, the shape and the size of an area are dynamically determined via learning, which enables a model to attend to information with varying granularity. Area attention can easily work with existing model architectures such as multi-head attention for simultaneously attending to multiple areas in the memory. We evaluate area attention on two tasks: neural machine translation (both character and token-level) and image captioning, and improve upon strong (state-of-the-art) baselines in all the cases. These improvements are obtainable with a basic form of area attention that is parameter free.", "published": "2018-10-23T23:14:27Z", "version": 7}, {"aid": "1811.02667", "authors": ["Pablo Ribalta Lorenzo", "Lukasz Tulczyjew", "Michal Marcinkiewicz", "Jakub Nalepa"], "title": "Band Selection from Hyperspectral Images Using Attention-based Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1811.02667v3", "summary": "This paper introduces new attention-based convolutional neural networks for selecting bands from hyperspectral images. The proposed approach re-uses convolutional activations at different depths, identifying the most informative regions of the spectrum with the help of gating mechanisms. Our attention techniques are modular and easy to implement, and they can be seamlessly trained end-to-end using gradient descent. Our rigorous experiments showed that deep models equipped with the attention mechanism deliver high-quality classification, and repeatedly identify significant bands in the training data, permitting the creation of refined and extremely compact sets that retain the most meaningful features.", "published": "2018-10-24T19:32:48Z", "version": 3}, {"aid": "1810.10853", "authors": ["Gabriele Valvano", "Nicola Martini", "Andrea Leo", "Gianmarco Santini", "Daniele Della Latta", "Emiliano Ricciardi", "Dante Chiappino"], "title": "Training of a Skull-Stripping Neural Network with efficient data augmentation", "url": "http://arxiv.org/pdf/1810.10853v1", "summary": "Skull-stripping methods aim to remove the non-brain tissue from acquisition of brain scans in magnetic resonance (MR) imaging. Although several methods sharing this common purpose have been presented in literature, they all suffer from the great variability of the MR images. In this work we propose a novel approach based on Convolutional Neural Networks to automatically perform the brain extraction obtaining cutting-edge performance in the NFBS public database. Additionally, we focus on the efficient training of the neural network designing an effective data augmentation pipeline. Obtained results are evaluated through Dice metric, obtaining a value of 96.5%, and processing time, with 4.5s per volume.", "published": "2018-10-25T13:01:27Z", "version": 1}, {"aid": "1810.10863", "authors": ["Christopher Bowles", "Liang Chen", "Ricardo Guerrero", "Paul Bentley", "Roger Gunn", "Alexander Hammers", "David Alexander Dickie", "Maria Vald\u00e9s Hern\u00e1ndez", "Joanna Wardlaw", "Daniel Rueckert"], "title": "GAN Augmentation: Augmenting Training Data using Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1810.10863v1", "summary": "One of the biggest issues facing the use of machine learning in medical imaging is the lack of availability of large, labelled datasets. The annotation of medical images is not only expensive and time consuming but also highly dependent on the availability of expert observers. The limited amount of training data can inhibit the performance of supervised machine learning algorithms which often need very large quantities of data on which to train to avoid overfitting. So far, much effort has been directed at extracting as much information as possible from what data is available. Generative Adversarial Networks (GANs) offer a novel way to unlock additional information from a dataset by generating synthetic samples with the appearance of real images. This paper demonstrates the feasibility of introducing GAN derived synthetic data to the training datasets in two brain segmentation tasks, leading to improvements in Dice Similarity Coefficient (DSC) of between 1 and 5 percentage points under different conditions, with the strongest effects seen fewer than ten training image stacks are available.", "published": "2018-10-25T13:17:33Z", "version": 1}, {"aid": "1810.11190", "authors": ["Ajay Patel", "Alexander Sands", "Chris Callison-Burch", "Marianna Apidianaki"], "title": "Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package", "url": "http://arxiv.org/pdf/1810.11190v1", "summary": "Vector space embedding models like word2vec, GloVe, fastText, and ELMo are extremely popular representations in natural language processing (NLP) applications. We present Magnitude, a fast, lightweight tool for utilizing and processing embeddings. Magnitude is an open source Python package with a compact vector storage file format that allows for efficient manipulation of huge numbers of embeddings. Magnitude performs common operations up to 60 to 6,000 times faster than Gensim. Magnitude introduces several novel features for improved robustness like out-of-vocabulary lookups.", "published": "2018-10-26T05:04:07Z", "version": 1}, {"aid": "1810.11335", "authors": ["Jirong Yi", "Anh Duc Le", "Tianming Wang", "Xiaodong Wu", "Weiyu Xu"], "title": "Outlier Detection using Generative Models with Theoretical Performance Guarantees", "url": "http://arxiv.org/pdf/1810.11335v1", "summary": "This paper considers the problem of recovering signals from compressed measurements contaminated with sparse outliers, which has arisen in many applications. In this paper, we propose a generative model neural network approach for reconstructing the ground truth signals under sparse outliers. We propose an iterative alternating direction method of multipliers (ADMM) algorithm for solving the outlier detection problem via $\\ell_1$ norm minimization, and a gradient descent algorithm for solving the outlier detection problem via squared $\\ell_1$ norm minimization. We establish the recovery guarantees for reconstruction of signals using generative models in the presence of outliers, and give an upper bound on the number of outliers allowed for recovery. Our results are applicable to both the linear generator neural network and the nonlinear generator neural network with an arbitrary number of layers. We conduct extensive experiments using variational auto-encoder and deep convolutional generative adversarial networks, and the experimental results show that the signals can be successfully reconstructed under outliers using our approach. Our approach outperforms the traditional Lasso and $\\ell_2$ minimization approach.", "published": "2018-10-26T14:11:04Z", "version": 1}, {"aid": "1810.11393", "authors": ["Jo\u00e3o Sacramento", "Rui Ponte Costa", "Yoshua Bengio", "Walter Senn"], "title": "Dendritic cortical microcircuits approximate the backpropagation algorithm", "url": "http://arxiv.org/pdf/1810.11393v1", "summary": "Deep learning has seen remarkable developments over the last years, many of them inspired by neuroscience. However, the main learning mechanism behind these advances - error backpropagation - appears to be at odds with neurobiology. Here, we introduce a multilayer neuronal network model with simplified dendritic compartments in which error-driven synaptic plasticity adapts the network towards a global desired output. In contrast to previous work our model does not require separate phases and synaptic learning is driven by local dendritic prediction errors continuously in time. Such errors originate at apical dendrites and occur due to a mismatch between predictive input from lateral interneurons and activity from actual top-down feedback. Through the use of simple dendritic compartments and different cell-types our model can represent both error and normal activity within a pyramidal neuron. We demonstrate the learning capabilities of the model in regression and classification tasks, and show analytically that it approximates the error backpropagation algorithm. Moreover, our framework is consistent with recent observations of learning between brain areas and the architecture of cortical microcircuits. Overall, we introduce a novel view of learning on dendritic cortical circuits and on how the brain may solve the long-standing synaptic credit assignment problem.", "published": "2018-10-26T15:40:58Z", "version": 1}, {"aid": "1810.11579", "authors": ["Yunpeng Chen", "Yannis Kalantidis", "Jianshu Li", "Shuicheng Yan", "Jiashi Feng"], "title": "$A^2$-Nets: Double Attention Networks", "url": "http://arxiv.org/pdf/1810.11579v1", "summary": "Learning to capture long-range relations is fundamental to image/video recognition. Existing CNN models generally rely on increasing depth to model such relations which is highly inefficient. In this work, we propose the \"double attention block\", a novel component that aggregates and propagates informative global features from the entire spatio-temporal space of input images/videos, enabling subsequent convolution layers to access features from the entire space efficiently. The component is designed with a double attention mechanism in two steps, where the first step gathers features from the entire space into a compact set through second-order attention pooling and the second step adaptively selects and distributes features to each location via another attention. The proposed double attention block is easy to adopt and can be plugged into existing deep neural networks conveniently. We conduct extensive ablation studies and experiments on both image and video recognition tasks for evaluating its performance. On the image recognition task, a ResNet-50 equipped with our double attention blocks outperforms a much larger ResNet-152 architecture on ImageNet-1k dataset with over 40% less the number of parameters and less FLOPs. On the action recognition task, our proposed model achieves the state-of-the-art results on the Kinetics and UCF-101 datasets with significantly higher efficiency than recent works.", "published": "2018-10-27T02:32:22Z", "version": 1}, {"aid": "1810.11594", "authors": ["Brian Hu", "Stefan Mihalas"], "title": "Convolutional neural networks with extra-classical receptive fields", "url": "http://arxiv.org/pdf/1810.11594v1", "summary": "Convolutional neural networks (CNNs) have had great success in many real-world applications and have also been used to model visual processing in the brain. However, these networks are quite brittle - small changes in the input image can dramatically change a network's output prediction. In contrast to what is known from biology, these networks largely rely on feedforward connections, ignoring the influence of recurrent connections. They also focus on supervised rather than unsupervised learning. To address these issues, we combine traditional supervised learning via backpropagation with a specialized unsupervised learning rule to learn lateral connections between neurons within a convolutional neural network. These connections have been shown to optimally integrate information from the surround, generating extra-classical receptive fields for the neurons in our new proposed model (CNNEx). Models with optimal lateral connections are more robust to noise and achieve better performance on noisy versions of the MNIST and CIFAR-10 datasets. Resistance to noise can be further improved by combining our model with additional regularization techniques such as dropout and weight decay. Although the image statistics of MNIST and CIFAR-10 differ greatly, the same unsupervised learning rule generalized to both datasets. Our results demonstrate the potential usefulness of combining supervised and unsupervised learning techniques and suggest that the integration of lateral connections into convolutional neural networks is an important area of future research.", "published": "2018-10-27T04:15:50Z", "version": 1}, {"aid": "1810.11654", "authors": ["Andriy Myronenko"], "title": "3D MRI brain tumor segmentation using autoencoder regularization", "url": "http://arxiv.org/pdf/1810.11654v3", "summary": "Automated segmentation of brain tumors from 3D magnetic resonance images (MRIs) is necessary for the diagnosis, monitoring, and treatment planning of the disease. Manual delineation practices require anatomical knowledge, are expensive, time consuming and can be inaccurate due to human error. Here, we describe a semantic segmentation network for tumor subregion segmentation from 3D MRIs based on encoder-decoder architecture. Due to a limited training dataset size, a variational auto-encoder branch is added to reconstruct the input image itself in order to regularize the shared decoder and impose additional constraints on its layers. The current approach won 1st place in the BraTS 2018 challenge.", "published": "2018-10-27T14:42:13Z", "version": 3}, {"aid": "1811.03009", "authors": ["Yana B. Feygin", "Kelly Morris", "Roman V. Yampolskiy"], "title": "Uploading Brain into Computer: Whom to Upload First?", "url": "http://arxiv.org/pdf/1811.03009v1", "summary": "The final goal of the intelligence augmentation process is a complete merger of biological brains and computers allowing for integration and mutual enhancement between computer's speed and memory and human's intelligence. This process, known as uploading, analyzes human brain in detail sufficient to understand its working patterns and makes it possible to simulate said brain on a computer. As it is likely that such simulations would quickly evolve or be modified to achieve superintelligence it is very important to make sure that the first brain chosen for such a procedure is a suitable one. In this paper, we attempt to answer the question: Whom to upload first?", "published": "2018-10-27T19:57:47Z", "version": 1}, {"aid": "1810.11787", "authors": ["Karanbir Chahal", "Manraj Singh Grover", "Kuntal Dey"], "title": "A Hitchhiker's Guide On Distributed Training of Deep Neural Networks", "url": "http://arxiv.org/pdf/1810.11787v1", "summary": "Deep learning has led to tremendous advancements in the field of Artificial Intelligence. One caveat however is the substantial amount of compute needed to train these deep learning models. Training a benchmark dataset like ImageNet on a single machine with a modern GPU can take upto a week, distributing training on multiple machines has been observed to drastically bring this time down. Recent work has brought down ImageNet training time to a time as low as 4 minutes by using a cluster of 2048 GPUs. This paper surveys the various algorithms and techniques used to distribute training and presents the current state of the art for a modern distributed training framework. More specifically, we explore the synchronous and asynchronous variants of distributed Stochastic Gradient Descent, various All Reduce gradient aggregation strategies and best practices for obtaining higher throughout and lower latency over a cluster such as mixed precision training, large batch training and gradient compression.", "published": "2018-10-28T09:37:47Z", "version": 1}, {"aid": "1810.11921", "authors": ["Weiping Song", "Chence Shi", "Zhiping Xiao", "Zhijian Duan", "Yewen Xu", "Ming Zhang", "Jian Tang"], "title": "AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks", "url": "http://arxiv.org/pdf/1810.11921v2", "summary": "Click-through rate (CTR) prediction, which aims to predict the probability of a user clicking on an ad or an item, is critical to many online applications such as online advertising and recommender systems. The problem is very challenging since (1) the input features (e.g., the user id, user age, item id, item category) are usually sparse and high-dimensional, and (2) an effective prediction relies on high-order combinatorial features (\\textit{a.k.a.} cross features), which are very time-consuming to hand-craft by domain experts and are impossible to be enumerated. Therefore, there have been efforts in finding low-dimensional representations of the sparse and high-dimensional raw features and their meaningful combinations. In this paper, we propose an effective and efficient method called the \\emph{AutoInt} to automatically learn the high-order feature interactions of input features. Our proposed algorithm is very general, which can be applied to both numerical and categorical input features. Specifically, we map both the numerical and categorical features into the same low-dimensional space. Afterwards, a multi-head self-attentive neural network with residual connections is proposed to explicitly model the feature interactions in the low-dimensional space. With different layers of the multi-head self-attentive neural networks, different orders of feature combinations of input features can be modeled. The whole model can be efficiently fit on large-scale raw data in an end-to-end fashion. Experimental results on four real-world datasets show that our proposed approach not only outperforms existing state-of-the-art approaches for prediction but also offers good explainability. Code is available at: \\url{https://github.com/DeepGraphLearning/RecommenderSystems}.", "published": "2018-10-29T01:56:25Z", "version": 2}, {"aid": "1810.12282", "authors": ["Charles Packer", "Katelyn Gao", "Jernej Kos", "Philipp Kr\u00e4henb\u00fchl", "Vladlen Koltun", "Dawn Song"], "title": "Assessing Generalization in Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1810.12282v2", "summary": "Deep reinforcement learning (RL) has achieved breakthrough results on many tasks, but agents often fail to generalize beyond the environment they were trained in. As a result, deep RL algorithms that promote generalization are receiving increasing attention. However, works in this area use a wide variety of tasks and experimental setups for evaluation. The literature lacks a controlled assessment of the merits of different generalization schemes. Our aim is to catalyze community-wide progress on generalization in deep RL. To this end, we present a benchmark and experimental protocol, and conduct a systematic empirical study. Our framework contains a diverse set of environments, our methodology covers both in-distribution and out-of-distribution generalization, and our evaluation includes deep RL algorithms that specifically tackle generalization. Our key finding is that `vanilla' deep RL algorithms generalize better than specialized schemes that were proposed specifically to tackle generalization.", "published": "2018-10-29T17:51:46Z", "version": 2}, {"aid": "1810.12575", "authors": ["Tobias Pl\u00f6tz", "Stefan Roth"], "title": "Neural Nearest Neighbors Networks", "url": "http://arxiv.org/pdf/1810.12575v1", "summary": "Non-local methods exploiting the self-similarity of natural signals have been well studied, for example in image analysis and restoration. Existing approaches, however, rely on k-nearest neighbors (KNN) matching in a fixed feature space. The main hurdle in optimizing this feature space w.r.t. application performance is the non-differentiability of the KNN selection rule. To overcome this, we propose a continuous deterministic relaxation of KNN selection that maintains differentiability w.r.t. pairwise distances, but retains the original KNN as the limit of a temperature parameter approaching zero. To exploit our relaxation, we propose the neural nearest neighbors block (N3 block), a novel non-local processing layer that leverages the principle of self-similarity and can be used as building block in modern neural network architectures. We show its effectiveness for the set reasoning task of correspondence classification as well as for image restoration, including image denoising and single image super-resolution, where we outperform strong convolutional neural network (CNN) baselines and recent non-local models that rely on KNN selection in hand-chosen features spaces.", "published": "2018-10-30T08:32:47Z", "version": 1}, {"aid": "1810.12640", "authors": ["Lyes Khacef", "Bernard Girau", "Nicolas Rougier", "Andres Upegui", "Benoit Miramond"], "title": "Neuromorphic hardware as a self-organizing computing system", "url": "http://arxiv.org/pdf/1810.12640v1", "summary": "This paper presents the self-organized neuromorphic architecture named SOMA. The objective is to study neural-based self-organization in computing systems and to prove the feasibility of a self-organizing hardware structure. Considering that these properties emerge from large scale and fully connected neural maps, we will focus on the definition of a self-organizing hardware architecture based on digital spiking neurons that offer hardware efficiency. From a biological point of view, this corresponds to a combination of the so-called synaptic and structural plasticities. We intend to define computational models able to simultaneously self-organize at both computation and communication levels, and we want these models to be hardware-compliant, fault tolerant and scalable by means of a neuro-cellular structure.", "published": "2018-10-30T10:35:07Z", "version": 1}, {"aid": "1810.12850", "authors": ["Robson P. Bonidia", "Luiz A. L. Rodrigues", "Anderson P. Avila-Santos", "Danilo S. Sanches", "Jacques D. Brancher"], "title": "Computational Intelligence in Sports: A Systematic Literature Review", "url": "http://arxiv.org/pdf/1810.12850v1", "summary": "Recently, data mining studies are being successfully conducted to estimate several parameters in a variety of domains. Data mining techniques have attracted the attention of the information industry and society as a whole, due to a large amount of data and the imminent need to turn it into useful knowledge. However, the effective use of data in some areas is still under development, as is the case in sports, which in recent years, has presented a slight growth; consequently, many sports organizations have begun to see that there is a wealth of unexplored knowledge in the data extracted by them. Therefore, this article presents a systematic review of sports data mining. Regarding years 2010 to 2018, 31 types of research were found in this topic. Based on these studies, we present the current panorama, themes, the database used, proposals, algorithms, and research opportunities. Our findings provide a better understanding of the sports data mining potentials, besides motivating the scientific community to explore this timely and interesting topic.", "published": "2018-10-30T16:46:08Z", "version": 1}, {"aid": "1810.12890", "authors": ["Golnaz Ghiasi", "Tsung-Yi Lin", "Quoc V. Le"], "title": "DropBlock: A regularization method for convolutional networks", "url": "http://arxiv.org/pdf/1810.12890v1", "summary": "Deep neural networks often work well when they are over-parameterized and trained with a massive amount of noise and regularization, such as weight decay and dropout. Although dropout is widely used as a regularization technique for fully connected layers, it is often less effective for convolutional layers. This lack of success of dropout for convolutional layers is perhaps due to the fact that activation units in convolutional layers are spatially correlated so information can still flow through convolutional networks despite dropout. Thus a structured form of dropout is needed to regularize convolutional networks. In this paper, we introduce DropBlock, a form of structured dropout, where units in a contiguous region of a feature map are dropped together. We found that applying DropbBlock in skip connections in addition to the convolution layers increases the accuracy. Also, gradually increasing number of dropped units during training leads to better accuracy and more robust to hyperparameter choices. Extensive experiments show that DropBlock works better than dropout in regularizing convolutional networks. On ImageNet classification, ResNet-50 architecture with DropBlock achieves $78.13\\%$ accuracy, which is more than $1.6\\%$ improvement on the baseline. On COCO detection, DropBlock improves Average Precision of RetinaNet from $36.8\\%$ to $38.4\\%$.", "published": "2018-10-30T17:39:42Z", "version": 1}, {"aid": "1811.02636", "authors": ["Qiuwen Lou", "Chenyun Pan", "John McGuiness", "Andras Horvath", "Azad Naeemi", "Michael Niemier", "X. Sharon Hu"], "title": "A mixed signal architecture for convolutional neural networks", "url": "http://arxiv.org/pdf/1811.02636v4", "summary": "Deep neural network (DNN) accelerators with improved energy and delay are desirable for meeting the requirements of hardware targeted for IoT and edge computing systems. Convolutional neural networks (CoNNs) belong to one of the most popular types of DNN architectures. This paper presents the design and evaluation of an accelerator for CoNNs. The system-level architecture is based on mixed-signal, cellular neural networks (CeNNs). Specifically, we present (i) the implementation of different layers, including convolution, ReLU, and pooling, in a CoNN using CeNN, (ii) modified CoNN structures with CeNN-friendly layers to reduce computational overheads typically associated with a CoNN, (iii) a mixed-signal CeNN architecture that performs CoNN computations in the analog and mixed signal domain, and (iv) design space exploration that identifies what CeNN-based algorithm and architectural features fare best compared to existing algorithms and architectures when evaluated over common datasets -- MNIST and CIFAR-10. Notably, the proposed approach can lead to 8.7$\\times$ improvements in energy-delay product (EDP) per digit classification for the MNIST dataset at iso-accuracy when compared with the state-of-the-art DNN engine, while our approach could offer 4.3$\\times$ improvements in EDP when compared to other network implementations for the CIFAR-10 dataset.", "published": "2018-10-30T18:51:57Z", "version": 4}, {"aid": "1810.13135", "authors": ["Naima Chouikhi", "Adel M. Alimi"], "title": "Adaptive Extreme Learning Machine for Recurrent Beta-basis Function Neural Network Training", "url": "http://arxiv.org/pdf/1810.13135v1", "summary": "Beta Basis Function Neural Network (BBFNN) is a special kind of kernel basis neural networks. It is a feedforward network typified by the use of beta function as a hidden activation function. Beta is a flexible transfer function representing richer forms than the common existing functions. As in every network, the architecture setting as well as the learning method are two main gauntlets faced by BBFNN. In this paper, new architecture and training algorithm are proposed for the BBFNN. An Extreme Learning Machine (ELM) is used as a training approach of BBFNN with the aim of quickening the training process. The peculiarity of ELM is permitting a certain decrement of the computing time and complexity regarding the already used BBFNN learning algorithms such as backpropagation, OLS, etc. For the architectural design, a recurrent structure is added to the common BBFNN architecture in order to make it more able to deal with complex, non linear and time varying problems. Throughout this paper, the conceived recurrent ELM-trained BBFNN is tested on a number of tasks related to time series prediction, classification and regression. Experimental results show noticeable achievements of the proposed network compared to common feedforward and recurrent networks trained by ELM and using hyperbolic tangent as activation function. These achievements are in terms of accuracy and robustness against data breakdowns such as noise signals.", "published": "2018-10-31T07:31:08Z", "version": 1}, {"aid": "1811.02656", "authors": ["Titouan Parcollet", "Mohamed Morchid", "Georges Linar\u00e8s"], "title": "Quaternion Convolutional Neural Networks for Heterogeneous Image Processing", "url": "http://arxiv.org/pdf/1811.02656v1", "summary": "Convolutional neural networks (CNN) have recently achieved state-of-the-art results in various applications. In the case of image recognition, an ideal model has to learn independently of the training data, both local dependencies between the three components (R,G,B) of a pixel, and the global relations describing edges or shapes, making it efficient with small or heterogeneous datasets. Quaternion-valued convolutional neural networks (QCNN) solved this problematic by introducing multidimensional algebra to CNN. This paper proposes to explore the fundamental reason of the success of QCNN over CNN, by investigating the impact of the Hamilton product on a color image reconstruction task performed from a gray-scale only training. By learning independently both internal and external relations and with less parameters than real valued convolutional encoder-decoder (CAE), quaternion convolutional encoder-decoders (QCAE) perfectly reconstructed unseen color images while CAE produced worst and gray-scale versions.", "published": "2018-10-31T11:22:54Z", "version": 1}, {"aid": "1810.13306", "authors": ["Zhenqian Shen", "Yongqi Zhang", "Lanning Wei", "Huan Zhao", "Quanming Yao"], "title": "Automated Machine Learning: From Principles to Practices", "url": "http://arxiv.org/pdf/1810.13306v5", "summary": "Machine learning (ML) methods have been developing rapidly, but configuring and selecting proper methods to achieve a desired performance is increasingly difficult and tedious. To address this challenge, automated machine learning (AutoML) has emerged, which aims to generate satisfactory ML configurations for given tasks in a data-driven way. In this paper, we provide a comprehensive survey on this topic. We begin with the formal definition of AutoML and then introduce its principles, including the bi-level learning objective, the learning strategy, and the theoretical interpretation. Then, we summarize the AutoML practices by setting up the taxonomy of existing works based on three main factors: the search space, the search algorithm, and the evaluation strategy. Each category is also explained with the representative methods. Then, we illustrate the principles and practices with exemplary applications from configuring ML pipeline, one-shot neural architecture search, and integration with foundation models. Finally, we highlight the emerging directions of AutoML and conclude the survey.", "published": "2018-10-31T14:35:38Z", "version": 5}, {"aid": "1810.13373", "authors": ["David G. T. Barrett", "Ari S. Morcos", "Jakob H. Macke"], "title": "Analyzing biological and artificial neural networks: challenges with opportunities for synergy?", "url": "http://arxiv.org/pdf/1810.13373v1", "summary": "Deep neural networks (DNNs) transform stimuli across multiple processing stages to produce representations that can be used to solve complex tasks, such as object recognition in images. However, a full understanding of how they achieve this remains elusive. The complexity of biological neural networks substantially exceeds the complexity of DNNs, making it even more challenging to understand the representations that they learn. Thus, both machine learning and computational neuroscience are faced with a shared challenge: how can we analyze their representations in order to understand how they solve complex tasks?   We review how data-analysis concepts and techniques developed by computational neuroscientists can be useful for analyzing representations in DNNs, and in turn, how recently developed techniques for analysis of DNNs can be useful for understanding representations in biological neural networks. We explore opportunities for synergy between the two fields, such as the use of DNNs as in-silico model systems for neuroscience, and how this synergy can lead to new hypotheses about the operating principles of biological neural networks.", "published": "2018-10-31T16:09:44Z", "version": 1}, {"aid": "1811.00231", "authors": ["Benjamin James Lansdell", "Konrad Paul Kording"], "title": "Towards learning-to-learn", "url": "http://arxiv.org/pdf/1811.00231v3", "summary": "In good old-fashioned artificial intelligence (GOFAI), humans specified systems that solved problems. Much of the recent progress in AI has come from replacing human insights by learning. However, learning itself is still usually built by humans -- specifically the choice that parameter updates should follow the gradient of a cost function. Yet, in analogy with GOFAI, there is no reason to believe that humans are particularly good at defining such learning systems: we may expect learning itself to be better if we learn it. Recent research in machine learning has started to realize the benefits of that strategy. We should thus expect this to be relevant for neuroscience: how could the correct learning rules be acquired? Indeed, cognitive science has long shown that humans learn-to-learn, which is potentially responsible for their impressive learning abilities. Here we discuss ideas across machine learning, neuroscience, and cognitive science that matter for the principle of learning-to-learn.", "published": "2018-11-01T05:07:49Z", "version": 3}, {"aid": "1811.00323", "authors": ["Emna Krichene", "Wael Ouarda", "Habib Chabchoub", "Adel M. Alimi"], "title": "Taylor-based Optimized Recursive Extended Exponential Smoothed Neural Networks Forecasting Method", "url": "http://arxiv.org/pdf/1811.00323v1", "summary": "A newly introduced method called Taylor-based Optimized Recursive Extended Exponential Smoothed Neural Networks Forecasting method is applied and extended in this study to forecast numerical values. Unlike traditional forecasting techniques which forecast only future values, our proposed method provides a new extension to correct the predicted values which is done by forecasting the estimated error. Experimental results demonstrated that the proposed method has a high accuracy both in training and testing data and outperform the state-of-the-art RNN models on Mackey-Glass, NARMA, Lorenz and Henon map datasets.", "published": "2018-11-01T11:39:49Z", "version": 1}, {"aid": "1811.00796", "authors": ["Mitsuru Kusumoto", "Keisuke Yahata", "Masahiro Sakai"], "title": "Automated Theorem Proving in Intuitionistic Propositional Logic by Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1811.00796v1", "summary": "The problem-solving in automated theorem proving (ATP) can be interpreted as a search problem where the prover constructs a proof tree step by step. In this paper, we propose a deep reinforcement learning algorithm for proof search in intuitionistic propositional logic. The most significant challenge in the application of deep learning to the ATP is the absence of large, public theorem database. We, however, overcame this issue by applying a novel data augmentation procedure at each iteration of the reinforcement learning. We also improve the efficiency of the algorithm by representing the syntactic structure of formulas by a novel compact graph representation. Using the large volume of augmented data, we train highly accurate graph neural networks that approximate the value function for the set of the syntactic structures of formulas. Our method is also cost-efficient in terms of computational time. We will show that our prover outperforms Coq's $\\texttt{tauto}$ tactic, a prover based on human-engineered heuristics. Within the specified time limit, our prover solved 84% of the theorems in a benchmark library, while $\\texttt{tauto}$ was able to solve only 52%.", "published": "2018-11-02T09:49:18Z", "version": 1}, {"aid": "1811.00876", "authors": ["Deniz Lefkeli", "Baris Akgun", "Sahibzada Omar", "Aansa Malik", "Zeynep Gurhan Canli", "Terry Eskenazi"], "title": "Mind in the Machine: Perceived Minds Induce Decision Change", "url": "http://arxiv.org/pdf/1811.00876v1", "summary": "Recent research on human robot interaction explored whether people's tendency to conform to others extends to artificial agents (Hertz & Wiese, 2016). However, little is known about to what extent perception of a robot as having a mind affects people's decisions. Grounded on the theory of mind perception, the current study proposes that artificial agents can induce decision change to the extent in which individuals perceive them as having minds. By varying the degree to which robots expressed ability to act (agency) or feel (experience), we specifically investigated the underlying mechanisms of mind attribution to robots and social influence. Our results show an interactive effect of perceived experience and perceived agency on social influence induced by artificial agents. The findings provide preliminary insights regarding autonomous robots' influence on individuals' decisions and form a basis for understanding the underlying dynamics of decision making with robots.", "published": "2018-11-02T14:22:47Z", "version": 1}, {"aid": "1811.00941", "authors": ["Andrey Babichev", "Dmitriy Morozov", "Yuri Dabaghian"], "title": "Replays of spatial memories suppress topological fluctuations in cognitive map", "url": "http://arxiv.org/pdf/1811.00941v1", "summary": "The spiking activity of the hippocampal place cells plays a key role in producing and sustaining an internalized representation of the ambient space---a cognitive map. These cells do not only exhibit location-specific spiking during navigation, but also may rapidly replay the navigated routs through endogenous dynamics of the hippocampal network. Physiologically, such reactivations are viewed as manifestations of \"memory replays\" that help to learn new information and to consolidate previously acquired memories by reinforcing synapses in the parahippocampal networks. Below we propose a computational model of these processes that allows assessing the effect of replays on acquiring a robust topological map of the environment and demonstrate that replays may play a key role in stabilizing the hippocampal representation of space.", "published": "2018-11-02T15:43:40Z", "version": 1}, {"aid": "1811.00995", "authors": ["Jens Behrmann", "Will Grathwohl", "Ricky T. Q. Chen", "David Duvenaud", "J\u00f6rn-Henrik Jacobsen"], "title": "Invertible Residual Networks", "url": "http://arxiv.org/pdf/1811.00995v3", "summary": "We show that standard ResNet architectures can be made invertible, allowing the same model to be used for classification, density estimation, and generation. Typically, enforcing invertibility requires partitioning dimensions or restricting network architectures. In contrast, our approach only requires adding a simple normalization step during training, already available in standard frameworks. Invertible ResNets define a generative model which can be trained by maximum likelihood on unlabeled data. To compute likelihoods, we introduce a tractable approximation to the Jacobian log-determinant of a residual block. Our empirical evaluation shows that invertible ResNets perform competitively with both state-of-the-art image classifiers and flow-based generative models, something that has not been previously achieved with a single architecture.", "published": "2018-11-02T17:17:55Z", "version": 3}, {"aid": "1811.01199", "authors": ["Christoph von der Malsburg"], "title": "Concerning the Neural Code", "url": "http://arxiv.org/pdf/1811.01199v1", "summary": "The central problem with understanding brain and mind is the neural code issue: understanding the matter of our brain as basis for the phenomena of our mind. The richness with which our mind represents our environment, the parsimony of genetic data, the tremendous efficiency with which the brain learns from scant sensory input and the creativity with which our mind constructs mental worlds all speak in favor of mind as an emergent phenomenon. This raises the further issue of how the neural code supports these processes of organization. The central point of this communication is that the neural code has the form of structured net fragments that are formed by network self-organization, activate and de-activate on the functional time scale, and spontaneously combine to form larger nets with the same basic structure.", "published": "2018-11-03T12:35:44Z", "version": 1}, {"aid": "1811.01545", "authors": ["P. Guo", "K. Wang", "X. L. Zhou"], "title": "PILAE: A Non-gradient Descent Learning Scheme for Deep Feedforward Neural Networks", "url": "http://arxiv.org/pdf/1811.01545v3", "summary": "In this work, a non-gradient descent learning (NGDL) scheme was proposed for deep feedforward neural networks (DNN). It is known that an autoencoder can be used as the building blocks of the multi-layer perceptron (MLP) DNN, the MLP is taken as an example to illustrate the proposed scheme of pseudoinverse learning algorithm for autoencoder (PILAE) in this paper. The PILAE with low rank approximation is a NGDL algorithm, and the encoder weight matrix is set to be the low rank approximation of the pseudoinverse of the input matrix, while the decoder weight matrix is calculated by the pseudoinverse learning algorithm. It is worth to note that only very few network structure hyper-parameters need to be tuned compared with classical gradient descent learning algorithm. Hence, the proposed algorithm could be regarded as a quasi-automated training algorithm which could be utilized in automated machine learning field. The experimental results show that the proposed learning scheme for DNN could achieve better performance on considering the tradeoff between training efficiency and classification accuracy.", "published": "2018-11-05T08:14:11Z", "version": 3}, {"aid": "1811.02130", "authors": ["Prem Seetharaman", "Gordon Wichern", "Jonathan Le Roux", "Bryan Pardo"], "title": "Bootstrapping single-channel source separation via unsupervised spatial clustering on stereo mixtures", "url": "http://arxiv.org/pdf/1811.02130v1", "summary": "Separating an audio scene into isolated sources is a fundamental problem in computer audition, analogous to image segmentation in visual scene analysis. Source separation systems based on deep learning are currently the most successful approaches for solving the underdetermined separation problem, where there are more sources than channels. Traditionally, such systems are trained on sound mixtures where the ground truth decomposition is already known. Since most real-world recordings do not have such a decomposition available, this limits the range of mixtures one can train on, and the range of mixtures the learned models may successfully separate. In this work, we use a simple blind spatial source separation algorithm to generate estimated decompositions of stereo mixtures. These estimates, together with a weighting scheme in the time-frequency domain, based on confidence in the separation quality, are used to train a deep learning model that can be used for single-channel separation, where no source direction information is available. This demonstrates how a simple cue such as the direction of origin of source can be used to bootstrap a model for source separation that can be used in situations where that cue is not available.", "published": "2018-11-06T02:20:40Z", "version": 1}, {"aid": "1811.02191", "authors": ["Ali Cheraghian", "Lars Petersson"], "title": "3DCapsule: Extending the Capsule Architecture to Classify 3D Point Clouds", "url": "http://arxiv.org/pdf/1811.02191v1", "summary": "This paper introduces the 3DCapsule, which is a 3D extension of the recently introduced Capsule concept that makes it applicable to unordered point sets. The original Capsule relies on the existence of a spatial relationship between the elements in the feature map it is presented with, whereas in point permutation invariant formulations of 3D point set classification methods, such relationships are typically lost. Here, a new layer called ComposeCaps is introduced that, in lieu of a spatially relevant feature mapping, learns a new mapping that can be exploited by the 3DCapsule. Previous works in the 3D point set classification domain have focused on other parts of the architecture, whereas instead, the 3DCapsule is a drop-in replacement of the commonly used fully connected classifier. It is demonstrated via an ablation study, that when the 3DCapsule is applied to recent 3D point set classification architectures, it consistently shows an improvement, in particular when subjected to noisy data. Similarly, the ComposeCaps layer is evaluated and demonstrates an improvement over the baseline. In an apples-to-apples comparison against state-of-the-art methods, again, better performance is demonstrated by the 3DCapsule.", "published": "2018-11-06T06:57:49Z", "version": 1}, {"aid": "1811.02290", "authors": ["Qi Yan", "Yajing Zheng", "Shanshan Jia", "Yichen Zhang", "Zhaofei Yu", "Feng Chen", "Yonghong Tian", "Tiejun Huang", "Jian K. Liu"], "title": "Revealing Fine Structures of the Retinal Receptive Field by Deep Learning Networks", "url": "http://arxiv.org/pdf/1811.02290v2", "summary": "Deep convolutional neural networks (CNNs) have demonstrated impressive performance on many visual tasks. Recently, they became useful models for the visual system in neuroscience. However, it is still not clear what are learned by CNNs in terms of neuronal circuits. When a deep CNN with many layers is used for the visual system, it is not easy to compare the structure components of CNNs with possible neuroscience underpinnings due to highly complex circuits from the retina to higher visual cortex. Here we address this issue by focusing on single retinal ganglion cells with biophysical models and recording data from animals. By training CNNs with white noise images to predict neuronal responses, we found that fine structures of the retinal receptive field can be revealed. Specifically, convolutional filters learned are resembling biological components of the retinal circuit. This suggests that a CNN learning from one single retinal cell reveals a minimal neural network carried out in this cell. Furthermore, when CNNs learned from different cells are transferred between cells, there is a diversity of transfer learning performance, which indicates that CNNs are cell-specific. Moreover, when CNNs are transferred between different types of input images, here white noise v.s. natural images, transfer learning shows a good performance, which implies that CNNs indeed capture the full computational ability of a single retinal cell for different inputs. Taken together, these results suggest that CNNs could be used to reveal structure components of neuronal circuits, and provide a powerful model for neural system identification.", "published": "2018-11-06T11:20:46Z", "version": 2}, {"aid": "1811.02353", "authors": ["Xian-Rui Zhang", "Meng-Ying Lei", "Yang Li"], "title": "An amplitudes-perturbation data augmentation method in convolutional neural networks for EEG decoding", "url": "http://arxiv.org/pdf/1811.02353v1", "summary": "Brain-Computer Interface (BCI) system provides a pathway between humans and the outside world by analyzing brain signals which contain potential neural information. Electroencephalography (EEG) is one of most commonly used brain signals and EEG recognition is an important part of BCI system. Recently, convolutional neural networks (ConvNet) in deep learning are becoming the new cutting edge tools to tackle the problem of EEG recognition. However, training an effective deep learning model requires a big number of data, which limits the application of EEG datasets with a small number of samples. In order to solve the issue of data insufficiency in deep learning for EEG decoding, we propose a novel data augmentation method that add perturbations to amplitudes of EEG signals after transform them to frequency domain. In experiments, we explore the performance of signal recognition with the state-of-the-art models before and after data augmentation on BCI Competition IV dataset 2a and our local dataset. The results show that our data augmentation technique can improve the accuracy of EEG recognition effectively.", "published": "2018-11-06T14:00:05Z", "version": 1}, {"aid": "1811.04760", "authors": ["Steven Gratton"], "title": "Quantum Reasoning using Lie Algebra for Everyday Life (and AI perhaps...)", "url": "http://arxiv.org/pdf/1811.04760v1", "summary": "We investigate the applicability of the formalism of quantum mechanics to everyday life. It seems to be directly relevant for situations in which the very act of coming to a conclusion or decision on one issue affects one's confidence about conclusions or decisions on another issue. Lie algebra theory is argued to be a very useful tool in guiding the construction of quantum descriptions of such situations. Tests, extensions and speculative applications and implications, including for the encoding of thoughts in neural networks, are discussed. It is suggested that the recognition and incorporation of such mathematical structure into machine learning and artificial intelligence might lead to significant efficiency and generality gains in addition to ensuring probabilistic reasoning at a fundamental level.", "published": "2018-11-06T15:08:08Z", "version": 1}, {"aid": "1811.02454", "authors": ["Chen Lin", "Zhao Zhong", "Wei Wu", "Junjie Yan"], "title": "Synaptic Strength For Convolutional Neural Network", "url": "http://arxiv.org/pdf/1811.02454v1", "summary": "Convolutional Neural Networks(CNNs) are both computation and memory intensive which hindered their deployment in mobile devices. Inspired by the relevant concept in neural science literature, we propose Synaptic Pruning: a data-driven method to prune connections between input and output feature maps with a newly proposed class of parameters called Synaptic Strength. Synaptic Strength is designed to capture the importance of a connection based on the amount of information it transports. Experiment results show the effectiveness of our approach. On CIFAR-10, we prune connections for various CNN models with up to 96% , which results in significant size reduction and computation saving. Further evaluation on ImageNet demonstrates that synaptic pruning is able to discover efficient models which is competitive to state-of-the-art compact CNNs such as MobileNet-V2 and NasNet-Mobile. Our contribution is summarized as following: (1) We introduce Synaptic Strength, a new class of parameters for CNNs to indicate the importance of each connections. (2) Our approach can prune various CNNs with high compression without compromising accuracy. (3) Further investigation shows, the proposed Synaptic Strength is a better indicator for kernel pruning compared with the previous approach in both empirical result and theoretical analysis.", "published": "2018-11-06T16:06:49Z", "version": 1}, {"aid": "1811.06825", "authors": ["Jerome Feldman"], "title": "Towards a Science of Mind", "url": "http://arxiv.org/pdf/1811.06825v3", "summary": "The ancient mind/body problem continues to be one of deepest mysteries of science and of the human spirit. Despite major advances in many fields, there is still no plausible link between subjective experience (qualia) and its realization in the body. This paper outlines some of the elements of a rigorous science of mind (SoM) - key ideas include scientific realism of mind, agnostic mysterianism, careful attention to language, and a focus on concrete (touchstone) questions and results. A core suggestion is to focus effort on the (still mysterious) mapping from neural activity to subjective experience.", "published": "2018-11-06T18:02:40Z", "version": 3}, {"aid": "1811.02546", "authors": ["Paul Yaworsky"], "title": "A Model for General Intelligence", "url": "http://arxiv.org/pdf/1811.02546v2", "summary": "The overarching problem in artificial intelligence (AI) is that we do not understand the intelligence process well enough to enable the development of adequate computational models. Much work has been done in AI over the years at lower levels, but a big part of what has been missing involves the high level, abstract, general nature of intelligence. We address this gap by developing a model for general intelligence. To accomplish this, we focus on three basic aspects of intelligence. First, we must realize the general order and nature of intelligence at a high level. Second, we must come to know what these realizations mean with respect to the overall intelligence process. Third, we must describe these realizations as clearly as possible. We propose a hierarchical model to help capture and exploit the order within intelligence. The underlying order involves patterns of signals that become organized, stored and activated in space and time. These patterns can be described using a simple, general hierarchy, with physical signals at the lowest level, information in the middle, and abstract signal representations at the top. This high level perspective provides a big picture that literally helps us see the intelligence process, thereby enabling fundamental realizations, a better understanding and clear descriptions of the intelligence process. The resulting model can be used to support all kinds of information processing across multiple levels of abstraction. As computer technology improves, and as cooperation increases between humans and computers, people will become more efficient and more productive in performing their information processing tasks.", "published": "2018-11-06T18:37:04Z", "version": 2}, {"aid": "1811.02597", "authors": ["Sina Ghiassian", "Andrew Patterson", "Martha White", "Richard S. Sutton", "Adam White"], "title": "Online Off-policy Prediction", "url": "http://arxiv.org/pdf/1811.02597v1", "summary": "This paper investigates the problem of online prediction learning, where learning proceeds continuously as the agent interacts with an environment. The predictions made by the agent are contingent on a particular way of behaving, represented as a value function. However, the behavior used to select actions and generate the behavior data might be different from the one used to define the predictions, and thus the samples are generated off-policy. The ability to learn behavior-contingent predictions online and off-policy has long been advocated as a key capability of predictive-knowledge learning systems but remained an open algorithmic challenge for decades. The issue lies with the temporal difference (TD) learning update at the heart of most prediction algorithms: combining bootstrapping, off-policy sampling and function approximation may cause the value estimate to diverge. A breakthrough came with the development of a new objective function that admitted stochastic gradient descent variants of TD. Since then, many sound online off-policy prediction algorithms have been developed, but there has been limited empirical work investigating the relative merits of all the variants. This paper aims to fill these empirical gaps and provide clarity on the key ideas behind each method. We summarize the large body of literature on off-policy learning, focusing on 1- methods that use computation linear in the number of features and are convergent under off-policy sampling, and 2- other methods which have proven useful with non-fixed, nonlinear function approximation. We provide an empirical study of off-policy prediction methods in two challenging microworlds. We report each method's parameter sensitivity, empirical convergence rate, and final performance, providing new insights that should enable practitioners to successfully extend these new methods to large-scale applications.[Abridged abstract]", "published": "2018-11-06T19:09:04Z", "version": 1}, {"aid": "1811.02617", "authors": ["Kieran Greer"], "title": "Category Trees", "url": "http://arxiv.org/pdf/1811.02617v6", "summary": "This paper presents a batch classifier that has been improved from the earlier version and fixed a mistake in the earlier paper. Two important changes have been made. Each category is represented by a classifier, where each classifier classifies its own subset of data rows, using batch input values to represent the centroid. The first change is to use the category centroid as the desired category output. When the classifier represents more than one category, it creates a new layer and splits, to represent each category separately in the new layer. The second change therefore, is to allow the classifier to branch to new levels when there is a split in the data, or when some data rows are incorrectly classified. Each layer can therefore branch like a tree - not for distinguishing features, but for distinguishing categories. The paper then suggests further innovations, by adding fixed value ranges through bands, for each column or feature of the input dataset. When considering features, it is shown that some of the data can be classified directly through fixed value ranges, while the rest can be classified using the classifier technique. Tests show that the method can successfully classify a diverse set of benchmark datasets to better than the state-of-the-art. The paper also discusses a biological analogy with neurons and neuron links.", "published": "2018-11-06T20:21:26Z", "version": 6}, {"aid": "1811.02942", "authors": ["Shahab Aslani", "Michael Dayan", "Loredana Storelli", "Massimo Filippi", "Vittorio Murino", "Maria A Rocca", "Diego Sona"], "title": "Multi-branch Convolutional Neural Network for Multiple Sclerosis Lesion Segmentation", "url": "http://arxiv.org/pdf/1811.02942v4", "summary": "In this paper, we present an automated approach for segmenting multiple sclerosis (MS) lesions from multi-modal brain magnetic resonance images. Our method is based on a deep end-to-end 2D convolutional neural network (CNN) for slice-based segmentation of 3D volumetric data. The proposed CNN includes a multi-branch downsampling path, which enables the network to encode information from multiple modalities separately. Multi-scale feature fusion blocks are proposed to combine feature maps from different modalities at different stages of the network. Then, multi-scale feature upsampling blocks are introduced to upsize combined feature maps to leverage information from lesion shape and location. We trained and tested the proposed model using orthogonal plane orientations of each 3D modality to exploit the contextual information in all directions. The proposed pipeline is evaluated on two different datasets: a private dataset including 37 MS patients and a publicly available dataset known as the ISBI 2015 longitudinal MS lesion segmentation challenge dataset, consisting of 14 MS patients. Considering the ISBI challenge, at the time of submission, our method was amongst the top performing solutions. On the private dataset, using the same array of performance metrics as in the ISBI challenge, the proposed approach shows high improvements in MS lesion segmentation compared with other publicly available tools.", "published": "2018-11-07T15:42:57Z", "version": 4}, {"aid": "1811.03120", "authors": ["Vincent Billaut", "Matthieu de Rochemonteix", "Marc Thibault"], "title": "ColorUNet: A convolutional classification approach to colorization", "url": "http://arxiv.org/pdf/1811.03120v1", "summary": "This paper tackles the challenge of colorizing grayscale images. We take a deep convolutional neural network approach, and choose to take the angle of classification, working on a finite set of possible colors. Similarly to a recent paper, we implement a loss and a prediction function that favor realistic, colorful images rather than \"true\" ones.   We show that a rather lightweight architecture inspired by the U-Net, and trained on a reasonable amount of pictures of landscapes, achieves satisfactory results on this specific subset of pictures. We show that data augmentation significantly improves the performance and robustness of the model, and provide visual analysis of the prediction confidence.   We show an application of our model, extending the task to video colorization. We suggest a way to smooth color predictions across frames, without the need to train a recurrent network designed for sequential inputs.", "published": "2018-11-07T19:20:59Z", "version": 1}, {"aid": "1811.03151", "authors": ["K. Gretchen Greene"], "title": "DragonPaint: Rule based bootstrapping for small data with an application to cartoon coloring", "url": "http://arxiv.org/pdf/1811.03151v1", "summary": "In this paper, we confront the problem of deep learning's big labeled data requirements, offer a rule based strategy for extreme augmentation of small data sets and apply that strategy with the image to image translation model by Isola et al. (2016) to automate cel style cartoon coloring with very limited training data. While our experimental results using geometric rules and transformations demonstrate the performance of our methods on an image translation task with industry applications in art, design and animation, we also propose the use of rules on partial data sets as a generalizable small data strategy, potentially applicable across data types and domains.", "published": "2018-11-07T21:23:31Z", "version": 1}, {"aid": "1811.03376", "authors": ["Xi Chen", "Ali Ghadirzadeh", "M\u00e5rten Bj\u00f6rkman", "Patric Jensfelt"], "title": "Meta-Learning for Multi-objective Reinforcement Learning", "url": "http://arxiv.org/pdf/1811.03376v2", "summary": "Multi-objective reinforcement learning (MORL) is the generalization of standard reinforcement learning (RL) approaches to solve sequential decision making problems that consist of several, possibly conflicting, objectives. Generally, in such formulations, there is no single optimal policy which optimizes all the objectives simultaneously, and instead, a number of policies has to be found each optimizing a preference of the objectives. In other words, the MORL is framed as a meta-learning problem, with the task distribution given by a distribution over the preferences. We demonstrate that such a formulation results in a better approximation of the Pareto optimal solutions in terms of both the optimality and the computational efficiency. We evaluated our method on obtaining Pareto optimal policies using a number of continuous control problems with high degrees of freedom.", "published": "2018-11-08T12:26:42Z", "version": 2}, {"aid": "1811.03378", "authors": ["Chigozie Nwankpa", "Winifred Ijomah", "Anthony Gachagan", "Stephen Marshall"], "title": "Activation Functions: Comparison of trends in Practice and Research for Deep Learning", "url": "http://arxiv.org/pdf/1811.03378v1", "summary": "Deep neural networks have been successfully used in diverse emerging domains to solve real world complex problems with may more deep learning(DL) architectures, being developed to date. To achieve these state-of-the-art performances, the DL architectures use activation functions (AFs), to perform diverse computations between the hidden layers and the output layers of any given DL architecture. This paper presents a survey on the existing AFs used in deep learning applications and highlights the recent trends in the use of the activation functions for deep learning applications. The novelty of this paper is that it compiles majority of the AFs used in DL and outlines the current trends in the applications and usage of these functions in practical deep learning deployments against the state-of-the-art research results. This compilation will aid in making effective decisions in the choice of the most suitable and appropriate activation function for any given application, ready for deployment. This paper is timely because most research papers on AF highlights similar works and results while this paper will be the first, to compile the trends in AF applications in practice against the research results from literature, found in deep learning research to date.", "published": "2018-11-08T12:28:43Z", "version": 1}, {"aid": "1811.03567", "authors": ["Will Xiao", "Honglin Chen", "Qianli Liao", "Tomaso Poggio"], "title": "Biologically-plausible learning algorithms can scale to large datasets", "url": "http://arxiv.org/pdf/1811.03567v3", "summary": "The backpropagation (BP) algorithm is often thought to be biologically implausible in the brain. One of the main reasons is that BP requires symmetric weight matrices in the feedforward and feedback pathways. To address this \"weight transport problem\" (Grossberg, 1987), two more biologically plausible algorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax BP's weight symmetry requirements and demonstrate comparable learning capabilities to that of BP on small datasets. However, a recent study by Bartunov et al. (2018) evaluate variants of target-propagation (TP) and feedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that although many of the proposed algorithms perform well on MNIST and CIFAR, they perform significantly worse than BP on ImageNet. Here, we additionally evaluate the sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and FA in that the feedback and feedforward weights share signs but not magnitudes. We examine the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using different network architectures (ResNet-18 and AlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained with sign-symmetry can attain classification performance approaching that of BP-trained networks. These results complement the study by Bartunov et al. (2018), and establish a new benchmark for future biologically plausible learning algorithms on more difficult datasets and more complex architectures.", "published": "2018-11-08T17:43:59Z", "version": 3}, {"aid": "1811.03804", "authors": ["Simon S. Du", "Jason D. Lee", "Haochuan Li", "Liwei Wang", "Xiyu Zhai"], "title": "Gradient Descent Finds Global Minima of Deep Neural Networks", "url": "http://arxiv.org/pdf/1811.03804v4", "summary": "Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep over-parameterized neural network with residual connections (ResNet). Our analysis relies on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. We further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.", "published": "2018-11-09T07:39:59Z", "version": 4}, {"aid": "1811.03831", "authors": ["S. Bellavia", "G. Gurioli", "B. Morini", "Ph. L. Toint"], "title": "Adaptive Regularization Algorithms with Inexact Evaluations for Nonconvex Optimization", "url": "http://arxiv.org/pdf/1811.03831v3", "summary": "A regularization algorithm using inexact function values and inexact derivatives is proposed and its evaluation complexity analyzed. This algorithm is applicable to unconstrained problems and to problems with inexpensive constraints (that is constraints whose evaluation and enforcement has negligible cost) under the assumption that the derivative of highest degree is $\\beta$-H\\\"{o}lder continuous. It features a very flexible adaptive mechanism for determining the inexactness which is allowed, at each iteration, when computing objective function values and derivatives. The complexity analysis covers arbitrary optimality order and arbitrary degree of available approximate derivatives. It extends results of Cartis, Gould and Toint (2018) on the evaluation complexity to the inexact case: if a $q$th order minimizer is sought using approximations to the first $p$ derivatives, it is proved that a suitable approximate minimizer within $\\epsilon$ is computed by the proposed algorithm in at most $O(\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ iterations and at most $O(|\\log(\\epsilon)|\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ approximate evaluations. An algorithmic variant, although more rigid in practice, can be proved to find such an approximate minimizer in $O(|\\log(\\epsilon)|+\\epsilon^{-\\frac{p+\\beta}{p-q+\\beta}})$ evaluations.While the proposed framework remains so far conceptual for high degrees and orders, it is shown to yield simple and computationally realistic inexact methods when specialized to the unconstrained and bound-constrained first- and second-order cases. The deterministic complexity results are finally extended to the stochastic context, yielding adaptive sample-size rules for subsampling methods typical of machine learning.", "published": "2018-11-09T09:39:53Z", "version": 3}, {"aid": "1811.03848", "authors": ["Sune Darkner", "Stefan Sommer", "Andreas Schuhmacher", "Henrik Ingerslev Anders O. Baandrup", "Carsten Thomsen", "S\u00f8ren J\u00f8nsson"], "title": "An Average of the Human Ear Canal: Recovering Acoustical Properties via Shape Analysis", "url": "http://arxiv.org/pdf/1811.03848v1", "summary": "Humans are highly dependent on the ability to process audio in order to interact through conversation and navigate from sound. For this, the shape of the ear acts as a mechanical audio filter. The anatomy of the outer human ear canal to approximately 15-20 mm beyond the Tragus is well described because of its importance for customized hearing aid production. This is however not the case for the part of the ear canal that is embedded in the skull, until the typanic membrane. Due to the sensitivity of the outer ear, this part, referred to as the bony part, has only been described in a few population studies and only ex-vivo. We present a study of the entire ear canal including the bony part and the tympanic membrane. We form an average ear canal from a number of MRI scans using standard image registration methods. We show that the obtained representation is realistic in the sense that it has acoustical properties almost identical to a real ear.", "published": "2018-11-09T10:19:25Z", "version": 1}, {"aid": "1811.04790", "authors": ["Mieczys\u0142aw K\u0142opotek"], "title": "Reasoning From Data in the Mathematical Theory of Evidence", "url": "http://arxiv.org/pdf/1811.04790v1", "summary": "Mathematical Theory of Evidence (MTE) is known as a foundation for reasoning when knowledge is expressed at various levels of detail. Though much research effort has been committed to this theory since its foundation, many questions remain open. One of the most important open questions seems to be the relationship between frequencies and the Mathematical Theory of Evidence. The theory is blamed to leave frequencies outside (or aside of) its framework. The seriousness of this accusation is obvious: no experiment may be run to compare the performance of MTE-based models of real world processes against real world data.   In this paper we develop a frequentist model of the MTE bringing to fall the above argument against MTE. We describe, how to interpret data in terms of MTE belief functions, how to reason from data about conditional belief functions, how to generate a random sample out of a MTE model, how to derive MTE model from data and how to compare results of reasoning in MTE model and reasoning from data.   It is claimed in this paper that MTE is suitable to model some types of destructive processes", "published": "2018-11-09T11:41:10Z", "version": 1}, {"aid": "1811.04047", "authors": ["Hongyang Jia", "Yinqi Tang", "Hossein Valavi", "Jintao Zhang", "Naveen Verma"], "title": "A Microprocessor implemented in 65nm CMOS with Configurable and Bit-scalable Accelerator for Programmable In-memory Computing", "url": "http://arxiv.org/pdf/1811.04047v1", "summary": "This paper presents a programmable in-memory-computing processor, demonstrated in a 65nm CMOS technology. For data-centric workloads, such as deep neural networks, data movement often dominates when implemented with today's computing architectures. This has motivated spatial architectures, where the arrangement of data-storage and compute hardware is distributed and explicitly aligned to the computation dataflow, most notably for matrix-vector multiplication. In-memory computing is a spatial architecture where processing elements correspond to dense bit cells, providing local storage and compute, typically employing analog operation. Though this raises the potential for high energy efficiency and throughput, analog operation has significantly limited robustness, scale, and programmability. This paper describes a 590kb in-memory-computing accelerator integrated in a programmable processor architecture, by exploiting recent approaches to charge-domain in-memory computing. The architecture takes the approach of tight coupling with an embedded CPU, through accelerator interfaces enabling integration in the standard processor memory space. Additionally, a near-memory-computing datapath both enables diverse computations locally, to address operations required across applications, and enables bit-precision scalability for matrix/input-vector elements, through a bit-parallel/bit-serial (BP/BS) scheme. Chip measurements show an energy efficiency of 152/297 1b-TOPS/W and throughput of 4.7/1.9 1b-TOPS (scaling linearly with the matrix/input-vector element precisions) at VDD of 1.2/0.85V. Neural network demonstrations with 1-b/4-b weights and activations for CIFAR-10 classification consume 5.3/105.2 $\\mu$J/image at 176/23 fps, with accuracy at the level of digital/software implementation (89.3/92.4 $\\%$ accuracy).", "published": "2018-11-09T18:03:14Z", "version": 1}, {"aid": "1811.04110", "authors": ["Akshay Raj Dhamija", "Manuel G\u00fcnther", "Terrance E. Boult"], "title": "Reducing Network Agnostophobia", "url": "http://arxiv.org/pdf/1811.04110v2", "summary": "Agnostophobia, the fear of the unknown, can be experienced by deep learning engineers while applying their networks to real-world applications. Unfortunately, network behavior is not well defined for inputs far from a networks training set. In an uncontrolled environment, networks face many instances that are not of interest to them and have to be rejected in order to avoid a false positive. This problem has previously been tackled by researchers by either a) thresholding softmax, which by construction cannot return \"none of the known classes\", or b) using an additional background or garbage class. In this paper, we show that both of these approaches help, but are generally insufficient when previously unseen classes are encountered. We also introduce a new evaluation metric that focuses on comparing the performance of multiple approaches in scenarios where such unseen classes or unknowns are encountered. Our major contributions are simple yet effective Entropic Open-Set and Objectosphere losses that train networks using negative samples from some classes. These novel losses are designed to maximize entropy for unknown inputs while increasing separation in deep feature space by modifying magnitudes of known and unknown samples. Experiments on networks trained to classify classes from MNIST and CIFAR-10 show that our novel loss functions are significantly better at dealing with unknown inputs from datasets such as Devanagari, NotMNIST, CIFAR-100, and SVHN.", "published": "2018-11-09T19:29:58Z", "version": 2}, {"aid": "1811.04239", "authors": ["Geesara Prathap", "Titus Nanda Kumara", "Roshan Ragel"], "title": "Near Real-Time Data Labeling Using a Depth Sensor for EMG Based Prosthetic Arms", "url": "http://arxiv.org/pdf/1811.04239v1", "summary": "Recognizing sEMG (Surface Electromyography) signals belonging to a particular action (e.g., lateral arm raise) automatically is a challenging task as EMG signals themselves have a lot of variation even for the same action due to several factors. To overcome this issue, there should be a proper separation which indicates similar patterns repetitively for a particular action in raw signals. A repetitive pattern is not always matched because the same action can be carried out with different time duration. Thus, a depth sensor (Kinect) was used for pattern identification where three joint angles were recording continuously which is clearly separable for a particular action while recording sEMG signals. To Segment out a repetitive pattern in angle data, MDTW (Moving Dynamic Time Warping) approach is introduced. This technique is allowed to retrieve suspected motion of interest from raw signals. MDTW based on DTW algorithm, but it will be moving through the whole dataset in a pre-defined manner which is capable of picking up almost all the suspected segments inside a given dataset an optimal way. Elevated bicep curl and lateral arm raise movements are taken as motions of interest to show how the proposed technique can be employed to achieve auto identification and labelling. The full implementation is available at https://github.com/GPrathap/OpenBCIPython", "published": "2018-11-10T11:59:56Z", "version": 1}, {"aid": "1811.04504", "authors": ["Aaron Mishkin", "Frederik Kunstner", "Didrik Nielsen", "Mark Schmidt", "Mohammad Emtiyaz Khan"], "title": "SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient", "url": "http://arxiv.org/pdf/1811.04504v2", "summary": "Uncertainty estimation in large deep-learning models is a computationally challenging task, where it is difficult to form even a Gaussian approximation to the posterior distribution. In such situations, existing methods usually resort to a diagonal approximation of the covariance matrix despite, the fact that these matrices are known to result in poor uncertainty estimates. To address this issue, we propose a new stochastic, low-rank, approximate natural-gradient (SLANG) method for variational inference in large, deep models. Our method estimates a \"diagonal plus low-rank\" structure based solely on back-propagated gradients of the network log-likelihood. This requires strictly less gradient computations than methods that compute the gradient of the whole variational objective. Empirical evaluations on standard benchmarks confirm that SLANG enables faster and more accurate estimation of uncertainty than mean-field methods, and performs comparably to state-of-the-art methods.", "published": "2018-11-11T23:18:27Z", "version": 2}, {"aid": "1811.04581", "authors": ["Shigeko Takahashi"], "title": "Topographic maps in the brain are fundamental to processing of causality", "url": "http://arxiv.org/pdf/1811.04581v1", "summary": "The ubiquity of topographic maps in the brain has long been known, and molecular mechanisms for the formation of topographic organization of neural systems have been revealed. Less attention has been given to the question of why are the maps topographical and why so ubiquitous. In this study, I explore the implications of the topographic maps for brain function, by employing the mathematical framework of the Zeeman topology. I propose the notion about the meaning of topographic order as generic mechanisms for the representation and analysis of causal structure, implemented by the neural systems. This leads to a much improved understanding of the division of labour between chemical systems and neural systems in the formation of maps to deal with causality.", "published": "2018-11-12T06:42:42Z", "version": 1}, {"aid": "1811.04768", "authors": ["Mingyang Geng", "Kele Xu", "Bo Ding", "Huaimin Wang", "Lei Zhang"], "title": "Learning data augmentation policies using augmented random search", "url": "http://arxiv.org/pdf/1811.04768v1", "summary": "Previous attempts for data augmentation are designed manually, and the augmentation policies are dataset-specific. Recently, an automatic data augmentation approach, named AutoAugment, is proposed using reinforcement learning. AutoAugment searches for the augmentation polices in the discrete search space, which may lead to a sub-optimal solution. In this paper, we employ the Augmented Random Search method (ARS) to improve the performance of AutoAugment. Our key contribution is to change the discrete search space to continuous space, which will improve the searching performance and maintain the diversities between sub-policies. With the proposed method, state-of-the-art accuracies are achieved on CIFAR-10, CIFAR-100, and ImageNet (without additional data). Our code is available at https://github.com/gmy2013/ARS-Aug.", "published": "2018-11-12T15:14:18Z", "version": 1}, {"aid": "1811.05029", "authors": ["Ricardo Martin-Brualla", "Rohit Pandey", "Shuoran Yang", "Pavel Pidlypenskyi", "Jonathan Taylor", "Julien Valentin", "Sameh Khamis", "Philip Davidson", "Anastasia Tkach", "Peter Lincoln", "Adarsh Kowdle", "Christoph Rhemann", "Dan B Goldman", "Cem Keskin", "Steve Seitz", "Shahram Izadi", "Sean Fanello"], "title": "LookinGood: Enhancing Performance Capture with Real-time Neural Re-Rendering", "url": "http://arxiv.org/pdf/1811.05029v1", "summary": "Motivated by augmented and virtual reality applications such as telepresence, there has been a recent focus in real-time performance capture of humans under motion. However, given the real-time constraint, these systems often suffer from artifacts in geometry and texture such as holes and noise in the final rendering, poor lighting, and low-resolution textures. We take the novel approach to augment such real-time performance capture systems with a deep architecture that takes a rendering from an arbitrary viewpoint, and jointly performs completion, super resolution, and denoising of the imagery in real-time. We call this approach neural (re-)rendering, and our live system \"LookinGood\". Our deep architecture is trained to produce high resolution and high quality images from a coarse rendering in real-time. First, we propose a self-supervised training method that does not require manual ground-truth annotation. We contribute a specialized reconstruction error that uses semantic information to focus on relevant parts of the subject, e.g. the face. We also introduce a salient reweighing scheme of the loss function that is able to discard outliers. We specifically design the system for virtual and augmented reality headsets where the consistency between the left and right eye plays a crucial role in the final user experience. Finally, we generate temporally stable results by explicitly minimizing the difference between two consecutive frames. We tested the proposed system in two different scenarios: one involving a single RGB-D sensor, and upper body reconstruction of an actor, the second consisting of full body 360 degree capture. Through extensive experimentation, we demonstrate how our system generalizes across unseen sequences and subjects. The supplementary video is available at http://youtu.be/Md3tdAKoLGU.", "published": "2018-11-12T22:51:19Z", "version": 1}, {"aid": "1811.05067", "authors": ["John Benhardt", "Peter Hase", "Liuyi Zhu", "Cynthia Rudin"], "title": "Shall I Compare Thee to a Machine-Written Sonnet? An Approach to Algorithmic Sonnet Generation", "url": "http://arxiv.org/pdf/1811.05067v2", "summary": "We provide an approach for generating beautiful poetry. Our sonnet-generation algorithm includes several novel elements that improve over the state of the art, leading to metrical, rhyming poetry with many human-like qualities. These novel elements include in-line punctuation, part of speech restrictions, and more appropriate training corpora. Our work is the winner of the 2018 PoetiX Literary Turing Test Award for computer-generated poetry.", "published": "2018-11-13T02:04:42Z", "version": 2}, {"aid": "1811.05106", "authors": ["Sungmin Kang", "David Keetae Park", "Jaehyuk Chang", "Jaegul Choo"], "title": "Interpreting Models by Allowing to Ask", "url": "http://arxiv.org/pdf/1811.05106v1", "summary": "Questions convey information about the questioner, namely what one does not know. In this paper, we propose a novel approach to allow a learning agent to ask what it considers as tricky to predict, in the course of producing a final output. By analyzing when and what it asks, we can make our model more transparent and interpretable. We first develop this idea to propose a general framework of deep neural networks that can ask questions, which we call asking networks. A specific architecture and training process for an asking network is proposed for the task of colorization, which is an exemplar one-to-many task and thus a task where asking questions is helpful in performing the task accurately. Our results show that the model learns to generate meaningful questions, asks difficult questions first, and utilizes the provided hint more efficiently than baseline models. We conclude that the proposed asking framework makes the learning agent reveal its weaknesses, which poses a promising new direction in developing interpretable and interactive models.", "published": "2018-11-13T04:57:48Z", "version": 1}, {"aid": "1811.05531", "authors": ["Dimitris Spathis", "Nikolaos Passalis", "Anastasios Tefas"], "title": "Interactive dimensionality reduction using similarity projections", "url": "http://arxiv.org/pdf/1811.05531v1", "summary": "Recent advances in machine learning allow us to analyze and describe the content of high-dimensional data like text, audio, images or other signals. In order to visualize that data in 2D or 3D, usually Dimensionality Reduction (DR) techniques are employed. Most of these techniques, e.g., PCA or t-SNE, produce static projections without taking into account corrections from humans or other data exploration scenarios. In this work, we propose the interactive Similarity Projection (iSP), a novel interactive DR framework based on similarity embeddings, where we form a differentiable objective based on the user interactions and perform learning using gradient descent, with an end-to-end trainable architecture. Two interaction scenarios are evaluated. First, a common methodology in multidimensional projection is to project a subset of data, arrange them in classes or clusters, and project the rest unseen dataset based on that manipulation, in a kind of semi-supervised interpolation. We report results that outperform competitive baselines in a wide range of metrics and datasets. Second, we explore the scenario of manipulating some classes, while enriching the optimization with high-dimensional neighbor information. Apart from improving classification precision and clustering on images and text documents, the new emerging structure of the projection unveils semantic manifolds. For example, on the Head Pose dataset, by just dragging the faces looking far left to the left and those looking far right to the right, all faces are re-arranged on a continuum even on the vertical axis (face up and down). This end-to-end framework can be used for fast, visual semi-supervised learning, manifold exploration, interactive domain adaptation of neural embeddings and transfer learning.", "published": "2018-11-13T21:21:15Z", "version": 1}, {"aid": "1811.06115", "authors": ["Fergal Cotter", "Nick Kingsbury"], "title": "Deep Learning in the Wavelet Domain", "url": "http://arxiv.org/pdf/1811.06115v1", "summary": "This paper examines the possibility of, and the possible advantages to learning the filters of convolutional neural networks (CNNs) for image analysis in the wavelet domain. We are stimulated by both Mallat's scattering transform and the idea of filtering in the Fourier domain. It is important to explore new spaces in which to learn, as these may provide inherent advantages that are not available in the pixel space. However, the scattering transform is limited by its inability to learn in between scattering orders, and any Fourier domain filtering is limited by the large number of filter parameters needed to get localized filters. Instead we consider filtering in the wavelet domain with learnable filters. The wavelet space allows us to have local, smooth filters with far fewer parameters, and learnability can give us flexibility. We present a novel layer which takes CNN activations into the wavelet space, learns parameters and returns to the pixel space. This allows it to be easily dropped in to any neural network without affecting the structure. As part of this work, we show how to pass gradients through a multirate system and give preliminary results.", "published": "2018-11-14T23:33:09Z", "version": 1}, {"aid": "1811.06145", "authors": ["Jing Shi", "Jiaming Xu", "Yiqun Yao", "Bo Xu"], "title": "Concept Learning through Deep Reinforcement Learning with Memory-Augmented Neural Networks", "url": "http://arxiv.org/pdf/1811.06145v1", "summary": "Deep neural networks have shown superior performance in many regimes to remember familiar patterns with large amounts of data. However, the standard supervised deep learning paradigm is still limited when facing the need to learn new concepts efficiently from scarce data. In this paper, we present a memory-augmented neural network which is motivated by the process of human concept learning. The training procedure, imitating the concept formation course of human, learns how to distinguish samples from different classes and aggregate samples of the same kind. In order to better utilize the advantages originated from the human behavior, we propose a sequential process, during which the network should decide how to remember each sample at every step. In this sequential process, a stable and interactive memory serves as an important module. We validate our model in some typical one-shot learning tasks and also an exploratory outlier detection problem. In all the experiments, our model gets highly competitive to reach or outperform those strong baselines.", "published": "2018-11-15T02:38:57Z", "version": 1}, {"aid": "1811.06624", "authors": ["Jason R. C. Nurse"], "title": "Cybercrime and You: How Criminals Attack and the Human Factors That They Seek to Exploit", "url": "http://arxiv.org/pdf/1811.06624v1", "summary": "Cybercrime is a significant challenge to society, but it can be particularly harmful to the individuals who become victims. This chapter engages in a comprehensive and topical analysis of the cybercrimes that target individuals. It also examines the motivation of criminals that perpetrate such attacks and the key human factors and psychological aspects that help to make cybercriminals successful. Key areas assessed include social engineering (e.g., phishing, romance scams, catfishing), online harassment (e.g., cyberbullying, trolling, revenge porn, hate crimes), identity-related crimes (e.g., identity theft, doxing), hacking (e.g., malware, cryptojacking, account hacking), and denial-of-service crimes. As a part of its contribution, the chapter introduces a summary taxonomy of cybercrimes against individuals and a case for why they will continue to occur if concerted interdisciplinary efforts are not pursued.", "published": "2018-11-15T23:16:37Z", "version": 1}, {"aid": "1811.06783", "authors": ["Hengyue Pan", "Hui Jiang", "Xin Niu", "Yong Dou"], "title": "DropFilter: A Novel Regularization Method for Learning Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1811.06783v2", "summary": "The past few years have witnessed the fast development of different regularization methods for deep learning models such as fully-connected deep neural networks (DNNs) and Convolutional Neural Networks (CNNs). Most of previous methods mainly consider to drop features from input data and hidden layers, such as Dropout, Cutout and DropBlocks. DropConnect select to drop connections between fully-connected layers. By randomly discard some features or connections, the above mentioned methods control the overfitting problem and improve the performance of neural networks. In this paper, we proposed two novel regularization methods, namely DropFilter and DropFilter-PLUS, for the learning of CNNs. Different from the previous methods, DropFilter and DropFilter-PLUS selects to modify the convolution filters. For DropFilter-PLUS, we find a suitable way to accelerate the learning process based on theoretical analysis. Experimental results on MNIST show that using DropFilter and DropFilter-PLUS may improve performance on image classification tasks.", "published": "2018-11-16T12:40:39Z", "version": 2}, {"aid": "1811.06878", "authors": ["Jung HyoungHo", "Lee Ryong", "Lee Sanghwan", "Hwang Wonjun"], "title": "Residual Convolutional Neural Network Revisited with Active Weighted Mapping", "url": "http://arxiv.org/pdf/1811.06878v1", "summary": "In visual recognition, the key to the performance improvement of ResNet is the success in establishing the stack of deep sequential convolutional layers using identical mapping by a shortcut connection. It results in multiple paths of data flow under a network and the paths are merged with the equal weights. However, it is questionable whether it is correct to use the fixed and predefined weights at the mapping units of all paths. In this paper, we introduce the active weighted mapping method which infers proper weight values based on the characteristic of input data on the fly. The weight values of each mapping unit are not fixed but changed as the input image is changed, and the most proper weight values for each mapping unit are derived according to the input image. For this purpose, channel-wise information is embedded from both the shortcut connection and convolutional block, and then the fully connected layers are used to estimate the weight values for the mapping units. We train the backbone network and the proposed module alternately for a more stable learning of the proposed method. Results of the extensive experiments show that the proposed method works successfully on the various backbone architectures from ResNet to DenseNet. We also verify the superiority and generality of the proposed method on various datasets in comparison with the baseline.", "published": "2018-11-16T15:51:20Z", "version": 1}, {"aid": "1811.06981", "authors": ["Oren Rippel", "Sanjay Nair", "Carissa Lew", "Steve Branson", "Alexander G. Anderson", "Lubomir Bourdev"], "title": "Learned Video Compression", "url": "http://arxiv.org/pdf/1811.06981v1", "summary": "We present a new algorithm for video coding, learned end-to-end for the low-latency mode. In this setting, our approach outperforms all existing video codecs across nearly the entire bitrate range. To our knowledge, this is the first ML-based method to do so.   We evaluate our approach on standard video compression test sets of varying resolutions, and benchmark against all mainstream commercial codecs, in the low-latency mode. On standard-definition videos, relative to our algorithm, HEVC/H.265, AVC/H.264 and VP9 typically produce codes up to 60% larger. On high-definition 1080p videos, H.265 and VP9 typically produce codes up to 20% larger, and H.264 up to 35% larger. Furthermore, our approach does not suffer from blocking artifacts and pixelation, and thus produces videos that are more visually pleasing.   We propose two main contributions. The first is a novel architecture for video compression, which (1) generalizes motion estimation to perform any learned compensation beyond simple translations, (2) rather than strictly relying on previously transmitted reference frames, maintains a state of arbitrary information learned by the model, and (3) enables jointly compressing all transmitted signals (such as optical flow and residual).   Secondly, we present a framework for ML-based spatial rate control: namely, a mechanism for assigning variable bitrates across space for each frame. This is a critical component for video coding, which to our knowledge had not been developed within a machine learning setting.", "published": "2018-11-16T17:29:51Z", "version": 1}, {"aid": "1811.07012", "authors": ["Benjamin P Cohen", "Carson C Chow", "Shashaank Vattikuti"], "title": "Multi-scale variability in neuronal competition", "url": "http://arxiv.org/pdf/1811.07012v1", "summary": "We examine whether a single biophysical cortical circuit model can explain both spiking and perceptual variability. We consider perceptual rivalry, which provides a window into intrinsic neural processing since neural activity in some brain areas is correlated to the alternating perception rather than the constant ambiguous stimulus. The prevalent theory for spiking variability is a chaotic attractor called the balanced state; whereas, the source of perceptual variability is an open question. We present a dynamical model with a chaotic attractor that explains both spiking and perceptual variability and adheres to a broad set of strict experimental constraints. The model makes quantitative predictions for how both spiking and perceptual variability will change as the stimulus changes.", "published": "2018-11-16T20:05:41Z", "version": 1}, {"aid": "1811.07017", "authors": ["Shagun Sodhani", "Sarath Chandar", "Yoshua Bengio"], "title": "Towards Training Recurrent Neural Networks for Lifelong Learning", "url": "http://arxiv.org/pdf/1811.07017v3", "summary": "Catastrophic forgetting and capacity saturation are the central challenges of any parametric lifelong learning system. In this work, we study these challenges in the context of sequential supervised learning with an emphasis on recurrent neural networks. To evaluate the models in the lifelong learning setting, we propose a curriculum-based, simple, and intuitive benchmark where the models are trained on tasks with increasing levels of difficulty. To measure the impact of catastrophic forgetting, the model is tested on all the previous tasks as it completes any task. As a step towards developing true lifelong learning systems, we unify Gradient Episodic Memory (a catastrophic forgetting alleviation approach) and Net2Net(a capacity expansion approach). Both these models are proposed in the context of feedforward networks and we evaluate the feasibility of using them for recurrent networks. Evaluation on the proposed benchmark shows that the unified model is more suitable than the constituent models for lifelong learning setting.", "published": "2018-11-16T20:13:23Z", "version": 3}, {"aid": "1812.03813", "authors": ["Marcel Nassar"], "title": "Hierarchical Bipartite Graph Convolution Networks", "url": "http://arxiv.org/pdf/1812.03813v2", "summary": "Recently, graph neural networks have been adopted in a wide variety of applications ranging from relational representations to modeling irregular data domains such as point clouds and social graphs. However, the space of graph neural network architectures remains highly fragmented impeding the development of optimized implementations similar to what is available for convolutional neural networks. In this work, we present BiGraphNet, a graph neural network architecture that generalizes many popular graph neural network models and enables new efficient operations similar to those supported by ConvNets. By explicitly separating the input and output nodes, BiGraphNet: (i) generalizes the graph convolution to support new efficient operations such as coarsened graph convolutions (similar to strided convolution in convnets), multiple input graphs convolution and graph expansions (unpooling) which can be used to implement various graph architectures such as graph autoencoders, and graph residual nets; and (ii) accelerates and scales the computations and memory requirements in hierarchical networks by performing computations only at specified output nodes.", "published": "2018-11-17T02:43:59Z", "version": 2}, {"aid": "1811.07246", "authors": ["Wenxuan Wu", "Zhongang Qi", "Li Fuxin"], "title": "PointConv: Deep Convolutional Networks on 3D Point Clouds", "url": "http://arxiv.org/pdf/1811.07246v3", "summary": "Unlike images which are represented in regular dense grids, 3D point clouds are irregular and unordered, hence applying convolution on them can be difficult. In this paper, we extend the dynamic filter to a new convolution operation, named PointConv. PointConv can be applied on point clouds to build deep convolutional networks. We treat convolution kernels as nonlinear functions of the local coordinates of 3D points comprised of weight and density functions. With respect to a given point, the weight functions are learned with multi-layer perceptron networks and density functions through kernel density estimation. The most important contribution of this work is a novel reformulation proposed for efficiently computing the weight functions, which allowed us to dramatically scale up the network and significantly improve its performance. The learned convolution kernel can be used to compute translation-invariant and permutation-invariant convolution on any point set in the 3D space. Besides, PointConv can also be used as deconvolution operators to propagate features from a subsampled point cloud back to its original resolution. Experiments on ModelNet40, ShapeNet, and ScanNet show that deep convolutional neural networks built on PointConv are able to achieve state-of-the-art on challenging semantic segmentation benchmarks on 3D point clouds. Besides, our experiments converting CIFAR-10 into a point cloud showed that networks built on PointConv can match the performance of convolutional networks in 2D images of a similar structure.", "published": "2018-11-17T23:42:13Z", "version": 3}, {"aid": "1811.07407", "authors": ["Faisal Mahmood", "Ziyun Yang", "Thomas Ashley", "Nicholas J. Durr"], "title": "Multimodal Densenet", "url": "http://arxiv.org/pdf/1811.07407v1", "summary": "Humans make accurate decisions by interpreting complex data from multiple sources. Medical diagnostics, in particular, often hinge on human interpretation of multi-modal information. In order for artificial intelligence to make progress in automated, objective, and accurate diagnosis and prognosis, methods to fuse information from multiple medical imaging modalities are required. However, combining information from multiple data sources has several challenges, as current deep learning architectures lack the ability to extract useful representations from multimodal information, and often simple concatenation is used to fuse such information. In this work, we propose Multimodal DenseNet, a novel architecture for fusing multimodal data. Instead of focusing on concatenation or early and late fusion, our proposed architectures fuses information over several layers and gives the model flexibility in how it combines information from multiple sources. We apply this architecture to the challenge of polyp characterization and landmark identification in endoscopy. Features from white light images are fused with features from narrow band imaging or depth maps. This study demonstrates that Multimodal DenseNet outperforms monomodal classification as well as other multimodal fusion techniques by a significant margin on two different datasets.", "published": "2018-11-18T21:31:22Z", "version": 1}, {"aid": "1811.07491", "authors": ["Yushan Feng", "Huitong Pan", "Craig Meyer", "Xue Feng"], "title": "A Self-Adaptive Network For Multiple Sclerosis Lesion Segmentation From Multi-Contrast MRI With Various Imaging Protocols", "url": "http://arxiv.org/pdf/1811.07491v1", "summary": "Deep neural networks (DNN) have shown promises in the lesion segmentation of multiple sclerosis (MS) from multicontrast MRI including T1, T2, proton density (PD) and FLAIR sequences. However, one challenge in deploying such networks into clinical practice is the variability of imaging protocols, which often differ from the training dataset as certain MRI sequences may be unavailable or unusable. Therefore, trained networks need to adapt to practical situations when imaging protocols are different in deployment. In this paper, we propose a DNN-based MS lesion segmentation framework with a novel technique called sequence dropout which can adapt to various combinations of input MRI sequences during deployment and achieve the maximal possible performance from the given input. In addition, with this framework, we studied the quantitative impact of each MRI sequence on the MS lesion segmentation task without training separate networks. Experiments were performed using the IEEE ISBI 2015 Longitudinal MS Lesion Challenge dataset and our method is currently ranked 2nd with a Dice similarity coefficient of 0.684. Furthermore, we showed our network achieved the maximal possible performance when one sequence is unavailable during deployment by comparing with separate networks trained on the corresponding input MRI sequences. In particular, we discovered T1 and PD have minor impact on segmentation performance while FLAIR is the predominant sequence. Experiments with multiple missing sequences were also performed and showed the robustness of our network.", "published": "2018-11-19T04:18:57Z", "version": 1}, {"aid": "1811.07542", "authors": ["Jean Stawiaski"], "title": "A Pretrained DenseNet Encoder for Brain Tumor Segmentation", "url": "http://arxiv.org/pdf/1811.07542v1", "summary": "This article presents a convolutional neural network for the automatic segmentation of brain tumors in multimodal 3D MR images based on a U-net architecture.We evaluate the use of a densely connected convolutional network encoder (DenseNet) which was pretrained on the ImageNet data set. We detail two network architectures that can take into account multiple 3D images as inputs. This work aims to identify if a generic pretrained network can be used for very specific medical applications where the target data differ both in the number of spatial dimensions as well as in the number of inputs channels. Moreover in order to regularize this transfer learning task we only train the decoder part of the U-net architecture. We evaluate the effectiveness of the proposed approach on the BRATS 2018 segmentation challenge where we obtained dice scores of 0.79, 0.90, 0.85 and 95/% Hausdorff distance of 2.9mm, 3.95mm, and 6.48mm for enhanced tumor core, whole tumor and tumor core respectively on the validation set. This scores degrades to 0.77, 0.88, 0.78 and 95 /% Hausdorff distance of 3.6mm, 5.72mm, and 5.83mm on the testing set.", "published": "2018-11-19T08:00:22Z", "version": 1}, {"aid": "1811.07545", "authors": ["Yunxiao Qin", "Chenxu Zhao", "Zezheng Wang", "Junliang Xing", "Jun Wan", "Zhen Lei"], "title": "Representation based and Attention augmented Meta learning", "url": "http://arxiv.org/pdf/1811.07545v3", "summary": "Deep learning based computer vision fails to work when labeled images are scarce. Recently, Meta learning algorithm has been confirmed as a promising way to improve the ability of learning from few images for computer vision. However, previous Meta learning approaches expose problems:   1) they ignored the importance of attention mechanism for the Meta learner;   2) they didn't give the Meta learner the ability of well using the past knowledge which can help to express images into high representations, resulting in that the Meta learner has to solve few shot learning task directly from the original high dimensional RGB images.   In this paper, we argue that the attention mechanism and the past knowledge are crucial for the Meta learner, and the Meta learner should be trained on high representations of the RGB images instead of directly on the original ones. Based on these arguments, we propose two methods: Attention augmented Meta Learning (AML) and Representation based and Attention augmented Meta Learning(RAML). The method AML aims to improve the Meta learner's attention ability by explicitly embedding an attention model into its network. The method RAML aims to give the Meta learner the ability of leveraging the past learned knowledge to reduce the dimension of the original input data by expressing it into high representations, and help the Meta learner to perform well. Extensive experiments demonstrate the effectiveness of the proposed models, with state-of-the-art few shot learning performances on several few shot learning benchmarks. The source code of our proposed methods will be released soon to facilitate further studies on those aforementioned problem.", "published": "2018-11-19T08:08:00Z", "version": 3}, {"aid": "1811.07583", "authors": ["Jaime Spencer", "Oscar Mendez", "Richard Bowden", "Simon Hadfield"], "title": "Localisation via Deep Imagination: learn the features not the map", "url": "http://arxiv.org/pdf/1811.07583v1", "summary": "How many times does a human have to drive through the same area to become familiar with it? To begin with, we might first build a mental model of our surroundings. Upon revisiting this area, we can use this model to extrapolate to new unseen locations and imagine their appearance. Based on this, we propose an approach where an agent is capable of modelling new environments after a single visitation. To this end, we introduce \"Deep Imagination\", a combination of classical Visual-based Monte Carlo Localisation and deep learning. By making use of a feature embedded 3D map, the system can \"imagine\" the view from any novel location. These \"imagined\" views are contrasted with the current observation in order to estimate the agent's current location. In order to build the embedded map, we train a deep Siamese Fully Convolutional U-Net to perform dense feature extraction. By training these features to be generic, no additional training or fine tuning is required to adapt to new environments. Our results demonstrate the generality and transfer capability of our learnt dense features by training and evaluating on multiple datasets. Additionally, we include several visualizations of the feature representations and resulting 3D maps, as well as their application to localisation.", "published": "2018-11-19T09:52:34Z", "version": 1}, {"aid": "1811.07727", "authors": ["Ping Luo", "Zhanglin Peng", "Jiamin Ren", "Ruimao Zhang"], "title": "Do Normalization Layers in a Deep ConvNet Really Need to Be Distinct?", "url": "http://arxiv.org/pdf/1811.07727v1", "summary": "Yes, they do. This work investigates a perspective for deep learning: whether different normalization layers in a ConvNet require different normalizers. This is the first step towards understanding this phenomenon. We allow each convolutional layer to be stacked before a switchable normalization (SN) that learns to choose a normalizer from a pool of normalization methods. Through systematic experiments in ImageNet, COCO, Cityscapes, and ADE20K, we answer three questions: (a) Is it useful to allow each normalization layer to select its own normalizer? (b) What impacts the choices of normalizers? (c) Do different tasks and datasets prefer different normalizers? Our results suggest that (1) using distinct normalizers improves both learning and generalization of a ConvNet; (2) the choices of normalizers are more related to depth and batch size, but less relevant to parameter initialization, learning rate decay, and solver; (3) different tasks and datasets have different behaviors when learning to select normalizers.", "published": "2018-11-19T14:36:25Z", "version": 1}, {"aid": "1812.07965", "authors": ["Yali Amit"], "title": "Deep learning with asymmetric connections and Hebbian updates", "url": "http://arxiv.org/pdf/1812.07965v2", "summary": "We show that deep networks can be trained using Hebbian updates yielding similar performance to ordinary back-propagation on challenging image datasets. To overcome the unrealistic symmetry in connections between layers, implicit in back-propagation, the feedback weights are separate from the feedforward weights. The feedback weights are also updated with a local rule, the same as the feedforward weights - a weight is updated solely based on the product of activity of the units it connects. With fixed feedback weights as proposed in Lillicrap et. al (2016) performance degrades quickly as the depth of the network increases. If the feedforward and feedback weights are initialized with the same values, as proposed in Zipser and Rumelhart (1990), they remain the same throughout training thus precisely implementing back-propagation. We show that even when the weights are initialized differently and at random, and the algorithm is no longer performing back-propagation, performance is comparable on challenging datasets. We also propose a cost function whose derivative can be represented as a local Hebbian update on the last layer. Convolutional layers are updated with tied weights across space, which is not biologically plausible. We show that similar performance is achieved with untied layers, also known as locally connected layers, corresponding to the connectivity implied by the convolutional layers, but where weights are untied and updated separately. In the linear case we show theoretically that the convergence of the error to zero is accelerated by the update of the feedback weights.", "published": "2018-11-19T20:40:29Z", "version": 2}, {"aid": "1811.08051", "authors": ["Prithviraj Dhar", "Rajat Vikram Singh", "Kuan-Chuan Peng", "Ziyan Wu", "Rama Chellappa"], "title": "Learning without Memorizing", "url": "http://arxiv.org/pdf/1811.08051v2", "summary": "Incremental learning (IL) is an important task aimed at increasing the capability of a trained model, in terms of the number of classes recognizable by the model. The key problem in this task is the requirement of storing data (e.g. images) associated with existing classes, while teaching the classifier to learn new classes. However, this is impractical as it increases the memory requirement at every incremental step, which makes it impossible to implement IL algorithms on edge devices with limited memory. Hence, we propose a novel approach, called `Learning without Memorizing (LwM)', to preserve the information about existing (base) classes, without storing any of their data, while making the classifier progressively learn the new classes. In LwM, we present an information preserving penalty: Attention Distillation Loss ($L_{AD}$), and demonstrate that penalizing the changes in classifiers' attention maps helps to retain information of the base classes, as new classes are added. We show that adding $L_{AD}$ to the distillation loss which is an existing information preserving loss consistently outperforms the state-of-the-art performance in the iILSVRC-small and iCIFAR-100 datasets in terms of the overall accuracy of base and incrementally learned classes.", "published": "2018-11-20T03:20:16Z", "version": 2}, {"aid": "1811.08056", "authors": ["Dae Hoon Park", "Chiu Man Ho", "Yi Chang", "Huaqing Zhang"], "title": "Gradient-Coherent Strong Regularization for Deep Neural Networks", "url": "http://arxiv.org/pdf/1811.08056v2", "summary": "Regularization plays an important role in generalization of deep neural networks, which are often prone to overfitting with their numerous parameters. L1 and L2 regularizers are common regularization tools in machine learning with their simplicity and effectiveness. However, we observe that imposing strong L1 or L2 regularization with stochastic gradient descent on deep neural networks easily fails, which limits the generalization ability of the underlying neural networks. To understand this phenomenon, we first investigate how and why learning fails when strong regularization is imposed on deep neural networks. We then propose a novel method, gradient-coherent strong regularization, which imposes regularization only when the gradients are kept coherent in the presence of strong regularization. Experiments are performed with multiple deep architectures on three benchmark data sets for image recognition. Experimental results show that our proposed approach indeed endures strong regularization and significantly improves both accuracy and compression (up to 9.9x), which could not be achieved otherwise.", "published": "2018-11-20T03:41:56Z", "version": 2}, {"aid": "1811.08081", "authors": ["Safwan Hossain", "Kiarash Jamali", "Yuchen Li", "Frank Rudzicz"], "title": "ChainGAN: A sequential approach to GANs", "url": "http://arxiv.org/pdf/1811.08081v2", "summary": "We propose a new architecture and training methodology for generative adversarial networks. Current approaches attempt to learn the transformation from a noise sample to a generated data sample in one shot. Our proposed generator architecture, called $\\textit{ChainGAN}$, uses a two-step process. It first attempts to transform a noise vector into a crude sample, similar to a traditional generator. Next, a chain of networks, called $\\textit{editors}$, attempt to sequentially enhance this sample. We train each of these units independently, instead of with end-to-end backpropagation on the entire chain. Our model is robust, efficient, and flexible as we can apply it to various network architectures. We provide rationale for our choices and experimentally evaluate our model, achieving competitive results on several datasets.", "published": "2018-11-20T05:30:32Z", "version": 2}, {"aid": "1811.08126", "authors": ["Firas Shama", "Roey Mechrez", "Alon Shoshan", "Lihi Zelnik-Manor"], "title": "Adversarial Feedback Loop", "url": "http://arxiv.org/pdf/1811.08126v1", "summary": "Thanks to their remarkable generative capabilities, GANs have gained great popularity, and are used abundantly in state-of-the-art methods and applications. In a GAN based model, a discriminator is trained to learn the real data distribution. To date, it has been used only for training purposes, where it's utilized to train the generator to provide real-looking outputs. In this paper we propose a novel method that makes an explicit use of the discriminator in test-time, in a feedback manner in order to improve the generator results. To the best of our knowledge it is the first time a discriminator is involved in test-time. We claim that the discriminator holds significant information on the real data distribution, that could be useful for test-time as well, a potential that has not been explored before.   The approach we propose does not alter the conventional training stage. At test-time, however, it transfers the output from the generator into the discriminator, and uses feedback modules (convolutional blocks) to translate the features of the discriminator layers into corrections to the features of the generator layers, which are used eventually to get a better generator result. Our method can contribute to both conditional and unconditional GANs. As demonstrated by our experiments, it can improve the results of state-of-the-art networks for super-resolution, and image generation.", "published": "2018-11-20T08:53:27Z", "version": 1}, {"aid": "1811.08210", "authors": ["Xing Hsu", "Zhifeng Zhao", "Rongpeng Li", "Honggang Zhang"], "title": "Brain-Inspired Stigmergy Learning", "url": "http://arxiv.org/pdf/1811.08210v1", "summary": "Stigmergy has proved its great superiority in terms of distributed control, robustness and adaptability, thus being regarded as an ideal solution for large-scale swarm control problems. Based on new discoveries on astrocytes in regulating synaptic transmission in the brain, this paper has mapped stigmergy mechanism into the interaction between synapses and investigated its characteristics and advantages. Particularly, we have divided the interaction between synapses which are not directly connected into three phases and proposed a stigmergic learning model. In this model, the state change of a stigmergy agent will expand its influence to affect the states of others. The strength of the interaction is determined by the level of neural activity as well as the distance between stigmergy agents. Inspired by the morphological and functional changes in astrocytes during environmental enrichment, it is likely that the regulation of distance between stigmergy agents plays a critical role in the stigmergy learning process. Simulation results have verified its importance and indicated that the well-regulated distance between stigmergy agents can help to obtain stigmergy learning gain.", "published": "2018-11-20T12:36:25Z", "version": 1}, {"aid": "1811.08618", "authors": ["Jinhyeok Jang", "Jaehong Kim", "Jaeyeon Lee", "Seungjoon Yang"], "title": "Neural Networks with Activation Networks", "url": "http://arxiv.org/pdf/1811.08618v1", "summary": "This work presents an adaptive activation method for neural networks that exploits the interdependency of features. Each pixel, node, and layer is assigned with a polynomial activation function, whose coefficients are provided by an auxiliary activation network. The activation of a feature depends on the features of neighboring pixels in a convolutional layer and other nodes in a dense layer. The dependency is learned from data by the activation networks. In our experiments, networks with activation networks provide significant performance improvement compared to the baseline networks on which they are built. The proposed method can be used to improve the network performance as an alternative to increasing the number of nodes and layers.", "published": "2018-11-21T07:54:41Z", "version": 1}, {"aid": "1811.08634", "authors": ["Yifan Yang", "Qijing Huang", "Bichen Wu", "Tianjun Zhang", "Liang Ma", "Giulio Gambardella", "Michaela Blott", "Luciano Lavagno", "Kees Vissers", "John Wawrzynek", "Kurt Keutzer"], "title": "Synetgy: Algorithm-hardware Co-design for ConvNet Accelerators on Embedded FPGAs", "url": "http://arxiv.org/pdf/1811.08634v4", "summary": "Using FPGAs to accelerate ConvNets has attracted significant attention in recent years. However, FPGA accelerator design has not leveraged the latest progress of ConvNets. As a result, the key application characteristics such as frames-per-second (FPS) are ignored in favor of simply counting GOPs, and results on accuracy, which is critical to application success, are often not even reported. In this work, we adopt an algorithm-hardware co-design approach to develop a ConvNet accelerator called Synetgy and a novel ConvNet model called DiracDeltaNet$^{\\dagger}$. Both the accelerator and ConvNet are tailored to FPGA requirements. DiracDeltaNet, as the name suggests, is a ConvNet with only $1\\times 1$ convolutions while spatial convolutions are replaced by more efficient shift operations. DiracDeltaNet achieves competitive accuracy on ImageNet (88.7\\% top-5), but with 42$\\times$ fewer parameters and 48$\\times$ fewer OPs than VGG16. We further quantize DiracDeltaNet's weights to 4-bit and activations to 4-bits, with less than 1\\% accuracy loss. These quantizations exploit well the nature of FPGA hardware. In short, DiracDeltaNet's small model size, low computational OP count, low precision and simplified operators allow us to co-design a highly customized computing unit for an FPGA. We implement the computing units for DiracDeltaNet on an Ultra96 SoC system through high-level synthesis. Our accelerator's final top-5 accuracy of 88.1\\% on ImageNet, is higher than all the previously reported embedded FPGA accelerators. In addition, the accelerator reaches an inference speed of 66.3 FPS on the ImageNet classification task, surpassing prior works with similar accuracy by at least 11.6$\\times$.", "published": "2018-11-21T08:42:30Z", "version": 4}, {"aid": "1811.08728", "authors": ["Christian Wilms", "Simone Frintrop"], "title": "AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects", "url": "http://arxiv.org/pdf/1811.08728v1", "summary": "We propose a novel approach for class-agnostic object proposal generation, which is efficient and especially well-suited to detect small objects. Efficiency is achieved by scale-specific objectness attention maps which focus the processing on promising parts of the image and reduce the amount of sampled windows strongly. This leads to a system, which is $33\\%$ faster than the state-of-the-art and clearly outperforming state-of-the-art in terms of average recall. Secondly, we add a module for detecting small objects, which are often missed by recent models. We show that this module improves the average recall for small objects by about $53\\%$.", "published": "2018-11-21T13:43:43Z", "version": 1}, {"aid": "1811.09347", "authors": ["Bowen Cheng", "Yunchao Wei", "Jiahui Yu", "Shiyu Chang", "Jinjun Xiong", "Wen-Mei Hwu", "Thomas S. Huang", "Humphrey Shi"], "title": "A Simple Non-i.i.d. Sampling Approach for Efficient Training and Better Generalization", "url": "http://arxiv.org/pdf/1811.09347v2", "summary": "While training on samples drawn from independent and identical distribution has been a de facto paradigm for optimizing image classification networks, humans learn new concepts in an easy-to-hard manner and on the selected examples progressively. Driven by this fact, we investigate the training paradigms where the samples are not drawn from independent and identical distribution. We propose a data sampling strategy, named Drop-and-Refresh (DaR), motivated by the learning behaviors of humans that selectively drop easy samples and refresh them only periodically. We show in our experiments that the proposed DaR strategy can maintain (and in many cases improve) the predictive accuracy even when the training cost is reduced by 15% on various datasets (CIFAR 10, CIFAR 100 and ImageNet) and with different backbone architectures (ResNets, DenseNets and MobileNets). Furthermore and perhaps more importantly, we find the ImageNet pre-trained models using our DaR sampling strategy achieves better transferability for the downstream tasks including object detection (+0.3 AP), instance segmentation (+0.3 AP), scene parsing (+0.5 mIoU) and human pose estimation (+0.6 AP). Our investigation encourages people to rethink the connections between the sampling strategy for training and the transferability of its learned features for pre-training ImageNet models.", "published": "2018-11-23T02:49:47Z", "version": 2}, {"aid": "1811.09358", "authors": ["Fangyu Zou", "Li Shen", "Zequn Jie", "Weizhong Zhang", "Wei Liu"], "title": "A Sufficient Condition for Convergences of Adam and RMSProp", "url": "http://arxiv.org/pdf/1811.09358v3", "summary": "Adam and RMSProp are two of the most influential adaptive stochastic algorithms for training deep neural networks, which have been pointed out to be divergent even in the convex setting via a few simple counterexamples. Many attempts, such as decreasing an adaptive learning rate, adopting a big batch size, incorporating a temporal decorrelation technique, seeking an analogous surrogate, etc., have been tried to promote Adam/RMSProp-type algorithms to converge. In contrast with existing approaches, we introduce an alternative easy-to-check sufficient condition, which merely depends on the parameters of the base learning rate and combinations of historical second-order moments, to guarantee the global convergence of generic Adam/RMSProp for solving large-scale non-convex stochastic optimization. Moreover, we show that the convergences of several variants of Adam, such as AdamNC, AdaEMA, etc., can be directly implied via the proposed sufficient condition in the non-convex setting. In addition, we illustrate that Adam is essentially a specifically weighted AdaGrad with exponential moving average momentum, which provides a novel perspective for understanding Adam and RMSProp. This observation coupled with this sufficient condition gives much deeper interpretations on their divergences. At last, we validate the sufficient condition by applying Adam and RMSProp to tackle a certain counterexample and train deep neural networks. Numerical results are exactly in accord with our theoretical analysis.", "published": "2018-11-23T04:26:47Z", "version": 3}, {"aid": "1811.09362", "authors": ["Yansen Wang", "Ying Shen", "Zhun Liu", "Paul Pu Liang", "Amir Zadeh", "Louis-Philippe Morency"], "title": "Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors", "url": "http://arxiv.org/pdf/1811.09362v2", "summary": "Humans convey their intentions through the usage of both verbal and nonverbal behaviors during face-to-face communication. Speaker intentions often vary dynamically depending on different nonverbal contexts, such as vocal patterns and facial expressions. As a result, when modeling human language, it is essential to not only consider the literal meaning of the words but also the nonverbal contexts in which these words appear. To better model human language, we first model expressive nonverbal representations by analyzing the fine-grained visual and acoustic patterns that occur during word segments. In addition, we seek to capture the dynamic nature of nonverbal intents by shifting word representations based on the accompanying nonverbal behaviors. To this end, we propose the Recurrent Attended Variation Embedding Network (RAVEN) that models the fine-grained structure of nonverbal subword sequences and dynamically shifts word representations based on nonverbal cues. Our proposed model achieves competitive performance on two publicly available datasets for multimodal sentiment analysis and emotion recognition. We also visualize the shifted word representations in different nonverbal contexts and summarize common patterns regarding multimodal variations of word representations.", "published": "2018-11-23T05:13:38Z", "version": 2}, {"aid": "1811.09567", "authors": ["Yipeng Qin", "Niloy Mitra", "Peter Wonka"], "title": "How does Lipschitz Regularization Influence GAN Training?", "url": "http://arxiv.org/pdf/1811.09567v3", "summary": "Despite the success of Lipschitz regularization in stabilizing GAN training, the exact reason of its effectiveness remains poorly understood. The direct effect of $K$-Lipschitz regularization is to restrict the $L2$-norm of the neural network gradient to be smaller than a threshold $K$ (e.g., $K=1$) such that $\\|\\nabla f\\| \\leq K$. In this work, we uncover an even more important effect of Lipschitz regularization by examining its impact on the loss function: It degenerates GAN loss functions to almost linear ones by restricting their domain and interval of attainable gradient values. Our analysis shows that loss functions are only successful if they are degenerated to almost linear ones. We also show that loss functions perform poorly if they are not degenerated and that a wide range of functions can be used as loss function as long as they are sufficiently degenerated by regularization. Basically, Lipschitz regularization ensures that all loss functions effectively work in the same way. Empirically, we verify our proposition on the MNIST, CIFAR10 and CelebA datasets.", "published": "2018-11-23T17:18:00Z", "version": 3}, {"aid": "1811.09699", "authors": ["Hossein Adeli", "Gregory Zelinsky"], "title": "Learning to attend in a brain-inspired deep neural network", "url": "http://arxiv.org/pdf/1811.09699v1", "summary": "Recent machine learning models have shown that including attention as a component results in improved model accuracy and interpretability, despite the concept of attention in these approaches only loosely approximating the brain's attention mechanism. Here we extend this work by building a more brain-inspired deep network model of the primate ATTention Network (ATTNet) that learns to shift its attention so as to maximize the reward. Using deep reinforcement learning, ATTNet learned to shift its attention to the visual features of a target category in the context of a search task. ATTNet's dorsal layers also learned to prioritize these shifts of attention so as to maximize success of the ventral pathway classification and receive greater reward. Model behavior was tested against the fixations made by subjects searching images for the same cued category. Both subjects and ATTNet showed evidence for attention being preferentially directed to target goals, behaviorally measured as oculomotor guidance to targets. More fundamentally, ATTNet learned to shift its attention to target like objects and spatially route its visual inputs to accomplish the task. This work makes a step toward a better understanding of the role of attention in the brain and other computational systems.", "published": "2018-11-23T21:23:56Z", "version": 1}, {"aid": "1811.09786", "authors": ["Yi Tay", "Luu Anh Tuan", "Siu Cheung Hui"], "title": "Recurrently Controlled Recurrent Networks", "url": "http://arxiv.org/pdf/1811.09786v1", "summary": "Recurrent neural networks (RNNs) such as long short-term memory and gated recurrent units are pivotal building blocks across a broad spectrum of sequence modeling problems. This paper proposes a recurrently controlled recurrent network (RCRN) for expressive and powerful sequence encoding. More concretely, the key idea behind our approach is to learn the recurrent gating functions using recurrent networks. Our architecture is split into two components - a controller cell and a listener cell whereby the recurrent controller actively influences the compositionality of the listener cell. We conduct extensive experiments on a myriad of tasks in the NLP domain such as sentiment analysis (SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment classification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading comprehension (NarrativeQA). Across all 26 datasets, our results demonstrate that RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs, suggesting that our controller architecture might be a suitable replacement for the widely adopted stacked architecture.", "published": "2018-11-24T08:15:50Z", "version": 1}, {"aid": "1811.09800", "authors": ["Abhijit Guha Roy", "Sailesh Conjeti", "Nassir Navab", "Christian Wachinger"], "title": "Bayesian QuickNAT: Model Uncertainty in Deep Whole-Brain Segmentation for Structure-wise Quality Control", "url": "http://arxiv.org/pdf/1811.09800v1", "summary": "We introduce Bayesian QuickNAT for the automated quality control of whole-brain segmentation on MRI T1 scans. Next to the Bayesian fully convolutional neural network, we also present inherent measures of segmentation uncertainty that allow for quality control per brain structure. For estimating model uncertainty, we follow a Bayesian approach, wherein, Monte Carlo (MC) samples from the posterior distribution are generated by keeping the dropout layers active at test time. Entropy over the MC samples provides a voxel-wise model uncertainty map, whereas expectation over the MC predictions provides the final segmentation. Next to voxel-wise uncertainty, we introduce four metrics to quantify structure-wise uncertainty in segmentation for quality control. We report experiments on four out-of-sample datasets comprising of diverse age range, pathology and imaging artifacts. The proposed structure-wise uncertainty metrics are highly correlated with the Dice score estimated with manual annotation and therefore present an inherent measure of segmentation quality. In particular, the intersection over union over all the MC samples is a suitable proxy for the Dice score. In addition to quality control at scan-level, we propose to incorporate the structure-wise uncertainty as a measure of confidence to do reliable group analysis on large data repositories. We envisage that the introduced uncertainty metrics would help assess the fidelity of automated deep learning based segmentation methods for large-scale population studies, as they enable automated quality control and group analyses in processing large data repositories.", "published": "2018-11-24T09:41:28Z", "version": 1}, {"aid": "1811.10052", "authors": ["Alexander Selvikv\u00e5g Lundervold", "Arvid Lundervold"], "title": "An overview of deep learning in medical imaging focusing on MRI", "url": "http://arxiv.org/pdf/1811.10052v2", "summary": "What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI.   Our aim is threefold: (i) give a brief introduction to deep learning with pointers to core references; (ii) indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii) provide a starting point for people interested in experimenting and perhaps contributing to the field of machine learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.", "published": "2018-11-25T16:40:42Z", "version": 2}, {"aid": "1811.10111", "authors": ["Abhay Koushik", "Judith Amores", "Pattie Maes"], "title": "Real-Time Sleep Staging using Deep Learning on a Smartphone for a Wearable EEG", "url": "http://arxiv.org/pdf/1811.10111v2", "summary": "We present the first real-time sleep staging system that uses deep learning without the need for servers in a smartphone application for a wearable EEG. We employ real-time adaptation of a single channel Electroencephalography (EEG) to infer from a Time-Distributed 1-D Deep Convolutional Neural Network. Polysomnography (PSG)-the gold standard for sleep staging, requires a human scorer and is both complex and resource-intensive. Our work demonstrates an end-to-end on-smartphone pipeline that can infer sleep stages in just single 30-second epochs, with an overall accuracy of 83.5% on 20-fold cross validation for five-class classification of sleep stages using the open Sleep-EDF dataset.", "published": "2018-11-25T22:25:31Z", "version": 2}, {"aid": "1811.10146", "authors": ["Zhi-Qin John Xu"], "title": "Frequency Principle in Deep Learning with General Loss Functions and Its Potential Application", "url": "http://arxiv.org/pdf/1811.10146v1", "summary": "Previous studies have shown that deep neural networks (DNNs) with common settings often capture target functions from low to high frequency, which is called Frequency Principle (F-Principle). It has also been shown that F-Principle can provide an understanding to the often observed good generalization ability of DNNs. However, previous studies focused on the loss function of mean square error, while various loss functions are used in practice. In this work, we show that the F-Principle holds for a general loss function (e.g., mean square error, cross entropy, etc.). In addition, DNN's F-Principle may be applied to develop numerical schemes for solving various problems which would benefit from a fast converging of low frequency. As an example of the potential usage of F-Principle, we apply DNN in solving differential equations, in which conventional methods (e.g., Jacobi method) is usually slow in solving problems due to the convergence from high to low frequency.", "published": "2018-11-26T02:27:44Z", "version": 1}, {"aid": "1811.10355", "authors": ["Benjamin Graham"], "title": "Unsupervised learning with sparse space-and-time autoencoders", "url": "http://arxiv.org/pdf/1811.10355v1", "summary": "We use spatially-sparse two, three and four dimensional convolutional autoencoder networks to model sparse structures in 2D space, 3D space, and 3+1=4 dimensional space-time. We evaluate the resulting latent spaces by testing their usefulness for downstream tasks. Applications are to handwriting recognition in 2D, segmentation for parts in 3D objects, segmentation for objects in 3D scenes, and body-part segmentation for 4D wire-frame models generated from motion capture data.", "published": "2018-11-26T13:22:17Z", "version": 1}, {"aid": "1811.10798", "authors": ["Yiwen Huang", "Rihui Wu", "Pinglai Ou", "Ziyong Feng"], "title": "Sequentially Aggregated Convolutional Networks", "url": "http://arxiv.org/pdf/1811.10798v3", "summary": "Modern deep networks generally implement a certain form of shortcut connections to alleviate optimization difficulties. However, we observe that such network topology alters the nature of deep networks. In many ways, these networks behave similarly to aggregated wide networks. We thus exploit the aggregation nature of shortcut connections at a finer architectural level and place them within wide convolutional layers. We end up with a sequentially aggregated convolutional (SeqConv) layer that combines the benefits of both wide and deep representations by aggregating features of various depths in sequence. The proposed SeqConv serves as a drop-in replacement of regular wide convolutional layers and thus could be handily integrated into any backbone network. We apply SeqConv to widely adopted backbones including ResNet and ResNeXt, and conduct experiments for image classification on public benchmark datasets. Our ResNet based network with a model size of ResNet-50 easily surpasses the performance of the 2.35$\\times$ larger ResNet-152, while our ResNeXt based model sets a new state-of-the-art accuracy on ImageNet classification for networks with similar model complexity. The code and pre-trained models of our work are publicly available at https://github.com/GroupOfAlchemists/SeqConv.", "published": "2018-11-27T04:15:35Z", "version": 3}, {"aid": "1811.11051", "authors": ["Idan Kligvasser", "Tomer Michaeli"], "title": "Dense xUnit Networks", "url": "http://arxiv.org/pdf/1811.11051v1", "summary": "Deep net architectures have constantly evolved over the past few years, leading to significant advancements in a wide array of computer vision tasks. However, besides high accuracy, many applications also require a low computational load and limited memory footprint. To date, efficiency has typically been achieved either by architectural choices at the macro level (e.g. using skip connections or pruning techniques) or modifications at the level of the individual layers (e.g. using depth-wise convolutions or channel shuffle operations). Interestingly, much less attention has been devoted to the role of the activation functions in constructing efficient nets. Recently, Kligvasser et al. showed that incorporating spatial connections within the activation functions, enables a significant boost in performance in image restoration tasks, at any given budget of parameters. However, the effectiveness of their xUnit module has only been tested on simple small models, which are not characteristic of those used in high-level vision tasks. In this paper, we adopt and improve the xUnit activation, show how it can be incorporated into the DenseNet architecture, and illustrate its high effectiveness for classification and image restoration tasks alike. While the DenseNet architecture is extremely efficient to begin with, our dense xUnit net (DxNet) can typically achieve the same performance with far fewer parameters. For example, on ImageNet, our DxNet outperforms a ReLU-based DenseNet having 30% more parameters and achieves state-of-the-art results for this budget of parameters. Furthermore, in denoising and super-resolution, DxNet significantly improves upon all existing lightweight solutions, including the xUnit-based nets of Kligvasser et al.", "published": "2018-11-27T15:21:50Z", "version": 1}, {"aid": "1811.11168", "authors": ["Xizhou Zhu", "Han Hu", "Stephen Lin", "Jifeng Dai"], "title": "Deformable ConvNets v2: More Deformable, Better Results", "url": "http://arxiv.org/pdf/1811.11168v2", "summary": "The superior performance of Deformable Convolutional Networks arises from its ability to adapt to the geometric variations of objects. Through an examination of its adaptive behavior, we observe that while the spatial support for its neural features conforms more closely than regular ConvNets to object structure, this support may nevertheless extend well beyond the region of interest, causing features to be influenced by irrelevant image content. To address this problem, we present a reformulation of Deformable ConvNets that improves its ability to focus on pertinent image regions, through increased modeling power and stronger training. The modeling power is enhanced through a more comprehensive integration of deformable convolution within the network, and by introducing a modulation mechanism that expands the scope of deformation modeling. To effectively harness this enriched modeling capability, we guide network training via a proposed feature mimicking scheme that helps the network to learn features that reflect the object focus and classification power of R-CNN features. With the proposed contributions, this new version of Deformable ConvNets yields significant performance gains over the original model and produces leading results on the COCO benchmark for object detection and instance segmentation.", "published": "2018-11-27T18:58:11Z", "version": 2}, {"aid": "1811.11205", "authors": ["Zhourong Chen", "Yang Li", "Samy Bengio", "Si Si"], "title": "You Look Twice: GaterNet for Dynamic Filter Selection in CNNs", "url": "http://arxiv.org/pdf/1811.11205v2", "summary": "The concept of conditional computation for deep nets has been proposed previously to improve model performance by selectively using only parts of the model conditioned on the sample it is processing. In this paper, we investigate input-dependent dynamic filter selection in deep convolutional neural networks (CNNs). The problem is interesting because the idea of forcing different parts of the model to learn from different types of samples may help us acquire better filters in CNNs, improve the model generalization performance and potentially increase the interpretability of model behavior. We propose a novel yet simple framework called GaterNet, which involves a backbone and a gater network. The backbone network is a regular CNN that performs the major computation needed for making a prediction, while a global gater network is introduced to generate binary gates for selectively activating filters in the backbone network based on each input. Extensive experiments on CIFAR and ImageNet datasets show that our models consistently outperform the original models with a large margin. On CIFAR-10, our model also improves upon state-of-the-art results.", "published": "2018-11-27T19:14:49Z", "version": 2}, {"aid": "1811.11236", "authors": ["Liane Gabora"], "title": "The Making of a Creative Worldview", "url": "http://arxiv.org/pdf/1811.11236v1", "summary": "Research at the interface between cognitive psychology, neuroscience, and the science of complex, dynamical systems, is piecing together an understanding of the creative process, including how it works, how it can be fostered, and the developmental antecedents and personality traits of particularly creative people. This chapter examines the workings of creative minds, those with the potential to significantly impact the evolution of human culture.", "published": "2018-11-27T20:14:31Z", "version": 1}, {"aid": "1811.11876", "authors": ["Rajesh P. N. Rao"], "title": "Towards Neural Co-Processors for the Brain: Combining Decoding and Encoding in Brain-Computer Interfaces", "url": "http://arxiv.org/pdf/1811.11876v2", "summary": "The field of brain-computer interfaces is poised to advance from the traditional goal of controlling prosthetic devices using brain signals to combining neural decoding and encoding within a single neuroprosthetic device. Such a device acts as a \"co-processor\" for the brain, with applications ranging from inducing Hebbian plasticity for rehabilitation after brain injury to reanimating paralyzed limbs and enhancing memory. We review recent progress in simultaneous decoding and encoding for closed-loop control and plasticity induction. To address the challenge of multi-channel decoding and encoding, we introduce a unifying framework for developing brain co-processors based on artificial neural networks and deep learning. These \"neural co-processors\" can be used to jointly optimize cost functions with the nervous system to achieve desired behaviors ranging from targeted neuro-rehabilitation to augmentation of brain function.", "published": "2018-11-28T23:13:24Z", "version": 2}, {"aid": "1811.11987", "authors": ["Laurent Bou\u00e9"], "title": "Deep learning for pedestrians: backpropagation in CNNs", "url": "http://arxiv.org/pdf/1811.11987v1", "summary": "The goal of this document is to provide a pedagogical introduction to the main concepts underpinning the training of deep neural networks using gradient descent; a process known as backpropagation. Although we focus on a very influential class of architectures called \"convolutional neural networks\" (CNNs) the approach is generic and useful to the machine learning community as a whole. Motivated by the observation that derivations of backpropagation are often obscured by clumsy index-heavy narratives that appear somewhat mathemagical, we aim to offer a conceptually clear, vectorized description that articulates well the higher level logic. Following the principle of \"writing is nature's way of letting you know how sloppy your thinking is\", we try to make the calculations meticulous, self-contained and yet as intuitive as possible. Taking nothing for granted, ample illustrations serve as visual guides and an extensive bibliography is provided for further explorations.   (For the sake of clarity, long mathematical derivations and visualizations have been broken up into short \"summarized views\" and longer \"detailed views\" encoded into the PDF as optional content groups. Some figures contain animations designed to illustrate important concepts in a more engaging style. For these reasons, we advise to download the document locally and open it using Adobe Acrobat Reader. Other viewers were not tested and may not render the detailed views, animations correctly.)", "published": "2018-11-29T07:00:09Z", "version": 1}, {"aid": "1811.12043", "authors": ["Jun-Hyuk Kim", "Jun-Ho Choi", "Manri Cheon", "Jong-Seok Lee"], "title": "MAMNet: Multi-path Adaptive Modulation Network for Image Super-Resolution", "url": "http://arxiv.org/pdf/1811.12043v2", "summary": "In recent years, single image super-resolution (SR) methods based on deep convolutional neural networks (CNNs) have made significant progress. However, due to the non-adaptive nature of the convolution operation, they cannot adapt to various characteristics of images, which limits their representational capability and, consequently, results in unnecessarily large model sizes. To address this issue, we propose a novel multi-path adaptive modulation network (MAMNet). Specifically, we propose a multi-path adaptive modulation block (MAMB), which is a lightweight yet effective residual block that adaptively modulates residual feature responses by fully exploiting their information via three paths. The three paths model three types of information suitable for SR: 1) channel-specific information (CSI) using global variance pooling, 2) inter-channel dependencies (ICD) based on the CSI, 3) and channel-specific spatial dependencies (CSD) via depth-wise convolution. We demonstrate that the proposed MAMB is effective and parameter-efficient for image SR than other feature modulation methods. In addition, experimental results show that our MAMNet outperforms most of the state-of-the-art methods with a relatively small number of parameters.", "published": "2018-11-29T09:59:31Z", "version": 2}, {"aid": "1811.12091", "authors": ["Patrick Krauss", "Karin Prebeck", "Achim Schilling", "Claus Metzner"], "title": "Stochastic resonance in three-neuron motifs", "url": "http://arxiv.org/pdf/1811.12091v1", "summary": "Stochastic resonance is a non-linear phenomenon, in which the sensitivity of signal detectors can be enhanced by adding random noise to the detector input. Here, we demonstrate that noise can also improve the information flux in recurrent neural networks. In particular, we show for the case of three-neuron motifs that the mutual information between successive network states can be maximized by adding a suitable amount of noise to the neuron inputs. This striking result suggests that noise in the brain may not be a problem that needs to be suppressed, but indeed a resource that is dynamically regulated in order to optimize information processing.", "published": "2018-11-29T12:12:47Z", "version": 1}, {"aid": "1811.12108", "authors": ["Kilho Son", "Jesse Hostetler", "Sek Chai"], "title": "Bootstrapping Deep Neural Networks from Approximate Image Processing Pipelines", "url": "http://arxiv.org/pdf/1811.12108v2", "summary": "Complex image processing and computer vision systems often consist of a processing pipeline of functional modules. We intend to replace parts or all of a target pipeline with deep neural networks to achieve benefits such as increased accuracy or reduced computational requirement. To acquire a large amount of labeled data necessary to train the deep neural network, we propose a workflow that leverages the target pipeline to create a significantly larger labeled training set automatically, without prior domain knowledge of the target pipeline. We show experimentally that despite the noise introduced by automated labeling and only using a very small initially labeled data set, the trained deep neural networks can achieve similar or even better performance than the components they replace, while in some cases also reducing computational requirements.", "published": "2018-11-29T12:54:51Z", "version": 2}, {"aid": "1811.12231", "authors": ["Robert Geirhos", "Patricia Rubisch", "Claudio Michaelis", "Matthias Bethge", "Felix A. Wichmann", "Wieland Brendel"], "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness", "url": "http://arxiv.org/pdf/1811.12231v3", "summary": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNet-trained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation.", "published": "2018-11-29T15:04:05Z", "version": 3}, {"aid": "1811.12248", "authors": ["Yuancheng Ye", "Xiaodong Yang", "Yingli Tian"], "title": "Discovering Spatio-Temporal Action Tubes", "url": "http://arxiv.org/pdf/1811.12248v1", "summary": "In this paper, we address the challenging problem of spatial and temporal action detection in videos. We first develop an effective approach to localize frame-level action regions through integrating static and kinematic information by the early- and late-fusion detection scheme. With the intention of exploring important temporal connections among the detected action regions, we propose a tracking-by-point-matching algorithm to stitch the discrete action regions into a continuous spatio-temporal action tube. Recurrent 3D convolutional neural network is used to predict action categories and determine temporal boundaries of the generated tubes. We then introduce an action footprint map to refine the candidate tubes based on the action-specific spatial characteristics preserved in the convolutional layers of R3DCNN. In the extensive experiments, our method achieves superior detection results on the three public benchmark datasets: UCFSports, J-HMDB and UCF101.", "published": "2018-11-29T15:29:43Z", "version": 1}, {"aid": "1811.12560", "authors": ["Vincent Francois-Lavet", "Peter Henderson", "Riashat Islam", "Marc G. Bellemare", "Joelle Pineau"], "title": "An Introduction to Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1811.12560v2", "summary": "Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.", "published": "2018-11-30T00:57:30Z", "version": 2}, {"aid": "1811.12642", "authors": ["Tomasz M. Rutkowski", "Qibin Zhao", "Masao S. Abe", "Mihoko Otake"], "title": "AI Neurotechnology for Aging Societies -- Task-load and Dementia EEG Digital Biomarker Development Using Information Geometry Machine Learning Methods", "url": "http://arxiv.org/pdf/1811.12642v1", "summary": "Dementia and especially Alzheimer's disease (AD) are the most common causes of cognitive decline in elderly people. A spread of the above mentioned mental health problems in aging societies is causing a significant medical and economic burden in many countries around the world. According to a recent World Health Organization (WHO) report, it is approximated that currently, worldwide, about 47 million people live with a dementia spectrum of neurocognitive disorders. This number is expected to triple by 2050, which calls for possible application of AI-based technologies to support an early screening for preventive interventions and a subsequent mental wellbeing monitoring as well as maintenance with so-called digital-pharma or beyond a pill therapeutical approaches. This paper discusses our attempt and preliminary results of brainwave (EEG) techniques to develop digital biomarkers for dementia progress detection and monitoring. We present an information geometry-based classification approach for automatic EEG-derived event related responses (ERPs) discrimination of low versus high task-load auditory or tactile stimuli recognition, of which amplitude and latency variabilities are similar to those in dementia. The discussed approach is a step forward to develop AI, and especially machine learning (ML) approaches, for the subsequent application to mild-cognitive impairment (MCI) and AD diagnostics.", "published": "2018-11-30T06:58:16Z", "version": 1}, {"aid": "1812.00020", "authors": ["Jingwei Huang", "Haotian Zhang", "Li Yi", "Thomas Funkhouser", "Matthias Nie\u00dfner", "Leonidas Guibas"], "title": "TextureNet: Consistent Local Parametrizations for Learning from High-Resolution Signals on Meshes", "url": "http://arxiv.org/pdf/1812.00020v2", "summary": "We introduce, TextureNet, a neural network architecture designed to extract features from high-resolution signals associated with 3D surface meshes (e.g., color texture maps). The key idea is to utilize a 4-rotational symmetric (4-RoSy) field to define a domain for convolution on a surface. Though 4-RoSy fields have several properties favorable for convolution on surfaces (low distortion, few singularities, consistent parameterization, etc.), orientations are ambiguous up to 4-fold rotation at any sample point. So, we introduce a new convolutional operator invariant to the 4-RoSy ambiguity and use it in a network to extract features from high-resolution signals on geodesic neighborhoods of a surface. In comparison to alternatives, such as PointNet based methods which lack a notion of orientation, the coherent structure given by these neighborhoods results in significantly stronger features. As an example application, we demonstrate the benefits of our architecture for 3D semantic segmentation of textured 3D meshes. The results show that our method outperforms all existing methods on the basis of mean IoU by a significant margin in both geometry-only (6.4%) and RGB+Geometry (6.9-8.2%) settings.", "published": "2018-11-30T19:01:09Z", "version": 2}, {"aid": "1812.00136", "authors": ["Yujian Li"], "title": "Theory of Cognitive Relativity: A Promising Paradigm for True AI", "url": "http://arxiv.org/pdf/1812.00136v3", "summary": "The rise of deep learning has brought artificial intelligence (AI) to the forefront. The ultimate goal of AI is to realize machines with human mind and consciousness, but existing achievements mainly simulate intelligent behavior on computer platforms. These achievements all belong to weak AI rather than strong AI. How to achieve strong AI is not known yet in the field of intelligence science. Currently, this field is calling for a new paradigm, especially Theory of Cognitive Relativity (TCR). The TCR aims to summarize a simple and elegant set of first principles about the nature of intelligence, at least including the Principle of World's Relativity and the Principle of Symbol's Relativity. The Principle of World's Relativity states that the subjective world an intelligent agent can observe is strongly constrained by the way it perceives the objective world. The Principle of Symbol's Relativity states that an intelligent agent can use any physical symbol system to express what it observes in its subjective world. The two principles are derived from scientific facts and life experience. Thought experiments show that they are important to understand high-level intelligence and necessary to establish a scientific theory of mind and consciousness. Rather than brain-like intelligence, the TCR indeed advocates a promising change in direction to realize true AI, i.e. artificial general intelligence or artificial consciousness, particularly different from humans' and animals'. Furthermore, a TCR creed has been presented and extended to reveal the secrets of consciousness and to guide realization of conscious machines. In the sense that true AI could be diversely implemented in a brain-different way, the TCR would probably drive an intelligence revolution in combination with some additional first principles.", "published": "2018-12-01T04:01:03Z", "version": 3}, {"aid": "1812.00231", "authors": ["Assaf Shocher", "Shai Bagon", "Phillip Isola", "Michal Irani"], "title": "InGAN: Capturing and Remapping the \"DNA\" of a Natural Image", "url": "http://arxiv.org/pdf/1812.00231v2", "summary": "Generative Adversarial Networks (GANs) typically learn a distribution of images in a large image dataset, and are then able to generate new images from this distribution. However, each natural image has its own internal statistics, captured by its unique distribution of patches. In this paper we propose an \"Internal GAN\" (InGAN) - an image-specific GAN - which trains on a single input image and learns its internal distribution of patches. It is then able to synthesize a plethora of new natural images of significantly different sizes, shapes and aspect-ratios - all with the same internal patch-distribution (same \"DNA\") as the input image. In particular, despite large changes in global size/shape of the image, all elements inside the image maintain their local size/shape. InGAN is fully unsupervised, requiring no additional data other than the input image itself. Once trained on the input image, it can remap the input to any size or shape in a single feedforward pass, while preserving the same internal patch distribution. InGAN provides a unified framework for a variety of tasks, bridging the gap between textures and natural images.", "published": "2018-12-01T17:48:02Z", "version": 2}, {"aid": "1812.00278", "authors": ["Nikolaus Kriegeskorte", "Pamela K. Douglas"], "title": "Interpreting Encoding and Decoding Models", "url": "http://arxiv.org/pdf/1812.00278v2", "summary": "Encoding and decoding models are widely used in systems, cognitive, and computational neuroscience to make sense of brain-activity data. However, the interpretation of their results requires care. Decoding models can help reveal whether particular information is present in a brain region in a format the decoder can exploit. Encoding models make comprehensive predictions about representational spaces. In the context of sensory systems, encoding models enable us to test and compare brain-computational models, and thus directly constrain computational theory. Encoding and decoding models typically include fitted linear-model components. Sometimes the weights of the fitted linear combinations are interpreted as reflecting, in an encoding model, the contribution of different sensory features to the representation or, in a decoding model, the contribution of different measured brain responses to a decoded feature. Such interpretations can be problematic when the predictor variables or their noise components are correlated and when priors (or penalties) are used to regularize the fit. Encoding and decoding models are evaluated in terms of their generalization performance. The correct interpretation depends on the level of generalization a model achieves (e.g. to new response measurements for the same stimuli, to new stimuli from the same population, or to stimuli from a different population). Significant decoding or encoding performance of a single model (at whatever level of generality) does not provide strong constraints for theory. Many models must be tested and inferentially compared for analyses to drive theoretical progress.", "published": "2018-12-01T22:58:55Z", "version": 2}, {"aid": "1812.01714", "authors": ["Yuji Yoshimura", "Bill Cai", "Zhoutong Wang", "Carlo Ratti"], "title": "Deep Learning Architect: Classification for Architectural Design through the Eye of Artificial Intelligence", "url": "http://arxiv.org/pdf/1812.01714v1", "summary": "This paper applies state-of-the-art techniques in deep learning and computer vision to measure visual similarities between architectural designs by different architects. Using a dataset consisting of web scraped images and an original collection of images of architectural works, we first train a deep convolutional neural network (DCNN) model capable of achieving 73% accuracy in classifying works belonging to 34 different architects. Through examining the weights in the trained DCNN model, we are able to quantitatively measure the visual similarities between architects that are implicitly learned by our model. Using this measure, we cluster architects that are identified to be similar and compare our findings to conventional classification made by architectural historians and theorists. Our clustering of architectural designs remarkably corroborates conventional views in architectural history, and the learned architectural features also coheres with the traditional understanding of architectural designs.", "published": "2018-12-03T00:30:59Z", "version": 1}, {"aid": "1812.00722", "authors": ["Petros Koutras", "Petros Maragos"], "title": "SUSiNet: See, Understand and Summarize it", "url": "http://arxiv.org/pdf/1812.00722v2", "summary": "In this work we propose a multi-task spatio-temporal network, called SUSiNet, that can jointly tackle the spatio-temporal problems of saliency estimation, action recognition and video summarization. Our approach employs a single network that is jointly end-to-end trained for all tasks with multiple and diverse datasets related to the exploring tasks. The proposed network uses a unified architecture that includes global and task specific layer and produces multiple output types, i.e., saliency maps or classification labels, by employing the same video input. Moreover, one additional contribution is that the proposed network can be deeply supervised through an attention module that is related to human attention as it is expressed by eye-tracking data. From the extensive evaluation, on seven different datasets, we have observed that the multi-task network performs as well as the state-of-the-art single-task methods (or in some cases better), while it requires less computational budget than having one independent network per each task.", "published": "2018-12-03T13:21:51Z", "version": 2}, {"aid": "1812.01719", "authors": ["Patrick McClure", "Nao Rho", "John A. Lee", "Jakub R. Kaczmarzyk", "Charles Zheng", "Satrajit S. Ghosh", "Dylan Nielson", "Adam G. Thomas", "Peter Bandettini", "Francisco Pereira"], "title": "Knowing what you know in brain segmentation using Bayesian deep neural networks", "url": "http://arxiv.org/pdf/1812.01719v5", "summary": "In this paper, we describe a Bayesian deep neural network (DNN) for predicting FreeSurfer segmentations of structural MRI volumes, in minutes rather than hours. The network was trained and evaluated on a large dataset (n = 11,480), obtained by combining data from more than a hundred different sites, and also evaluated on another completely held-out dataset (n = 418). The network was trained using a novel spike-and-slab dropout-based variational inference approach. We show that, on these datasets, the proposed Bayesian DNN outperforms previously proposed methods, in terms of the similarity between the segmentation predictions and the FreeSurfer labels, and the usefulness of the estimate uncertainty of these predictions. In particular, we demonstrated that the prediction uncertainty of this network at each voxel is a good indicator of whether the network has made an error and that the uncertainty across the whole brain can predict the manual quality control ratings of a scan. The proposed Bayesian DNN method should be applicable to any new network architecture for addressing the segmentation problem.", "published": "2018-12-03T13:23:30Z", "version": 5}, {"aid": "1812.02578", "authors": ["Daniel Estrada"], "title": "Conscious enactive computation", "url": "http://arxiv.org/pdf/1812.02578v1", "summary": "This paper looks at recent debates in the enactivist literature on computation and consciousness in order to assess major obstacles to building artificial conscious agents. We consider a proposal from Villalobos and Dewhurst (2018) for enactive computation on the basis of organizational closure. We attempt to improve the argument by reflecting on the closed paths through state space taken by finite state automata. This motivates a defense against Clark's recent criticisms of \"extended consciousness\", and perhaps a new perspective on living with machines.", "published": "2018-12-03T17:48:11Z", "version": 1}, {"aid": "1812.01024", "authors": ["Vincent Sitzmann", "Justus Thies", "Felix Heide", "Matthias Nie\u00dfner", "Gordon Wetzstein", "Michael Zollh\u00f6fer"], "title": "DeepVoxels: Learning Persistent 3D Feature Embeddings", "url": "http://arxiv.org/pdf/1812.01024v2", "summary": "In this work, we address the lack of 3D understanding of generative neural networks by introducing a persistent 3D feature embedding for view synthesis. To this end, we propose DeepVoxels, a learned representation that encodes the view-dependent appearance of a 3D scene without having to explicitly model its geometry. At its core, our approach is based on a Cartesian 3D grid of persistent embedded features that learn to make use of the underlying 3D scene structure. Our approach combines insights from 3D geometric computer vision with recent advances in learning image-to-image mappings based on adversarial loss functions. DeepVoxels is supervised, without requiring a 3D reconstruction of the scene, using a 2D re-rendering loss and enforces perspective and multi-view geometry in a principled manner. We apply our persistent 3D scene representation to the problem of novel view synthesis demonstrating high-quality results for a variety of challenging scenes.", "published": "2018-12-03T19:01:01Z", "version": 2}, {"aid": "1812.01243", "authors": ["Zhuoran Shen", "Mingyuan Zhang", "Haiyu Zhao", "Shuai Yi", "Hongsheng Li"], "title": "Efficient Attention: Attention with Linear Complexities", "url": "http://arxiv.org/pdf/1812.01243v10", "summary": "Dot-product attention has wide applications in computer vision and natural language processing. However, its memory and computational costs grow quadratically with the input size. Such growth prohibits its application on high-resolution inputs. To remedy this drawback, this paper proposes a novel efficient attention mechanism equivalent to dot-product attention but with substantially less memory and computational costs. Its resource efficiency allows more widespread and flexible integration of attention modules into a network, which leads to better accuracies. Empirical evaluations demonstrated the effectiveness of its advantages. Efficient attention modules brought significant performance boosts to object detectors and instance segmenters on MS-COCO 2017. Further, the resource efficiency democratizes attention to complex models, where high costs prohibit the use of dot-product attention. As an exemplar, a model with efficient attention achieved state-of-the-art accuracies for stereo depth estimation on the Scene Flow dataset. Code is available at https://github.com/cmsflash/efficient-attention.", "published": "2018-12-04T06:41:46Z", "version": 10}, {"aid": "1812.01569", "authors": ["Iris Rubi Seaman", "Jan-Willem van de Meent", "David Wingate"], "title": "Nested Reasoning About Autonomous Agents Using Probabilistic Programs", "url": "http://arxiv.org/pdf/1812.01569v2", "summary": "As autonomous agents become more ubiquitous, they will eventually have to reason about the plans of other agents, which is known as theory of mind reasoning. We develop a planning-as-inference framework in which agents perform nested simulation to reason about the behavior of other agents in an online manner. As a concrete application of this framework, we use probabilistic programs to model a high-uncertainty variant of pursuit-evasion games in which an agent must make inferences about the other agents' plans to craft counter-plans. Our probabilistic programs incorporate a variety of complex primitives such as field-of-view calculations and path planners, which enable us to model quasi-realistic scenarios in a computationally tractable manner. We perform extensive experimental evaluations which establish a variety of rational behaviors and quantify how allocating computation across levels of nesting affects the variance of our estimators.", "published": "2018-12-04T18:19:34Z", "version": 2}, {"aid": "1812.01600", "authors": ["Mahyar Najibi", "Bharat Singh", "Larry S. Davis"], "title": "AutoFocus: Efficient Multi-Scale Inference", "url": "http://arxiv.org/pdf/1812.01600v2", "summary": "This paper describes AutoFocus, an efficient multi-scale inference algorithm for deep-learning based object detectors. Instead of processing an entire image pyramid, AutoFocus adopts a coarse to fine approach and only processes regions which are likely to contain small objects at finer scales. This is achieved by predicting category agnostic segmentation maps for small objects at coarser scales, called FocusPixels. FocusPixels can be predicted with high recall, and in many cases, they only cover a small fraction of the entire image. To make efficient use of FocusPixels, an algorithm is proposed which generates compact rectangular FocusChips which enclose FocusPixels. The detector is only applied inside FocusChips, which reduces computation while processing finer scales. Different types of error can arise when detections from FocusChips of multiple scales are combined, hence techniques to correct them are proposed. AutoFocus obtains an mAP of 47.9% (68.3% at 50% overlap) on the COCO test-dev set while processing 6.4 images per second on a Titan X (Pascal) GPU. This is 2.5X faster than our multi-scale baseline detector and matches its mAP. The number of pixels processed in the pyramid can be reduced by 5X with a 1% drop in mAP. AutoFocus obtains more than 10% mAP gain compared to RetinaNet but runs at the same speed with the same ResNet-101 backbone.", "published": "2018-12-04T18:57:08Z", "version": 2}, {"aid": "1812.01659", "authors": ["Oren Dovrat", "Itai Lang", "Shai Avidan"], "title": "Learning to Sample", "url": "http://arxiv.org/pdf/1812.01659v2", "summary": "Processing large point clouds is a challenging task. Therefore, the data is often sampled to a size that can be processed more easily. The question is how to sample the data? A popular sampling technique is Farthest Point Sampling (FPS). However, FPS is agnostic to a downstream application (classification, retrieval, etc.). The underlying assumption seems to be that minimizing the farthest point distance, as done by FPS, is a good proxy to other objective functions.   We show that it is better to learn how to sample. To do that, we propose a deep network to simplify 3D point clouds. The network, termed S-NET, takes a point cloud and produces a smaller point cloud that is optimized for a particular task. The simplified point cloud is not guaranteed to be a subset of the original point cloud. Therefore, we match it to a subset of the original points in a post-processing step. We contrast our approach with FPS by experimenting on two standard data sets and show significantly better results for a variety of applications. Our code is publicly available at: https://github.com/orendv/learning_to_sample", "published": "2018-12-04T19:58:44Z", "version": 2}, {"aid": "1812.01754", "authors": ["Xingchao Peng", "Qinxun Bai", "Xide Xia", "Zijun Huang", "Kate Saenko", "Bo Wang"], "title": "Moment Matching for Multi-Source Domain Adaptation", "url": "http://arxiv.org/pdf/1812.01754v4", "summary": "Conventional unsupervised domain adaptation (UDA) assumes that training data are sampled from a single domain. This neglects the more practical scenario where training data are collected from multiple sources, requiring multi-source domain adaptation. We make three major contributions towards addressing this problem. First, we collect and annotate by far the largest UDA dataset, called DomainNet, which contains six domains and about 0.6 million images distributed among 345 categories, addressing the gap in data availability for multi-source UDA research. Second, we propose a new deep learning approach, Moment Matching for Multi-Source Domain Adaptation M3SDA, which aims to transfer knowledge learned from multiple labeled source domains to an unlabeled target domain by dynamically aligning moments of their feature distributions. Third, we provide new theoretical insights specifically for moment matching approaches in both single and multiple source domain adaptation. Extensive experiments are conducted to demonstrate the power of our new dataset in benchmarking state-of-the-art multi-source domain adaptation methods, as well as the advantage of our proposed model. Dataset and Code are available at \\url{http://ai.bu.edu/M3SDA/}.", "published": "2018-12-04T23:43:37Z", "version": 4}, {"aid": "1812.01894", "authors": ["Wei Shen", "Rujie Liu"], "title": "Learning to generate filters for convolutional neural networks", "url": "http://arxiv.org/pdf/1812.01894v1", "summary": "Conventionally, convolutional neural networks (CNNs) process different images with the same set of filters. However, the variations in images pose a challenge to this fashion. In this paper, we propose to generate sample-specific filters for convolutional layers in the forward pass. Since the filters are generated on-the-fly, the model becomes more flexible and can better fit the training data compared to traditional CNNs. In order to obtain sample-specific features, we extract the intermediate feature maps from an autoencoder. As filters are usually high dimensional, we propose to learn a set of coefficients instead of a set of filters. These coefficients are used to linearly combine the base filters from a filter repository to generate the final filters for a CNN. The proposed method is evaluated on MNIST, MTFL and CIFAR10 datasets. Experiment results demonstrate that the classification accuracy of the baseline model can be improved by using the proposed filter generation method.", "published": "2018-12-05T10:16:38Z", "version": 1}, {"aid": "1812.02068", "authors": ["Qiaoying Huang", "Xiao Chen", "Dimitris Metaxas", "Mariappan S. Nadar"], "title": "Brain Segmentation from k-space with End-to-end Recurrent Attention Network", "url": "http://arxiv.org/pdf/1812.02068v2", "summary": "The task of medical image segmentation commonly involves an image reconstruction step to convert acquired raw data to images before any analysis. However, noises, artifacts and loss of information due to the reconstruction process are almost inevitable, which compromises the final performance of segmentation. We present a novel learning framework that performs magnetic resonance brain image segmentation directly from k-space data. The end-to-end framework consists of a unique task-driven attention module that recurrently utilizes intermediate segmentation estimation to facilitate image-domain feature extraction from the raw data, thus closely bridging the reconstruction and the segmentation tasks. In addition, to address the challenge of manual labeling, we introduce a novel workflow to generate labeled training data for segmentation by exploiting imaging modality simulators and digital phantoms. Extensive experimental results show that the proposed method outperforms several state-of-the-art methods.", "published": "2018-12-05T16:01:28Z", "version": 2}, {"aid": "1812.02340", "authors": ["Daniel Philps", "Tillman Weyde", "Artur d'Avila Garcez", "Roy Batchelor"], "title": "Continual Learning Augmented Investment Decisions", "url": "http://arxiv.org/pdf/1812.02340v4", "summary": "Investment decisions can benefit from incorporating an accumulated knowledge of the past to drive future decision making. We introduce Continual Learning Augmentation (CLA) which is based on an explicit memory structure and a feed forward neural network (FFNN) base model and used to drive long term financial investment decisions. We demonstrate that our approach improves accuracy in investment decision making while memory is addressed in an explainable way. Our approach introduces novel remember cues, consisting of empirically learned change points in the absolute error series of the FFNN. Memory recall is also novel, with contextual similarity assessed over time by sampling distances using dynamic time warping (DTW). We demonstrate the benefits of our approach by using it in an expected return forecasting task to drive investment decisions. In an investment simulation in a broad international equity universe between 2003-2017, our approach significantly outperforms FFNN base models. We also illustrate how CLA's memory addressing works in practice, using a worked example to demonstrate the explainability of our approach.", "published": "2018-12-06T04:26:25Z", "version": 4}, {"aid": "1812.02375", "authors": ["Yuhui Xu", "Shuai Zhang", "Yingyong Qi", "Jiaxian Guo", "Weiyao Lin", "Hongkai Xiong"], "title": "DNQ: Dynamic Network Quantization", "url": "http://arxiv.org/pdf/1812.02375v1", "summary": "Network quantization is an effective method for the deployment of neural networks on memory and energy constrained mobile devices. In this paper, we propose a Dynamic Network Quantization (DNQ) framework which is composed of two modules: a bit-width controller and a quantizer. Unlike most existing quantization methods that use a universal quantization bit-width for the whole network, we utilize policy gradient to train an agent to learn the bit-width of each layer by the bit-width controller. This controller can make a trade-off between accuracy and compression ratio. Given the quantization bit-width sequence, the quantizer adopts the quantization distance as the criterion of the weights importance during quantization. We extensively validate the proposed approach on various main-stream neural networks and obtain impressive results.", "published": "2018-12-06T07:06:17Z", "version": 1}, {"aid": "1812.02415", "authors": ["Oshri Halimi", "Or Litany", "Emanuele Rodol\u00e0", "Alex Bronstein", "Ron Kimmel"], "title": "Self-supervised Learning of Dense Shape Correspondence", "url": "http://arxiv.org/pdf/1812.02415v1", "summary": "We introduce the first completely unsupervised correspondence learning approach for deformable 3D shapes. Key to our model is the understanding that natural deformations (such as changes in pose) approximately preserve the metric structure of the surface, yielding a natural criterion to drive the learning process toward distortion-minimizing predictions. On this basis, we overcome the need for annotated data and replace it by a purely geometric criterion. The resulting learning model is class-agnostic, and is able to leverage any type of deformable geometric data for the training phase. In contrast to existing supervised approaches which specialize on the class seen at training time, we demonstrate stronger generalization as well as applicability to a variety of challenging settings. We showcase our method on a wide selection of correspondence benchmarks, where we outperform other methods in terms of accuracy, generalization, and efficiency.", "published": "2018-12-06T09:26:03Z", "version": 1}, {"aid": "1812.02464", "authors": ["Craig Atkinson", "Brendan McCane", "Lech Szymanski", "Anthony Robins"], "title": "Pseudo-Rehearsal: Achieving Deep Reinforcement Learning without Catastrophic Forgetting", "url": "http://arxiv.org/pdf/1812.02464v6", "summary": "Neural networks can achieve excellent results in a wide variety of applications. However, when they attempt to sequentially learn, they tend to learn the new task while catastrophically forgetting previous ones. We propose a model that overcomes catastrophic forgetting in sequential reinforcement learning by combining ideas from continual learning in both the image classification domain and the reinforcement learning domain. This model features a dual memory system which separates continual learning from reinforcement learning and a pseudo-rehearsal system that \"recalls\" items representative of previous tasks via a deep generative network. Our model sequentially learns Atari 2600 games without demonstrating catastrophic forgetting and continues to perform above human level on all three games. This result is achieved without: demanding additional storage requirements as the number of tasks increases, storing raw data or revisiting past tasks. In comparison, previous state-of-the-art solutions are substantially more vulnerable to forgetting on these complex deep reinforcement learning tasks.", "published": "2018-12-06T11:20:18Z", "version": 6}, {"aid": "1812.02984", "authors": ["Ehsan Pajouheshgar", "Christoph H. Lampert"], "title": "Back to square one: probabilistic trajectory forecasting without bells and whistles", "url": "http://arxiv.org/pdf/1812.02984v1", "summary": "We introduce a spatio-temporal convolutional neural network model for trajectory forecasting from visual sources. Applied in an auto-regressive way it provides an explicit probability distribution over continuations of a given initial trajectory segment. We discuss it in relation to (more complicated) existing work and report on experiments on two standard datasets for trajectory forecasting: MNISTseq and Stanford Drones, achieving results on-par with or better than previous methods.", "published": "2018-12-07T11:31:05Z", "version": 1}, {"aid": "1812.03115", "authors": ["Yu-Chuan Su", "Kristen Grauman"], "title": "Kernel Transformer Networks for Compact Spherical Convolution", "url": "http://arxiv.org/pdf/1812.03115v2", "summary": "Ideally, 360{\\deg} imagery could inherit the deep convolutional neural networks (CNNs) already trained with great success on perspective projection images. However, existing methods to transfer CNNs from perspective to spherical images introduce significant computational costs and/or degradations in accuracy. In this work, we present the Kernel Transformer Network (KTN). KTNs efficiently transfer convolution kernels from perspective images to the equirectangular projection of 360{\\deg} images. Given a source CNN for perspective images as input, the KTN produces a function parameterized by a polar angle and kernel as output. Given a novel 360{\\deg} image, that function in turn can compute convolutions for arbitrary layers and kernels as would the source CNN on the corresponding tangent plane projections. Distinct from all existing methods, KTNs allow model transfer: the same model can be applied to different source CNNs with the same base architecture. This enables application to multiple recognition tasks without re-training the KTN. Validating our approach with multiple source CNNs and datasets, we show that KTNs improve the state of the art for spherical convolution. KTNs successfully preserve the source CNN's accuracy, while offering transferability, scalability to typical image resolutions, and, in many cases, a substantially lower memory footprint.", "published": "2018-12-07T17:26:28Z", "version": 2}, {"aid": "1812.03381", "authors": ["Tim Salimans", "Richard Chen"], "title": "Learning Montezuma's Revenge from a Single Demonstration", "url": "http://arxiv.org/pdf/1812.03381v1", "summary": "We propose a new method for learning from a single demonstration to solve hard exploration tasks like the Atari game Montezuma's Revenge. Instead of imitating human demonstrations, as proposed in other recent works, our approach is to maximize rewards directly. Our agent is trained using off-the-shelf reinforcement learning, but starts every episode by resetting to a state from a demonstration. By starting from such demonstration states, the agent requires much less exploration to learn a game compared to when it starts from the beginning of the game at every episode. We analyze reinforcement learning for tasks with sparse rewards in a simple toy environment, where we show that the run-time of standard RL methods scales exponentially in the number of states between rewards. Our method reduces this to quadratic scaling, opening up many tasks that were previously infeasible. We then apply our method to Montezuma's Revenge, for which we present a trained agent achieving a high-score of 74,500, better than any previously published result.", "published": "2018-12-08T20:16:16Z", "version": 1}, {"aid": "1812.03385", "authors": ["Rahul Kumar Jaiswal", "Gaurav Saxena"], "title": "Biometric Recognition System (Algorithm)", "url": "http://arxiv.org/pdf/1812.03385v1", "summary": "Fingerprints are the most widely deployed form of biometric identification. No two individuals share the same fingerprint because they have unique biometric identifiers. This paper presents an efficient fingerprint verification algorithm which improves matching accuracy. Fingerprint images get degraded and corrupted due to variations in skin and impression conditions. Thus, image enhancement techniques are employed prior to singular point detection and minutiae extraction. Singular point is the point of maximum curvature. It is determined by the normal of each fingerprint ridge, and then following them inward towards the centre. The local ridge features known as minutiae is extracted using cross-number method to find ridge endings and ridge bifurcations. The proposed algorithm chooses a radius and draws a circle with core point as centre, making fingerprint images rotationally invariant and uniform. The radius can be varied according to the accuracy depending on the particular application. Morphological techniques such as clean, spur and H-break is employed to remove noise, followed by removing spurious minutiae. Templates are created based on feature vector extraction and databases are made for verification and identification for the fingerprint images taken from Fingerprint Verification Competition (FVC2002). Minimum Euclidean distance is calculated between saved template and the test fingerprint image template and compared with the set threshold for matching decision. For the performance evaluation of the proposed algorithm various measures, equal error rate (EER), Dmin at EER, accuracy and threshold are evaluated and plotted. The measures demonstrate that the proposed algorithm is more effective and robust.", "published": "2018-12-08T21:12:38Z", "version": 1}, {"aid": "1812.03451", "authors": ["Chloe Eunhyang Kim", "Mahdi Maktab Dar Oghaz", "Jiri Fajtl", "Vasileios Argyriou", "Paolo Remagnino"], "title": "A Comparison of Embedded Deep Learning Methods for Person Detection", "url": "http://arxiv.org/pdf/1812.03451v2", "summary": "Recent advancements in parallel computing, GPU technology and deep learning provide a new platform for complex image processing tasks such as person detection to flourish. Person detection is fundamental preliminary operation for several high level computer vision tasks. One industry that can significantly benefit from person detection is retail. In recent years, various studies attempt to find an optimal solution for person detection using neural networks and deep learning. This study conducts a comparison among the state of the art deep learning base object detector with the focus on person detection performance in indoor environments. Performance of various implementations of YOLO, SSD, RCNN, R-FCN and SqueezeDet have been assessed using our in-house proprietary dataset which consists of over 10 thousands indoor images captured form shopping malls, retails and stores. Experimental results indicate that, Tiny YOLO-416 and SSD (VGG-300) are the fastest and Faster-RCNN (Inception ResNet-v2) and R-FCN (ResNet-101) are the most accurate detectors investigated in this study. Further analysis shows that YOLO v3-416 delivers relatively accurate result in a reasonable amount of time, which makes it an ideal model for person detection in embedded platforms.", "published": "2018-12-09T09:29:28Z", "version": 2}, {"aid": "1812.03945", "authors": ["Hao Zheng", "Yizhe Zhang", "Lin Yang", "Peixian Liang", "Zhuo Zhao", "Chaoli Wang", "Danny Z. Chen"], "title": "A New Ensemble Learning Framework for 3D Biomedical Image Segmentation", "url": "http://arxiv.org/pdf/1812.03945v1", "summary": "3D image segmentation plays an important role in biomedical image analysis. Many 2D and 3D deep learning models have achieved state-of-the-art segmentation performance on 3D biomedical image datasets. Yet, 2D and 3D models have their own strengths and weaknesses, and by unifying them together, one may be able to achieve more accurate results. In this paper, we propose a new ensemble learning framework for 3D biomedical image segmentation that combines the merits of 2D and 3D models. First, we develop a fully convolutional network based meta-learner to learn how to improve the results from 2D and 3D models (base-learners). Then, to minimize over-fitting for our sophisticated meta-learner, we devise a new training method that uses the results of the base-learners as multiple versions of \"ground truths\". Furthermore, since our new meta-learner training scheme does not depend on manual annotation, it can utilize abundant unlabeled 3D image data to further improve the model. Extensive experiments on two public datasets (the HVSMR 2016 Challenge dataset and the mouse piriform cortex dataset) show that our approach is effective under fully-supervised, semi-supervised, and transductive settings, and attains superior performance over state-of-the-art image segmentation methods.", "published": "2018-12-10T17:58:00Z", "version": 1}, {"aid": "1812.04056", "authors": ["Georgios Georgiadis"], "title": "Accelerating Convolutional Neural Networks via Activation Map Compression", "url": "http://arxiv.org/pdf/1812.04056v2", "summary": "The deep learning revolution brought us an extensive array of neural network architectures that achieve state-of-the-art performance in a wide variety of Computer Vision tasks including among others, classification, detection and segmentation. In parallel, we have also been observing an unprecedented demand in computational and memory requirements, rendering the efficient use of neural networks in low-powered devices virtually unattainable. Towards this end, we propose a three-stage compression and acceleration pipeline that sparsifies, quantizes and entropy encodes activation maps of Convolutional Neural Networks. Sparsification increases the representational power of activation maps leading to both acceleration of inference and higher model accuracy. Inception-V3 and MobileNet-V1 can be accelerated by as much as $1.6\\times$ with an increase in accuracy of $0.38\\%$ and $0.54\\%$ on the ImageNet and CIFAR-10 datasets respectively. Quantizing and entropy coding the sparser activation maps lead to higher compression over the baseline, reducing the memory cost of the network execution. Inception-V3 and MobileNet-V1 activation maps, quantized to $16$ bits, are compressed by as much as $6\\times$ with an increase in accuracy of $0.36\\%$ and $0.55\\%$ respectively.", "published": "2018-12-10T19:50:44Z", "version": 2}, {"aid": "1812.04240", "authors": ["Tianyu Zhao", "Wenqi Ren", "Changqing Zhang", "Dongwei Ren", "Qinghua Hu"], "title": "Unsupervised Degradation Learning for Single Image Super-Resolution", "url": "http://arxiv.org/pdf/1812.04240v2", "summary": "Deep Convolution Neural Networks (CNN) have achieved significant performance on single image super-resolution (SR) recently. However, existing CNN-based methods use artificially synthetic low-resolution (LR) and high-resolution (HR) image pairs to train networks, which cannot handle real-world cases since the degradation from HR to LR is much more complex than manually designed. To solve this problem, we propose a real-world LR images guided bi-cycle network for single image super-resolution, in which the bidirectional structural consistency is exploited to train both the degradation and SR reconstruction networks in an unsupervised way. Specifically, we propose a degradation network to model the real-world degradation process from HR to LR via generative adversarial networks, and these generated realistic LR images paired with real-world HR images are exploited for training the SR reconstruction network, forming the first cycle. Then in the second reverse cycle, consistency of real-world LR images are exploited to further stabilize the training of SR reconstruction and degradation networks. Extensive experiments on both synthetic and real-world images demonstrate that the proposed algorithm performs favorably against state-of-the-art single image SR methods.", "published": "2018-12-11T07:07:58Z", "version": 2}, {"aid": "1812.04955", "authors": ["Yunxiao Qin", "Weiguo Zhang", "Chenxu Zhao", "Zezheng Wang", "Xiangyu Zhu", "Guojun Qi", "Jingping Shi", "Zhen Lei"], "title": "Prior-Knowledge and Attention-based Meta-Learning for Few-Shot Learning", "url": "http://arxiv.org/pdf/1812.04955v5", "summary": "Recently, meta-learning has been shown as a promising way to solve few-shot learning. In this paper, inspired by the human cognition process which utilizes both prior-knowledge and vision attention in learning new knowledge, we present a novel paradigm of meta-learning approach with three developments to introduce attention mechanism and prior-knowledge for meta-learning. In our approach, prior-knowledge is responsible for helping meta-learner expressing the input data into high-level representation space, and attention mechanism enables meta-learner focusing on key features of the data in the representation space. Compared with existing meta-learning approaches that pay little attention to prior-knowledge and vision attention, our approach alleviates the meta-learner's few-shot cognition burden. Furthermore, a Task-Over-Fitting (TOF) problem, which indicates that the meta-learner has poor generalization on different K-shot learning tasks, is discovered and we propose a Cross-Entropy across Tasks (CET) metric to model and solve the TOF problem. Extensive experiments demonstrate that we improve the meta-learner with state-of-the-art performance on several few-shot learning benchmarks, and at the same time the TOF problem can also be released greatly.", "published": "2018-12-11T08:56:47Z", "version": 5}, {"aid": "1812.04604", "authors": ["Biye Jiang", "David M. Chan", "Tianhao Zhang", "John F. Canny"], "title": "Diagnostic Visualization for Deep Neural Networks Using Stochastic Gradient Langevin Dynamics", "url": "http://arxiv.org/pdf/1812.04604v1", "summary": "The internal states of most deep neural networks are difficult to interpret, which makes diagnosis and debugging during training challenging. Activation maximization methods are widely used, but lead to multiple optima and are hard to interpret (appear noise-like) for complex neurons. Image-based methods use maximally-activating image regions which are easier to interpret, but do not provide pixel-level insight into why the neuron responds to them. In this work we introduce an MCMC method: Langevin Dynamics Activation Maximization (LDAM), which is designed for diagnostic visualization. LDAM provides two affordances in combination: the ability to explore the set of maximally activating pre-images, and the ability to trade-off interpretability and pixel-level accuracy using a GAN-style discriminator as a regularizer. We present case studies on MNIST, CIFAR and ImageNet datasets exploring these trade-offs. Finally we show that diagnostic visualization using LDAM leads to a novel insight into the parameter averaging method for deep net training.", "published": "2018-12-11T18:43:52Z", "version": 1}, {"aid": "1812.04754", "authors": ["Guy Gur-Ari", "Daniel A. Roberts", "Ethan Dyer"], "title": "Gradient Descent Happens in a Tiny Subspace", "url": "http://arxiv.org/pdf/1812.04754v1", "summary": "We show that in a variety of large-scale deep learning scenarios the gradient dynamically converges to a very small subspace after a short period of training. The subspace is spanned by a few top eigenvectors of the Hessian (equal to the number of classes in the dataset), and is mostly preserved over long periods of training. A simple argument then suggests that gradient descent may happen mostly in this subspace. We give an example of this effect in a solvable model of classification, and we comment on possible implications for optimization and learning.", "published": "2018-12-12T00:36:17Z", "version": 1}, {"aid": "1812.04769", "authors": ["Emanuel Diamant"], "title": "Designing Artificial Cognitive Architectures: Brain Inspired or Biologically Inspired?", "url": "http://arxiv.org/pdf/1812.04769v1", "summary": "Artificial Neural Networks (ANNs) were devised as a tool for Artificial Intelligence design implementations. However, it was soon became obvious that they are unable to fulfill their duties. The fully autonomous way of ANNs working, precluded from any human intervention or supervision, deprived of any theoretical underpinning, leads to a strange state of affairs, when ANN designers cannot explain why and how they achieve their amazing and remarkable results. Therefore, contemporary Artificial Intelligence R&D looks more like a Modern Alchemy enterprise rather than a respected scientific or technological undertaking. On the other hand, modern biological science posits that intelligence can be distinguished not only in human brains. Intelligence today is considered as a fundamental property of each and every living being. Therefore, lower simplified forms of natural intelligence are more suitable for investigation and further replication in artificial cognitive architectures.", "published": "2018-12-12T01:40:51Z", "version": 1}, {"aid": "1812.05668", "authors": ["Hang Yu", "Ziyi Liu", "Jiansheng Wu"], "title": "Forgetting in order to Remember Better", "url": "http://arxiv.org/pdf/1812.05668v1", "summary": "In human memory, forgetting occur rapidly after the remembering and the rate of forgetting slowed down as time went. This is so-called the Ebbinghaus forgetting curve. There are many explanations of how this curve occur based on the properties of the brains. In this article, we use a simple mathematical model to explain the mechanism of forgetting based on rearrangement inequality and get a general formalism for short-term and long-term memory and use it to fit the Ebbinghaus forgetting curve. We also find out that forgetting is not a flaw, instead it is help to improve the efficiency of remembering when human confront different situations by reducing the interference of information and reducing the number of retrievals. Furthurmove, we find that the interference of informations limits the capacity of human memory, which is the \"magic number seven\".", "published": "2018-12-12T18:54:27Z", "version": 1}, {"aid": "1812.05212", "authors": ["Marcel Nassar", "Xin Wang", "Evren Tumer"], "title": "Conditional Graph Neural Processes: A Functional Autoencoder Approach", "url": "http://arxiv.org/pdf/1812.05212v1", "summary": "We introduce a novel encoder-decoder architecture to embed functional processes into latent vector spaces. This embedding can then be decoded to sample the encoded functions over any arbitrary domain. This autoencoder generalizes the recently introduced Conditional Neural Process (CNP) model of random processes. Our architecture employs the latest advances in graph neural networks to process irregularly sampled functions. Thus, we refer to our model as Conditional Graph Neural Process (CGNP). Graph neural networks can effectively exploit `local' structures of the metric spaces over which the functions/processes are defined. The contributions of this paper are twofold: (i) a novel graph-based encoder-decoder architecture for functional and process embeddings, and (ii) a demonstration of the importance of using the structure of metric spaces for this type of representations.", "published": "2018-12-13T00:52:56Z", "version": 1}, {"aid": "1812.05905", "authors": ["Tuomas Haarnoja", "Aurick Zhou", "Kristian Hartikainen", "George Tucker", "Sehoon Ha", "Jie Tan", "Vikash Kumar", "Henry Zhu", "Abhishek Gupta", "Pieter Abbeel", "Sergey Levine"], "title": "Soft Actor-Critic Algorithms and Applications", "url": "http://arxiv.org/pdf/1812.05905v2", "summary": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.", "published": "2018-12-13T04:44:29Z", "version": 2}, {"aid": "1812.05687", "authors": ["Peter E. Lillian", "Richard Meyes", "Tobias Meisen"], "title": "Ablation of a Robot's Brain: Neural Networks Under a Knife", "url": "http://arxiv.org/pdf/1812.05687v2", "summary": "It is still not fully understood exactly how neural networks are able to solve the complex tasks that have recently pushed AI research forward. We present a novel method for determining how information is structured inside a neural network. Using ablation (a neuroscience technique for cutting away parts of a brain to determine their function), we approach several neural network architectures from a biological perspective. Through an analysis of this method's results, we examine important similarities between biological and artificial neural networks to search for the implicit knowledge locked away in the network's weights.", "published": "2018-12-13T20:58:37Z", "version": 2}, {"aid": "1812.05806", "authors": ["Yifan Xing", "Rahul Tewari", "Paulo R. S. Mendonca"], "title": "A Self-Supervised Bootstrap Method for Single-Image 3D Face Reconstruction", "url": "http://arxiv.org/pdf/1812.05806v2", "summary": "State-of-the-art methods for 3D reconstruction of faces from a single image require 2D-3D pairs of ground-truth data for supervision. Such data is costly to acquire, and most datasets available in the literature are restricted to pairs for which the input 2D images depict faces in a near fronto-parallel pose. Therefore, many data-driven methods for single-image 3D facial reconstruction perform poorly on profile and near-profile faces. We propose a method to improve the performance of single-image 3D facial reconstruction networks by utilizing the network to synthesize its own training data for fine-tuning, comprising: (i) single-image 3D reconstruction of faces in near-frontal images without ground-truth 3D shape; (ii) application of a rigid-body transformation to the reconstructed face model; (iii) rendering of the face model from new viewpoints; and (iv) use of the rendered image and corresponding 3D reconstruction as additional data for supervised fine-tuning. The new 2D-3D pairs thus produced have the same high-quality observed for near fronto-parallel reconstructions, thereby nudging the network towards more uniform performance as a function of the viewing angle of input faces. Application of the proposed technique to the fine-tuning of a state-of-the-art single-image 3D-reconstruction network for faces demonstrates the usefulness of the method, with particularly significant gains for profile or near-profile views.", "published": "2018-12-14T07:46:02Z", "version": 2}, {"aid": "1812.05945", "authors": ["Daniel Omeiza", "Kayode Sakariyah Adewole", "Daniel Nkemelu"], "title": "EEG-based Communication with a Predictive Text Algorithm", "url": "http://arxiv.org/pdf/1812.05945v4", "summary": "Several changes occur in the brain in response to voluntary and involuntary activities performed by a person. The ability to retrieve data from the brain within a time space provides a basis for in-depth analyses that offer insight on what changes occur in the brain during its decision-making processes. In this work, we present the technical description and software implementation of an electroencephalographic (EEG) based communication system. We read EEG data in real-time with which we compute the likelihood that a voluntary eye blink has been made by a person and use the decision to trigger buttons on a user interface in order to produce text. Relevant texts are suggested using a modification of the T9 algorithm. Our results indicate that EEG-based technology can be effectively applied in facilitating speech for people with severe speech and muscular disabilities, providing a foundation for future work in the area.", "published": "2018-12-14T14:08:35Z", "version": 4}, {"aid": "1812.07032", "authors": ["Hoel Kervadec", "Jihene Bouchtiba", "Christian Desrosiers", "Eric Granger", "Jose Dolz", "Ismail Ben Ayed"], "title": "Boundary loss for highly unbalanced segmentation", "url": "http://arxiv.org/pdf/1812.07032v4", "summary": "Widely used loss functions for CNN segmentation, e.g., Dice or cross-entropy, are based on integrals over the segmentation regions. Unfortunately, for highly unbalanced segmentations, such regional summations have values that differ by several orders of magnitude across classes, which affects training performance and stability. We propose a boundary loss, which takes the form of a distance metric on the space of contours, not regions. This can mitigate the difficulties of highly unbalanced problems because it uses integrals over the interface between regions instead of unbalanced integrals over the regions. Furthermore, a boundary loss complements regional information. Inspired by graph-based optimization techniques for computing active-contour flows, we express a non-symmetric $L_2$ distance on the space of contours as a regional integral, which avoids completely local differential computations involving contour points. This yields a boundary loss expressed with the regional softmax probability outputs of the network, which can be easily combined with standard regional losses and implemented with any existing deep network architecture for N-D segmentation. We report comprehensive evaluations and comparisons on different unbalanced problems, showing that our boundary loss can yield significant increases in performances while improving training stability. Our code is publicly available: https://github.com/LIVIAETS/surface-loss .", "published": "2018-12-17T20:06:50Z", "version": 4}, {"aid": "1812.07363", "authors": ["Jian Han", "Sezer Karaoglu", "Hoang-An Le", "Theo Gevers"], "title": "Improving Face Detection Performance with 3D-Rendered Synthetic Data", "url": "http://arxiv.org/pdf/1812.07363v3", "summary": "In this paper, we provide a synthetic data generator methodology with fully controlled, multifaceted variations based on a new 3D face dataset (3DU-Face). We customized synthetic datasets to address specific types of variations (scale, pose, occlusion, blur, etc.), and systematically investigate the influence of different variations on face detection performances. We examine whether and how these factors contribute to better face detection performances. We validate our synthetic data augmentation for different face detectors (Faster RCNN, SSH and HR) on various face datasets (MAFA, UFDD and Wider Face).", "published": "2018-12-18T13:46:58Z", "version": 3}, {"aid": "1812.07544", "authors": ["Nikolay Nikolov", "Johannes Kirschner", "Felix Berkenkamp", "Andreas Krause"], "title": "Information-Directed Exploration for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1812.07544v2", "summary": "Efficient exploration remains a major challenge for reinforcement learning. One reason is that the variability of the returns often depends on the current state and action, and is therefore heteroscedastic. Classical exploration strategies such as upper confidence bound algorithms and Thompson sampling fail to appropriately account for heteroscedasticity, even in the bandit setting. Motivated by recent findings that address this issue in bandits, we propose to use Information-Directed Sampling (IDS) for exploration in reinforcement learning. As our main contribution, we build on recent advances in distributional reinforcement learning and propose a novel, tractable approximation of IDS for deep Q-learning. The resulting exploration strategy explicitly accounts for both parametric uncertainty and heteroscedastic observation noise. We evaluate our method on Atari games and demonstrate a significant improvement over alternative approaches.", "published": "2018-12-18T18:20:49Z", "version": 2}, {"aid": "1812.07697", "authors": ["Ren Li", "Jared S. Johansen", "Hamad Ahmed", "Thomas V. Ilyevsky", "Ronnie B Wilbur", "Hari M Bharadwaj", "Jeffrey Mark Siskind"], "title": "Training on the test set? An analysis of Spampinato et al. [31]", "url": "http://arxiv.org/pdf/1812.07697v1", "summary": "A recent paper [31] claims to classify brain processing evoked in subjects watching ImageNet stimuli as measured with EEG and to use a representation derived from this processing to create a novel object classifier. That paper, together with a series of subsequent papers [8, 15, 17, 20, 21, 30, 35], claims to revolutionize the field by achieving extremely successful results on several computer-vision tasks, including object classification, transfer learning, and generation of images depicting human perception and thought using brain-derived representations measured through EEG. Our novel experiments and analyses demonstrate that their results crucially depend on the block design that they use, where all stimuli of a given class are presented together, and fail with a rapid-event design, where stimuli of different classes are randomly intermixed. The block design leads to classification of arbitrary brain states based on block-level temporal correlations that tend to exist in all EEG data, rather than stimulus-related activity. Because every trial in their test sets comes from the same block as many trials in the corresponding training sets, their block design thus leads to surreptitiously training on the test set. This invalidates all subsequent analyses performed on this data in multiple published papers and calls into question all of the purported results. We further show that a novel object classifier constructed with a random codebook performs as well as or better than a novel object classifier constructed with the representation extracted from EEG data, suggesting that the performance of their classifier constructed with a representation extracted from EEG data does not benefit at all from the brain-derived representation. Our results calibrate the underlying difficulty of the tasks involved and caution against sensational and overly optimistic, but false, claims to the contrary.", "published": "2018-12-18T23:38:28Z", "version": 1}, {"aid": "1812.08989", "authors": ["Li Zhou", "Jianfeng Gao", "Di Li", "Heung-Yeung Shum"], "title": "The Design and Implementation of XiaoIce, an Empathetic Social Chatbot", "url": "http://arxiv.org/pdf/1812.08989v2", "summary": "This paper describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an AI companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient (IQ) and emotional quotient (EQ) in system design, cast human-machine social chat as decision-making over Markov Decision Processes (MDPs), and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since her launch in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of large scale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.", "published": "2018-12-21T08:01:31Z", "version": 2}, {"aid": "1812.10587", "authors": ["Jianwen Xie", "Ruiqi Gao", "Zilong Zheng", "Song-Chun Zhu", "Ying Nian Wu"], "title": "Learning Dynamic Generator Model by Alternating Back-Propagation Through Time", "url": "http://arxiv.org/pdf/1812.10587v1", "summary": "This paper studies the dynamic generator model for spatial-temporal processes such as dynamic textures and action sequences in video data. In this model, each time frame of the video sequence is generated by a generator model, which is a non-linear transformation of a latent state vector, where the non-linear transformation is parametrized by a top-down neural network. The sequence of latent state vectors follows a non-linear auto-regressive model, where the state vector of the next frame is a non-linear transformation of the state vector of the current frame as well as an independent noise vector that provides randomness in the transition. The non-linear transformation of this transition model can be parametrized by a feedforward neural network. We show that this model can be learned by an alternating back-propagation through time algorithm that iteratively samples the noise vectors and updates the parameters in the transition model and the generator model. We show that our training method can learn realistic models for dynamic textures and action patterns.", "published": "2018-12-27T01:34:08Z", "version": 1}, {"aid": "1812.10775", "authors": ["Yongheng Zhao", "Tolga Birdal", "Haowen Deng", "Federico Tombari"], "title": "3D Point Capsule Networks", "url": "http://arxiv.org/pdf/1812.10775v2", "summary": "In this paper, we propose 3D point-capsule networks, an auto-encoder designed to process sparse 3D point clouds while preserving spatial arrangements of the input data. 3D capsule networks arise as a direct consequence of our novel unified 3D auto-encoder formulation. Their dynamic routing scheme and the peculiar 2D latent space deployed by our approach bring in improvements for several common point cloud-related tasks, such as object classification, object reconstruction and part segmentation as substantiated by our extensive evaluations. Moreover, it enables new applications such as part interpolation and replacement.", "published": "2018-12-27T17:16:48Z", "version": 2}, {"aid": "1812.11214", "authors": ["Mathieu Andreux", "Tom\u00e1s Angles", "Georgios Exarchakis", "Roberto Leonarduzzi", "Gaspar Rochette", "Louis Thiry", "John Zarka", "St\u00e9phane Mallat", "Joakim and\u00e9n", "Eugene Belilovsky", "Joan Bruna", "Vincent Lostanlen", "Muawiz Chaudhary", "Matthew J. Hirn", "Edouard Oyallon", "Sixin Zhang", "Carmine Cella", "Michael Eickenberg"], "title": "Kymatio: Scattering Transforms in Python", "url": "http://arxiv.org/pdf/1812.11214v3", "summary": "The wavelet scattering transform is an invariant signal representation suitable for many signal processing and machine learning applications. We present the Kymatio software package, an easy-to-use, high-performance Python implementation of the scattering transform in 1D, 2D, and 3D that is compatible with modern deep learning frameworks. All transforms may be executed on a GPU (in addition to CPU), offering a considerable speed up over CPU implementations. The package also has a small memory footprint, resulting inefficient memory usage. The source code, documentation, and examples are available undera BSD license at https://www.kymat.io/", "published": "2018-12-28T20:53:29Z", "version": 3}, {"aid": "1812.11440", "authors": ["Irina Sanchez", "Veronica Vilaplana"], "title": "Brain MRI super-resolution using 3D generative adversarial networks", "url": "http://arxiv.org/pdf/1812.11440v1", "summary": "In this work we propose an adversarial learning approach to generate high resolution MRI scans from low resolution images. The architecture, based on the SRGAN model, adopts 3D convolutions to exploit volumetric information. For the discriminator, the adversarial loss uses least squares in order to stabilize the training. For the generator, the loss function is a combination of a least squares adversarial loss and a content term based on mean square error and image gradients in order to improve the quality of the generated images. We explore different solutions for the upsampling phase. We present promising results that improve classical interpolation, showing the potential of the approach for 3D medical imaging super-resolution. Source code available at https://github.com/imatge-upc/3D-GAN-superresolution", "published": "2018-12-29T22:19:00Z", "version": 1}, {"aid": "1812.11677", "authors": ["Ao Ren", "Tianyun Zhang", "Shaokai Ye", "Jiayu Li", "Wenyao Xu", "Xuehai Qian", "Xue Lin", "Yanzhi Wang"], "title": "ADMM-NN: An Algorithm-Hardware Co-Design Framework of DNNs Using Alternating Direction Method of Multipliers", "url": "http://arxiv.org/pdf/1812.11677v1", "summary": "To facilitate efficient embedded and hardware implementations of deep neural networks (DNNs), two important categories of DNN model compression techniques: weight pruning and weight quantization are investigated. The former leverages the redundancy in the number of weights, whereas the latter leverages the redundancy in bit representation of weights. However, there lacks a systematic framework of joint weight pruning and quantization of DNNs, thereby limiting the available model compression ratio. Moreover, the computation reduction, energy efficiency improvement, and hardware performance overhead need to be accounted for besides simply model size reduction.   To address these limitations, we present ADMM-NN, the first algorithm-hardware co-optimization framework of DNNs using Alternating Direction Method of Multipliers (ADMM), a powerful technique to deal with non-convex optimization problems with possibly combinatorial constraints. The first part of ADMM-NN is a systematic, joint framework of DNN weight pruning and quantization using ADMM. It can be understood as a smart regularization technique with regularization target dynamically updated in each ADMM iteration, thereby resulting in higher performance in model compression than prior work. The second part is hardware-aware DNN optimizations to facilitate hardware-level implementations.   Without accuracy loss, we can achieve 85$\\times$ and 24$\\times$ pruning on LeNet-5 and AlexNet models, respectively, significantly higher than prior work. The improvement becomes more significant when focusing on computation reductions. Combining weight pruning and quantization, we achieve 1,910$\\times$ and 231$\\times$ reductions in overall model size on these two benchmarks, when focusing on data storage. Highly promising results are also observed on other representative DNNs such as VGGNet and ResNet-50.", "published": "2018-12-31T02:26:48Z", "version": 1}, {"aid": "1812.11780", "authors": ["F\u00e1bio Perez", "R\u00e9mi Lebret", "Karl Aberer"], "title": "Weakly Supervised Active Learning with Cluster Annotation", "url": "http://arxiv.org/pdf/1812.11780v2", "summary": "In this work, we introduce a novel framework that employs cluster annotation to boost active learning by reducing the number of human interactions required to train deep neural networks. Instead of annotating single samples individually, humans can also label clusters, producing a higher number of annotated samples with the cost of a small label error. Our experiments show that the proposed framework requires 82% and 87% less human interactions for CIFAR-10 and EuroSAT datasets respectively when compared with the fully-supervised training while maintaining similar performance on the test set.", "published": "2018-12-31T13:06:09Z", "version": 2}, {"aid": "1812.11806", "authors": ["Wouter M. Kouw", "Marco Loog"], "title": "An introduction to domain adaptation and transfer learning", "url": "http://arxiv.org/pdf/1812.11806v2", "summary": "In machine learning, if the training data is an unbiased sample of an underlying distribution, then the learned classification function will make accurate predictions for new samples. However, if the training data is not an unbiased sample, then there will be differences between how the training data is distributed and how the test data is distributed. Standard classifiers cannot cope with changes in data distributions between training and test phases, and will not perform well. Domain adaptation and transfer learning are sub-fields within machine learning that are concerned with accounting for these types of changes. Here, we present an introduction to these fields, guided by the question: when and how can a classifier generalize from a source to a target domain? We will start with a brief introduction into risk minimization, and how transfer learning and domain adaptation expand upon this framework. Following that, we discuss three special cases of data set shift, namely prior, covariate and concept shift. For more complex domain shifts, there are a wide variety of approaches. These are categorized into: importance-weighting, subspace mapping, domain-invariant spaces, feature augmentation, minimax estimators and robust algorithms. A number of points will arise, which we will discuss in the last section. We conclude with the remark that many open questions will have to be addressed before transfer learners and domain-adaptive classifiers become practical.", "published": "2018-12-31T14:19:20Z", "version": 2}, {"aid": "1901.05903", "authors": ["Yash Srivastava", "Vaishnav Murali", "Shiv Ram Dubey"], "title": "A Performance Comparison of Loss Functions for Deep Face Recognition", "url": "http://arxiv.org/pdf/1901.05903v2", "summary": "Face recognition is one of the most widely publicized feature in the devices today and hence represents an important problem that should be studied with the utmost priority. As per the recent trends, the Convolutional Neural Network (CNN) based approaches are highly successful in many tasks of Computer Vision including face recognition. The loss function is used on the top of CNN to judge the goodness of any network. In this paper, we present a performance comparison of different loss functions such as Cross-Entropy, Angular Softmax, Additive-Margin Softmax, ArcFace and Marginal Loss for face recognition. The experiments are conducted with two CNN architectures namely, ResNet and MobileNet. Two widely used face datasets namely, CASIA-Webface and MS-Celeb-1M are used for the training and benchmark Labeled Faces in the Wild (LFW) face dataset is used for the testing.", "published": "2019-01-01T03:00:10Z", "version": 2}, {"aid": "1901.00945", "authors": ["Jack Lindsey", "Samuel A. Ocko", "Surya Ganguli", "Stephane Deny"], "title": "A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs", "url": "http://arxiv.org/pdf/1901.00945v1", "summary": "The visual system is hierarchically organized to process visual information in successive stages. Neural representations vary drastically across the first stages of visual processing: at the output of the retina, ganglion cell receptive fields (RFs) exhibit a clear antagonistic center-surround structure, whereas in the primary visual cortex, typical RFs are sharply tuned to a precise orientation. There is currently no unified theory explaining these differences in representations across layers. Here, using a deep convolutional neural network trained on image recognition as a model of the visual system, we show that such differences in representation can emerge as a direct consequence of different neural resource constraints on the retinal and cortical networks, and we find a single model from which both geometries spontaneously emerge at the appropriate stages of visual processing. The key constraint is a reduced number of neurons at the retinal output, consistent with the anatomy of the optic nerve as a stringent bottleneck. Second, we find that, for simple cortical networks, visual representations at the retinal output emerge as nonlinear and lossy feature detectors, whereas they emerge as linear and faithful encoders of the visual scene for more complex cortices. This result predicts that the retinas of small vertebrates should perform sophisticated nonlinear computations, extracting features directly relevant to behavior, whereas retinas of large animals such as primates should mostly encode the visual scene linearly and respond to a much broader range of stimuli. These predictions could reconcile the two seemingly incompatible views of the retina as either performing feature extraction or efficient coding of natural scenes, by suggesting that all vertebrates lie on a spectrum between these two objectives, depending on the degree of neural resources allocated to their visual system.", "published": "2019-01-03T23:51:38Z", "version": 1}, {"aid": "1901.01021", "authors": ["Rongrong Ma", "Jianyu Miao", "Lingfeng Niu", "Peng Zhang"], "title": "Transformed $\\ell_1$ Regularization for Learning Sparse Deep Neural Networks", "url": "http://arxiv.org/pdf/1901.01021v1", "summary": "Deep neural networks (DNNs) have achieved extraordinary success in numerous areas. However, to attain this success, DNNs often carry a large number of weight parameters, leading to heavy costs of memory and computation resources. Overfitting is also likely to happen in such network when the training data are insufficient. These shortcomings severely hinder the application of DNNs in resource-constrained platforms. In fact, many network weights are known to be redundant and can be removed from the network without much loss of performance. To this end, we introduce a new non-convex integrated transformed $\\ell_1$ regularizer to promote sparsity for DNNs, which removes both redundant connections and unnecessary neurons simultaneously. To be specific, we apply the transformed $\\ell_1$ to the matrix space of network weights and utilize it to remove redundant connections. Besides, group sparsity is also employed as an auxiliary to remove unnecessary neurons. An efficient stochastic proximal gradient algorithm is presented to solve the new model at the same time. To the best of our knowledge, this is the first work to utilize a non-convex regularizer in sparse optimization based method to promote sparsity for DNNs. Experiments on several public datasets demonstrate the effectiveness of the proposed method.", "published": "2019-01-04T08:46:16Z", "version": 1}, {"aid": "1901.01091", "authors": ["Thomas Lucas", "Konstantin Shmelkov", "Karteek Alahari", "Cordelia Schmid", "Jakob Verbeek"], "title": "Adaptive Density Estimation for Generative Models", "url": "http://arxiv.org/pdf/1901.01091v3", "summary": "Unsupervised learning of generative models has seen tremendous progress over recent years, in particular due to generative adversarial networks (GANs), variational autoencoders, and flow-based models. GANs have dramatically improved sample quality, but suffer from two drawbacks: (i) they mode-drop, i.e., do not cover the full support of the train data, and (ii) they do not allow for likelihood evaluations on held-out data. In contrast, likelihood-based training encourages models to cover the full support of the train data, but yields poorer samples. These mutual shortcomings can in principle be addressed by training generative latent variable models in a hybrid adversarial-likelihood manner. However, we show that commonly made parametric assumptions create a conflict between them, making successful hybrid models non trivial. As a solution, we propose to use deep invertible transformations in the latent variable decoder. This approach allows for likelihood computations in image space, is more efficient than fully invertible models, and can take full advantage of adversarial training. We show that our model significantly improves over existing hybrid models: offering GAN-like samples, IS and FID scores that are competitive with fully adversarial models, and improved likelihood scores.", "published": "2019-01-04T13:43:18Z", "version": 3}, {"aid": "1901.01672", "authors": ["Vaishnavh Nagarajan", "J. Zico Kolter"], "title": "Generalization in Deep Networks: The Role of Distance from Initialization", "url": "http://arxiv.org/pdf/1901.01672v2", "summary": "Why does training deep neural networks using stochastic gradient descent (SGD) result in a generalization error that does not worsen with the number of parameters in the network? To answer this question, we advocate a notion of effective model capacity that is dependent on {\\em a given random initialization of the network} and not just the training algorithm and the data distribution. We provide empirical evidences that demonstrate that the model capacity of SGD-trained deep networks is in fact restricted through implicit regularization of {\\em the $\\ell_2$ distance from the initialization}. We also provide theoretical arguments that further highlight the need for initialization-dependent notions of model capacity. We leave as open questions how and why distance from initialization is regularized, and whether it is sufficient to explain generalization.", "published": "2019-01-07T05:59:11Z", "version": 2}, {"aid": "1901.02358", "authors": ["Aditya Kusupati", "Manish Singh", "Kush Bhatia", "Ashish Kumar", "Prateek Jain", "Manik Varma"], "title": "FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network", "url": "http://arxiv.org/pdf/1901.02358v1", "summary": "This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they require a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by adding a residual connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the residual connection to a gate by reusing the RNN matrices to match state-of-the-art gated RNN accuracies but with a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse and quantized resulted in accurate models that could be up to 35x smaller than leading gated and unitary RNNs. This allowed FastGRNN to accurately recognize the \"Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely resource-constrained IoT microcontrollers too tiny to store other RNN models. FastGRNN's code is available at https://github.com/Microsoft/EdgeML/.", "published": "2019-01-08T15:19:13Z", "version": 1}, {"aid": "1901.02874", "authors": ["Sophie Schrader", "Andreas Westhoff", "Maria Carla Piastra", "Tuuli Miinalainen", "Sampsa Pursiainen", "Johannes Vorwerk", "Heinrich Brinck", "Carsten H. Wolters", "Christian Engwer"], "title": "DUNEuro -- A software toolbox for forward modeling in bioelectromagnetism", "url": "http://arxiv.org/pdf/1901.02874v4", "summary": "Accurate and efficient source analysis in electro- and magnetoencephalography using sophisticated realistic head geometries requires advanced numerical approaches. This paper presents DUNEuro, a free and open source C++ software toolbox for forward modeling in bioelectromagnetism. Building upon the DUNE framework, it provides implementations of modern fitted and unfitted finite element methods to efficiently solve the forward problems in electro- and magnetoencephalography. The user can choose between a variety of different source models that are implemented. The software's aim is to provide interfaces that are extendible and easy-to-use. In order to enable a closer integration into existing analysis pipelines, interfaces to Python and Matlab are provided. The practical use is demonstrated by a source analysis example of somatosensory evoked potentials using a realistic six compartment head model.", "published": "2019-01-09T18:52:01Z", "version": 4}, {"aid": "1901.05376", "authors": ["Tony Joseph", "Konstantinos G. Derpanis", "Faisal Z. Qureshi"], "title": "Joint Spatial and Layer Attention for Convolutional Networks", "url": "http://arxiv.org/pdf/1901.05376v2", "summary": "In this paper, we propose a novel approach that learns to sequentially attend to different Convolutional Neural Networks (CNN) layers (i.e., ``what'' feature abstraction to attend to) and different spatial locations of the selected feature map (i.e., ``where'') to perform the task at hand. Specifically, at each Recurrent Neural Network (RNN) step, both a CNN layer and localized spatial region within it are selected for further processing. We demonstrate the effectiveness of this approach on two computer vision tasks: (i) image-based six degree of freedom camera pose regression and (ii) indoor scene classification. Empirically, we show that combining the ``what'' and ``where'' aspects of attention improves network performance on both tasks. We evaluate our method on standard benchmarks for camera localization (Cambridge, 7-Scenes, and TUM-LSI) and for scene classification (MIT-67 Indoor Scenes). For camera localization our approach reduces the median error by 18.8\\% for position and 8.2\\% for orientation (averaged over all scenes), and for scene classification it improves the mean accuracy by 3.4\\% over previous methods.", "published": "2019-01-16T16:32:31Z", "version": 2}, {"aid": "1901.05555", "authors": ["Yin Cui", "Menglin Jia", "Tsung-Yi Lin", "Yang Song", "Serge Belongie"], "title": "Class-Balanced Loss Based on Effective Number of Samples", "url": "http://arxiv.org/pdf/1901.05555v1", "summary": "With the rapid increase of large-scale, real-world datasets, it becomes critical to address the problem of long-tailed data distribution (i.e., a few classes account for most of the data, while most classes are under-represented). Existing solutions typically adopt class re-balancing strategies such as re-sampling and re-weighting based on the number of observations for each class. In this work, we argue that as the number of samples increases, the additional benefit of a newly added data point will diminish. We introduce a novel theoretical framework to measure data overlap by associating with each sample a small neighboring region rather than a single point. The effective number of samples is defined as the volume of samples and can be calculated by a simple formula $(1-\\beta^{n})/(1-\\beta)$, where $n$ is the number of samples and $\\beta \\in [0,1)$ is a hyperparameter. We design a re-weighting scheme that uses the effective number of samples for each class to re-balance the loss, thereby yielding a class-balanced loss. Comprehensive experiments are conducted on artificially induced long-tailed CIFAR datasets and large-scale datasets including ImageNet and iNaturalist. Our results show that when trained with the proposed class-balanced loss, the network is able to achieve significant performance gains on long-tailed datasets.", "published": "2019-01-16T23:03:45Z", "version": 1}, {"aid": "1901.05567", "authors": ["Shichen Liu", "Weikai Chen", "Tianye Li", "Hao Li"], "title": "Soft Rasterizer: Differentiable Rendering for Unsupervised Single-View Mesh Reconstruction", "url": "http://arxiv.org/pdf/1901.05567v2", "summary": "Rendering is the process of generating 2D images from 3D assets, simulated in a virtual environment, typically with a graphics pipeline. By inverting such renderer, one can think of a learning approach to predict a 3D shape from an input image. However, standard rendering pipelines involve a fundamental discretization step called rasterization, which prevents the rendering process to be differentiable, hence suitable for learning. We present the first non-parametric and truly differentiable rasterizer based on silhouettes. Our method enables unsupervised learning for high-quality 3D mesh reconstruction from a single image. We call our framework `soft rasterizer' as it provides an accurate soft approximation of the standard rasterizer. The key idea is to fuse the probabilistic contributions of all mesh triangles with respect to the rendered pixels. When combined with a mesh generator in a deep neural network, our soft rasterizer is able to generate an approximated silhouette of the generated polygon mesh in the forward pass. The rendering loss is back-propagated to supervise the mesh generation without the need of 3D training data. Experimental results demonstrate that our approach significantly outperforms the state-of-the-art unsupervised techniques, both quantitatively and qualitatively. We also show that our soft rasterizer can achieve comparable results to the cutting-edge supervised learning method and in various cases even better ones, especially for real-world data.", "published": "2019-01-17T00:00:58Z", "version": 2}, {"aid": "1901.05733", "authors": ["Mostafa Salem", "Sergi Valverde", "Mariano Cabezas", "Deborah Pareto", "Arnau Oliver", "Joaquim Salvi", "\u00c0lex Rovira", "Xavier Llad\u00f3"], "title": "Multiple Sclerosis Lesion Synthesis in MRI using an encoder-decoder U-NET", "url": "http://arxiv.org/pdf/1901.05733v1", "summary": "In this paper, we propose generating synthetic multiple sclerosis (MS) lesions on MRI images with the final aim to improve the performance of supervised machine learning algorithms, therefore avoiding the problem of the lack of available ground truth. We propose a two-input two-output fully convolutional neural network model for MS lesion synthesis in MRI images. The lesion information is encoded as discrete binary intensity level masks passed to the model and stacked with the input images. The model is trained end-to-end without the need for manually annotating the lesions in the training set. We then perform the generation of synthetic lesions on healthy images via registration of patient images, which are subsequently used for data augmentation to increase the performance for supervised MS lesion detection algorithms. Our pipeline is evaluated on MS patient data from an in-house clinical dataset and the public ISBI2015 challenge dataset. The evaluation is based on measuring the similarities between the real and the synthetic images as well as in terms of lesion detection performance by segmenting both the original and synthetic images individually using a state-of-the-art segmentation framework. We also demonstrate the usage of synthetic MS lesions generated on healthy images as data augmentation. We analyze a scenario of limited training data (one-image training) to demonstrate the effect of the data augmentation on both datasets. Our results significantly show the effectiveness of the usage of synthetic MS lesion images. For the ISBI2015 challenge, our one-image model trained using only a single image plus the synthetic data augmentation strategy showed a performance similar to that of other CNN methods that were fully trained using the entire training set, yielding a comparable human expert rater performance", "published": "2019-01-17T11:25:50Z", "version": 1}, {"aid": "1901.06032", "authors": ["Asifullah Khan", "Anabia Sohail", "Umme Zahoora", "Aqsa Saeed Qureshi"], "title": "A Survey of the Recent Architectures of Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1901.06032v7", "summary": "Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.", "published": "2019-01-17T23:20:23Z", "version": 7}, {"aid": "1901.06110", "authors": ["Unni V. S.", "Sanjay Ghosh", "Kunal N. Chaudhury"], "title": "Linearized ADMM and Fast Nonlocal Denoising for Efficient Plug-and-Play Restoration", "url": "http://arxiv.org/pdf/1901.06110v1", "summary": "In plug-and-play image restoration, the regularization is performed using powerful denoisers such as nonlocal means (NLM) or BM3D. This is done within the framework of alternating direction method of multipliers (ADMM), where the regularization step is formally replaced by an off-the-shelf denoiser. Each plug-and-play iteration involves the inversion of the forward model followed by a denoising step. In this paper, we present a couple of ideas for improving the efficiency of the inversion and denoising steps. First, we propose to use linearized ADMM, which generally allows us to perform the inversion at a lower cost than standard ADMM. Moreover, we can easily incorporate hard constraints into the optimization framework as a result. Second, we develop a fast algorithm for doubly stochastic NLM, originally proposed by Sreehari et al. (IEEE TCI, 2016), which is about 80x faster than brute-force computation. This particular denoiser can be expressed as the proximal map of a convex regularizer and, as a consequence, we can guarantee convergence for linearized plug-and-play ADMM. We demonstrate the effectiveness of our proposals for super-resolution and single-photon imaging.", "published": "2019-01-18T07:20:32Z", "version": 1}, {"aid": "1901.06401", "authors": ["Atra Akandeh", "Fathi M. Salem"], "title": "Slim LSTM networks: LSTM_6 and LSTM_C6", "url": "http://arxiv.org/pdf/1901.06401v1", "summary": "We have shown previously that our parameter-reduced variants of Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN) are comparable in performance to the standard LSTM RNN on the MNIST dataset. In this study, we show that this is also the case for two diverse benchmark datasets, namely, the review sentiment IMDB and the 20 Newsgroup datasets. Specifically, we focus on two of the simplest variants, namely LSTM_6 (i.e., standard LSTM with three constant fixed gates) and LSTM_C6 (i.e., LSTM_6 with further reduced cell body input block). We demonstrate that these two aggressively reduced-parameter variants are competitive with the standard LSTM when hyper-parameters, e.g., learning parameter, number of hidden units and gate constants are set properly. These architectures enable speeding up training computations and hence, these networks would be more suitable for online training and inference onto portable devices with relatively limited computational resources.", "published": "2019-01-18T19:36:41Z", "version": 1}, {"aid": "1901.06773", "authors": ["Jinrong Guo", "Wantao Liu", "Wang Wang", "Qu Lu", "Songlin Hu", "Jizhong Han", "Ruixuan Li"], "title": "AccUDNN: A GPU Memory Efficient Accelerator for Training Ultra-deep Neural Networks", "url": "http://arxiv.org/pdf/1901.06773v2", "summary": "Typically, Ultra-deep neural network(UDNN) tends to yield high-quality model, but its training process is usually resource intensive and time-consuming. Modern GPU's scarce DRAM capacity is the primary bottleneck that hinders the trainability and the training efficiency of UDNN. In this paper, we present \"AccUDNN\", an accelerator that aims to make the utmost use of finite GPU memory resources to speed up the training process of UDNN. AccUDNN mainly includes two modules: memory optimizer and hyperparameter tuner. Memory optimizer develops a performance-model guided dynamic swap out/in strategy, by offloading appropriate data to host memory, GPU memory footprint can be significantly slashed to overcome the restriction of trainability of UDNN. After applying the memory optimization strategy, hyperparameter tuner is designed to explore the efficiency-optimal minibatch size and the matched learning rate. Evaluations demonstrate that AccUDNN cuts down the GPU memory requirement of ResNet-152 from more than 24GB to 8GB. In turn, given 12GB GPU memory budget, the efficiency-optimal minibatch size can reach 4.2x larger than original Caffe. Benefiting from better utilization of single GPU's computing resources and fewer parameter synchronization of large minibatch size, 7.7x speed-up is achieved by 8 GPUs' cluster without any communication optimization and no accuracy losses.", "published": "2019-01-21T02:52:09Z", "version": 2}, {"aid": "1902.02771", "authors": ["S. H. Shabbeer Basha", "Shiv Ram Dubey", "Viswanath Pulabaigari", "Snehasis Mukherjee"], "title": "Impact of Fully Connected Layers on Performance of Convolutional Neural Networks for Image Classification", "url": "http://arxiv.org/pdf/1902.02771v3", "summary": "The Convolutional Neural Networks (CNNs), in domains like computer vision, mostly reduced the need for handcrafted features due to its ability to learn the problem-specific features from the raw input data. However, the selection of dataset-specific CNN architecture, which mostly performed by either experience or expertise is a time-consuming and error-prone process. To automate the process of learning a CNN architecture, this paper attempts at finding the relationship between Fully Connected (FC) layers with some of the characteristics of the datasets. The CNN architectures, and recently datasets also, are categorized as deep, shallow, wide, etc. This paper tries to formalize these terms along with answering the following questions. (i) What is the impact of deeper/shallow architectures on the performance of the CNN w.r.t. FC layers?, (ii) How the deeper/wider datasets influence the performance of CNN w.r.t. FC layers?, and (iii) Which kind of architecture (deeper/ shallower) is better suitable for which kind of (deeper/ wider) datasets. To address these findings, we have performed experiments with three CNN architectures having different depths. The experiments are conducted by varying the number of FC layers. We used four widely used datasets including CIFAR-10, CIFAR-100, Tiny ImageNet, and CRCHistoPhenotypes to justify our findings in the context of the image classification problem. The source code of this research is available at https://github.com/shabbeersh/Impact-of-FC-layers.", "published": "2019-01-21T07:42:26Z", "version": 3}, {"aid": "1901.11390", "authors": ["Christopher P. Burgess", "Loic Matthey", "Nicholas Watters", "Rishabh Kabra", "Irina Higgins", "Matt Botvinick", "Alexander Lerchner"], "title": "MONet: Unsupervised Scene Decomposition and Representation", "url": "http://arxiv.org/pdf/1901.11390v1", "summary": "The ability to decompose scenes in terms of abstract building blocks is crucial for general intelligence. Where those basic building blocks share meaningful properties, interactions and other regularities across scenes, such decompositions can simplify reasoning and facilitate imagination of novel scenarios. In particular, representing perceptual observations in terms of entities should improve data efficiency and transfer performance on a wide range of tasks. Thus we need models capable of discovering useful decompositions of scenes by identifying units with such regularities and representing them in a common format. To address this problem, we have developed the Multi-Object Network (MONet). In this model, a VAE is trained end-to-end together with a recurrent attention network -- in a purely unsupervised manner -- to provide attention masks around, and reconstructions of, regions of images. We show that this model is capable of learning to decompose and represent challenging 3D scenes into semantically meaningful components, such as objects and background elements.", "published": "2019-01-22T18:55:34Z", "version": 1}, {"aid": "1901.07647", "authors": ["Jong Chul Ye", "Woon Kyoung Sung"], "title": "Understanding Geometry of Encoder-Decoder CNNs", "url": "http://arxiv.org/pdf/1901.07647v2", "summary": "Encoder-decoder networks using convolutional neural network (CNN) architecture have been extensively used in deep learning literatures thanks to its excellent performance for various inverse problems. However, it is still difficult to obtain coherent geometric view why such an architecture gives the desired performance. Inspired by recent theoretical understanding on generalizability, expressivity and optimization landscape of neural networks, as well as the theory of convolutional framelets, here we provide a unified theoretical framework that leads to a better understanding of geometry of encoder-decoder CNNs. Our unified mathematical framework shows that encoder-decoder CNN architecture is closely related to nonlinear basis representation using combinatorial convolution frames, whose expressibility increases exponentially with the network depth. We also demonstrate the importance of skipped connection in terms of expressibility, and optimization landscape.", "published": "2019-01-22T23:37:43Z", "version": 2}, {"aid": "1901.07680", "authors": ["Guanghan Ning", "Ping Liu", "Xiaochuan Fan", "Chi Zhang"], "title": "A Top-down Approach to Articulated Human Pose Estimation and Tracking", "url": "http://arxiv.org/pdf/1901.07680v1", "summary": "Both the tasks of multi-person human pose estimation and pose tracking in videos are quite challenging. Existing methods can be categorized into two groups: top-down and bottom-up approaches. In this paper, following the top-down approach, we aim to build a strong baseline system with three modules: human candidate detector, single-person pose estimator and human pose tracker. Firstly, we choose a generic object detector among state-of-the-art methods to detect human candidates. Then, the cascaded pyramid network is used to estimate the corresponding human pose. Finally, we use a flow-based pose tracker to render keypoint-association across frames, i.e., assigning each human candidate a unique and temporally-consistent id, for the multi-target pose tracking purpose. We conduct extensive ablative experiments to validate various choices of models and configurations. We take part in two ECCV 18 PoseTrack challenges: pose estimation and pose tracking.", "published": "2019-01-23T01:19:29Z", "version": 1}, {"aid": "1901.07929", "authors": ["Jos\u00e9 Ignacio Orlando", "Philipp Seeb\u00f6ck", "Hrvoje Bogunovi\u0107", "Sophie Klimscha", "Christoph Grechenig", "Sebastian Waldstein", "Bianca S. Gerendas", "Ursula Schmidt-Erfurth"], "title": "U2-Net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans", "url": "http://arxiv.org/pdf/1901.07929v2", "summary": "In this paper, we introduce a Bayesian deep learning based model for segmenting the photoreceptor layer in pathological OCT scans. Our architecture provides accurate segmentations of the photoreceptor layer and produces pixel-wise epistemic uncertainty maps that highlight potential areas of pathologies or segmentation errors. We empirically evaluated this approach in two sets of pathological OCT scans of patients with age-related macular degeneration, retinal vein oclussion and diabetic macular edema, improving the performance of the baseline U-Net both in terms of the Dice index and the area under the precision/recall curve. We also observed that the uncertainty estimates were inversely correlated with the model performance, underlying its utility for highlighting areas where manual inspection/correction might be needed.", "published": "2019-01-23T14:52:33Z", "version": 2}, {"aid": "1901.07945", "authors": ["Samuel J. Gershman"], "title": "What does the free energy principle tell us about the brain?", "url": "http://arxiv.org/pdf/1901.07945v5", "summary": "The free energy principle has been proposed as a unifying account of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.", "published": "2019-01-23T15:23:00Z", "version": 5}, {"aid": "1901.08373", "authors": ["Xuesong Li", "Jose Guivant", "Ngaiming Kwok", "Yongzhi Xu", "Ruowei Li", "Hongkun Wu"], "title": "Three-dimensional Backbone Network for 3D Object Detection in Traffic Scenes", "url": "http://arxiv.org/pdf/1901.08373v2", "summary": "The task of detecting 3D objects in traffic scenes has a pivotal role in many real-world applications. However, the performance of 3D object detection is lower than that of 2D object detection due to the lack of powerful 3D feature extraction methods. To address this issue, this study proposes a 3D backbone network to acquire comprehensive 3D feature maps for 3D object detection. It primarily consists of sparse 3D convolutional neural network operations in the point cloud. The 3D backbone network can inherently learn 3D features from the raw data without compressing the point cloud into multiple 2D images. The sparse 3D convolutional neural network takes full advantage of the sparsity in the 3D point cloud to accelerate computation and save memory, which makes the 3D backbone network feasible in a real-world application. Empirical experiments were conducted on the KITTI benchmark and comparable results were obtained with respect to the state-of-the-art performance for 3D object detection.", "published": "2019-01-24T12:11:05Z", "version": 2}, {"aid": "1901.08688", "authors": ["Poojan Oza", "Vishal M. Patel"], "title": "One-Class Convolutional Neural Network", "url": "http://arxiv.org/pdf/1901.08688v1", "summary": "We present a novel Convolutional Neural Network (CNN) based approach for one class classification. The idea is to use a zero centered Gaussian noise in the latent space as the pseudo-negative class and train the network using the cross-entropy loss to learn a good representation as well as the decision boundary for the given class. A key feature of the proposed approach is that any pre-trained CNN can be used as the base network for one class classification. The proposed One Class CNN (OC-CNN) is evaluated on the UMDAA-02 Face, Abnormality-1001, FounderType-200 datasets. These datasets are related to a variety of one class application problems such as user authentication, abnormality detection and novelty detection. Extensive experiments demonstrate that the proposed method achieves significant improvements over the recent state-of-the-art methods. The source code is available at : github.com/otkupjnoz/oc-cnn.", "published": "2019-01-24T23:31:11Z", "version": 1}, {"aid": "1901.09822", "authors": ["Haifeng Shi", "Guanyu Cai", "Yuqin Wang", "Shaohua Shang", "Lianghua He"], "title": "Virtual Conditional Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1901.09822v1", "summary": "When trained on multimodal image datasets, normal Generative Adversarial Networks (GANs) are usually outperformed by class-conditional GANs and ensemble GANs, but conditional GANs is restricted to labeled datasets and ensemble GANs lack efficiency. We propose a novel GAN variant called virtual conditional GAN (vcGAN) which is not only an ensemble GAN with multiple generative paths while adding almost zero network parameters, but also a conditional GAN that can be trained on unlabeled datasets without explicit clustering steps or objectives other than the adversary loss. Inside the vcGAN's generator, a learnable ``analog-to-digital converter (ADC)\" module maps a slice of the inputted multivariate Gaussian noise to discrete/digital noise (virtual label), according to which a selector selects the corresponding generative path to produce the sample. All the generative paths share the same decoder network while in each path the decoder network is fed with a concatenation of a different pre-computed amplified one-hot vector and the inputted Gaussian noise. We conducted a lot of experiments on several balanced/imbalanced image datasets to demonstrate that vcGAN converges faster and achieves improved Frech\\'et Inception Distance (FID). In addition, we show the training byproduct that the ADC in vcGAN learned the categorical probability of each mode and that each generative path generates samples of specific mode, which enables class-conditional sampling. Codes are available at \\url{https://github.com/annonnymmouss/vcgan}", "published": "2019-01-25T07:15:17Z", "version": 1}, {"aid": "1901.09054", "authors": ["Bj\u00f6rn Barz", "Joachim Denzler"], "title": "Deep Learning on Small Datasets without Pre-Training using Cosine Loss", "url": "http://arxiv.org/pdf/1901.09054v2", "summary": "Two things seem to be indisputable in the contemporary deep learning discourse: 1. The categorical cross-entropy loss after softmax activation is the method of choice for classification. 2. Training a CNN classifier from scratch on small datasets does not work well. In contrast to this, we show that the cosine loss function provides significantly better performance than cross-entropy on datasets with only a handful of samples per class. For example, the accuracy achieved on the CUB-200-2011 dataset without pre-training is by 30% higher than with the cross-entropy loss. Further experiments on other popular datasets confirm our findings. Moreover, we demonstrate that integrating prior knowledge in the form of class hierarchies is straightforward with the cosine loss and improves classification performance further.", "published": "2019-01-25T19:13:03Z", "version": 2}, {"aid": "1901.09465", "authors": ["Banghua Zhu", "Jiantao Jiao", "David Tse"], "title": "Deconstructing Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1901.09465v7", "summary": "We deconstruct the performance of GANs into three components:   1. Formulation: we propose a perturbation view of the population target of GANs. Building on this interpretation, we show that GANs can be viewed as a generalization of the robust statistics framework, and propose a novel GAN architecture, termed as Cascade GANs, to provably recover meaningful low-dimensional generator approximations when the real distribution is high-dimensional and corrupted by outliers.   2. Generalization: given a population target of GANs, we design a systematic principle, projection under admissible distance, to design GANs to meet the population requirement using finite samples. We implement our principle in three cases to achieve polynomial and sometimes near-optimal sample complexities: (1) learning an arbitrary generator under an arbitrary pseudonorm; (2) learning a Gaussian location family under TV distance, where we utilize our principle provide a new proof for the optimality of Tukey median viewed as GANs; (3) learning a low-dimensional Gaussian approximation of a high-dimensional arbitrary distribution under Wasserstein distance. We demonstrate a fundamental trade-off in the approximation error and statistical error in GANs, and show how to apply our principle with empirical samples to predict how many samples are sufficient for GANs in order not to suffer from the discriminator winning problem.   3. Optimization: we demonstrate alternating gradient descent is provably not locally asymptotically stable in optimizing the GAN formulation of PCA. We diagnose the problem as the minimax duality gap being non-zero, and propose a new GAN architecture whose duality gap is zero, where the value of the game is equal to the previous minimax value (not the maximin value). We prove the new GAN architecture is globally asymptotically stable in optimization under alternating gradient descent.", "published": "2019-01-27T23:53:32Z", "version": 7}, {"aid": "1901.09615", "authors": ["Okan K\u00f6p\u00fckl\u00fc", "Maryam Babaee", "Stefan H\u00f6rmann", "Gerhard Rigoll"], "title": "Convolutional Neural Networks with Layer Reuse", "url": "http://arxiv.org/pdf/1901.09615v2", "summary": "A convolutional layer in a Convolutional Neural Network (CNN) consists of many filters which apply convolution operation to the input, capture some special patterns and pass the result to the next layer. If the same patterns also occur at the deeper layers of the network, why wouldn't the same convolutional filters be used also in those layers? In this paper, we propose a CNN architecture, Layer Reuse Network (LruNet), where the convolutional layers are used repeatedly without the need of introducing new layers to get a better performance. This approach introduces several advantages: (i) Considerable amount of parameters are saved since we are reusing the layers instead of introducing new layers, (ii) the Memory Access Cost (MAC) can be reduced since reused layer parameters can be fetched only once, (iii) the number of nonlinearities increases with layer reuse, and (iv) reused layers get gradient updates from multiple parts of the network. The proposed approach is evaluated on CIFAR-10, CIFAR-100 and Fashion-MNIST datasets for image classification task, and layer reuse improves the performance by 5.14%, 5.85% and 2.29%, respectively. The source code and pretrained models are publicly available.", "published": "2019-01-28T11:45:50Z", "version": 2}, {"aid": "1901.09886", "authors": ["Tapabrata Chakraborti", "Brendan McCane", "Steven Mills", "Umapada Pal"], "title": "CoCoNet: A Collaborative Convolutional Network", "url": "http://arxiv.org/pdf/1901.09886v4", "summary": "We present an end-to-end deep network for fine-grained visual categorization called Collaborative Convolutional Network (CoCoNet). The network uses a collaborative layer after the convolutional layers to represent an image as an optimal weighted collaboration of features learned from training samples as a whole rather than one at a time. This gives CoCoNet more power to encode the fine-grained nature of the data with limited samples. We perform a detailed study of the performance with 1-stage and 2-stage transfer learning. The ablation study shows that the proposed method outperforms its constituent parts consistently. CoCoNet also outperforms few state-of-the-art competing methods. Experiments have been performed on the fine-grained bird species classification problem as a representative example, but the method may be applied to other similar tasks. We also introduce a new public dataset for fine-grained species recognition, that of Indian endemic birds and have reported initial results on it.", "published": "2019-01-28T18:58:50Z", "version": 4}, {"aid": "1901.10177", "authors": ["Hong-Xing Yu", "Ancong Wu", "Wei-Shi Zheng"], "title": "Unsupervised Person Re-identification by Deep Asymmetric Metric Embedding", "url": "http://arxiv.org/pdf/1901.10177v1", "summary": "Person re-identification (Re-ID) aims to match identities across non-overlapping camera views. Researchers have proposed many supervised Re-ID models which require quantities of cross-view pairwise labelled data. This limits their scalabilities to many applications where a large amount of data from multiple disjoint camera views is available but unlabelled. Although some unsupervised Re-ID models have been proposed to address the scalability problem, they often suffer from the view-specific bias problem which is caused by dramatic variances across different camera views, e.g., different illumination, viewpoints and occlusion. The dramatic variances induce specific feature distortions in different camera views, which can be very disturbing in finding cross-view discriminative information for Re-ID in the unsupervised scenarios, since no label information is available to help alleviate the bias. We propose to explicitly address this problem by learning an unsupervised asymmetric distance metric based on cross-view clustering. The asymmetric distance metric allows specific feature transformations for each camera view to tackle the specific feature distortions. We then design a novel unsupervised loss function to embed the asymmetric metric into a deep neural network, and therefore develop a novel unsupervised deep framework named the DEep Clustering-based Asymmetric MEtric Learning (DECAMEL). In such a way, DECAMEL jointly learns the feature representation and the unsupervised asymmetric metric. DECAMEL learns a compact cross-view cluster structure of Re-ID data, and thus help alleviate the view-specific bias and facilitate mining the potential cross-view discriminative information for unsupervised Re-ID. Extensive experiments on seven benchmark datasets whose sizes span several orders show the effectiveness of our framework.", "published": "2019-01-29T08:49:26Z", "version": 1}, {"aid": "1901.10208", "authors": ["Nicola Strisciuglio", "Manuel Lopez-Antequera", "Nicolai Petkov"], "title": "A Push-Pull Layer Improves Robustness of Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1901.10208v1", "summary": "We propose a new layer in Convolutional Neural Networks (CNNs) to increase their robustness to several types of noise perturbations of the input images. We call this a push-pull layer and compute its response as the combination of two half-wave rectified convolutions, with kernels of opposite polarity. It is based on a biologically-motivated non-linear model of certain neurons in the visual system that exhibit a response suppression phenomenon, known as push-pull inhibition. We validate our method by substituting the first convolutional layer of the LeNet-5 and WideResNet architectures with our push-pull layer. We train the networks on nonperturbed training images from the MNIST, CIFAR-10 and CIFAR-100 data sets, and test on images perturbed by noise that is unseen by the training process. We demonstrate that our push-pull layers contribute to a considerable improvement in robustness of classification of images perturbed by noise, while maintaining state-of-the-art performance on the original image classification task.", "published": "2019-01-29T10:42:04Z", "version": 1}, {"aid": "1901.10430", "authors": ["Felix Wu", "Angela Fan", "Alexei Baevski", "Yann N. Dauphin", "Michael Auli"], "title": "Pay Less Attention with Lightweight and Dynamic Convolutions", "url": "http://arxiv.org/pdf/1901.10430v2", "summary": "Self-attention is a useful mechanism to build generative models for language and images. It determines the importance of context elements by comparing each element to the current time step. In this paper, we show that a very lightweight convolution can perform competitively to the best reported self-attention results. Next, we introduce dynamic convolutions which are simpler and more efficient than self-attention. We predict separate convolution kernels based solely on the current time-step in order to determine the importance of context elements. The number of operations required by this approach scales linearly in the input length, whereas self-attention is quadratic. Experiments on large-scale machine translation, language modeling and abstractive summarization show that dynamic convolutions improve over strong self-attention models. On the WMT'14 English-German test set dynamic convolutions achieve a new state of the art of 29.7 BLEU.", "published": "2019-01-29T18:01:35Z", "version": 2}, {"aid": "1901.11082", "authors": ["Chiyu \"Max\" Jiang", "Dana Lynn Ona Lansigan", "Philip Marcus", "Matthias Nie\u00dfner"], "title": "DDSL: Deep Differentiable Simplex Layer for Learning Geometric Signals", "url": "http://arxiv.org/pdf/1901.11082v3", "summary": "We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for geometric deep learning. The DDSL is a differentiable layer compatible with deep neural networks for bridging simplex mesh-based geometry representations (point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images (e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to perform differentiable, efficient, anti-aliased rasterization of simplex-based signals. We present a complete theoretical framework for the process as well as an efficient backpropagation algorithm. Compared to previous differentiable renderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees and dimensions. In particular, we explore its applications to 2D shapes and illustrate two applications of this method: (1) mesh editing and optimization guided by neural network outputs, and (2) using DDSL for a differentiable rasterization loss to facilitate end-to-end training of polygon generators. We are able to validate the effectiveness of gradient-based shape optimization with the example of airfoil optimization, and using the differentiable rasterization loss to facilitate end-to-end training, we surpass state of the art for polygonal image segmentation given ground-truth bounding boxes.", "published": "2019-01-30T20:17:50Z", "version": 3}, {"aid": "1901.11137", "authors": ["Emiel Hoogeboom", "Rianne van den Berg", "Max Welling"], "title": "Emerging Convolutions for Generative Normalizing Flows", "url": "http://arxiv.org/pdf/1901.11137v3", "summary": "Generative flows are attractive because they admit exact likelihood optimization and efficient image synthesis. Recently, Kingma & Dhariwal (2018) demonstrated with Glow that generative flows are capable of generating high quality images. We generalize the 1 x 1 convolutions proposed in Glow to invertible d x d convolutions, which are more flexible since they operate on both channel and spatial axes. We propose two methods to produce invertible convolutions that have receptive fields identical to standard convolutions: Emerging convolutions are obtained by chaining specific autoregressive convolutions, and periodic convolutions are decoupled in the frequency domain. Our experiments show that the flexibility of d x d convolutions significantly improves the performance of generative flow models on galaxy images, CIFAR10 and ImageNet.", "published": "2019-01-30T23:02:37Z", "version": 3}, {"aid": "1901.11153", "authors": ["Haozhe Xie", "Hongxun Yao", "Xiaoshuai Sun", "Shangchen Zhou", "Shengping Zhang"], "title": "Pix2Vox: Context-aware 3D Reconstruction from Single and Multi-view Images", "url": "http://arxiv.org/pdf/1901.11153v2", "summary": "Recovering the 3D representation of an object from single-view or multi-view RGB images by deep neural networks has attracted increasing attention in the past few years. Several mainstream works (e.g., 3D-R2N2) use recurrent neural networks (RNNs) to fuse multiple feature maps extracted from input images sequentially. However, when given the same set of input images with different orders, RNN-based approaches are unable to produce consistent reconstruction results. Moreover, due to long-term memory loss, RNNs cannot fully exploit input images to refine reconstruction results. To solve these problems, we propose a novel framework for single-view and multi-view 3D reconstruction, named Pix2Vox. By using a well-designed encoder-decoder, it generates a coarse 3D volume from each input image. Then, a context-aware fusion module is introduced to adaptively select high-quality reconstructions for each part (e.g., table legs) from different coarse 3D volumes to obtain a fused 3D volume. Finally, a refiner further refines the fused 3D volume to generate the final output. Experimental results on the ShapeNet and Pix3D benchmarks indicate that the proposed Pix2Vox outperforms state-of-the-arts by a large margin. Furthermore, the proposed method is 24 times faster than 3D-R2N2 in terms of backward inference time. The experiments on ShapeNet unseen 3D categories have shown the superior generalization abilities of our method.", "published": "2019-01-31T00:01:25Z", "version": 2}, {"aid": "1901.11228", "authors": ["Vineet Edupuganti", "Morteza Mardani", "Shreyas Vasanawala", "John Pauly"], "title": "Uncertainty Quantification in Deep MRI Reconstruction", "url": "http://arxiv.org/pdf/1901.11228v3", "summary": "Reliable MRI is crucial for accurate interpretation in therapeutic and diagnostic tasks. However, undersampling during MRI acquisition as well as the overparameterized and non-transparent nature of deep learning (DL) leaves substantial uncertainty about the accuracy of DL reconstruction. With this in mind, this study aims to quantify the uncertainty in image recovery with DL models. To this end, we first leverage variational autoencoders (VAEs) to develop a probabilistic reconstruction scheme that maps out (low-quality) short scans with aliasing artifacts to the diagnostic-quality ones. The VAE encodes the acquisition uncertainty in a latent code and naturally offers a posterior of the image from which one can generate pixel variance maps using Monte-Carlo sampling. Accurately predicting risk requires knowledge of the bias as well, for which we leverage Stein's Unbiased Risk Estimator (SURE) as a proxy for mean-squared-error (MSE). Extensive empirical experiments are performed for Knee MRI reconstruction under different training losses (adversarial and pixel-wise) and unrolled recurrent network architectures. Our key observations indicate that: 1) adversarial losses introduce more uncertainty; and 2) recurrent unrolled nets reduce the prediction uncertainty and risk.", "published": "2019-01-31T06:33:48Z", "version": 3}, {"aid": "1902.10815", "authors": ["Cheng Ouyang", "Jo Schlemper", "Carlo Biffi", "Gavin Seegoolam", "Jose Caballero", "Anthony N. Price", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Generalizing Deep Learning MRI Reconstruction across Different Domains", "url": "http://arxiv.org/pdf/1902.10815v2", "summary": "We look into the robustness of deep learning based MRI reconstruction when tested on unseen contrasts and organs. We then propose to generalize the network by training with large publicly-available natural image datasets with synthesized phase information to achieve high cross-domain reconstruction performance which is competitive with domain-specific training. To explain its generalization mechanism, we have also analyzed patch sets for different training datasets.", "published": "2019-01-31T12:08:33Z", "version": 2}, {"aid": "1901.11515", "authors": ["Willie Neiswanger", "Kirthevasan Kandasamy", "Barnabas Poczos", "Jeff Schneider", "Eric Xing"], "title": "ProBO: Versatile Bayesian Optimization Using Any Probabilistic Programming Language", "url": "http://arxiv.org/pdf/1901.11515v2", "summary": "Optimizing an expensive-to-query function is a common task in science and engineering, where it is beneficial to keep the number of queries to a minimum. A popular strategy is Bayesian optimization (BO), which leverages probabilistic models for this task. Most BO today uses Gaussian processes (GPs), or a few other surrogate models. However, there is a broad set of Bayesian modeling techniques that could be used to capture complex systems and reduce the number of queries in BO. Probabilistic programming languages (PPLs) are modern tools that allow for flexible model definition, prior specification, model composition, and automatic inference. In this paper, we develop ProBO, a BO procedure that uses only standard operations common to most PPLs. This allows a user to drop in a model built with an arbitrary PPL and use it directly in BO. We describe acquisition functions for ProBO, and strategies for efficiently optimizing these functions given complex models or costly inference procedures. Using existing PPLs, we implement new models to aid in a few challenging optimization settings, and demonstrate these on model hyperparameter and architecture search tasks.", "published": "2019-01-31T18:35:56Z", "version": 2}, {"aid": "1902.00137", "authors": ["Kyungjae Lee", "Sungyub Kim", "Sungbin Lim", "Sungjoon Choi", "Songhwai Oh"], "title": "Tsallis Reinforcement Learning: A Unified Framework for Maximum Entropy Reinforcement Learning", "url": "http://arxiv.org/pdf/1902.00137v2", "summary": "In this paper, we present a new class of Markov decision processes (MDPs), called Tsallis MDPs, with Tsallis entropy maximization, which generalizes existing maximum entropy reinforcement learning (RL). A Tsallis MDP provides a unified framework for the original RL problem and RL with various types of entropy, including the well-known standard Shannon-Gibbs (SG) entropy, using an additional real-valued parameter, called an entropic index. By controlling the entropic index, we can generate various types of entropy, including the SG entropy, and a different entropy results in a different class of the optimal policy in Tsallis MDPs. We also provide a full mathematical analysis of Tsallis MDPs, including the optimality condition, performance error bounds, and convergence. Our theoretical result enables us to use any positive entropic index in RL. To handle complex and large-scale problems, we propose a model-free actor-critic RL method using Tsallis entropy maximization. We evaluate the regularization effect of the Tsallis entropy with various values of entropic indices and show that the entropic index controls the exploration tendency of the proposed method. For a different type of RL problems, we find that a different value of the entropic index is desirable. The proposed method is evaluated using the MuJoCo simulator and achieves the state-of-the-art performance.", "published": "2019-01-31T23:59:34Z", "version": 2}, {"aid": "1902.00301", "authors": ["Oleksii Sidorov", "Jon Yngve Hardeberg"], "title": "Deep Hyperspectral Prior: Denoising, Inpainting, Super-Resolution", "url": "http://arxiv.org/pdf/1902.00301v2", "summary": "Deep learning algorithms have demonstrated state-of-the-art performance in various tasks of image restoration. This was made possible through the ability of CNNs to learn from large exemplar sets. However, the latter becomes an issue for hyperspectral image processing where datasets commonly consist of just a few images. In this work, we propose a new approach to denoising, inpainting, and super-resolution of hyperspectral image data using intrinsic properties of a CNN without any training. The performance of the given algorithm is shown to be comparable to the performance of trained networks, while its application is not restricted by the availability of training data. This work is an extension of original \"deep prior\" algorithm to HSI domain and 3D-convolutional networks.", "published": "2019-02-01T12:20:38Z", "version": 2}, {"aid": "1902.00347", "authors": ["Christoph Angermann", "Markus Haltmeier", "Ruth Steiger", "Sergiy Pereverzyev Jr", "Elke Gizewski"], "title": "Projection-Based 2.5D U-net Architecture for Fast Volumetric Segmentation", "url": "http://arxiv.org/pdf/1902.00347v2", "summary": "Convolutional neural networks are state-of-the-art for various segmentation tasks. While for 2D images these networks are also computationally efficient, 3D convolutions have huge storage requirements and require long training time. To overcome this issue, we introduce a network structure for volumetric data without 3D convolutional layers. The main idea is to include maximum intensity projections from different directions to transform the volumetric data to a sequence of images, where each image contains information of the full data. We then apply 2D convolutions to these projection images and lift them again to volumetric data using a trainable reconstruction algorithm.The proposed network architecture has less storage requirements than network structures using 3D convolutions. For a tested binary segmentation task, it even shows better performance than the 3D U-net and can be trained much faster.", "published": "2019-02-01T14:19:00Z", "version": 2}, {"aid": "1902.00730", "authors": ["Fayez Lahoud", "Radhakrishna Achanta", "Pablo M\u00e1rquez-Neila", "Sabine S\u00fcsstrunk"], "title": "Self-Binarizing Networks", "url": "http://arxiv.org/pdf/1902.00730v1", "summary": "We present a method to train self-binarizing neural networks, that is, networks that evolve their weights and activations during training to become binary. To obtain similar binary networks, existing methods rely on the sign activation function. This function, however, has no gradients for non-zero values, which makes standard backpropagation impossible. To circumvent the difficulty of training a network relying on the sign activation function, these methods alternate between floating-point and binary representations of the network during training, which is sub-optimal and inefficient. We approach the binarization task by training on a unique representation involving a smooth activation function, which is iteratively sharpened during training until it becomes a binary representation equivalent to the sign activation function. Additionally, we introduce a new technique to perform binary batch normalization that simplifies the conventional batch normalization by transforming it into a simple comparison operation. This is unlike existing methods, which are forced to the retain the conventional floating-point-based batch normalization. Our binary networks, apart from displaying advantages of lower memory and computation as compared to conventional floating-point and binary networks, also show higher classification accuracy than existing state-of-the-art methods on multiple benchmark datasets.", "published": "2019-02-02T14:48:16Z", "version": 1}, {"aid": "1902.01722", "authors": ["Paavo Parmas"], "title": "Total stochastic gradient algorithms and applications in reinforcement learning", "url": "http://arxiv.org/pdf/1902.01722v1", "summary": "Backpropagation and the chain rule of derivatives have been prominent; however, the total derivative rule has not enjoyed the same amount of attention. In this work we show how the total derivative rule leads to an intuitive visual framework for creating gradient estimators on graphical models. In particular, previous \"policy gradient theorems\" are easily derived. We derive new gradient estimators based on density estimation, as well as a likelihood ratio gradient, which \"jumps\" to an intermediate node, not directly to the objective function. We evaluate our methods on model-based policy gradient algorithms, achieve good performance, and present evidence towards demystifying the success of the popular PILCO algorithm.", "published": "2019-02-05T14:54:05Z", "version": 1}, {"aid": "1902.01831", "authors": ["Roberto Valle", "Jos\u00e9 M. Buenaposada", "Antonio Vald\u00e9s", "Luis Baumela"], "title": "Face Alignment using a 3D Deeply-initialized Ensemble of Regression Trees", "url": "http://arxiv.org/pdf/1902.01831v2", "summary": "Face alignment algorithms locate a set of landmark points in images of faces taken in unrestricted situations. State-of-the-art approaches typically fail or lose accuracy in the presence of occlusions, strong deformations, large pose variations and ambiguous configurations. In this paper we present 3DDE, a robust and efficient face alignment algorithm based on a coarse-to-fine cascade of ensembles of regression trees. It is initialized by robustly fitting a 3D face model to the probability maps produced by a convolutional neural network. With this initialization we address self-occlusions and large face rotations. Further, the regressor implicitly imposes a prior face shape on the solution, addressing occlusions and ambiguous face configurations. Its coarse-to-fine structure tackles the combinatorial explosion of parts deformation. In the experiments performed, 3DDE improves the state-of-the-art in 300W, COFW, AFLW and WFLW data sets. Finally, we perform cross-dataset experiments that reveal the existence of a significant data set bias in these benchmarks.", "published": "2019-02-05T18:07:17Z", "version": 2}, {"aid": "1902.01996", "authors": ["Chiyuan Zhang", "Samy Bengio", "Yoram Singer"], "title": "Are All Layers Created Equal?", "url": "http://arxiv.org/pdf/1902.01996v4", "summary": "Understanding deep neural networks is a major research objective with notable experimental and theoretical attention in recent years. The practical success of excessively large networks underscores the need for better theoretical analyses and justifications. In this paper we focus on layer-wise functional structure and behavior in overparameterized deep models. To do so, we study empirically the layers' robustness to post-training re-initialization and re-randomization of the parameters. We provide experimental results which give evidence for the heterogeneity of layers. Morally, layers of large deep neural networks can be categorized as either \"robust\" or \"critical\". Resetting the robust layers to their initial values does not result in adverse decline in performance. In many cases, robust layers hardly change throughout training. In contrast, re-initializing critical layers vastly degrades the performance of the network with test error essentially dropping to random guesses. Our study provides further evidence that mere parameter counting or norm calculations are too coarse in studying generalization of deep models, and \"flatness\" and robustness analysis of trained models need to be examined while taking into account the respective network architectures.", "published": "2019-02-06T01:29:01Z", "version": 4}, {"aid": "1902.02354", "authors": ["Oded Ben-David", "Zohar Ringel"], "title": "The role of a layer in deep neural networks: a Gaussian Process perspective", "url": "http://arxiv.org/pdf/1902.02354v3", "summary": "A fundamental question in deep learning concerns the role played by individual layers in a deep neural network (DNN) and the transferable properties of the data representations which they learn. To the extent that layers have clear roles, one should be able to optimize them separately using layer-wise loss functions. Such loss functions would describe what is the set of good data representations at each depth of the network and provide a target for layer-wise greedy optimization (LEGO). Here we derive a novel correspondence between Gaussian Processes and SGD trained deep neural networks. Leveraging this correspondence, we derive the Deep Gaussian Layer-wise loss functions (DGLs) which, we believe, are the first supervised layer-wise loss functions which are both explicit and competitive in terms of accuracy. Being highly structured and symmetric, the DGLs provide a promising analytic route to understanding the internal representations generated by DNNs.", "published": "2019-02-06T19:00:03Z", "version": 3}, {"aid": "1902.02399", "authors": ["Payel Das", "Brian Quanz", "Pin-Yu Chen", "Jae-wook Ahn", "Dhruv Shah"], "title": "Toward A Neuro-inspired Creative Decoder", "url": "http://arxiv.org/pdf/1902.02399v4", "summary": "Creativity, a process that generates novel and meaningful ideas, involves increased association between task-positive (control) and task-negative (default) networks in the human brain. Inspired by this seminal finding, in this study we propose a creative decoder within a deep generative framework, which involves direct modulation of the neuronal activation pattern after sampling from the learned latent space. The proposed approach is fully unsupervised and can be used off-the-shelf. Several novelty metrics and human evaluation were used to evaluate the creative capacity of the deep decoder. Our experiments on different image datasets (MNIST, FMNIST, MNIST+FMNIST, WikiArt and CelebA) reveal that atypical co-activation of highly activated and weakly activated neurons in a deep decoder promotes generation of novel and meaningful artifacts.", "published": "2019-02-06T21:06:58Z", "version": 4}, {"aid": "1902.02449", "authors": ["Byung Hyun Lee", "Se Young Chun"], "title": "Empirically Accelerating Scaled Gradient Projection Using Deep Neural Network For Inverse Problems In Image Processing", "url": "http://arxiv.org/pdf/1902.02449v3", "summary": "Recently, deep neural networks (DNNs) have shown advantages in accelerating optimization algorithms. One approach is to unfold finite number of iterations of conventional optimization algorithms and to learn parameters in the algorithms. However, these are forward methods and are indeed neither iterative nor convergent. Here, we present a novel DNN-based convergent iterative algorithm that accelerates conventional optimization algorithms. We train a DNN to yield parameters in scaled gradient projection method. So far, these parameters have been chosen heuristically, but have shown to be crucial for good empirical performance. In simulation results, the proposed method significantly improves the empirical convergence rate over conventional optimization methods for various large-scale inverse problems in image processing.", "published": "2019-02-07T02:19:53Z", "version": 3}, {"aid": "1902.02476", "authors": ["Wesley Maddox", "Timur Garipov", "Pavel Izmailov", "Dmitry Vetrov", "Andrew Gordon Wilson"], "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning", "url": "http://arxiv.org/pdf/1902.02476v2", "summary": "We propose SWA-Gaussian (SWAG), a simple, scalable, and general purpose approach for uncertainty representation and calibration in deep learning. Stochastic Weight Averaging (SWA), which computes the first moment of stochastic gradient descent (SGD) iterates with a modified learning rate schedule, has recently been shown to improve generalization in deep learning. With SWAG, we fit a Gaussian using the SWA solution as the first moment and a low rank plus diagonal covariance also derived from the SGD iterates, forming an approximate posterior distribution over neural network weights; we then sample from this Gaussian distribution to perform Bayesian model averaging. We empirically find that SWAG approximates the shape of the true posterior, in accordance with results describing the stationary distribution of SGD iterates. Moreover, we demonstrate that SWAG performs well on a wide variety of tasks, including out of sample detection, calibration, and transfer learning, in comparison to many popular alternatives including MC dropout, KFAC Laplace, SGLD, and temperature scaling.", "published": "2019-02-07T05:15:46Z", "version": 2}, {"aid": "1902.02693", "authors": ["Joost Visser", "Alessandro Corbetta", "Vlado Menkovski", "Federico Toschi"], "title": "StampNet: unsupervised multi-class object discovery", "url": "http://arxiv.org/pdf/1902.02693v1", "summary": "Unsupervised object discovery in images involves uncovering recurring patterns that define objects and discriminates them against the background. This is more challenging than image clustering as the size and the location of the objects are not known: this adds additional degrees of freedom and increases the problem complexity. In this work, we propose StampNet, a novel autoencoding neural network that localizes shapes (objects) over a simple background in images and categorizes them simultaneously. StampNet consists of a discrete latent space that is used to categorize objects and to determine the location of the objects. The object categories are formed during the training, resulting in the discovery of a fixed set of objects. We present a set of experiments that demonstrate that StampNet is able to localize and cluster multiple overlapping shapes with varying complexity including the digits from the MNIST dataset. We also present an application of StampNet in the localization of pedestrians in overhead depth-maps.", "published": "2019-02-07T15:35:55Z", "version": 1}, {"aid": "1902.02875", "authors": ["Christian Klos", "Yaroslav Felipe Kalle Kossio", "Sven Goedeke", "Aditya Gilra", "Raoul-Martin Memmesheimer"], "title": "Dynamical learning of dynamics", "url": "http://arxiv.org/pdf/1902.02875v3", "summary": "The ability of humans and animals to quickly adapt to novel tasks is difficult to reconcile with the standard paradigm of learning by slow synaptic weight modification. Here we show that fixed-weight neural networks can learn to generate required dynamics by imitation. After appropriate weight pretraining, the networks quickly and dynamically adapt to learn new tasks and thereafter continue to achieve them without further teacher feedback. We explain this ability and illustrate it with a variety of target dynamics, ranging from oscillatory trajectories to driven and chaotic dynamical systems.", "published": "2019-02-07T23:00:54Z", "version": 3}, {"aid": "1902.02893", "authors": ["Silviu Pitis"], "title": "Rethinking the Discount Factor in Reinforcement Learning: A Decision Theoretic Approach", "url": "http://arxiv.org/pdf/1902.02893v1", "summary": "Reinforcement learning (RL) agents have traditionally been tasked with maximizing the value function of a Markov decision process (MDP), either in continuous settings, with fixed discount factor $\\gamma < 1$, or in episodic settings, with $\\gamma = 1$. While this has proven effective for specific tasks with well-defined objectives (e.g., games), it has never been established that fixed discounting is suitable for general purpose use (e.g., as a model of human preferences). This paper characterizes rationality in sequential decision making using a set of seven axioms and arrives at a form of discounting that generalizes traditional fixed discounting. In particular, our framework admits a state-action dependent \"discount\" factor that is not constrained to be less than 1, so long as there is eventual long run discounting. Although this broadens the range of possible preference structures in continuous settings, we show that there exists a unique \"optimizing MDP\" with fixed $\\gamma < 1$ whose optimal value function matches the true utility of the optimal policy, and we quantify the difference between value and utility for suboptimal policies. Our work can be seen as providing a normative justification for (a slight generalization of) Martha White's RL task formalism (2017) and other recent departures from the traditional RL, and is relevant to task specification in RL, inverse RL and preference-based RL.", "published": "2019-02-08T00:30:53Z", "version": 1}, {"aid": "1902.03043", "authors": ["Ross Harper", "Joshua Southern"], "title": "A Bayesian Deep Learning Framework for End-To-End Prediction of Emotion from Heartbeat", "url": "http://arxiv.org/pdf/1902.03043v2", "summary": "Automatic prediction of emotion promises to revolutionise human-computer interaction. Recent trends involve fusion of multiple data modalities - audio, visual, and physiological - to classify emotional state. However, in practice, collection of physiological data `in the wild' is currently limited to heartbeat time series of the kind generated by affordable wearable heart monitors. Furthermore, real-world applications of emotion prediction often require some measure of uncertainty over model output, in order to inform downstream decision-making. We present here an end-to-end deep learning model for classifying emotional valence from unimodal heartbeat time series. We further propose a Bayesian framework for modelling uncertainty over these valence predictions, and describe a probabilistic procedure for choosing to accept or reject model output according to the intended application. We benchmarked our framework against two established datasets and achieved peak classification accuracy of 90%. These results lay the foundation for applications of affective computing in real-world domains such as healthcare, where a high premium is placed on non-invasive collection of data, and predictive certainty.", "published": "2019-02-08T12:10:45Z", "version": 2}, {"aid": "1902.03389", "authors": ["Hiroki Tamaru", "Yuki Saito", "Shinnosuke Takamichi", "Tomoki Koriyama", "Hiroshi Saruwatari"], "title": "Generative Moment Matching Network-based Random Modulation Post-filter for DNN-based Singing Voice Synthesis and Neural Double-tracking", "url": "http://arxiv.org/pdf/1902.03389v1", "summary": "This paper proposes a generative moment matching network (GMMN)-based post-filter that provides inter-utterance pitch variation for deep neural network (DNN)-based singing voice synthesis. The natural pitch variation of a human singing voice leads to a richer musical experience and is used in double-tracking, a recording method in which two performances of the same phrase are recorded and mixed to create a richer, layered sound. However, singing voices synthesized using conventional DNN-based methods never vary because the synthesis process is deterministic and only one waveform is synthesized from one musical score. To address this problem, we use a GMMN to model the variation of the modulation spectrum of the pitch contour of natural singing voices and add a randomized inter-utterance variation to the pitch contour generated by conventional DNN-based singing voice synthesis. Experimental evaluations suggest that 1) our approach can provide perceptible inter-utterance pitch variation while preserving speech quality. We extend our approach to double-tracking, and the evaluation demonstrates that 2) GMMN-based neural double-tracking is perceptually closer to natural double-tracking than conventional signal processing-based artificial double-tracking is.", "published": "2019-02-09T07:49:42Z", "version": 1}, {"aid": "1902.03459", "authors": ["Marcin Kopaczka", "Justus Schock", "Dorit Merhof"], "title": "Super-realtime facial landmark detection and shape fitting by deep regression of shape model parameters", "url": "http://arxiv.org/pdf/1902.03459v1", "summary": "We present a method for highly efficient landmark detection that combines deep convolutional neural networks with well established model-based fitting algorithms. Motivated by established model-based fitting methods such as active shapes, we use a PCA of the landmark positions to allow generative modeling of facial landmarks. Instead of computing the model parameters using iterative optimization, the PCA is included in a deep neural network using a novel layer type. The network predicts model parameters in a single forward pass, thereby allowing facial landmark detection at several hundreds of frames per second. Our architecture allows direct end-to-end training of a model-based landmark detection method and shows that deep neural networks can be used to reliably predict model parameters directly without the need for an iterative optimization. The method is evaluated on different datasets for facial landmark detection and medical image segmentation. PyTorch code is freely available at https://github.com/justusschock/shapenet", "published": "2019-02-09T17:59:07Z", "version": 1}, {"aid": "1902.03524", "authors": ["Stephen Balaban"], "title": "Deep learning and face recognition: the state of the art", "url": "http://arxiv.org/pdf/1902.03524v1", "summary": "Deep Neural Networks (DNNs) have established themselves as a dominant technique in machine learning. DNNs have been top performers on a wide variety of tasks including image classification, speech recognition, and face recognition. Convolutional neural networks (CNNs) have been used in nearly all of the top performing methods on the Labeled Faces in the Wild (LFW) dataset. In this talk and accompanying paper, I attempt to provide a review and summary of the deep learning techniques used in the state-of-the-art. In addition, I highlight the need for both larger and more challenging public datasets to benchmark these systems. The high accuracy (99.63% for FaceNet at the time of publishing) and utilization of outside data (hundreds of millions of images in the case of Google's FaceNet) suggest that current face verification benchmarks such as LFW may not be challenging enough, nor provide enough data, for current techniques. There exist a variety of organizations with mobile photo sharing applications that would be capable of releasing a very large scale and highly diverse dataset of facial images captured on mobile devices. Such an \"ImageNet for Face Recognition\" would likely receive a warm welcome from researchers and practitioners alike.", "published": "2019-02-10T01:07:15Z", "version": 1}, {"aid": "1902.03565", "authors": ["Ran He", "Jie Cao", "Lingxiao Song", "Zhenan Sun", "Tieniu Tan"], "title": "Cross-spectral Face Completion for NIR-VIS Heterogeneous Face Recognition", "url": "http://arxiv.org/pdf/1902.03565v1", "summary": "Near infrared-visible (NIR-VIS) heterogeneous face recognition refers to the process of matching NIR to VIS face images. Current heterogeneous methods try to extend VIS face recognition methods to the NIR spectrum by synthesizing VIS images from NIR images. However, due to self-occlusion and sensing gap, NIR face images lose some visible lighting contents so that they are always incomplete compared to VIS face images. This paper models high resolution heterogeneous face synthesis as a complementary combination of two components, a texture inpainting component and pose correction component. The inpainting component synthesizes and inpaints VIS image textures from NIR image textures. The correction component maps any pose in NIR images to a frontal pose in VIS images, resulting in paired NIR and VIS textures. A warping procedure is developed to integrate the two components into an end-to-end deep network. A fine-grained discriminator and a wavelet-based discriminator are designed to supervise intra-class variance and visual quality respectively. One UV loss, two adversarial losses and one pixel loss are imposed to ensure synthesis results. We demonstrate that by attaching the correction component, we can simplify heterogeneous face synthesis from one-to-many unpaired image translation to one-to-one paired image translation, and minimize spectral and pose discrepancy during heterogeneous recognition. Extensive experimental results show that our network not only generates high-resolution VIS face images and but also facilitates the accuracy improvement of heterogeneous face recognition.", "published": "2019-02-10T10:20:38Z", "version": 1}, {"aid": "1902.03619", "authors": ["Victoria Fernandez Abrevaya", "Adnane Boukhayma", "Stefanie Wuhrer", "Edmond Boyer"], "title": "A Decoupled 3D Facial Shape Model by Adversarial Training", "url": "http://arxiv.org/pdf/1902.03619v3", "summary": "Data-driven generative 3D face models are used to compactly encode facial shape data into meaningful parametric representations. A desirable property of these models is their ability to effectively decouple natural sources of variation, in particular identity and expression. While factorized representations have been proposed for that purpose, they are still limited in the variability they can capture and may present modeling artifacts when applied to tasks such as expression transfer. In this work, we explore a new direction with Generative Adversarial Networks and show that they contribute to better face modeling performances, especially in decoupling natural factors, while also achieving more diverse samples. To train the model we introduce a novel architecture that combines a 3D generator with a 2D discriminator that leverages conventional CNNs, where the two components are bridged by a geometry mapping layer. We further present a training scheme, based on auxiliary classifiers, to explicitly disentangle identity and expression attributes. Through quantitative and qualitative results on standard face datasets, we illustrate the benefits of our model and demonstrate that it outperforms competing state of the art methods in terms of decoupling and diversity.", "published": "2019-02-10T15:15:44Z", "version": 3}, {"aid": "1902.04394", "authors": ["Alex B\u00e4uerle", "Christian van Onzenoodt", "Timo Ropinski"], "title": "Net2Vis -- A Visual Grammar for Automatically Generating Publication-Tailored CNN Architecture Visualizations", "url": "http://arxiv.org/pdf/1902.04394v6", "summary": "To convey neural network architectures in publications, appropriate visualizations are of great importance. While most current deep learning papers contain such visualizations, these are usually handcrafted just before publication, which results in a lack of a common visual grammar, significant time investment, errors, and ambiguities. Current automatic network visualization tools focus on debugging the network itself and are not ideal for generating publication visualizations. Therefore, we present an approach to automate this process by translating network architectures specified in Keras into visualizations that can directly be embedded into any publication. To do so, we propose a visual grammar for convolutional neural networks (CNNs), which has been derived from an analysis of such figures extracted from all ICCV and CVPR papers published between 2013 and 2019. The proposed grammar incorporates visual encoding, network layout, layer aggregation, and legend generation. We have further realized our approach in an online system available to the community, which we have evaluated through expert feedback, and a quantitative study. It not only reduces the time needed to generate network visualizations for publications, but also enables a unified and unambiguous visualization design.", "published": "2019-02-11T15:13:58Z", "version": 6}, {"aid": "1902.04049", "authors": ["Nabil Ibtehaz", "M. Sohel Rahman"], "title": "MultiResUNet : Rethinking the U-Net Architecture for Multimodal Biomedical Image Segmentation", "url": "http://arxiv.org/pdf/1902.04049v1", "summary": "In recent years Deep Learning has brought about a breakthrough in Medical Image Segmentation. U-Net is the most prominent deep network in this regard, which has been the most popular architecture in the medical imaging community. Despite outstanding overall performance in segmenting multimodal medical images, from extensive experimentations on challenging datasets, we found out that the classical U-Net architecture seems to be lacking in certain aspects. Therefore, we propose some modifications to improve upon the already state-of-the-art U-Net model. Hence, following the modifications we develop a novel architecture MultiResUNet as the potential successor to the successful U-Net architecture. We have compared our proposed architecture MultiResUNet with the classical U-Net on a vast repertoire of multimodal medical images. Albeit slight improvements in the cases of ideal images, a remarkable gain in performance has been attained for challenging images. We have evaluated our model on five different datasets, each with their own unique challenges, and have obtained a relative improvement in performance of 10.15%, 5.07%, 2.63%, 1.41%, and 0.62% respectively.", "published": "2019-02-11T18:50:11Z", "version": 1}, {"aid": "1902.04161", "authors": ["Gopalakrishnan Srinivasan", "Kaushik Roy"], "title": "ReStoCNet: Residual Stochastic Binary Convolutional Spiking Neural Network for Memory-Efficient Neuromorphic Computing", "url": "http://arxiv.org/pdf/1902.04161v1", "summary": "In this work, we propose ReStoCNet, a residual stochastic multilayer convolutional Spiking Neural Network (SNN) composed of binary kernels, to reduce the synaptic memory footprint and enhance the computational efficiency of SNNs for complex pattern recognition tasks. ReStoCNet consists of an input layer followed by stacked convolutional layers for hierarchical input feature extraction, pooling layers for dimensionality reduction, and fully-connected layer for inference. In addition, we introduce residual connections between the stacked convolutional layers to improve the hierarchical feature learning capability of deep SNNs. We propose Spike Timing Dependent Plasticity (STDP) based probabilistic learning algorithm, referred to as Hybrid-STDP (HB-STDP), incorporating Hebbian and anti-Hebbian learning mechanisms, to train the binary kernels forming ReStoCNet in a layer-wise unsupervised manner. We demonstrate the efficacy of ReStoCNet and the presented HB-STDP based unsupervised training methodology on the MNIST and CIFAR-10 datasets. We show that residual connections enable the deeper convolutional layers to self-learn useful high-level input features and mitigate the accuracy loss observed in deep SNNs devoid of residual connections. The proposed ReStoCNet offers >20x kernel memory compression compared to full-precision (32-bit) SNN while yielding high enough classification accuracy on the chosen pattern recognition tasks.", "published": "2019-02-11T21:54:48Z", "version": 1}, {"aid": "1902.04294", "authors": ["Jaeyoung Yoo", "Hojun Lee", "Nojun Kwak"], "title": "Unpriortized Autoencoder For Image Generation", "url": "http://arxiv.org/pdf/1902.04294v2", "summary": "In this paper, we treat the image generation task using an autoencoder, a representative latent model. Unlike many studies regularizing the latent variable's distribution by assuming a manually specified prior, we approach the image generation task using an autoencoder by directly estimating the latent distribution. To this end, we introduce 'latent density estimator' which captures latent distribution explicitly and propose its structure. Through experiments, we show that our generative model generates images with the improved visual quality compared to previous autoencoder-based generative models.", "published": "2019-02-12T09:41:36Z", "version": 2}, {"aid": "1902.04698", "authors": ["Chiyuan Zhang", "Samy Bengio", "Moritz Hardt", "Michael C. Mozer", "Yoram Singer"], "title": "Identity Crisis: Memorization and Generalization under Extreme Overparameterization", "url": "http://arxiv.org/pdf/1902.04698v4", "summary": "We study the interplay between memorization and generalization of overparameterized networks in the extreme case of a single training example and an identity-mapping task. We examine fully-connected and convolutional networks (FCN and CNN), both linear and nonlinear, initialized randomly and then trained to minimize the reconstruction error. The trained networks stereotypically take one of two forms: the constant function (memorization) and the identity function (generalization). We formally characterize generalization in single-layer FCNs and CNNs. We show empirically that different architectures exhibit strikingly different inductive biases. For example, CNNs of up to 10 layers are able to generalize from a single example, whereas FCNs cannot learn the identity function reliably from 60k examples. Deeper CNNs often fail, but nonetheless do astonishing work to memorize the training output: because CNN biases are location invariant, the model must progressively grow an output pattern from the image boundaries via the coordination of many layers. Our work helps to quantify and visualize the sensitivity of inductive biases to architectural choices such as depth, kernel width, and number of channels.", "published": "2019-02-13T01:45:30Z", "version": 4}, {"aid": "1902.04832", "authors": ["Tshilidzi Marwala"], "title": "Relative rationality: Is machine rationality subjective?", "url": "http://arxiv.org/pdf/1902.04832v1", "summary": "Rational decision making in its linguistic description means making logical decisions. In essence, a rational agent optimally processes all relevant information to achieve its goal. Rationality has two elements and these are the use of relevant information and the efficient processing of such information. In reality, relevant information is incomplete, imperfect and the processing engine, which is a brain for humans, is suboptimal. Humans are risk averse rather than utility maximizers. In the real world, problems are predominantly non-convex and this makes the idea of rational decision-making fundamentally unachievable and Herbert Simon called this bounded rationality. There is a trade-off between the amount of information used for decision-making and the complexity of the decision model used. This explores whether machine rationality is subjective and concludes that indeed it is.", "published": "2019-02-13T10:08:12Z", "version": 1}, {"aid": "1902.05908", "authors": ["Naimul Mefraz Khan", "Nabila Abraham", "Ling Guan"], "title": "Machine Learning on Biomedical Images: Interactive Learning, Transfer Learning, Class Imbalance, and Beyond", "url": "http://arxiv.org/pdf/1902.05908v1", "summary": "In this paper, we highlight three issues that limit performance of machine learning on biomedical images, and tackle them through 3 case studies: 1) Interactive Machine Learning (IML): we show how IML can drastically improve exploration time and quality of direct volume rendering. 2) transfer learning: we show how transfer learning along with intelligent pre-processing can result in better Alzheimer's diagnosis using a much smaller training set 3) data imbalance: we show how our novel focal Tversky loss function can provide better segmentation results taking into account the imbalanced nature of segmentation datasets. The case studies are accompanied by in-depth analytical discussion of results with possible future directions.", "published": "2019-02-13T21:23:07Z", "version": 1}, {"aid": "1902.05978", "authors": ["Baris Gecer", "Stylianos Ploumpis", "Irene Kotsia", "Stefanos Zafeiriou"], "title": "GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction", "url": "http://arxiv.org/pdf/1902.05978v2", "summary": "In the past few years, a lot of work has been done towards reconstructing the 3D facial structure from single images by capitalizing on the power of Deep Convolutional Neural Networks (DCNNs). In the most recent works, differentiable renderers were employed in order to learn the relationship between the facial identity features and the parameters of a 3D morphable model for shape and texture. The texture features either correspond to components of a linear texture space or are learned by auto-encoders directly from in-the-wild images. In all cases, the quality of the facial texture reconstruction of the state-of-the-art methods is still not capable of modeling textures in high fidelity. In this paper, we take a radically different approach and harness the power of Generative Adversarial Networks (GANs) and DCNNs in order to reconstruct the facial texture and shape from single images. That is, we utilize GANs to train a very powerful generator of facial texture in UV space. Then, we revisit the original 3D Morphable Models (3DMMs) fitting approaches making use of non-linear optimization to find the optimal latent parameters that best reconstruct the test image but under a new perspective. We optimize the parameters with the supervision of pretrained deep identity features through our end-to-end differentiable framework. We demonstrate excellent results in photorealistic and identity preserving 3D face reconstructions and achieve for the first time, to the best of our knowledge, facial texture reconstruction with high-frequency details.", "published": "2019-02-15T19:53:45Z", "version": 2}, {"aid": "1902.11106", "authors": ["Serkan Kiranyaz", "Turker Ince", "Alexandros Iosifidis", "Moncef Gabbouj"], "title": "Operational Neural Networks", "url": "http://arxiv.org/pdf/1902.11106v2", "summary": "Feed-forward, fully-connected Artificial Neural Networks (ANNs) or the so-called Multi-Layer Perceptrons (MLPs) are well-known universal approximators. However, their learning performance varies significantly depending on the function or the solution space that they attempt to approximate. This is mainly because of their homogenous configuration based solely on the linear neuron model. Therefore, while they learn very well those problems with a monotonous, relatively simple and linearly separable solution space, they may entirely fail to do so when the solution space is highly nonlinear and complex. Sharing the same linear neuron model with two additional constraints (local connections and weight sharing), this is also true for the conventional Convolutional Neural Networks (CNNs) and, it is, therefore, not surprising that in many challenging problems only the deep CNNs with a massive complexity and depth can achieve the required diversity and the learning performance. In order to address this drawback and also to accomplish a more generalized model over the convolutional neurons, this study proposes a novel network model, called Operational Neural Networks (ONNs), which can be heterogeneous and encapsulate neurons with any set of operators to boost diversity and to learn highly complex and multi-modal functions or spaces with minimal network complexity and training data. Finally, a novel training method is formulated to back-propagate the error through the operational layers of ONNs. Experimental results over highly challenging problems demonstrate the superior learning capabilities of ONNs even with few neurons and hidden layers.", "published": "2019-02-15T20:13:51Z", "version": 2}, {"aid": "1902.06066", "authors": ["Varshaneya V", "Balasubramanian S", "Darshan Gera"], "title": "RES-SE-NET: Boosting Performance of Resnets by Enhancing Bridge-connections", "url": "http://arxiv.org/pdf/1902.06066v1", "summary": "One of the ways to train deep neural networks effectively is to use residual connections. Residual connections can be classified as being either identity connections or bridge-connections with a reshaping convolution. Empirical observations on CIFAR-10 and CIFAR-100 datasets using a baseline Resnet model, with bridge-connections removed, have shown a significant reduction in accuracy. This reduction is due to lack of contribution, in the form of feature maps, by the bridge-connections. Hence bridge-connections are vital for Resnet. However, all feature maps in the bridge-connections are considered to be equally important. In this work, an upgraded architecture \"Res-SE-Net\" is proposed to further strengthen the contribution from the bridge-connections by quantifying the importance of each feature map and weighting them accordingly using Squeeze-and-Excitation (SE) block. It is demonstrated that Res-SE-Net generalizes much better than Resnet and SE-Resnet on the benchmark CIFAR-10 and CIFAR-100 datasets.", "published": "2019-02-16T08:25:16Z", "version": 1}, {"aid": "1902.06068", "authors": ["Zhihao Wang", "Jian Chen", "Steven C. H. Hoi"], "title": "Deep Learning for Image Super-resolution: A Survey", "url": "http://arxiv.org/pdf/1902.06068v2", "summary": "Image Super-Resolution (SR) is an important class of image processing techniques to enhance the resolution of images and videos in computer vision. Recent years have witnessed remarkable progress of image super-resolution using deep learning techniques. This article aims to provide a comprehensive survey on recent advances of image super-resolution using deep learning approaches. In general, we can roughly group the existing studies of SR techniques into three major categories: supervised SR, unsupervised SR, and domain-specific SR. In addition, we also cover some other important issues, such as publicly available benchmark datasets and performance evaluation metrics. Finally, we conclude this survey by highlighting several future directions and open issues which should be further addressed by the community in the future.", "published": "2019-02-16T08:39:36Z", "version": 2}, {"aid": "1902.06292", "authors": ["Sercan O. Arik", "Tomas Pfister"], "title": "ProtoAttend: Attention-Based Prototypical Learning", "url": "http://arxiv.org/pdf/1902.06292v4", "summary": "We propose a novel inherently interpretable machine learning method that bases decisions on few relevant examples that we call prototypes. Our method, ProtoAttend, can be integrated into a wide range of neural network architectures including pre-trained models. It utilizes an attention mechanism that relates the encoded representations to samples in order to determine prototypes. The resulting model outperforms state of the art in three high impact problems without sacrificing accuracy of the original model: (1) it enables high-quality interpretability that outputs samples most relevant to the decision-making (i.e. a sample-based interpretability method); (2) it achieves state of the art confidence estimation by quantifying the mismatch across prototype labels; and (3) it obtains state of the art in distribution mismatch detection. All this can be achieved with minimal additional test time and a practically viable training time computational cost.", "published": "2019-02-17T17:12:07Z", "version": 4}, {"aid": "1902.06853", "authors": ["Soufiane Hayou", "Arnaud Doucet", "Judith Rousseau"], "title": "On the Impact of the Activation Function on Deep Neural Networks Training", "url": "http://arxiv.org/pdf/1902.06853v2", "summary": "The weight initialization and the activation function of deep neural networks have a crucial impact on the performance of the training procedure. An inappropriate selection can lead to the loss of information of the input during forward propagation and the exponential vanishing/exploding of gradients during back-propagation. Understanding the theoretical properties of untrained random networks is key to identifying which deep networks may be trained successfully as recently demonstrated by Samuel et al (2017) who showed that for deep feedforward neural networks only a specific choice of hyperparameters known as the `Edge of Chaos' can lead to good performance. While the work by Samuel et al (2017) discuss trainability issues, we focus here on training acceleration and overall performance. We give a comprehensive theoretical analysis of the Edge of Chaos and show that we can indeed tune the initialization parameters and the activation function in order to accelerate the training and improve the performance.", "published": "2019-02-19T00:50:19Z", "version": 2}, {"aid": "1902.07153", "authors": ["Felix Wu", "Tianyi Zhang", "Amauri Holanda de Souza Jr.", "Christopher Fifty", "Tao Yu", "Kilian Q. Weinberger"], "title": "Simplifying Graph Convolutional Networks", "url": "http://arxiv.org/pdf/1902.07153v2", "summary": "Graph Convolutional Networks (GCNs) and their variants have experienced significant attention and have become the de facto methods for learning graph representations. GCNs derive inspiration primarily from recent deep learning approaches, and as a result, may inherit unnecessary complexity and redundant computation. In this paper, we reduce this excess complexity through successively removing nonlinearities and collapsing weight matrices between consecutive layers. We theoretically analyze the resulting linear model and show that it corresponds to a fixed low-pass filter followed by a linear classifier. Notably, our experimental evaluation demonstrates that these simplifications do not negatively impact accuracy in many downstream applications. Moreover, the resulting model scales to larger datasets, is naturally interpretable, and yields up to two orders of magnitude speedup over FastGCN.", "published": "2019-02-19T17:21:15Z", "version": 2}, {"aid": "1902.07474", "authors": ["Domen Tabernik", "Matej Kristan", "Ale\u0161 Leonardis"], "title": "Spatially-Adaptive Filter Units for Compact and Efficient Deep Neural Networks", "url": "http://arxiv.org/pdf/1902.07474v2", "summary": "Convolutional neural networks excel in a number of computer vision tasks. One of their most crucial architectural elements is the effective receptive field size, that has to be manually set to accommodate a specific task. Standard solutions involve large kernels, down/up-sampling and dilated convolutions. These require testing a variety of dilation and down/up-sampling factors and result in non-compact representations and excessive number of parameters. We address this issue by proposing a new convolution filter composed of displaced aggregation units (DAU). DAUs learn spatial displacements and adapt the receptive field sizes of individual convolution filters to a given problem, thus eliminating the need for hand-crafted modifications. DAUs provide a seamless substitution of convolutional filters in existing state-of-the-art architectures, which we demonstrate on AlexNet, ResNet50, ResNet101, DeepLab and SRN-DeblurNet. The benefits of this design are demonstrated on a variety of computer vision tasks and datasets, such as image classification (ILSVRC 2012), semantic segmentation (PASCAL VOC 2011, Cityscape) and blind image de-blurring (GOPRO). Results show that DAUs efficiently allocate parameters resulting in up to four times more compact networks at similar or better performance.", "published": "2019-02-20T09:49:55Z", "version": 2}, {"aid": "1902.07476", "authors": ["Sercan T\u00fcrkmen", "Janne Heikkil\u00e4"], "title": "An efficient solution for semantic segmentation: ShuffleNet V2 with atrous separable convolutions", "url": "http://arxiv.org/pdf/1902.07476v2", "summary": "Assigning a label to each pixel in an image, namely semantic segmentation, has been an important task in computer vision, and has applications in autonomous driving, robotic navigation, localization, and scene understanding. Fully convolutional neural networks have proved to be a successful solution for the task over the years but most of the work being done focuses primarily on accuracy. In this paper, we present a computationally efficient approach to semantic segmentation, while achieving a high mean intersection over union (mIOU), 70.33% on Cityscapes challenge. The network proposed is capable of running real-time on mobile devices. In addition, we make our code and model weights publicly available.", "published": "2019-02-20T09:50:47Z", "version": 2}, {"aid": "1902.07656", "authors": ["Bartosz W\u00f3jcik", "\u0141ukasz Maziarka", "Jacek Tabor"], "title": "LOSSGRAD: automatic learning rate in gradient descent", "url": "http://arxiv.org/pdf/1902.07656v1", "summary": "In this paper, we propose a simple, fast and easy to implement algorithm LOSSGRAD (locally optimal step-size in gradient descent), which automatically modifies the step-size in gradient descent during neural networks training. Given a function $f$, a point $x$, and the gradient $\\nabla_x f$ of $f$, we aim to find the step-size $h$ which is (locally) optimal, i.e. satisfies: $$ h=arg\\,min_{t \\geq 0} f(x-t \\nabla_x f). $$ Making use of quadratic approximation, we show that the algorithm satisfies the above assumption. We experimentally show that our method is insensitive to the choice of initial learning rate while achieving results comparable to other methods.", "published": "2019-02-20T17:11:17Z", "version": 1}, {"aid": "1902.08153", "authors": ["Steven K. Esser", "Jeffrey L. McKinstry", "Deepika Bablani", "Rathinakumar Appuswamy", "Dharmendra S. Modha"], "title": "Learned Step Size Quantization", "url": "http://arxiv.org/pdf/1902.08153v3", "summary": "Deep networks run with low precision operations at inference time offer power and space advantages over high precision alternatives, but need to overcome the challenge of maintaining high accuracy as precision decreases. Here, we present a method for training such networks, Learned Step Size Quantization, that achieves the highest accuracy to date on the ImageNet dataset when using models, from a variety of architectures, with weights and activations quantized to 2-, 3- or 4-bits of precision, and that can train 3-bit models that reach full precision baseline accuracy. Our approach builds upon existing methods for learning weights in quantized networks by improving how the quantizer itself is configured. Specifically, we introduce a novel means to estimate and scale the task loss gradient at each weight and activation layer's quantizer step size, such that it can be learned in conjunction with other network parameters. This approach works using different levels of precision as needed for a given system and requires only a simple modification of existing training code.", "published": "2019-02-21T17:31:32Z", "version": 3}, {"aid": "1902.08994", "authors": ["S. M. Kamrul Hasan", "Cristian A. Linte"], "title": "U-NetPlus: A Modified Encoder-Decoder U-Net Architecture for Semantic and Instance Segmentation of Surgical Instrument", "url": "http://arxiv.org/pdf/1902.08994v1", "summary": "Conventional therapy approaches limit surgeons' dexterity control due to limited field-of-view. With the advent of robot-assisted surgery, there has been a paradigm shift in medical technology for minimally invasive surgery. However, it is very challenging to track the position of the surgical instruments in a surgical scene, and accurate detection & identification of surgical tools is paramount. Deep learning-based semantic segmentation in frames of surgery videos has the potential to facilitate this task. In this work, we modify the U-Net architecture named U-NetPlus, by introducing a pre-trained encoder and re-design the decoder part, by replacing the transposed convolution operation with an upsampling operation based on nearest-neighbor (NN) interpolation. To further improve performance, we also employ a very fast and flexible data augmentation technique. We trained the framework on 8 x 225 frame sequences of robotic surgical videos, available through the MICCAI 2017 EndoVis Challenge dataset and tested it on 8 x 75 frame and 2 x 300 frame videos. Using our U-NetPlus architecture, we report a 90.20% DICE for binary segmentation, 76.26% DICE for instrument part segmentation, and 46.07% for instrument type (i.e., all instruments) segmentation, outperforming the results of previous techniques implemented and tested on these data.", "published": "2019-02-24T18:57:19Z", "version": 1}, {"aid": "1902.09782", "authors": ["Qingyan Duan", "Lei Zhang"], "title": "BoostGAN for Occlusive Profile Face Frontalization and Recognition", "url": "http://arxiv.org/pdf/1902.09782v1", "summary": "There are many facts affecting human face recognition, such as pose, occlusion, illumination, age, etc. First and foremost are large pose and occlusion problems, which can even result in more than 10% performance degradation. Pose-invariant feature representation and face frontalization with generative adversarial networks (GAN) have been widely used to solve the pose problem. However, the synthesis and recognition of occlusive but profile faces is still an uninvestigated problem. To address this issue, in this paper, we aim to contribute an effective solution on how to recognize occlusive but profile faces, even with facial keypoint region (e.g. eyes, nose, etc.) corrupted. Specifically, we propose a boosting Generative Adversarial Network (BoostGAN) for de-occlusion, frontalization, and recognition of faces. Upon the assumption that facial occlusion is partial and incomplete, multiple patch occluded images are fed as inputs for knowledge boosting, such as identity and texture information. A new aggregation structure composed of a deep GAN for coarse face synthesis and a shallow boosting net for fine face generation is further designed. Exhaustive experiments demonstrate that the proposed approach not only presents clear perceptual photo-realistic results but also shows state-of-the-art recognition performance for occlusive but profile faces.", "published": "2019-02-26T07:59:47Z", "version": 1}, {"aid": "1902.09992", "authors": ["Javier Garcia-Barcos", "Ruben Martinez-Cantin"], "title": "Fully Distributed Bayesian Optimization with Stochastic Policies", "url": "http://arxiv.org/pdf/1902.09992v2", "summary": "Bayesian optimization has become a popular method for high-throughput computing, like the design of computer experiments or hyperparameter tuning of expensive models, where sample efficiency is mandatory. In these applications, distributed and scalable architectures are a necessity. However, Bayesian optimization is mostly sequential. Even parallel variants require certain computations between samples, limiting the parallelization bandwidth. Thompson sampling has been previously applied for distributed Bayesian optimization. But, when compared with other acquisition functions in the sequential setting, Thompson sampling is known to perform suboptimally. In this paper, we present a new method for fully distributed Bayesian optimization, which can be combined with any acquisition function. Our approach considers Bayesian optimization as a partially observable Markov decision process. In this context, stochastic policies, such as the Boltzmann policy, have some interesting properties which can also be studied for Bayesian optimization. Furthermore, the Boltzmann policy trivially allows a distributed Bayesian optimization implementation with high level of parallelism and scalability. We present results in several benchmarks and applications that shows the performance of our method.", "published": "2019-02-26T15:13:17Z", "version": 2}, {"aid": "1902.10658", "authors": ["Baihan Lin"], "title": "Regularity Normalization: Neuroscience-Inspired Unsupervised Attention across Neural Network Layers", "url": "http://arxiv.org/pdf/1902.10658v13", "summary": "Inspired by the adaptation phenomenon of neuronal firing, we propose the regularity normalization (RN) as an unsupervised attention mechanism (UAM) which computes the statistical regularity in the implicit space of neural networks under the Minimum Description Length (MDL) principle. Treating the neural network optimization process as a partially observable model selection problem, the regularity normalization constrains the implicit space by a normalization factor, the universal code length. We compute this universal code incrementally across neural network layers and demonstrate the flexibility to include data priors such as top-down attention and other oracle information. Empirically, our approach outperforms existing normalization methods in tackling limited, imbalanced and non-stationary input distribution in image classification, classic control, procedurally-generated reinforcement learning, generative modeling, handwriting generation and question answering tasks with various neural network architectures. Lastly, the unsupervised attention mechanisms is a useful probing tool for neural networks by tracking the dependency and critical learning stages across layers and recurrent time steps of deep networks.", "published": "2019-02-27T17:44:50Z", "version": 13}, {"aid": "1902.10747", "authors": ["Mikael Brudfors", "Ya\u00ebl Balbastre", "John Ashburner"], "title": "Nonlinear Markov Random Fields Learned via Backpropagation", "url": "http://arxiv.org/pdf/1902.10747v2", "summary": "Although convolutional neural networks (CNNs) currently dominate competitions on image segmentation, for neuroimaging analysis tasks, more classical generative approaches based on mixture models are still used in practice to parcellate brains. To bridge the gap between the two, in this paper we propose a marriage between a probabilistic generative model, which has been shown to be robust to variability among magnetic resonance (MR) images acquired via different imaging protocols, and a CNN. The link is in the prior distribution over the unknown tissue classes, which are classically modelled using a Markov random field. In this work we model the interactions among neighbouring pixels by a type of recurrent CNN, which can encode more complex spatial interactions. We validate our proposed model on publicly available MR data, from different centres, and show that it generalises across imaging protocols. This result demonstrates a successful and principled inclusion of a CNN in a generative model, which in turn could be adapted by any probabilistic generative approach for image segmentation.", "published": "2019-02-27T19:34:22Z", "version": 2}, {"aid": "1902.10949", "authors": ["Yingcheng Su", "Shunfeng Zhou", "Yichao Wu", "Tian Su", "Ding Liang", "Jiaheng Liu", "Dixin Zheng", "Yingxu Wang", "Junjie Yan", "Xiaolin Hu"], "title": "Dynamic Multi-path Neural Network", "url": "http://arxiv.org/pdf/1902.10949v3", "summary": "Although deeper and larger neural networks have achieved better performance, the complex network structure and increasing computational cost cannot meet the demands of many resource-constrained applications. Existing methods usually choose to execute or skip an entire specific layer, which can only alter the depth of the network. In this paper, we propose a novel method called Dynamic Multi-path Neural Network (DMNN), which provides more path selection choices in terms of network width and depth during inference. The inference path of the network is determined by a controller, which takes into account both previous state and object category information. The proposed method can be easily incorporated into most modern network architectures. Experimental results on ImageNet and CIFAR-100 demonstrate the superiority of our method on both efficiency and overall classification accuracy. To be specific, DMNN-101 significantly outperforms ResNet-101 with an encouraging 45.1% FLOPs reduction, and DMNN-50 performs comparably to ResNet-101 while saving 42.1% parameters.", "published": "2019-02-28T08:48:18Z", "version": 3}, {"aid": "1903.00840", "authors": ["Amir Zadeh", "Yao-Chong Lim", "Paul Pu Liang", "Louis-Philippe Morency"], "title": "Variational Auto-Decoder: A Method for Neural Generative Modeling from Incomplete Data", "url": "http://arxiv.org/pdf/1903.00840v6", "summary": "Learning a generative model from partial data (data with missingness) is a challenging area of machine learning research. We study a specific implementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named in this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework which uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to learn a generative model from partial data. The main distinction between VAD and Variational Auto-Encoder (VAE) is the encoder component, as VAD does not have one. Using a proposed efficient inference method from a multivariate Gaussian approximate posterior, VAD models allow inference to be performed via simple gradient ascent rather than MCMC sampling from a probabilistic decoder. This technique reduces the inference computational cost, allows for using more complex optimization techniques during latent space inference (which are shown to be crucial due to a high degree of freedom in the VAD latent space), and keeps the framework simple to implement. Through extensive experiments over several datasets and different missing ratios, we show that encoders cannot efficiently marginalize the input volatility caused by imputed missing values. We study multimodal datasets in this paper, which is a particular area of impact for VAD models.", "published": "2019-03-03T06:19:55Z", "version": 6}, {"aid": "1903.01003", "authors": ["Ismail Akrout", "Amal Feriani", "Mohamed Akrout"], "title": "Hacking Google reCAPTCHA v3 using Reinforcement Learning", "url": "http://arxiv.org/pdf/1903.01003v3", "summary": "We present a Reinforcement Learning (RL) methodology to bypass Google reCAPTCHA v3. We formulate the problem as a grid world where the agent learns how to move the mouse and click on the reCAPTCHA button to receive a high score. We study the performance of the agent when we vary the cell size of the grid world and show that the performance drops when the agent takes big steps toward the goal. Finally, we used a divide and conquer strategy to defeat the reCAPTCHA system for any grid resolution. Our proposed method achieves a success rate of 97.4% on a 100x100 grid and 96.7% on a 1000x1000 screen resolution.", "published": "2019-03-03T22:10:47Z", "version": 3}, {"aid": "1903.01882", "authors": ["Reuben Feinman", "Brenden M. Lake"], "title": "Learning a smooth kernel regularizer for convolutional neural networks", "url": "http://arxiv.org/pdf/1903.01882v1", "summary": "Modern deep neural networks require a tremendous amount of data to train, often needing hundreds or thousands of labeled examples to learn an effective representation. For these networks to work with less data, more structure must be built into their architectures or learned from previous experience. The learned weights of convolutional neural networks (CNNs) trained on large datasets for object recognition contain a substantial amount of structure. These representations have parallels to simple cells in the primary visual cortex, where receptive fields are smooth and contain many regularities. Incorporating smoothness constraints over the kernel weights of modern CNN architectures is a promising way to improve their sample complexity. We propose a smooth kernel regularizer that encourages spatial correlations in convolution kernel weights. The correlation parameters of this regularizer are learned from previous experience, yielding a method with a hierarchical Bayesian interpretation. We show that our correlated regularizer can help constrain models for visual recognition, improving over an L2 regularization baseline.", "published": "2019-03-05T15:07:29Z", "version": 1}, {"aid": "1903.01931", "authors": ["Jianlin Su"], "title": "O-GAN: Extremely Concise Approach for Auto-Encoding Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1903.01931v1", "summary": "In this paper, we propose Orthogonal Generative Adversarial Networks (O-GANs). We decompose the network of discriminator orthogonally and add an extra loss into the objective of common GANs, which can enforce discriminator become an effective encoder. The same extra loss can be embedded into any kind of GANs and there is almost no increase in computation. Furthermore, we discuss the principle of our method, which is relative to the fully-exploiting of the remaining degrees of freedom of discriminator. As we know, our solution is the simplest approach to train a generative adversarial network with auto-encoding ability.", "published": "2019-03-05T17:01:49Z", "version": 1}, {"aid": "1903.04933", "authors": ["Jeffrey De Fauw", "Sander Dieleman", "Karen Simonyan"], "title": "Hierarchical Autoregressive Image Models with Auxiliary Decoders", "url": "http://arxiv.org/pdf/1903.04933v2", "summary": "Autoregressive generative models of images tend to be biased towards capturing local structure, and as a result they often produce samples which are lacking in terms of large-scale coherence. To address this, we propose two methods to learn discrete representations of images which abstract away local detail. We show that autoregressive models conditioned on these representations can produce high-fidelity reconstructions of images, and that we can train autoregressive priors on these representations that produce samples with large-scale coherence. We can recursively apply the learning procedure, yielding a hierarchy of progressively more abstract image representations. We train hierarchical class-conditional autoregressive models on the ImageNet dataset and demonstrate that they are able to generate realistic images at resolutions of 128$\\times$128 and 256$\\times$256 pixels. We also perform a human evaluation study comparing our models with both adversarial and likelihood-based state-of-the-art generative models.", "published": "2019-03-06T22:13:52Z", "version": 2}, {"aid": "1903.04019", "authors": ["Xiaoguang Han", "Zhaoxuan Zhang", "Dong Du", "Mingdai Yang", "Jingming Yu", "Pan Pan", "Xin Yang", "Ligang Liu", "Zixiang Xiong", "Shuguang Cui"], "title": "Deep Reinforcement Learning of Volume-guided Progressive View Inpainting for 3D Point Scene Completion from a Single Depth Image", "url": "http://arxiv.org/pdf/1903.04019v2", "summary": "We present a deep reinforcement learning method of progressive view inpainting for 3D point scene completion under volume guidance, achieving high-quality scene reconstruction from only a single depth image with severe occlusion. Our approach is end-to-end, consisting of three modules: 3D scene volume reconstruction, 2D depth map inpainting, and multi-view selection for completion. Given a single depth image, our method first goes through the 3D volume branch to obtain a volumetric scene reconstruction as a guide to the next view inpainting step, which attempts to make up the missing information; the third step involves projecting the volume under the same view of the input, concatenating them to complete the current view depth, and integrating all depth into the point cloud. Since the occluded areas are unavailable, we resort to a deep Q-Network to glance around and pick the next best view for large hole completion progressively until a scene is adequately reconstructed while guaranteeing validity. All steps are learned jointly to achieve robust and consistent results. We perform qualitative and quantitative evaluations with extensive experiments on the SUNCG data, obtaining better results than the state of the art.", "published": "2019-03-10T16:25:03Z", "version": 2}, {"aid": "1903.04576", "authors": ["Javier A. Galad\u00ed", "Joaqu\u00edn J. Torres", "J. Marro"], "title": "Emergence of Brain Rhythms: Model Interpretation of EEG Data", "url": "http://arxiv.org/pdf/1903.04576v1", "summary": "Electroencephalography (EEG) monitors ---by either intrusive or noninvasive electrodes--- time and frequency variations and spectral content of voltage fluctuations or waves, known as brain rhythms, which in some way uncover activity during both rest periods and specific events in which the subject is under stimulus. This is a useful tool to explore brain behavior, as it complements imaging techniques that have a poorer temporal resolution. We here approach the understanding of EEG data from first principles by studying a networked model of excitatory and inhibitory neurons which generates a variety of comparable waves. In fact, we thus reproduce $\\alpha$, $\\beta,$ $\\gamma$ and other rhythms as observed by EEG, and identify the details of the respectively involved complex phenomena, including a precise relationship between an input and the collective response to it. It ensues the potentiality of our model to better understand actual mind mechanisms and its possible disorders, and we also describe kind of stochastic resonance phenomena which locate main qualitative changes of mental behavior in (e.g.) humans. We also discuss the plausible use of these findings to design deep learning algorithms to detect the occurence of phase transitions in the brain and to analyse its consequences.", "published": "2019-03-11T20:13:42Z", "version": 1}, {"aid": "1903.04687", "authors": ["Lei Zhang", "Xinbo Gao"], "title": "Transfer Adaptation Learning: A Decade Survey", "url": "http://arxiv.org/pdf/1903.04687v2", "summary": "The world we see is ever-changing and it always changes with people, things, and the environment. Domain is referred to as the state of the world at a certain moment. A research problem is characterized as transfer adaptation learning (TAL) when it needs knowledge correspondence between different moments/domains. Conventional machine learning aims to find a model with the minimum expected risk on test data by minimizing the regularized empirical risk on the training data, which, however, supposes that the training and test data share similar joint probability distribution. TAL aims to build models that can perform tasks of target domain by learning knowledge from a semantic related but distribution different source domain. It is an energetic research filed of increasing influence and importance, which is presenting a blowout publication trend. This paper surveys the advances of TAL methodologies in the past decade, and the technical challenges and essential problems of TAL have been observed and discussed with deep insights and new perspectives. Broader solutions of transfer adaptation learning being created by researchers are identified, i.e., instance re-weighting adaptation, feature adaptation, classifier adaptation, deep network adaptation and adversarial adaptation, which are beyond the early semi-supervised and unsupervised split. The survey helps researchers rapidly but comprehensively understand and identify the research foundation, research status, theoretical limitations, future challenges and under-studied issues (universality, interpretability, and credibility) to be broken in the field toward universal representation and safe applications in open-world scenarios.", "published": "2019-03-12T01:32:59Z", "version": 2}, {"aid": "1903.04711", "authors": ["Wentao Zhu"], "title": "Deep Learning for Automated Medical Image Analysis", "url": "http://arxiv.org/pdf/1903.04711v1", "summary": "Medical imaging is an essential tool in many areas of medical applications, used for both diagnosis and treatment. However, reading medical images and making diagnosis or treatment recommendations require specially trained medical specialists. The current practice of reading medical images is labor-intensive, time-consuming, costly, and error-prone. It would be more desirable to have a computer-aided system that can automatically make diagnosis and treatment recommendations. Recent advances in deep learning enable us to rethink the ways of clinician diagnosis based on medical images. In this thesis, we will introduce 1) mammograms for detecting breast cancers, the most frequently diagnosed solid cancer for U.S. women, 2) lung CT images for detecting lung cancers, the most frequently diagnosed malignant cancer, and 3) head and neck CT images for automated delineation of organs at risk in radiotherapy. First, we will show how to employ the adversarial concept to generate the hard examples improving mammogram mass segmentation. Second, we will demonstrate how to use the weakly labeled data for the mammogram breast cancer diagnosis by efficiently design deep learning for multi-instance learning. Third, the thesis will walk through DeepLung system which combines deep 3D ConvNets and GBM for automated lung nodule detection and classification. Fourth, we will show how to use weakly labeled data to improve existing lung nodule detection system by integrating deep learning with a probabilistic graphic model. Lastly, we will demonstrate the AnatomyNet which is thousands of times faster and more accurate than previous methods on automated anatomy segmentation.", "published": "2019-03-12T03:28:37Z", "version": 1}, {"aid": "1903.04772", "authors": ["Arash Akbarinia", "Karl R. Gegenfurtner"], "title": "Paradox in Deep Neural Networks: Similar yet Different while Different yet Similar", "url": "http://arxiv.org/pdf/1903.04772v1", "summary": "Machine learning is advancing towards a data-science approach, implying a necessity to a line of investigation to divulge the knowledge learnt by deep neuronal networks. Limiting the comparison among networks merely to a predefined intelligent ability, according to ground truth, does not suffice, it should be associated with innate similarity of these artificial entities. Here, we analysed multiple instances of an identical architecture trained to classify objects in static images (CIFAR and ImageNet data sets). We evaluated the performance of the networks under various distortions and compared it to the intrinsic similarity between their constituent kernels. While we expected a close correspondence between these two measures, we observed a puzzling phenomenon. Pairs of networks whose kernels' weights are over 99.9% correlated can exhibit significantly different performances, yet other pairs with no correlation can reach quite compatible levels of performance. We show implications of this for transfer learning, and argue its importance in our general understanding of what intelligence is, whether natural or artificial.", "published": "2019-03-12T08:04:44Z", "version": 1}, {"aid": "1903.06530", "authors": ["Seijoon Kim", "Seongsik Park", "Byunggook Na", "Sungroh Yoon"], "title": "Spiking-YOLO: Spiking Neural Network for Energy-Efficient Object Detection", "url": "http://arxiv.org/pdf/1903.06530v2", "summary": "Over the past decade, deep neural networks (DNNs) have demonstrated remarkable performance in a variety of applications. As we try to solve more advanced problems, increasing demands for computing and power resources has become inevitable. Spiking neural networks (SNNs) have attracted widespread interest as the third-generation of neural networks due to their event-driven and low-powered nature. SNNs, however, are difficult to train, mainly owing to their complex dynamics of neurons and non-differentiable spike operations. Furthermore, their applications have been limited to relatively simple tasks such as image classification. In this study, we investigate the performance degradation of SNNs in a more challenging regression problem (i.e., object detection). Through our in-depth analysis, we introduce two novel methods: channel-wise normalization and signed neuron with imbalanced threshold, both of which provide fast and accurate information transmission for deep SNNs. Consequently, we present a first spiked-based object detection model, called Spiking-YOLO. Our experiments show that Spiking-YOLO achieves remarkable results that are comparable (up to 98%) to those of Tiny YOLO on non-trivial datasets, PASCAL VOC and MS COCO. Furthermore, Spiking-YOLO on a neuromorphic chip consumes approximately 280 times less energy than Tiny YOLO and converges 2.3 to 4 times faster than previous SNN conversion methods.", "published": "2019-03-12T08:34:47Z", "version": 2}, {"aid": "1903.05285", "authors": ["Weijie Chen", "Di Xie", "Yuan Zhang", "Shiliang Pu"], "title": "All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification", "url": "http://arxiv.org/pdf/1903.05285v1", "summary": "Shift operation is an efficient alternative over depthwise separable convolution. However, it is still bottlenecked by its implementation manner, namely memory movement. To put this direction forward, a new and novel basic component named Sparse Shift Layer (SSL) is introduced in this paper to construct efficient convolutional neural networks. In this family of architectures, the basic block is only composed by 1x1 convolutional layers with only a few shift operations applied to the intermediate feature maps. To make this idea feasible, we introduce shift operation penalty during optimization and further propose a quantization-aware shift learning method to impose the learned displacement more friendly for inference. Extensive ablation studies indicate that only a few shift operations are sufficient to provide spatial information communication. Furthermore, to maximize the role of SSL, we redesign an improved network architecture to Fully Exploit the limited capacity of neural Network (FE-Net). Equipped with SSL, this network can achieve 75.0% top-1 accuracy on ImageNet with only 563M M-Adds. It surpasses other counterparts constructed by depthwise separable convolution and the networks searched by NAS in terms of accuracy and practical speed.", "published": "2019-03-13T01:44:39Z", "version": 1}, {"aid": "1903.05359", "authors": ["Jun Long", "WuQing Sun", "Zhan Yang", "Osolo Ian Raymond"], "title": "Asymmetric Residual Neural Network for Accurate Human Activity Recognition", "url": "http://arxiv.org/pdf/1903.05359v3", "summary": "Human Activity Recognition (HAR) using deep neural network has become a hot topic in human-computer interaction. Machine can effectively identify human naturalistic activities by learning from a large collection of sensor data. Activity recognition is not only an interesting research problem, but also has many real-world practical applications. Based on the success of residual networks in achieving a high level of aesthetic representation of the automatic learning, we propose a novel \\textbf{A}symmetric \\textbf{R}esidual \\textbf{N}etwork, named ARN. ARN is implemented using two identical path frameworks consisting of (1) a short time window, which is used to capture spatial features, and (2) a long time window, which is used to capture fine temporal features. The long time window path can be made very lightweight by reducing its channel capacity, yet still being able to learn useful temporal representations for activity recognition. In this paper, we mainly focus on proposing a new model to improve the accuracy of HAR. In order to demonstrate the effectiveness of ARN model, we carried out extensive experiments on benchmark datasets (i.e., OPPORTUNITY, UniMiB-SHAR) and compared with some conventional and state-of-the-art learning-based methods. Then, we discuss the influence of networks parameters on performance to provide insights about its optimization. Results from our experiments show that ARN is effective in recognizing human activities via wearable datasets.", "published": "2019-03-13T08:44:01Z", "version": 3}, {"aid": "1903.05503", "authors": ["Wenzhao Zheng", "Zhaodong Chen", "Jiwen Lu", "Jie Zhou"], "title": "Hardness-Aware Deep Metric Learning", "url": "http://arxiv.org/pdf/1903.05503v2", "summary": "This paper presents a hardness-aware deep metric learning (HDML) framework. Most previous deep metric learning methods employ the hard negative mining strategy to alleviate the lack of informative samples for training. However, this mining strategy only utilizes a subset of training data, which may not be enough to characterize the global geometry of the embedding space comprehensively. To address this problem, we perform linear interpolation on embeddings to adaptively manipulate their hard levels and generate corresponding label-preserving synthetics for recycled training, so that information buried in all samples can be fully exploited and the metric is always challenged with proper difficulty. Our method achieves very competitive performance on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets.", "published": "2019-03-13T14:14:54Z", "version": 2}, {"aid": "1903.05610", "authors": ["Paul Smolen", "Douglas A. Baxter", "John H. Byrne"], "title": "How Can Memories Last for Days, Years, or a Lifetime? Proposed Mechanisms for Maintaining Synaptic Potentiation and Memory", "url": "http://arxiv.org/pdf/1903.05610v3", "summary": "With memory encoding reliant on persistent changes in the properties of synapses, a key question is how can memories be maintained from days to months or a lifetime given molecular turnover? It is likely that positive feedback loops are necessary to persistently maintain the strength of synapses that participate in encoding. Such feedback may occur within signal-transduction cascades and/or the regulation of translation, and it may occur within specific subcellular compartments or within neuronal networks. Not surprisingly, numerous positive feedback loops have been proposed. Some posited loops operate at the level of biochemical signal transduction cascades, such as persistent activation of calcium/calmodulin kinase II or protein kinase M. Another level consists of feedback loops involving transcriptional, epigenetic and translational pathways, and autocrine actions of growth factors such as BDNF. Finally, at the neuronal network level, recurrent reactivation of cell assemblies encoding memories is likely to be essential for late maintenance of memory. These levels are not isolated, but linked by shared components of feedback loops. Here, we review characteristics of some commonly discussed feedback loops proposed to underlie the maintenance of memory and long-term synaptic plasticity, assess evidence for and against their necessity, and suggest experiments that could further delineate the dynamics of these feedback loops. We also discuss crosstalk between proposed loops, and ways in which such interaction can facilitate the rapidity and robustness of memory formation and storage.", "published": "2019-03-13T17:16:52Z", "version": 3}, {"aid": "1903.08066", "authors": ["Sambhav R. Jain", "Albert Gural", "Michael Wu", "Chris H. Dick"], "title": "Trained Quantization Thresholds for Accurate and Efficient Fixed-Point Inference of Deep Neural Networks", "url": "http://arxiv.org/pdf/1903.08066v3", "summary": "We propose a method of training quantization thresholds (TQT) for uniform symmetric quantizers using standard backpropagation and gradient descent. Contrary to prior work, we show that a careful analysis of the straight-through estimator for threshold gradients allows for a natural range-precision trade-off leading to better optima. Our quantizers are constrained to use power-of-2 scale-factors and per-tensor scaling of weights and activations to make it amenable for hardware implementations. We present analytical support for the general robustness of our methods and empirically validate them on various CNNs for ImageNet classification. We are able to achieve near-floating-point accuracy on traditionally difficult networks such as MobileNets with less than 5 epochs of quantized (8-bit) retraining. Finally, we present Graffitist, a framework that enables automatic quantization of TensorFlow graphs for TQT (available at https://github.com/Xilinx/graffitist ).", "published": "2019-03-19T15:50:24Z", "version": 3}, {"aid": "1903.09630", "authors": ["Francesca Arese Lucini", "Gino Del Ferraro", "Mariano Sigman", "Hernan A. Makse"], "title": "How the Brain Transitions from Conscious to Subliminal Perception", "url": "http://arxiv.org/pdf/1903.09630v3", "summary": "We study the transition in the functional networks that characterize the human brains' conscious-state to an unconscious subliminal state of perception by using k-core percolation. We find that the most inner core (i.e., the most connected kernel) of the conscious-state functional network corresponds to areas which remain functionally active when the brain transitions from the conscious-state to the subliminal-state. That is, the inner core of the conscious network coincides with the subliminal-state. Mathematical modeling allows to interpret the conscious to subliminal transition as driven by k-core percolation, through which the conscious state is lost by the inactivation of the peripheral k-shells of the conscious functional network. Thus, the inner core and most robust component of the conscious brain corresponds to the unconscious subliminal state. This finding imposes constraints to theoretical models of consciousness, in that the location of the core of the functional brain network is in the unconscious part of the brain rather than in the conscious state as previously thought.", "published": "2019-03-21T01:09:05Z", "version": 3}, {"aid": "1903.11683", "authors": ["Vasileios Tzoumas", "Pasquale Antonante", "Luca Carlone"], "title": "Outlier-Robust Spatial Perception: Hardness, General-Purpose Algorithms, and Guarantees", "url": "http://arxiv.org/pdf/1903.11683v2", "summary": "Spatial perception is the backbone of many robotics applications, and spans a broad range of research problems, including localization and mapping, point cloud alignment, and relative pose estimation from camera images. Robust spatial perception is jeopardized by the presence of incorrect data association, and in general, outliers. Although techniques to handle outliers do exist, they can fail in unpredictable manners (e.g., RANSAC, robust estimators), or can have exponential runtime (e.g., branch-and-bound). In this paper, we advance the state of the art in outlier rejection by making three contributions. First, we show that even a simple linear instance of outlier rejection is inapproximable: in the worst-case one cannot design a quasi-polynomial time algorithm that computes an approximate solution efficiently. Our second contribution is to provide the first per-instance sub-optimality bounds to assess the approximation quality of a given outlier rejection outcome. Our third contribution is to propose a simple general-purpose algorithm, named adaptive trimming, to remove outliers. Our algorithm leverages recently-proposed global solvers that are able to solve outlier-free problems, and iteratively removes measurements with large errors. We demonstrate the proposed algorithm on three spatial perception problems: 3D registration, two-view geometry, and SLAM. The results show that our algorithm outperforms several state-of-the-art methods across applications while being a general-purpose method.", "published": "2019-03-27T20:12:37Z", "version": 2}, {"aid": "1903.11816", "authors": ["Huikai Wu", "Junge Zhang", "Kaiqi Huang", "Kongming Liang", "Yizhou Yu"], "title": "FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation", "url": "http://arxiv.org/pdf/1903.11816v1", "summary": "Modern approaches for semantic segmentation usually employ dilated convolutions in the backbone to extract high-resolution feature maps, which brings heavy computation complexity and memory footprint. To replace the time and memory consuming dilated convolutions, we propose a novel joint upsampling module named Joint Pyramid Upsampling (JPU) by formulating the task of extracting high-resolution feature maps into a joint upsampling problem. With the proposed JPU, our method reduces the computation complexity by more than three times without performance loss. Experiments show that JPU is superior to other upsampling modules, which can be plugged into many existing approaches to reduce computation complexity and improve performance. By replacing dilated convolutions with the proposed JPU module, our method achieves the state-of-the-art performance in Pascal Context dataset (mIoU of 53.13%) and ADE20K dataset (final score of 0.5584) while running 3 times faster.", "published": "2019-03-28T07:49:36Z", "version": 1}, {"aid": "1903.12152", "authors": ["Yuankai Huo", "Zhoubing Xu", "Yunxi Xiong", "Katherine Aboud", "Prasanna Parvathaneni", "Shunxing Bao", "Camilo Bermudez", "Susan M. Resnick", "Laurie E. Cutting", "Bennett A. Landman"], "title": "3D Whole Brain Segmentation using Spatially Localized Atlas Network Tiles", "url": "http://arxiv.org/pdf/1903.12152v1", "summary": "Detailed whole brain segmentation is an essential quantitative technique, which provides a non-invasive way of measuring brain regions from a structural magnetic resonance imaging (MRI). Recently, deep convolution neural network (CNN) has been applied to whole brain segmentation. However, restricted by current GPU memory, 2D based methods, downsampling based 3D CNN methods, and patch-based high-resolution 3D CNN methods have been the de facto standard solutions. 3D patch-based high resolution methods typically yield superior performance among CNN approaches on detailed whole brain segmentation (>100 labels), however, whose performance are still commonly inferior compared with multi-atlas segmentation methods (MAS) due to the following challenges: (1) a single network is typically used to learn both spatial and contextual information for the patches, (2) limited manually traced whole brain volumes are available (typically less than 50) for training a network. In this work, we propose the spatially localized atlas network tiles (SLANT) method to distribute multiple independent 3D fully convolutional networks (FCN) for high-resolution whole brain segmentation. To address the first challenge, multiple spatially distributed networks were used in the SLANT method, in which each network learned contextual information for a fixed spatial location. To address the second challenge, auxiliary labels on 5111 initially unlabeled scans were created by multi-atlas segmentation for training. Since the method integrated multiple traditional medical image processing methods with deep learning, we developed a containerized pipeline to deploy the end-to-end solution. From the results, the proposed method achieved superior performance compared with multi-atlas segmentation methods, while reducing the computational time from >30 hours to 15 minutes (https://github.com/MASILab/SLANTbrainSeg).", "published": "2019-03-28T17:40:32Z", "version": 1}, {"aid": "1904.00277", "authors": ["Fei Wang", "Stanislav Panev", "Ziyi Dai", "Jinsong Han", "Dong Huang"], "title": "Can WiFi Estimate Person Pose?", "url": "http://arxiv.org/pdf/1904.00277v2", "summary": "WiFi human sensing has achieved great progress in indoor localization, activity classification, etc. Retracing the development of these work, we have a natural question: can WiFi devices work like cameras for vision applications? In this paper We try to answer this question by exploring the ability of WiFi on estimating single person pose. We use a 3-antenna WiFi sender and a 3-antenna receiver to generate WiFi data. Meanwhile, we use a synchronized camera to capture person videos for corresponding keypoint annotations. We further propose a fully convolutional network (FCN), termed WiSPPN, to estimate single person pose from the collected data and annotations. Evaluation on over 80k images (16 sites and 8 persons) replies aforesaid question with a positive answer. Codes have been made publicly available at https://github.com/geekfeiw/WiSPPN.", "published": "2019-03-30T19:50:52Z", "version": 2}, {"aid": "1904.00962", "authors": ["Yang You", "Jing Li", "Sashank Reddi", "Jonathan Hseu", "Sanjiv Kumar", "Srinadh Bhojanapalli", "Xiaodan Song", "James Demmel", "Kurt Keutzer", "Cho-Jui Hsieh"], "title": "Large Batch Optimization for Deep Learning: Training BERT in 76 minutes", "url": "http://arxiv.org/pdf/1904.00962v5", "summary": "Training large deep neural networks on massive datasets is computationally very challenging. There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue. The most prominent algorithm in this line of research is LARS, which by employing layerwise adaptive learning rates trains ResNet on ImageNet in a few minutes. However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks. In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings. Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and ResNet-50 training with very little hyperparameter tuning. In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance. By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes (Table 1). The LAMB implementation is available at https://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py", "published": "2019-04-01T16:53:35Z", "version": 5}, {"aid": "1904.01169", "authors": ["Shang-Hua Gao", "Ming-Ming Cheng", "Kai Zhao", "Xin-Yu Zhang", "Ming-Hsuan Yang", "Philip Torr"], "title": "Res2Net: A New Multi-scale Backbone Architecture", "url": "http://arxiv.org/pdf/1904.01169v3", "summary": "Representing features at multiple scales is of great importance for numerous vision tasks. Recent advances in backbone convolutional neural networks (CNNs) continually demonstrate stronger multi-scale representation ability, leading to consistent performance gains on a wide range of applications. However, most existing methods represent the multi-scale features in a layer-wise manner. In this paper, we propose a novel building block for CNNs, namely Res2Net, by constructing hierarchical residual-like connections within one single residual block. The Res2Net represents multi-scale features at a granular level and increases the range of receptive fields for each network layer. The proposed Res2Net block can be plugged into the state-of-the-art backbone CNN models, e.g., ResNet, ResNeXt, and DLA. We evaluate the Res2Net block on all these models and demonstrate consistent performance gains over baseline models on widely-used datasets, e.g., CIFAR-100 and ImageNet. Further ablation studies and experimental results on representative computer vision tasks, i.e., object detection, class activation mapping, and salient object detection, further verify the superiority of the Res2Net over the state-of-the-art baseline methods. The source code and trained models are available on https://mmcheng.net/res2net/.", "published": "2019-04-02T01:56:34Z", "version": 3}, {"aid": "1904.01186", "authors": ["Hanting Chen", "Yunhe Wang", "Chang Xu", "Zhaohui Yang", "Chuanjian Liu", "Boxin Shi", "Chunjing Xu", "Chao Xu", "Qi Tian"], "title": "Data-Free Learning of Student Networks", "url": "http://arxiv.org/pdf/1904.01186v4", "summary": "Learning portable neural networks is very essential for computer vision for the purpose that pre-trained heavy deep models can be well applied on edge devices such as mobile phones and micro sensors. Most existing deep neural network compression and speed-up methods are very effective for training compact deep models, when we can directly access the training dataset. However, training data for the given deep network are often unavailable due to some practice problems (e.g. privacy, legal issue, and transmission), and the architecture of the given network are also unknown except some interfaces. To this end, we propose a novel framework for training efficient deep neural networks by exploiting generative adversarial networks (GANs). To be specific, the pre-trained teacher networks are regarded as a fixed discriminator and the generator is utilized for derivating training samples which can obtain the maximum response on the discriminator. Then, an efficient network with smaller model size and computational complexity is trained using the generated data and the teacher network, simultaneously. Efficient student networks learned using the proposed Data-Free Learning (DAFL) method achieve 92.22% and 74.47% accuracies using ResNet-18 without any training data on the CIFAR-10 and CIFAR-100 datasets, respectively. Meanwhile, our student network obtains an 80.56% accuracy on the CelebA benchmark.", "published": "2019-04-02T03:00:06Z", "version": 4}, {"aid": "1904.01277", "authors": ["Sa\u00efd Ladjal", "Alasdair Newson", "Chi-Hieu Pham"], "title": "A PCA-like Autoencoder", "url": "http://arxiv.org/pdf/1904.01277v1", "summary": "An autoencoder is a neural network which data projects to and from a lower dimensional latent space, where this data is easier to understand and model. The autoencoder consists of two sub-networks, the encoder and the decoder, which carry out these transformations. The neural network is trained such that the output is as close to the input as possible, the data having gone through an information bottleneck : the latent space. This tool bears significant ressemblance to Principal Component Analysis (PCA), with two main differences. Firstly, the autoencoder is a non-linear transformation, contrary to PCA, which makes the autoencoder more flexible and powerful. Secondly, the axes found by a PCA are orthogonal, and are ordered in terms of the amount of variability which the data presents along these axes. This makes the interpretability of the PCA much greater than that of the autoencoder, which does not have these attributes. Ideally, then, we would like an autoencoder whose latent space consists of independent components, ordered by decreasing importance to the data. In this paper, we propose an algorithm to create such a network. We create an iterative algorithm which progressively increases the size of the latent space, learning a new dimension at each step. Secondly, we propose a covariance loss term to add to the standard autoencoder loss function, as well as a normalisation layer just before the latent space, which encourages the latent space components to be statistically independent. We demonstrate the results of this autoencoder on simple geometric shapes, and find that the algorithm indeed finds a meaningful representation in the latent space. This means that subsequent interpolation in the latent space has meaning with respect to the geometric properties of the images.", "published": "2019-04-02T08:27:52Z", "version": 1}, {"aid": "1904.01318", "authors": ["Christian Rupprecht", "Cyril Ibrahim", "Christopher J. Pal"], "title": "Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents", "url": "http://arxiv.org/pdf/1904.01318v1", "summary": "As deep reinforcement learning driven by visual perception becomes more widely used there is a growing need to better understand and probe the learned agents. Understanding the decision making process and its relationship to visual inputs can be very valuable to identify problems in learned behavior. However, this topic has been relatively under-explored in the research community. In this work we present a method for synthesizing visual inputs of interest for a trained agent. Such inputs or states could be situations in which specific actions are necessary. Further, critical states in which a very high or a very low reward can be achieved are often interesting to understand the situational awareness of the system as they can correspond to risky states. To this end, we learn a generative model over the state space of the environment and use its latent space to optimize a target function for the state of interest. In our experiments we show that this method can generate insights for a variety of environments and reinforcement learning methods. We explore results in the standard Atari benchmark games as well as in an autonomous driving simulator. Based on the efficiency with which we have been able to identify behavioural weaknesses with this technique, we believe this general approach could serve as an important tool for AI safety applications.", "published": "2019-04-02T10:21:23Z", "version": 1}, {"aid": "1904.01326", "authors": ["Thu Nguyen-Phuoc", "Chuan Li", "Lucas Theis", "Christian Richardt", "Yong-Liang Yang"], "title": "HoloGAN: Unsupervised learning of 3D representations from natural images", "url": "http://arxiv.org/pdf/1904.01326v2", "summary": "We propose a novel generative adversarial network (GAN) for the task of unsupervised learning of 3D representations from natural images. Most generative models rely on 2D kernels to generate images and make few assumptions about the 3D world. These models therefore tend to create blurry images or artefacts in tasks that require a strong 3D understanding, such as novel-view synthesis. HoloGAN instead learns a 3D representation of the world, and to render this representation in a realistic manner. Unlike other GANs, HoloGAN provides explicit control over the pose of generated objects through rigid-body transformations of the learnt 3D features. Our experiments show that using explicit 3D features enables HoloGAN to disentangle 3D pose and identity, which is further decomposed into shape and appearance, while still being able to generate images with similar or higher visual quality than other generative models. HoloGAN can be trained end-to-end from unlabelled 2D images only. Particularly, we do not require pose labels, 3D shapes, or multiple views of the same objects. This shows that HoloGAN is the first generative model that learns 3D representations from natural images in an entirely unsupervised manner.", "published": "2019-04-02T10:36:01Z", "version": 2}, {"aid": "1904.01774", "authors": ["Atsuhiro Noguchi", "Tatsuya Harada"], "title": "Image Generation From Small Datasets via Batch Statistics Adaptation", "url": "http://arxiv.org/pdf/1904.01774v4", "summary": "Thanks to the recent development of deep generative models, it is becoming possible to generate high-quality images with both fidelity and diversity. However, the training of such generative models requires a large dataset. To reduce the amount of data required, we propose a new method for transferring prior knowledge of the pre-trained generator, which is trained with a large dataset, to a small dataset in a different domain. Using such prior knowledge, the model can generate images leveraging some common sense that cannot be acquired from a small dataset. In this work, we propose a novel method focusing on the parameters for batch statistics, scale and shift, of the hidden layers in the generator. By training only these parameters in a supervised manner, we achieved stable training of the generator, and our method can generate higher quality images compared to previous methods without collapsing, even when the dataset is small (~100). Our results show that the diversity of the filters acquired in the pre-trained generator is important for the performance on the target domain. Our method makes it possible to add a new class or domain to a pre-trained generator without disturbing the performance on the original domain.", "published": "2019-04-03T05:24:02Z", "version": 4}, {"aid": "1904.01777", "authors": ["Heng Wang", "Mingzhi Mao"], "title": "Defeats GAN: A Simpler Model Outperforms in Knowledge Representation Learning", "url": "http://arxiv.org/pdf/1904.01777v1", "summary": "The goal of knowledge representation learning is to embed entities and relations into a low-dimensional, continuous vector space. How to push a model to its limit and obtain better results is of great significance in knowledge graph's applications. We propose a simple and elegant method, Trans-DLR, whose main idea is dynamic learning rate control during training. Our method achieves remarkable improvement, compared with recent GAN-based method. Moreover, we introduce a new negative sampling trick which corrupts not only entities, but also relations, in different probabilities. We also develop an efficient way, which fully utilizes multiprocessing and parallel computing, to speed up evaluation of the model in link prediction tasks. Experiments show that our method is effective.", "published": "2019-04-03T05:42:14Z", "version": 1}, {"aid": "1904.01786", "authors": ["Shichen Liu", "Tianye Li", "Weikai Chen", "Hao Li"], "title": "Soft Rasterizer: A Differentiable Renderer for Image-based 3D Reasoning", "url": "http://arxiv.org/pdf/1904.01786v1", "summary": "Rendering bridges the gap between 2D vision and 3D scenes by simulating the physical process of image formation. By inverting such renderer, one can think of a learning approach to infer 3D information from 2D images. However, standard graphics renderers involve a fundamental discretization step called rasterization, which prevents the rendering process to be differentiable, hence able to be learned. Unlike the state-of-the-art differentiable renderers, which only approximate the rendering gradient in the back propagation, we propose a truly differentiable rendering framework that is able to (1) directly render colorized mesh using differentiable functions and (2) back-propagate efficient supervision signals to mesh vertices and their attributes from various forms of image representations, including silhouette, shading and color images. The key to our framework is a novel formulation that views rendering as an aggregation function that fuses the probabilistic contributions of all mesh triangles with respect to the rendered pixels. Such formulation enables our framework to flow gradients to the occluded and far-range vertices, which cannot be achieved by the previous state-of-the-arts. We show that by using the proposed renderer, one can achieve significant improvement in 3D unsupervised single-view reconstruction both qualitatively and quantitatively. Experiments also demonstrate that our approach is able to handle the challenging tasks in image-based shape fitting, which remain nontrivial to existing differentiable renderers.", "published": "2019-04-03T06:06:43Z", "version": 1}, {"aid": "1904.02021", "authors": ["James Smith", "Cameron Taylor", "Seth Baer", "Constantine Dovrolis"], "title": "Unsupervised Progressive Learning and the STAM Architecture", "url": "http://arxiv.org/pdf/1904.02021v6", "summary": "We first pose the Unsupervised Progressive Learning (UPL) problem: an online representation learning problem in which the learner observes a non-stationary and unlabeled data stream, learning a growing number of features that persist over time even though the data is not stored or replayed. To solve the UPL problem we propose the Self-Taught Associative Memory (STAM) architecture. Layered hierarchies of STAM modules learn based on a combination of online clustering, novelty detection, forgetting outliers, and storing only prototypical features rather than specific examples. We evaluate STAM representations using clustering and classification tasks. While there are no existing learning scenarios that are directly comparable to UPL, we compare the STAM architecture with two recent continual learning models, Memory Aware Synapses (MAS) and Gradient Episodic Memories (GEM), after adapting them in the UPL setting.", "published": "2019-04-03T14:25:08Z", "version": 6}, {"aid": "1904.02063", "authors": ["Jeremias Knoblauch", "Jack Jewson", "Theodoros Damoulas"], "title": "Generalized Variational Inference: Three arguments for deriving new Posteriors", "url": "http://arxiv.org/pdf/1904.02063v4", "summary": "We advocate an optimization-centric view on and introduce a novel generalization of Bayesian inference. Our inspiration is the representation of Bayes' rule as infinite-dimensional optimization problem (Csiszar, 1975; Donsker and Varadhan; 1975, Zellner; 1988). First, we use it to prove an optimality result of standard Variational Inference (VI): Under the proposed view, the standard Evidence Lower Bound (ELBO) maximizing VI posterior is preferable to alternative approximations of the Bayesian posterior. Next, we argue for generalizing standard Bayesian inference. The need for this arises in situations of severe misalignment between reality and three assumptions underlying standard Bayesian inference: (1) Well-specified priors, (2) well-specified likelihoods, (3) the availability of infinite computing power. Our generalization addresses these shortcomings with three arguments and is called the Rule of Three (RoT). We derive it axiomatically and recover existing posteriors as special cases, including the Bayesian posterior and its approximation by standard VI. In contrast, approximations based on alternative ELBO-like objectives violate the axioms. Finally, we study a special case of the RoT that we call Generalized Variational Inference (GVI). GVI posteriors are a large and tractable family of belief distributions specified by three arguments: A loss, a divergence and a variational family. GVI posteriors have appealing properties, including consistency and an interpretation as approximate ELBO. The last part of the paper explores some attractive applications of GVI in popular machine learning models, including robustness and more appropriate marginals. After deriving black box inference schemes for GVI posteriors, their predictive performance is investigated on Bayesian Neural Networks and Deep Gaussian Processes, where GVI can comprehensively improve upon existing methods.", "published": "2019-04-03T15:31:46Z", "version": 4}, {"aid": "1904.02323", "authors": ["Fred Hohman", "Haekyu Park", "Caleb Robinson", "Duen Horng Chau"], "title": "Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations", "url": "http://arxiv.org/pdf/1904.02323v3", "summary": "Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.", "published": "2019-04-04T03:00:40Z", "version": 3}, {"aid": "1904.05677", "authors": ["Muhammad Haris", "Greg Shakhnarovich", "Norimichi Ukita"], "title": "Deep Back-Projection Networks for Single Image Super-resolution", "url": "http://arxiv.org/pdf/1904.05677v2", "summary": "Previous feed-forward architectures of recently proposed deep super-resolution networks learn the features of low-resolution inputs and the non-linear mapping from those to a high-resolution output. However, this approach does not fully address the mutual dependencies of low- and high-resolution images. We propose Deep Back-Projection Networks (DBPN), the winner of two image super-resolution challenges (NTIRE2018 and PIRM2018), that exploit iterative up- and down-sampling layers. These layers are formed as a unit providing an error feedback mechanism for projection errors. We construct mutually-connected up- and down-sampling units each of which represents different types of low- and high-resolution components. We also show that extending this idea to demonstrate a new insight towards more efficient network design substantially, such as parameter sharing on the projection module and transition layer on projection step. The experimental results yield superior results and in particular establishing new state-of-the-art results across multiple data sets, especially for large scaling factors such as 8x.", "published": "2019-04-04T05:32:53Z", "version": 2}, {"aid": "1904.02358", "authors": ["Chaofeng Wang", "Zheng Li", "Jun Shi"], "title": "Lightweight Image Super-Resolution with Adaptive Weighted Learning Network", "url": "http://arxiv.org/pdf/1904.02358v1", "summary": "Deep learning has been successfully applied to the single-image super-resolution (SISR) task with great performance in recent years. However, most convolutional neural network based SR models require heavy computation, which limit their real-world applications. In this work, a lightweight SR network, named Adaptive Weighted Super-Resolution Network (AWSRN), is proposed for SISR to address this issue. A novel local fusion block (LFB) is designed in AWSRN for efficient residual learning, which consists of stacked adaptive weighted residual units (AWRU) and a local residual fusion unit (LRFU). Moreover, an adaptive weighted multi-scale (AWMS) module is proposed to make full use of features in reconstruction layer. AWMS consists of several different scale convolutions, and the redundancy scale branch can be removed according to the contribution of adaptive weights in AWMS for lightweight network. The experimental results on the commonly used datasets show that the proposed lightweight AWSRN achieves superior performance on x2, x3, x4, and x8 scale factors to state-of-the-art methods with similar parameters and computational overhead. Code is avaliable at: https://github.com/ChaofWang/AWSRN", "published": "2019-04-04T05:44:32Z", "version": 1}, {"aid": "1904.02375", "authors": ["Alexandre Boulch"], "title": "ConvPoint: Continuous Convolutions for Point Cloud Processing", "url": "http://arxiv.org/pdf/1904.02375v5", "summary": "Point clouds are unstructured and unordered data, as opposed to images. Thus, most machine learning approach developed for image cannot be directly transferred to point clouds. In this paper, we propose a generalization of discrete convolutional neural networks (CNNs) in order to deal with point clouds by replacing discrete kernels by continuous ones. This formulation is simple, allows arbitrary point cloud sizes and can easily be used for designing neural networks similarly to 2D CNNs. We present experimental results with various architectures, highlighting the flexibility of the proposed approach. We obtain competitive results compared to the state-of-the-art on shape classification, part segmentation and semantic segmentation for large-scale point clouds.", "published": "2019-04-04T06:51:56Z", "version": 5}, {"aid": "1904.02639", "authors": ["Dong Gong", "Lingqiao Liu", "Vuong Le", "Budhaditya Saha", "Moussa Reda Mansour", "Svetha Venkatesh", "Anton van den Hengel"], "title": "Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection", "url": "http://arxiv.org/pdf/1904.02639v2", "summary": "Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder \"generalizes\" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.", "published": "2019-04-04T16:16:50Z", "version": 2}, {"aid": "1904.02675", "authors": ["Wu Jionghao"], "title": "UU-Nets Connecting Discriminator and Generator for Image to Image Translation", "url": "http://arxiv.org/pdf/1904.02675v1", "summary": "Adversarial generative model have successfully manifest itself in image synthesis. However, the performance deteriorate and unstable, because discriminator is far stable than generator, and it is hard to control the game between the two modules. Various methods have been introduced to tackle the problem such as WGAN, Relativistic GAN and their successors by adding or restricting the loss function, which certainly help balance the min-max game, but they all focused on the loss function ignoring the intrinsic structure limitation. We present a UU-Net architecture inspired by U-net bridging the encoder and the decoder, UU-Net composed by two U-Net liked modules respectively served as generator and discriminator. Because the modules in U-net are symmetrical, therefore it shares weights easily between all four components. Thanks to UU-net's modules identical and symmetric property, we could not only carried the features from inner generator's encoder to its decoder, but also to the discriminator's encoder and decoder. By this design, it give us more control and condition flexibility to intervene the process between the generator and the discriminator.", "published": "2019-04-04T17:25:21Z", "version": 1}, {"aid": "1904.02698", "authors": ["Jean Kossaifi", "Adrian Bulat", "Georgios Tzimiropoulos", "Maja Pantic"], "title": "T-Net: Parametrizing Fully Convolutional Nets with a Single High-Order Tensor", "url": "http://arxiv.org/pdf/1904.02698v1", "summary": "Recent findings indicate that over-parametrization, while crucial for successfully training deep neural networks, also introduces large amounts of redundancy. Tensor methods have the potential to efficiently parametrize over-complete representations by leveraging this redundancy. In this paper, we propose to fully parametrize Convolutional Neural Networks (CNNs) with a single high-order, low-rank tensor. Previous works on network tensorization have focused on parametrizing individual layers (convolutional or fully connected) only, and perform the tensorization layer-by-layer separately. In contrast, we propose to jointly capture the full structure of a neural network by parametrizing it with a single high-order tensor, the modes of which represent each of the architectural design parameters of the network (e.g. number of convolutional blocks, depth, number of stacks, input features, etc). This parametrization allows to regularize the whole network and drastically reduce the number of parameters. Our model is end-to-end trainable and the low-rank structure imposed on the weight tensor acts as an implicit regularization. We study the case of networks with rich structure, namely Fully Convolutional Networks (FCNs), which we propose to parametrize with a single 8th-order tensor. We show that our approach can achieve superior performance with small compression rates, and attain high compression rates with negligible drop in accuracy for the challenging task of human pose estimation.", "published": "2019-04-04T17:55:37Z", "version": 1}, {"aid": "1904.02741", "authors": ["David Berga", "Xavier Otazu"], "title": "Modeling Bottom-Up and Top-Down Attention with a Neurodynamic Model of V1", "url": "http://arxiv.org/pdf/1904.02741v3", "summary": "Previous studies suggested that lateral interactions of V1 cells are responsible, among other visual effects, of bottom-up visual attention (alternatively named visual salience or saliency). Our objective is to mimic these connections with a neurodynamic network of firing-rate neurons in order to predict visual attention. Early visual subcortical processes (i.e. retinal and thalamic) are functionally simulated. An implementation of the cortical magnification function is included to define the retinotopical projections towards V1, processing neuronal activity for each distinct view during scene observation. Novel computational definitions of top-down inhibition (in terms of inhibition of return and selection mechanisms), are also proposed to predict attention in Free-Viewing and Visual Search tasks. Results show that our model outpeforms other biologically-inpired models of saliency prediction while predicting visual saccade sequences with the same model. We also show how temporal and spatial characteristics of inhibition of return can improve prediction of saccades, as well as how distinct search strategies (in terms of feature-selective or category-specific inhibition) can predict attention at distinct image contexts.", "published": "2019-04-04T18:33:15Z", "version": 3}, {"aid": "1904.03092", "authors": ["Jie Hao", "Xing Wang", "Baosong Yang", "Longyue Wang", "Jinfeng Zhang", "Zhaopeng Tu"], "title": "Modeling Recurrence for Transformer", "url": "http://arxiv.org/pdf/1904.03092v1", "summary": "Recently, the Transformer model that is based solely on attention mechanisms, has advanced the state-of-the-art on various machine translation tasks. However, recent studies reveal that the lack of recurrence hinders its further improvement of translation capacity. In response to this problem, we propose to directly model recurrence for Transformer with an additional recurrence encoder. In addition to the standard recurrent neural network, we introduce a novel attentive recurrent network to leverage the strengths of both attention and recurrent networks. Experimental results on the widely-used WMT14 English-German and WMT17 Chinese-English translation tasks demonstrate the effectiveness of the proposed approach. Our studies also reveal that the proposed model benefits from a short-cut that bridges the source and target sequences with a single recurrent layer, which outperforms its deep counterpart.", "published": "2019-04-05T14:40:22Z", "version": 1}, {"aid": "1904.03107", "authors": ["Baosong Yang", "Longyue Wang", "Derek Wong", "Lidia S. Chao", "Zhaopeng Tu"], "title": "Convolutional Self-Attention Networks", "url": "http://arxiv.org/pdf/1904.03107v1", "summary": "Self-attention networks (SANs) have drawn increasing interest due to their high parallelization in computation and flexibility in modeling dependencies. SANs can be further enhanced with multi-head attention by allowing the model to attend to information from different representation subspaces. In this work, we propose novel convolutional self-attention networks, which offer SANs the abilities to 1) strengthen dependencies among neighboring elements, and 2) model the interaction between features extracted by multiple attention heads. Experimental results of machine translation on different language pairs and model settings show that our approach outperforms both the strong Transformer baseline and other existing models on enhancing the locality of SANs. Comparing with prior studies, the proposed model is parameter free in terms of introducing no more parameters.", "published": "2019-04-05T15:02:26Z", "version": 1}, {"aid": "1904.03392", "authors": ["Shaofeng Cai", "Yao Shu", "Gang Chen", "Beng Chin Ooi", "Wei Wang", "Meihui Zhang"], "title": "Effective and Efficient Dropout for Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1904.03392v5", "summary": "Convolutional Neural networks (CNNs) based applications have become ubiquitous, where proper regularization is greatly needed. To prevent large neural network models from overfitting, dropout has been widely used as an efficient regularization technique in practice. However, many recent works show that the standard dropout is ineffective or even detrimental to the training of CNNs. In this paper, we revisit this issue and examine various dropout variants in an attempt to improve existing dropout-based regularization techniques for CNNs. We attribute the failure of standard dropout to the conflict between the stochasticity of dropout and its following Batch Normalization (BN), and propose to reduce the conflict by placing dropout operations right before the convolutional operation instead of BN, or totally address this issue by replacing BN with Group Normalization (GN). We further introduce a structurally more suited dropout variant Drop-Conv2d, which provides more efficient and effective regularization for deep CNNs. These dropout variants can be readily integrated into the building blocks of CNNs and implemented in existing deep learning platforms. Extensive experiments on benchmark datasets including CIFAR, SVHN and ImageNet are conducted to compare the existing building blocks and the proposed ones with dropout training. Results show that our building blocks improve over state-of-the-art CNNs significantly, which is mainly due to the better regularization and implicit model ensemble effect.", "published": "2019-04-06T09:17:51Z", "version": 5}, {"aid": "1904.03441", "authors": ["Lei Huang", "Yi Zhou", "Fan Zhu", "Li Liu", "Ling Shao"], "title": "Iterative Normalization: Beyond Standardization towards Efficient Whitening", "url": "http://arxiv.org/pdf/1904.03441v1", "summary": "Batch Normalization (BN) is ubiquitously employed for accelerating neural network training and improving the generalization capability by performing standardization within mini-batches. Decorrelated Batch Normalization (DBN) further boosts the above effectiveness by whitening. However, DBN relies heavily on either a large batch size, or eigen-decomposition that suffers from poor efficiency on GPUs. We propose Iterative Normalization (IterNorm), which employs Newton's iterations for much more efficient whitening, while simultaneously avoiding the eigen-decomposition. Furthermore, we develop a comprehensive study to show IterNorm has better trade-off between optimization and generalization, with theoretical and experimental support. To this end, we exclusively introduce Stochastic Normalization Disturbance (SND), which measures the inherent stochastic uncertainty of samples when applied to normalization operations. With the support of SND, we provide natural explanations to several phenomena from the perspective of optimization, e.g., why group-wise whitening of DBN generally outperforms full-whitening and why the accuracy of BN degenerates with reduced batch sizes. We demonstrate the consistently improved performance of IterNorm with extensive experiments on CIFAR-10 and ImageNet over BN and DBN.", "published": "2019-04-06T13:10:20Z", "version": 1}, {"aid": "1904.03525", "authors": ["Yuxiang Zhou", "Jiankang Deng", "Irene Kotsia", "Stefanos Zafeiriou"], "title": "Dense 3D Face Decoding over 2500FPS: Joint Texture & Shape Convolutional Mesh Decoders", "url": "http://arxiv.org/pdf/1904.03525v1", "summary": "3D Morphable Models (3DMMs) are statistical models that represent facial texture and shape variations using a set of linear bases and more particular Principal Component Analysis (PCA). 3DMMs were used as statistical priors for reconstructing 3D faces from images by solving non-linear least square optimization problems. Recently, 3DMMs were used as generative models for training non-linear mappings (\\ie, regressors) from image to the parameters of the models via Deep Convolutional Neural Networks (DCNNs). Nevertheless, all of the above methods use either fully connected layers or 2D convolutions on parametric unwrapped UV spaces leading to large networks with many parameters. In this paper, we present the first, to the best of our knowledge, non-linear 3DMMs by learning joint texture and shape auto-encoders using direct mesh convolutions. We demonstrate how these auto-encoders can be used to train very light-weight models that perform Coloured Mesh Decoding (CMD) in-the-wild at a speed of over 2500 FPS.", "published": "2019-04-06T20:22:53Z", "version": 1}, {"aid": "1904.03751", "authors": ["Guohao Li", "Matthias M\u00fcller", "Ali Thabet", "Bernard Ghanem"], "title": "DeepGCNs: Can GCNs Go as Deep as CNNs?", "url": "http://arxiv.org/pdf/1904.03751v2", "summary": "Convolutional Neural Networks (CNNs) achieve impressive performance in a wide variety of fields. Their success benefited from a massive boost when very deep CNN models were able to be reliably trained. Despite their merits, CNNs fail to properly address problems with non-Euclidean data. To overcome this challenge, Graph Convolutional Networks (GCNs) build graphs to represent non-Euclidean data, borrow concepts from CNNs, and apply them in training. GCNs show promising results, but they are usually limited to very shallow models due to the vanishing gradient problem. As a result, most state-of-the-art GCN models are no deeper than 3 or 4 layers. In this work, we present new ways to successfully train very deep GCNs. We do this by borrowing concepts from CNNs, specifically residual/dense connections and dilated convolutions, and adapting them to GCN architectures. Extensive experiments show the positive effect of these deep GCN frameworks. Finally, we use these new concepts to build a very deep 56-layer GCN, and show how it significantly boosts performance (+3.7% mIoU over state-of-the-art) in the task of point cloud semantic segmentation. We believe that the community can greatly benefit from this work, as it opens up many opportunities for advancing GCN-based research.", "published": "2019-04-07T21:49:26Z", "version": 2}, {"aid": "1904.03955", "authors": ["Chen Wang", "Jianfei Yang", "Lihua Xie", "Junsong Yuan"], "title": "Kervolutional Neural Networks", "url": "http://arxiv.org/pdf/1904.03955v2", "summary": "Convolutional neural networks (CNNs) have enabled the state-of-the-art performance in many computer vision tasks. However, little effort has been devoted to establishing convolution in non-linear space. Existing works mainly leverage on the activation layers, which can only provide point-wise non-linearity. To solve this problem, a new operation, kervolution (kernel convolution), is introduced to approximate complex behaviors of human perception systems leveraging on the kernel trick. It generalizes convolution, enhances the model capacity, and captures higher order interactions of features, via patch-wise kernel functions, but without introducing additional parameters. Extensive experiments show that kervolutional neural networks (KNN) achieve higher accuracy and faster convergence than baseline CNN.", "published": "2019-04-08T11:10:51Z", "version": 2}, {"aid": "1904.04015", "authors": ["Maxime Chabance", "Gr\u00e9goire Cattan", "Bastien Maureille"], "title": "Implementation of a Daemon for OpenBCI", "url": "http://arxiv.org/pdf/1904.04015v1", "summary": "This document describes a technical study of the electroencephalographic (EEG) headset OpenBCI (New York, US). In comparison to research grade EEG, the OpenBCI headset is affordable thus suitable for the general public use. In this study we designed a daemon, that is, a background and continuous task communicating with the headset, acquiring, filtering and analyzing the EEG data. This study was promoted by the IHMTEK Company (Vienne, France) in 2016 within a thesis on the integration of EEG-based brain-computer interfaces in virtual reality for the general public.", "published": "2019-04-08T12:45:51Z", "version": 1}, {"aid": "1904.04579", "authors": ["Kieran Greer"], "title": "A Concept-Value Network as a Brain Model", "url": "http://arxiv.org/pdf/1904.04579v6", "summary": "This paper suggests a statistical framework for describing the relations between the physical and conceptual entities of a brain-like model. Features and concept instances are put into context, where the paper suggests that features may be the electrical wiring, although chemical connections are also possible. With this idea, the actual length of the connection is important, because it is related to firing rates and neuron synchronization, but the signal type is less important. The paper then suggests that concepts are neuron groups that link feature sets and concept instances are determined by chemical signals from those groups. Therefore, features become the static horizontal framework of the neural system and concepts are vertically interconnected combinations of these. With regards to functionality, the neuron is then considered to be functional and the more horizontal memory structures can even be glial. This would also suggest that features can be distributed entities and not concentrated to a single area. Another aspect could be signal 'breaks' that compartmentalise a pattern and may help with neural binding.", "published": "2019-04-09T10:30:23Z", "version": 6}, {"aid": "1904.04862", "authors": ["Mojan Javaheripi", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "title": "SWNet: Small-World Neural Networks and Rapid Convergence", "url": "http://arxiv.org/pdf/1904.04862v1", "summary": "Training large and highly accurate deep learning (DL) models is computationally costly. This cost is in great part due to the excessive number of trained parameters, which are well-known to be redundant and compressible for the execution phase. This paper proposes a novel transformation which changes the topology of the DL architecture such that it reaches an optimal cross-layer connectivity. This transformation leverages our important observation that for a set level of accuracy, convergence is fastest when network topology reaches the boundary of a Small-World Network. Small-world graphs are known to possess a specific connectivity structure that enables enhanced signal propagation among nodes. Our small-world models, called SWNets, provide several intriguing benefits: they facilitate data (gradient) flow within the network, enable feature-map reuse by adding long-range connections and accommodate various network architectures/datasets. Compared to densely connected networks (e.g., DenseNets), SWNets require a substantially fewer number of training parameters while maintaining a similar level of classification accuracy. We evaluate our networks on various DL model architectures and image classification datasets, namely, CIFAR10, CIFAR100, and ILSVRC (ImageNet). Our experiments demonstrate an average of ~2.1x improvement in convergence speed to the desired accuracy", "published": "2019-04-09T18:41:26Z", "version": 1}, {"aid": "1904.05019", "authors": ["Yurun Tian", "Xin Yu", "Bin Fan", "Fuchao Wu", "Huub Heijnen", "Vassileios Balntas"], "title": "SOSNet: Second Order Similarity Regularization for Local Descriptor Learning", "url": "http://arxiv.org/pdf/1904.05019v2", "summary": "Despite the fact that Second Order Similarity (SOS) has been used with significant success in tasks such as graph matching and clustering, it has not been exploited for learning local descriptors. In this work, we explore the potential of SOS in the field of descriptor learning by building upon the intuition that a positive pair of matching points should exhibit similar distances with respect to other points in the embedding space. Thus, we propose a novel regularization term, named Second Order Similarity Regularization (SOSR), that follows this principle. By incorporating SOSR into training, our learned descriptor achieves state-of-the-art performance on several challenging benchmarks containing distinct tasks ranging from local patch retrieval to structure from motion. Furthermore, by designing a von Mises-Fischer distribution based evaluation method, we link the utilization of the descriptor space to the matching performance, thus demonstrating the effectiveness of our proposed SOSR. Extensive experimental results, empirical evidence, and in-depth analysis are provided, indicating that SOSR can significantly boost the matching performance of the learned descriptor.", "published": "2019-04-10T06:33:28Z", "version": 2}, {"aid": "1904.05046", "authors": ["Yaqing Wang", "Quanming Yao", "James Kwok", "Lionel M. Ni"], "title": "Generalizing from a Few Examples: A Survey on Few-Shot Learning", "url": "http://arxiv.org/pdf/1904.05046v3", "summary": "Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-Shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this paper, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimized is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications and theories, are also proposed to provide insights for future research.", "published": "2019-04-10T08:05:48Z", "version": 3}, {"aid": "1904.05049", "authors": ["Yunpeng Chen", "Haoqi Fan", "Bing Xu", "Zhicheng Yan", "Yannis Kalantidis", "Marcus Rohrbach", "Shuicheng Yan", "Jiashi Feng"], "title": "Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution", "url": "http://arxiv.org/pdf/1904.05049v3", "summary": "In natural images, information is conveyed at different frequencies where higher frequencies are usually encoded with fine details and lower frequencies are usually encoded with global structures. Similarly, the output feature maps of a convolution layer can also be seen as a mixture of information at different frequencies. In this work, we propose to factorize the mixed feature maps by their frequencies, and design a novel Octave Convolution (OctConv) operation to store and process feature maps that vary spatially \"slower\" at a lower spatial resolution reducing both memory and computation cost. Unlike existing multi-scale methods, OctConv is formulated as a single, generic, plug-and-play convolutional unit that can be used as a direct replacement of (vanilla) convolutions without any adjustments in the network architecture. It is also orthogonal and complementary to methods that suggest better topologies or reduce channel-wise redundancy like group or depth-wise convolutions. We experimentally show that by simply replacing convolutions with OctConv, we can consistently boost accuracy for both image and video recognition tasks, while reducing memory and computational cost. An OctConv-equipped ResNet-152 can achieve 82.9% top-1 classification accuracy on ImageNet with merely 22.2 GFLOPs.", "published": "2019-04-10T08:15:00Z", "version": 3}, {"aid": "1904.05373", "authors": ["Hang Su", "Varun Jampani", "Deqing Sun", "Orazio Gallo", "Erik Learned-Miller", "Jan Kautz"], "title": "Pixel-Adaptive Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1904.05373v1", "summary": "Convolutions are the fundamental building block of CNNs. The fact that their weights are spatially shared is one of the main reasons for their widespread use, but it also is a major limitation, as it makes convolutions content agnostic. We propose a pixel-adaptive convolution (PAC) operation, a simple yet effective modification of standard convolutions, in which the filter weights are multiplied with a spatially-varying kernel that depends on learnable, local pixel features. PAC is a generalization of several popular filtering techniques and thus can be used for a wide range of use cases. Specifically, we demonstrate state-of-the-art performance when PAC is used for deep joint image upsampling. PAC also offers an effective alternative to fully-connected CRF (Full-CRF), called PAC-CRF, which performs competitively, while being considerably faster. In addition, we also demonstrate that PAC can be used as a drop-in replacement for convolution layers in pre-trained networks, resulting in consistent performance improvements.", "published": "2019-04-10T18:02:54Z", "version": 1}, {"aid": "1904.05387", "authors": ["Eunice Jun", "Maureen Daum", "Jared Roesch", "Sarah E. Chasins", "Emery D. Berger", "Rene Just", "Katharina Reinecke"], "title": "Tea: A High-level Language and Runtime System for Automating Statistical Analysis", "url": "http://arxiv.org/pdf/1904.05387v1", "summary": "Though statistical analyses are centered on research questions and hypotheses, current statistical analysis tools are not. Users must first translate their hypotheses into specific statistical tests and then perform API calls with functions and parameters. To do so accurately requires that users have statistical expertise. To lower this barrier to valid, replicable statistical analysis, we introduce Tea, a high-level declarative language and runtime system. In Tea, users express their study design, any parametric assumptions, and their hypotheses. Tea compiles these high-level specifications into a constraint satisfaction problem that determines the set of valid statistical tests, and then executes them to test the hypothesis. We evaluate Tea using a suite of statistical analyses drawn from popular tutorials. We show that Tea generally matches the choices of experts while automatically switching to non-parametric tests when parametric assumptions are not met. We simulate the effect of mistakes made by non-expert users and show that Tea automatically avoids both false negatives and false positives that could be produced by the application of incorrect statistical tests.", "published": "2019-04-10T18:44:55Z", "version": 1}, {"aid": "1904.05408", "authors": ["Jiqing Wu", "Zhiwu Huang", "Dinesh Acharya", "Wen Li", "Janine Thoma", "Danda Pani Paudel", "Luc Van Gool"], "title": "Sliced Wasserstein Generative Models", "url": "http://arxiv.org/pdf/1904.05408v2", "summary": "In generative modeling, the Wasserstein distance (WD) has emerged as a useful metric to measure the discrepancy between generated and real data distributions. Unfortunately, it is challenging to approximate the WD of high-dimensional distributions. In contrast, the sliced Wasserstein distance (SWD) factorizes high-dimensional distributions into their multiple one-dimensional marginal distributions and is thus easier to approximate. In this paper, we introduce novel approximations of the primal and dual SWD. Instead of using a large number of random projections, as it is done by conventional SWD approximation methods, we propose to approximate SWDs with a small number of parameterized orthogonal projections in an end-to-end deep learning fashion. As concrete applications of our SWD approximations, we design two types of differentiable SWD blocks to equip modern generative frameworks---Auto-Encoders (AE) and Generative Adversarial Networks (GAN). In the experiments, we not only show the superiority of the proposed generative models on standard image synthesis benchmarks, but also demonstrate the state-of-the-art performance on challenging high resolution image and video generation in an unsupervised manner.", "published": "2019-04-10T19:49:43Z", "version": 2}, {"aid": "1904.10508", "authors": ["Yasunao Katayama"], "title": "Quantum-Inspired Computing: Can it be a Microscopic Computing Model of the Brain?", "url": "http://arxiv.org/pdf/1904.10508v2", "summary": "Quantum computing and the workings of the brain have many aspects in common and have been attracting increasing attention in academia and industry. The computation in both is parallel and non-discrete. Though the underlying physical dynamics (e.g., equation of motion) may be deterministic, the observed or interpreted outcomes are often probabilistic. Consequently, various investigations have been undertaken to understand and reproduce the brain on the basis of quantum physics and computing. However, there have been arguments on whether the brain can and have to take advantage of quantum phenomena that need to survive in the macroscopic space-time region at room temperature. This paper presents a unique microscopic computational model for the brain based on an ansatz that the brain computes in a manner similar to quantum computing, but with classical waves. Log-scale encoding of information in the context of computing with waves is shown to play a critical role in bridging the computing models with classical and quantum waves. Our quantum-inspired computing model opens up a possibility of unifying the computing framework of artificial intelligence and quantum computing beyond quantum machine learning approaches.", "published": "2019-04-11T01:12:23Z", "version": 2}, {"aid": "1904.05493", "authors": ["Juan Liu", "Kevin M. Koch"], "title": "Non-locally Encoder-Decoder Convolutional Network for Whole Brain QSM Inversion", "url": "http://arxiv.org/pdf/1904.05493v1", "summary": "Quantitative Susceptibility Mapping (QSM) reconstruction is a challenging inverse problem driven by ill conditioning of its field-to -susceptibility transformation. State-of-art QSM reconstruction methods either suffer from image artifacts or long computation times, which limits QSM clinical translation efforts. To overcome these limitations, a non-locally encoder-decoder gated convolutional neural network is trained to infer whole brain susceptibility map, using the local field and brain mask as the inputs. The performance of the proposed method is evaluated relative to synthetic data, a publicly available challenge dataset, and clinical datasets. The proposed approach can outperform existing methods on quantitative metrics and visual assessment of image sharpness and streaking artifacts. The estimated susceptibility maps can preserve conspicuity of fine features and suppress streaking artifacts. The demonstrated methods have potential value in advancing QSM clinical research and aiding in the translation of QSM to clinical operations.", "published": "2019-04-11T01:20:05Z", "version": 1}, {"aid": "1904.06194", "authors": ["Ze-Feng Gao", "Song Cheng", "Rong-Qiang He", "Z. Y. Xie", "Hui-Hai Zhao", "Zhong-Yi Lu", "Tao Xiang"], "title": "Compressing deep neural networks by matrix product operators", "url": "http://arxiv.org/pdf/1904.06194v2", "summary": "A deep neural network is a parametrization of a multilayer mapping of signals in terms of many alternatively arranged linear and nonlinear transformations. The linear transformations, which are generally used in the fully connected as well as convolutional layers, contain most of the variational parameters that are trained and stored. Compressing a deep neural network to reduce its number of variational parameters but not its prediction power is an important but challenging problem toward the establishment of an optimized scheme in training efficiently these parameters and in lowering the risk of overfitting. Here we show that this problem can be effectively solved by representing linear transformations with matrix product operators (MPOs), which is a tensor network originally proposed in physics to characterize the short-range entanglement in one-dimensional quantum states. We have tested this approach in five typical neural networks, including FC2, LeNet-5, VGG, ResNet, and DenseNet on two widely used data sets, namely, MNIST and CIFAR-10, and found that this MPO representation indeed sets up a faithful and efficient mapping between input and output signals, which can keep or even improve the prediction accuracy with a dramatically reduced number of parameters. Our method greatly simplifies the representations in deep learning, and opens a possible route toward establishing a framework of modern neural networks which might be simpler and cheaper, but more efficient.", "published": "2019-04-11T17:59:00Z", "version": 2}, {"aid": "1904.06008", "authors": ["Qiuyu Zhu", "Pengju Zhang", "Xin Ye"], "title": "A New Loss Function for CNN Classifier Based on Pre-defined Evenly-Distributed Class Centroids", "url": "http://arxiv.org/pdf/1904.06008v2", "summary": "With the development of convolutional neural networks (CNNs) in recent years, the network structure has become more and more complex and varied, and has achieved very good results in pattern recognition, image classification, object detection and tracking. For CNNs used for image classification, in addition to the network structure, more and more research is now focusing on the improvement of the loss function, so as to enlarge the inter-class feature differences, and reduce the intra-class feature variations as soon as possible. Besides the traditional Softmax, typical loss functions include L-Softmax, AM-Softmax, ArcFace, and Center loss, etc. Based on the concept of predefined evenly-distributed class centroids (PEDCC) in CSAE network, this paper proposes a PEDCC-based loss function called PEDCC-Loss, which can make the inter-class distance maximal and intra-class distance small enough in hidden feature space. Multiple experiments on image classification and face recognition have proved that our method achieve the best recognition accuracy, and network training is stable and easy to converge. Code is available in https://github.com/ZLeopard/PEDCC-Loss", "published": "2019-04-12T02:19:45Z", "version": 2}, {"aid": "1904.06031", "authors": ["Saurabh Singh", "Abhinav Shrivastava"], "title": "EvalNorm: Estimating Batch Normalization Statistics for Evaluation", "url": "http://arxiv.org/pdf/1904.06031v2", "summary": "Batch normalization (BN) has been very effective for deep learning and is widely used. However, when training with small minibatches, models using BN exhibit a significant degradation in performance. In this paper we study this peculiar behavior of BN to gain a better understanding of the problem, and identify a cause. We propose 'EvalNorm' to address the issue by estimating corrected normalization statistics to use for BN during evaluation. EvalNorm supports online estimation of the corrected statistics while the model is being trained, and does not affect the training scheme of the model. As a result, EvalNorm can also be used with existing pre-trained models allowing them to benefit from our method. EvalNorm yields large gains for models trained with smaller batches. Our experiments show that EvalNorm performs 6.18% (absolute) better than vanilla BN for a batchsize of 2 on ImageNet validation set and from 1.5 to 7.0 points (absolute) gain on the COCO object detection benchmark across a variety of setups.", "published": "2019-04-12T04:54:56Z", "version": 2}, {"aid": "1904.06252", "authors": ["Jingcai Guo", "Shiheng Ma", "Song Guo"], "title": "MAANet: Multi-view Aware Attention Networks for Image Super-Resolution", "url": "http://arxiv.org/pdf/1904.06252v1", "summary": "In most recent years, deep convolutional neural networks (DCNNs) based image super-resolution (SR) has gained increasing attention in multimedia and computer vision communities, focusing on restoring the high-resolution (HR) image from a low-resolution (LR) image. However, one nonnegligible flaw of DCNNs based methods is that most of them are not able to restore high-resolution images containing sufficient high-frequency information from low-resolution images with low-frequency information redundancy. Worse still, as the depth of DCNNs increases, the training easily encounters the problem of vanishing gradients, which makes the training more difficult. These problems hinder the effectiveness of DCNNs in image SR task. To solve these problems, we propose the Multi-view Aware Attention Networks (MAANet) for image SR task. Specifically, we propose the local aware (LA) and global aware (GA) attention to deal with LR features in unequal manners, which can highlight the high-frequency components and discriminate each feature from LR images in the local and the global views, respectively. Furthermore, we propose the local attentive residual-dense (LARD) block, which combines the LA attention with multiple residual and dense connections, to fit a deeper yet easy to train architecture. The experimental results show that our proposed approach can achieve remarkable performance compared with other state-of-the-art methods.", "published": "2019-04-12T14:32:10Z", "version": 1}, {"aid": "1904.06260", "authors": ["Eric Benhamou"], "title": "Similarities between policy gradient methods (PGM) in Reinforcement learning (RL) and supervised learning (SL)", "url": "http://arxiv.org/pdf/1904.06260v3", "summary": "Reinforcement learning (RL) is about sequential decision making and is traditionally opposed to supervised learning (SL) and unsupervised learning (USL). In RL, given the current state, the agent makes a decision that may influence the next state as opposed to SL (and USL) where, the next state remains the same, regardless of the decisions taken, either in batch or online learning. Although this difference is fundamental between SL and RL, there are connections that have been overlooked. In particular, we prove in this paper that gradient policy method can be cast as a supervised learning problem where true label are replaced with discounted rewards. We provide a new proof of policy gradient methods (PGM) that emphasizes the tight link with the cross entropy and supervised learning. We provide a simple experiment where we interchange label and pseudo rewards. We conclude that other relationships with SL could be made if we modify the reward functions wisely.", "published": "2019-04-12T14:49:28Z", "version": 3}, {"aid": "1904.06458", "authors": ["Kyle Olszewski", "Sergey Tulyakov", "Oliver Woodford", "Hao Li", "Linjie Luo"], "title": "Transformable Bottleneck Networks", "url": "http://arxiv.org/pdf/1904.06458v5", "summary": "We propose a novel approach to performing fine-grained 3D manipulation of image content via a convolutional neural network, which we call the Transformable Bottleneck Network (TBN). It applies given spatial transformations directly to a volumetric bottleneck within our encoder-bottleneck-decoder architecture. Multi-view supervision encourages the network to learn to spatially disentangle the feature space within the bottleneck. The resulting spatial structure can be manipulated with arbitrary spatial transformations. We demonstrate the efficacy of TBNs for novel view synthesis, achieving state-of-the-art results on a challenging benchmark. We demonstrate that the bottlenecks produced by networks trained for this task contain meaningful spatial structure that allows us to intuitively perform a variety of image manipulations in 3D, well beyond the rigid transformations seen during training. These manipulations include non-uniform scaling, non-rigid warping, and combining content from different images. Finally, we extract explicit 3D structure from the bottleneck, performing impressive 3D reconstruction from a single input image.", "published": "2019-04-13T00:56:29Z", "version": 5}, {"aid": "1904.06813", "authors": ["Changhua Pei", "Yi Zhang", "Yongfeng Zhang", "Fei Sun", "Xiao Lin", "Hanxiao Sun", "Jian Wu", "Peng Jiang", "Wenwu Ou"], "title": "Personalized Re-ranking for Recommendation", "url": "http://arxiv.org/pdf/1904.06813v3", "summary": "Ranking is a core task in recommender systems, which aims at providing an ordered list of items to users. Typically, a ranking function is learned from the labeled dataset to optimize the global performance, which produces a ranking score for each individual item. However, it may be sub-optimal because the scoring function applies to each item individually and does not explicitly consider the mutual influence between items, as well as the differences of users' preferences or intents. Therefore, we propose a personalized re-ranking model for recommender systems. The proposed re-ranking model can be easily deployed as a follow-up modular after any ranking algorithm, by directly using the existing ranking feature vectors. It directly optimizes the whole recommendation list by employing a transformer structure to efficiently encode the information of all items in the list. Specifically, the Transformer applies a self-attention mechanism that directly models the global relationships between any pair of items in the whole list. We confirm that the performance can be further improved by introducing pre-trained embedding to learn personalized encoding functions for different users. Experimental results on both offline benchmarks and real-world online e-commerce systems demonstrate the significant improvements of the proposed re-ranking model.", "published": "2019-04-15T02:47:40Z", "version": 3}, {"aid": "1904.06836", "authors": ["Qilong Wang", "Jiangtao Xie", "Wangmeng Zuo", "Lei Zhang", "Peihua Li"], "title": "Deep CNNs Meet Global Covariance Pooling: Better Representation and Generalization", "url": "http://arxiv.org/pdf/1904.06836v2", "summary": "Compared with global average pooling in existing deep convolutional neural networks (CNNs), global covariance pooling can capture richer statistics of deep features, having potential for improving representation and generalization abilities of deep CNNs. However, integration of global covariance pooling into deep CNNs brings two challenges: (1) robust covariance estimation given deep features of high dimension and small sample size; (2) appropriate usage of geometry of covariances. To address these challenges, we propose a global Matrix Power Normalized COVariance (MPN-COV) Pooling. Our MPN-COV conforms to a robust covariance estimator, very suitable for scenario of high dimension and small sample size. It can also be regarded as Power-Euclidean metric between covariances, effectively exploiting their geometry. Furthermore, a global Gaussian embedding network is proposed to incorporate first-order statistics into MPN-COV. For fast training of MPN-COV networks, we implement an iterative matrix square root normalization, avoiding GPU unfriendly eigen-decomposition inherent in MPN-COV. Additionally, progressive 1x1 convolutions and group convolution are introduced to compress covariance representations. The proposed methods are highly modular, readily plugged into existing deep CNNs. Extensive experiments are conducted on large-scale object classification, scene categorization, fine-grained visual recognition and texture classification, showing our methods outperform the counterparts and obtain state-of-the-art performance.", "published": "2019-04-15T04:30:01Z", "version": 2}, {"aid": "1904.07523", "authors": ["Saeed Anwar", "Salman Khan", "Nick Barnes"], "title": "A Deep Journey into Super-resolution: A survey", "url": "http://arxiv.org/pdf/1904.07523v3", "summary": "Deep convolutional networks based super-resolution is a fast-growing field with numerous practical applications. In this exposition, we extensively compare 30+ state-of-the-art super-resolution Convolutional Neural Networks (CNNs) over three classical and three recently introduced challenging datasets to benchmark single image super-resolution. We introduce a taxonomy for deep-learning based super-resolution networks that groups existing methods into nine categories including linear, residual, multi-branch, recursive, progressive, attention-based and adversarial designs. We also provide comparisons between the models in terms of network complexity, memory footprint, model input and output, learning details, the type of network losses and important architectural differences (e.g., depth, skip-connections, filters). The extensive evaluation performed, shows the consistent and rapid growth in the accuracy in the past few years along with a corresponding boost in model complexity and the availability of large-scale datasets. It is also observed that the pioneering methods identified as the benchmark have been significantly outperformed by the current contenders. Despite the progress in recent years, we identify several shortcomings of existing techniques and provide future research directions towards the solution of these open problems.", "published": "2019-04-16T08:08:14Z", "version": 3}, {"aid": "1904.07952", "authors": ["Linda Wang"], "title": "Response of Selective Attention in Middle Temporal Area", "url": "http://arxiv.org/pdf/1904.07952v1", "summary": "The primary visual cortex processes a large amount of visual information, however, due to its large receptive fields, when multiple stimuli fall within one receptive field, there are computational problems. To solve this problem, the visual system uses selective attention, which allocates resources to a specific spatial location, to attend to one of the stimuli in the receptive field. During this process, the center and width of the attending receptive field change. The model presented in the paper, which is extended and altered from Bobier et al., simulates the selective attention between the primary visual cortex, V1, and middle temporal (MT) area. The responses of the MT columns, which encode the target stimulus, are compared to the results of an experiment conducted by Womelsdorf et al. on the receptive field shift and shrinkage in macaque MT area from selective attention. Based on the results, the responses in the MT area are similar to the Gaussian shaped receptive fields found in the experiment. As well, the responses of the MT columns are also measured for accuracy of representing the target visual stimulus and is found to represent the stimulus with a root mean squared error around 0.17 to 0.18. The paper also explores varying model parameters, such as the membrane time constant and maximum firing rates, and how those affect the measurement. This model is a start to modeling the responses of selective attention, however there are still improvements that can be made to better compare with the experiment, produce more accurate responses and incorporate more biologically plausible features.", "published": "2019-04-16T20:04:32Z", "version": 1}, {"aid": "1904.08128", "authors": ["Fabian Isensee", "Paul F. J\u00e4ger", "Simon A. A. Kohl", "Jens Petersen", "Klaus H. Maier-Hein"], "title": "Automated Design of Deep Learning Methods for Biomedical Image Segmentation", "url": "http://arxiv.org/pdf/1904.08128v2", "summary": "Biomedical imaging is a driver of scientific discovery and core component of medical care, currently stimulated by the field of deep learning. While semantic segmentation algorithms enable 3D image analysis and quantification in many applications, the design of respective specialised solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We propose nnU-Net, a deep learning framework that condenses the current domain knowledge and autonomously takes the key decisions required to transfer a basic architecture to different datasets and segmentation tasks. Without manual tuning, nnU-Net surpasses most specialised deep learning pipelines in 19 public international competitions and sets a new state of the art in the majority of the 49 tasks. The results demonstrate a vast hidden potential in the systematic adaptation of deep learning methods to different datasets. We make nnU-Net publicly available as an open-source tool that can effectively be used out-of-the-box, rendering state of the art segmentation accessible to non-experts and catalyzing scientific progress as a framework for automated method design.", "published": "2019-04-17T08:30:17Z", "version": 2}, {"aid": "1904.08935", "authors": ["Alan H. Gee", "Diego Garcia-Olano", "Joydeep Ghosh", "David Paydarfar"], "title": "Explaining Deep Classification of Time-Series Data with Learned Prototypes", "url": "http://arxiv.org/pdf/1904.08935v3", "summary": "The emergence of deep learning networks raises a need for explainable AI so that users and domain experts can be confident applying them to high-risk decisions. In this paper, we leverage data from the latent space induced by deep learning models to learn stereotypical representations or \"prototypes\" during training to elucidate the algorithmic decision-making process. We study how leveraging prototypes effect classification decisions of two dimensional time-series data in a few different settings: (1) electrocardiogram (ECG) waveforms to detect clinical bradycardia, a slowing of heart rate, in preterm infants, (2) respiration waveforms to detect apnea of prematurity, and (3) audio waveforms to classify spoken digits. We improve upon existing models by optimizing for increased prototype diversity and robustness, visualize how these prototypes in the latent space are used by the model to distinguish classes, and show that prototypes are capable of learning features on two dimensional time-series data to produce explainable insights during classification tasks. We show that the prototypes are capable of learning real-world features - bradycardia in ECG, apnea in respiration, and articulation in speech - as well as features within sub-classes. Our novel work leverages learned prototypical framework on two dimensional time-series data to produce explainable insights during classification tasks.", "published": "2019-04-18T07:14:45Z", "version": 3}, {"aid": "1904.08939", "authors": ["Anh Nguyen", "Jason Yosinski", "Jeff Clune"], "title": "Understanding Neural Networks via Feature Visualization: A survey", "url": "http://arxiv.org/pdf/1904.08939v1", "summary": "A neuroscience method to understanding the brain is to find and study the preferred stimuli that highly activate an individual cell or groups of cells. Recent advances in machine learning enable a family of methods to synthesize preferred stimuli that cause a neuron in an artificial or biological brain to fire strongly. Those methods are known as Activation Maximization (AM) or Feature Visualization via Optimization. In this chapter, we (1) review existing AM techniques in the literature; (2) discuss a probabilistic interpretation for AM; and (3) review the applications of AM in debugging and explaining networks.", "published": "2019-04-18T15:46:26Z", "version": 1}, {"aid": "1904.09120", "authors": ["Yunze Man", "Yangsibo Huang", "Junyi Feng", "Xi Li", "Fei Wu"], "title": "Deep Q Learning Driven CT Pancreas Segmentation with Geometry-Aware U-Net", "url": "http://arxiv.org/pdf/1904.09120v1", "summary": "Segmentation of pancreas is important for medical image analysis, yet it faces great challenges of class imbalance, background distractions and non-rigid geometrical features. To address these difficulties, we introduce a Deep Q Network(DQN) driven approach with deformable U-Net to accurately segment the pancreas by explicitly interacting with contextual information and extract anisotropic features from pancreas. The DQN based model learns a context-adaptive localization policy to produce a visually tightened and precise localization bounding box of the pancreas. Furthermore, deformable U-Net captures geometry-aware information of pancreas by learning geometrically deformable filters for feature extraction. Experiments on NIH dataset validate the effectiveness of the proposed framework in pancreas segmentation.", "published": "2019-04-19T08:36:21Z", "version": 1}, {"aid": "1904.09658", "authors": ["Yichun Shi", "Anil K. Jain"], "title": "Probabilistic Face Embeddings", "url": "http://arxiv.org/pdf/1904.09658v4", "summary": "Embedding methods have achieved success in face recognition by comparing facial features in a latent semantic space. However, in a fully unconstrained face setting, the facial features learned by the embedding model could be ambiguous or may not even be present in the input face, leading to noisy representations. We propose Probabilistic Face Embeddings (PFEs), which represent each face image as a Gaussian distribution in the latent space. The mean of the distribution estimates the most likely feature values while the variance shows the uncertainty in the feature values. Probabilistic solutions can then be naturally derived for matching and fusing PFEs using the uncertainty information. Empirical evaluation on different baseline models, training datasets and benchmarks show that the proposed method can improve the face recognition performance of deterministic embeddings by converting them into PFEs. The uncertainties estimated by PFEs also serve as good indicators of the potential matching accuracy, which are important for a risk-controlled recognition system.", "published": "2019-04-21T21:08:00Z", "version": 4}, {"aid": "1904.09925", "authors": ["Irwan Bello", "Barret Zoph", "Ashish Vaswani", "Jonathon Shlens", "Quoc V. Le"], "title": "Attention Augmented Convolutional Networks", "url": "http://arxiv.org/pdf/1904.09925v5", "summary": "Convolutional networks have been the paradigm of choice in many computer vision applications. The convolution operation however has a significant weakness in that it only operates on a local neighborhood, thus missing global information. Self-attention, on the other hand, has emerged as a recent advance to capture long range interactions, but has mostly been applied to sequence modeling and generative modeling tasks. In this paper, we consider the use of self-attention for discriminative visual tasks as an alternative to convolutions. We introduce a novel two-dimensional relative self-attention mechanism that proves competitive in replacing convolutions as a stand-alone computational primitive for image classification. We find in control experiments that the best results are obtained when combining both convolutions and self-attention. We therefore propose to augment convolutional operators with this self-attention mechanism by concatenating convolutional feature maps with a set of feature maps produced via self-attention. Extensive experiments show that Attention Augmentation leads to consistent improvements in image classification on ImageNet and object detection on COCO across many different models and scales, including ResNets and a state-of-the art mobile constrained network, while keeping the number of parameters similar. In particular, our method achieves a $1.3\\%$ top-1 accuracy improvement on ImageNet classification over a ResNet50 baseline and outperforms other attention mechanisms for images such as Squeeze-and-Excitation. It also achieves an improvement of 1.4 mAP in COCO Object Detection on top of a RetinaNet baseline.", "published": "2019-04-22T15:31:15Z", "version": 5}, {"aid": "1904.10255", "authors": ["Ahmed Imtiaz Humayun", "Asif Shahriyar Sushmit", "Taufiq Hasan", "Mohammed Imamul Hassan Bhuiyan"], "title": "End-to-end Sleep Staging with Raw Single Channel EEG using Deep Residual ConvNets", "url": "http://arxiv.org/pdf/1904.10255v1", "summary": "Humans approximately spend a third of their life sleeping, which makes monitoring sleep an integral part of well-being. In this paper, a 34-layer deep residual ConvNet architecture for end-to-end sleep staging is proposed. The network takes raw single channel electroencephalogram (Fpz-Cz) signal as input and yields hypnogram annotations for each 30s segments as output. Experiments are carried out for two different scoring standards (5 and 6 stage classification) on the expanded PhysioNet Sleep-EDF dataset, which contains multi-source data from hospital and household polysomnography setups. The performance of the proposed network is compared with that of the state-of-the-art algorithms in patient independent validation tasks. The experimental results demonstrate the superiority of the proposed network compared to the best existing method, providing a relative improvement in epoch-wise average accuracy of 6.8% and 6.3% on the household data and multi-source data, respectively. Codes are made publicly available on Github.", "published": "2019-04-23T11:32:46Z", "version": 1}, {"aid": "1904.10405", "authors": ["Jacques Carette", "William M. Farmer", "Michael Kohlhase", "Florian Rabe"], "title": "Big Math and the One-Brain Barrier A Position Paper and Architecture Proposal", "url": "http://arxiv.org/pdf/1904.10405v2", "summary": "Over the last decades, a class of important mathematical results have required an ever increasing amount of human effort to carry out. For some, the help of computers is now indispensable. We analyze the implications of this trend towards \"big mathematics\", its relation to human cognition, and how machine support for big math can be organized. The central contribution of this position paper is an information model for \"doing mathematics\", which posits that humans very efficiently integrate four aspects: inference, computation, tabulation, and narration around a well-organized core of mathematical knowledge. The challenge for mathematical software systems is that these four aspects need to be integrated as well. We briefly survey the state of the art.", "published": "2019-04-23T16:15:52Z", "version": 2}, {"aid": "1904.10424", "authors": ["Shengcai Liao", "Ling Shao"], "title": "Interpretable and Generalizable Person Re-Identification with Query-Adaptive Convolution and Temporal Lifting", "url": "http://arxiv.org/pdf/1904.10424v4", "summary": "For person re-identification, existing deep networks often focus on representation learning. However, without transfer learning, the learned model is fixed as is, which is not adaptable for handling various unseen scenarios. In this paper, beyond representation learning, we consider how to formulate person image matching directly in deep feature maps. We treat image matching as finding local correspondences in feature maps, and construct query-adaptive convolution kernels on the fly to achieve local matching. In this way, the matching process and results are interpretable, and this explicit matching is more generalizable than representation features to unseen scenarios, such as unknown misalignments, pose or viewpoint changes. To facilitate end-to-end training of this architecture, we further build a class memory module to cache feature maps of the most recent samples of each class, so as to compute image matching losses for metric learning. Through direct cross-dataset evaluation, the proposed Query-Adaptive Convolution (QAConv) method gains large improvements over popular learning methods (about 10%+ mAP), and achieves comparable results to many transfer learning methods. Besides, a model-free temporal cooccurrence based score weighting method called TLift is proposed, which improves the performance to a further extent, achieving state-of-the-art results in cross-dataset person re-identification. Code is available at https://github.com/ShengcaiLiao/QAConv.", "published": "2019-04-23T17:03:13Z", "version": 4}, {"aid": "1904.10489", "authors": ["Jingpeng Wu", "William M. Silversmith", "Kisuk Lee", "H. Sebastian Seung"], "title": "Chunkflow: Distributed Hybrid Cloud Processing of Large 3D Images by Convolutional Nets", "url": "http://arxiv.org/pdf/1904.10489v3", "summary": "It is now common to process volumetric biomedical images using 3D Convolutional Networks (ConvNets). This can be challenging for the teravoxel and even petavoxel images that are being acquired today by light or electron microscopy. Here we introduce chunkflow, a software framework for distributing ConvNet processing over local and cloud GPUs and CPUs. The image volume is divided into overlapping chunks, each chunk is processed by a ConvNet, and the results are blended together to yield the output image. The frontend submits ConvNet tasks to a cloud queue. The tasks are executed by local and cloud GPUs and CPUs. Thanks to the fault-tolerant architecture of Chunkflow, cost can be greatly reduced by utilizing cheap unstable cloud instances. Chunkflow currently supports PyTorch for GPUs and PZnet for CPUs. To illustrate its usage, a large 3D brain image from serial section electron microscopy was processed by a 3D ConvNet with a U-Net style architecture. Chunkflow provides some chunk operations for general use, and the operations can be composed flexibly in a command line interface.", "published": "2019-04-23T18:47:57Z", "version": 3}, {"aid": "1904.10619", "authors": ["Hongzhu Li", "Weiqiang Wang"], "title": "Reinterpreting CTC training as iterative fitting", "url": "http://arxiv.org/pdf/1904.10619v2", "summary": "The connectionist temporal classification (CTC) enables end-to-end sequence learning by maximizing the probability of correctly recognizing sequences during training. The outputs of a CTC-trained model tend to form a series of spikes separated by strongly predicted blanks, know as the spiky problem. To figure out the reason for it, we reinterpret the CTC training process as an iterative fitting task that is based on frame-wise cross-entropy loss. It offers us an intuitive way to compare target probabilities with model outputs for each iteration, and explain how the model outputs gradually turns spiky. Inspired by it, we put forward two ways to modify the CTC training. The experiments demonstrate that our method can well solve the spiky problem and moreover, lead to faster convergence over various training settings. Beside this, the reinterpretation of CTC, as a brand new perspective, may be potentially useful in other situations. The code is publicly available at https://github.com/hzli-ucas/caffe/tree/ctc.", "published": "2019-04-24T02:50:29Z", "version": 2}, {"aid": "1904.10633", "authors": ["Yonghao He", "Dezhong Xu", "Lifang Wu", "Meng Jian", "Shiming Xiang", "Chunhong Pan"], "title": "LFFD: A Light and Fast Face Detector for Edge Devices", "url": "http://arxiv.org/pdf/1904.10633v3", "summary": "Face detection, as a fundamental technology for various applications, is always deployed on edge devices which have limited memory storage and low computing power. This paper introduces a Light and Fast Face Detector (LFFD) for edge devices. The proposed method is anchor-free and belongs to the one-stage category. Specifically, we rethink the importance of receptive field (RF) and effective receptive field (ERF) in the background of face detection. Essentially, the RFs of neurons in a certain layer are distributed regularly in the input image and theses RFs are natural \"anchors\". Combining RF \"anchors\" and appropriate RF strides, the proposed method can detect a large range of continuous face scales with 100% coverage in theory. The insightful understanding of relations between ERF and face scales motivates an efficient backbone for one-stage detection. The backbone is characterized by eight detection branches and common layers, resulting in efficient computation. Comprehensive and extensive experiments on popular benchmarks: WIDER FACE and FDDB are conducted. A new evaluation schema is proposed for application-oriented scenarios. Under the new schema, the proposed method can achieve superior accuracy (WIDER FACE Val/Test -- Easy: 0.910/0.896, Medium: 0.881/0.865, Hard: 0.780/0.770; FDDB -- discontinuous: 0.973, continuous: 0.724). Multiple hardware platforms are introduced to evaluate the running efficiency. The proposed method can obtain fast inference speed (NVIDIA TITAN Xp: 131.45 FPS at 640x480; NVIDIA TX2: 136.99 PFS at 160x120; Raspberry Pi 3 Model B+: 8.44 FPS at 160x120) with model size of 9 MB.", "published": "2019-04-24T03:47:24Z", "version": 3}, {"aid": "1904.10644", "authors": ["Yu Chen", "Tom Diethe", "Neil Lawrence"], "title": "Facilitating Bayesian Continual Learning by Natural Gradients and Stein Gradients", "url": "http://arxiv.org/pdf/1904.10644v1", "summary": "Continual learning aims to enable machine learning models to learn a general solution space for past and future tasks in a sequential manner. Conventional models tend to forget the knowledge of previous tasks while learning a new task, a phenomenon known as catastrophic forgetting. When using Bayesian models in continual learning, knowledge from previous tasks can be retained in two ways: 1). posterior distributions over the parameters, containing the knowledge gained from inference in previous tasks, which then serve as the priors for the following task; 2). coresets, containing knowledge of data distributions of previous tasks. Here, we show that Bayesian continual learning can be facilitated in terms of these two means through the use of natural gradients and Stein gradients respectively.", "published": "2019-04-24T05:18:32Z", "version": 1}, {"aid": "1904.10653", "authors": ["Xu Zhu"], "title": "Stochastic Lipschitz Q-Learning", "url": "http://arxiv.org/pdf/1904.10653v2", "summary": "In an episodic Markov Decision Process (MDP) problem, an online algorithm chooses from a set of actions in a sequence of $H$ trials, where $H$ is the episode length, in order to maximize the total payoff of the chosen actions. Q-learning, as the most popular model-free reinforcement learning (RL) algorithm, directly parameterizes and updates value functions without explicitly modeling the environment. Recently, [Jin et al. 2018] studies the sample complexity of Q-learning with finite states and actions. Their algorithm achieves nearly optimal regret, which shows that Q-learning can be made sample efficient. However, MDPs with large discrete states and actions [Silver et al. 2016] or continuous spaces [Mnih et al. 2013] cannot learn efficiently in this way. Hence, it is critical to develop new algorithms to solve this dilemma with provable guarantee on the sample complexity. With this motivation, we propose a novel algorithm that works for MDPs with a more general setting, which has infinitely many states and actions and assumes that the payoff function and transition kernel are Lipschitz continuous. We also provide corresponding theory justification for our algorithm. It achieves the regret $\\tilde{\\mathcal{O}}(K^{\\frac{d+1}{d+2}}\\sqrt{H^3}),$ where $K$ denotes the number of episodes and $d$ denotes the dimension of the joint space. To the best of our knowledge, this is the first analysis in the model-free setting whose established regret matches the lower bound up to a logarithmic factor.", "published": "2019-04-24T06:25:42Z", "version": 2}, {"aid": "1904.12456", "authors": ["Yousef Jamali", "Mohammad Jamali", "Mehdi Golshani"], "title": "A new method of brain stimulation at ultra-high frequency", "url": "http://arxiv.org/pdf/1904.12456v1", "summary": "Nerve stimulation via micro-electrode implants is one of the neurostimulation approaches which is used frequently in the medical treatment of some brain disorders, neural prosthetics, brain-machine interfaces and also in the cyborg. In this method, the electrical stimulation signal can be categorized by the frequency band: low frequency, high frequency, and ultra-high frequency. The stimulation should be less destructive, more smooth, and controllable. In this article, we present a brief description of the mechanism underlying the ultra-high frequency stimulation. In the flowing, from an informatics perspective, we propose a state-of-the-art, low destructive, and highly efficient stimulation method at the low amplitude ultra-high frequency signal. In this method, we have tried to reduce the adaptation of the nerve system by modulating the stimulation signal via a low frequency rectangular random wave. By this method, we could reach the \"almost zero discharge\" with minimum destructive effect in the experimental test on the fish nervous system.", "published": "2019-04-29T05:52:43Z", "version": 1}, {"aid": "1904.12460", "authors": ["Mohammad Jamali", "Yousef Jamali", "Mehdi Golshani"], "title": "Theory of cyborg: a new approach to fish locomotion control", "url": "http://arxiv.org/pdf/1904.12460v2", "summary": "Cyborg in the brain-machine interface field has attracted more attention in recent years. To control a creature via a machine called cyborg method, three stages are considerable: stimulation of neurons, neural response, and the behavioral reaction of the subject. Our main concern was to know how electrical stimulation induces neural activity and leads to a behavioral response. Additionally, we were interested to explore which type of electrical stimulation is optimal from different aspects such as maximum response with minimum induction stimulus field, minimum damage of the tissue and the electrode, reduction of the noxiousness of stimuli or pain in the living creature. In this article, we proposed a new model for the induction of neural activity led to locomotion responses through electrical stimulation. Furthermore, based on this model, we developed a new approach of electrical neural stimulation to provide a better locomotion control of living beings. This approach was verified through the empirical data of fish cyborg. We stimulated the fish brain by use of an ultra-high frequency signal which careered by a random low frequency. According to our model, we could control the locomotion of fish in a novel and innovative way. In this study, we categorized the different cyborg methods based on the nervous system areas and the stimulation signal properties to reach the better and optimal behavioral control of creature. According to this, we proposed a new stimulation method theoretically and confirmed it experimentally.", "published": "2019-04-29T06:03:38Z", "version": 2}, {"aid": "1904.12848", "authors": ["Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Minh-Thang Luong", "Quoc V. Le"], "title": "Unsupervised Data Augmentation for Consistency Training", "url": "http://arxiv.org/pdf/1904.12848v6", "summary": "Semi-supervised learning lately has shown much promise in improving deep learning models when labeled data is scarce. Common among recent approaches is the use of consistency training on a large amount of unlabeled data to constrain model predictions to be invariant to input noise. In this work, we present a new perspective on how to effectively noise unlabeled examples and argue that the quality of noising, specifically those produced by advanced data augmentation methods, plays a crucial role in semi-supervised learning. By substituting simple noising operations with advanced data augmentation methods such as RandAugment and back-translation, our method brings substantial improvements across six language and three vision tasks under the same consistency training framework. On the IMDb text classification dataset, with only 20 labeled examples, our method achieves an error rate of 4.20, outperforming the state-of-the-art model trained on 25,000 labeled examples. On a standard semi-supervised learning benchmark, CIFAR-10, our method outperforms all previous approaches and achieves an error rate of 5.43 with only 250 examples. Our method also combines well with transfer learning, e.g., when finetuning from BERT, and yields improvements in high-data regime, such as ImageNet, whether when there is only 10% labeled data or when a full labeled set with 1.3M extra unlabeled examples is used. Code is available at https://github.com/google-research/uda.", "published": "2019-04-29T17:56:59Z", "version": 6}, {"aid": "1904.13132", "authors": ["Yuki M. Asano", "Christian Rupprecht", "Andrea Vedaldi"], "title": "A critical analysis of self-supervision, or what we can learn from a single image", "url": "http://arxiv.org/pdf/1904.13132v3", "summary": "We look critically at popular self-supervision techniques for learning deep convolutional neural networks without manual labels. We show that three different and representative methods, BiGAN, RotNet and DeepCluster, can learn the first few layers of a convolutional network from a single image as well as using millions of images and manual labels, provided that strong data augmentation is used. However, for deeper layers the gap with manual supervision cannot be closed even if millions of unlabelled images are used for training. We conclude that: (1) the weights of the early layers of deep networks contain limited information about the statistics of natural images, that (2) such low-level statistics can be learned through self-supervision just as well as through strong supervision, and that (3) the low-level statistics can be captured via synthetic transformations instead of using a large image dataset.", "published": "2019-04-30T10:10:38Z", "version": 3}, {"aid": "1905.01988", "authors": ["Xianbin Hong", "Gautam Pal", "Sheng-Uei Guan", "Prudence Wong", "Dawei Liu", "Ka Lok Man", "Xin Huang"], "title": "Semi-Unsupervised Lifelong Learning for Sentiment Classification: Less Manual Data Annotation and More Self-Studying", "url": "http://arxiv.org/pdf/1905.01988v2", "summary": "Lifelong machine learning is a novel machine learning paradigm which can continually accumulate knowledge during learning. The knowledge extracting and reusing abilities enable the lifelong machine learning to solve the related problems. The traditional approaches like Na\\\"ive Bayes and some neural network based approaches only aim to achieve the best performance upon a single task. Unlike them, the lifelong machine learning in this paper focuses on how to accumulate knowledge during learning and leverage them for further tasks. Meanwhile, the demand for labelled data for training also is significantly decreased with the knowledge reusing. This paper suggests that the aim of the lifelong learning is to use less labelled data and computational cost to achieve the performance as well as or even better than the supervised learning.", "published": "2019-04-30T23:56:54Z", "version": 2}, {"aid": "1905.00780", "authors": ["Suraj Srinivas", "Francois Fleuret"], "title": "Full-Gradient Representation for Neural Network Visualization", "url": "http://arxiv.org/pdf/1905.00780v4", "summary": "We introduce a new tool for interpreting neural net responses, namely full-gradients, which decomposes the neural net response into input sensitivity and per-neuron sensitivity components. This is the first proposed representation which satisfies two key properties: completeness and weak dependence, which provably cannot be satisfied by any saliency map-based interpretability method. For convolutional nets, we also propose an approximate saliency map representation, called FullGrad, obtained by aggregating the full-gradient components.   We experimentally evaluate the usefulness of FullGrad in explaining model behaviour with two quantitative tests: pixel perturbation and remove-and-retrain. Our experiments reveal that our method explains model behaviour correctly, and more comprehensively than other methods in the literature. Visual inspection also reveals that our saliency maps are sharper and more tightly confined to object regions than other methods.", "published": "2019-05-02T14:41:31Z", "version": 4}, {"aid": "1905.01164", "authors": ["Tamar Rott Shaham", "Tali Dekel", "Tomer Michaeli"], "title": "SinGAN: Learning a Generative Model from a Single Natural Image", "url": "http://arxiv.org/pdf/1905.01164v2", "summary": "We introduce SinGAN, an unconditional generative model that can be learned from a single natural image. Our model is trained to capture the internal distribution of patches within the image, and is then able to generate high quality, diverse samples that carry the same visual content as the image. SinGAN contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. This allows generating new samples of arbitrary size and aspect ratio, that have significant variability, yet maintain both the global structure and the fine textures of the training image. In contrast to previous single image GAN schemes, our approach is not limited to texture images, and is not conditional (i.e. it generates samples from noise). User studies confirm that the generated samples are commonly confused to be real images. We illustrate the utility of SinGAN in a wide range of image manipulation tasks.", "published": "2019-05-02T16:15:38Z", "version": 2}, {"aid": "1905.11437", "authors": ["Leonardo Enzo Brito da Silva", "Islam Elnabarawy", "Donald C. Wunsch II"], "title": "A Survey of Adaptive Resonance Theory Neural Network Models for Engineering Applications", "url": "http://arxiv.org/pdf/1905.11437v1", "summary": "This survey samples from the ever-growing family of adaptive resonance theory (ART) neural network models used to perform the three primary machine learning modalities, namely, unsupervised, supervised and reinforcement learning. It comprises a representative list from classic to modern ART models, thereby painting a general picture of the architectures developed by researchers over the past 30 years. The learning dynamics of these ART models are briefly described, and their distinctive characteristics such as code representation, long-term memory and corresponding geometric interpretation are discussed. Useful engineering properties of ART (speed, configurability, explainability, parallelization and hardware implementation) are examined along with current challenges. Finally, a compilation of online software libraries is provided. It is expected that this overview will be helpful to new and seasoned ART researchers.", "published": "2019-05-04T00:54:06Z", "version": 1}, {"aid": "1905.02244", "authors": ["Andrew Howard", "Mark Sandler", "Grace Chu", "Liang-Chieh Chen", "Bo Chen", "Mingxing Tan", "Weijun Wang", "Yukun Zhu", "Ruoming Pang", "Vijay Vasudevan", "Quoc V. Le", "Hartwig Adam"], "title": "Searching for MobileNetV3", "url": "http://arxiv.org/pdf/1905.02244v5", "summary": "We present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design. MobileNetV3 is tuned to mobile phone CPUs through a combination of hardware-aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and network design can work together to harness complementary approaches improving the overall state of the art. Through this process we create two new MobileNet models for release: MobileNetV3-Large and MobileNetV3-Small which are targeted for high and low resource use cases. These models are then adapted and applied to the tasks of object detection and semantic segmentation. For the task of semantic segmentation (or any dense pixel prediction), we propose a new efficient segmentation decoder Lite Reduced Atrous Spatial Pyramid Pooling (LR-ASPP). We achieve new state of the art results for mobile classification, detection and segmentation. MobileNetV3-Large is 3.2\\% more accurate on ImageNet classification while reducing latency by 15\\% compared to MobileNetV2. MobileNetV3-Small is 4.6\\% more accurate while reducing latency by 5\\% compared to MobileNetV2. MobileNetV3-Large detection is 25\\% faster at roughly the same accuracy as MobileNetV2 on COCO detection. MobileNetV3-Large LR-ASPP is 30\\% faster than MobileNetV2 R-ASPP at similar accuracy for Cityscapes segmentation.", "published": "2019-05-06T19:38:31Z", "version": 5}, {"aid": "1905.02249", "authors": ["David Berthelot", "Nicholas Carlini", "Ian Goodfellow", "Nicolas Papernot", "Avital Oliver", "Colin Raffel"], "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning", "url": "http://arxiv.org/pdf/1905.02249v2", "summary": "Semi-supervised learning has proven to be a powerful paradigm for leveraging unlabeled data to mitigate the reliance on large labeled datasets. In this work, we unify the current dominant approaches for semi-supervised learning to produce a new algorithm, MixMatch, that works by guessing low-entropy labels for data-augmented unlabeled examples and mixing labeled and unlabeled data using MixUp. We show that MixMatch obtains state-of-the-art results by a large margin across many datasets and labeled data amounts. For example, on CIFAR-10 with 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by a factor of 2 on STL-10. We also demonstrate how MixMatch can help achieve a dramatically better accuracy-privacy trade-off for differential privacy. Finally, we perform an ablation study to tease apart which components of MixMatch are most important for its success.", "published": "2019-05-06T19:56:03Z", "version": 2}, {"aid": "1905.02876", "authors": ["Giorgos Bouritsas", "Sergiy Bokhnyak", "Stylianos Ploumpis", "Michael Bronstein", "Stefanos Zafeiriou"], "title": "Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape Representation Learning and Generation", "url": "http://arxiv.org/pdf/1905.02876v3", "summary": "Generative models for 3D geometric data arise in many important applications in 3D computer vision and graphics. In this paper, we focus on 3D deformable shapes that share a common topological structure, such as human faces and bodies. Morphable Models and their variants, despite their linear formulation, have been widely used for shape representation, while most of the recently proposed nonlinear approaches resort to intermediate representations, such as 3D voxel grids or 2D views. In this work, we introduce a novel graph convolutional operator, acting directly on the 3D mesh, that explicitly models the inductive bias of the fixed underlying graph. This is achieved by enforcing consistent local orderings of the vertices of the graph, through the spiral operator, thus breaking the permutation invariance property that is adopted by all the prior work on Graph Neural Networks. Our operator comes by construction with desirable properties (anisotropic, topology-aware, lightweight, easy-to-optimise), and by using it as a building block for traditional deep generative architectures, we demonstrate state-of-the-art results on a variety of 3D shape datasets compared to the linear Morphable Model and other graph convolutional operators.", "published": "2019-05-08T02:37:27Z", "version": 3}, {"aid": "1905.03329", "authors": ["Charlie Frogner", "Farzaneh Mirzazadeh", "Justin Solomon"], "title": "Learning Embeddings into Entropic Wasserstein Spaces", "url": "http://arxiv.org/pdf/1905.03329v1", "summary": "Euclidean embeddings of data are fundamentally limited in their ability to capture latent semantic structures, which need not conform to Euclidean spatial assumptions. Here we consider an alternative, which embeds data as discrete probability distributions in a Wasserstein space, endowed with an optimal transport metric. Wasserstein spaces are much larger and more flexible than Euclidean spaces, in that they can successfully embed a wider variety of metric structures. We exploit this flexibility by learning an embedding that captures semantic information in the Wasserstein distance between embedded distributions. We examine empirically the representational capacity of our learned Wasserstein embeddings, showing that they can embed a wide variety of metric structures with smaller distortion than an equivalent Euclidean embedding. We also investigate an application to word embedding, demonstrating a unique advantage of Wasserstein embeddings: We can visualize the high-dimensional embedding directly, since it is a probability distribution on a low-dimensional space. This obviates the need for dimensionality reduction techniques like t-SNE for visualization.", "published": "2019-05-08T20:48:28Z", "version": 1}, {"aid": "1905.03658", "authors": ["Jason Ramapuram", "Russ Webb"], "title": "Improving Discrete Latent Representations With Differentiable Approximation Bridges", "url": "http://arxiv.org/pdf/1905.03658v3", "summary": "Modern neural network training relies on piece-wise (sub-)differentiable functions in order to use backpropagation to update model parameters. In this work, we introduce a novel method to allow simple non-differentiable functions at intermediary layers of deep neural networks. We do so by training with a differentiable approximation bridge (DAB) neural network which approximates the non-differentiable forward function and provides gradient updates during backpropagation. We present strong empirical results (performing over 600 experiments) in four different domains: unsupervised (image) representation learning, variational (image) density estimation, image classification, and sequence sorting to demonstrate that our proposed method improves state of the art performance. We demonstrate that training with DAB aided discrete non-differentiable functions improves image reconstruction quality and posterior linear separability by 10% against the Gumbel-Softmax relaxed estimator [37, 26] as well as providing a 9% improvement in the test variational lower bound in comparison to the state of the art RELAX [16] discrete estimator. We also observe an accuracy improvement of 77% in neural sequence sorting and a 25% improvement against the straight-through estimator [5] in an image classification setting. The DAB network is not used for inference and expands the class of functions that are usable in neural networks.", "published": "2019-05-09T14:31:59Z", "version": 3}, {"aid": "1905.04149", "authors": ["Xiang Zhang", "Lina Yao", "Xianzhi Wang", "Jessica Monaghan", "David Mcalpine", "Yu Zhang"], "title": "A Survey on Deep Learning-based Non-Invasive Brain Signals:Recent Advances and New Frontiers", "url": "http://arxiv.org/pdf/1905.04149v5", "summary": "Brain-Computer Interface (BCI) bridges the human's neural world and the outer physical world by decoding individuals' brain signals into commands recognizable by computer devices. Deep learning has lifted the performance of brain-computer interface systems significantly in recent years. In this article, we systematically investigate brain signal types for BCI and related deep learning concepts for brain signal analysis. We then present a comprehensive survey of deep learning techniques used for BCI, by summarizing over 230 contributions most published in the past five years. Finally, we discuss the applied areas, opening challenges, and future directions for deep learning-based BCI.", "published": "2019-05-10T13:04:00Z", "version": 5}, {"aid": "1905.04215", "authors": ["Xudong Mao", "Yun Ma", "Zhenguo Yang", "Yangbin Chen", "Qing Li"], "title": "Virtual Mixup Training for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/1905.04215v4", "summary": "We study the problem of unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain. Recently, the cluster assumption has been applied to unsupervised domain adaptation and achieved strong performance. One critical factor in successful training of the cluster assumption is to impose the locally-Lipschitz constraint to the model. Existing methods only impose the locally-Lipschitz constraint around the training points while miss the other areas, such as the points in-between training data. In this paper, we address this issue by encouraging the model to behave linearly in-between training points. We propose a new regularization method called Virtual Mixup Training (VMT), which is able to incorporate the locally-Lipschitz constraint to the areas in-between training data. Unlike the traditional mixup model, our method constructs the combination samples without using the label information, allowing it to apply to unsupervised domain adaptation. The proposed method is generic and can be combined with most existing models such as the recent state-of-the-art model called VADA. Extensive experiments demonstrate that VMT significantly improves the performance of VADA on six domain adaptation benchmark datasets. For the challenging task of adapting MNIST to SVHN, VMT can improve the accuracy of VADA by over 30\\%. Code is available at \\url{https://github.com/xudonmao/VMT}.", "published": "2019-05-10T15:24:17Z", "version": 4}, {"aid": "1905.04243", "authors": ["Zhengwei Wang", "Qi She", "Alan F. Smeaton", "Tomas E. Ward", "Graham Healy"], "title": "Synthetic-Neuroscore: Using A Neuro-AI Interface for Evaluating Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1905.04243v2", "summary": "Generative adversarial networks (GANs) are increasingly attracting attention in the computer vision, natural language processing, speech synthesis and similar domains. Arguably the most striking results have been in the area of image synthesis. However, evaluating the performance of GANs is still an open and challenging problem. Existing evaluation metrics primarily measure the dissimilarity between real and generated images using automated statistical methods. They often require large sample sizes for evaluation and do not directly reflect human perception of image quality. In this work, we describe an evaluation metric we call Neuroscore, for evaluating the performance of GANs, that more directly reflects psychoperceptual image quality through the utilization of brain signals. Our results show that Neuroscore has superior performance to the current evaluation metrics in that: (1) It is more consistent with human judgment; (2) The evaluation process needs much smaller numbers of samples; and (3) It is able to rank the quality of images on a per GAN basis. A convolutional neural network (CNN) based neuro-AI interface is proposed to predict Neuroscore from GAN-generated images directly without the need for neural responses. Importantly, we show that including neural responses during the training phase of the network can significantly improve the prediction capability of the proposed model. Materials related to this work are provided at https://github.com/villawang/Neuro-AI-Interface.", "published": "2019-05-10T16:25:07Z", "version": 2}, {"aid": "1906.01704", "authors": ["Yang Li", "Wenming Zheng", "Lei Wang", "Yuan Zong", "Lei Qi", "Zhen Cui", "Tong Zhang", "Tengfei Song"], "title": "A Novel Bi-hemispheric Discrepancy Model for EEG Emotion Recognition", "url": "http://arxiv.org/pdf/1906.01704v1", "summary": "The neuroscience study has revealed the discrepancy of emotion expression between left and right hemispheres of human brain. Inspired by this study, in this paper, we propose a novel bi-hemispheric discrepancy model (BiHDM) to learn the asymmetric differences between two hemispheres for electroencephalograph (EEG) emotion recognition. Concretely, we first employ four directed recurrent neural networks (RNNs) based on two spatial orientations to traverse electrode signals on two separate brain regions, which enables the model to obtain the deep representations of all the EEG electrodes' signals while keeping the intrinsic spatial dependence. Then we design a pairwise subnetwork to capture the discrepancy information between two hemispheres and extract higher-level features for final classification. Besides, in order to reduce the domain shift between training and testing data, we use a domain discriminator that adversarially induces the overall feature learning module to generate emotion-related but domain-invariant feature, which can further promote EEG emotion recognition. We conduct experiments on three public EEG emotional datasets, and the experiments show that the new state-of-the-art results can be achieved.", "published": "2019-05-11T01:17:22Z", "version": 1}, {"aid": "1905.05055", "authors": ["Zhengxia Zou", "Keyan Chen", "Zhenwei Shi", "Yuhong Guo", "Jieping Ye"], "title": "Object Detection in 20 Years: A Survey", "url": "http://arxiv.org/pdf/1905.05055v3", "summary": "Object detection, as of one the most fundamental and challenging problems in computer vision, has received great attention in recent years. Over the past two decades, we have seen a rapid technological evolution of object detection and its profound impact on the entire computer vision field. If we consider today's object detection technique as a revolution driven by deep learning, then back in the 1990s, we would see the ingenious thinking and long-term perspective design of early computer vision. This paper extensively reviews this fast-moving research field in the light of technical evolution, spanning over a quarter-century's time (from the 1990s to 2022). A number of topics have been covered in this paper, including the milestone detectors in history, detection datasets, metrics, fundamental building blocks of the detection system, speed-up techniques, and the recent state-of-the-art detection methods.", "published": "2019-05-13T14:26:50Z", "version": 3}, {"aid": "1905.06484", "authors": ["Wenyuan Li", "Zichen Wang", "Jiayun Li", "Jennifer Polson", "William Speier", "Corey Arnold"], "title": "Semi-supervised learning based on generative adversarial network: a comparison between good GAN and bad GAN approach", "url": "http://arxiv.org/pdf/1905.06484v2", "summary": "Recently, semi-supervised learning methods based on generative adversarial networks (GANs) have received much attention. Among them, two distinct approaches have achieved competitive results on a variety of benchmark datasets. Bad GAN learns a classifier with unrealistic samples distributed on the complement of the support of the input data. Conversely, Triple GAN consists of a three-player game that tries to leverage good generated samples to boost classification results. In this paper, we perform a comprehensive comparison of these two approaches on different benchmark datasets. We demonstrate their different properties on image generation, and sensitivity to the amount of labeled data provided. By comprehensively comparing these two methods, we hope to shed light on the future of GAN-based semi-supervised learning.", "published": "2019-05-16T00:43:47Z", "version": 2}, {"aid": "1905.07177", "authors": ["Hui Yin", "Yuanhao Gong", "Guoping Qiu"], "title": "Side Window Filtering", "url": "http://arxiv.org/pdf/1905.07177v1", "summary": "Local windows are routinely used in computer vision and almost without exception the center of the window is aligned with the pixels being processed. We show that this conventional wisdom is not universally applicable. When a pixel is on an edge, placing the center of the window on the pixel is one of the fundamental reasons that cause many filtering algorithms to blur the edges. Based on this insight, we propose a new Side Window Filtering (SWF) technique which aligns the window's side or corner with the pixel being processed. The SWF technique is surprisingly simple yet theoretically rooted and very effective in practice. We show that many traditional linear and nonlinear filters can be easily implemented under the SWF framework. Extensive analysis and experiments show that implementing the SWF principle can significantly improve their edge preserving capabilities and achieve state of the art performances in applications such as image smoothing, denoising, enhancement, structure-preserving texture-removing, mutual-structure extraction, and HDR tone mapping. In addition to image filtering, we further show that the SWF principle can be extended to other applications involving the use of a local window. Using colorization by optimization as an example, we demonstrate that implementing the SWF principle can effectively prevent artifacts such as color leakage associated with the conventional implementation. Given the ubiquity of window based operations in computer vision, the new SWF technique is likely to benefit many more applications.", "published": "2019-05-17T09:39:53Z", "version": 1}, {"aid": "1905.07373", "authors": ["Chen Lin", "Minghao Guo", "Chuming Li", "Yuan Xin", "Wei Wu", "Dahua Lin", "Wanli Ouyang", "Junjie Yan"], "title": "Online Hyper-parameter Learning for Auto-Augmentation Strategy", "url": "http://arxiv.org/pdf/1905.07373v2", "summary": "Data augmentation is critical to the success of modern deep learning techniques. In this paper, we propose Online Hyper-parameter Learning for Auto-Augmentation (OHL-Auto-Aug), an economical solution that learns the augmentation policy distribution along with network training. Unlike previous methods on auto-augmentation that search augmentation strategies in an offline manner, our method formulates the augmentation policy as a parameterized probability distribution, thus allowing its parameters to be optimized jointly with network parameters. Our proposed OHL-Auto-Aug eliminates the need of re-training and dramatically reduces the cost of the overall search process, while establishes significantly accuracy improvements over baseline models. On both CIFAR-10 and ImageNet, our method achieves remarkable on search accuracy, 60x faster on CIFAR-10 and 24x faster on ImageNet, while maintaining competitive accuracies.", "published": "2019-05-17T16:59:31Z", "version": 2}, {"aid": "1905.07375", "authors": ["Chuming Li", "Yuan Xin", "Chen Lin", "Minghao Guo", "Wei Wu", "Wanli Ouyang", "Junjie Yan"], "title": "AM-LFS: AutoML for Loss Function Search", "url": "http://arxiv.org/pdf/1905.07375v2", "summary": "Designing an effective loss function plays an important role in visual analysis. Most existing loss function designs rely on hand-crafted heuristics that require domain experts to explore the large design space, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Loss Function Search (AM-LFS) which leverages REINFORCE to search loss functions during the training process. The key contribution of this work is the design of search space which can guarantee the generalization and transferability on different vision tasks by including a bunch of existing prevailing loss functions in a unified formulation. We also propose an efficient optimization framework which can dynamically optimize the parameters of loss function's distribution during training. Extensive experimental results on four benchmark datasets show that, without any tricks, our method outperforms existing hand-crafted loss functions in various computer vision tasks.", "published": "2019-05-17T17:06:49Z", "version": 2}, {"aid": "1905.07562", "authors": ["Feng Qi", "Wenchuan Wu"], "title": "Human-like machine thinking: Language guided imagination", "url": "http://arxiv.org/pdf/1905.07562v2", "summary": "Human thinking requires the brain to understand the meaning of language expression and to properly organize the thoughts flow using the language. However, current natural language processing models are primarily limited in the word probability estimation. Here, we proposed a Language guided imagination (LGI) network to incrementally learn the meaning and usage of numerous words and syntaxes, aiming to form a human-like machine thinking process. LGI contains three subsystems: (1) vision system that contains an encoder to disentangle the input or imagined scenarios into abstract population representations, and an imagination decoder to reconstruct imagined scenario from higher level representations; (2) Language system, that contains a binarizer to transfer symbol texts into binary vectors, an IPS (mimicking the human IntraParietal Sulcus, implemented by an LSTM) to extract the quantity information from the input texts, and a textizer to convert binary vectors into text symbols; (3) a PFC (mimicking the human PreFrontal Cortex, implemented by an LSTM) to combine inputs of both language and vision representations, and predict text symbols and manipulated images accordingly. LGI has incrementally learned eight different syntaxes (or tasks), with which a machine thinking loop has been formed and validated by the proper interaction between language and vision system. The paper provides a new architecture to let the machine learn, understand and use language in a human-like way that could ultimately enable a machine to construct fictitious 'mental' scenario and possess intelligence.", "published": "2019-05-18T09:23:00Z", "version": 2}, {"aid": "1905.12601", "authors": ["Harikrishnan N B", "Nithin Nagaraj"], "title": "A Novel Chaos Theory Inspired Neuronal Architecture", "url": "http://arxiv.org/pdf/1905.12601v1", "summary": "The practical success of widely used machine learning (ML) and deep learning (DL) algorithms in Artificial Intelligence (AI) community owes to availability of large datasets for training and huge computational resources. Despite the enormous practical success of AI, these algorithms are only loosely inspired from the biological brain and do not mimic any of the fundamental properties of neurons in the brain, one such property being the chaotic firing of biological neurons. This motivates us to develop a novel neuronal architecture where the individual neurons are intrinsically chaotic in nature. By making use of the topological transitivity property of chaos, our neuronal network is able to perform classification tasks with very less number of training samples. For the MNIST dataset, with as low as $0.1 \\%$ of the total training data, our method outperforms ML and matches DL in classification accuracy for up to $7$ training samples/class. For the Iris dataset, our accuracy is comparable with ML algorithms, and even with just two training samples/class, we report an accuracy as high as $95.8 \\%$. This work highlights the effectiveness of chaos and its properties for learning and paves the way for chaos-inspired neuronal architectures by closely mimicking the chaotic nature of neurons in the brain.", "published": "2019-05-19T07:45:57Z", "version": 1}, {"aid": "1905.07870", "authors": ["Qingyun Wang", "Lifu Huang", "Zhiying Jiang", "Kevin Knight", "Heng Ji", "Mohit Bansal", "Yi Luan"], "title": "PaperRobot: Incremental Draft Generation of Scientific Ideas", "url": "http://arxiv.org/pdf/1905.07870v4", "summary": "We present a PaperRobot who performs as an automatic research assistant by (1) conducting deep understanding of a large collection of human-written papers in a target domain and constructing comprehensive background knowledge graphs (KGs); (2) creating new ideas by predicting links from the background KGs, by combining graph attention and contextual text attention; (3) incrementally writing some key elements of a new paper based on memory-attention networks: from the input title along with predicted related entities to generate a paper abstract, from the abstract to generate conclusion and future work, and finally from future work to generate a title for a follow-on paper. Turing Tests, where a biomedical domain expert is asked to compare a system output and a human-authored string, show PaperRobot generated abstracts, conclusion and future work sections, and new titles are chosen over human-written ones up to 30%, 24% and 12% of the time, respectively.", "published": "2019-05-20T04:41:10Z", "version": 4}, {"aid": "1905.10924", "authors": ["Zalan Gyenis", "Andras Kornai"], "title": "Naive probability", "url": "http://arxiv.org/pdf/1905.10924v2", "summary": "We describe a rational, but low resolution model of probability.", "published": "2019-05-20T22:32:21Z", "version": 2}, {"aid": "1905.09688", "authors": ["Ole-Christoffer Granmo", "Sondre Glimsdal", "Lei Jiao", "Morten Goodwin", "Christian W. Omlin", "Geir Thore Berge"], "title": "The Convolutional Tsetlin Machine", "url": "http://arxiv.org/pdf/1905.09688v5", "summary": "Convolutional neural networks (CNNs) have obtained astounding successes for important pattern recognition tasks, but they suffer from high computational complexity and the lack of interpretability. The recent Tsetlin Machine (TM) attempts to address this lack by using easy-to-interpret conjunctive clauses in propositional logic to solve complex pattern recognition problems. The TM provides competitive accuracy in several benchmarks, while keeping the important property of interpretability. It further facilitates hardware-near implementation since inputs, patterns, and outputs are expressed as bits, while recognition and learning rely on straightforward bit manipulation. In this paper, we exploit the TM paradigm by introducing the Convolutional Tsetlin Machine (CTM), as an interpretable alternative to CNNs. Whereas the TM categorizes an image by employing each clause once to the whole image, the CTM uses each clause as a convolution filter. That is, a clause is evaluated multiple times, once per image patch taking part in the convolution. To make the clauses location-aware, each patch is further augmented with its coordinates within the image. The output of a convolution clause is obtained simply by ORing the outcome of evaluating the clause on each patch. In the learning phase of the TM, clauses that evaluate to 1 are contrasted against the input. For the CTM, we instead contrast against one of the patches, randomly selected among the patches that made the clause evaluate to 1. Accordingly, the standard Type I and Type II feedback of the classic TM can be employed directly, without further modification. The CTM obtains a peak test accuracy of 99.4% on MNIST, 96.31% on Kuzushiji-MNIST, 91.5% on Fashion-MNIST, and 100.0% on the 2D Noisy XOR Problem, which is competitive with results reported for simple 4-layer CNNs, BinaryConnect, Logistic Circuits and an FPGA-accelerated Binary CNN.", "published": "2019-05-23T14:47:33Z", "version": 5}, {"aid": "1905.10037", "authors": ["Satoshi Nishida", "Yusuke Nakano", "Antoine Blanc", "Naoya Maeda", "Masataka Kado", "Shinji Nishimoto"], "title": "Brain-mediated Transfer Learning of Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1905.10037v3", "summary": "The human brain can effectively learn a new task from a small number of samples, which indicate that the brain can transfer its prior knowledge to solve tasks in different domains. This function is analogous to transfer learning (TL) in the field of machine learning. TL uses a well-trained feature space in a specific task domain to improve performance in new tasks with insufficient training data. TL with rich feature representations, such as features of convolutional neural networks (CNNs), shows high generalization ability across different task domains. However, such TL is still insufficient in making machine learning attain generalization ability comparable to that of the human brain. To examine if the internal representation of the brain could be used to achieve more efficient TL, we introduce a method for TL mediated by human brains. Our method transforms feature representations of audiovisual inputs in CNNs into those in activation patterns of individual brains via their association learned ahead using measured brain responses. Then, to estimate labels reflecting human cognition and behavior induced by the audiovisual inputs, the transformed representations are used for TL. We demonstrate that our brain-mediated TL (BTL) shows higher performance in the label estimation than the standard TL. In addition, we illustrate that the estimations mediated by different brains vary from brain to brain, and the variability reflects the individual variability in perception. Thus, our BTL provides a framework to improve the generalization ability of machine-learning feature representations and enable machine learning to estimate human-like cognition and behavior, including individual variability.", "published": "2019-05-24T05:15:17Z", "version": 3}, {"aid": "1905.10404", "authors": ["Aadil Hayat", "Utsav Singh", "Vinay P. Namboodiri"], "title": "InfoRL: Interpretable Reinforcement Learning using Information Maximization", "url": "http://arxiv.org/pdf/1905.10404v1", "summary": "Recent advances in reinforcement learning have proved that given an environment we can learn to perform a task in that environment if we have access to some form of a reward function (dense, sparse or derived from IRL). But most of the algorithms focus on learning a single best policy to perform a given set of tasks. In this paper, we focus on an algorithm that learns to not just perform a task but different ways to perform the same task. As we know when the environment is complex enough there always exists multiple ways to perform a task. We show that using the concept of information maximization it is possible to learn latent codes for discovering multiple ways to perform any given task in an environment.", "published": "2019-05-24T18:47:09Z", "version": 1}, {"aid": "1905.10448", "authors": ["Michael Perlmutter", "Feng Gao", "Guy Wolf", "Matthew Hirn"], "title": "Geometric Wavelet Scattering Networks on Compact Riemannian Manifolds", "url": "http://arxiv.org/pdf/1905.10448v4", "summary": "The Euclidean scattering transform was introduced nearly a decade ago to improve the mathematical understanding of convolutional neural networks. Inspired by recent interest in geometric deep learning, which aims to generalize convolutional neural networks to manifold and graph-structured domains, we define a geometric scattering transform on manifolds. Similar to the Euclidean scattering transform, the geometric scattering transform is based on a cascade of wavelet filters and pointwise nonlinearities. It is invariant to local isometries and stable to certain types of diffeomorphisms. Empirical results demonstrate its utility on several geometric learning tasks. Our results generalize the deformation stability and local translation invariance of Euclidean scattering, and demonstrate the importance of linking the used filter structures to the underlying geometry of the data.", "published": "2019-05-24T21:19:04Z", "version": 4}, {"aid": "1905.10484", "authors": ["Keegan Lensink", "Bas Peters", "Eldad Haber"], "title": "Fully Hyperbolic Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1905.10484v3", "summary": "Convolutional Neural Networks (CNN) have recently seen tremendous success in various computer vision tasks. However, their application to problems with high dimensional input and output, such as high-resolution image and video segmentation or 3D medical imaging, has been limited by various factors. Primarily, in the training stage, it is necessary to store network activations for back propagation. In these settings, the memory requirements associated with storing activations can exceed what is feasible with current hardware, especially for problems in 3D. Motivated by the propagation of signals over physical networks, that are governed by the hyperbolic Telegraph equation, in this work we introduce a fully conservative hyperbolic network for problems with high dimensional input and output. We introduce a coarsening operation that allows completely reversible CNNs by using a learnable Discrete Wavelet Transform and its inverse to both coarsen and interpolate the network state and change the number of channels. We show that fully reversible networks are able to achieve results comparable to the state of the art in 4D time-lapse hyper spectral image segmentation and full 3D video segmentation, with a much lower memory footprint that is a constant independent of the network depth. We also extend the use of such networks to Variational Auto Encoders with high resolution input and output.", "published": "2019-05-24T23:43:36Z", "version": 3}, {"aid": "1905.10575", "authors": ["Xiang Ma", "Liangzhe Chen", "Zhaohong Deng", "Peng Xu", "Qisheng Yan", "Kup-Sze Choi", "Shitong Wang"], "title": "Deep Image Feature Learning with Fuzzy Rules", "url": "http://arxiv.org/pdf/1905.10575v3", "summary": "The methods of extracting image features are the key to many image processing tasks. At present, the most popular method is the deep neural network which can automatically extract robust features through end-to-end training instead of hand-crafted feature extraction. However, the deep neural network currently faces many challenges: 1) its effectiveness is heavily dependent on large datasets, so the computational complexity is very high; 2) it is usually regarded as a black box model with poor interpretability. To meet the above challenges, a more interpretable and scalable feature learning method, i.e., deep image feature learning with fuzzy rules (DIFL-FR), is proposed in the paper, which combines the rule-based fuzzy modeling technique and the deep stacked learning strategy. The method progressively learns image features through a layer-by-layer manner based on fuzzy rules, so the feature learning process can be better explained by the generated rules. More importantly, the learning process of the method is only based on forward propagation without back propagation and iterative learning, which results in the high learning efficiency. In addition, the method is under the settings of unsupervised learning and can be easily extended to scenes of supervised and semi-supervised learning. Extensive experiments are conducted on image datasets of different scales. The results obviously show the effectiveness of the proposed method.", "published": "2019-05-25T11:33:02Z", "version": 3}, {"aid": "1905.10671", "authors": ["Zhongzhan Huang", "Senwei Liang", "Mingfu Liang", "Haizhao Yang"], "title": "DIANet: Dense-and-Implicit Attention Network", "url": "http://arxiv.org/pdf/1905.10671v2", "summary": "Attention networks have successfully boosted the performance in various vision problems. Previous works lay emphasis on designing a new attention module and individually plug them into the networks. Our paper proposes a novel-and-simple framework that shares an attention module throughout different network layers to encourage the integration of layer-wise information and this parameter-sharing module is referred as Dense-and-Implicit-Attention (DIA) unit. Many choices of modules can be used in the DIA unit. Since Long Short Term Memory (LSTM) has a capacity of capturing long-distance dependency, we focus on the case when the DIA unit is the modified LSTM (refer as DIA-LSTM). Experiments on benchmark datasets show that the DIA-LSTM unit is capable of emphasizing layer-wise feature interrelation and leads to significant improvement of image classification accuracy. We further empirically show that the DIA-LSTM has a strong regularization ability on stabilizing the training of deep networks by the experiments with the removal of skip connections or Batch Normalization in the whole residual network. The code is released at https://github.com/gbup-group/DIANet.", "published": "2019-05-25T20:51:07Z", "version": 2}, {"aid": "1905.10681", "authors": ["Ahmed H. Qureshi", "Jacob J. Johnson", "Yuzhe Qin", "Taylor Henderson", "Byron Boots", "Michael C. Yip"], "title": "Composing Task-Agnostic Policies with Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1905.10681v2", "summary": "The composition of elementary behaviors to solve challenging transfer learning problems is one of the key elements in building intelligent machines. To date, there has been plenty of work on learning task-specific policies or skills but almost no focus on composing necessary, task-agnostic skills to find a solution to new problems. In this paper, we propose a novel deep reinforcement learning-based skill transfer and composition method that takes the agent's primitive policies to solve unseen tasks. We evaluate our method in difficult cases where training policy through standard reinforcement learning (RL) or even hierarchical RL is either not feasible or exhibits high sample complexity. We show that our method not only transfers skills to new problem settings but also solves the challenging environments requiring both task planning and motion control with high data efficiency.", "published": "2019-05-25T21:40:38Z", "version": 2}, {"aid": "1905.10710", "authors": ["Alexander Tong", "Guy Wolf", "Smita Krishnaswamy"], "title": "Fixing Bias in Reconstruction-based Anomaly Detection with Lipschitz Discriminators", "url": "http://arxiv.org/pdf/1905.10710v3", "summary": "Anomaly detection is of great interest in fields where abnormalities need to be identified and corrected (e.g., medicine and finance). Deep learning methods for this task often rely on autoencoder reconstruction error, sometimes in conjunction with other errors. We show that this approach exhibits intrinsic biases that lead to undesirable results. Reconstruction-based methods are sensitive to training-data outliers and simple-to-reconstruct points. Instead, we introduce a new unsupervised Lipschitz anomaly discriminator that does not suffer from these biases. Our anomaly discriminator is trained, similar to the ones used in GANs, to detect the difference between the training data and corruptions of the training data. We show that this procedure successfully detects unseen anomalies with guarantees on those that have a certain Wasserstein distance from the data or corrupted training set. These additions allow us to show improved performance on MNIST, CIFAR10, and health record data.", "published": "2019-05-26T01:57:42Z", "version": 3}, {"aid": "1905.10836", "authors": ["Bingchen Liu", "Yizhe Zhu", "Zuohui Fu", "Gerard de Melo", "Ahmed Elgammal"], "title": "OOGAN: Disentangling GAN with One-Hot Sampling and Orthogonal Regularization", "url": "http://arxiv.org/pdf/1905.10836v5", "summary": "Exploring the potential of GANs for unsupervised disentanglement learning, this paper proposes a novel GAN-based disentanglement framework with One-Hot Sampling and Orthogonal Regularization (OOGAN). While previous works mostly attempt to tackle disentanglement learning through VAE and seek to implicitly minimize the Total Correlation (TC) objective with various sorts of approximation methods, we show that GANs have a natural advantage in disentangling with an alternating latent variable (noise) sampling method that is straightforward and robust. Furthermore, we provide a brand-new perspective on designing the structure of the generator and discriminator, demonstrating that a minor structural change and an orthogonal regularization on model weights entails an improved disentanglement. Instead of experimenting on simple toy datasets, we conduct experiments on higher-resolution images and show that OOGAN greatly pushes the boundary of unsupervised disentanglement.", "published": "2019-05-26T16:42:56Z", "version": 5}, {"aid": "1905.11006", "authors": ["Jiatao Gu", "Changhan Wang", "Jake Zhao"], "title": "Levenshtein Transformer", "url": "http://arxiv.org/pdf/1905.11006v2", "summary": "Modern neural sequence generation models are built to either generate tokens step-by-step from scratch or (iteratively) modify a sequence of tokens bounded by a fixed length. In this work, we develop Levenshtein Transformer, a new partially autoregressive model devised for more flexible and amenable sequence generation. Unlike previous approaches, the atomic operations of our model are insertion and deletion. The combination of them facilitates not only generation but also sequence refinement allowing dynamic length changes. We also propose a set of new training techniques dedicated at them, effectively exploiting one as the other's learning signal thanks to their complementary nature. Experiments applying the proposed model achieve comparable performance but much-improved efficiency on both generation (e.g. machine translation, text summarization) and refinement tasks (e.g. automatic post-editing). We further confirm the flexibility of our model by showing a Levenshtein Transformer trained by machine translation can straightforwardly be used for automatic post-editing.", "published": "2019-05-27T07:08:12Z", "version": 2}, {"aid": "1905.11498", "authors": ["Chu Wang", "Babak Samari", "Vladimir Kim", "Siddhartha Chaudhuri", "Kaleem Siddiqi"], "title": "FAN: Focused Attention Networks", "url": "http://arxiv.org/pdf/1905.11498v3", "summary": "Attention networks show promise for both vision and language tasks, by emphasizing relationships between constituent elements through weighting functions. Such elements could be regions in an image output by a region proposal network, or words in a sentence, represented by word embedding. Thus far the learning of attention weights has been driven solely by the minimization of task specific loss functions. We introduce a method for learning attention weights to better emphasize informative pair-wise relations between entities. The key component is a novel center-mass cross entropy loss, which can be applied in conjunction with the task specific ones. We further introduce a focused attention backbone to learn these attention weights for general tasks. We demonstrate that the focused supervision leads to improved attention distribution across meaningful entities, and that it enhances the representation by aggregating features from them. Our focused attention module leads to state-of-the-art recovery of relations in a relationship proposal task and boosts performance for various vision and language tasks.", "published": "2019-05-27T20:41:53Z", "version": 3}, {"aid": "1905.11926", "authors": ["Chengxi Ye", "Matthew Evanusa", "Hua He", "Anton Mitrokhin", "Tom Goldstein", "James A. Yorke", "Cornelia Ferm\u00fcller", "Yiannis Aloimonos"], "title": "Network Deconvolution", "url": "http://arxiv.org/pdf/1905.11926v4", "summary": "Convolution is a central operation in Convolutional Neural Networks (CNNs), which applies a kernel to overlapping regions shifted across the image. However, because of the strong correlations in real-world image data, convolutional kernels are in effect re-learning redundant data. In this work, we show that this redundancy has made neural network training challenging, and propose network deconvolution, a procedure which optimally removes pixel-wise and channel-wise correlations before the data is fed into each layer. Network deconvolution can be efficiently calculated at a fraction of the computational cost of a convolution layer. We also show that the deconvolution filters in the first layer of the network resemble the center-surround structure found in biological neurons in the visual regions of the brain. Filtering with such kernels results in a sparse representation, a desired property that has been missing in the training of neural networks. Learning from the sparse representation promotes faster convergence and superior results without the use of batch normalization. We apply our network deconvolution operation to 10 modern neural network models by replacing batch normalization within each. Extensive experiments show that the network deconvolution operation is able to deliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST, Fashion-MNIST, Cityscapes, and ImageNet datasets.", "published": "2019-05-28T16:38:34Z", "version": 4}, {"aid": "1905.13545", "authors": ["Haohan Wang", "Xindi Wu", "Zeyi Huang", "Eric P. Xing"], "title": "High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1905.13545v3", "summary": "We investigate the relationship between the frequency spectrum of image data and the generalization behavior of convolutional neural networks (CNN). We first notice CNN's ability in capturing the high-frequency components of images. These high-frequency components are almost imperceptible to a human. Thus the observation leads to multiple hypotheses that are related to the generalization behaviors of CNN, including a potential explanation for adversarial examples, a discussion of CNN's trade-off between robustness and accuracy, and some evidence in understanding training heuristics.", "published": "2019-05-28T19:42:04Z", "version": 3}, {"aid": "1905.12100", "authors": ["Owen Marschall", "Kyunghyun Cho", "Cristina Savin"], "title": "Using local plasticity rules to train recurrent neural networks", "url": "http://arxiv.org/pdf/1905.12100v1", "summary": "To learn useful dynamics on long time scales, neurons must use plasticity rules that account for long-term, circuit-wide effects of synaptic changes. In other words, neural circuits must solve a credit assignment problem to appropriately assign responsibility for global network behavior to individual circuit components. Furthermore, biological constraints demand that plasticity rules are spatially and temporally local; that is, synaptic changes can depend only on variables accessible to the pre- and postsynaptic neurons. While artificial intelligence offers a computational solution for credit assignment, namely backpropagation through time (BPTT), this solution is wildly biologically implausible. It requires both nonlocal computations and unlimited memory capacity, as any synaptic change is a complicated function of the entire history of network activity. Similar nonlocality issues plague other approaches such as FORCE (Sussillo et al. 2009). Overall, we are still missing a model for learning in recurrent circuits that both works computationally and uses only local updates. Leveraging recent advances in machine learning on approximating gradients for BPTT, we derive biologically plausible plasticity rules that enable recurrent networks to accurately learn long-term dependencies in sequential data. The solution takes the form of neurons with segregated voltage compartments, with several synaptic sub-populations that have different functional properties. The network operates in distinct phases during which each synaptic sub-population is updated by its own local plasticity rule. Our results provide new insights into the potential roles of segregated dendritic compartments, branch-specific inhibition, and global circuit phases in learning.", "published": "2019-05-28T21:32:26Z", "version": 1}, {"aid": "1905.13010", "authors": ["Arthur Charlesworth"], "title": "Definitively Identifying an Inherent Limitation to Actual Cognition", "url": "http://arxiv.org/pdf/1905.13010v2", "summary": "A century ago, discoveries of a serious kind of logical error made separately by several leading mathematicians led to acceptance of a sharply enhanced standard for rigor within what ultimately became the foundation for Computer Science. By 1931, Godel had obtained a definitive and remarkable result: an inherent limitation to that foundation. The resulting limitation is not applicable to actual human cognition, to even the smallest extent, unless both of these extremely brittle assumptions hold: humans are infallible reasoners and reason solely via formal inference rules. Both assumptions are contradicted by empirical data from well-known Cognitive Science experiments. This article investigates how a novel multi-part methodology recasts computability theory within Computer Science to obtain a definitive limitation whose application to human cognition avoids assumptions contradicting empirical data. The limitation applies to individual humans, to finite sets of humans, and more generally to any real-world entity.", "published": "2019-05-29T17:55:38Z", "version": 2}, {"aid": "1905.12775", "authors": ["Xiang Xu", "Xiong Zhou", "Ragav Venkatesan", "Gurumurthy Swaminathan", "Orchid Majumder"], "title": "$d$-SNE: Domain Adaptation using Stochastic Neighborhood Embedding", "url": "http://arxiv.org/pdf/1905.12775v1", "summary": "Deep neural networks often require copious amount of labeled-data to train their scads of parameters. Training larger and deeper networks is hard without appropriate regularization, particularly while using a small dataset. Laterally, collecting well-annotated data is expensive, time-consuming and often infeasible. A popular way to regularize these networks is to simply train the network with more data from an alternate representative dataset. This can lead to adverse effects if the statistics of the representative dataset are dissimilar to our target. This predicament is due to the problem of domain shift. Data from a shifted domain might not produce bespoke features when a feature extractor from the representative domain is used. In this paper, we propose a new technique ($d$-SNE) of domain adaptation that cleverly uses stochastic neighborhood embedding techniques and a novel modified-Hausdorff distance. The proposed technique is learnable end-to-end and is therefore, ideally suited to train neural networks. Extensive experiments demonstrate that $d$-SNE outperforms the current states-of-the-art and is robust to the variances in different datasets, even in the one-shot and semi-supervised learning settings. $d$-SNE also demonstrates the ability to generalize to multiple domains concurrently.", "published": "2019-05-29T23:16:51Z", "version": 1}, {"aid": "1905.12830", "authors": ["Haijun Liu", "Jian Cheng", "Shiguang Wang", "Wen Wang"], "title": "Attention: A Big Surprise for Cross-Domain Person Re-Identification", "url": "http://arxiv.org/pdf/1905.12830v1", "summary": "In this paper, we focus on model generalization and adaptation for cross-domain person re-identification (Re-ID). Unlike existing cross-domain Re-ID methods, leveraging the auxiliary information of those unlabeled target-domain data, we aim at enhancing the model generalization and adaptation by discriminative feature learning, and directly exploiting a pre-trained model to new domains (datasets) without any utilization of the information from target domains. To address the discriminative feature learning problem, we surprisingly find that simply introducing the attention mechanism to adaptively extract the person features for every domain is of great effectiveness. We adopt two popular type of attention mechanisms, long-range dependency based attention and direct generation based attention. Both of them can perform the attention via spatial or channel dimensions alone, even the combination of spatial and channel dimensions. The outline of different attentions are well illustrated. Moreover, we also incorporate the attention results into the final output of model through skip-connection to improve the features with both high and middle level semantic visual information. In the manner of directly exploiting a pre-trained model to new domains, the attention incorporation method truly could enhance the model generalization and adaptation to perform the cross-domain person Re-ID. We conduct extensive experiments between three large datasets, Market-1501, DukeMTMC-reID and MSMT17. Surprisingly, introducing only attention can achieve state-of-the-art performance, even much better than those cross-domain Re-ID methods utilizing auxiliary information from the target domain.", "published": "2019-05-30T02:17:07Z", "version": 1}, {"aid": "1905.12837", "authors": ["Haijun Liu", "Jian Cheng", "Wen Wang", "Yanzhou Su"], "title": "The General Pair-based Weighting Loss for Deep Metric Learning", "url": "http://arxiv.org/pdf/1905.12837v1", "summary": "Deep metric learning aims at learning the distance metric between pair of samples, through the deep neural networks to extract the semantic feature embeddings where similar samples are close to each other while dissimilar samples are farther apart. A large amount of loss functions based on pair distances have been presented in the literature for guiding the training of deep metric learning. In this paper, we unify them in a general pair-based weighting loss function, where the minimizing objective loss is just the distances weighting of informative pairs. The general pair-based weighting loss includes two main aspects, (1) samples mining and (2) pairs weighting. Samples mining aims at selecting the informative positive and negative pair sets to exploit the structured relationship of samples in a mini-batch and also reduce the number of non-trivial pairs. Pair weighting aims at assigning different weights for different pairs according to the pair distances for discriminatively training the network. We detailedly review those existing pair-based losses inline with our general loss function, and explore some possible methods from the perspective of samples mining and pairs weighting. Finally, extensive experiments on three image retrieval datasets show that our general pair-based weighting loss obtains new state-of-the-art performance, demonstrating the effectiveness of the pair-based samples mining and pairs weighting for deep metric learning.", "published": "2019-05-30T02:59:26Z", "version": 1}, {"aid": "1905.12871", "authors": ["Hideaki Hayashi", "Seiichi Uchida"], "title": "A Trainable Multiplication Layer for Auto-correlation and Co-occurrence Extraction", "url": "http://arxiv.org/pdf/1905.12871v1", "summary": "In this paper, we propose a trainable multiplication layer (TML) for a neural network that can be used to calculate the multiplication between the input features. Taking an image as an input, the TML raises each pixel value to the power of a weight and then multiplies them, thereby extracting the higher-order local auto-correlation from the input image. The TML can also be used to extract co-occurrence from the feature map of a convolutional network. The training of the TML is formulated based on backpropagation with constraints to the weights, enabling us to learn discriminative multiplication patterns in an end-to-end manner. In the experiments, the characteristics of the TML are investigated by visualizing learned kernels and the corresponding output features. The applicability of the TML for classification and neural network interpretation is also evaluated using public datasets.", "published": "2019-05-30T06:21:54Z", "version": 1}, {"aid": "1905.13049", "authors": ["Xiaoran Xu", "Wei Feng", "Zhiqing Sun", "Zhi-Hong Deng"], "title": "Neural Consciousness Flow", "url": "http://arxiv.org/pdf/1905.13049v1", "summary": "The ability of reasoning beyond data fitting is substantial to deep learning systems in order to make a leap forward towards artificial general intelligence. A lot of efforts have been made to model neural-based reasoning as an iterative decision-making process based on recurrent networks and reinforcement learning. Instead, inspired by the consciousness prior proposed by Yoshua Bengio, we explore reasoning with the notion of attentive awareness from a cognitive perspective, and formulate it in the form of attentive message passing on graphs, called neural consciousness flow (NeuCFlow). Aiming to bridge the gap between deep learning systems and reasoning, we propose an attentive computation framework with a three-layer architecture, which consists of an unconsciousness flow layer, a consciousness flow layer, and an attention flow layer. We implement the NeuCFlow model with graph neural networks (GNNs) and conditional transition matrices. Our attentive computation greatly reduces the complexity of vanilla GNN-based methods, capable of running on large-scale graphs. We validate our model for knowledge graph reasoning by solving a series of knowledge base completion (KBC) tasks. The experimental results show NeuCFlow significantly outperforms previous state-of-the-art KBC methods, including the embedding-based and the path-based. The reproducible code can be found by the link below.", "published": "2019-05-30T13:33:55Z", "version": 1}, {"aid": "1905.13211", "authors": ["Keyulu Xu", "Jingling Li", "Mozhi Zhang", "Simon S. Du", "Ken-ichi Kawarabayashi", "Stefanie Jegelka"], "title": "What Can Neural Networks Reason About?", "url": "http://arxiv.org/pdf/1905.13211v4", "summary": "Neural networks have succeeded in many reasoning tasks. Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, but less structured networks fail. Theoretically, there is limited understanding of why and when a network structure generalizes better than others, although they have equal expressive power. In this paper, we develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. We formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. As an example, we unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP). We show that GNNs align with DP and thus are expected to solve these tasks. On several reasoning tasks, our theory is supported by empirical results.", "published": "2019-05-30T17:53:30Z", "version": 4}, {"aid": "1906.01703", "authors": ["Jiawei Zhang"], "title": "Basic Neural Units of the Brain: Neurons, Synapses and Action Potential", "url": "http://arxiv.org/pdf/1906.01703v1", "summary": "As a follow-up tutorial article of [29], in this paper, we will introduce the basic compositional units of the human brain, which will further illustrate the cell-level bio-structure of the brain. On average, the human brain contains about 100 billion neurons and many more neuroglia which serve to support and protect the neurons. Each neuron may be connected to up to 10,000 other neurons, passing signals to each other via as many as 1,000 trillion synapses. In the nervous system, a synapse is a structure that permits a neuron to pass an electrical or chemical signal to another neuron or to the target effector cell. Such signals will be accumulated as the membrane potential of the neurons, and it will trigger and pass the signal pulse (i.e., action potential) to other neurons when the membrane potential is greater than a precisely defined threshold voltage. To be more specific, in this paper, we will talk about the neurons, synapses and the action potential concepts in detail. Many of the materials used in this paper are from wikipedia and several other neuroscience introductory articles, which will be properly cited in this paper. This is the second of the three tutorial articles about the brain (the other two are [29] and [28]). The readers are suggested to read the previous tutorial article [29] to get more background information about the brain structure and functions prior to reading this paper.", "published": "2019-05-30T23:11:57Z", "version": 1}, {"aid": "1905.13386", "authors": ["Kai Rothauge", "Zhewei Yao", "Zixi Hu", "Michael W. Mahoney"], "title": "Residual Networks as Nonlinear Systems: Stability Analysis using Linearization", "url": "http://arxiv.org/pdf/1905.13386v1", "summary": "We regard pre-trained residual networks (ResNets) as nonlinear systems and use linearization, a common method used in the qualitative analysis of nonlinear systems, to understand the behavior of the networks under small perturbations of the input images. We work with ResNet-56 and ResNet-110 trained on the CIFAR-10 data set. We linearize these networks at the level of residual units and network stages, and the singular value decomposition is used in the stability analysis of these components. It is found that most of the singular values of the linearizations of residual units are 1 and, in spite of the fact that the linearizations depend directly on the activation maps, the singular values differ only slightly for different input images. However, adjusting the scaling of the skip connection or the values of the weights in a residual unit has a significant impact on the singular value distributions. Inspection of how random and adversarial perturbations of input images propagate through the network reveals that there is a dramatic jump in the magnitude of adversarial perturbations towards the end of the final stage of the network that is not present in the case of random perturbations. We attempt to gain a better understanding of this phenomenon by projecting the perturbations onto singular vectors of the linearizations of the residual units.", "published": "2019-05-31T02:44:28Z", "version": 1}, {"aid": "1905.13388", "authors": ["Haonan Wang", "Jun Lin", "Zhongfeng Wang"], "title": "Design Light-weight 3D Convolutional Networks for Video Recognition Temporal Residual, Fully Separable Block, and Fast Algorithm", "url": "http://arxiv.org/pdf/1905.13388v1", "summary": "Deep 3-dimensional (3D) Convolutional Network (ConvNet) has shown promising performance on video recognition tasks because of its powerful spatio-temporal information fusion ability. However, the extremely intensive requirements on memory access and computing power prohibit it from being used in resource-constrained scenarios, such as portable and edge devices. So in this paper, we first propose a two-stage Fully Separable Block (FSB) to significantly compress the model sizes of 3D ConvNets. Then a feature enhancement approach named Temporal Residual Gradient (TRG) is developed to improve the performance of compressed model on video tasks, which provides higher accuracy, faster convergency and better robustness. Moreover, in order to further decrease the computing workload, we propose a hybrid Fast Algorithm (hFA) to drastically reduce the computation complexity of convolutions. These methods are effectively combined to design a light-weight and efficient ConvNet for video recognition tasks. Experiments on the popular dataset report 2.3x compression rate, 3.6x workload reduction, and 6.3% top-1 accuracy gain, over the state-of-the-art SlowFast model, which is already a highly compact model. The proposed methods also show good adaptability on traditional 3D ConvNet, demonstrating 7.4x more compact model, 11.0x less workload, and 3.0% higher accuracy", "published": "2019-05-31T02:48:21Z", "version": 1}, {"aid": "1906.00025", "authors": ["Heinrich Jiang", "Maya Gupta"], "title": "Minimum-Margin Active Learning", "url": "http://arxiv.org/pdf/1906.00025v1", "summary": "We present a new active sampling method we call min-margin which trains multiple learners on bootstrap samples and then chooses the examples to label based on the candidates' minimum margin amongst the bootstrapped models. This extends standard margin sampling in a way that increases its diversity in a supervised manner as it arises from the model uncertainty. We focus on the one-shot batch active learning setting, and show theoretically and through extensive experiments on a broad set of problems that min-margin outperforms other methods, particularly as batch size grows.", "published": "2019-05-31T18:32:18Z", "version": 1}, {"aid": "1906.00131", "authors": ["Arsh Javed Rehman", "Pradeep Tomar"], "title": "Decision-Making in Reinforcement Learning", "url": "http://arxiv.org/pdf/1906.00131v1", "summary": "In this research work, probabilistic decision-making approaches are studied, e.g. Bayesian and Boltzmann strategies, along with various deterministic exploration strategies, e.g. greedy, epsilon-Greedy and random approaches. In this research work, a comparative study has been done between probabilistic and deterministic decision-making approaches, the experiments are performed in OpenAI gym environment, solving Cart Pole problem. This research work discusses about the Bayesian approach to decision-making in deep reinforcement learning, and about dropout, how it can reduce the computational cost. All the exploration approaches are compared. It also discusses about the importance of exploration in deep reinforcement learning, and how improving exploration strategies may help in science and technology. This research work shows how probabilistic decision-making approaches are better in the long run as compared to the deterministic approaches. When there is uncertainty, Bayesian dropout approach proved to be better than all other approaches in this research work.", "published": "2019-06-01T02:36:42Z", "version": 1}, {"aid": "1906.00180", "authors": ["Mathijs Mul", "Willem Zuidema"], "title": "Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization", "url": "http://arxiv.org/pdf/1906.00180v1", "summary": "Can neural nets learn logic? We approach this classic question with current methods, and demonstrate that recurrent neural networks can learn to recognize first order logical entailment relations between expressions. We define an artificial language in first-order predicate logic, generate a large dataset of sample 'sentences', and use an automatic theorem prover to infer the relation between random pairs of such sentences. We describe a Siamese neural architecture trained to predict the logical relation, and experiment with recurrent and recursive networks. Siamese Recurrent Networks are surprisingly successful at the entailment recognition task, reaching near perfect performance on novel sentences (consisting of known words), and even outperforming recursive networks. We report a series of experiments to test the ability of the models to perform compositional generalization. In particular, we study how they deal with sentences of unseen length, and sentences containing unseen words. We show that set-ups using LSTMs and GRUs obtain high scores on these tests, demonstrating a form of compositionality.", "published": "2019-06-01T08:17:42Z", "version": 1}, {"aid": "1906.00184", "authors": ["Jianxin Lin", "Yingce Xia", "Sen Liu", "Shuqin Zhao", "Zhibo Chen"], "title": "ZstGAN: An Adversarial Approach for Unsupervised Zero-Shot Image-to-Image Translation", "url": "http://arxiv.org/pdf/1906.00184v2", "summary": "Image-to-image translation models have shown remarkable ability on transferring images among different domains. Most of existing work follows the setting that the source domain and target domain keep the same at training and inference phases, which cannot be generalized to the scenarios for translating an image from an unseen domain to another unseen domain. In this work, we propose the Unsupervised Zero-Shot Image-to-image Translation (UZSIT) problem, which aims to learn a model that can translate samples from image domains that are not observed during training. Accordingly, we propose a framework called ZstGAN: By introducing an adversarial training scheme, ZstGAN learns to model each domain with domain-specific feature distribution that is semantically consistent on vision and attribute modalities. Then the domain-invariant features are disentangled with an shared encoder for image generation. We carry out extensive experiments on CUB and FLO datasets, and the results demonstrate the effectiveness of proposed method on UZSIT task. Moreover, ZstGAN shows significant accuracy improvements over state-of-the-art zero-shot learning methods on CUB and FLO.", "published": "2019-06-01T08:43:44Z", "version": 2}, {"aid": "1906.00254", "authors": ["Ivan Kiskin", "Udeepa Meepegama", "Steven Roberts"], "title": "Super-resolution of Time-series Labels for Bootstrapped Event Detection", "url": "http://arxiv.org/pdf/1906.00254v1", "summary": "Solving real-world problems, particularly with deep learning, relies on the availability of abundant, quality data. In this paper we develop a novel framework that maximises the utility of time-series datasets that contain only small quantities of expertly-labelled data, larger quantities of weakly (or coarsely) labelled data and a large volume of unlabelled data. This represents scenarios commonly encountered in the real world, such as in crowd-sourcing applications. In our work, we use a nested loop using a Kernel Density Estimator (KDE) to super-resolve the abundant low-quality data labels, thereby enabling effective training of a Convolutional Neural Network (CNN). We demonstrate two key results: a) The KDE is able to super-resolve labels more accurately, and with better calibrated probabilities, than well-established classifiers acting as baselines; b) Our CNN, trained on super-resolved labels from the KDE, achieves an improvement in F1 score of 22.1% over the next best baseline system in our candidate problem domain.", "published": "2019-06-01T16:29:50Z", "version": 1}, {"aid": "1906.00332", "authors": ["Haekyu Park", "Fred Hohman", "Duen Horng Chau"], "title": "NeuralDivergence: Exploring and Understanding Neural Networks by Comparing Activation Distributions", "url": "http://arxiv.org/pdf/1906.00332v1", "summary": "As deep neural networks are increasingly used in solving high-stake problems, there is a pressing need to understand their internal decision mechanisms. Visualization has helped address this problem by assisting with interpreting complex deep neural networks. However, current tools often support only single data instances, or visualize layers in isolation. We present NeuralDivergence, an interactive visualization system that uses activation distributions as a high-level summary of what a model has learned. NeuralDivergence enables users to interactively summarize and compare activation distributions across layers, classes, and instances (e.g., pairs of adversarial attacked and benign images), helping them gain better understanding of neural network models.", "published": "2019-06-02T03:03:51Z", "version": 1}, {"aid": "1906.00446", "authors": ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2", "url": "http://arxiv.org/pdf/1906.00446v1", "summary": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before. We use simple feed-forward encoder and decoder networks, making our model an attractive candidate for applications where the encoding and/or decoding speed is critical. Additionally, VQ-VAE requires sampling an autoregressive model only in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.", "published": "2019-06-02T16:46:42Z", "version": 1}, {"aid": "1906.00511", "authors": ["Christian Meisel", "Rima El Atrache", "Michele Jackson", "Sarah Schubach", "Claire Ufongene", "Tobias Loddenkemper"], "title": "Deep learning from wristband sensor data: towards wearable, non-invasive seizure forecasting", "url": "http://arxiv.org/pdf/1906.00511v2", "summary": "Seizure forecasting may provide patients with timely warnings to adapt their daily activities and help clinicians deliver more objective, personalized treatments. While recent work has convincingly demonstrated that seizure risk assessment is possible, these early approaches relied largely on complex, often invasive setups including intracranial electrocorticography, implanted devices and multi-channel EEG, which limits translation of these methods to broad clinical application. To facilitate broader adaptation of seizure forecasting in clinical practice, non-invasive, easily applicable techniques that reliably assess seizure risk, in combination with clinical information, are crucial. Wristbands that continuously record physiological parameters, including electrodermal activity, body temperature, blood volume pressure and actigraphy, may afford monitoring of autonomous nervous system function and movement relevant for such a task, hence minimizing potential complications associated with invasive monitoring, and avoiding stigma associated with bulky external monitoring devices on the head. Here, we use deep learning to analyze long-term, multi-modal wristband sensor data from 50 patients with epilepsy (total duration $>$1400 hours) to assess its capability to distinguish preictal from interictal states. Prediction performance is assessed using area under the receiver operating charateristic (AUC) and improvement over chance (IoC) based on F1 scores. Using one- and two-dimensional convolutional neural networks, we identified better-than-chance predictability in out-of-sample test data in 60\\% of the patients in leave-one-out and 43\\% of patients in pseudo-prospective approaches. These results provide a step towards developing easier to apply, non-invasive methods for seizure risk assessments in patients with epilepsy.", "published": "2019-06-03T00:34:55Z", "version": 2}, {"aid": "1906.00532", "authors": ["Aishwarya Bhandare", "Vamsi Sripathi", "Deepthi Karkada", "Vivek Menon", "Sun Choi", "Kushal Datta", "Vikram Saletore"], "title": "Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model", "url": "http://arxiv.org/pdf/1906.00532v2", "summary": "In this work, we quantize a trained Transformer machine language translation model leveraging INT8/VNNI instructions in the latest Intel$^\\circledR$ Xeon$^\\circledR$ Cascade Lake processors to improve inference performance while maintaining less than 0.5$\\%$ drop in accuracy. To the best of our knowledge, this is the first attempt in the industry to quantize the Transformer model. This has high impact as it clearly demonstrates the various complexities of quantizing the language translation model. We present novel quantization techniques directly in TensorFlow to opportunistically replace 32-bit floating point (FP32) computations with 8-bit integers (INT8) and transform the FP32 computational graph. We also present a bin-packing parallel batching technique to maximize CPU utilization. Overall, our optimizations with INT8/VNNI deliver 1.5X improvement over the best FP32 performance. Furthermore, it reveals the opportunities and challenges to boost performance of quantized deep learning inference and establishes best practices to run inference with high efficiency on Intel CPUs.", "published": "2019-06-03T02:29:22Z", "version": 2}, {"aid": "1906.00586", "authors": ["Mitchell Wortsman", "Ali Farhadi", "Mohammad Rastegari"], "title": "Discovering Neural Wirings", "url": "http://arxiv.org/pdf/1906.00586v5", "summary": "The success of neural networks has driven a shift in focus from feature engineering to architecture engineering. However, successful networks today are constructed using a small and manually defined set of building blocks. Even in methods of neural architecture search (NAS) the network connectivity patterns are largely constrained. In this work we propose a method for discovering neural wirings. We relax the typical notion of layers and instead enable channels to form connections independent of each other. This allows for a much larger space of possible networks. The wiring of our network is not fixed during training -- as we learn the network parameters we also learn the structure itself. Our experiments demonstrate that our learned connectivity outperforms hand engineered and randomly wired networks. By learning the connectivity of MobileNetV1we boost the ImageNet accuracy by 10% at ~41M FLOPs. Moreover, we show that our method generalizes to recurrent and continuous time networks. Our work may also be regarded as unifying core aspects of the neural architecture search problem with sparse neural network learning. As NAS becomes more fine grained, finding a good architecture is akin to finding a sparse subnetwork of the complete graph. Accordingly, DNW provides an effective mechanism for discovering sparse subnetworks of predefined architectures in a single training run. Though we only ever use a small percentage of the weights during the forward pass, we still play the so-called initialization lottery with a combinatorial number of subnetworks. Code and pretrained models are available at https://github.com/allenai/dnw while additional visualizations may be found at https://mitchellnw.github.io/blog/2019/dnw/.", "published": "2019-06-03T05:58:33Z", "version": 5}, {"aid": "1906.00695", "authors": ["Johannes von Oswald", "Christian Henning", "Benjamin F. Grewe", "Jo\u00e3o Sacramento"], "title": "Continual learning with hypernetworks", "url": "http://arxiv.org/pdf/1906.00695v4", "summary": "Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned hypernetworks, i.e., networks that generate the weights of a target model based on task identity. Continual learning (CL) is less difficult for this class of models thanks to a simple key feature: instead of recalling the input-output relations of all previously seen data, task-conditioned hypernetworks only require rehearsing task-specific weight realizations, which can be maintained in memory using a simple regularizer. Besides achieving state-of-the-art performance on standard CL benchmarks, additional experiments on long task sequences reveal that task-conditioned hypernetworks display a very large capacity to retain previous memories. Notably, such long memory lifetimes are achieved in a compressive regime, when the number of trainable hypernetwork weights is comparable or smaller than target network size. We provide insight into the structure of low-dimensional task embedding spaces (the input space of the hypernetwork) and show that task-conditioned hypernetworks demonstrate transfer learning. Finally, forward information transfer is further supported by empirical results on a challenging CL benchmark based on the CIFAR-10/100 image datasets.", "published": "2019-06-03T10:45:08Z", "version": 4}, {"aid": "1906.00709", "authors": ["Min-Cheol Sagong", "Yong-Goo Shin", "Yoon-Jae Yeo", "Seung Park", "Sung-Jea Ko"], "title": "cGANs with Conditional Convolution Layer", "url": "http://arxiv.org/pdf/1906.00709v2", "summary": "Conditional generative adversarial networks (cGANs) have been widely researched to generate class conditional images using a single generator. However, in the conventional cGANs techniques, it is still challenging for the generator to learn condition-specific features, since a standard convolutional layer with the same weights is used regardless of the condition. In this paper, we propose a novel convolution layer, called the conditional convolution layer, which directly generates different feature maps by employing the weights which are adjusted depending on the conditions. More specifically, in each conditional convolution layer, the weights are conditioned in a simple but effective way through filter-wise scaling and channel-wise shifting operations. In contrast to the conventional methods, the proposed method with a single generator can effectively handle condition-specific characteristics. The experimental results on CIFAR, LSUN and ImageNet datasets show that the generator with the proposed conditional convolution layer achieves a higher quality of conditional image generation than that with the standard convolution layer.", "published": "2019-06-03T11:15:51Z", "version": 2}, {"aid": "1906.00889", "authors": ["Benjamin James Lansdell", "Prashanth Ravi Prakash", "Konrad Paul Kording"], "title": "Learning to solve the credit assignment problem", "url": "http://arxiv.org/pdf/1906.00889v4", "summary": "Backpropagation is driving today's artificial neural networks (ANNs). However, despite extensive research, it remains unclear if the brain implements this algorithm. Among neuroscientists, reinforcement learning (RL) algorithms are often seen as a realistic alternative: neurons can randomly introduce change, and use unspecific feedback signals to observe their effect on the cost and thus approximate their gradient. However, the convergence rate of such learning scales poorly with the number of involved neurons. Here we propose a hybrid learning approach. Each neuron uses an RL-type strategy to learn how to approximate the gradients that backpropagation would provide. We provide proof that our approach converges to the true gradient for certain classes of networks. In both feedforward and convolutional networks, we empirically show that our approach learns to approximate the gradient, and can match or the performance of exact gradient-based learning. Learning feedback weights provides a biologically plausible mechanism of achieving good performance, without the need for precise, pre-specified learning rules.", "published": "2019-06-03T15:48:38Z", "version": 4}, {"aid": "1906.00917", "authors": ["Yichang Wang", "R\u00e9mi Emonet", "Elisa Fromont", "Simon Malinowski", "Etienne Menager", "Lo\u00efc Mosser", "Romain Tavenard"], "title": "Learning Interpretable Shapelets for Time Series Classification through Adversarial Regularization", "url": "http://arxiv.org/pdf/1906.00917v2", "summary": "Times series classification can be successfully tackled by jointly learning a shapelet-based representation of the series in the dataset and classifying the series according to this representation. However, although the learned shapelets are discriminative, they are not always similar to pieces of a real series in the dataset. This makes it difficult to interpret the decision, i.e. difficult to analyze if there are particular behaviors in a series that triggered the decision. In this paper, we make use of a simple convolutional network to tackle the time series classification task and we introduce an adversarial regularization to constrain the model to learn more interpretable shapelets. Our classification results on all the usual time series benchmarks are comparable with the results obtained by similar state-of-the-art algorithms but our adversarially regularized method learns shapelets that are, by design, interpretable.", "published": "2019-06-03T16:38:20Z", "version": 2}, {"aid": "1906.00925", "authors": ["Yawei Li", "Vagia Tsiminaki", "Radu Timofte", "Marc Pollefeys", "Luc van Gool"], "title": "3D Appearance Super-Resolution with Deep Learning", "url": "http://arxiv.org/pdf/1906.00925v2", "summary": "We tackle the problem of retrieving high-resolution (HR) texture maps of objects that are captured from multiple view points. In the multi-view case, model-based super-resolution (SR) methods have been recently proved to recover high quality texture maps. On the other hand, the advent of deep learning-based methods has already a significant impact on the problem of video and image SR. Yet, a deep learning-based approach to super-resolve the appearance of 3D objects is still missing. The main limitation of exploiting the power of deep learning techniques in the multi-view case is the lack of data. We introduce a 3D appearance SR (3DASR) dataset based on the existing ETH3D [42], SyB3R [31], MiddleBury, and our Collection of 3D scenes from TUM [21], Fountain [51] and Relief [53]. We provide the high- and low-resolution texture maps, the 3D geometric model, images and projection matrices. We exploit the power of 2D learning-based SR methods and design networks suitable for the 3D multi-view case. We incorporate the geometric information by introducing normal maps and further improve the learning process. Experimental results demonstrate that our proposed networks successfully incorporate the 3D geometric information and super-resolve the texture maps.", "published": "2019-06-03T16:51:35Z", "version": 2}, {"aid": "1906.01039", "authors": ["Guruprasad Raghavan", "Matt Thomson"], "title": "Neural networks grown and self-organized by noise", "url": "http://arxiv.org/pdf/1906.01039v1", "summary": "Living neural networks emerge through a process of growth and self-organization that begins with a single cell and results in a brain, an organized and functional computational device. Artificial neural networks, however, rely on human-designed, hand-programmed architectures for their remarkable performance. Can we develop artificial computational devices that can grow and self-organize without human intervention? In this paper, we propose a biologically inspired developmental algorithm that can 'grow' a functional, layered neural network from a single initial cell. The algorithm organizes inter-layer connections to construct a convolutional pooling layer, a key constituent of convolutional neural networks (CNN's). Our approach is inspired by the mechanisms employed by the early visual system to wire the retina to the lateral geniculate nucleus (LGN), days before animals open their eyes. The key ingredients for robust self-organization are an emergent spontaneous spatiotemporal activity wave in the first layer and a local learning rule in the second layer that 'learns' the underlying activity pattern in the first layer. The algorithm is adaptable to a wide-range of input-layer geometries, robust to malfunctioning units in the first layer, and so can be used to successfully grow and self-organize pooling architectures of different pool-sizes and shapes. The algorithm provides a primitive procedure for constructing layered neural networks through growth and self-organization. Broadly, our work shows that biologically inspired developmental algorithms can be applied to autonomously grow functional 'brains' in-silico.", "published": "2019-06-03T19:33:39Z", "version": 1}, {"aid": "1906.01166", "authors": ["Yuchao Li", "Rongrong Ji", "Shaohui Lin", "Baochang Zhang", "Chenqian Yan", "Yongjian Wu", "Feiyue Huang", "Ling Shao"], "title": "Interpretable Neural Network Decoupling", "url": "http://arxiv.org/pdf/1906.01166v2", "summary": "The remarkable performance of convolutional neural networks (CNNs) is entangled with their huge number of uninterpretable parameters, which has become the bottleneck limiting the exploitation of their full potential. Towards network interpretation, previous endeavors mainly resort to the single filter analysis, which however ignores the relationship between filters. In this paper, we propose a novel architecture decoupling method to interpret the network from a perspective of investigating its calculation paths. More specifically, we introduce a novel architecture controlling module in each layer to encode the network architecture by a vector. By maximizing the mutual information between the vectors and input images, the module is trained to select specific filters to distill a unique calculation path for each input. Furthermore, to improve the interpretability and compactness of the decoupled network, the output of each layer is encoded to align the architecture encoding vector with the constraint of sparsity regularization. Unlike conventional pixel-level or filter-level network interpretation methods, we propose a path-level analysis to explore the relationship between the combination of filter and semantic concepts, which is more suitable to interpret the working rationale of the decoupled network. Extensive experiments show that the decoupled network achieves several applications, i.e., network interpretation, network acceleration, and adversarial samples detection.", "published": "2019-06-04T02:40:38Z", "version": 2}, {"aid": "1906.01984", "authors": ["Xianxu Hou", "Ke Sun", "Linlin Shen", "Guoping Qiu"], "title": "Improving Variational Autoencoder with Deep Feature Consistent and Generative Adversarial Training", "url": "http://arxiv.org/pdf/1906.01984v1", "summary": "We present a new method for improving the performances of variational autoencoder (VAE). In addition to enforcing the deep feature consistent principle thus ensuring the VAE output and its corresponding input images to have similar deep features, we also implement a generative adversarial training mechanism to force the VAE to output realistic and natural images. We present experimental results to show that the VAE trained with our new method outperforms state of the art in generating face images with much clearer and more natural noses, eyes, teeth, hair textures as well as reasonable backgrounds. We also show that our method can learn powerful embeddings of input face images, which can be used to achieve facial attribute manipulation. Moreover we propose a multi-view feature extraction strategy to extract effective image representations, which can be used to achieve state of the art performance in facial attribute prediction.", "published": "2019-06-04T03:17:30Z", "version": 1}, {"aid": "1906.01234", "authors": ["Kris Korrel", "Dieuwke Hupkes", "Verna Dankers", "Elia Bruni"], "title": "Transcoding compositionally: using attention to find more generalizable solutions", "url": "http://arxiv.org/pdf/1906.01234v2", "summary": "While sequence-to-sequence models have shown remarkable generalization power across several natural language tasks, their construct of solutions are argued to be less compositional than human-like generalization. In this paper, we present seq2attn, a new architecture that is specifically designed to exploit attention to find compositional patterns in the input. In seq2attn, the two standard components of an encoder-decoder model are connected via a transcoder, that modulates the information flow between them. We show that seq2attn can successfully generalize, without requiring any additional supervision, on two tasks which are specifically constructed to challenge the compositional skills of neural networks. The solutions found by the model are highly interpretable, allowing easy analysis of both the types of solutions that are found and potential causes for mistakes. We exploit this opportunity to introduce a new paradigm to test compositionality that studies the extent to which a model overgeneralizes when confronted with exceptions. We show that seq2attn exhibits such overgeneralization to a larger degree than a standard sequence-to-sequence model.", "published": "2019-06-04T07:07:56Z", "version": 2}, {"aid": "1906.01478", "authors": ["Laura Thesing", "Vegard Antun", "Anders C. Hansen"], "title": "What do AI algorithms actually learn? - On false structures in deep learning", "url": "http://arxiv.org/pdf/1906.01478v1", "summary": "There are two big unsolved mathematical questions in artificial intelligence (AI): (1) Why is deep learning so successful in classification problems and (2) why are neural nets based on deep learning at the same time universally unstable, where the instabilities make the networks vulnerable to adversarial attacks. We present a solution to these questions that can be summed up in two words; false structures. Indeed, deep learning does not learn the original structures that humans use when recognising images (cats have whiskers, paws, fur, pointy ears, etc), but rather different false structures that correlate with the original structure and hence yield the success. However, the false structure, unlike the original structure, is unstable. The false structure is simpler than the original structure, hence easier to learn with less data and the numerical algorithm used in the training will more easily converge to the neural network that captures the false structure. We formally define the concept of false structures and formulate the solution as a conjecture. Given that trained neural networks always are computed with approximations, this conjecture can only be established through a combination of theoretical and computational results similar to how one establishes a postulate in theoretical physics (e.g. the speed of light is constant). Establishing the conjecture fully will require a vast research program characterising the false structures. We provide the foundations for such a program establishing the existence of the false structures in practice. Finally, we discuss the far reaching consequences the existence of the false structures has on state-of-the-art AI and Smale's 18th problem.", "published": "2019-06-04T14:35:32Z", "version": 1}, {"aid": "1906.01529", "authors": ["Zhengwei Wang", "Qi She", "Tomas E. Ward"], "title": "Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy", "url": "http://arxiv.org/pdf/1906.01529v6", "summary": "Generative adversarial networks (GANs) have been extensively studied in the past few years. Arguably their most significant impact has been in the area of computer vision where great advances have been made in challenges such as plausible image generation, image-to-image translation, facial attribute manipulation and similar domains. Despite the significant successes achieved to date, applying GANs to real-world problems still poses significant challenges, three of which we focus on here. These are: (1) the generation of high quality images, (2) diversity of image generation, and (3) stable training. Focusing on the degree to which popular GAN technologies have made progress against these challenges, we provide a detailed review of the state of the art in GAN-related research in the published scientific literature. We further structure this review through a convenient taxonomy we have adopted based on variations in GAN architectures and loss functions. While several reviews for GANs have been presented to date, none have considered the status of this field based on their progress towards addressing practical challenges relevant to computer vision. Accordingly, we review and critically discuss the most popular architecture-variant, and loss-variant GANs, for tackling these challenges. Our objective is to provide an overview as well as a critical analysis of the status of GAN research in terms of relevant progress towards important computer vision application requirements. As we do this we also discuss the most compelling applications in computer vision in which GANs have demonstrated considerable success along with some suggestions for future research directions. Code related to GAN-variants studied in this work is summarized on https://github.com/sheqi/GAN_Review.", "published": "2019-06-04T15:40:53Z", "version": 6}, {"aid": "1906.02182", "authors": ["Huijuan Xu", "Abir Das", "Kate Saenko"], "title": "Two-Stream Region Convolutional 3D Network for Temporal Activity Detection", "url": "http://arxiv.org/pdf/1906.02182v1", "summary": "We address the problem of temporal activity detection in continuous, untrimmed video streams. This is a difficult task that requires extracting meaningful spatio-temporal features to capture activities, accurately localizing the start and end times of each activity. We introduce a new model, Region Convolutional 3D Network (R-C3D), which encodes the video streams using a three-dimensional fully convolutional network, then generates candidate temporal regions containing activities and finally classifies selected regions into specific activities. Computation is saved due to the sharing of convolutional features between the proposal and the classification pipelines. We further improve the detection performance by efficiently integrating an optical flow based motion stream with the original RGB stream. The two-stream network is jointly optimized by fusing the flow and RGB feature maps at different levels. Additionally, the training stage incorporates an online hard example mining strategy to address the extreme foreground-background imbalance typically observed in any detection pipeline. Instead of heuristically sampling the candidate segments for the final activity classification stage, we rank them according to their performance and only select the worst performers to update the model. This improves the model without heavy hyper-parameter tuning. Extensive experiments on three benchmark datasets are carried out to show superior performance over existing temporal activity detection methods. Our model achieves state-of-the-art results on the THUMOS'14 and Charades datasets. We further demonstrate that our model is a general temporal activity detection framework that does not rely on assumptions about particular dataset properties by evaluating our approach on the ActivityNet dataset.", "published": "2019-06-05T02:48:37Z", "version": 1}, {"aid": "1906.01862", "authors": ["Pierrick Coup\u00e9", "Boris Mansencal", "Micha\u00ebl Cl\u00e9ment", "R\u00e9mi Giraud", "Baudouin Denis de Senneville", "Vinh-Thong Ta", "Vincent Lepetit", "Jos\u00e9 V. Manjon"], "title": "AssemblyNet: A Novel Deep Decision-Making Process for Whole Brain MRI Segmentation", "url": "http://arxiv.org/pdf/1906.01862v1", "summary": "Whole brain segmentation using deep learning (DL) is a very challenging task since the number of anatomical labels is very high compared to the number of available training images. To address this problem, previous DL methods proposed to use a global convolution neural network (CNN) or few independent CNNs. In this paper, we present a novel ensemble method based on a large number of CNNs processing different overlapping brain areas. Inspired by parliamentary decision-making systems, we propose a framework called AssemblyNet, made of two \"assemblies\" of U-Nets. Such a parliamentary system is capable of dealing with complex decisions and reaching a consensus quickly. AssemblyNet introduces sharing of knowledge among neighboring U-Nets, an \"amendment\" procedure made by the second assembly at higher-resolution to refine the decision taken by the first one, and a final decision obtained by majority voting. When using the same 45 training images, AssemblyNet outperforms global U-Net by 28% in terms of the Dice metric, patch-based joint label fusion by 15% and SLANT-27 by 10%. Finally, AssemblyNet demonstrates high capacity to deal with limited training data to achieve whole brain segmentation in practical training and testing times.", "published": "2019-06-05T07:35:37Z", "version": 1}, {"aid": "1906.02076", "authors": ["David Calhas", "Enrique Romero", "Rui Henriques"], "title": "On the use of Pairwise Distance Learning for Brain Signal Classification with Limited Observations", "url": "http://arxiv.org/pdf/1906.02076v2", "summary": "The increasing access to brain signal data using electroencephalography creates new opportunities to study electrophysiological brain activity and perform ambulatory diagnoses of neuronal diseases. This work proposes a pairwise distance learning approach for Schizophrenia classification relying on the spectral properties of the signal. Given the limited number of observations (i.e. the case and/or control individuals) in clinical trials, we propose a Siamese neural network architecture to learn a discriminative feature space from pairwise combinations of observations per channel. In this way, the multivariate order of the signal is used as a form of data augmentation, further supporting the network generalization ability. Convolutional layers with parameters learned under a cosine contrastive loss are proposed to adequately explore spectral images derived from the brain signal. Results on a case-control population show that the features extracted using the proposed neural network lead to an improved Schizophrenia diagnosis (+10pp in accuracy and sensitivity) against spectral features, thus suggesting the existence of non-trivial, discriminative electrophysiological brain patterns.", "published": "2019-06-05T15:36:57Z", "version": 2}, {"aid": "1906.02164", "authors": ["L. Elisa Celis", "Vijay Keswani", "Nisheeth K. Vishnoi"], "title": "Data preprocessing to mitigate bias: A maximum entropy based approach", "url": "http://arxiv.org/pdf/1906.02164v2", "summary": "Data containing human or social attributes may over- or under-represent groups with respect to salient social attributes such as gender or race, which can lead to biases in downstream applications. This paper presents an algorithmic framework that can be used as a data preprocessing method towards mitigating such bias. Unlike prior work, it can efficiently learn distributions over large domains, controllably adjust the representation rates of protected groups and achieve target fairness metrics such as statistical parity, yet remains close to the empirical distribution induced by the given dataset. Our approach leverages the principle of maximum entropy - amongst all distributions satisfying a given set of constraints, we should choose the one closest in KL-divergence to a given prior. While maximum entropy distributions can succinctly encode distributions over large domains, they can be difficult to compute. Our main contribution is an instantiation of this framework for our set of constraints and priors, which encode our bias mitigation goals, and that runs in time polynomial in the dimension of the data. Empirically, we observe that samples from the learned distribution have desired representation rates and statistical rates, and when used for training a classifier incurs only a slight loss in accuracy while maintaining fairness properties.", "published": "2019-06-05T17:54:00Z", "version": 2}, {"aid": "1906.02168", "authors": ["Vaishaal Shankar", "Achal Dave", "Rebecca Roelofs", "Deva Ramanan", "Benjamin Recht", "Ludwig Schmidt"], "title": "Do Image Classifiers Generalize Across Time?", "url": "http://arxiv.org/pdf/1906.02168v3", "summary": "We study the robustness of image classifiers to temporal perturbations derived from videos. As part of this study, we construct two datasets, ImageNet-Vid-Robust and YTBB-Robust , containing a total 57,897 images grouped into 3,139 sets of perceptually similar images. Our datasets were derived from ImageNet-Vid and Youtube-BB respectively and thoroughly re-annotated by human experts for image similarity. We evaluate a diverse array of classifiers pre-trained on ImageNet and show a median classification accuracy drop of 16 and 10 on our two datasets. Additionally, we evaluate three detection models and show that natural perturbations induce both classification as well as localization errors, leading to a median drop in detection mAP of 14 points. Our analysis demonstrates that perturbations occurring naturally in videos pose a substantial and realistic challenge to deploying convolutional neural networks in environments that require both reliable and low-latency predictions", "published": "2019-06-05T17:55:42Z", "version": 3}, {"aid": "1906.02256", "authors": ["Keivan Alizadeh Vahid", "Anish Prabhu", "Ali Farhadi", "Mohammad Rastegari"], "title": "Butterfly Transform: An Efficient FFT Based Neural Architecture Design", "url": "http://arxiv.org/pdf/1906.02256v2", "summary": "In this paper, we show that extending the butterfly operations from the FFT algorithm to a general Butterfly Transform (BFT) can be beneficial in building an efficient block structure for CNN designs. Pointwise convolutions, which we refer to as channel fusions, are the main computational bottleneck in the state-of-the-art efficient CNNs (e.g. MobileNets ). We introduce a set of criteria for channel fusion and prove that BFT yields an asymptotically optimal FLOP count with respect to these criteria. By replacing pointwise convolutions with BFT, we reduce the computational complexity of these layers from O(n^2) to O(n\\log n) with respect to the number of channels. Our experimental evaluations show that our method results in significant accuracy gains across a wide range of network architectures, especially at low FLOP ranges. For example, BFT results in up to a 6.75% absolute Top-1 improvement for MobileNetV1, 4.4 \\% for ShuffleNet V2 and 5.4% for MobileNetV3 on ImageNet under a similar number of FLOPS. Notably, ShuffleNet-V2+BFT outperforms state-of-the-art architecture search methods MNasNet, FBNet and MobilenetV3 in the low FLOP regime.", "published": "2019-06-05T19:04:06Z", "version": 2}, {"aid": "1906.02355", "authors": ["Xuanqing Liu", "Tesi Xiao", "Si Si", "Qin Cao", "Sanjiv Kumar", "Cho-Jui Hsieh"], "title": "Neural SDE: Stabilizing Neural ODE Networks with Stochastic Noise", "url": "http://arxiv.org/pdf/1906.02355v1", "summary": "Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE) network, which naturally incorporates various commonly used regularization mechanisms based on random noise injection. Our framework can model various types of noise injection frequently used in discrete networks for regularization purpose, such as dropout and additive/multiplicative noise in each block. We provide theoretical analysis explaining the improved robustness of Neural SDE models against input perturbations/adversarial attacks. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.", "published": "2019-06-05T23:19:50Z", "version": 1}, {"aid": "1906.02641", "authors": ["Matthew Rahtz", "James Fang", "Anca D. Dragan", "Dylan Hadfield-Menell"], "title": "An Extensible Interactive Interface for Agent Design", "url": "http://arxiv.org/pdf/1906.02641v3", "summary": "In artificial intelligence, we often specify tasks through a reward function. While this works well in some settings, many tasks are hard to specify this way. In deep reinforcement learning, for example, directly specifying a reward as a function of a high-dimensional observation is challenging. Instead, we present an interface for specifying tasks interactively using demonstrations. Our approach defines a set of increasingly complex policies. The interface allows the user to switch between these policies at fixed intervals to generate demonstrations of novel, more complex, tasks. We train new policies based on these demonstrations and repeat the process. We present a case study of our approach in the Lunar Lander domain, and show that this simple approach can quickly learn a successful landing policy and outperforms an existing comparison-based deep RL method.", "published": "2019-06-06T15:18:40Z", "version": 3}, {"aid": "1906.02717", "authors": ["Mikhail Khodak", "Maria-Florina Balcan", "Ameet Talwalkar"], "title": "Adaptive Gradient-Based Meta-Learning Methods", "url": "http://arxiv.org/pdf/1906.02717v3", "summary": "We build a theoretical framework for designing and understanding practical meta-learning methods that integrates sophisticated formalizations of task-similarity with the extensive literature on online convex optimization and sequential prediction algorithms. Our approach enables the task-similarity to be learned adaptively, provides sharper transfer-risk bounds in the setting of statistical learning-to-learn, and leads to straightforward derivations of average-case regret bounds for efficient algorithms in settings where the task-environment changes dynamically or the tasks share a certain geometric structure. We use our theory to modify several popular meta-learning algorithms and improve their meta-test-time performance on standard problems in few-shot learning and federated learning.", "published": "2019-06-06T17:36:34Z", "version": 3}, {"aid": "1906.02858", "authors": ["Joe Mathai", "Iacopo Masi", "Wael AbdAlmageed"], "title": "Does Generative Face Completion Help Face Recognition?", "url": "http://arxiv.org/pdf/1906.02858v1", "summary": "Face occlusions, covering either the majority or discriminative parts of the face, can break facial perception and produce a drastic loss of information. Biometric systems such as recent deep face recognition models are not immune to obstructions or other objects covering parts of the face. While most of the current face recognition methods are not optimized to handle occlusions, there have been a few attempts to improve robustness directly in the training stage. Unlike those, we propose to study the effect of generative face completion on the recognition. We offer a face completion encoder-decoder, based on a convolutional operator with a gating mechanism, trained with an ample set of face occlusions. To systematically evaluate the impact of realistic occlusions on recognition, we propose to play the occlusion game: we render 3D objects onto different face parts, providing precious knowledge of what the impact is of effectively removing those occlusions. Extensive experiments on the Labeled Faces in the Wild (LFW), and its more difficult variant LFW-BLUFR, testify that face completion is able to partially restore face perception in machine vision systems for improved recognition.", "published": "2019-06-07T01:48:28Z", "version": 1}, {"aid": "1906.02909", "authors": ["Wei Wen", "Feng Yan", "Yiran Chen", "Hai Li"], "title": "AutoGrow: Automatic Layer Growing in Deep Convolutional Networks", "url": "http://arxiv.org/pdf/1906.02909v5", "summary": "Depth is a key component of Deep Neural Networks (DNNs), however, designing depth is heuristic and requires many human efforts. We propose AutoGrow to automate depth discovery in DNNs: starting from a shallow seed architecture, AutoGrow grows new layers if the growth improves the accuracy; otherwise, stops growing and thus discovers the depth. We propose robust growing and stopping policies to generalize to different network architectures and datasets. Our experiments show that by applying the same policy to different network architectures, AutoGrow can always discover near-optimal depth on various datasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet. For example, in terms of accuracy-computation trade-off, AutoGrow discovers a better depth combination in ResNets than human experts. Our AutoGrow is efficient. It discovers depth within similar time of training a single DNN. Our code is available at https://github.com/wenwei202/autogrow.", "published": "2019-06-07T05:54:41Z", "version": 5}, {"aid": "1906.02940", "authors": ["Trieu H. Trinh", "Minh-Thang Luong", "Quoc V. Le"], "title": "Selfie: Self-supervised Pretraining for Image Embedding", "url": "http://arxiv.org/pdf/1906.02940v3", "summary": "We introduce a pretraining technique called Selfie, which stands for SELFie supervised Image Embedding. Selfie generalizes the concept of masked language modeling of BERT (Devlin et al., 2019) to continuous data, such as images, by making use of the Contrastive Predictive Coding loss (Oord et al., 2018). Given masked-out patches in an input image, our method learns to select the correct patch, among other \"distractor\" patches sampled from the same image, to fill in the masked location. This classification objective sidesteps the need for predicting exact pixel values of the target patches. The pretraining architecture of Selfie includes a network of convolutional blocks to process patches followed by an attention pooling network to summarize the content of unmasked patches before predicting masked ones. During finetuning, we reuse the convolutional weights found by pretraining. We evaluate Selfie on three benchmarks (CIFAR-10, ImageNet 32 x 32, and ImageNet 224 x 224) with varying amounts of labeled data, from 5% to 100% of the training sets. Our pretraining method provides consistent improvements to ResNet-50 across all settings compared to the standard supervised training of the same network. Notably, on ImageNet 224 x 224 with 60 examples per class (5%), our method improves the mean accuracy of ResNet-50 from 35.6% to 46.7%, an improvement of 11.1 points in absolute accuracy. Our pretraining method also improves ResNet-50 training stability, especially on low data regime, by significantly lowering the standard deviation of test accuracies across different runs.", "published": "2019-06-07T07:47:24Z", "version": 3}, {"aid": "1906.03051", "authors": ["Feihong Liu", "Jun Feng", "Geng Chen", "Ye Wu", "Yoonmi Hong", "Pew-Thian Yap", "Dinggang Shen"], "title": "DeepBundle: Fiber Bundle Parcellation with Graph Convolution Neural Networks", "url": "http://arxiv.org/pdf/1906.03051v2", "summary": "Parcellation of whole-brain tractography streamlines is an important step for tract-based analysis of brain white matter microstructure. Existing fiber parcellation approaches rely on accurate registration between an atlas and the tractograms of an individual, however, due to large individual differences, accurate registration is hard to guarantee in practice. To resolve this issue, we propose a novel deep learning method, called DeepBundle, for registration-free fiber parcellation. Our method utilizes graph convolution neural networks (GCNNs) to predict the parcellation label of each fiber tract. GCNNs are capable of extracting the geometric features of each fiber tract and harnessing the resulting features for accurate fiber parcellation and ultimately avoiding the use of atlases and any registration method. We evaluate DeepBundle using data from the Human Connectome Project. Experimental results demonstrate the advantages of DeepBundle and suggest that the geometric features extracted from each fiber tract can be used to effectively parcellate the fiber tracts.", "published": "2019-06-07T12:37:08Z", "version": 2}, {"aid": "1906.03352", "authors": ["Allan Zhou", "Eric Jang", "Daniel Kappler", "Alex Herzog", "Mohi Khansari", "Paul Wohlhart", "Yunfei Bai", "Mrinal Kalakrishnan", "Sergey Levine", "Chelsea Finn"], "title": "Watch, Try, Learn: Meta-Learning from Demonstrations and Reward", "url": "http://arxiv.org/pdf/1906.03352v4", "summary": "Imitation learning allows agents to learn complex behaviors from demonstrations. However, learning a complex vision-based task may require an impractical number of demonstrations. Meta-imitation learning is a promising approach towards enabling agents to learn a new task from one or a few demonstrations by leveraging experience from learning similar tasks. In the presence of task ambiguity or unobserved dynamics, demonstrations alone may not provide enough information; an agent must also try the task to successfully infer a policy. In this work, we propose a method that can learn to learn from both demonstrations and trial-and-error experience with sparse reward feedback. In comparison to meta-imitation, this approach enables the agent to effectively and efficiently improve itself autonomously beyond the demonstration data. In comparison to meta-reinforcement learning, we can scale to substantially broader distributions of tasks, as the demonstration reduces the burden of exploration. Our experiments show that our method significantly outperforms prior approaches on a set of challenging, vision-based control tasks.", "published": "2019-06-07T22:46:35Z", "version": 4}, {"aid": "1906.03516", "authors": ["Sachin Mehta", "Hannaneh Hajishirzi", "Mohammad Rastegari"], "title": "DiCENet: Dimension-wise Convolutions for Efficient Networks", "url": "http://arxiv.org/pdf/1906.03516v3", "summary": "We introduce a novel and generic convolutional unit, DiCE unit, that is built using dimension-wise convolutions and dimension-wise fusion. The dimension-wise convolutions apply light-weight convolutional filtering across each dimension of the input tensor while dimension-wise fusion efficiently combines these dimension-wise representations; allowing the DiCE unit to efficiently encode spatial and channel-wise information contained in the input tensor. The DiCE unit is simple and can be seamlessly integrated with any architecture to improve its efficiency and performance. Compared to depth-wise separable convolutions, the DiCE unit shows significant improvements across different architectures. When DiCE units are stacked to build the DiCENet model, we observe significant improvements over state-of-the-art models across various computer vision tasks including image classification, object detection, and semantic segmentation. On the ImageNet dataset, the DiCENet delivers 2-4% higher accuracy than state-of-the-art manually designed models (e.g., MobileNetv2 and ShuffleNetv2). Also, DiCENet generalizes better to tasks (e.g., object detection) that are often used in resource-constrained devices in comparison to state-of-the-art separable convolution-based efficient networks, including neural search-based methods (e.g., MobileNetv3 and MixNet. Our source code in PyTorch is open-source and is available at https://github.com/sacmehta/EdgeNets/", "published": "2019-06-08T20:17:06Z", "version": 3}, {"aid": "1906.04721", "authors": ["Markus Nagel", "Mart van Baalen", "Tijmen Blankevoort", "Max Welling"], "title": "Data-Free Quantization Through Weight Equalization and Bias Correction", "url": "http://arxiv.org/pdf/1906.04721v3", "summary": "We introduce a data-free quantization method for deep neural networks that does not require fine-tuning or hyperparameter selection. It achieves near-original model performance on common computer vision architectures and tasks. 8-bit fixed-point quantization is essential for efficient inference on modern deep learning hardware. However, quantizing models to run in 8-bit is a non-trivial task, frequently leading to either significant performance reduction or engineering time spent on training a network to be amenable to quantization. Our approach relies on equalizing the weight ranges in the network by making use of a scale-equivariance property of activation functions. In addition the method corrects biases in the error that are introduced during quantization. This improves quantization accuracy performance, and can be applied to many common computer vision architectures with a straight forward API call. For common architectures, such as the MobileNet family, we achieve state-of-the-art quantized model performance. We further show that the method also extends to other computer vision architectures and tasks such as semantic segmentation and object detection.", "published": "2019-06-11T17:47:51Z", "version": 3}, {"aid": "1906.04893", "authors": ["Mahyar Fazlyab", "Alexander Robey", "Hamed Hassani", "Manfred Morari", "George J. Pappas"], "title": "Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks", "url": "http://arxiv.org/pdf/1906.04893v2", "summary": "Tight estimation of the Lipschitz constant for deep neural networks (DNNs) is useful in many applications ranging from robustness certification of classifiers to stability analysis of closed-loop systems with reinforcement learning controllers. Existing methods in the literature for estimating the Lipschitz constant suffer from either lack of accuracy or poor scalability. In this paper, we present a convex optimization framework to compute guaranteed upper bounds on the Lipschitz constant of DNNs both accurately and efficiently. Our main idea is to interpret activation functions as gradients of convex potential functions. Hence, they satisfy certain properties that can be described by quadratic constraints. This particular description allows us to pose the Lipschitz constant estimation problem as a semidefinite program (SDP). The resulting SDP can be adapted to increase either the estimation accuracy (by capturing the interaction between activation functions of different layers) or scalability (by decomposition and parallel implementation). We illustrate the utility of our approach with a variety of experiments on randomly generated networks and on classifiers trained on the MNIST and Iris datasets. In particular, we experimentally demonstrate that our Lipschitz bounds are the most accurate compared to those in the literature. We also study the impact of adversarial training methods on the Lipschitz bounds of the resulting classifiers and show that our bounds can be used to efficiently provide robustness guarantees.", "published": "2019-06-12T02:18:19Z", "version": 2}, {"aid": "1906.05909", "authors": ["Prajit Ramachandran", "Niki Parmar", "Ashish Vaswani", "Irwan Bello", "Anselm Levskaya", "Jonathon Shlens"], "title": "Stand-Alone Self-Attention in Vision Models", "url": "http://arxiv.org/pdf/1906.05909v1", "summary": "Convolutions are a fundamental building block of modern computer vision systems. Recent approaches have argued for going beyond convolutions in order to capture long-range dependencies. These efforts focus on augmenting convolutional models with content-based interactions, such as self-attention and non-local means, to achieve gains on a number of vision tasks. The natural question that arises is whether attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions. In developing and testing a pure self-attention vision model, we verify that self-attention can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of self-attention applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12% fewer FLOPS and 29% fewer parameters. On COCO object detection, a pure self-attention model matches the mAP of a baseline RetinaNet while having 39% fewer FLOPS and 34% fewer parameters. Detailed ablation studies demonstrate that self-attention is especially impactful when used in later layers. These results establish that stand-alone self-attention is an important addition to the vision practitioner's toolbox.", "published": "2019-06-13T19:43:01Z", "version": 1}, {"aid": "1906.06841", "authors": ["Biao Jia", "Jonathan Brandt", "Radomir Mech", "Byungmoon Kim", "Dinesh Manocha"], "title": "LPaintB: Learning to Paint from Self-Supervision", "url": "http://arxiv.org/pdf/1906.06841v2", "summary": "We present a novel reinforcement learning-based natural media painting algorithm. Our goal is to reproduce a reference image using brush strokes and we encode the objective through observations. Our formulation takes into account that the distribution of the reward in the action space is sparse and training a reinforcement learning algorithm from scratch can be difficult. We present an approach that combines self-supervised learning and reinforcement learning to effectively transfer negative samples into positive ones and change the reward distribution. We demonstrate the benefits of our painting agent to reproduce reference images with brush strokes. The training phase takes about one hour and the runtime algorithm takes about 30 seconds on a GTX1080 GPU reproducing a 1000x800 image with 20,000 strokes.", "published": "2019-06-17T04:52:15Z", "version": 2}, {"aid": "1906.07413", "authors": ["Kaidi Cao", "Colin Wei", "Adrien Gaidon", "Nikos Arechiga", "Tengyu Ma"], "title": "Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss", "url": "http://arxiv.org/pdf/1906.07413v2", "summary": "Deep learning algorithms can fare poorly when the training dataset suffers from heavy class-imbalance but the testing criterion requires good generalization on less frequent classes. We design two novel methods to improve performance in such scenarios. First, we propose a theoretically-principled label-distribution-aware margin (LDAM) loss motivated by minimizing a margin-based generalization bound. This loss replaces the standard cross-entropy objective during training and can be applied with prior strategies for training with class-imbalance such as re-weighting or re-sampling. Second, we propose a simple, yet effective, training schedule that defers re-weighting until after the initial stage, allowing the model to learn an initial representation while avoiding some of the complications associated with re-weighting or re-sampling. We test our methods on several benchmark vision tasks including the real-world imbalanced dataset iNaturalist 2018. Our experiments show that either of these methods alone can already improve over existing techniques and their combination achieves even better performance gains.", "published": "2019-06-18T07:21:18Z", "version": 2}, {"aid": "1906.08804", "authors": ["Alianna J. Maren"], "title": "Derivation of the Variational Bayes Equations", "url": "http://arxiv.org/pdf/1906.08804v6", "summary": "The derivation of key equations for the variational Bayes approach is well-known in certain circles. However, translating the fundamental derivations (e.g., as found in Beal's work) to Friston's notation is somewhat delicate. Further, the notion of using variational Bayes in the context of a system with a Markov blanket requires special attention. This Technical Report presents the derivation in detail. It further illustrates how the variational Bayes method provides a framework for a new computational engine, incorporating the 2-D cluster variation method (CVM), which provides a necessary free energy equation that can be minimized across both the external and representational systems' states, respectively.", "published": "2019-06-20T18:43:47Z", "version": 6}, {"aid": "1907.01361", "authors": ["Matias Tassano", "Julie Delon", "Thomas Veit"], "title": "FastDVDnet: Towards Real-Time Deep Video Denoising Without Flow Estimation", "url": "http://arxiv.org/pdf/1907.01361v2", "summary": "In this paper, we propose a state-of-the-art video denoising algorithm based on a convolutional neural network architecture. Until recently, video denoising with neural networks had been a largely under explored domain, and existing methods could not compete with the performance of the best patch-based methods. The approach we introduce in this paper, called FastDVDnet, shows similar or better performance than other state-of-the-art competitors with significantly lower computing times. In contrast to other existing neural network denoisers, our algorithm exhibits several desirable properties such as fast runtimes, and the ability to handle a wide range of noise levels with a single network model. The characteristics of its architecture make it possible to avoid using a costly motion compensation stage while achieving excellent performance. The combination between its denoising performance and lower computational load makes this algorithm attractive for practical denoising applications. We compare our method with different state-of-art algorithms, both visually and with respect to objective quality metrics.", "published": "2019-07-01T14:10:34Z", "version": 2}, {"aid": "1907.03876", "authors": ["Beren Millidge"], "title": "Deep Active Inference as Variational Policy Gradients", "url": "http://arxiv.org/pdf/1907.03876v1", "summary": "Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity - the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.", "published": "2019-07-08T21:14:29Z", "version": 1}, {"aid": "1907.04312", "authors": ["Boyi Li", "Felix Wu", "Kilian Q. Weinberger", "Serge Belongie"], "title": "Positional Normalization", "url": "http://arxiv.org/pdf/1907.04312v2", "summary": "A popular method to reduce the training time of deep neural networks is to normalize activations at each layer. Although various normalization schemes have been proposed, they all follow a common theme: normalize across spatial dimensions and discard the extracted statistics. In this paper, we propose an alternative normalization method that noticeably departs from this convention and normalizes exclusively across channels. We argue that the channel dimension is naturally appealing as it allows us to extract the first and second moments of features extracted at a particular image position. These moments capture structural information about the input image and extracted features, which opens a new avenue along which a network can benefit from feature normalization: Instead of disregarding the normalization constants, we propose to re-inject them into later layers to preserve or transfer structural information in generative networks. Codes are available at https://github.com/Boyiliee/PONO.", "published": "2019-07-09T17:52:01Z", "version": 2}, {"aid": "1907.06592", "authors": ["Paschalis Bizopoulos", "Dimitrios Koutsouris"], "title": "Sparsely Activated Networks", "url": "http://arxiv.org/pdf/1907.06592v11", "summary": "Previous literature on unsupervised learning focused on designing structural priors with the aim of learning meaningful features. However, this was done without considering the description length of the learned representations which is a direct and unbiased measure of the model complexity. In this paper, first we introduce the $\\varphi$ metric that evaluates unsupervised models based on their reconstruction accuracy and the degree of compression of their internal representations. We then present and define two activation functions (Identity, ReLU) as base of reference and three sparse activation functions (top-k absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize the previously defined $\\varphi$. We lastly present Sparsely Activated Networks (SANs) that consist of kernels with shared weights that, during encoding, are convolved with the input and then passed through a sparse activation function. During decoding, the same weights are convolved with the sparse activation map and subsequently the partial reconstructions from each weight are summed to reconstruct the input. We compare SANs using the five previously defined activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST, FMNIST) and show that models that are selected using $\\varphi$ have small description representation length and consist of interpretable kernels.", "published": "2019-07-12T08:01:47Z", "version": 11}, {"aid": "1907.05686", "authors": ["Pierre Stock", "Armand Joulin", "R\u00e9mi Gribonval", "Benjamin Graham", "Herv\u00e9 J\u00e9gou"], "title": "And the Bit Goes Down: Revisiting the Quantization of Neural Networks", "url": "http://arxiv.org/pdf/1907.05686v5", "summary": "In this paper, we address the problem of reducing the memory footprint of convolutional network architectures. We introduce a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The principle of our approach is that it minimizes the loss reconstruction error for in-domain inputs. Our method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using byte-aligned codebooks to store the compressed weights. We validate our approach by quantizing a high performing ResNet-50 model to a memory size of 5MB (20x compression factor) while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.", "published": "2019-07-12T11:52:54Z", "version": 5}, {"aid": "1907.06916", "authors": ["Mark D. McDonnell", "Hesham Mostafa", "Runchun Wang", "Andre van Schaik"], "title": "Single-bit-per-weight deep convolutional neural networks without batch-normalization layers for embedded systems", "url": "http://arxiv.org/pdf/1907.06916v2", "summary": "Batch-normalization (BN) layers are thought to be an integrally important layer type in today's state-of-the-art deep convolutional neural networks for computer vision tasks such as classification and detection. However, BN layers introduce complexity and computational overheads that are highly undesirable for training and/or inference on low-power custom hardware implementations of real-time embedded vision systems such as UAVs, robots and Internet of Things (IoT) devices. They are also problematic when batch sizes need to be very small during training, and innovations such as residual connections introduced more recently than BN layers could potentially have lessened their impact. In this paper we aim to quantify the benefits BN layers offer in image classification networks, in comparison with alternative choices. In particular, we study networks that use shifted-ReLU layers instead of BN layers. We found, following experiments with wide residual networks applied to the ImageNet, CIFAR 10 and CIFAR 100 image classification datasets, that BN layers do not consistently offer a significant advantage. We found that the accuracy margin offered by BN layers depends on the data set, the network size, and the bit-depth of weights. We conclude that in situations where BN layers are undesirable due to speed, memory or complexity costs, that using shifted-ReLU layers instead should be considered; we found they can offer advantages in all these areas, and often do not impose a significant accuracy cost.", "published": "2019-07-16T09:42:02Z", "version": 2}, {"aid": "1907.08610", "authors": ["Michael R. Zhang", "James Lucas", "Geoffrey Hinton", "Jimmy Ba"], "title": "Lookahead Optimizer: k steps forward, 1 step back", "url": "http://arxiv.org/pdf/1907.08610v2", "summary": "The vast majority of successful deep neural networks are trained using variants of stochastic gradient descent (SGD) algorithms. Recent attempts to improve SGD can be broadly categorized into two approaches: (1) adaptive learning rate schemes, such as AdaGrad and Adam, and (2) accelerated schemes, such as heavy-ball and Nesterov momentum. In this paper, we propose a new optimization algorithm, Lookahead, that is orthogonal to these previous approaches and iteratively updates two sets of weights. Intuitively, the algorithm chooses a search direction by looking ahead at the sequence of fast weights generated by another optimizer. We show that Lookahead improves the learning stability and lowers the variance of its inner optimizer with negligible computation and memory cost. We empirically demonstrate Lookahead can significantly improve the performance of SGD and Adam, even with their default hyperparameter settings on ImageNet, CIFAR-10/100, neural machine translation, and Penn Treebank.", "published": "2019-07-19T17:59:50Z", "version": 2}, {"aid": "1907.08650", "authors": ["Khushbu Agarwal", "Tome Eftimov", "Raghavendra Addanki", "Sutanay Choudhury", "Suzanne Tamang", "Robert Rallo"], "title": "Snomed2Vec: Random Walk and Poincar\u00e9 Embeddings of a Clinical Knowledge Base for Healthcare Analytics", "url": "http://arxiv.org/pdf/1907.08650v1", "summary": "Representation learning methods that transform encoded data (e.g., diagnosis and drug codes) into continuous vector spaces (i.e., vector embeddings) are critical for the application of deep learning in healthcare. Initial work in this area explored the use of variants of the word2vec algorithm to learn embeddings for medical concepts from electronic health records or medical claims datasets. We propose learning embeddings for medical concepts by using graph-based representation learning methods on SNOMED-CT, a widely popular knowledge graph in the healthcare domain with numerous operational and research applications. Current work presents an empirical analysis of various embedding methods, including the evaluation of their performance on multiple tasks of biomedical relevance (node classification, link prediction, and patient state prediction). Our results show that concept embeddings derived from the SNOMED-CT knowledge graph significantly outperform state-of-the-art embeddings, showing 5-6x improvement in ``concept similarity\" and 6-20\\% improvement in patient diagnosis.", "published": "2019-07-19T19:11:39Z", "version": 1}, {"aid": "1907.08801", "authors": ["Amadeus Maes", "Mauricio Barahona", "Claudia Clopath"], "title": "Learning spatiotemporal signals using a recurrent spiking network that discretizes time", "url": "http://arxiv.org/pdf/1907.08801v2", "summary": "Learning to produce spatiotemporal sequences is a common task that the brain has to solve. The same neural substrate may be used by the brain to produce different sequential behaviours. The way the brain learns and encodes such tasks remains unknown as current computational models do not typically use realistic biologically-plausible learning. Here, we propose a model where a spiking recurrent network of excitatory and inhibitory biophysical neurons drives a read-out layer: the dynamics of the driver recurrent network is trained to encode time which is then mapped through the read-out neurons to encode another dimension, such as space or a phase. Different spatiotemporal patterns can be learned and encoded through the synaptic weights to the read-out neurons that follow common Hebbian learning rules. We demonstrate that the model is able to learn spatiotemporal dynamics on time scales that are behaviourally relevant and we show that the learned sequences are robustly replayed during a regime of spontaneous activity.", "published": "2019-07-20T11:54:20Z", "version": 2}, {"aid": "1907.09008", "authors": ["Dong Wang", "Yicheng Liu", "Wenwo Tang", "Fanhua Shang", "Hongying Liu", "Qigong Sun", "Licheng Jiao"], "title": "signADAM: Learning Confidences for Deep Neural Networks", "url": "http://arxiv.org/pdf/1907.09008v1", "summary": "In this paper, we propose a new first-order gradient-based algorithm to train deep neural networks. We first introduce the sign operation of stochastic gradients (as in sign-based methods, e.g., SIGN-SGD) into ADAM, which is called as signADAM. Moreover, in order to make the rate of fitting each feature closer, we define a confidence function to distinguish different components of gradients and apply it to our algorithm. It can generate more sparse gradients than existing algorithms do. We call this new algorithm signADAM++. In particular, both our algorithms are easy to implement and can speed up training of various deep neural networks. The motivation of signADAM++ is preferably learning features from the most different samples by updating large and useful gradients regardless of useless information in stochastic gradients. We also establish theoretical convergence guarantees for our algorithms. Empirical results on various datasets and models show that our algorithms yield much better performance than many state-of-the-art algorithms including SIGN-SGD, SIGNUM and ADAM. We also analyze the performance from multiple perspectives including the loss landscape and develop an adaptive method to further improve generalization. The source code is available at https://github.com/DongWanginxdu/signADAM-Learn-by-Confidence.", "published": "2019-07-21T17:08:50Z", "version": 1}, {"aid": "1907.09472", "authors": ["Alexandru Baltag", "Soroush Rafiee Rad", "Sonja Smets"], "title": "Learning Probabilities: Towards a Logic of Statistical Learning", "url": "http://arxiv.org/pdf/1907.09472v1", "summary": "We propose a new model for forming beliefs and learning about unknown probabilities (such as the probability of picking a red marble from a bag with an unknown distribution of coloured marbles). The most widespread model for such situations of 'radical uncertainty' is in terms of imprecise probabilities, i.e. representing the agent's knowledge as a set of probability measures. We add to this model a plausibility map, associating to each measure a plausibility number, as a way to go beyond what is known with certainty and represent the agent's beliefs about probability. There are a number of standard examples: Shannon Entropy, Centre of Mass etc. We then consider learning of two types of information: (1) learning by repeated sampling from the unknown distribution (e.g. picking marbles from the bag); and (2) learning higher-order information about the distribution (in the shape of linear inequalities, e.g. we are told there are more red marbles than green marbles). The first changes only the plausibility map (via a 'plausibilistic' version of Bayes' Rule), but leaves the given set of measures unchanged; the second shrinks the set of measures, without changing their plausibility. Beliefs are defined as in Belief Revision Theory, in terms of truth in the most plausible worlds. But our belief change does not comply with standard AGM axioms, since the revision induced by (1) is of a non-AGM type. This is essential, as it allows our agents to learn the true probability: we prove that the beliefs obtained by repeated sampling converge almost surely to the correct belief (in the true probability). We end by sketching the contours of a dynamic doxastic logic for statistical learning.", "published": "2019-07-22T03:13:04Z", "version": 1}, {"aid": "1907.09200", "authors": ["Matthew C. H. Lee", "Ozan Oktay", "Andreas Schuh", "Michiel Schaap", "Ben Glocker"], "title": "Image-and-Spatial Transformer Networks for Structure-Guided Image Registration", "url": "http://arxiv.org/pdf/1907.09200v1", "summary": "Image registration with deep neural networks has become an active field of research and exciting avenue for a long standing problem in medical imaging. The goal is to learn a complex function that maps the appearance of input image pairs to parameters of a spatial transformation in order to align corresponding anatomical structures. We argue and show that the current direct, non-iterative approaches are sub-optimal, in particular if we seek accurate alignment of Structures-of-Interest (SoI). Information about SoI is often available at training time, for example, in form of segmentations or landmarks. We introduce a novel, generic framework, Image-and-Spatial Transformer Networks (ISTNs), to leverage SoI information allowing us to learn new image representations that are optimised for the downstream registration task. Thanks to these representations we can employ a test-specific, iterative refinement over the transformation parameters which yields highly accurate registration even with very limited training data. Performance is demonstrated on pairwise 3D brain registration and illustrative synthetic data.", "published": "2019-07-22T09:39:53Z", "version": 1}, {"aid": "1907.09245", "authors": ["Kaan Karaman", "Erhan Gundogdu", "Aykut Koc", "A. Aydin Alatan"], "title": "Quadruplet Selection Methods for Deep Embedding Learning", "url": "http://arxiv.org/pdf/1907.09245v1", "summary": "Recognition of objects with subtle differences has been used in many practical applications, such as car model recognition and maritime vessel identification. For discrimination of the objects in fine-grained detail, we focus on deep embedding learning by using a multi-task learning framework, in which the hierarchical labels (coarse and fine labels) of the samples are utilized both for classification and a quadruplet-based loss function. In order to improve the recognition strength of the learned features, we present a novel feature selection method specifically designed for four training samples of a quadruplet. By experiments, it is observed that the selection of very hard negative samples with relatively easy positive ones from the same coarse and fine classes significantly increases some performance metrics in a fine-grained dataset when compared to selecting the quadruplet samples randomly. The feature embedding learned by the proposed method achieves favorable performance against its state-of-the-art counterparts.", "published": "2019-07-22T11:39:15Z", "version": 1}, {"aid": "1907.10473", "authors": ["Ping Luo", "Ruimao Zhang", "Jiamin Ren", "Zhanglin Peng", "Jingyu Li"], "title": "Switchable Normalization for Learning-to-Normalize Deep Representation", "url": "http://arxiv.org/pdf/1907.10473v1", "summary": "We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network. SN employs three distinct scopes to compute statistics (means and variances) including a channel, a layer, and a minibatch. SN switches between them by learning their importance weights in an end-to-end manner. It has several good properties. First, it adapts to various network architectures and tasks. Second, it is robust to a wide range of batch sizes, maintaining high performance even when small minibatch is presented (e.g. 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike group normalization that searches the number of groups as a hyper-parameter. Without bells and whistles, SN outperforms its counterparts on various challenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, MegaFace, and Kinetics. Analyses of SN are also presented to answer the following three questions: (a) Is it useful to allow each normalization layer to select its own normalizer? (b) What impacts the choices of normalizers? (c) Do different tasks and datasets prefer different normalizers? We hope SN will help ease the usage and understand the normalization techniques in deep learning. The code of SN has been released at https://github.com/switchablenorms.", "published": "2019-07-22T17:50:31Z", "version": 1}, {"aid": "1907.09533", "authors": ["Ozan \u00d6zdenizci", "Timm Meyer", "Felix Wichmann", "Jan Peters", "Bernhard Sch\u00f6lkopf", "M\u00fcjdat \u00c7etin", "Moritz Grosse-Wentrup"], "title": "Neural Signatures of Motor Skill in the Resting Brain", "url": "http://arxiv.org/pdf/1907.09533v1", "summary": "Stroke-induced disturbances of large-scale cortical networks are known to be associated with the extent of motor deficits. We argue that identifying brain networks representative of motor behavior in the resting brain would provide significant insights for current neurorehabilitation approaches. Particularly, we aim to investigate the global configuration of brain rhythms and their relation to motor skill, instead of learning performance as broadly studied. We empirically approach this problem by conducting a three-dimensional physical space visuomotor learning experiment during electroencephalographic (EEG) data recordings with thirty-seven healthy participants. We demonstrate that across-subjects variations in average movement smoothness as the quantified measure of subjects' motor skills can be predicted from the global configuration of resting-state EEG alpha-rhythms (8-14 Hz) recorded prior to the experiment. Importantly, this neural signature of motor skill was found to be orthogonal to (independent of) task -- as well as to learning-related changes in alpha-rhythms, which we interpret as an organizing principle of the brain. We argue that disturbances of such configurations in the brain may contribute to motor deficits in stroke, and that reconfiguring stroke patients' brain rhythms by neurofeedback may enhance post-stroke neurorehabilitation.", "published": "2019-07-22T19:09:13Z", "version": 1}, {"aid": "1907.09540", "authors": ["Ozan Ozdenizci", "Barry Oken", "Tab Memmott", "Melanie Fried-Oken", "Deniz Erdogmus"], "title": "Adversarial Feature Learning in Brain Interfacing: An Experimental Study on Eliminating Drowsiness Effects", "url": "http://arxiv.org/pdf/1907.09540v1", "summary": "Across- and within-recording variabilities in electroencephalographic (EEG) activity is a major limitation in EEG-based brain-computer interfaces (BCIs). Specifically, gradual changes in fatigue and vigilance levels during long EEG recording durations and BCI system usage bring along significant fluctuations in BCI performances even when these systems are calibrated daily. We address this in an experimental offline study from EEG-based BCI speller usage data acquired for one hour duration. As the main part of our methodological approach, we propose the concept of adversarial invariant feature learning for BCIs as a regularization approach on recently expanding EEG deep learning architectures, to learn nuisance-invariant discriminative features. We empirically demonstrate the feasibility of adversarial feature learning on eliminating drowsiness effects from event related EEG activity features, by using temporal recording block ordering as the source of drowsiness variability.", "published": "2019-07-22T19:28:37Z", "version": 1}, {"aid": "1907.10597", "authors": ["Roy Schwartz", "Jesse Dodge", "Noah A. Smith", "Oren Etzioni"], "title": "Green AI", "url": "http://arxiv.org/pdf/1907.10597v3", "summary": "The computations required for deep learning research have been doubling every few months, resulting in an estimated 300,000x increase from 2012 to 2018 [2]. These computations have a surprisingly large carbon footprint [38]. Ironically, deep learning was inspired by the human brain, which is remarkably energy efficient. Moreover, the financial cost of the computations can make it difficult for academics, students, and researchers, in particular those from emerging economies, to engage in deep learning research.   This position paper advocates a practical solution by making efficiency an evaluation criterion for research alongside accuracy and related measures. In addition, we propose reporting the financial cost or \"price tag\" of developing, training, and running models to provide baselines for the investigation of increasingly efficient methods. Our goal is to make AI both greener and more inclusive---enabling any inspired undergraduate with a laptop to write high-quality research papers. Green AI is an emerging focus at the Allen Institute for AI.", "published": "2019-07-22T19:36:18Z", "version": 3}, {"aid": "1907.09595", "authors": ["Mingxing Tan", "Quoc V. Le"], "title": "MixConv: Mixed Depthwise Convolutional Kernels", "url": "http://arxiv.org/pdf/1907.09595v3", "summary": "Depthwise convolution is becoming increasingly popular in modern efficient ConvNets, but its kernel size is often overlooked. In this paper, we systematically study the impact of different kernel sizes, and observe that combining the benefits of multiple kernel sizes can lead to better accuracy and efficiency. Based on this observation, we propose a new mixed depthwise convolution (MixConv), which naturally mixes up multiple kernel sizes in a single convolution. As a simple drop-in replacement of vanilla depthwise convolution, our MixConv improves the accuracy and efficiency for existing MobileNets on both ImageNet classification and COCO object detection. To demonstrate the effectiveness of MixConv, we integrate it into AutoML search space and develop a new family of models, named as MixNets, which outperform previous mobile models including MobileNetV2 [20] (ImageNet top-1 accuracy +4.2%), ShuffleNetV2 [16] (+3.5%), MnasNet [26] (+1.3%), ProxylessNAS [2] (+2.2%), and FBNet [27] (+2.0%). In particular, our MixNet-L achieves a new state-of-the-art 78.9% ImageNet top-1 accuracy under typical mobile settings (<600M FLOPS). Code is at https://github.com/ tensorflow/tpu/tree/master/models/official/mnasnet/mixnet", "published": "2019-07-22T21:49:25Z", "version": 3}, {"aid": "1907.09798", "authors": ["Liang Pan", "Chee-Meng Chew", "Gim Hee Lee"], "title": "PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points", "url": "http://arxiv.org/pdf/1907.09798v2", "summary": "Motivated by the success of encoding multi-scale contextual information for image analysis, we propose our PointAtrousGraph (PAG) - a deep permutation-invariant hierarchical encoder-decoder for efficiently exploiting multi-scale edge features in point clouds. Our PAG is constructed by several novel modules, such as Point Atrous Convolution (PAC), Edge-preserved Pooling (EP) and Edge-preserved Unpooling (EU). Similar with atrous convolution, our PAC can effectively enlarge receptive fields of filters and thus densely learn multi-scale point features. Following the idea of non-overlapping max-pooling operations, we propose our EP to preserve critical edge features during subsampling. Correspondingly, our EU modules gradually recover spatial information for edge features. In addition, we introduce chained skip subsampling/upsampling modules that directly propagate edge features to the final stage. Particularly, our proposed auxiliary loss functions can further improve our performance. Experimental results show that our PAG outperform previous state-of-the-art methods on various 3D semantic perception applications.", "published": "2019-07-23T10:16:58Z", "version": 2}, {"aid": "1907.10060", "authors": ["Massimiliano Zanin", "Bahar G\u00fcntekin", "Tuba Akt\u00fcrk", "L\u00fctf\u00fc Hano\u011flu", "David Papo"], "title": "Time irreversibility of resting brain activity in the healthy brain and pathology", "url": "http://arxiv.org/pdf/1907.10060v1", "summary": "Characterising brain activity at rest is of paramount importance to our understanding both of general principles of brain functioning and of the way brain dynamics is affected in the presence of neurological or psychiatric pathologies. We measured the time-reversal symmetry of spontaneous electroencephalographic brain activity recorded from three groups of patients and their respective control group under two experimental conditions (eyes open and closed). We evaluated differences in time irreversibility in terms of possible underlying physical generating mechanisms. The results showed that resting brain activity is generically time-irreversible at sufficiently long time scales, and that brain pathology is generally associated with a reduction in time-asymmetry, albeit with pathology-specific patterns. The significance of these results and their possible dynamical aetiology are discussed. Some implications of the differential modulation of time asymmetry by pathology and experimental condition are examined.", "published": "2019-07-23T16:37:55Z", "version": 1}, {"aid": "1907.10104", "authors": ["Omid Abdollahi Aghdam", "Behzad Bozorgtabar", "Haz\u0131m Kemal Ekenel", "Jean-Philippe Thiran"], "title": "Exploring Factors for Improving Low Resolution Face Recognition", "url": "http://arxiv.org/pdf/1907.10104v2", "summary": "State-of-the-art deep face recognition approaches report near perfect performance on popular benchmarks, e.g., Labeled Faces in the Wild. However, their performance deteriorates significantly when they are applied on low quality images, such as those acquired by surveillance cameras. A further challenge for low resolution face recognition for surveillance applications is the matching of recorded low resolution probe face images with high resolution reference images, which could be the case in watchlist scenarios. In this paper, we have addressed these problems and investigated the factors that would contribute to the identification performance of the state-of-the-art deep face recognition models when they are applied to low resolution face recognition under mismatched conditions. We have observed that the following factors affect performance in a positive way: appearance variety and resolution distribution of the training dataset, resolution matching between the gallery and probe images, and the amount of information included in the probe images. By leveraging this information, we have utilized deep face models trained on MS-Celeb-1M and fine-tuned on VGGFace2 dataset and achieved state-of-the-art accuracies on the SCFace and ICB-RW benchmarks, even without using any training data from the datasets of these benchmarks.", "published": "2019-07-23T19:16:48Z", "version": 2}, {"aid": "1907.10107", "authors": ["Mengyao Zhai", "Lei Chen", "Fred Tung", "Jiawei He", "Megha Nawhal", "Greg Mori"], "title": "Lifelong GAN: Continual Learning for Conditional Image Generation", "url": "http://arxiv.org/pdf/1907.10107v2", "summary": "Lifelong learning is challenging for deep neural networks due to their susceptibility to catastrophic forgetting. Catastrophic forgetting occurs when a trained network is not able to maintain its ability to accomplish previously learned tasks when it is trained to perform new tasks. We study the problem of lifelong learning for generative models, extending a trained network to new conditional generation tasks without forgetting previous tasks, while assuming access to the training data for the current task only. In contrast to state-of-the-art memory replay based approaches which are limited to label-conditioned image generation tasks, a more generic framework for continual learning of generative models under different conditional image generation settings is proposed in this paper. Lifelong GAN employs knowledge distillation to transfer learned knowledge from previous networks to the new network. This makes it possible to perform image-conditioned generation tasks in a lifelong learning setting. We validate Lifelong GAN for both image-conditioned and label-conditioned generation tasks, and provide qualitative and quantitative results to show the generality and effectiveness of our method.", "published": "2019-07-23T19:25:15Z", "version": 2}, {"aid": "1907.10213", "authors": ["Qi Zhang", "Huafeng Wang", "Sichen Yang"], "title": "Image Super-Resolution Using a Wavelet-based Generative Adversarial Network", "url": "http://arxiv.org/pdf/1907.10213v1", "summary": "In this paper, we consider the problem of super-resolution recons-truction. This is a hot topic because super-resolution reconstruction has a wide range of applications in the medical field, remote sensing monitoring, and criminal investigation. Compared with traditional algorithms, the current super-resolution reconstruction algorithm based on deep learning greatly improves the clarity of reconstructed pictures. Existing work like Super-Resolution Using a Generative Adversarial Network (SRGAN) can effectively restore the texture details of the image. However, experimentally verified that the texture details of the image recovered by the SRGAN are not robust. In order to get super-resolution reconstructed images with richer high-frequency details, we improve the network structure and propose a super-resolution reconstruction algorithm combining wavelet transform and Generative Adversarial Network. The proposed algorithm can efficiently reconstruct high-resolution images with rich global information and local texture details. We have trained our model by PyTorch framework and VOC2012 dataset, and tested it by Set5, Set14, BSD100 and Urban100 test datasets.", "published": "2019-07-24T02:44:41Z", "version": 1}, {"aid": "1907.10244", "authors": ["Hyeongmin Lee", "Taeoh Kim", "Tae-young Chung", "Daehyun Pak", "Yuseok Ban", "Sangyoun Lee"], "title": "AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation", "url": "http://arxiv.org/pdf/1907.10244v3", "summary": "Video frame interpolation is one of the most challenging tasks in video processing research. Recently, many studies based on deep learning have been suggested. Most of these methods focus on finding locations with useful information to estimate each output pixel using their own frame warping operations. However, many of them have Degrees of Freedom (DoF) limitations and fail to deal with the complex motions found in real world videos. To solve this problem, we propose a new warping module named Adaptive Collaboration of Flows (AdaCoF). Our method estimates both kernel weights and offset vectors for each target pixel to synthesize the output frame. AdaCoF is one of the most generalized warping modules compared to other approaches, and covers most of them as special cases of it. Therefore, it can deal with a significantly wide domain of complex motions. To further improve our framework and synthesize more realistic outputs, we introduce dual-frame adversarial loss which is applicable only to video frame interpolation tasks. The experimental results show that our method outperforms the state-of-the-art methods for both fixed training set environments and the Middlebury benchmark.", "published": "2019-07-24T05:40:53Z", "version": 3}, {"aid": "1907.10628", "authors": ["Vinod Kumar Kurmi", "Vipul Bajaj", "Venkatesh K Subramanian", "Vinay P Namboodiri"], "title": "Curriculum based Dropout Discriminator for Domain Adaptation", "url": "http://arxiv.org/pdf/1907.10628v2", "summary": "Domain adaptation is essential to enable wide usage of deep learning based networks trained using large labeled datasets. Adversarial learning based techniques have shown their utility towards solving this problem using a discriminator that ensures source and target distributions are close. However, here we suggest that rather than using a point estimate, it would be useful if a distribution based discriminator could be used to bridge this gap. This could be achieved using multiple classifiers or using traditional ensemble methods. In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator could suffice to obtain the distribution based discriminator. Specifically, we propose a curriculum based dropout discriminator that gradually increases the variance of the sample based distribution and the corresponding reverse gradients are used to align the source and target feature representations. The detailed results and thorough ablation analysis show that our model outperforms state-of-the-art results.", "published": "2019-07-24T18:00:12Z", "version": 2}, {"aid": "1907.10786", "authors": ["Yujun Shen", "Jinjin Gu", "Xiaoou Tang", "Bolei Zhou"], "title": "Interpreting the Latent Space of GANs for Semantic Face Editing", "url": "http://arxiv.org/pdf/1907.10786v3", "summary": "Despite the recent advance of Generative Adversarial Networks (GANs) in high-fidelity image synthesis, there lacks enough understanding of how GANs are able to map a latent code sampled from a random distribution to a photo-realistic image. Previous work assumes the latent space learned by GANs follows a distributed representation but observes the vector arithmetic phenomenon. In this work, we propose a novel framework, called InterFaceGAN, for semantic face editing by interpreting the latent semantics learned by GANs. In this framework, we conduct a detailed study on how different semantics are encoded in the latent space of GANs for face synthesis. We find that the latent code of well-trained generative models actually learns a disentangled representation after linear transformations. We explore the disentanglement between various semantics and manage to decouple some entangled semantics with subspace projection, leading to more precise control of facial attributes. Besides manipulating gender, age, expression, and the presence of eyeglasses, we can even vary the face pose as well as fix the artifacts accidentally generated by GAN models. The proposed method is further applied to achieve real image manipulation when combined with GAN inversion methods or some encoder-involved models. Extensive results suggest that learning to synthesize faces spontaneously brings a disentangled and controllable facial attribute representation.", "published": "2019-07-25T01:30:16Z", "version": 3}, {"aid": "1907.10830", "authors": ["Junho Kim", "Minjae Kim", "Hyeonwoo Kang", "Kwanghee Lee"], "title": "U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation", "url": "http://arxiv.org/pdf/1907.10830v4", "summary": "We propose a novel method for unsupervised image-to-image translation, which incorporates a new attention module and a new learnable normalization function in an end-to-end manner. The attention module guides our model to focus on more important regions distinguishing between source and target domains based on the attention map obtained by the auxiliary classifier. Unlike previous attention-based method which cannot handle the geometric changes between domains, our model can translate both images requiring holistic changes and images requiring large shape changes. Moreover, our new AdaLIN (Adaptive Layer-Instance Normalization) function helps our attention-guided model to flexibly control the amount of change in shape and texture by learned parameters depending on datasets. Experimental results show the superiority of the proposed method compared to the existing state-of-the-art models with a fixed network architecture and hyper-parameters. Our code and datasets are available at https://github.com/taki0112/UGATIT or https://github.com/znxlwm/UGATIT-pytorch.", "published": "2019-07-25T04:17:25Z", "version": 4}, {"aid": "1907.10949", "authors": ["Massimiliano Patacchiola", "Patrick Fox-Roberts", "Edward Rosten"], "title": "Y-Autoencoders: disentangling latent representations via sequential-encoding", "url": "http://arxiv.org/pdf/1907.10949v1", "summary": "In the last few years there have been important advancements in generative models with the two dominant approaches being Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs). However, standard Autoencoders (AEs) and closely related structures have remained popular because they are easy to train and adapt to different tasks. An interesting question is if we can achieve state-of-the-art performance with AEs while retaining their good properties. We propose an answer to this question by introducing a new model called Y-Autoencoder (Y-AE). The structure and training procedure of a Y-AE enclose a representation into an implicit and an explicit part. The implicit part is similar to the output of an autoencoder and the explicit part is strongly correlated with labels in the training set. The two parts are separated in the latent space by splitting the output of the encoder into two paths (forming a Y shape) before decoding and re-encoding. We then impose a number of losses, such as reconstruction loss, and a loss on dependence between the implicit and explicit parts. Additionally, the projection in the explicit manifold is monitored by a predictor, that is embedded in the encoder and trained end-to-end with no adversarial losses. We provide significant experimental results on various domains, such as separation of style and content, image-to-image translation, and inverse graphics.", "published": "2019-07-25T10:28:15Z", "version": 1}, {"aid": "1907.11357", "authors": ["Gen Li", "Inyoung Yun", "Jonghyun Kim", "Joongkyu Kim"], "title": "DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation", "url": "http://arxiv.org/pdf/1907.11357v2", "summary": "As a pixel-level prediction task, semantic segmentation needs large computational cost with enormous parameters to obtain high performance. Recently, due to the increasing demand for autonomous systems and robots, it is significant to make a tradeoff between accuracy and inference speed. In this paper, we propose a novel Depthwise Asymmetric Bottleneck (DAB) module to address this dilemma, which efficiently adopts depth-wise asymmetric convolution and dilated convolution to build a bottleneck structure. Based on the DAB module, we design a Depth-wise Asymmetric Bottleneck Network (DABNet) especially for real-time semantic segmentation, which creates sufficient receptive field and densely utilizes the contextual information. Experiments on Cityscapes and CamVid datasets demonstrate that the proposed DABNet achieves a balance between speed and precision. Specifically, without any pretrained model and postprocessing, it achieves 70.1% Mean IoU on the Cityscapes test dataset with only 0.76 million parameters and a speed of 104 FPS on a single GTX 1080Ti card.", "published": "2019-07-26T01:50:31Z", "version": 2}, {"aid": "1907.11432", "authors": ["Kumara Kahatapitiya", "Ranga Rodrigo"], "title": "Exploiting the Redundancy in Convolutional Filters for Parameter Reduction", "url": "http://arxiv.org/pdf/1907.11432v3", "summary": "Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance in many computer vision tasks over the years. However, this comes at the cost of heavy computation and memory intensive network designs, suggesting potential improvements in efficiency. Convolutional layers of CNNs partly account for such an inefficiency, as they are known to learn redundant features. In this work, we exploit this redundancy, observing it as the correlation between convolutional filters of a layer, and propose an alternative approach to reproduce it efficiently. The proposed 'LinearConv' layer learns a set of orthogonal filters, and a set of coefficients that linearly combines them to introduce a controlled redundancy. We introduce a correlation-based regularization loss to achieve such flexibility over redundancy, and control the number of parameters in turn. This is designed as a plug-and-play layer to conveniently replace a conventional convolutional layer, without any additional changes required in the network architecture or the hyperparameter settings. Our experiments verify that LinearConv models achieve a performance on-par with their counterparts, with almost a 50% reduction in parameters on average, and the same computational requirement and speed at inference.", "published": "2019-07-26T08:39:31Z", "version": 3}, {"aid": "1907.11440", "authors": ["Junhyuk Hyun", "Hongje Seong", "Euntai Kim"], "title": "Universal Pooling -- A New Pooling Method for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1907.11440v1", "summary": "Pooling is one of the main elements in convolutional neural networks. The pooling reduces the size of the feature map, enabling training and testing with a limited amount of computation. This paper proposes a new pooling method named universal pooling. Unlike the existing pooling methods such as average pooling, max pooling, and stride pooling with fixed pooling function, universal pooling generates any pooling function, depending on a given problem and dataset. Universal pooling was inspired by attention methods and can be considered as a channel-wise form of local spatial attention. Universal pooling is trained jointly with the main network and it is shown that it includes the existing pooling methods. Finally, when applied to two benchmark problems, the proposed method outperformed the existing pooling methods and performed with the expected diversity, adapting to the given problem.", "published": "2019-07-26T09:00:00Z", "version": 1}, {"aid": "1907.11503", "authors": ["Bulla Rajesh", "Mohammed Javed", "Ratnesh", "Shubham Srivastava"], "title": "DCT-CompCNN: A Novel Image Classification Network Using JPEG Compressed DCT Coefficients", "url": "http://arxiv.org/pdf/1907.11503v1", "summary": "The popularity of Convolutional Neural Network (CNN) in the field of Image Processing and Computer Vision has motivated researchers and industrialist experts across the globe to solve different challenges with high accuracy. The simplest way to train a CNN classifier is to directly feed the original RGB pixels images into the network. However, if we intend to classify images directly with its compressed data, the same approach may not work better, like in case of JPEG compressed images. This research paper investigates the issues of modifying the input representation of the JPEG compressed data, and then feeding into the CNN. The architecture is termed as DCT-CompCNN. This novel approach has shown that CNNs can also be trained with JPEG compressed DCT coefficients, and subsequently can produce a better performance in comparison with the conventional CNN approach. The efficiency of the modified input representation is tested with the existing ResNet-50 architecture and the proposed DCT-CompCNN architecture on a public image classification datasets like Dog Vs Cat and CIFAR-10 datasets, reporting a better performance", "published": "2019-07-26T12:01:21Z", "version": 1}, {"aid": "1907.11559", "authors": ["Guilherme Pombo", "Robert Gray", "Tom Varsavsky", "John Ashburner", "Parashkev Nachev"], "title": "Bayesian Volumetric Autoregressive generative models for better semisupervised learning", "url": "http://arxiv.org/pdf/1907.11559v1", "summary": "Deep generative models are rapidly gaining traction in medical imaging. Nonetheless, most generative architectures struggle to capture the underlying probability distributions of volumetric data, exhibit convergence problems, and offer no robust indices of model uncertainty. By comparison, the autoregressive generative model PixelCNN can be extended to volumetric data with relative ease, it readily attempts to learn the true underlying probability distribution and it still admits a Bayesian reformulation that provides a principled framework for reasoning about model uncertainty. Our contributions in this paper are two fold: first, we extend PixelCNN to work with volumetric brain magnetic resonance imaging data. Second, we show that reformulating this model to approximate a deep Gaussian process yields a measure of uncertainty that improves the performance of semi-supervised learning, in particular classification performance in settings where the proportion of labelled data is low. We quantify this improvement across classification, regression, and semantic segmentation tasks, training and testing on clinical magnetic resonance brain imaging data comprising T1-weighted and diffusion-weighted sequences.", "published": "2019-07-26T13:08:36Z", "version": 1}, {"aid": "1907.11818", "authors": ["Il Yong Chun", "Zhengyu Huang", "Hongki Lim", "Jeffrey A. Fessler"], "title": "Momentum-Net: Fast and convergent iterative neural network for inverse problems", "url": "http://arxiv.org/pdf/1907.11818v3", "summary": "Iterative neural networks (INN) are rapidly gaining attention for solving inverse problems in imaging, image processing, and computer vision. INNs combine regression NNs and an iterative model-based image reconstruction (MBIR) algorithm, often leading to both good generalization capability and outperforming reconstruction quality over existing MBIR optimization models. This paper proposes the first fast and convergent INN architecture, Momentum-Net, by generalizing a block-wise MBIR algorithm that uses momentum and majorizers with regression NNs. For fast MBIR, Momentum-Net uses momentum terms in extrapolation modules, and noniterative MBIR modules at each iteration by using majorizers, where each iteration of Momentum-Net consists of three core modules: image refining, extrapolation, and MBIR. Momentum-Net guarantees convergence to a fixed-point for general differentiable (non)convex MBIR functions (or data-fit terms) and convex feasible sets, under two asymptomatic conditions. To consider data-fit variations across training and testing samples, we also propose a regularization parameter selection scheme based on the \"spectral spread\" of majorization matrices. Numerical experiments for light-field photography using a focal stack and sparse-view computational tomography demonstrate that, given identical regression NN architectures, Momentum-Net significantly improves MBIR speed and accuracy over several existing INNs; it significantly improves reconstruction quality compared to a state-of-the-art MBIR method in each application.", "published": "2019-07-26T23:42:37Z", "version": 3}, {"aid": "1907.11891", "authors": ["Mingtian Zhang", "Thomas Bird", "Raza Habib", "Tianlin Xu", "David Barber"], "title": "Variational f-divergence Minimization", "url": "http://arxiv.org/pdf/1907.11891v2", "summary": "Probabilistic models are often trained by maximum likelihood, which corresponds to minimizing a specific f-divergence between the model and data distribution. In light of recent successes in training Generative Adversarial Networks, alternative non-likelihood training criteria have been proposed. Whilst not necessarily statistically efficient, these alternatives may better match user requirements such as sharp image generation. A general variational method for training probabilistic latent variable models using maximum likelihood is well established; however, how to train latent variable models using other f-divergences is comparatively unknown. We discuss a variational approach that, when combined with the recently introduced Spread Divergence, can be applied to train a large class of latent variable models using any f-divergence.", "published": "2019-07-27T10:32:08Z", "version": 2}, {"aid": "1907.12046", "authors": ["Francis Engelmann", "Theodora Kontogianni", "Bastian Leibe"], "title": "Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds", "url": "http://arxiv.org/pdf/1907.12046v3", "summary": "In this work, we propose Dilated Point Convolutions (DPC). In a thorough ablation study, we show that the receptive field size is directly related to the performance of 3D point cloud processing tasks, including semantic segmentation and object classification. Point convolutions are widely used to efficiently process 3D data representations such as point clouds or graphs. However, we observe that the receptive field size of recent point convolutional networks is inherently limited. Our dilated point convolutions alleviate this issue, they significantly increase the receptive field size of point convolutions. Importantly, our dilation mechanism can easily be integrated into most existing point convolutional networks. To evaluate the resulting network architectures, we visualize the receptive field and report competitive scores on popular point cloud benchmarks.", "published": "2019-07-28T08:52:41Z", "version": 3}, {"aid": "1907.12256", "authors": ["Xianyang Li", "Feng Wang", "Qinghao Hu", "Cong Leng"], "title": "AirFace: Lightweight and Efficient Model for Face Recognition", "url": "http://arxiv.org/pdf/1907.12256v3", "summary": "With the development of convolutional neural network, significant progress has been made in computer vision tasks. However, the commonly used loss function softmax loss and highly efficient network architecture for common visual tasks are not as effective for face recognition. In this paper, we propose a novel loss function named Li-ArcFace based on ArcFace. Li-ArcFace takes the value of the angle through linear function as the target logit rather than through cosine function, which has better convergence and performance on low dimensional embedding feature learning for face recognition. In terms of network architecture, we improved the the perfomance of MobileFaceNet by increasing the network depth, width and adding attention module. Besides, we found some useful training tricks for face recognition. With all the above results, we won the second place in the deepglint-light challenge of LFR2019.", "published": "2019-07-29T08:04:37Z", "version": 3}, {"aid": "1907.12537", "authors": ["Andrew Cook", "Bappaditya Mandal", "Donna Berry", "Matthew Johnson"], "title": "Towards Automatic Screening of Typical and Atypical Behaviors in Children With Autism", "url": "http://arxiv.org/pdf/1907.12537v2", "summary": "This paper has been withdrawn by the authors due to insufficient or definition error(s) in the ethics approval protocol.   Autism spectrum disorders (ASD) impact the cognitive, social, communicative and behavioral abilities of an individual. The development of new clinical decision support systems is of importance in reducing the delay between presentation of symptoms and an accurate diagnosis. In this work, we contribute a new database consisting of video clips of typical (normal) and atypical (such as hand flapping, spinning or rocking) behaviors, displayed in natural settings, which have been collected from the YouTube video website. We propose a preliminary non-intrusive approach based on skeleton keypoint identification using pretrained deep neural networks on human body video clips to extract features and perform body movement analysis that differentiates typical and atypical behaviors of children. Experimental results on the newly contributed database show that our platform performs best with decision tree as the classifier when compared to other popular methodologies and offers a baseline against which alternate approaches may developed and tested.", "published": "2019-07-29T17:18:11Z", "version": 2}, {"aid": "1908.04396", "authors": ["Xi Zhang", "Xiaolin Wu", "Jun Du"], "title": "Challenge of Spatial Cognition for Deep Learning", "url": "http://arxiv.org/pdf/1908.04396v2", "summary": "Given the success of the deep convolutional neural networks (DCNNs) in applications of visual recognition and classification, it would be tantalizing to test if DCNNs can also learn spatial concepts, such as straightness, convexity, left/right, front/back, relative size, aspect ratio, polygons, etc., from varied visual examples of these concepts that are simple and yet vital for spatial reasoning. Much to our dismay, extensive experiments of the type of cognitive psychology demonstrate that the data-driven deep learning (DL) cannot see through superficial variations in visual representations and grasp the spatial concept in abstraction. The root cause of failure turns out to be the learning methodology, not the computational model of the neural network itself. By incorporating task-specific convolutional kernels, we are able to construct DCNNs for spatial cognition tasks that can generalize to input images not drawn from the same distribution of the training set. This work raises a precaution that without manually-incorporated priors or features DCCNs may fail spatial cognitive tasks at rudimentary level.", "published": "2019-07-30T11:35:40Z", "version": 2}, {"aid": "1907.13196", "authors": ["Mohammed Amin Abdullah", "Hang Ren", "Haitham Bou Ammar", "Vladimir Milenkovic", "Rui Luo", "Mingtian Zhang", "Jun Wang"], "title": "Wasserstein Robust Reinforcement Learning", "url": "http://arxiv.org/pdf/1907.13196v4", "summary": "Reinforcement learning algorithms, though successful, tend to over-fit to training environments hampering their application to the real-world. This paper proposes $\\text{W}\\text{R}^{2}\\text{L}$ -- a robust reinforcement learning algorithm with significant robust performance on low and high-dimensional control tasks. Our method formalises robust reinforcement learning as a novel min-max game with a Wasserstein constraint for a correct and convergent solver. Apart from the formulation, we also propose an efficient and scalable solver following a novel zero-order optimisation method that we believe can be useful to numerical optimisation in general. We empirically demonstrate significant gains compared to standard and robust state-of-the-art algorithms on high-dimensional MuJuCo environments.", "published": "2019-07-30T19:42:52Z", "version": 4}, {"aid": "1907.13255", "authors": ["Amit Kumar", "Rama Chellappa"], "title": "Landmark Detection in Low Resolution Faces with Semi-Supervised Learning", "url": "http://arxiv.org/pdf/1907.13255v1", "summary": "Landmark detection algorithms trained on high resolution images perform poorly on datasets containing low resolution images. This deters the performance of algorithms relying on quality landmarks, for example, face recognition. To the best of our knowledge, there does not exist any dataset consisting of low resolution face images along with their annotated landmarks, making supervised training infeasible. In this paper, we present a semi-supervised approach to predict landmarks on low resolution images by learning them from labeled high resolution images. The objective of this work is to show that predicting landmarks directly on low resolution images is more effective than the current practice of aligning images after rescaling or superresolution. In a two-step process, the proposed approach first learns to generate low resolution images by modeling the distribution of target low resolution images. In the second stage, the roles of generated images and real low resolution images are switched and the model learns to predict landmarks for real low resolution images from generated low resolution images. With extensive experimentation, we study the impact of each of the design choices and also show that prediction of landmarks directly on low resolution images improves the performance of important tasks such as face recognition in low resolution images.", "published": "2019-07-30T23:12:01Z", "version": 1}, {"aid": "1908.00077", "authors": ["Jennifer Stiso", "Marie-Constance Corsi", "Jean M. Vettel", "Javier O. Garcia", "Fabio Pasqualetti", "Fabrizio De Vico Fallani", "Timothy H. Lucas", "Danielle S. Bassett"], "title": "Learning in brain-computer interface control evidenced by joint decomposition of brain and behavior", "url": "http://arxiv.org/pdf/1908.00077v2", "summary": "Motor imagery-based brain-computer interfaces (BCIs) use an individuals ability to volitionally modulate localized brain activity as a therapy for motor dysfunction or to probe causal relations between brain activity and behavior. However, many individuals cannot learn to successfully modulate their brain activity, greatly limiting the efficacy of BCI for therapy and for basic scientific inquiry. Previous research suggests that coherent activity across diverse cognitive systems is a hallmark of individuals who can successfully learn to control the BCI. However, little is known about how these distributed networks interact through time to support learning. Here, we address this gap in knowledge by constructing and applying a multimodal network approach to decipher brain-behavior relations in motor imagery-based brain-computer interface learning using MEG. Specifically, we employ a minimally constrained matrix decomposition method (non-negative matrix factorization) to simultaneously identify regularized, covarying subgraphs of functional connectivity, to assess their similarity to task performance, and to detect their time-varying expression. Individuals also displayed marked variation in the spatial properties of subgraphs such as the connectivity between the frontal lobe and the rest of the brain, and in the temporal properties of subgraphs such as the stage of learning at which they reached maximum expression. From these observations, we posit a conceptual model in which certain subgraphs support learning by modulating brain activity in regions important for sustaining attention. To test this model, we use tools that stipulate regional dynamics on a networked system (network control theory), and find that good learners display a single subgraph whose temporal expression tracked performance and whose architecture supports easy modulation of brain regions important for attention.", "published": "2019-07-31T20:17:07Z", "version": 2}, {"aid": "1908.00473", "authors": ["Pengyi Zhang", "Yunxin Zhong", "Yulin Deng", "Xiaoying Tang", "Xiaoqiong Li"], "title": "A Survey on Deep Learning of Small Sample in Biomedical Image Analysis", "url": "http://arxiv.org/pdf/1908.00473v1", "summary": "The success of deep learning has been witnessed as a promising technique for computer-aided biomedical image analysis, due to end-to-end learning framework and availability of large-scale labelled samples. However, in many cases of biomedical image analysis, deep learning techniques suffer from the small sample learning (SSL) dilemma caused mainly by lack of annotations. To be more practical for biomedical image analysis, in this paper we survey the key SSL techniques that help relieve the suffering of deep learning by combining with the development of related techniques in computer vision applications. In order to accelerate the clinical usage of biomedical image analysis based on deep learning techniques, we intentionally expand this survey to include the explanation methods for deep models that are important to clinical decision making. We survey the key SSL techniques by dividing them into five categories: (1) explanation techniques, (2) weakly supervised learning techniques, (3) transfer learning techniques, (4) active learning techniques, and (5) miscellaneous techniques involving data augmentation, domain knowledge, traditional shallow methods and attention mechanism. These key techniques are expected to effectively support the application of deep learning in clinical biomedical image analysis, and furtherly improve the analysis performance, especially when large-scale annotated samples are not available. We bulid demos at https://github.com/PengyiZhang/MIADeepSSL.", "published": "2019-08-01T16:01:31Z", "version": 1}, {"aid": "1908.00682", "authors": ["Feifan Lv", "Yu Li", "Feng Lu"], "title": "Attention Guided Low-light Image Enhancement with a Large Scale Low-light Simulation Dataset", "url": "http://arxiv.org/pdf/1908.00682v3", "summary": "Low-light image enhancement is challenging in that it needs to consider not only brightness recovery but also complex issues like color distortion and noise, which usually hide in the dark. Simply adjusting the brightness of a low-light image will inevitably amplify those artifacts. To address this difficult problem, this paper proposes a novel end-to-end attention-guided method based on multi-branch convolutional neural network. To this end, we first construct a synthetic dataset with carefully designed low-light simulation strategies. The dataset is much larger and more diverse than existing ones. With the new dataset for training, our method learns two attention maps to guide the brightness enhancement and denoising tasks respectively. The first attention map distinguishes underexposed regions from well lit regions, and the second attention map distinguishes noises from real textures. With their guidance, the proposed multi-branch decomposition-and-fusion enhancement network works in an input adaptive way. Moreover, a reinforcement-net further enhances color and contrast of the output image. Extensive experiments on multiple datasets demonstrate that our method can produce high fidelity enhancement results for low-light images and outperforms the current state-of-the-art methods by a large margin both quantitatively and visually.", "published": "2019-08-02T02:28:00Z", "version": 3}, {"aid": "1908.00704", "authors": ["Alireza Naghizadeh", "Mohammadsajad Abavisani", "Dimitris N. Metaxas"], "title": "Greedy AutoAugment", "url": "http://arxiv.org/pdf/1908.00704v2", "summary": "A major problem in data augmentation is to ensure that the generated new samples cover the search space. This is a challenging problem and requires exploration for data augmentation policies to ensure their effectiveness in covering the search space. In this paper, we propose Greedy AutoAugment as a highly efficient search algorithm to find the best augmentation policies. We use a greedy approach to reduce the exponential growth of the number of possible trials to linear growth. The Greedy Search also helps us to lead the search towards the sub-policies with better results, which eventually helps to increase the accuracy. The proposed method can be used as a reliable addition to the current artifitial neural networks. Our experiments on four datasets (Tiny ImageNet, CIFAR-10, CIFAR-100, and SVHN) show that Greedy AutoAugment provides better accuracy, while using 360 times fewer computational resources.", "published": "2019-08-02T05:28:03Z", "version": 2}, {"aid": "1908.00821", "authors": ["Yuenan Hou", "Zheng Ma", "Chunxiao Liu", "Chen Change Loy"], "title": "Learning Lightweight Lane Detection CNNs by Self Attention Distillation", "url": "http://arxiv.org/pdf/1908.00821v1", "summary": "Training deep models for lane detection is challenging due to the very subtle and sparse supervisory signals inherent in lane annotations. Without learning from much richer context, these models often fail in challenging scenarios, e.g., severe occlusion, ambiguous lanes, and poor lighting conditions. In this paper, we present a novel knowledge distillation approach, i.e., Self Attention Distillation (SAD), which allows a model to learn from itself and gains substantial improvement without any additional supervision or labels. Specifically, we observe that attention maps extracted from a model trained to a reasonable level would encode rich contextual information. The valuable contextual information can be used as a form of 'free' supervision for further representation learning through performing topdown and layer-wise attention distillation within the network itself. SAD can be easily incorporated in any feedforward convolutional neural networks (CNN) and does not increase the inference time. We validate SAD on three popular lane detection benchmarks (TuSimple, CULane and BDD100K) using lightweight models such as ENet, ResNet-18 and ResNet-34. The lightest model, ENet-SAD, performs comparatively or even surpasses existing algorithms. Notably, ENet-SAD has 20 x fewer parameters and runs 10 x faster compared to the state-of-the-art SCNN, while still achieving compelling performance in all benchmarks. Our code is available at https://github.com/cardwing/Codes-for-Lane-Detection.", "published": "2019-08-02T12:13:34Z", "version": 1}, {"aid": "1908.01070", "authors": ["Brian Teixeira", "Birgi Tamersoy", "Vivek Singh", "Ankur Kapoor"], "title": "Adaloss: Adaptive Loss Function for Landmark Localization", "url": "http://arxiv.org/pdf/1908.01070v1", "summary": "Landmark localization is a challenging problem in computer vision with a multitude of applications. Recent deep learning based methods have shown improved results by regressing likelihood maps instead of regressing the coordinates directly. However, setting the precision of these regression targets during the training is a cumbersome process since it creates a trade-off between trainability vs localization accuracy. Using precise targets introduces a significant sampling bias and hence makes the training more difficult, whereas using imprecise targets results in inaccurate landmark detectors. In this paper, we introduce \"Adaloss\", an objective function that adapts itself during the training by updating the target precision based on the training statistics. This approach does not require setting problem-specific parameters and shows improved stability in training and better localization accuracy during inference. We demonstrate the effectiveness of our proposed method in three different applications of landmark localization: 1) the challenging task of precisely detecting catheter tips in medical X-ray images, 2) localizing surgical instruments in endoscopic images, and 3) localizing facial features on in-the-wild images where we show state-of-the-art results on the 300-W benchmark dataset.", "published": "2019-08-02T21:18:50Z", "version": 1}, {"aid": "1908.01166", "authors": ["Menglei Zhang", "Zhou Liu", "Lei Yu"], "title": "CRNet: Image Super-Resolution Using A Convolutional Sparse Coding Inspired Network", "url": "http://arxiv.org/pdf/1908.01166v1", "summary": "Convolutional Sparse Coding (CSC) has been attracting more and more attention in recent years, for making full use of image global correlation to improve performance on various computer vision applications. However, very few studies focus on solving CSC based image Super-Resolution (SR) problem. As a consequence, there is no significant progress in this area over a period of time. In this paper, we exploit the natural connection between CSC and Convolutional Neural Networks (CNN) to address CSC based image SR. Specifically, Convolutional Iterative Soft Thresholding Algorithm (CISTA) is introduced to solve CSC problem and it can be implemented using CNN architectures. Then we develop a novel CSC based SR framework analogy to the traditional SC based SR methods. Two models inspired by this framework are proposed for pre-/post-upsampling SR, respectively. Compared with recent state-of-the-art SR methods, both of our proposed models show superior performance in terms of both quantitative and qualitative measurements.", "published": "2019-08-03T13:10:03Z", "version": 1}, {"aid": "1908.01259", "authors": ["Xilai Li", "Wei Sun", "Tianfu Wu"], "title": "Attentive Normalization", "url": "http://arxiv.org/pdf/1908.01259v3", "summary": "In state-of-the-art deep neural networks, both feature normalization and feature attention have become ubiquitous. % with significant performance improvement shown in a vast amount of tasks. They are usually studied as separate modules, however. In this paper, we propose a light-weight integration between the two schema and present Attentive Normalization (AN). Instead of learning a single affine transformation, AN learns a mixture of affine transformations and utilizes their weighted-sum as the final affine transformation applied to re-calibrate features in an instance-specific way. The weights are learned by leveraging channel-wise feature attention. In experiments, we test the proposed AN using four representative neural architectures in the ImageNet-1000 classification benchmark and the MS-COCO 2017 object detection and instance segmentation benchmark. AN obtains consistent performance improvement for different neural architectures in both benchmarks with absolute increase of top-1 accuracy in ImageNet-1000 between 0.5\\% and 2.7\\%, and absolute increase up to 1.8\\% and 2.2\\% for bounding box and mask AP in MS-COCO respectively. We observe that the proposed AN provides a strong alternative to the widely used Squeeze-and-Excitation (SE) module. The source codes are publicly available at https://github.com/iVMCL/AOGNet-v2 (the ImageNet Classification Repo) and https://github.com/iVMCL/AttentiveNorm\\_Detection (the MS-COCO Detection and Segmentation Repo).", "published": "2019-08-04T02:17:34Z", "version": 3}, {"aid": "1908.01477", "authors": ["Haibao Yu", "Tuopu Wen", "Guangliang Cheng", "Jiankai Sun", "Qi Han", "Jianping Shi"], "title": "GDRQ: Group-based Distribution Reshaping for Quantization", "url": "http://arxiv.org/pdf/1908.01477v1", "summary": "Low-bit quantization is challenging to maintain high performance with limited model capacity (e.g., 4-bit for both weights and activations). Naturally, the distribution of both weights and activations in deep neural network are Gaussian-like. Nevertheless, due to the limited bitwidth of low-bit model, uniform-like distributed weights and activations have been proved to be more friendly to quantization while preserving accuracy~\\cite{Han2015Learning}. Motivated by this, we propose Scale-Clip, a Distribution Reshaping technique that can reshape weights or activations into a uniform-like distribution in a dynamic manner. Furthermore, to increase the model capability for a low-bit model, a novel Group-based Quantization algorithm is proposed to split the filters into several groups. Different groups can learn different quantization parameters, which can be elegantly merged in to batch normalization layer without extra computational cost in the inference stage. Finally, we integrate Scale-Clip technique with Group-based Quantization algorithm and propose the Group-based Distribution Reshaping Quantization (GDQR) framework to further improve the quantization performance. Experiments on various networks (e.g. VGGNet and ResNet) and vision tasks (e.g. classification, detection and segmentation) demonstrate that our framework achieves good performance.", "published": "2019-08-05T05:44:52Z", "version": 1}, {"aid": "1908.01581", "authors": ["Ruofan Liang", "Tianlin Li", "Longfei Li", "Jing Wang", "Quanshi Zhang"], "title": "Knowledge Consistency between Neural Networks and Beyond", "url": "http://arxiv.org/pdf/1908.01581v2", "summary": "This paper aims to analyze knowledge consistency between pre-trained deep neural networks. We propose a generic definition for knowledge consistency between neural networks at different fuzziness levels. A task-agnostic method is designed to disentangle feature components, which represent the consistent knowledge, from raw intermediate-layer features of each neural network. As a generic tool, our method can be broadly used for different applications. In preliminary experiments, we have used knowledge consistency as a tool to diagnose representations of neural networks. Knowledge consistency provides new insights to explain the success of existing deep-learning techniques, such as knowledge distillation and network compression. More crucially, knowledge consistency can also be used to refine pre-trained networks and boost performance.", "published": "2019-08-05T12:25:37Z", "version": 2}, {"aid": "1908.01867", "authors": ["Cengiz Pehlevan", "Dmitri B. Chklovskii"], "title": "Neuroscience-inspired online unsupervised learning algorithms", "url": "http://arxiv.org/pdf/1908.01867v2", "summary": "Although the currently popular deep learning networks achieve unprecedented performance on some tasks, the human brain still has a monopoly on general intelligence. Motivated by this and biological implausibility of deep learning networks, we developed a family of biologically plausible artificial neural networks (NNs) for unsupervised learning. Our approach is based on optimizing principled objective functions containing a term that matches the pairwise similarity of outputs to the similarity of inputs, hence the name - similarity-based. Gradient-based online optimization of such similarity-based objective functions can be implemented by NNs with biologically plausible local learning rules. Similarity-based cost functions and associated NNs solve unsupervised learning tasks such as linear dimensionality reduction, sparse and/or nonnegative feature extraction, blind nonnegative source separation, clustering and manifold learning.", "published": "2019-08-05T21:30:35Z", "version": 2}, {"aid": "1908.02197", "authors": ["Dongwei Ren", "Kai Zhang", "Qilong Wang", "Qinghua Hu", "Wangmeng Zuo"], "title": "Neural Blind Deconvolution Using Deep Priors", "url": "http://arxiv.org/pdf/1908.02197v2", "summary": "Blind deconvolution is a classical yet challenging low-level vision problem with many real-world applications. Traditional maximum a posterior (MAP) based methods rely heavily on fixed and handcrafted priors that certainly are insufficient in characterizing clean images and blur kernels, and usually adopt specially designed alternating minimization to avoid trivial solution. In contrast, existing deep motion deblurring networks learn from massive training images the mapping to clean image or blur kernel, but are limited in handling various complex and large size blur kernels. To connect MAP and deep models, we in this paper present two generative networks for respectively modeling the deep priors of clean image and blur kernel, and propose an unconstrained neural optimization solution to blind deconvolution. In particular, we adopt an asymmetric Autoencoder with skip connections for generating latent clean image, and a fully-connected network (FCN) for generating blur kernel. Moreover, the SoftMax nonlinearity is applied to the output layer of FCN to meet the non-negative and equality constraints. The process of neural optimization can be explained as a kind of \"zero-shot\" self-supervised learning of the generative networks, and thus our proposed method is dubbed SelfDeblur. Experimental results show that our SelfDeblur can achieve notable quantitative gains as well as more visually plausible deblurring results in comparison to state-of-the-art blind deconvolution methods on benchmark datasets and real-world blurry images. The source code is available at https://github.com/csdwren/SelfDeblur", "published": "2019-08-06T15:03:44Z", "version": 2}, {"aid": "1908.02498", "authors": ["Gihyun Kwon", "Chihye Han", "Dae-shik Kim"], "title": "Generation of 3D Brain MRI Using Auto-Encoding Generative Adversarial Networks", "url": "http://arxiv.org/pdf/1908.02498v1", "summary": "As deep learning is showing unprecedented success in medical image analysis tasks, the lack of sufficient medical data is emerging as a critical problem. While recent attempts to solve the limited data problem using Generative Adversarial Networks (GAN) have been successful in generating realistic images with diversity, most of them are based on image-to-image translation and thus require extensive datasets from different domains. Here, we propose a novel model that can successfully generate 3D brain MRI data from random vectors by learning the data distribution. Our 3D GAN model solves both image blurriness and mode collapse problems by leveraging alpha-GAN that combines the advantages of Variational Auto-Encoder (VAE) and GAN with an additional code discriminator network. We also use the Wasserstein GAN with Gradient Penalty (WGAN-GP) loss to lower the training instability. To demonstrate the effectiveness of our model, we generate new images of normal brain MRI and show that our model outperforms baseline models in both quantitative and qualitative measurements. We also train the model to synthesize brain disorder MRI data to demonstrate the wide applicability of our model. Our results suggest that the proposed model can successfully generate various types and modalities of 3D whole brain volumes from a small set of training data.", "published": "2019-08-07T09:33:03Z", "version": 1}, {"aid": "1908.02626", "authors": ["Marco Rudolph", "Bastian Wandt", "Bodo Rosenhahn"], "title": "Structuring Autoencoders", "url": "http://arxiv.org/pdf/1908.02626v1", "summary": "In this paper we propose Structuring AutoEncoders (SAE). SAEs are neural networks which learn a low dimensional representation of data which are additionally enriched with a desired structure in this low dimensional space. While traditional Autoencoders have proven to structure data naturally they fail to discover semantic structure that is hard to recognize in the raw data. The SAE solves the problem by enhancing a traditional Autoencoder using weak supervision to form a structured latent space. In the experiments we demonstrate, that the structured latent space allows for a much more efficient data representation for further tasks such as classification for sparsely labeled data, an efficient choice of data to label, and morphing between classes. To demonstrate the general applicability of our method, we show experiments on the benchmark image datasets MNIST, Fashion-MNIST, DeepFashion2 and on a dataset of 3D human shapes.", "published": "2019-08-07T13:29:11Z", "version": 1}, {"aid": "1908.02648", "authors": ["Seongmin Hwang", "Gwanghuyn Yu", "Cheolkon Jung", "Jinyoung Kim"], "title": "Attention-Aware Linear Depthwise Convolution for Single Image Super-Resolution", "url": "http://arxiv.org/pdf/1908.02648v3", "summary": "Although deep convolutional neural networks (CNNs) have obtained outstanding performance in image superresolution (SR), their computational cost increases geometrically as CNN models get deeper and wider. Meanwhile, the features of intermediate layers are treated equally across the channel, thus hindering the representational capability of CNNs. In this paper, we propose an attention-aware linear depthwise network to address the problems for single image SR, named ALDNet. Specifically, linear depthwise convolution allows CNN-based SR models to preserve useful information for reconstructing a super-resolved image while reducing computational burden. Furthermore, we design an attention-aware branch that enhances the representation ability of depthwise convolution layers by making full use of depthwise filter interdependency. Experiments on publicly available benchmark datasets show that ALDNet achieves superior performance to traditional depthwise separable convolutions in terms of quantitative measurements and visual quality.", "published": "2019-08-07T14:09:46Z", "version": 3}, {"aid": "1908.02735", "authors": ["Pierre Jacob", "David Picard", "Aymeric Histace", "Edouard Klein"], "title": "Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings", "url": "http://arxiv.org/pdf/1908.02735v1", "summary": "Learning an effective similarity measure between image representations is key to the success of recent advances in visual search tasks (e.g. verification or zero-shot learning). Although the metric learning part is well addressed, this metric is usually computed over the average of the extracted deep features. This representation is then trained to be discriminative. However, these deep features tend to be scattered across the feature space. Consequently, the representations are not robust to outliers, object occlusions, background variations, etc. In this paper, we tackle this scattering problem with a distribution-aware regularization named HORDE. This regularizer enforces visually-close images to have deep features with the same distribution which are well localized in the feature space. We provide a theoretical analysis supporting this regularization effect. We also show the effectiveness of our approach by obtaining state-of-the-art results on 4 well-known datasets (Cub-200-2011, Cars-196, Stanford Online Products and Inshop Clothes Retrieval).", "published": "2019-08-07T17:22:01Z", "version": 1}, {"aid": "1908.03015", "authors": ["Felix Berkhahn", "Richard Keys", "Wajih Ouertani", "Nikhil Shetty", "Dominik Gei\u00dfler"], "title": "Augmenting Variational Autoencoders with Sparse Labels: A Unified Framework for Unsupervised, Semi-(un)supervised, and Supervised Learning", "url": "http://arxiv.org/pdf/1908.03015v2", "summary": "We present a new flavor of Variational Autoencoder (VAE) that interpolates seamlessly between unsupervised, semi-supervised and fully supervised learning domains. We show that unlabeled datapoints not only boost unsupervised tasks, but also the classification performance. Vice versa, every label not only improves classification, but also unsupervised tasks. The proposed architecture is simple: A classification layer is connected to the topmost encoder layer, and then combined with the resampled latent layer for the decoder. The usual evidence lower bound (ELBO) loss is supplemented with a supervised loss target on this classification layer that is only applied for labeled datapoints. This simplicity allows for extending any existing VAE model to our proposed semi-supervised framework with minimal effort. In the context of classification, we found that this approach even outperforms a direct supervised setup.", "published": "2019-08-08T11:07:22Z", "version": 2}, {"aid": "1908.03532", "authors": ["Leendert A Remmelzwaal", "George F R Ellis", "Jonathan Tapson", "Amit K Mishra"], "title": "Biologically-inspired Salience Affected Artificial Neural Network (SANN)", "url": "http://arxiv.org/pdf/1908.03532v5", "summary": "In this paper we introduce a novel Salience Affected Artificial Neural Network (SANN) that models the way neuromodulators such as dopamine and noradrenaline affect neural dynamics in the human brain by being distributed diffusely through neocortical regions, allowing both salience signals to modulate cognition immediately, and one time learning to take place through strengthening entire patterns of activation at one go. We present a model that is capable of one-time salience tagging in a neural network trained to classify objects, and returns a salience response during classification (inference). We explore the effects of salience on learning via its effect on the activation functions of each node, as well as on the strength of weights between nodes in the network. We demonstrate that salience tagging can improve classification confidence for both the individual image as well as the class of images it belongs to. We also show that the computation impact of producing a salience response is minimal. This research serves as a proof of concept, and could be the first step towards introducing salience tagging into Deep Learning Networks and robotics.", "published": "2019-08-09T16:40:52Z", "version": 5}, {"aid": "1908.03682", "authors": ["Yang Liu", "Jianpeng Zhang", "Chao Gao", "Jinghua Qu", "Lixin Ji"], "title": "Natural-Logarithm-Rectified Activation Function in Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1908.03682v2", "summary": "Activation functions play a key role in providing remarkable performance in deep neural networks, and the rectified linear unit (ReLU) is one of the most widely used activation functions. Various new activation functions and improvements on ReLU have been proposed, but each carry performance drawbacks. In this paper, we propose an improved activation function, which we name the natural-logarithm-rectified linear unit (NLReLU). This activation function uses the parametric natural logarithmic transform to improve ReLU and is simply defined as. NLReLU not only retains the sparse activation characteristic of ReLU, but it also alleviates the \"dying ReLU\" and vanishing gradient problems to some extent. It also reduces the bias shift effect and heteroscedasticity of neuron data distributions among network layers in order to accelerate the learning process. The proposed method was verified across ten convolutional neural networks with different depths for two essential datasets. Experiments illustrate that convolutional neural networks with NLReLU exhibit higher accuracy than those with ReLU, and that NLReLU is comparable to other well-known activation functions. NLReLU provides 0.16% and 2.04% higher classification accuracy on average compared to ReLU when used in shallow convolutional neural networks with the MNIST and CIFAR-10 datasets, respectively. The average accuracy of deep convolutional neural networks with NLReLU is 1.35% higher on average with the CIFAR-10 dataset.", "published": "2019-08-10T03:51:36Z", "version": 2}, {"aid": "1908.05845", "authors": ["Matthias Springer"], "title": "Memory-Efficient Object-Oriented Programming on GPUs", "url": "http://arxiv.org/pdf/1908.05845v1", "summary": "Object-oriented programming is often regarded as too inefficient for high-performance computing (HPC), despite the fact that many important HPC problems have an inherent object structure. Our goal is to bring efficient, object-oriented programming to massively parallel SIMD architectures, especially GPUs.   In this thesis, we develop various techniques for optimizing object-oriented GPU code. Most notably, we identify the object-oriented Single-Method Multiple-Objects (SMMO) programming model. We first develop an embedded C++ Structure of Arrays (SOA) data layout DSL for SMMO applications. We then design a lock-free, dynamic memory allocator that stores allocations in SOA layout. Finally, we show how to further optimize the memory access of SMMO applications with memory defragmentation.", "published": "2019-08-16T04:50:29Z", "version": 1}, {"aid": "1908.07644", "authors": ["Gamaleldin F. Elsayed", "Simon Kornblith", "Quoc V. Le"], "title": "Saccader: Improving Accuracy of Hard Attention Models for Vision", "url": "http://arxiv.org/pdf/1908.07644v3", "summary": "Although deep convolutional neural networks achieve state-of-the-art performance across nearly all image classification tasks, their decisions are difficult to interpret. One approach that offers some level of interpretability by design is \\textit{hard attention}, which uses only relevant portions of the image. However, training hard attention models with only class label supervision is challenging, and hard attention has proved difficult to scale to complex datasets. Here, we propose a novel hard attention model, which we term Saccader. Key to Saccader is a pretraining step that requires only class labels and provides initial attention locations for policy gradient optimization. Our best models narrow the gap to common ImageNet baselines, achieving $75\\%$ top-1 and $91\\%$ top-5 while attending to less than one-third of the image.", "published": "2019-08-20T23:40:21Z", "version": 3}, {"aid": "1908.08466", "authors": ["Xiao-Yun Zhou", "Peichao Li", "Zhao-Yang Wang", "Guang-Zhong Yang"], "title": "U-Net Training with Instance-Layer Normalization", "url": "http://arxiv.org/pdf/1908.08466v2", "summary": "Normalization layers are essential in a Deep Convolutional Neural Network (DCNN). Various normalization methods have been proposed. The statistics used to normalize the feature maps can be computed at batch, channel, or instance level. However, in most of existing methods, the normalization for each layer is fixed. Batch-Instance Normalization (BIN) is one of the first proposed methods that combines two different normalization methods and achieve diverse normalization for different layers. However, two potential issues exist in BIN: first, the Clip function is not differentiable at input values of 0 and 1; second, the combined feature map is not with a normalized distribution which is harmful for signal propagation in DCNN. In this paper, an Instance-Layer Normalization (ILN) layer is proposed by using the Sigmoid function for the feature map combination, and cascading group normalization. The performance of ILN is validated on image segmentation of the Right Ventricle (RV) and Left Ventricle (LV) using U-Net as the network architecture. The results show that the proposed ILN outperforms previous traditional and popular normalization methods with noticeable accuracy improvements for most validations, supporting the effectiveness of the proposed ILN.", "published": "2019-08-21T11:24:25Z", "version": 2}, {"aid": "1908.08331", "authors": ["Dominique Beaini", "Sofiane Achiche", "Alexandre Duperr\u00e9", "Maxime Raison"], "title": "Deep Green Function Convolution for Improving Saliency in Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1908.08331v2", "summary": "Current saliency methods require to learn large scale regional features using small convolutional kernels, which is not possible with a simple feed-forward network. Some methods solve this problem by using segmentation into superpixels while others downscale the image through the network and rescale it back to its original size. The objective of this paper is to show that saliency convolutional neural networks (CNN) can be improved by using a Green's function convolution (GFC) to extrapolate edges features into salient regions. The GFC acts as a gradient integrator, allowing to produce saliency features by filling thin edges directly inside the CNN. Hence, we propose the gradient integration and sum (GIS) layer that combines the edges features with the saliency features. Using the HED and DSS architecture, we demonstrated that adding a GIS layer near the network's output allows to reduce the sensitivity to the parameter initialization, to reduce the overfitting and to improve the repeatability of the training. By simply adding a GIS layer to the state-of-the-art DSS model, there is an absolute increase of 1.6% for the F-measure on the DUT-OMRON dataset, with only 10ms of additional computation time. The GIS layer further allows the network to perform significantly better in the case of highly noisy images or low-brightness images. In fact, we observed an F-measure improvement of 5.2% when noise was added to the dataset and 2.8% when the brightness was reduced. Since the GIS layer is model agnostic, it can be implemented into different fully convolutional networks. A major contribution of the current work is the first implementation of Green's function convolution inside a neural network, which allows the network to operate in the feature domain and in the gradient domain at the same time, thus improving the regional representation via edge filling.", "published": "2019-08-22T12:14:26Z", "version": 2}, {"aid": "1908.08807", "authors": ["Hao Wu", "Ziyu Zhu", "Jiayi Wang", "Nanning Zheng", "Badong Chen"], "title": "An encoding framework with brain inner state for natural image identification", "url": "http://arxiv.org/pdf/1908.08807v1", "summary": "Neural encoding and decoding, which aim to characterize the relationship between stimuli and brain activities, have emerged as an important area in cognitive neuroscience. Traditional encoding models, which focus on feature extraction and mapping, consider the brain as an input-output mapper without inner states. In this work, inspired by the fact that human brain acts like a state machine, we proposed a novel encoding framework that combines information from both the external world and the inner state to predict brain activity. The framework comprises two parts: forward encoding model that deals with visual stimuli and inner state model that captures influence from intrinsic connections in the brain. The forward model can be any traditional encoding model, making the framework flexible. The inner state model is a linear model to utilize information in the prediction residuals of the forward model. The proposed encoding framework can achieve much better performance on natural image identification from fMRI response than forwardonly models. The identification accuracy will decrease slightly with the dataset size increasing, but remain relatively stable with different identification methods. The results confirm that the new encoding framework is effective and robust when used for brain decoding.", "published": "2019-08-22T13:41:49Z", "version": 1}, {"aid": "1908.08453", "authors": ["Abdelrahman Abdelhamed", "Marcus A. Brubaker", "Michael S. Brown"], "title": "Noise Flow: Noise Modeling with Conditional Normalizing Flows", "url": "http://arxiv.org/pdf/1908.08453v1", "summary": "Modeling and synthesizing image noise is an important aspect in many computer vision applications. The long-standing additive white Gaussian and heteroscedastic (signal-dependent) noise models widely used in the literature provide only a coarse approximation of real sensor noise. This paper introduces Noise Flow, a powerful and accurate noise model based on recent normalizing flow architectures. Noise Flow combines well-established basic parametric noise models (e.g., signal-dependent noise) with the flexibility and expressiveness of normalizing flow networks. The result is a single, comprehensive, compact noise model containing fewer than 2500 parameters yet able to represent multiple cameras and gain factors. Noise Flow dramatically outperforms existing noise models, with 0.42 nats/pixel improvement over the camera-calibrated noise level functions, which translates to 52% improvement in the likelihood of sampled noise. Noise Flow represents the first serious attempt to go beyond simple parametric models to one that leverages the power of deep learning and data-driven noise distributions.", "published": "2019-08-22T15:30:32Z", "version": 1}, {"aid": "1908.08681", "authors": ["Diganta Misra"], "title": "Mish: A Self Regularized Non-Monotonic Activation Function", "url": "http://arxiv.org/pdf/1908.08681v3", "summary": "We propose $\\textit{Mish}$, a novel self-regularized non-monotonic activation function which can be mathematically defined as: $f(x)=x\\tanh(softplus(x))$. As activation functions play a crucial role in the performance and training dynamics in neural networks, we validated experimentally on several well-known benchmarks against the best combinations of architectures and activation functions. We also observe that data augmentation techniques have a favorable effect on benchmarks like ImageNet-1k and MS-COCO across multiple architectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a CSP-DarkNet-53 backbone on average precision ($AP_{50}^{val}$) by 2.1$\\%$ in MS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy by $\\approx$1$\\%$ while keeping all other network parameters and hyperparameters constant. Furthermore, we explore the mathematical formulation of Mish in relation with the Swish family of functions and propose an intuitive understanding on how the first derivative behavior may be acting as a regularizer helping the optimization of deep neural networks. Code is publicly available at https://github.com/digantamisra98/Mish.", "published": "2019-08-23T06:22:06Z", "version": 3}, {"aid": "1909.04138", "authors": ["Jiang Lu", "Lei Li", "Changshui Zhang"], "title": "Self-reinforcing Unsupervised Matching", "url": "http://arxiv.org/pdf/1909.04138v1", "summary": "Remarkable gains in deep learning usually rely on tremendous supervised data. Ensuring the modality diversity for one object in training set is critical for the generalization of cutting-edge deep models, but it burdens human with heavy manual labor on data collection and annotation. In addition, some rare or unexpected modalities are new for the current model, causing reduced performance under such emerging modalities. Inspired by the achievements in speech recognition, psychology and behavioristics, we present a practical solution, self-reinforcing unsupervised matching (SUM), to annotate the images with 2D structure-preserving property in an emerging modality by cross-modality matching. This approach requires no any supervision in emerging modality and only one template in seen modality, providing a possible route towards continual learning.", "published": "2019-08-23T10:43:43Z", "version": 1}, {"aid": "1908.08999", "authors": ["Tomas Jenicek", "Ond\u0159ej Chum"], "title": "No Fear of the Dark: Image Retrieval under Varying Illumination Conditions", "url": "http://arxiv.org/pdf/1908.08999v1", "summary": "Image retrieval under varying illumination conditions, such as day and night images, is addressed by image preprocessing, both hand-crafted and learned. Prior to extracting image descriptors by a convolutional neural network, images are photometrically normalised in order to reduce the descriptor sensitivity to illumination changes. We propose a learnable normalisation based on the U-Net architecture, which is trained on a combination of single-camera multi-exposure images and a newly constructed collection of similar views of landmarks during day and night. We experimentally show that both hand-crafted normalisation based on local histogram equalisation and the learnable normalisation outperform standard approaches in varying illumination conditions, while staying on par with the state-of-the-art methods on daylight illumination benchmarks, such as Oxford or Paris datasets.", "published": "2019-08-23T19:30:37Z", "version": 1}, {"aid": "1908.09066", "authors": ["Le Zhang", "Zenglin Shi", "Ming-Ming Cheng", "Yun Liu", "Jia-Wang Bian", "Joey Tianyi Zhou", "Guoyan Zheng", "Zeng Zeng"], "title": "Robust Regression via Deep Negative Correlation Learning", "url": "http://arxiv.org/pdf/1908.09066v1", "summary": "Nonlinear regression has been extensively employed in many computer vision problems (e.g., crowd counting, age estimation, affective computing). Under the umbrella of deep learning, two common solutions exist i) transforming nonlinear regression to a robust loss function which is jointly optimizable with the deep convolutional network, and ii) utilizing ensemble of deep networks. Although some improved performance is achieved, the former may be lacking due to the intrinsic limitation of choosing a single hypothesis and the latter usually suffers from much larger computational complexity. To cope with those issues, we propose to regress via an efficient \"divide and conquer\" manner. The core of our approach is the generalization of negative correlation learning that has been shown, both theoretically and empirically, to work well for non-deep regression problems. Without extra parameters, the proposed method controls the bias-variance-covariance trade-off systematically and usually yields a deep regression ensemble where each base model is both \"accurate\" and \"diversified\". Moreover, we show that each sub-problem in the proposed method has less Rademacher Complexity and thus is easier to optimize. Extensive experiments on several diverse and challenging tasks including crowd counting, personality analysis, age estimation, and image super-resolution demonstrate the superiority over challenging baselines as well as the versatility of the proposed method.", "published": "2019-08-24T01:26:03Z", "version": 1}, {"aid": "1908.09124", "authors": ["Jintao Zhang"], "title": "SeesawFaceNets: sparse and robust face verification model for mobile platform", "url": "http://arxiv.org/pdf/1908.09124v3", "summary": "Deep Convolutional Neural Network (DCNNs) come to be the most widely used solution for most computer vision related tasks, and one of the most important application scenes is face verification. Due to its high-accuracy performance, deep face verification models of which the inference stage occurs on cloud platform through internet plays the key role on most prectical scenes. However, two critical issues exist: First, individual privacy may not be well protected since they have to upload their personal photo and other private information to the online cloud backend. Secondly, either training or inference stage is time-comsuming and the latency may affect customer experience, especially when the internet link speed is not so stable or in remote areas where mobile reception is not so good, but also in cities where building and other construction may block mobile signals. Therefore, designing lightweight networks with low memory requirement and computational cost is one of the most practical solutions for face verification on mobile platform. In this paper, a novel mobile network named SeesawFaceNets, a simple but effective model, is proposed for productively deploying face recognition for mobile devices. Dense experimental results have shown that our proposed model SeesawFaceNets outperforms the baseline MobilefaceNets, with only {\\bf66\\%}(146M VS 221M MAdds) computational cost, smaller batch size and less training steps, and SeesawFaceNets achieve comparable performance with other SOTA model e.g. mobiface with only {\\bf54.2\\%}(1.3M VS 2.4M) parameters and {\\bf31.6\\%}(146M VS 462M MAdds) computational cost, It is also eventually competitive against large-scale deep-networks face recognition on all 5 listed public validation datasets, with {\\bf6.5\\%}(4.2M VS 65M) parameters and {\\bf4.35\\%}(526M VS 12G MAdds) computational cost.", "published": "2019-08-24T11:21:38Z", "version": 3}, {"aid": "1908.09257", "authors": ["Ivan Kobyzev", "Simon J. D. Prince", "Marcus A. Brubaker"], "title": "Normalizing Flows: An Introduction and Review of Current Methods", "url": "http://arxiv.org/pdf/1908.09257v4", "summary": "Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.", "published": "2019-08-25T06:14:08Z", "version": 4}, {"aid": "1909.09588", "authors": ["Rene Schaub"], "title": "What are Neural Networks made of?", "url": "http://arxiv.org/pdf/1909.09588v1", "summary": "The success of Deep Learning methods is not well understood, though various attempts at explaining it have been made, typically centered on properties of stochastic gradient descent. Even less clear is why certain neural network architectures perform better than others. We provide a potential opening with the hypothesis that neural network training is a form of Genetic Programming.", "published": "2019-08-25T21:59:26Z", "version": 1}, {"aid": "1908.09442", "authors": ["Xin Li", "Tianwei Lin", "Xiao Liu", "Chuang Gan", "Wangmeng Zuo", "Chao Li", "Xiang Long", "Dongliang He", "Fu Li", "Shilei Wen"], "title": "Deep Concept-wise Temporal Convolutional Networks for Action Localization", "url": "http://arxiv.org/pdf/1908.09442v1", "summary": "Existing action localization approaches adopt shallow temporal convolutional networks (\\ie, TCN) on 1D feature map extracted from video frames. In this paper, we empirically find that stacking more conventional temporal convolution layers actually deteriorates action classification performance, possibly ascribing to that all channels of 1D feature map, which generally are highly abstract and can be regarded as latent concepts, are excessively recombined in temporal convolution. To address this issue, we introduce a novel concept-wise temporal convolution (CTC) layer as an alternative to conventional temporal convolution layer for training deeper action localization networks. Instead of recombining latent concepts, CTC layer deploys a number of temporal filters to each concept separately with shared filter parameters across concepts. Thus can capture common temporal patterns of different concepts and significantly enrich representation ability. Via stacking CTC layers, we proposed a deep concept-wise temporal convolutional network (C-TCN), which boosts the state-of-the-art action localization performance on THUMOS'14 from 42.8 to 52.1 in terms of mAP(\\%), achieving a relative improvement of 21.7\\%. Favorable result is also obtained on ActivityNet.", "published": "2019-08-26T02:56:07Z", "version": 1}, {"aid": "1908.09791", "authors": ["Han Cai", "Chuang Gan", "Tianzhe Wang", "Zhekai Zhang", "Song Han"], "title": "Once-for-All: Train One Network and Specialize it for Efficient Deployment", "url": "http://arxiv.org/pdf/1908.09791v5", "summary": "We address the challenging problem of efficient inference across many devices and resource constraints, especially on edge devices. Conventional approaches either manually design or use neural architecture search (NAS) to find a specialized neural network and train it from scratch for each case, which is computationally prohibitive (causing $CO_2$ emission as much as 5 cars' lifetime) thus unscalable. In this work, we propose to train a once-for-all (OFA) network that supports diverse architectural settings by decoupling training and search, to reduce the cost. We can quickly get a specialized sub-network by selecting from the OFA network without additional training. To efficiently train OFA networks, we also propose a novel progressive shrinking algorithm, a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution). It can obtain a surprisingly large number of sub-networks ($> 10^{19}$) that can fit different hardware platforms and latency constraints while maintaining the same level of accuracy as training independently. On diverse edge devices, OFA consistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0% ImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x faster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency) while reducing many orders of magnitude GPU hours and $CO_2$ emission. In particular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the mobile setting ($<$600M MACs). OFA is the winning solution for the 3rd Low Power Computer Vision Challenge (LPCVC), DSP classification track and the 4th LPCVC, both classification track and detection track. Code and 50 pre-trained models (for many devices & many latency constraints) are released at https://github.com/mit-han-lab/once-for-all.", "published": "2019-08-26T16:46:23Z", "version": 5}, {"aid": "1908.10059", "authors": ["Zhijun Mai", "Guosheng Hu", "Dexiong Chen", "Fumin Shen", "Heng Tao Shen"], "title": "MetaMixUp: Learning Adaptive Interpolation Policy of MixUp with Meta-Learning", "url": "http://arxiv.org/pdf/1908.10059v1", "summary": "MixUp is an effective data augmentation method to regularize deep neural networks via random linear interpolations between pairs of samples and their labels. It plays an important role in model regularization, semi-supervised learning and domain adaption. However, despite its empirical success, its deficiency of randomly mixing samples has poorly been studied. Since deep networks are capable of memorizing the entire dataset, the corrupted samples generated by vanilla MixUp with a badly chosen interpolation policy will degrade the performance of networks. To overcome the underfitting by corrupted samples, inspired by Meta-learning (learning to learn), we propose a novel technique of learning to mixup in this work, namely, MetaMixUp. Unlike the vanilla MixUp that samples interpolation policy from a predefined distribution, this paper introduces a meta-learning based online optimization approach to dynamically learn the interpolation policy in a data-adaptive way. The validation set performance via meta-learning captures the underfitting issue, which provides more information to refine interpolation policy. Furthermore, we adapt our method for pseudo-label based semisupervised learning (SSL) along with a refined pseudo-labeling strategy. In our experiments, our method achieves better performance than vanilla MixUp and its variants under supervised learning configuration. In particular, extensive experiments show that our MetaMixUp adapted SSL greatly outperforms MixUp and many state-of-the-art methods on CIFAR-10 and SVHN benchmarks under SSL configuration.", "published": "2019-08-27T07:26:35Z", "version": 1}, {"aid": "1908.10417", "authors": ["Corneliu Arsene"], "title": "Complex Deep Learning Models for Denoising of Human Heart ECG signals", "url": "http://arxiv.org/pdf/1908.10417v3", "summary": "Effective and powerful methods for denoising real electrocardiogram (ECG) signals are important for wearable sensors and devices. Deep Learning (DL) models have been used extensively in image processing and other domains with great success but only very recently have been used in processing ECG signals. This paper presents several DL models namely Convolutional Neural Networks (CNNs), Long Short-Term Memory (LSTM), Restricted Boltzmann Machine (RBM) together with the more conventional filtering methods (low pass filtering, high pass filtering, Notch filtering) and the standard wavelet-based technique for denoising EEG signals. These methods are trained, tested and evaluated on different synthetic and real ECG datasets taken from the MIT PhysioNet database and for different simulation conditions (i.e. various lengths of the ECG signals, single or multiple records). The results show the CNN model is a performant model that can be used for off-line denoising ECG applications where it is satisfactory to train on a clean part of an ECG signal from an ECG record, and then to test on the same ECG signal, which would have some high level of noise added to it. However, for real-time applications or near-real time applications, this task becomes more cumbersome, as the clean part of an ECG signal is very probable to be very limited in size. Therefore the solution put forth in this work is to train a CNN model on 1 second ECG noisy artificial multiple heartbeat data (i.e. ECG at effort), which was generated in a first instance based on few sequences of real signal heartbeat ECG data (i.e. ECG at rest). Afterwards it would be possible to use the trained CNN model in real life situations to denoise the ECG signal.", "published": "2019-08-27T19:14:32Z", "version": 3}, {"aid": "1908.11494", "authors": ["Jingbin Liu", "Xinyang Gu", "Shuai Liu"], "title": "Reinforcement learning with world model", "url": "http://arxiv.org/pdf/1908.11494v4", "summary": "Nowadays, model-free reinforcement learning algorithms have achieved remarkable performance on many decision making and control tasks, but high sample complexity and low sample efficiency still hinder the wide use of model-free reinforcement learning algorithms. In this paper, we argue that if we intend to design an intelligent agent that learns fast and transfers well, the agent must be able to reflect key elements of intelligence, like intuition, Memory, PredictionandCuriosity. We propose an agent framework that integrates off-policy reinforcement learning with world model learning, so as to embody the important features of intelligence in our algorithm design. We adopt the state-of-art model-free reinforcement learning algorithm, Soft Actor-Critic, as the agent intuition, and world model learning through RNN to endow the agent with memory, curiosity, and the ability to predict. We show that these ideas can work collaboratively with each other and our agent (RMC) can give new state-of-art results while maintaining sample efficiency and training stability. Moreover, our agent framework can be easily extended from MDP to POMDP problems without performance loss.", "published": "2019-08-30T00:29:32Z", "version": 4}, {"aid": "1908.11628", "authors": ["Sagie Benaim", "Michael Khaitov", "Tomer Galanti", "Lior Wolf"], "title": "Domain Intersection and Domain Difference", "url": "http://arxiv.org/pdf/1908.11628v1", "summary": "We present a method for recovering the shared content between two visual domains as well as the content that is unique to each domain. This allows us to map from one domain to the other, in a way in which the content that is specific for the first domain is removed and the content that is specific for the second is imported from any image in the second domain. In addition, our method enables generation of images from the intersection of the two domains as well as their union, despite having no such samples during training. The method is shown analytically to contain all the sufficient and necessary constraints. It also outperforms the literature methods in an extensive set of experiments. Our code is available at https://github.com/sagiebenaim/DomainIntersectionDifference.", "published": "2019-08-30T10:08:43Z", "version": 1}, {"aid": "1909.01779", "authors": ["Matthia Sabatelli", "Gilles Louppe", "Pierre Geurts", "Marco A. Wiering"], "title": "Approximating two value functions instead of one: towards characterizing a new family of Deep Reinforcement Learning algorithms", "url": "http://arxiv.org/pdf/1909.01779v2", "summary": "This paper makes one step forward towards characterizing a new family of \\textit{model-free} Deep Reinforcement Learning (DRL) algorithms. The aim of these algorithms is to jointly learn an approximation of the state-value function ($V$), alongside an approximation of the state-action value function ($Q$). Our analysis starts with a thorough study of the Deep Quality-Value Learning (DQV) algorithm, a DRL algorithm which has been shown to outperform popular techniques such as Deep-Q-Learning (DQN) and Double-Deep-Q-Learning (DDQN) \\cite{sabatelli2018deep}. Intending to investigate why DQV's learning dynamics allow this algorithm to perform so well, we formulate a set of research questions which help us characterize a new family of DRL algorithms. Among our results, we present some specific cases in which DQV's performance can get harmed and introduce a novel \\textit{off-policy} DRL algorithm, called DQV-Max, which can outperform DQV. We then study the behavior of the $V$ and $Q$ functions that are learned by DQV and DQV-Max and show that both algorithms might perform so well on several DRL test-beds because they are less prone to suffer from the overestimation bias of the $Q$ function.", "published": "2019-09-01T10:29:54Z", "version": 2}, {"aid": "1909.00390", "authors": ["Philip May"], "title": "Improved Image Augmentation for Convolutional Neural Networks by Copyout and CopyPairing", "url": "http://arxiv.org/pdf/1909.00390v2", "summary": "Image augmentation is a widely used technique to improve the performance of convolutional neural networks (CNNs). In common image shifting, cropping, flipping, shearing and rotating are used for augmentation. But there are more advanced techniques like Cutout and SamplePairing. In this work we present two improvements of the state-of-the-art Cutout and SamplePairing techniques. Our new method called Copyout takes a square patch of another random training image and copies it onto a random location of each image used for training. The second technique we discovered is called CopyPairing. It combines Copyout and SamplePairing for further augmentation and even better performance. We apply different experiments with these augmentation techniques on the CIFAR-10 dataset to evaluate and compare them under different configurations. In our experiments we show that Copyout reduces the test error rate by 8.18% compared with Cutout and 4.27% compared with SamplePairing. CopyPairing reduces the test error rate by 11.97% compared with Cutout and 8.21% compared with SamplePairing. Copyout and CopyPairing implementations are available at https://github.com/t-systems-on-site-services-gmbh/coocop.", "published": "2019-09-01T12:59:09Z", "version": 2}, {"aid": "1909.05632", "authors": ["Arno Khachatourian"], "title": "Reusing Convolutional Activations from Frame to Frame to Speed up Training and Inference", "url": "http://arxiv.org/pdf/1909.05632v2", "summary": "When processing similar frames in succession, we can take advantage of the locality of the convolution operation to reevaluate only portions of the image that changed from the previous frame. By saving the output of a layer of convolutions and calculating the change from frame to frame, we can reuse previous activations and save computational resources that would otherwise be wasted recalculating convolutions whose outputs we have already observed. This technique can be applied to many domains, such as processing videos from stationary video cameras, studying the effects of occluding or distorting sections of images, applying convolution to multiple frames of audio or time series data, or playing Atari games. Furthermore, this technique can be applied to speed up both training and inference.", "published": "2019-09-02T00:21:03Z", "version": 2}, {"aid": "1909.01939", "authors": ["Pengfei Zhang", "Jianru Xue", "Cuiling Lan", "Wenjun Zeng", "Zhanning Gao", "Nanning Zheng"], "title": "EleAtt-RNN: Adding Attentiveness to Neurons in Recurrent Neural Networks", "url": "http://arxiv.org/pdf/1909.01939v1", "summary": "Recurrent neural networks (RNNs) are capable of modeling temporal dependencies of complex sequential data. In general, current available structures of RNNs tend to concentrate on controlling the contributions of current and previous information. However, the exploration of different importance levels of different elements within an input vector is always ignored. We propose a simple yet effective Element-wise-Attention Gate (EleAttG), which can be easily added to an RNN block (e.g. all RNN neurons in an RNN layer), to empower the RNN neurons to have attentiveness capability. For an RNN block, an EleAttG is used for adaptively modulating the input by assigning different levels of importance, i.e., attention, to each element/dimension of the input. We refer to an RNN block equipped with an EleAttG as an EleAtt-RNN block. Instead of modulating the input as a whole, the EleAttG modulates the input at fine granularity, i.e., element-wise, and the modulation is content adaptive. The proposed EleAttG, as an additional fundamental unit, is general and can be applied to any RNN structures, e.g., standard RNN, Long Short-Term Memory (LSTM), or Gated Recurrent Unit (GRU). We demonstrate the effectiveness of the proposed EleAtt-RNN by applying it to different tasks including the action recognition, from both skeleton-based data and RGB videos, gesture recognition, and sequential MNIST classification. Experiments show that adding attentiveness through EleAttGs to RNN blocks significantly improves the power of RNNs.", "published": "2019-09-03T08:15:09Z", "version": 1}, {"aid": "1909.01039", "authors": ["Henrich Kolkhorst", "Wolfram Burgard", "Michael Tangermann"], "title": "Learning User Preferences for Trajectories from Brain Signals", "url": "http://arxiv.org/pdf/1909.01039v2", "summary": "Robot motions in the presence of humans should not only be feasible and safe, but also conform to human preferences. This, however, requires user feedback on the robot's behavior. In this work, we propose a novel approach to leverage the user's brain signals as a feedback modality in order to decode the judgment of robot trajectories and rank them according to the user's preferences. We show that brain signals measured using electroencephalography during observation of a robotic arm's trajectory as well as in response to preference statements are informative regarding the user's preference. Furthermore, we demonstrate that user feedback from brain signals can be used to reliably infer pairwise trajectory preferences as well as to retrieve the preferred observed trajectories of the user with a performance comparable to explicit behavioral feedback.", "published": "2019-09-03T10:20:50Z", "version": 2}, {"aid": "1909.01815", "authors": ["Bernhard Egger", "William A. P. Smith", "Ayush Tewari", "Stefanie Wuhrer", "Michael Zollhoefer", "Thabo Beeler", "Florian Bernard", "Timo Bolkart", "Adam Kortylewski", "Sami Romdhani", "Christian Theobalt", "Volker Blanz", "Thomas Vetter"], "title": "3D Morphable Face Models -- Past, Present and Future", "url": "http://arxiv.org/pdf/1909.01815v2", "summary": "In this paper, we provide a detailed survey of 3D Morphable Face Models over the 20 years since they were first proposed. The challenges in building and applying these models, namely capture, modeling, image formation, and image analysis, are still active research topics, and we review the state-of-the-art in each of these areas. We also look ahead, identifying unsolved challenges, proposing directions for future research and highlighting the broad range of current and future applications.", "published": "2019-09-03T16:49:53Z", "version": 2}, {"aid": "1909.01498", "authors": ["Parth Natekar", "Avinash Kori", "Ganapathy Krishnamurthi"], "title": "Demystifying Brain Tumour Segmentation Networks: Interpretability and Uncertainty Analysis", "url": "http://arxiv.org/pdf/1909.01498v3", "summary": "The accurate automatic segmentation of gliomas and its intra-tumoral structures is important not only for treatment planning but also for follow-up evaluations. Several methods based on 2D and 3D Deep Neural Networks (DNN) have been developed to segment brain tumors and to classify different categories of tumors from different MRI modalities. However, these networks are often black-box models and do not provide any evidence regarding the process they take to perform this task. Increasing transparency and interpretability of such deep learning techniques are necessary for the complete integration of such methods into medical practice. In this paper, we explore various techniques to explain the functional organization of brain tumor segmentation models and to extract visualizations of internal concepts to understand how these networks achieve highly accurate tumor segmentations. We use the BraTS 2018 dataset to train three different networks with standard architectures and outline similarities and differences in the process that these networks take to segment brain tumors. We show that brain tumor segmentation networks learn certain human-understandable disentangled concepts on a filter level. We also show that they take a top-down or hierarchical approach to localizing the different parts of the tumor. We then extract visualizations of some internal feature maps and also provide a measure of uncertainty with regards to the outputs of the models to give additional qualitative evidence about the predictions of these networks. We believe that the emergence of such human-understandable organization and concepts might aid in the acceptance and integration of such methods in medical diagnosis.", "published": "2019-09-03T23:53:11Z", "version": 3}, {"aid": "1909.01500", "authors": ["Adam Stooke", "Pieter Abbeel"], "title": "rlpyt: A Research Code Base for Deep Reinforcement Learning in PyTorch", "url": "http://arxiv.org/pdf/1909.01500v2", "summary": "Since the recent advent of deep reinforcement learning for game play and simulated robotic control, a multitude of new algorithms have flourished. Most are model-free algorithms which can be categorized into three families: deep Q-learning, policy gradients, and Q-value policy gradients. These have developed along separate lines of research, such that few, if any, code bases incorporate all three kinds. Yet these algorithms share a great depth of common deep reinforcement learning machinery. We are pleased to share rlpyt, which implements all three algorithm families on top of a shared, optimized infrastructure, in a single repository. It contains modular implementations of many common deep RL algorithms in Python using PyTorch, a leading deep learning library. rlpyt is designed as a high-throughput code base for small- to medium-scale research in deep RL. This white paper summarizes its features, algorithms implemented, and relation to prior work, and concludes with detailed implementation and usage notes. rlpyt is available at https://github.com/astooke/rlpyt.", "published": "2019-09-03T23:57:13Z", "version": 2}, {"aid": "1909.01542", "authors": ["Yang Li", "Jianhe Yuan", "Zhiqun Zhao", "Hao Sun", "Zhihai He"], "title": "Snowball: Iterative Model Evolution and Confident Sample Discovery for Semi-Supervised Learning on Very Small Labeled Datasets", "url": "http://arxiv.org/pdf/1909.01542v1", "summary": "In this work, we develop a joint sample discovery and iterative model evolution method for semi-supervised learning on very small labeled training sets. We propose a master-teacher-student model framework to provide multi-layer guidance during the model evolution process with multiple iterations and generations. The teacher model is constructed by performing an exponential moving average of the student models obtained from past training steps. The master network combines the knowledge of the student and teacher models with additional access to newly discovered samples. The master and teacher models are then used to guide the training of the student network by enforcing the consistence between their predictions of unlabeled samples and evolve all models when more and more samples are discovered. Our extensive experiments demonstrate that the discovering confident samples from the unlabeled dataset, once coupled with the above master-teacher-student network evolution, can significantly improve the overall semi-supervised learning performance. For example, on the CIFAR-10 dataset, with a very small set of 250 labeled samples, our method achieves an error rate of 11.81 %, more than 38 % lower than the state-of-the-art method Mean-Teacher (49.91 %).", "published": "2019-09-04T03:41:27Z", "version": 1}, {"aid": "1909.06012", "authors": ["Chao Huang", "Hu Han", "Qingsong Yao", "Shankuan Zhu", "S. Kevin Zhou"], "title": "3D U$^2$-Net: A 3D Universal U-Net for Multi-Domain Medical Image Segmentation", "url": "http://arxiv.org/pdf/1909.06012v1", "summary": "Fully convolutional neural networks like U-Net have been the state-of-the-art methods in medical image segmentation. Practically, a network is highly specialized and trained separately for each segmentation task. Instead of a collection of multiple models, it is highly desirable to learn a universal data representation for different tasks, ideally a single model with the addition of a minimal number of parameters steered to each task. Inspired by the recent success of multi-domain learning in image classification, for the first time we explore a promising universal architecture that handles multiple medical segmentation tasks and is extendable for new tasks, regardless of different organs and imaging modalities. Our 3D Universal U-Net (3D U$^2$-Net) is built upon separable convolution, assuming that {\\it images from different domains have domain-specific spatial correlations which can be probed with channel-wise convolution while also share cross-channel correlations which can be modeled with pointwise convolution}. We evaluate the 3D U$^2$-Net on five organ segmentation datasets. Experimental results show that this universal network is capable of competing with traditional models in terms of segmentation accuracy, while requiring only about $1\\%$ of the parameters. Additionally, we observe that the architecture can be easily and effectively adapted to a new domain without sacrificing performance in the domains used to learn the shared parameterization of the universal network. We put the code of 3D U$^2$-Net into public domain. \\url{https://github.com/huangmozhilv/u2net_torch/}", "published": "2019-09-04T15:03:08Z", "version": 1}, {"aid": "1909.01861", "authors": ["Hui Zhu", "Zhulin An", "Chuanguang Yang", "Xiaolong Hu", "Kaiqiang Xu", "Yongjun Xu"], "title": "Rethinking the Number of Channels for the Convolutional Neural Network", "url": "http://arxiv.org/pdf/1909.01861v1", "summary": "Latest algorithms for automatic neural architecture search perform remarkable but few of them can effectively design the number of channels for convolutional neural networks and consume less computational efforts. In this paper, we propose a method for efficient automatic architecture search which is special to the widths of networks instead of the connections of neural architecture. Our method, functionally incremental search based on function-preserving, will explore the number of channels rapidly while controlling the number of parameters of the target network. On CIFAR-10 and CIFAR-100 classification, our method using minimal computational resources (0.4~1.3 GPU-days) can discover more efficient rules of the widths of networks to improve the accuracy by about 0.5% on CIFAR-10 and a~2.33% on CIFAR-100 with fewer number of parameters. In particular, our method is suitable for exploring the number of channels of almost any convolutional neural network rapidly.", "published": "2019-09-04T15:09:22Z", "version": 1}, {"aid": "1909.01960", "authors": ["Kristofer Schlachter", "Connor DeFanti", "Sebastian Herscher", "Ken Perlin", "Jonathan Tompson"], "title": "Beyond Photo Realism for Domain Adaptation from Synthetic Data", "url": "http://arxiv.org/pdf/1909.01960v1", "summary": "As synthetic imagery is used more frequently in training deep models, it is important to understand how different synthesis techniques impact the performance of such models. In this work, we perform a thorough evaluation of the effectiveness of several different synthesis techniques and their impact on the complexity of classifier domain adaptation to the \"real\" underlying data distribution that they seek to replicate. In addition, we propose a novel learned synthesis technique to better train classifier models than state-of-the-art offline graphical methods, while using significantly less computational resources. We accomplish this by learning a generative model to perform shading of synthetic geometry conditioned on a \"g-buffer\" representation of the scene to render, as well as a low sample Monte Carlo rendered image. The major contributions are (i) a dataset that allows comparison of real and synthetic versions of the same scene, (ii) an augmented data representation that boosts the stability of learning and improves the datasets accuracy, (iii) three different partially differentiable rendering techniques where lighting, denoising and shading are learned, and (iv) we improve a state of the art generative adversarial network (GAN) approach by using an ensemble of trained models to generate datasets that approach the performance of training on real data and surpass the performance of the full global illumination rendering.", "published": "2019-09-04T17:38:05Z", "version": 1}, {"aid": "1909.01963", "authors": ["Aman Shrivastava", "Will Adorno", "Yash Sharma", "Lubaina Ehsan", "S. Asad Ali", "Sean R. Moore", "Beatrice C. Amadi", "Paul Kelly", "Sana Syed", "Donald E. Brown"], "title": "Self-Attentive Adversarial Stain Normalization", "url": "http://arxiv.org/pdf/1909.01963v3", "summary": "Hematoxylin and Eosin (H&E) stained Whole Slide Images (WSIs) are utilized for biopsy visualization-based diagnostic and prognostic assessment of diseases. Variation in the H&E staining process across different lab sites can lead to significant variations in biopsy image appearance. These variations introduce an undesirable bias when the slides are examined by pathologists or used for training deep learning models. To reduce this bias, slides need to be translated to a common domain of stain appearance before analysis. We propose a Self-Attentive Adversarial Stain Normalization (SAASN) approach for the normalization of multiple stain appearances to a common domain. This unsupervised generative adversarial approach includes self-attention mechanism for synthesizing images with finer detail while preserving the structural consistency of the biopsy features during translation. SAASN demonstrates consistent and superior performance compared to other popular stain normalization techniques on H&E stained duodenal biopsy image data.", "published": "2019-09-04T17:41:19Z", "version": 3}, {"aid": "1909.02040", "authors": ["Zihui Wu", "Yu Sun", "Jiaming Liu", "Ulugbek S. Kamilov"], "title": "Online Regularization by Denoising with Applications to Phase Retrieval", "url": "http://arxiv.org/pdf/1909.02040v1", "summary": "Regularization by denoising (RED) is a powerful framework for solving imaging inverse problems. Most RED algorithms are iterative batch procedures, which limits their applicability to very large datasets. In this paper, we address this limitation by introducing a novel online RED (On-RED) algorithm, which processes a small subset of the data at a time. We establish the theoretical convergence of On-RED in convex settings and empirically discuss its effectiveness in non-convex ones by illustrating its applicability to phase retrieval. Our results suggest that On-RED is an effective alternative to the traditional RED algorithms when dealing with large datasets.", "published": "2019-09-04T18:29:10Z", "version": 1}, {"aid": "1909.02214", "authors": ["Yifan Liu", "Bohan Zhuang", "Chunhua Shen", "Hao Chen", "Wei Yin"], "title": "Auxiliary Learning for Deep Multi-task Learning", "url": "http://arxiv.org/pdf/1909.02214v2", "summary": "Multi-task learning (MTL) is an efficient solution to solve multiple tasks simultaneously in order to get better speed and performance than handling each single-task in turn. The most current methods can be categorized as either: (i) hard parameter sharing where a subset of the parameters is shared among tasks while other parameters are task-specific; or (ii) soft parameter sharing where all parameters are task-specific but they are jointly regularized. Both methods suffer from limitations: the shared hidden layers of the former are difficult to optimize due to the competing objectives while the complexity of the latter grows linearly with the increasing number of tasks. To mitigate those drawbacks, this paper proposes an alternative, where we explicitly construct an auxiliary module to mimic the soft parameter sharing for assisting the optimization of the hard parameter sharing layers in the training phase. In particular, the auxiliary module takes the outputs of the shared hidden layers as inputs and is supervised by the auxiliary task loss. During training, the auxiliary module is jointly optimized with the MTL network, serving as a regularization by introducing an inductive bias to the shared layers. In the testing phase, only the original MTL network is kept. Thus our method avoids the limitation of both categories. We evaluate the proposed auxiliary module on pixel-wise prediction tasks, including semantic segmentation, depth estimation, and surface normal prediction with different network structures. The extensive experiments over various settings verify the effectiveness of our methods.", "published": "2019-09-05T05:29:15Z", "version": 2}, {"aid": "1909.02603", "authors": ["Kameron Decker Harris"], "title": "Additive function approximation in the brain", "url": "http://arxiv.org/pdf/1909.02603v2", "summary": "Many biological learning systems such as the mushroom body, hippocampus, and cerebellum are built from sparsely connected networks of neurons. For a new understanding of such networks, we study the function spaces induced by sparse random features and characterize what functions may and may not be learned. A network with $d$ inputs per neuron is found to be equivalent to an additive model of order $d$, whereas with a degree distribution the network combines additive terms of different orders. We identify three specific advantages of sparsity: additive function approximation is a powerful inductive bias that limits the curse of dimensionality, sparse networks are stable to outlier noise in the inputs, and sparse random features are scalable. Thus, even simple brain architectures can be powerful function approximators. Finally, we hope that this work helps popularize kernel theories of networks among computational neuroscientists.", "published": "2019-09-05T19:07:33Z", "version": 2}, {"aid": "1909.02620", "authors": ["Ozan Ciga", "Jianan Chen", "Anne Martel"], "title": "Multi-layer Domain Adaptation for Deep Convolutional Networks", "url": "http://arxiv.org/pdf/1909.02620v1", "summary": "Despite their success in many computer vision tasks, convolutional networks tend to require large amounts of labeled data to achieve generalization. Furthermore, the performance is not guaranteed on a sample from an unseen domain at test time, if the network was not exposed to similar samples from that domain at training time. This hinders the adoption of these techniques in clinical setting where the imaging data is scarce, and where the intra- and inter-domain variance of the data can be substantial. We propose a domain adaptation technique that is especially suitable for deep networks to alleviate this requirement of labeled data. Our method utilizes gradient reversal layers and Squeezeand-Excite modules to stabilize the training in deep networks. The proposed method was applied to publicly available histopathology and chest X-ray databases and achieved superior performance to existing state-of-the-art networks with and without domain adaptation. Depending on the application, our method can improve multi-class classification accuracy by 5-20% compared to DANN introduced in (Ganin, 2014).", "published": "2019-09-05T20:24:49Z", "version": 1}, {"aid": "1909.02765", "authors": ["Zhuoran Ji"], "title": "ILP-M Conv: Optimize Convolution Algorithm for Single-Image Convolution Neural Network Inference on Mobile GPUs", "url": "http://arxiv.org/pdf/1909.02765v2", "summary": "Convolution neural networks are widely used for mobile applications. However, GPU convolution algorithms are designed for mini-batch neural network training, the single-image convolution neural network inference algorithm on mobile GPUs is not well-studied. After discussing the usage difference and examining the existing convolution algorithms, we proposed the HNTMP convolution algorithm. The HNTMP convolution algorithm achieves $14.6 \\times$ speedup than the most popular \\textit{im2col} convolution algorithm, and $2.30 \\times$ speedup than the fastest existing convolution algorithm (direct convolution) as far as we know.", "published": "2019-09-06T08:36:05Z", "version": 2}, {"aid": "1909.03834", "authors": ["Dongsheng Ruan", "Jun Wen", "Nenggan Zheng", "Min Zheng"], "title": "Linear Context Transform Block", "url": "http://arxiv.org/pdf/1909.03834v2", "summary": "Squeeze-and-Excitation (SE) block presents a channel attention mechanism for modeling global context via explicitly capturing dependencies across channels. However, we are still far from understanding how the SE block works. In this work, we first revisit the SE block, and then present a detailed empirical study of the relationship between global context and attention distribution, based on which we propose a simple yet effective module, called Linear Context Transform (LCT) block. We divide all channels into different groups and normalize the globally aggregated context features within each channel group, reducing the disturbance from irrelevant channels. Through linear transform of the normalized context features, we model global context for each channel independently. The LCT block is extremely lightweight and easy to be plugged into different backbone models while with negligible parameters and computational burden increase. Extensive experiments show that the LCT block outperforms the SE block in image classification task on the ImageNet and object detection/segmentation on the COCO dataset with different backbone models. Moreover, LCT yields consistent performance gains over existing state-of-the-art detection architectures, e.g., 1.5$\\sim$1.7% AP$^{bbox}$ and 1.0$\\sim$1.2% AP$^{mask}$ improvements on the COCO benchmark, irrespective of different baseline models of varied capacities. We hope our simple yet effective approach will shed some light on future research of attention-based models.", "published": "2019-09-06T12:31:28Z", "version": 2}, {"aid": "1909.04586", "authors": ["Prashant C. Raju"], "title": "A Theory on Formatting Sensory Input for Cognition", "url": "http://arxiv.org/pdf/1909.04586v5", "summary": "Over the last few decades, a lot of progress has been made in understanding different aspects of the brain's ability to form abstract representations, but a specific mechanism for how they are created and used remains to emerge. Here, we review recent findings on the subject and we propose a mechanism for the dynamics of forming abstract representations, where the formation of local connectivity in neural networks determines the of search terms between the prefrontal cortex and the hippocampus, as well as the amount of detail that is transcribed into abstract representations.", "published": "2019-09-08T20:00:55Z", "version": 5}, {"aid": "1909.04110", "authors": ["Zengming Shen", "S. Kevin Zhou", "Yifan Chen", "Bogdan Georgescu", "Xuqi Liu", "Thomas S. Huang"], "title": "One-to-one Mapping for Unpaired Image-to-image Translation", "url": "http://arxiv.org/pdf/1909.04110v6", "summary": "Recently image-to-image translation has attracted significant interests in the literature, starting from the successful use of the generative adversarial network (GAN), to the introduction of cyclic constraint, to extensions to multiple domains. However, in existing approaches, there is no guarantee that the mapping between two image domains is unique or one-to-one. Here we propose a self-inverse network learning approach for unpaired image-to-image translation. Building on top of CycleGAN, we learn a self-inverse function by simply augmenting the training samples by swapping inputs and outputs during training and with separated cycle consistency loss for each mapping direction. The outcome of such learning is a proven one-to-one mapping function. Our extensive experiments on a variety of datasets, including cross-modal medical image synthesis, object transfiguration, and semantic labeling, consistently demonstrate clear improvement over the CycleGAN method both qualitatively and quantitatively. Especially our proposed method reaches the state-of-the-art result on the cityscapes benchmark dataset for the label to photo unpaired directional image translation.", "published": "2019-09-09T19:10:05Z", "version": 6}, {"aid": "1909.04170", "authors": ["Giacomo Spigler"], "title": "Meta-learnt priors slow down catastrophic forgetting in neural networks", "url": "http://arxiv.org/pdf/1909.04170v2", "summary": "Current training regimes for deep learning usually involve exposure to a single task / dataset at a time. Here we start from the observation that in this context the trained model is not given any knowledge of anything outside its (single-task) training distribution, and has thus no way to learn parameters (i.e., feature detectors or policies) that could be helpful to solve other tasks, and to limit future interference with the acquired knowledge, and thus catastrophic forgetting. Here we show that catastrophic forgetting can be mitigated in a meta-learning context, by exposing a neural network to multiple tasks in a sequential manner during training. Finally, we present SeqFOMAML, a meta-learning algorithm that implements these principles, and we evaluate it on sequential learning problems composed by Omniglot and MiniImageNet classification tasks.", "published": "2019-09-09T21:46:19Z", "version": 2}, {"aid": "1909.04358", "authors": ["Friedrich Schuessler", "Alexis Dubreuil", "Francesca Mastrogiuseppe", "Srdjan Ostojic", "Omri Barak"], "title": "Dynamics of random recurrent networks with correlated low-rank structure", "url": "http://arxiv.org/pdf/1909.04358v3", "summary": "A given neural network in the brain is involved in many different tasks. This implies that, when considering a specific task, the network's connectivity contains a component which is related to the task and another component which can be considered random. Understanding the interplay between the structured and random components, and their effect on network dynamics and functionality is an important open question. Recent studies addressed the co-existence of random and structured connectivity, but considered the two parts to be uncorrelated. This constraint limits the dynamics and leaves the random connectivity non-functional. Algorithms that train networks to perform specific tasks typically generate correlations between structure and random connectivity. Here we study nonlinear networks with correlated structured and random components, assuming the structure to have a low rank. We develop an analytic framework to establish the precise effect of the correlations on the eigenvalue spectrum of the joint connectivity. We find that the spectrum consists of a bulk and multiple outliers, whose location is predicted by our theory. Using mean-field theory, we show that these outliers directly determine both the fixed points of the system and their stability. Taken together, our analysis elucidates how correlations allow structured and random connectivity to synergistically extend the range of computations available to networks.", "published": "2019-09-10T09:01:33Z", "version": 3}, {"aid": "1909.04630", "authors": ["Aravind Rajeswaran", "Chelsea Finn", "Sham Kakade", "Sergey Levine"], "title": "Meta-Learning with Implicit Gradients", "url": "http://arxiv.org/pdf/1909.04630v1", "summary": "A core capability of intelligent systems is the ability to quickly learn new tasks by drawing on prior experience. Gradient (or optimization) based meta-learning has recently emerged as an effective approach for few-shot learning. In this formulation, meta-parameters are learned in the outer loop, while task-specific models are learned in the inner-loop, by using only a small amount of data from the current task. A key challenge in scaling these approaches is the need to differentiate through the inner loop learning process, which can impose considerable computational and memory burdens. By drawing upon implicit differentiation, we develop the implicit MAML algorithm, which depends only on the solution to the inner level optimization and not the path taken by the inner loop optimizer. This effectively decouples the meta-gradient computation from the choice of inner loop optimizer. As a result, our approach is agnostic to the choice of inner loop optimizer and can gracefully handle many gradient steps without vanishing gradients or memory constraints. Theoretically, we prove that implicit MAML can compute accurate meta-gradients with a memory footprint that is, up to small constant factors, no more than that which is required to compute a single inner loop gradient and at no overall increase in the total computational cost. Experimentally, we show that these benefits of implicit MAML translate into empirical gains on few-shot image recognition benchmarks.", "published": "2019-09-10T17:14:14Z", "version": 1}, {"aid": "1909.04866", "authors": ["Stephen Gould", "Richard Hartley", "Dylan Campbell"], "title": "Deep Declarative Networks: A New Hope", "url": "http://arxiv.org/pdf/1909.04866v2", "summary": "We explore a new class of end-to-end learnable models wherein data processing nodes (or network layers) are defined in terms of desired behavior rather than an explicit forward function. Specifically, the forward function is implicitly defined as the solution to a mathematical optimization problem. Consistent with nomenclature in the programming languages community, we name these models deep declarative networks. Importantly, we show that the class of deep declarative networks subsumes current deep learning models. Moreover, invoking the implicit function theorem, we show how gradients can be back-propagated through many declaratively defined data processing nodes thereby enabling end-to-end learning. We show how these declarative processing nodes can be implemented in the popular PyTorch deep learning software library allowing declarative and imperative nodes to co-exist within the same network. We also provide numerous insights and illustrative examples of declarative nodes and demonstrate their application for image and point cloud classification tasks.", "published": "2019-09-11T06:19:25Z", "version": 2}, {"aid": "1909.05784", "authors": ["Dashan Gao", "Ce Ju", "Xiguang Wei", "Yang Liu", "Tianjian Chen", "Qiang Yang"], "title": "HHHFL: Hierarchical Heterogeneous Horizontal Federated Learning for Electroencephalography", "url": "http://arxiv.org/pdf/1909.05784v3", "summary": "Electroencephalography (EEG) classification techniques have been widely studied for human behavior and emotion recognition tasks. But it is still a challenging issue since the data may vary from subject to subject, may change over time for the same subject, and maybe heterogeneous. Recent years, increasing privacy-preserving demands poses new challenges to this task. The data heterogeneity, as well as the privacy constraint of the EEG data, is not concerned in previous studies. To fill this gap, in this paper, we propose a heterogeneous federated learning approach to train machine learning models over heterogeneous EEG data, while preserving the data privacy of each party. To verify the effectiveness of our approach, we conduct experiments on a real-world EEG dataset, consisting of heterogeneous data collected from diverse devices. Our approach achieves consistent performance improvement on every task.", "published": "2019-09-11T06:29:23Z", "version": 3}, {"aid": "1909.05085", "authors": ["Dennis Bontempi", "Sergio Benini", "Alberto Signoroni", "Michele Svanera", "Lars Muckli"], "title": "CEREBRUM: a fast and fully-volumetric Convolutional Encoder-decodeR for weakly-supervised sEgmentation of BRain strUctures from out-of-the-scanner MRI", "url": "http://arxiv.org/pdf/1909.05085v2", "summary": "Many functional and structural neuroimaging studies call for accurate morphometric segmentation of different brain structures starting from image intensity values of MRI scans. Current automatic (multi-) atlas-based segmentation strategies often lack accuracy on difficult-to-segment brain structures and, since these methods rely on atlas-to-scan alignment, they may take long processing times. Recently, methods deploying solutions based on Convolutional Neural Networks (CNNs) are making the direct analysis of out-of-the-scanner data feasible. However, current CNN-based solutions partition the test volume into 2D or 3D patches, which are processed independently. This entails a loss of global contextual information thereby negatively impacting the segmentation accuracy. In this work, we design and test an optimised end-to-end CNN architecture that makes the exploitation of global spatial information computationally tractable, allowing to process a whole MRI volume at once. We adopt a weakly supervised learning strategy by exploiting a large dataset composed by 947 out-of-the-scanner (3 Tesla T1-weighted 1mm isotropic MP-RAGE 3D sequences) MR Images. The resulting model is able to produce accurate multi-structure segmentation results in only few seconds. Different quantitative measures demonstrate an improved accuracy of our solution when compared to state-of-the-art techniques. Moreover, through a randomised survey involving expert neuroscientists, we show that subjective judgements clearly prefer our solution with respect to the widely adopted atlas-based FreeSurfer software.", "published": "2019-09-11T14:40:30Z", "version": 2}, {"aid": "1909.05235", "authors": ["Qi Qian", "Lei Shang", "Baigui Sun", "Juhua Hu", "Hao Li", "Rong Jin"], "title": "SoftTriple Loss: Deep Metric Learning Without Triplet Sampling", "url": "http://arxiv.org/pdf/1909.05235v2", "summary": "Distance metric learning (DML) is to learn the embeddings where examples from the same class are closer than examples from different classes. It can be cast as an optimization problem with triplet constraints. Due to the vast number of triplet constraints, a sampling strategy is essential for DML. With the tremendous success of deep learning in classifications, it has been applied for DML. When learning embeddings with deep neural networks (DNNs), only a mini-batch of data is available at each iteration. The set of triplet constraints has to be sampled within the mini-batch. Since a mini-batch cannot capture the neighbors in the original set well, it makes the learned embeddings sub-optimal. On the contrary, optimizing SoftMax loss, which is a classification loss, with DNN shows a superior performance in certain DML tasks. It inspires us to investigate the formulation of SoftMax. Our analysis shows that SoftMax loss is equivalent to a smoothed triplet loss where each class has a single center. In real-world data, one class can contain several local clusters rather than a single one, e.g., birds of different poses. Therefore, we propose the SoftTriple loss to extend the SoftMax loss with multiple centers for each class. Compared with conventional deep metric learning algorithms, optimizing SoftTriple loss can learn the embeddings without the sampling phase by mildly increasing the size of the last fully connected layer. Experiments on the benchmark fine-grained data sets demonstrate the effectiveness of the proposed loss function. Code is available at https://github.com/idstcv/SoftTriple", "published": "2019-09-11T17:47:25Z", "version": 2}, {"aid": "1909.11015", "authors": ["Shiv Ram Dubey", "Soumendu Chakraborty", "Swalpa Kumar Roy", "Snehasis Mukherjee", "Satish Kumar Singh", "Bidyut Baran Chaudhuri"], "title": "diffGrad: An Optimization Method for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1909.11015v4", "summary": "Stochastic Gradient Decent (SGD) is one of the core techniques behind the success of deep neural networks. The gradient provides information on the direction in which a function has the steepest rate of change. The main problem with basic SGD is to change by equal sized steps for all parameters, irrespective of gradient behavior. Hence, an efficient way of deep network optimization is to make adaptive step sizes for each parameter. Recently, several attempts have been made to improve gradient descent methods such as AdaGrad, AdaDelta, RMSProp and Adam. These methods rely on the square roots of exponential moving averages of squared past gradients. Thus, these methods do not take advantage of local change in gradients. In this paper, a novel optimizer is proposed based on the difference between the present and the immediate past gradient (i.e., diffGrad). In the proposed diffGrad optimization technique, the step size is adjusted for each parameter in such a way that it should have a larger step size for faster gradient changing parameters and a lower step size for lower gradient changing parameters. The convergence analysis is done using the regret bound approach of online learning framework. Rigorous analysis is made in this paper over three synthetic complex non-convex functions. The image categorization experiments are also conducted over the CIFAR10 and CIFAR100 datasets to observe the performance of diffGrad with respect to the state-of-the-art optimizers such as SGDM, AdaGrad, AdaDelta, RMSProp, AMSGrad, and Adam. The residual unit (ResNet) based Convolutional Neural Networks (CNN) architecture is used in the experiments. The experiments show that diffGrad outperforms other optimizers. Also, we show that diffGrad performs uniformly well for training CNN using different activation functions. The source code is made publicly available at https://github.com/shivram1987/diffGrad.", "published": "2019-09-12T06:20:05Z", "version": 4}, {"aid": "1909.07156", "authors": ["Masanari Kimura", "Masayuki Tanaka"], "title": "New Perspective of Interpretability of Deep Neural Networks", "url": "http://arxiv.org/pdf/1909.07156v1", "summary": "Deep neural networks (DNNs) are known as black-box models. In other words, it is difficult to interpret the internal state of the model. Improving the interpretability of DNNs is one of the hot research topics. However, at present, the definition of interpretability for DNNs is vague, and the question of what is a highly explanatory model is still controversial. To address this issue, we provide the definition of the human predictability of the model, as a part of the interpretability of the DNNs. The human predictability proposed in this paper is defined by easiness to predict the change of the inference when perturbating the model of the DNNs. In addition, we introduce one example of high human-predictable DNNs. We discuss that our definition will help to the research of the interpretability of the DNNs considering various types of applications.", "published": "2019-09-12T07:24:20Z", "version": 1}, {"aid": "1909.06043", "authors": ["Bo Chen", "Alvaro Parra", "Jiewei Cao", "Nan Li", "Tat-Jun Chin"], "title": "End-to-End Learnable Geometric Vision by Backpropagating PnP Optimization", "url": "http://arxiv.org/pdf/1909.06043v3", "summary": "Deep networks excel in learning patterns from large amounts of data. On the other hand, many geometric vision tasks are specified as optimization problems. To seamlessly combine deep learning and geometric vision, it is vital to perform learning and geometric optimization end-to-end. Towards this aim, we present BPnP, a novel network module that backpropagates gradients through a Perspective-n-Points (PnP) solver to guide parameter updates of a neural network. Based on implicit differentiation, we show that the gradients of a \"self-contained\" PnP solver can be derived accurately and efficiently, as if the optimizer block were a differentiable function. We validate BPnP by incorporating it in a deep model that can learn camera intrinsics, camera extrinsics (poses) and 3D structure from training datasets. Further, we develop an end-to-end trainable pipeline for object pose estimation, which achieves greater accuracy by combining feature-based heatmap losses with 2D-3D reprojection errors. Since our approach can be extended to other optimization problems, our work helps to pave the way to perform learnable geometric vision in a principled manner. Our PyTorch implementation of BPnP is available on http://github.com/BoChenYS/BPnP.", "published": "2019-09-13T05:45:25Z", "version": 3}, {"aid": "1909.06161", "authors": ["Jonas Kubilius", "Martin Schrimpf", "Kohitij Kar", "Ha Hong", "Najib J. Majaj", "Rishi Rajalingham", "Elias B. Issa", "Pouya Bashivan", "Jonathan Prescott-Roy", "Kailyn Schmidt", "Aran Nayebi", "Daniel Bear", "Daniel L. K. Yamins", "James J. DiCarlo"], "title": "Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs", "url": "http://arxiv.org/pdf/1909.06161v2", "summary": "Deep convolutional artificial neural networks (ANNs) are the leading class of candidate models of the mechanisms of visual processing in the primate ventral stream. While initially inspired by brain anatomy, over the past years, these ANNs have evolved from a simple eight-layer architecture in AlexNet to extremely deep and branching architectures, demonstrating increasingly better object categorization performance, yet bringing into question how brain-like they still are. In particular, typical deep models from the machine learning community are often hard to map onto the brain's anatomy due to their vast number of layers and missing biologically-important connections, such as recurrence. Here we demonstrate that better anatomical alignment to the brain and high performance on machine learning as well as neuroscience measures do not have to be in contradiction. We developed CORnet-S, a shallow ANN with four anatomically mapped areas and recurrent connectivity, guided by Brain-Score, a new large-scale composite of neural and behavioral benchmarks for quantifying the functional fidelity of models of the primate ventral visual stream. Despite being significantly shallower than most models, CORnet-S is the top model on Brain-Score and outperforms similarly compact models on ImageNet. Moreover, our extensive analyses of CORnet-S circuitry variants reveal that recurrence is the main predictive factor of both Brain-Score and ImageNet top-1 performance. Finally, we report that the temporal evolution of the CORnet-S \"IT\" neural population resembles the actual monkey IT population dynamics. Taken together, these results establish CORnet-S, a compact, recurrent ANN, as the current best model of the primate ventral visual stream.", "published": "2019-09-13T12:09:34Z", "version": 2}, {"aid": "1909.06236", "authors": ["Sohrab Ferdowsi", "Maurits Diephuis", "Shideh Rezaeifar", "Slava Voloshynovskiy"], "title": "$\u03c1$-VAE: Autoregressive parametrization of the VAE encoder", "url": "http://arxiv.org/pdf/1909.06236v1", "summary": "We make a minimal, but very effective alteration to the VAE model. This is about a drop-in replacement for the (sample-dependent) approximate posterior to change it from the standard white Gaussian with diagonal covariance to the first-order autoregressive Gaussian. We argue that this is a more reasonable choice to adopt for natural signals like images, as it does not force the existing correlation in the data to disappear in the posterior. Moreover, it allows more freedom for the approximate posterior to match the true posterior. This allows for the repararametrization trick, as well as the KL-divergence term to still have closed-form expressions, obviating the need for its sample-based estimation. Although providing more freedom to adapt to correlated distributions, our parametrization has even less number of parameters than the diagonal covariance, as it requires only two scalars, $\\rho$ and $s$, to characterize correlation and scaling, respectively. As validated by the experiments, our proposition noticeably and consistently improves the quality of image generation in a plug-and-play manner, needing no further parameter tuning, and across all setups. The code to reproduce our experiments is available at \\url{https://github.com/sssohrab/rho_VAE/}.", "published": "2019-09-13T14:01:33Z", "version": 1}, {"aid": "1909.06860", "authors": ["Alex Tong Lin", "Yonatan Dukler", "Wuchen Li", "Guido Montufar"], "title": "Wasserstein Diffusion Tikhonov Regularization", "url": "http://arxiv.org/pdf/1909.06860v1", "summary": "We propose regularization strategies for learning discriminative models that are robust to in-class variations of the input data. We use the Wasserstein-2 geometry to capture semantically meaningful neighborhoods in the space of images, and define a corresponding input-dependent additive noise data augmentation model. Expanding and integrating the augmented loss yields an effective Tikhonov-type Wasserstein diffusion smoothness regularizer. This approach allows us to apply high levels of regularization and train functions that have low variability within classes but remain flexible across classes. We provide efficient methods for computing the regularizer at a negligible cost in comparison to training with adversarial data augmentation. Initial experiments demonstrate improvements in generalization performance under adversarial perturbations and also large in-class variations of the input data.", "published": "2019-09-15T19:10:16Z", "version": 1}, {"aid": "1909.06970", "authors": ["Alicia Montserrat Alvarado-Gonzalez", "Gibran Fuentes-Pineda", "Jorge Cervantes-Ojeda"], "title": "A few filters are enough: Convolutional Neural Network for P300 Detection", "url": "http://arxiv.org/pdf/1909.06970v3", "summary": "Over the past decade, convolutional neural networks (CNNs) have become the driving force of an ever-increasing set of applications, achieving state-of-the-art performance. Most of the modern CNN architectures are composed of many convolutional and fully connected layers and typically require thousands or millions of parameters to learn. CNNs have also been effective in the detection of Event-Related Potentials from electroencephalogram (EEG) signals, notably the P300 component which is frequently employed in Brain-Computer Interfaces (BCIs). However, for this task, the increase in detection rates compared to approaches based on human-engineered features has not been as impressive as in other areas and might not justify such a large number of parameters. In this paper, we study the performances of existing CNN architectures with diverse complexities for single-trial within-subject and cross-subject P300 detection on four different datasets. We also proposed SepConv1D, a very simple CNN architecture consisting of a single depthwise separable 1D convolutional layer followed by a fully connected Sigmoid classification neuron. We found that with as few as four filters in its convolutional layer and a small overall number of parameters, SepConv1D obtained competitive performances in the four datasets. We believe this may represent an important step towards building simpler, cheaper, faster, and more portable BCIs.", "published": "2019-09-16T03:48:28Z", "version": 3}, {"aid": "1909.07375", "authors": ["Keehang Kwon"], "title": "Extending and Automating Basic Probability Theory with Propositional Computability Logic", "url": "http://arxiv.org/pdf/1909.07375v3", "summary": "Classical probability theory is formulated using sets. In this paper, we extend classical probability theory with propositional computability logic. Unlike other formalisms, computability logic is built on the notion of events/games, which is central to probability theory.   The probability theory based on CoL is therefore useful for {\\it automating} uncertainty reasoning. We describe some basic properties of this new probability theory. We also discuss a novel isomorphism between the set operations and computability logic operations.", "published": "2019-09-16T04:51:19Z", "version": 3}, {"aid": "1909.07636", "authors": ["Gil Shomron", "Ron Banner", "Moran Shkolnik", "Uri Weiser"], "title": "Thanks for Nothing: Predicting Zero-Valued Activations with Lightweight Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1909.07636v3", "summary": "Convolutional neural networks (CNNs) introduce state-of-the-art results for various tasks with the price of high computational demands. Inspired by the observation that spatial correlation exists in CNN output feature maps (ofms), we propose a method to dynamically predict whether ofm activations are zero-valued or not according to their neighboring activation values, thereby avoiding zero-valued activations and reducing the number of convolution operations. We implement the zero activation predictor (ZAP) with a lightweight CNN, which imposes negligible overheads and is easy to deploy on existing models. ZAPs are trained by mimicking hidden layer ouputs; thereby, enabling a parallel and label-free training. Furthermore, without retraining, each ZAP can be tuned to a different operating point trading accuracy for MAC reduction.", "published": "2019-09-17T07:56:54Z", "version": 3}, {"aid": "1909.07932", "authors": ["Yujiang Wang", "Nishant Sinha", "Gabrielle M. Schroeder", "Sriharsha Ramaraju", "Andrew W. McEvoy", "Anna Miserocchi", "Jane de Tisi", "Fahmida A. Chowdhury", "Beate Diehl", "John S. Duncan", "Peter N. Taylor"], "title": "Interictal intracranial EEG for predicting surgical success: the importance of space and time", "url": "http://arxiv.org/pdf/1909.07932v1", "summary": "Predicting post-operative seizure freedom using functional correlation networks derived from interictal intracranial EEG has shown some success. However, there are important challenges to consider. 1: electrodes physically closer to each other naturally tend to be more correlated causing a spatial bias. 2: implantation location and number of electrodes differ between patients, making cross-subject comparisons difficult. 3: functional correlation networks can vary over time but are currently assumed as static. In this study we address these three substantial challenges using intracranial EEG data from 55 patients with intractable focal epilepsy. Patients additionally underwent preoperative MR imaging, intra-operative CT, and post-operative MRI allowing accurate localisation of electrodes and delineation of removed tissue. We show that normalising for spatial proximity between nearby electrodes improves prediction of post-surgery seizure outcomes. Moreover, patients with more extensive electrode coverage were more likely to have their outcome predicted correctly (ROC-AUC >0.9, p<<0.05), but not necessarily more likely to have a better outcome. Finally, our predictions are robust regardless of the time segment. Future studies should account for the spatial proximity of electrodes in functional network construction to improve prediction of post-surgical seizure outcomes. Greater coverage of both removed and spared tissue allows for predictions with higher accuracy.", "published": "2019-09-17T17:00:18Z", "version": 1}, {"aid": "1909.08097", "authors": ["Umar Asif", "Jianbin Tang", "Stefan Harrer"], "title": "Ensemble Knowledge Distillation for Learning Improved and Efficient Networks", "url": "http://arxiv.org/pdf/1909.08097v3", "summary": "Ensemble models comprising of deep Convolutional Neural Networks (CNN) have shown significant improvements in model generalization but at the cost of large computation and memory requirements. In this paper, we present a framework for learning compact CNN models with improved classification performance and model generalization. For this, we propose a CNN architecture of a compact student model with parallel branches which are trained using ground truth labels and information from high capacity teacher networks in an ensemble learning fashion. Our framework provides two main benefits: i) Distilling knowledge from different teachers into the student network promotes heterogeneity in feature learning at different branches of the student network and enables the network to learn diverse solutions to the target problem. ii) Coupling the branches of the student network through ensembling encourages collaboration and improves the quality of the final predictions by reducing variance in the network outputs. Experiments on the well established CIFAR-10 and CIFAR-100 datasets show that our Ensemble Knowledge Distillation (EKD) improves classification accuracy and model generalization especially in situations with limited training data. Experiments also show that our EKD based compact networks outperform in terms of mean accuracy on the test datasets compared to state-of-the-art knowledge distillation based methods.", "published": "2019-09-17T21:03:19Z", "version": 3}, {"aid": "1909.08250", "authors": ["Van Duc Nguyen", "Tran Cao Son", "Enrico Pontelli"], "title": "Natural Language Generation for Non-Expert Users", "url": "http://arxiv.org/pdf/1909.08250v1", "summary": "Motivated by the difficulty in presenting computational results, especially when the results are a collection of atoms in a logical language, to users, who are not proficient in computer programming and/or the logical representation of the results, we propose a system for automatic generation of natural language descriptions for applications targeting mainstream users. Differently from many earlier systems with the same aim, the proposed system does not employ templates for the generation task. It assumes that there exist some natural language sentences in the application domain and uses this repository for the natural language description. It does not require, however, a large corpus as it is often required in machine learning approaches. The systems consist of two main components. The first one aims at analyzing the sentences and constructs a Grammatical Framework (GF) for given sentences and is implemented using the Stanford parser and an answer set program. The second component is for sentence construction and relies on GF Library. The paper includes two use cases to demostrate the capability of the system. As the sentence construction is done via GF, the paper includes a use case evaluation showing that the proposed system could also be utilized in addressing a challenge to create an abstract Wikipedia, which is recently discussed in the BlueSky session of the 2018 International Semantic Web Conference.", "published": "2019-09-18T07:09:07Z", "version": 1}, {"aid": "1909.08341", "authors": ["Shao-Qun Zhang", "Zhao-Yu Zhang", "Zhi-Hua Zhou"], "title": "Bifurcation Spiking Neural Network", "url": "http://arxiv.org/pdf/1909.08341v3", "summary": "Spiking neural networks (SNNs) has attracted much attention due to its great potential of modeling time-dependent signals. The firing rate of spiking neurons is decided by control rate which is fixed manually in advance, and thus, whether the firing rate is adequate for modeling actual time series relies on fortune. Though it is demanded to have an adaptive control rate, it is a non-trivial task because the control rate and the connection weights learned during the training process are usually entangled. In this paper, we show that the firing rate is related to the eigenvalue of the spike generation function. Inspired by this insight, by enabling the spike generation function to have adaptable eigenvalues rather than parametric control rates, we develop the Bifurcation Spiking Neural Network (BSNN), which has an adaptive firing rate and is insensitive to the setting of control rates. Experiments validate the effectiveness of BSNN on a broad range of tasks, showing that BSNN achieves superior performance to existing SNNs and is robust to the setting of control rates.", "published": "2019-09-18T10:34:59Z", "version": 3}, {"aid": "1909.09278", "authors": ["Harshala Gammulle", "Simon Denman", "Sridha Sridharan", "Clinton Fookes"], "title": "Forecasting Future Action Sequences with Neural Memory Networks", "url": "http://arxiv.org/pdf/1909.09278v1", "summary": "We propose a novel neural memory network based framework for future action sequence forecasting. This is a challenging task where we have to consider short-term, within sequence relationships as well as relationships in between sequences, to understand how sequences of actions evolve over time. To capture these relationships effectively, we introduce neural memory networks to our modelling scheme. We show the significance of using two input streams, the observed frames and the corresponding action labels, which provide different information cues for our prediction task. Furthermore, through the proposed method we effectively map the long-term relationships among individual input sequences through separate memory modules, which enables better fusion of the salient features. Our method outperforms the state-of-the-art approaches by a large margin on two publicly available datasets: Breakfast and 50 Salads.", "published": "2019-09-20T01:04:38Z", "version": 1}, {"aid": "1909.09349", "authors": ["Juan Luis Gonzalez Bello", "Munchurl Kim"], "title": "Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom", "url": "http://arxiv.org/pdf/1909.09349v2", "summary": "The 3D-zoom operation is the positive translation of the camera in the Z-axis, perpendicular to the image plane. In contrast, the optical zoom changes the focal length and the digital zoom is used to enlarge a certain region of an image to the original image size. In this paper, we are the first to formulate an unsupervised 3D-zoom learning problem where images with an arbitrary zoom factor can be generated from a given single image. An unsupervised framework is convenient, as it is a challenging task to obtain a 3D-zoom dataset of natural scenes due to the need for special equipment to ensure camera movement is restricted to the Z-axis. In addition, the objects in the scenes should not move when being captured, which hinders the construction of a large dataset of outdoor scenes. We present a novel unsupervised framework to learn how to generate arbitrarily 3D-zoomed versions of a single image, not requiring a 3D-zoom ground truth, called the Deep 3D-Zoom Net. The Deep 3D-Zoom Net incorporates the following features: (i) transfer learning from a pre-trained disparity estimation network via a back re-projection reconstruction loss; (ii) a fully convolutional network architecture that models depth-image-based rendering (DIBR), taking into account high-frequency details without the need for estimating the intermediate disparity; and (iii) incorporating a discriminator network that acts as a no-reference penalty for unnaturally rendered areas. Even though there is no baseline to fairly compare our results, our method outperforms previous novel view synthesis research in terms of realistic appearance on large camera baselines. We performed extensive experiments to verify the effectiveness of our method on the KITTI and Cityscapes datasets.", "published": "2019-09-20T07:18:39Z", "version": 2}, {"aid": "1909.09629", "authors": ["Andreas Lugmayr", "Martin Danelljan", "Radu Timofte"], "title": "Unsupervised Learning for Real-World Super-Resolution", "url": "http://arxiv.org/pdf/1909.09629v1", "summary": "Most current super-resolution methods rely on low and high resolution image pairs to train a network in a fully supervised manner. However, such image pairs are not available in real-world applications. Instead of directly addressing this problem, most works employ the popular bicubic downsampling strategy to artificially generate a corresponding low resolution image. Unfortunately, this strategy introduces significant artifacts, removing natural sensor noise and other real-world characteristics. Super-resolution networks trained on such bicubic images therefore struggle to generalize to natural images. In this work, we propose an unsupervised approach for image super-resolution. Given only unpaired data, we learn to invert the effects of bicubic downsampling in order to restore the natural image characteristics present in the data. This allows us to generate realistic image pairs, faithfully reflecting the distribution of real-world images. Our super-resolution network can therefore be trained with direct pixel-wise supervision in the high resolution domain, while robustly generalizing to real input. We demonstrate the effectiveness of our approach in quantitative and qualitative experiments.", "published": "2019-09-20T17:37:55Z", "version": 1}, {"aid": "1909.09706", "authors": ["Hassan Hafez-Kolahi", "Shohreh Kasaei", "Mahdiyeh Soleymani-Baghshah"], "title": "Do Compressed Representations Generalize Better?", "url": "http://arxiv.org/pdf/1909.09706v2", "summary": "One of the most studied problems in machine learning is finding reasonable constraints that guarantee the generalization of a learning algorithm. These constraints are usually expressed as some simplicity assumptions on the target. For instance, in the Vapnik-Chervonenkis (VC) theory the space of possible hypotheses is considered to have a limited VC dimension. In this paper, the constraint on the entropy $H(X)$ of the input variable $X$ is studied as a simplicity assumption. It is proven that the sample complexity to achieve an $\\epsilon$-$\\delta$ Probably Approximately Correct (PAC) hypothesis is bounded by $\\frac{2^{ \\left.6H(X)\\middle/\\epsilon\\right.}+\\log{\\frac{1}{\\delta}}}{\\epsilon^2}$ which is sharp up to the $\\frac{1}{\\epsilon^2}$ factor. Morever, it is shown that if a feature learning process is employed to learn the compressed representation from the dataset, this bound no longer exists. These findings have important implications on the Information Bottleneck (IB) theory which had been utilized to explain the generalization power of Deep Neural Networks (DNNs), but its applicability for this purpose is currently under debate by researchers. In particular, this is a rigorous proof for the previous heuristic that compressed representations are exponentially easier to be learned. However, our analysis pinpoints two factors preventing the IB, in its current form, to be applicable in studying neural networks. Firstly, the exponential dependence of sample complexity on $\\frac{1}{\\epsilon}$, which can lead to a dramatic effect on the bounds in practical applications when $\\epsilon$ is small. Secondly, our analysis reveals that arguments based on input compression are inherently insufficient to explain generalization of methods like DNNs in which the features are also learned using available data.", "published": "2019-09-20T19:54:42Z", "version": 2}, {"aid": "1909.09785", "authors": ["Hunter Lang", "Pengchuan Zhang", "Lin Xiao"], "title": "Using Statistics to Automate Stochastic Optimization", "url": "http://arxiv.org/pdf/1909.09785v1", "summary": "Despite the development of numerous adaptive optimizers, tuning the learning rate of stochastic gradient methods remains a major roadblock to obtaining good practical performance in machine learning. Rather than changing the learning rate at each iteration, we propose an approach that automates the most common hand-tuning heuristic: use a constant learning rate until \"progress stops,\" then drop. We design an explicit statistical test that determines when the dynamics of stochastic gradient descent reach a stationary distribution. This test can be performed easily during training, and when it fires, we decrease the learning rate by a constant multiplicative factor. Our experiments on several deep learning tasks demonstrate that this statistical adaptive stochastic approximation (SASA) method can automatically find good learning rate schedules and match the performance of hand-tuned methods using default settings of its parameters. The statistical testing helps to control the variance of this procedure and improves its robustness.", "published": "2019-09-21T07:27:48Z", "version": 1}, {"aid": "1909.09801", "authors": ["Saypraseuth Mounsaveng", "David Vazquez", "Ismail Ben Ayed", "Marco Pedersoli"], "title": "Adversarial Learning of General Transformations for Data Augmentation", "url": "http://arxiv.org/pdf/1909.09801v1", "summary": "Data augmentation (DA) is fundamental against overfitting in large convolutional neural networks, especially with a limited training dataset. In images, DA is usually based on heuristic transformations, like geometric or color transformations. Instead of using predefined transformations, our work learns data augmentation directly from the training data by learning to transform images with an encoder-decoder architecture combined with a spatial transformer network. The transformed images still belong to the same class but are new, more complex samples for the classifier. Our experiments show that our approach is better than previous generative data augmentation methods, and comparable to predefined transformation methods when training an image classifier.", "published": "2019-09-21T09:43:24Z", "version": 1}, {"aid": "1909.09934", "authors": ["Bohan Zhuang", "Chunhua Shen", "Mingkui Tan", "Peng Chen", "Lingqiao Liu", "Ian Reid"], "title": "Structured Binary Neural Networks for Image Recognition", "url": "http://arxiv.org/pdf/1909.09934v4", "summary": "We propose methods to train convolutional neural networks (CNNs) with both binarized weights and activations, leading to quantized models that are specifically friendly to mobile devices with limited power capacity and computation resources. Previous works on quantizing CNNs often seek to approximate the floating-point information using a set of discrete values, which we call value approximation, typically assuming the same architecture as the full-precision networks. Here we take a novel \"structure approximation\" view of quantization -- it is very likely that different architectures designed for low-bit networks may be better for achieving good performance. In particular, we propose a \"network decomposition\" strategy, termed Group-Net, in which we divide the network into groups. Thus, each full-precision group can be effectively reconstructed by aggregating a set of homogeneous binary branches. In addition, we learn effective connections among groups to improve the representation capability. Moreover, the proposed Group-Net shows strong generalization to other tasks. For instance, we extend Group-Net for accurate semantic segmentation by embedding rich context into the binary structure. Furthermore, for the first time, we apply binary neural networks to object detection. Experiments on both classification, semantic segmentation and object detection tasks demonstrate the superior performance of the proposed methods over various quantized networks in the literature. Our methods outperform the previous best binary neural networks in terms of accuracy and computation efficiency.", "published": "2019-09-22T03:45:49Z", "version": 4}, {"aid": "1909.10007", "authors": ["Tilo Schwalger", "Anton V. Chizhov"], "title": "Mind the Last Spike -- Firing Rate Models for Mesoscopic Populations of Spiking Neurons", "url": "http://arxiv.org/pdf/1909.10007v1", "summary": "The dominant modeling framework for understanding cortical computations are heuristic firing rate models. Despite their success, these models fall short to capture spike synchronization effects, to link to biophysical parameters and to describe finite-size fluctuations. In this opinion article, we propose that the refractory density method (RDM), also known as age-structured population dynamics or quasi-renewal theory, yields a powerful theoretical framework to build rate-based models for mesoscopic neural populations from realistic neuron dynamics at the microscopic level. We review recent advances achieved by the RDM to obtain efficient population density equations for networks of generalized integrate-and-fire (GIF) neurons -- a class of neuron models that has been successfully fitted to various cell types. The theory not only predicts the nonstationary dynamics of large populations of neurons but also permits an extension to finite-size populations and a systematic reduction to low-dimensional rate dynamics. The new types of rate models will allow a re-examination of models of cortical computations under biological constraints.", "published": "2019-09-22T13:57:44Z", "version": 1}, {"aid": "1909.10300", "authors": ["J\u00e9r\u00f4me Bolte", "Edouard Pauwels"], "title": "Conservative set valued fields, automatic differentiation, stochastic gradient method and deep learning", "url": "http://arxiv.org/pdf/1909.10300v4", "summary": "Modern problems in AI or in numerical analysis require nonsmooth approaches with a flexible calculus. We introduce generalized derivatives called conservative fields for which we develop a calculus and provide representation formulas. Functions having a conservative field are called path differentiable: convex, concave, Clarke regular and any semialgebraic Lipschitz continuous functions are path differentiable. Using Whitney stratification techniques for semialgebraic and definable sets, our model provides variational formulas for nonsmooth automatic differentiation oracles, as for instance the famous backpropagation algorithm in deep learning. Our differential model is applied to establish the convergence in values of nonsmooth stochastic gradient methods as they are implemented in practice.", "published": "2019-09-23T11:39:16Z", "version": 4}, {"aid": "1909.10340", "authors": ["Gideon Kowadlo", "Abdelrahman Ahmed", "David Rawlinson"], "title": "AHA! an 'Artificial Hippocampal Algorithm' for Episodic Machine Learning", "url": "http://arxiv.org/pdf/1909.10340v5", "summary": "The majority of ML research concerns slow, statistical learning of i.i.d. samples from large, labelled datasets. Animals do not learn this way. An enviable characteristic of animal learning is `episodic' learning - the ability to memorise a specific experience as a composition of existing concepts, after just one experience, without provided labels. The new knowledge can then be used to distinguish between similar experiences, to generalise between classes, and to selectively consolidate to long-term memory. The Hippocampus is known to be vital to these abilities. AHA is a biologically-plausible computational model of the Hippocampus. Unlike most machine learning models, AHA is trained without external labels and uses only local credit assignment. We demonstrate AHA in a superset of the Omniglot one-shot classification benchmark. The extended benchmark covers a wider range of known hippocampal functions by testing pattern separation, completion, and recall of original input. These functions are all performed within a single configuration of the computational model. Despite these constraints, image classification results are comparable to conventional deep convolutional ANNs.", "published": "2019-09-23T12:49:47Z", "version": 5}, {"aid": "1909.11483", "authors": ["Jordan Ott", "Erik Linstead", "Nicholas LaHaye", "Pierre Baldi"], "title": "Learning in the Machine: To Share or Not to Share?", "url": "http://arxiv.org/pdf/1909.11483v2", "summary": "Weight-sharing is one of the pillars behind Convolutional Neural Networks and their successes. However, in physical neural systems such as the brain, weight-sharing is implausible. This discrepancy raises the fundamental question of whether weight-sharing is necessary. If so, to which degree of precision? If not, what are the alternatives? The goal of this study is to investigate these questions, primarily through simulations where the weight-sharing assumption is relaxed. Taking inspiration from neural circuitry, we explore the use of Free Convolutional Networks and neurons with variable connection patterns. Using Free Convolutional Networks, we show that while weight-sharing is a pragmatic optimization approach, it is not a necessity in computer vision applications. Furthermore, Free Convolutional Networks match the performance observed in standard architectures when trained using properly translated data (akin to video). Under the assumption of translationally augmented data, Free Convolutional Networks learn translationally invariant representations that yield an approximate form of weight sharing.", "published": "2019-09-23T20:10:50Z", "version": 2}, {"aid": "1909.10702", "authors": ["Nitish Bahadur", "Randy Paffenroth"], "title": "Dimension Estimation Using Autoencoders", "url": "http://arxiv.org/pdf/1909.10702v1", "summary": "Dimension Estimation (DE) and Dimension Reduction (DR) are two closely related topics, but with quite different goals. In DE, one attempts to estimate the intrinsic dimensionality or number of latent variables in a set of measurements of a random vector. However, in DR, one attempts to project a random vector, either linearly or non-linearly, to a lower dimensional space that preserves the information contained in the original higher dimensional space. Of course, these two ideas are quite closely linked since, for example, doing DR to a dimension smaller than suggested by DE will likely lead to information loss. Accordingly, in this paper we will focus on a particular class of deep neural networks called autoencoders which are used extensively for DR but are less well studied for DE. We show that several important questions arise when using autoencoders for DE, above and beyond those that arise for more classic DR/DE techniques such as Principal Component Analysis. We address autoencoder architectural choices and regularization techniques that allow one to transform autoencoder latent layer representations into estimates of intrinsic dimension.", "published": "2019-09-24T04:09:48Z", "version": 1}, {"aid": "1909.10819", "authors": ["Risheng Liu", "Pan Mu", "Jin Zhang"], "title": "Investigating Customization Strategies and Convergence Behaviors of Task-specific ADMM", "url": "http://arxiv.org/pdf/1909.10819v2", "summary": "Alternating Direction Method of Multiplier (ADMM) has been a popular algorithmic framework for separable optimization problems with linear constraints. For numerical ADMM fail to exploit the particular structure of the problem at hand nor the input data information, leveraging task-specific modules (e.g., neural networks and other data-driven architectures) to extend ADMM is a significant but challenging task. This work focuses on designing a flexible algorithmic framework to incorporate various task-specific modules (with no additional constraints) to improve the performance of ADMM in real-world applications. Specifically, we propose Guidance from Optimality (GO), a new customization strategy, to embed task-specific modules into ADMM (GO-ADMM). By introducing an optimality-based criterion to guide the propagation, GO-ADMM establishes an updating scheme agnostic to the choice of additional modules. The existing task-specific methods just plug their task-specific modules into the numerical iterations in a straightforward manner. Even with some restrictive constraints on the plug-in modules, they can only obtain some relatively weaker convergence properties for the resulted ADMM iterations. Fortunately, without any restrictions on the embedded modules, we prove the convergence of GO-ADMM regarding objective values and constraint violations, and derive the worst-case convergence rate measured by iteration complexity. Extensive experiments are conducted to verify the theoretical results and demonstrate the efficiency of GO-ADMM.", "published": "2019-09-24T11:29:13Z", "version": 2}, {"aid": "1909.10893", "authors": ["Anirudh Goyal", "Alex Lamb", "Jordan Hoffmann", "Shagun Sodhani", "Sergey Levine", "Yoshua Bengio", "Bernhard Sch\u00f6lkopf"], "title": "Recurrent Independent Mechanisms", "url": "http://arxiv.org/pdf/1909.10893v6", "summary": "Learning modular structures which reflect the dynamics of the environment can lead to better generalization and robustness to changes which only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and are only updated at time steps where they are most relevant. We show that this leads to specialization amongst the RIMs, which in turn allows for dramatically improved generalization on tasks where some factors of variation differ systematically between training and evaluation.", "published": "2019-09-24T13:28:00Z", "version": 6}, {"aid": "1909.11145", "authors": ["Timo C. Wunderlich", "Akos F. Kungl", "Eric M\u00fcller", "Johannes Schemmel", "Mihai Petrovici"], "title": "Brain-Inspired Hardware for Artificial Intelligence: Accelerated Learning in a Physical-Model Spiking Neural Network", "url": "http://arxiv.org/pdf/1909.11145v2", "summary": "Future developments in artificial intelligence will profit from the existence of novel, non-traditional substrates for brain-inspired computing. Neuromorphic computers aim to provide such a substrate that reproduces the brain's capabilities in terms of adaptive, low-power information processing. We present results from a prototype chip of the BrainScaleS-2 mixed-signal neuromorphic system that adopts a physical-model approach with a 1000-fold acceleration of spiking neural network dynamics relative to biological real time. Using the embedded plasticity processor, we both simulate the Pong arcade video game and implement a local plasticity rule that enables reinforcement learning, allowing the on-chip neural network to learn to play the game. The experiment demonstrates key aspects of the employed approach, such as accelerated and flexible learning, high energy efficiency and resilience to noise.", "published": "2019-09-24T19:29:30Z", "version": 2}, {"aid": "1910.02020", "authors": ["Himanshu Goyal", "Pramit Saha", "Bryan Gick", "Sidney Fels"], "title": "EEG-to-F0: Establishing artificial neuro-muscular pathway for kinematics-based fundamental frequency control", "url": "http://arxiv.org/pdf/1910.02020v1", "summary": "The fundamental frequency (F0) of human voice is generally controlled by changing the vocal fold parameters (including tension, length and mass), which in turn is manipulated by the muscle exciters, activated by the neural synergies. In order to begin investigating the neuromuscular F0 control pathway, we simulate a simple biomechanical arm prototype (instead of an artificial vocal tract) that tends to control F0 of an artificial sound synthesiser based on the elbow movements. The intended arm movements are decoded from the EEG signal inputs (collected simultaneously with the kinematic hand data of the participant) through a combined machine learning and biomechanical modeling strategy. The machine learning model is employed to identify the muscle activation of a single-muscle arm model in ArtiSynth (from input brain signal), in order to match the actual kinematic (elbow joint angle) data . The biomechanical model utilises this estimated muscle excitation to produce corresponding changes in elbow angle, which is then linearly mapped to F0 of a vocal sound synthesiser. We use the F0 value mapped from the actual kinematic hand data (via same function) as the ground truth and compare the F0 estimated from brain signal. A detailed qualitative and quantitative performance comparison shows that the proposed neuromuscular pathway can indeed be utilised to accurately control the vocal fundamental frequency, thereby demonstrating the success of our closed loop neuro-biomechanical control scheme.", "published": "2019-09-25T02:49:12Z", "version": 1}, {"aid": "1909.11286", "authors": ["Ze Wang", "Xiuyuan Cheng", "Guillermo Sapiro", "Qiang Qiu"], "title": "Stochastic Conditional Generative Networks with Basis Decomposition", "url": "http://arxiv.org/pdf/1909.11286v2", "summary": "While generative adversarial networks (GANs) have revolutionized machine learning, a number of open questions remain to fully understand them and exploit their power. One of these questions is how to efficiently achieve proper diversity and sampling of the multi-mode data space. To address this, we introduce BasisGAN, a stochastic conditional multi-mode image generator. By exploiting the observation that a convolutional filter can be well approximated as a linear combination of a small set of basis elements, we learn a plug-and-played basis generator to stochastically generate basis elements, with just a few hundred of parameters, to fully embed stochasticity into convolutional filters. By sampling basis elements instead of filters, we dramatically reduce the cost of modeling the parameter space with no sacrifice on either image diversity or fidelity. To illustrate this proposed plug-and-play framework, we construct variants of BasisGAN based on state-of-the-art conditional image generation networks, and train the networks by simply plugging in a basis generator, without additional auxiliary components, hyperparameters, or training objectives. The experimental success is complemented with theoretical results indicating how the perturbations introduced by the proposed sampling of basis elements can propagate to the appearance of generated images.", "published": "2019-09-25T04:37:38Z", "version": 2}, {"aid": "1909.11321", "authors": ["Jun-Gi Jang", "Chun Quan", "Hyun Dong Lee", "U Kang"], "title": "FALCON: Lightweight and Accurate Convolution", "url": "http://arxiv.org/pdf/1909.11321v2", "summary": "How can we efficiently compress Convolutional Neural Network (CNN) while retaining their accuracy on classification tasks? Depthwise Separable Convolution (DSConv), which replaces a standard convolution with a depthwise convolution and a pointwise convolution, has been used for building lightweight architectures. However, previous works based on depthwise separable convolution are limited when compressing a trained CNN model since 1) they are mostly heuristic approaches without a precise understanding of their relations to standard convolution, and 2) their accuracies do not match that of the standard convolution. In this paper, we propose FALCON, an accurate and lightweight method to compress CNN. FALCON uses GEP, our proposed mathematical formulation to approximate the standard convolution kernel, to interpret existing convolution methods based on depthwise separable convolution. By exploiting the knowledge of a trained standard model and carefully determining the order of depthwise separable convolution via GEP, FALCON achieves sufficient accuracy close to that of the trained standard model. Furthermore, this interpretation leads to developing a generalized version rank-k FALCON which performs k independent FALCON operations and sums up the result. Experiments show that FALCON 1) provides higher accuracy than existing methods based on depthwise separable convolution and tensor decomposition, and 2) reduces the number of parameters and FLOPs of standard convolution by up to a factor of 8 while ensuring similar accuracy. We also demonstrate that rank-k FALCON further improves the accuracy while sacrificing a bit of compression and computation reduction rates.", "published": "2019-09-25T07:48:31Z", "version": 2}, {"aid": "1909.11825", "authors": ["Yu Sun", "Eric Tzeng", "Trevor Darrell", "Alexei A. Efros"], "title": "Unsupervised Domain Adaptation through Self-Supervision", "url": "http://arxiv.org/pdf/1909.11825v2", "summary": "This paper addresses unsupervised domain adaptation, the setting where labeled training data is available on a source domain, but the goal is to have good performance on a target domain with only unlabeled data. Like much of previous work, we seek to align the learned representations of the source and target domains while preserving discriminability. The way we accomplish alignment is by learning to perform auxiliary self-supervised task(s) on both domains simultaneously. Each self-supervised task brings the two domains closer together along the direction relevant to that task. Training this jointly with the main task classifier on the source domain is shown to successfully generalize to the unlabeled target domain. The presented objective is straightforward to implement and easy to optimize. We achieve state-of-the-art results on four out of seven standard benchmarks, and competitive results on segmentation adaptation. We also demonstrate that our method composes well with another popular pixel-level adaptation method.", "published": "2019-09-26T00:21:16Z", "version": 2}, {"aid": "1909.11851", "authors": ["Dennis Lee", "Christian Szegedy", "Markus N. Rabe", "Sarah M. Loos", "Kshitij Bansal"], "title": "Mathematical Reasoning in Latent Space", "url": "http://arxiv.org/pdf/1909.11851v1", "summary": "We design and conduct a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. We can compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether a statement can be rewritten by other theorems. Predicting the embedding of a formula generated by some rewrite rule is naturally viewed as approximate reasoning in the latent space. In order to measure the effectiveness of this reasoning, we perform approximate deduction sequences in the latent space and use the resulting embedding to inform the semantic features of the corresponding formal statement (which is obtained by performing the corresponding rewrite sequence using real formulas). Our experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps. Since our corpus of mathematical formulas includes a wide variety of mathematical disciplines, this experiment is a strong indicator for the feasibility of deduction in latent space in general.", "published": "2019-09-26T02:33:07Z", "version": 1}, {"aid": "1909.11862", "authors": ["Yi Wang", "Zhen-Peng Bian", "Junhui Hou", "Lap-Pui Chau"], "title": "Convolutional Neural Networks with Dynamic Regularization", "url": "http://arxiv.org/pdf/1909.11862v3", "summary": "Regularization is commonly used for alleviating overfitting in machine learning. For convolutional neural networks (CNNs), regularization methods, such as DropBlock and Shake-Shake, have illustrated the improvement in the generalization performance. However, these methods lack a self-adaptive ability throughout training. That is, the regularization strength is fixed to a predefined schedule, and manual adjustments are required to adapt to various network architectures. In this paper, we propose a dynamic regularization method for CNNs. Specifically, we model the regularization strength as a function of the training loss. According to the change of the training loss, our method can dynamically adjust the regularization strength in the training procedure, thereby balancing the underfitting and overfitting of CNNs. With dynamic regularization, a large-scale model is automatically regularized by the strong perturbation, and vice versa. Experimental results show that the proposed method can improve the generalization capability on off-the-shelf network architectures and outperform state-of-the-art regularization methods.", "published": "2019-09-26T03:06:49Z", "version": 3}, {"aid": "1909.11926", "authors": ["Guilin Li", "Xing Zhang", "Zitong Wang", "Matthias Tan", "Jiashi Feng", "Zhenguo Li", "Tong Zhang"], "title": "Hierarchical Neural Architecture Search via Operator Clustering", "url": "http://arxiv.org/pdf/1909.11926v5", "summary": "Recently, the efficiency of automatic neural architecture design has been significantly improved by gradient-based search methods such as DARTS. However, recent literature has brought doubt to the generalization ability of DARTS, arguing that DARTS performs poorly when the search space is changed, i.e, when different set of candidate operators are used. Regularization techniques such as early stopping have been proposed to partially solve this problem. In this paper, we tackle this problem from a different perspective by identifying two contributing factors to the collapse of DARTS when the search space changes: (1) the correlation of similar operators incurs unfavorable competition among them and makes their relative importance score unreliable and (2) the optimization complexity gap between the proxy search stage and the final training. Based on these findings, we propose a new hierarchical search algorithm. With its operator clustering and optimization complexity match, the algorithm can consistently find high-performance architecture across various search spaces. For all the five variants of the popular cell-based search spaces, the proposed algorithm always obtains state-of-the-art architecture with best accuracy on the CIFAR-10, CIFAR-100 and ImageNet over other well-established DARTS-alike algorithms. Code is available at https://github.com/susan0199/StacNAS.", "published": "2019-09-26T06:26:58Z", "version": 5}, {"aid": "1909.11932", "authors": ["Md Sazzad Hossain", "Andrew P Paplinski", "John M Betts"], "title": "Adaptive Class Weight based Dual Focal Loss for Improved Semantic Segmentation", "url": "http://arxiv.org/pdf/1909.11932v3", "summary": "In this paper, we propose a Dual Focal Loss (DFL) function, as a replacement for the standard cross entropy (CE) function to achieve a better treatment of the unbalanced classes in a dataset. Our DFL method is an improvement on the recently reported Focal Loss (FL) cross-entropy function, which proposes a scaling method that puts more weight on the examples that are difficult to classify over those that are easy. However, the scaling parameter of FL is empirically set, which is problem-dependent. In addition, like other CE variants, FL only focuses on the loss of true classes. Therefore, no loss feedback is gained from the false classes. Although focusing only on true examples increases probability on true classes and correspondingly reduces probability on false classes due to the nature of the softmax function, it does not achieve the best convergence due to avoidance of the loss on false classes. Our DFL method improves on the simple FL in two ways. Firstly, it takes the idea of FL to focus more on difficult examples than the easy ones, but evaluates loss on both true and negative classes with equal importance. Secondly, the scaling parameter of DFL has been made learnable so that it can tune itself by backpropagation rather than being dependent on manual tuning. In this way, our proposed DFL method offers an auto-tunable loss function that can reduce the class imbalance effect as well as put more focus on both true difficult examples and negative easy examples.", "published": "2019-09-26T06:36:21Z", "version": 3}, {"aid": "1910.13351", "authors": ["Donald C. Wunsch"], "title": "Admiring the Great Mountain: A Celebration Special Issue in Honor of Stephen Grossbergs 80th Birthday", "url": "http://arxiv.org/pdf/1910.13351v1", "summary": "This editorial summarizes selected key contributions of Prof. Stephen Grossberg and describes the papers in this 80th birthday special issue in his honor. His productivity, creativity, and vision would each be enough to mark a scientist of the first caliber. In combination, they have resulted in contributions that have changed the entire discipline of neural networks. Grossberg has been tremendously influential in engineering, dynamical systems, and artificial intelligence as well. Indeed, he has been one of the most important mentors and role models in my career, and has done so with extraordinary generosity and encouragement. All authors in this special issue have taken great pleasure in hereby commemorating his extraordinary career and contributions.", "published": "2019-09-26T09:17:01Z", "version": 1}, {"aid": "1909.12579", "authors": ["Yulong Wang", "Xiaolu Zhang", "Lingxi Xie", "Jun Zhou", "Hang Su", "Bo Zhang", "Xiaolin Hu"], "title": "Pruning from Scratch", "url": "http://arxiv.org/pdf/1909.12579v1", "summary": "Network pruning is an important research field aiming at reducing computational costs of neural networks. Conventional approaches follow a fixed paradigm which first trains a large and redundant network, and then determines which units (e.g., channels) are less important and thus can be removed. In this work, we find that pre-training an over-parameterized model is not necessary for obtaining the target pruned structure. In fact, a fully-trained over-parameterized model will reduce the search space for the pruned structure. We empirically show that more diverse pruned structures can be directly pruned from randomly initialized weights, including potential models with better performance. Therefore, we propose a novel network pruning pipeline which allows pruning from scratch. In the experiments for compressing classification models on CIFAR10 and ImageNet datasets, our approach not only greatly reduces the pre-training burden of traditional pruning methods, but also achieves similar or even higher accuracy under the same computation budgets. Our results facilitate the community to rethink the effectiveness of existing techniques used for network pruning.", "published": "2019-09-27T09:38:31Z", "version": 1}, {"aid": "1909.12638", "authors": ["Jinchen Xuan", "Yunchang Yang", "Ze Yang", "Di He", "Liwei Wang"], "title": "On the Anomalous Generalization of GANs", "url": "http://arxiv.org/pdf/1909.12638v2", "summary": "Generative models, especially Generative Adversarial Networks (GANs), have received significant attention recently. However, it has been observed that in terms of some attributes, e.g. the number of simple geometric primitives in an image, GANs are not able to learn the target distribution in practice. Motivated by this observation, we discover two specific problems of GANs leading to anomalous generalization behaviour, which we refer to as the sample insufficiency and the pixel-wise combination. For the first problem of sample insufficiency, we show theoretically and empirically that the batchsize of the training samples in practice may be insufficient for the discriminator to learn an accurate discrimination function. It could result in unstable training dynamics for the generator, leading to anomalous generalization. For the second problem of pixel-wise combination, we find that besides recognizing the positive training samples as real, under certain circumstances, the discriminator could be fooled to recognize the pixel-wise combinations (e.g. pixel-wise average) of the positive training samples as real. However, those combinations could be visually different from the real samples in the target distribution. With the fooled discriminator as reference, the generator would obtain biased supervision further, leading to the anomalous generalization behaviour. Additionally, in this paper, we propose methods to mitigate the anomalous generalization of GANs. Extensive experiments on benchmark show our proposed methods improve the FID score up to 30\\% on natural image dataset.", "published": "2019-09-27T12:00:41Z", "version": 2}, {"aid": "1909.12778", "authors": ["Xiaohan Ding", "Guiguang Ding", "Xiangxin Zhou", "Yuchen Guo", "Jungong Han", "Ji Liu"], "title": "Global Sparse Momentum SGD for Pruning Very Deep Neural Networks", "url": "http://arxiv.org/pdf/1909.12778v3", "summary": "Deep Neural Network (DNN) is powerful but computationally expensive and memory intensive, thus impeding its practical usage on resource-constrained front-end devices. DNN pruning is an approach for deep model compression, which aims at eliminating some parameters with tolerable performance degradation. In this paper, we propose a novel momentum-SGD-based optimization method to reduce the network complexity by on-the-fly pruning. Concretely, given a global compression ratio, we categorize all the parameters into two parts at each training iteration which are updated using different rules. In this way, we gradually zero out the redundant parameters, as we update them using only the ordinary weight decay but no gradients derived from the objective function. As a departure from prior methods that require heavy human works to tune the layer-wise sparsity ratios, prune by solving complicated non-differentiable problems or finetune the model after pruning, our method is characterized by 1) global compression that automatically finds the appropriate per-layer sparsity ratios; 2) end-to-end training; 3) no need for a time-consuming re-training process after pruning; and 4) superior capability to find better winning tickets which have won the initialization lottery.", "published": "2019-09-27T16:24:19Z", "version": 3}, {"aid": "1910.04858", "authors": ["Lu Mi", "Hao Wang", "Yonglong Tian", "Hao He", "Nir Shavit"], "title": "Training-Free Uncertainty Estimation for Dense Regression: Sensitivity as a Surrogate", "url": "http://arxiv.org/pdf/1910.04858v3", "summary": "Uncertainty estimation is an essential step in the evaluation of the robustness for deep learning models in computer vision, especially when applied in risk-sensitive areas. However, most state-of-the-art deep learning models either fail to obtain uncertainty estimation or need significant modification (e.g., formulating a proper Bayesian treatment) to obtain it. Most previous methods are not able to take an arbitrary model off the shelf and generate uncertainty estimation without retraining or redesigning it. To address this gap, we perform a systematic exploration into training-free uncertainty estimation for dense regression, an unrecognized yet important problem, and provide a theoretical construction justifying such estimations. We propose three simple and scalable methods to analyze the variance of outputs from a trained network under tolerable perturbations: infer-transformation, infer-noise, and infer-dropout. They operate solely during the inference, without the need to re-train, re-design, or fine-tune the models, as typically required by state-of-the-art uncertainty estimation methods. Surprisingly, even without involving such perturbations in training, our methods produce comparable or even better uncertainty estimation when compared to training-required state-of-the-art methods.", "published": "2019-09-28T02:30:02Z", "version": 3}, {"aid": "1909.13063", "authors": ["Jiao Xie", "Shaohui Lin", "Yichen Zhang", "Linkai Luo"], "title": "Training convolutional neural networks with cheap convolutions and online distillation", "url": "http://arxiv.org/pdf/1909.13063v3", "summary": "The large memory and computation consumption in convolutional neural networks (CNNs) has been one of the main barriers for deploying them on resource-limited systems. To this end, most cheap convolutions (e.g., group convolution, depth-wise convolution, and shift convolution) have recently been used for memory and computation reduction but with the specific architecture designing. Furthermore, it results in a low discriminability of the compressed networks by directly replacing the standard convolution with these cheap ones. In this paper, we propose to use knowledge distillation to improve the performance of the compact student networks with cheap convolutions. In our case, the teacher is a network with the standard convolution, while the student is a simple transformation of the teacher architecture without complicated redesigning. In particular, we propose a novel online distillation method, which online constructs the teacher network without pre-training and conducts mutual learning between the teacher and student network, to improve the performance of the student model. Extensive experiments demonstrate that the proposed approach achieves superior performance to simultaneously reduce memory and computation overhead of cutting-edge CNNs on different datasets, including CIFAR-10/100 and ImageNet ILSVRC 2012, compared to the state-of-the-art CNN compression and acceleration methods. The codes are publicly available at https://github.com/EthanZhangYC/OD-cheap-convolution.", "published": "2019-09-28T10:16:17Z", "version": 3}, {"aid": "1910.00138", "authors": ["Victor Bogdan", "Cosmin Bonchi\u015f", "Ciprian Orhei"], "title": "Custom Extended Sobel Filters", "url": "http://arxiv.org/pdf/1910.00138v1", "summary": "Edge detection is widely and fundamental feature used in various algorithms in computer vision to determine the edges in an image. The edge detection algorithm is used to determine the edges in an image which are further used by various algorithms from line detection to machine learning that can determine objects based on their contour. Inspired by new convolution techniques in machine learning we discuss here the idea of extending the standard Sobel kernels, which are used to compute the gradient of an image in order to find its edges. We compare the result of our custom extended filters with the results of the standard Sobel filter and other edge detection filters using different image sets and algorithms. We present statistical results regarding the custom extended Sobel filters improvements.", "published": "2019-09-30T22:30:09Z", "version": 1}, {"aid": "1910.00724", "authors": ["Souvik Kundu", "Saurav Prakash", "Haleh Akrami", "Peter A. Beerel", "Keith M. Chugg"], "title": "A Pre-defined Sparse Kernel Based Convolution for Deep CNNs", "url": "http://arxiv.org/pdf/1910.00724v2", "summary": "The high demand for computational and storage resources severely impede the deployment of deep convolutional neural networks (CNNs) in limited-resource devices. Recent CNN architectures have proposed reduced complexity versions (e.g. SuffleNet and MobileNet) but at the cost of modest decreases inaccuracy. This paper proposes pSConv, a pre-defined sparse 2D kernel-based convolution, which promises significant improvements in the trade-off between complexity and accuracy for both CNN training and inference. To explore the potential of this approach, we have experimented with two widely accepted datasets, CIFAR-10 and Tiny ImageNet, in sparse variants of both the ResNet18 and VGG16 architectures. Our approach shows a parameter count reduction of up to 4.24x with modest degradation in classification accuracy relative to that of standard CNNs. Our approach outperforms a popular variant of ShuffleNet using a variant of ResNet18 with pSConv having 3x3 kernels with only four of nine elements not fixed at zero. In particular, the parameter count is reduced by 1.7x for CIFAR-10 and 2.29x for Tiny ImageNet with an increased accuracy of ~4%.", "published": "2019-10-02T00:38:38Z", "version": 2}, {"aid": "1910.00775", "authors": ["Taesup Kim", "Sungjin Ahn", "Yoshua Bengio"], "title": "Variational Temporal Abstraction", "url": "http://arxiv.org/pdf/1910.00775v1", "summary": "We introduce a variational approach to learning and inference of temporally hierarchical structure and representation for sequential data. We propose the Variational Temporal Abstraction (VTA), a hierarchical recurrent state space model that can infer the latent temporal structure and thus perform the stochastic state transition hierarchically. We also propose to apply this model to implement the jumpy-imagination ability in imagination-augmented agent-learning in order to improve the efficiency of the imagination. In experiments, we demonstrate that our proposed method can model 2D and 3D visual sequence datasets with interpretable temporal structure discovery and that its application to jumpy imagination enables more efficient agent-learning in a 3D navigation task.", "published": "2019-10-02T04:37:23Z", "version": 1}, {"aid": "1910.01089", "authors": ["Juan Luis Gonzalez Bello", "Munchurl Kim"], "title": "Deep 3D Pan via adaptive \"t-shaped\" convolutions with global and local adaptive dilations", "url": "http://arxiv.org/pdf/1910.01089v3", "summary": "Recent advances in deep learning have shown promising results in many low-level vision tasks. However, solving the single-image-based view synthesis is still an open problem. In particular, the generation of new images at parallel camera views given a single input image is of great interest, as it enables 3D visualization of the 2D input scenery. We propose a novel network architecture to perform stereoscopic view synthesis at arbitrary camera positions along the X-axis, or Deep 3D Pan, with \"t-shaped\" adaptive kernels equipped with globally and locally adaptive dilations. Our proposed network architecture, the monster-net, is devised with a novel \"t-shaped\" adaptive kernel with globally and locally adaptive dilation, which can efficiently incorporate global camera shift into and handle local 3D geometries of the target image's pixels for the synthesis of naturally looking 3D panned views when a 2-D input image is given. Extensive experiments were performed on the KITTI, CityScapes and our VICLAB_STEREO indoors dataset to prove the efficacy of our method. Our monster-net significantly outperforms the state-of-the-art method, SOTA, by a large margin in all metrics of RMSE, PSNR, and SSIM. Our proposed monster-net is capable of reconstructing more reliable image structures in synthesized images with coherent geometry. Moreover, the disparity information that can be extracted from the \"t-shaped\" kernel is much more reliable than that of the SOTA for the unsupervised monocular depth estimation task, confirming the effectiveness of our method.", "published": "2019-10-02T17:09:58Z", "version": 3}, {"aid": "1910.01409", "authors": ["Dexuan Zhang", "Tatsuya Harada"], "title": "A General Upper Bound for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/1910.01409v2", "summary": "In this work, we present a novel upper bound of target error to address the problem for unsupervised domain adaptation. Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks. Furthermore, a theory proposed by Ben-David et al. (2010) provides a upper bound for target error when transferring the knowledge, which can be summarized as minimizing the source error and distance between marginal distributions simultaneously. However, common methods based on the theory usually ignore the joint error such that samples from different classes might be mixed together when matching marginal distribution. And in such case, no matter how we minimize the marginal discrepancy, the target error is not bounded due to an increasing joint error. To address this problem, we propose a general upper bound taking joint error into account, such that the undesirable case can be properly penalized. In addition, we utilize constrained hypothesis space to further formalize a tighter bound as well as a novel cross margin discrepancy to measure the dissimilarity between hypotheses which alleviates instability during adversarial learning. Extensive empirical evidence shows that our proposal outperforms related approaches in image classification error rates on standard domain adaptation benchmarks.", "published": "2019-10-03T11:31:14Z", "version": 2}, {"aid": "1910.01708", "authors": ["Scott Fujimoto", "Edoardo Conti", "Mohammad Ghavamzadeh", "Joelle Pineau"], "title": "Benchmarking Batch Deep Reinforcement Learning Algorithms", "url": "http://arxiv.org/pdf/1910.01708v1", "summary": "Widely-used deep reinforcement learning algorithms have been shown to fail in the batch setting--learning from a fixed data set without interaction with the environment. Following this result, there have been several papers showing reasonable performances under a variety of environments and batch settings. In this paper, we benchmark the performance of recent off-policy and batch reinforcement learning algorithms under unified settings on the Atari domain, with data generated by a single partially-trained behavioral policy. We find that under these conditions, many of these algorithms underperform DQN trained online with the same amount of data, as well as the partially-trained behavioral policy. To introduce a strong baseline, we adapt the Batch-Constrained Q-learning algorithm to a discrete-action setting, and show it outperforms all existing algorithms at this task.", "published": "2019-10-03T20:15:55Z", "version": 1}, {"aid": "1910.02840", "authors": ["Aram-Alexandre Pooladian", "Chris Finlay", "Adam M Oberman"], "title": "Farkas layers: don't shift the data, fix the geometry", "url": "http://arxiv.org/pdf/1910.02840v1", "summary": "Successfully training deep neural networks often requires either batch normalization, appropriate weight initialization, both of which come with their own challenges. We propose an alternative, geometrically motivated method for training. Using elementary results from linear programming, we introduce Farkas layers: a method that ensures at least one neuron is active at a given layer. Focusing on residual networks with ReLU activation, we empirically demonstrate a significant improvement in training capacity in the absence of batch normalization or methods of initialization across a broad range of network sizes on benchmark datasets.", "published": "2019-10-04T15:24:37Z", "version": 1}, {"aid": "1910.02560", "authors": ["Wenju Xu", "Shawn Keshmiri", "Guanghui Wang"], "title": "Stacked Wasserstein Autoencoder", "url": "http://arxiv.org/pdf/1910.02560v1", "summary": "Approximating distributions over complicated manifolds, such as natural images, are conceptually attractive. The deep latent variable model, trained using variational autoencoders and generative adversarial networks, is now a key technique for representation learning. However, it is difficult to unify these two models for exact latent-variable inference and parallelize both reconstruction and sampling, partly due to the regularization under the latent variables, to match a simple explicit prior distribution. These approaches are prone to be oversimplified, and can only characterize a few modes of the true distribution. Based on the recently proposed Wasserstein autoencoder (WAE) with a new regularization as an optimal transport. The paper proposes a stacked Wasserstein autoencoder (SWAE) to learn a deep latent variable model. SWAE is a hierarchical model, which relaxes the optimal transport constraints at two stages. At the first stage, the SWAE flexibly learns a representation distribution, i.e., the encoded prior; and at the second stage, the encoded representation distribution is approximated with a latent variable model under the regularization encouraging the latent distribution to match the explicit prior. This model allows us to generate natural textual outputs as well as perform manipulations in the latent space to induce changes in the output space. Both quantitative and qualitative results demonstrate the superior performance of SWAE compared with the state-of-the-art approaches in terms of faithful reconstruction and generation quality.", "published": "2019-10-04T17:07:42Z", "version": 1}, {"aid": "1910.02054", "authors": ["Samyam Rajbhandari", "Jeff Rasley", "Olatunji Ruwase", "Yuxiong He"], "title": "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models", "url": "http://arxiv.org/pdf/1910.02054v3", "summary": "Large deep learning models offer significant accuracy gains, but training billions to trillions of parameters is challenging. Existing solutions such as data and model parallelisms exhibit fundamental limitations to fit these models into limited device memory, while obtaining computation, communication and development efficiency. We develop a novel solution, Zero Redundancy Optimizer (ZeRO), to optimize memory, vastly improving training speed while increasing the model size that can be efficiently trained. ZeRO eliminates memory redundancies in data- and model-parallel training while retaining low communication volume and high computational granularity, allowing us to scale the model size proportional to the number of devices with sustained high efficiency. Our analysis on memory requirements and communication volume demonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters using today's hardware.   We implement and evaluate ZeRO: it trains large models of over 100B parameter with super-linear speedup on 400 GPUs, achieving throughput of 15 Petaflops. This represents an 8x increase in model size and 10x increase in achievable performance over state-of-the-art. In terms of usability, ZeRO can train large models of up to 13B parameters (e.g., larger than Megatron GPT 8.3B and T5 11B) without requiring model parallelism which is harder for scientists to apply. Last but not the least, researchers have used the system breakthroughs of ZeRO to create the world's largest language model (Turing-NLG, 17B parameters) with record breaking accuracy.", "published": "2019-10-04T17:29:39Z", "version": 3}, {"aid": "1910.02190", "authors": ["Edgar Riba", "Dmytro Mishkin", "Daniel Ponsa", "Ethan Rublee", "Gary Bradski"], "title": "Kornia: an Open Source Differentiable Computer Vision Library for PyTorch", "url": "http://arxiv.org/pdf/1910.02190v2", "summary": "This work presents Kornia -- an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. The package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.", "published": "2019-10-05T01:29:54Z", "version": 2}, {"aid": "1910.04875", "authors": ["Xiaomeng Dong", "Junpyo Hong", "Hsi-Ming Chang", "Michael Potter", "Aritra Chowdhury", "Purujit Bahl", "Vivek Soni", "Yun-Chan Tsai", "Rajesh Tamada", "Gaurav Kumar", "Caroline Favart", "V. Ratna Saripalli", "Gopal Avinash"], "title": "FastEstimator: A Deep Learning Library for Fast Prototyping and Productization", "url": "http://arxiv.org/pdf/1910.04875v2", "summary": "As the complexity of state-of-the-art deep learning models increases by the month, implementation, interpretation, and traceability become ever-more-burdensome challenges for AI practitioners around the world. Several AI frameworks have risen in an effort to stem this tide, but the steady advance of the field has begun to test the bounds of their flexibility, expressiveness, and ease of use. To address these concerns, we introduce a radically flexible high-level open source deep learning framework for both research and industry. We introduce FastEstimator.", "published": "2019-10-07T01:01:27Z", "version": 2}, {"aid": "1910.02629", "authors": ["Zhenyue Qin", "Dongwoo Kim"], "title": "Softmax Is Not an Artificial Trick: An Information-Theoretic View of Softmax in Neural Networks", "url": "http://arxiv.org/pdf/1910.02629v3", "summary": "Despite great popularity of applying softmax to map the non-normalised outputs of a neural network to a probability distribution over predicting classes, this normalised exponential transformation still seems to be artificial. A theoretic framework that incorporates softmax as an intrinsic component is still lacking. In this paper, we view neural networks embedding softmax from an information-theoretic perspective. Under this view, we can naturally and mathematically derive log-softmax as an inherent component in a neural network for evaluating the conditional mutual information between network output vectors and labels given an input datum. We show that training deterministic neural networks through maximising log-softmax is equivalent to enlarging the conditional mutual information, i.e., feeding label information into network outputs. We also generalise our informative-theoretic perspective to neural networks with stochasticity and derive information upper and lower bounds of log-softmax. In theory, such an information-theoretic view offers rationality support for embedding softmax in neural networks; in practice, we eventually demonstrate a computer vision application example of how to employ our information-theoretic view to filter out targeted objects on images.", "published": "2019-10-07T06:46:06Z", "version": 3}, {"aid": "1910.02940", "authors": ["Hang Gao", "Xizhou Zhu", "Steve Lin", "Jifeng Dai"], "title": "Deformable Kernels: Adapting Effective Receptive Fields for Object Deformation", "url": "http://arxiv.org/pdf/1910.02940v2", "summary": "Convolutional networks are not aware of an object's geometric variations, which leads to inefficient utilization of model and data capacity. To overcome this issue, recent works on deformation modeling seek to spatially reconfigure the data towards a common arrangement such that semantic recognition suffers less from deformation. This is typically done by augmenting static operators with learned free-form sampling grids in the image space, dynamically tuned to the data and task for adapting the receptive field. Yet adapting the receptive field does not quite reach the actual goal -- what really matters to the network is the \"effective\" receptive field (ERF), which reflects how much each pixel contributes. It is thus natural to design other approaches to adapt the ERF directly during runtime.   In this work, we instantiate one possible solution as Deformable Kernels (DKs), a family of novel and generic convolutional operators for handling object deformations by directly adapting the ERF while leaving the receptive field untouched. At the heart of our method is the ability to resample the original kernel space towards recovering the deformation of objects. This approach is justified with theoretical insights that the ERF is strictly determined by data sampling locations and kernel values. We implement DKs as generic drop-in replacements of rigid kernels and conduct a series of empirical studies whose results conform with our theories. Over several tasks and standard base models, our approach compares favorably against prior works that adapt during runtime. In addition, further experiments suggest a working mechanism orthogonal and complementary to previous works.", "published": "2019-10-07T17:58:10Z", "version": 2}, {"aid": "1910.04877", "authors": ["Prateeth Nayak", "David Zhang", "Sek Chai"], "title": "Bit Efficient Quantization for Deep Neural Networks", "url": "http://arxiv.org/pdf/1910.04877v1", "summary": "Quantization for deep neural networks have afforded models for edge devices that use less on-board memory and enable efficient low-power inference. In this paper, we present a comparison of model-parameter driven quantization approaches that can achieve as low as 3-bit precision without affecting accuracy. The post-training quantization approaches are data-free, and the resulting weight values are closely tied to the dataset distribution on which the model has converged to optimality. We show quantization results for a number of state-of-art deep neural networks (DNN) using large dataset like ImageNet. To better analyze quantization results, we describe the overall range and local sparsity of values afforded through various quantization schemes. We show the methods to lower bit-precision beyond quantization limits with object class clustering.", "published": "2019-10-07T18:43:12Z", "version": 1}, {"aid": "1910.03151", "authors": ["Qilong Wang", "Banggu Wu", "Pengfei Zhu", "Peihua Li", "Wangmeng Zuo", "Qinghua Hu"], "title": "ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1910.03151v4", "summary": "Recently, channel attention mechanism has demonstrated to offer great potential in improving the performance of deep convolutional neural networks (CNNs). However, most existing methods dedicate to developing more sophisticated attention modules for achieving better performance, which inevitably increase model complexity. To overcome the paradox of performance and complexity trade-off, this paper proposes an Efficient Channel Attention (ECA) module, which only involves a handful of parameters while bringing clear performance gain. By dissecting the channel attention module in SENet, we empirically show avoiding dimensionality reduction is important for learning channel attention, and appropriate cross-channel interaction can preserve performance while significantly decreasing model complexity. Therefore, we propose a local cross-channel interaction strategy without dimensionality reduction, which can be efficiently implemented via $1D$ convolution. Furthermore, we develop a method to adaptively select kernel size of $1D$ convolution, determining coverage of local cross-channel interaction. The proposed ECA module is efficient yet effective, e.g., the parameters and computations of our modules against backbone of ResNet50 are 80 vs. 24.37M and 4.7e-4 GFLOPs vs. 3.86 GFLOPs, respectively, and the performance boost is more than 2% in terms of Top-1 accuracy. We extensively evaluate our ECA module on image classification, object detection and instance segmentation with backbones of ResNets and MobileNetV2. The experimental results show our module is more efficient while performing favorably against its counterparts.", "published": "2019-10-08T01:14:26Z", "version": 4}, {"aid": "1910.03676", "authors": ["Ehsan Adeli", "Qingyu Zhao", "Adolf Pfefferbaum", "Edith V. Sullivan", "Li Fei-Fei", "Juan Carlos Niebles", "Kilian M. Pohl"], "title": "Representation Learning with Statistical Independence to Mitigate Bias", "url": "http://arxiv.org/pdf/1910.03676v4", "summary": "Presence of bias (in datasets or tasks) is inarguably one of the most critical challenges in machine learning applications that has alluded to pivotal debates in recent years. Such challenges range from spurious associations between variables in medical studies to the bias of race in gender or face recognition systems. Controlling for all types of biases in the dataset curation stage is cumbersome and sometimes impossible. The alternative is to use the available data and build models incorporating fair representation learning. In this paper, we propose such a model based on adversarial training with two competing objectives to learn features that have (1) maximum discriminative power with respect to the task and (2) minimal statistical mean dependence with the protected (bias) variable(s). Our approach does so by incorporating a new adversarial loss function that encourages a vanished correlation between the bias and the learned features. We apply our method to synthetic data, medical images (containing task bias), and a dataset for gender classification (containing dataset bias). Our results show that the learned features by our method not only result in superior prediction performance but also are unbiased. The code is available at https://github.com/QingyuZhao/BR-Net/.", "published": "2019-10-08T20:33:58Z", "version": 4}, {"aid": "1910.03866", "authors": ["Leonie Henschel", "Sailesh Conjeti", "Santiago Estrada", "Kersten Diers", "Bruce Fischl", "Martin Reuter"], "title": "FastSurfer -- A fast and accurate deep learning based neuroimaging pipeline", "url": "http://arxiv.org/pdf/1910.03866v4", "summary": "Traditional neuroimage analysis pipelines involve computationally intensive, time-consuming optimization steps, and thus, do not scale well to large cohort studies with thousands or tens of thousands of individuals. In this work we propose a fast and accurate deep learning based neuroimaging pipeline for the automated processing of structural human brain MRI scans, replicating FreeSurfer's anatomical segmentation including surface reconstruction and cortical parcellation. To this end, we introduce an advanced deep learning architecture capable of whole brain segmentation into 95 classes. The network architecture incorporates local and global competition via competitive dense blocks and competitive skip pathways, as well as multi-slice information aggregation that specifically tailor network performance towards accurate segmentation of both cortical and sub-cortical structures. Further, we perform fast cortical surface reconstruction and thickness analysis by introducing a spectral spherical embedding and by directly mapping the cortical labels from the image to the surface. This approach provides a full FreeSurfer alternative for volumetric analysis (in under 1 minute) and surface-based thickness analysis (within only around 1h runtime). For sustainability of this approach we perform extensive validation: we assert high segmentation accuracy on several unseen datasets, measure generalizability and demonstrate increased test-retest reliability, and high sensitivity to group differences in dementia.", "published": "2019-10-09T09:41:14Z", "version": 4}, {"aid": "1910.05448", "authors": ["Tharindu Fernando", "Simon Denman", "David Ahmedt-Aristizabal", "Sridha Sridharan", "Kristin Laurens", "Patrick Johnston", "Clinton Fookes"], "title": "Neural Memory Plasticity for Anomaly Detection", "url": "http://arxiv.org/pdf/1910.05448v1", "summary": "In the domain of machine learning, Neural Memory Networks (NMNs) have recently achieved impressive results in a variety of application areas including visual question answering, trajectory prediction, object tracking, and language modelling. However, we observe that the attention based knowledge retrieval mechanisms used in current NMNs restricts them from achieving their full potential as the attention process retrieves information based on a set of static connection weights. This is suboptimal in a setting where there are vast differences among samples in the data domain; such as anomaly detection where there is no consistent criteria for what constitutes an anomaly. In this paper, we propose a plastic neural memory access mechanism which exploits both static and dynamic connection weights in the memory read, write and output generation procedures. We demonstrate the effectiveness and flexibility of the proposed memory model in three challenging anomaly detection tasks in the medical domain: abnormal EEG identification, MRI tumour type classification and schizophrenia risk detection in children. In all settings, the proposed approach outperforms the current state-of-the-art. Furthermore, we perform an in-depth analysis demonstrating the utility of neural plasticity for the knowledge retrieval process and provide evidence on how the proposed memory model generates sparse yet informative memory outputs.", "published": "2019-10-12T00:32:56Z", "version": 1}, {"aid": "1910.05546", "authors": ["Zedong Bi", "Changsong Zhou"], "title": "Understanding the computation of time using neural network models", "url": "http://arxiv.org/pdf/1910.05546v4", "summary": "To maximize future rewards in this ever-changing world, animals must be able to discover the temporal structure of stimuli and then anticipate or act correctly at the right time. How the animals perceive, maintain, and use time intervals ranging from hundreds of milliseconds to multi-seconds in working memory? How temporal information is processed concurrently with spatial information and decision making? Why there are strong neuronal temporal signals in tasks in which temporal information is not required? A systematic understanding of the underlying neural mechanisms is still lacking. Here, we addressed these problems using supervised training of recurrent neural network models. We revealed that neural networks perceive elapsed time through state evolution along stereotypical trajectory, maintain time intervals in working memory in the monotonic increase or decrease of the firing rates of interval-tuned neurons, and compare or produce time intervals by scaling state evolution speed. Temporal and non-temporal information are coded in subspaces orthogonal with each other, and the state trajectories with time at different non-temporal information are quasi-parallel and isomorphic. Such coding geometry facilitates the decoding generalizability of temporal and non-temporal information across each other. The network structure exhibits multiple feedforward sequences that mutually excite or inhibit depending on whether their preferences of non-temporal information are similar or not. We identified four factors that facilitate strong temporal signals in non-timing tasks, including the anticipation of coming events. Our work discloses fundamental computational principles of temporal processing, and is supported by and gives predictions to a number of experimental phenomena.", "published": "2019-10-12T10:07:42Z", "version": 4}, {"aid": "1910.06764", "authors": ["Emilio Parisotto", "H. Francis Song", "Jack W. Rae", "Razvan Pascanu", "Caglar Gulcehre", "Siddhant M. Jayakumar", "Max Jaderberg", "Raphael Lopez Kaufman", "Aidan Clark", "Seb Noury", "Matthew M. Botvinick", "Nicolas Heess", "Raia Hadsell"], "title": "Stabilizing Transformers for Reinforcement Learning", "url": "http://arxiv.org/pdf/1910.06764v1", "summary": "Owing to their ability to both effectively integrate information over long time horizons and scale to massive amounts of data, self-attention architectures have recently shown breakthrough success in natural language processing (NLP), achieving state-of-the-art results in domains such as language modeling and machine translation. Harnessing the transformer's ability to process long time horizons of information could provide a similar performance boost in partially observable reinforcement learning (RL) domains, but the large-scale transformers used in NLP have yet to be successfully applied to the RL setting. In this work we demonstrate that the standard transformer architecture is difficult to optimize, which was previously observed in the supervised learning setting but becomes especially pronounced with RL objectives. We propose architectural modifications that substantially improve the stability and learning speed of the original Transformer and XL variant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses LSTMs on challenging memory environments and achieves state-of-the-art results on the multi-task DMLab-30 benchmark suite, exceeding the performance of an external memory architecture. We show that the GTrXL, trained using the same losses, has stability and performance that consistently matches or exceeds a competitive LSTM baseline, including on more reactive tasks where memory is less critical. GTrXL offers an easy-to-train, simple-to-implement but substantially more expressive architectural alternative to the standard multi-layer LSTM ubiquitously used for RL agents in partially observable environments.", "published": "2019-10-13T20:02:15Z", "version": 1}, {"aid": "1910.05872", "authors": ["Hankook Lee", "Sung Ju Hwang", "Jinwoo Shin"], "title": "Self-supervised Label Augmentation via Input Transformations", "url": "http://arxiv.org/pdf/1910.05872v2", "summary": "Self-supervised learning, which learns by constructing artificial labels given only the input signals, has recently gained considerable attention for learning representations with unlabeled datasets, i.e., learning without any human-annotated supervision. In this paper, we show that such a technique can be used to significantly improve the model accuracy even under fully-labeled datasets. Our scheme trains the model to learn both original and self-supervised tasks, but is different from conventional multi-task learning frameworks that optimize the summation of their corresponding losses. Our main idea is to learn a single unified task with respect to the joint distribution of the original and self-supervised labels, i.e., we augment original labels via self-supervision of input transformation. This simple, yet effective approach allows to train models easier by relaxing a certain invariant constraint during learning the original and self-supervised tasks simultaneously. It also enables an aggregated inference which combines the predictions from different augmentations to improve the prediction accuracy. Furthermore, we propose a novel knowledge transfer technique, which we refer to as self-distillation, that has the effect of the aggregated inference in a single (faster) inference. We demonstrate the large accuracy improvement and wide applicability of our framework on various fully-supervised settings, e.g., the few-shot and imbalanced classification scenarios.", "published": "2019-10-14T00:37:33Z", "version": 2}, {"aid": "1910.05878", "authors": ["Wen Zhang", "Dongrui Wu"], "title": "Manifold Embedded Knowledge Transfer for Brain-Computer Interfaces", "url": "http://arxiv.org/pdf/1910.05878v2", "summary": "Transfer learning makes use of data or knowledge in one problem to help solve a different, yet related, problem. It is particularly useful in brain-computer interfaces (BCIs), for coping with variations among different subjects and/or tasks. This paper considers offline unsupervised cross-subject electroencephalogram (EEG) classification, i.e., we have labeled EEG trials from one or more source subjects, but only unlabeled EEG trials from the target subject. We propose a novel manifold embedded knowledge transfer (MEKT) approach, which first aligns the covariance matrices of the EEG trials in the Riemannian manifold, extracts features in the tangent space, and then performs domain adaptation by minimizing the joint probability distribution shift between the source and the target domains, while preserving their geometric structures. MEKT can cope with one or multiple source domains, and can be computed efficiently. We also propose a domain transferability estimation (DTE) approach to identify the most beneficial source domains, in case there are a large number of source domains. Experiments on four EEG datasets from two different BCI paradigms demonstrated that MEKT outperformed several state-of-the-art transfer learning approaches, and DTE can reduce more than half of the computational cost when the number of source subjects is large, with little sacrifice of classification accuracy.", "published": "2019-10-14T01:33:33Z", "version": 2}, {"aid": "1910.06705", "authors": ["YoungJoon Yoo", "Sanghyuk Chun", "Sangdoo Yun", "Jung-Woo Ha", "Jaejun Yoo"], "title": "Neural Approximation of an Auto-Regressive Process through Confidence Guided Sampling", "url": "http://arxiv.org/pdf/1910.06705v1", "summary": "We propose a generic confidence-based approximation that can be plugged in and simplify the auto-regressive generation process with a proved convergence. We first assume that the priors of future samples can be generated in an independently and identically distributed (i.i.d.) manner using an efficient predictor. Given the past samples and future priors, the mother AR model can post-process the priors while the accompanied confidence predictor decides whether the current sample needs a resampling or not. Thanks to the i.i.d. assumption, the post-processing can update each sample in a parallel way, which remarkably accelerates the mother model. Our experiments on different data domains including sequences and images show that the proposed method can successfully capture the complex structures of the data and generate the meaningful future samples with lower computational cost while preserving the sequential relationship of the data.", "published": "2019-10-15T13:11:24Z", "version": 1}, {"aid": "1910.06849", "authors": ["Guohao Li", "Matthias M\u00fcller", "Guocheng Qian", "Itzel C. Delgadillo", "Abdulellah Abualshour", "Ali Thabet", "Bernard Ghanem"], "title": "DeepGCNs: Making GCNs Go as Deep as CNNs", "url": "http://arxiv.org/pdf/1910.06849v3", "summary": "Convolutional Neural Networks (CNNs) have been very successful at solving a variety of computer vision tasks such as object classification and detection, semantic segmentation, activity understanding, to name just a few. One key enabling factor for their great performance has been the ability to train very deep networks. Despite their huge success in many tasks, CNNs do not work well with non-Euclidean data, which is prevalent in many real-world applications. Graph Convolutional Networks (GCNs) offer an alternative that allows for non-Eucledian data input to a neural network. While GCNs already achieve encouraging results, they are currently limited to architectures with a relatively small number of layers, primarily due to vanishing gradients during training. This work transfers concepts such as residual/dense connections and dilated convolutions from CNNs to GCNs in order to successfully train very deep GCNs. We show the benefit of using deep GCNs (with as many as 112 layers) experimentally across various datasets and tasks. Specifically, we achieve very promising performance in part segmentation and semantic segmentation on point clouds and in node classification of protein functions across biological protein-protein interaction (PPI) graphs. We believe that the insights in this work will open avenues for future research on GCNs and their application to further tasks not explored in this paper. The source code for this work is available at https://github.com/lightaime/deep_gcns_torch and https://github.com/lightaime/deep_gcns for PyTorch and TensorFlow implementation respectively.", "published": "2019-10-15T15:10:34Z", "version": 3}, {"aid": "1910.06950", "authors": ["Nicha C. Dvornek", "Xiaoxiao Li", "Juntang Zhuang", "James S. Duncan"], "title": "Jointly Discriminative and Generative Recurrent Neural Networks for Learning from fMRI", "url": "http://arxiv.org/pdf/1910.06950v1", "summary": "Recurrent neural networks (RNNs) were designed for dealing with time-series data and have recently been used for creating predictive models from functional magnetic resonance imaging (fMRI) data. However, gathering large fMRI datasets for learning is a difficult task. Furthermore, network interpretability is unclear. To address these issues, we utilize multitask learning and design a novel RNN-based model that learns to discriminate between classes while simultaneously learning to generate the fMRI time-series data. Employing the long short-term memory (LSTM) structure, we develop a discriminative model based on the hidden state and a generative model based on the cell state. The addition of the generative model constrains the network to learn functional communities represented by the LSTM nodes that are both consistent with the data generation as well as useful for the classification task. We apply our approach to the classification of subjects with autism vs. healthy controls using several datasets from the Autism Brain Imaging Data Exchange. Experiments show that our jointly discriminative and generative model improves classification learning while also producing robust and meaningful functional communities for better model understanding.", "published": "2019-10-15T17:43:45Z", "version": 1}, {"aid": "1910.07117", "authors": ["Tianxing He", "Jun Liu", "Kyunghyun Cho", "Myle Ott", "Bing Liu", "James Glass", "Fuchun Peng"], "title": "Analyzing the Forgetting Problem in the Pretrain-Finetuning of Dialogue Response Models", "url": "http://arxiv.org/pdf/1910.07117v5", "summary": "In this work, we study how the finetuning stage in the pretrain-finetune framework changes the behavior of a pretrained neural language generator. We focus on the transformer encoder-decoder model for the open-domain dialogue response generation task. Our major finding is that after standard finetuning, the model forgets some of the important language generation skills acquired during large-scale pretraining. We demonstrate the forgetting phenomenon through a set of detailed behavior analysis from the perspectives of knowledge transfer, context sensitivity, and function space projection. As a preliminary attempt to alleviate the forgetting problem, we propose an intuitive finetuning strategy named \"mix-review\". We find that mix-review effectively regularizes the finetuning process, and the forgetting problem is alleviated to some extent. Finally, we discuss interesting behavior of the resulting dialogue model and its implications.", "published": "2019-10-16T01:10:10Z", "version": 5}, {"aid": "1910.07133", "authors": ["Vasil Kolev", "Todor Cooklev", "Fritz Keinert"], "title": "Design of a Simple Orthogonal Multiwavelet Filter by Matrix Spectral Factorization", "url": "http://arxiv.org/pdf/1910.07133v2", "summary": "We consider the design of an orthogonal symmetric/antisymmetric multiwavelet from its matrix product filter by matrix spectral factorization (MSF). As a test problem, we construct a simple matrix product filter with desirable properties, and factor it using Bauer's method, which in this case can be done in closed form. The corresponding orthogonal multiwavelet function is derived using algebraic techniques which allow symmetry to be considered. This leads to the known orthogonal multiwavelet SA1, which can also be derived directly. We also give a lifting scheme for SA1, investigate the influence of the number of significant digits in the calculations, and show some numerical experiments.", "published": "2019-10-16T02:21:52Z", "version": 2}, {"aid": "1910.10485", "authors": ["Gabriele Prato", "Ella Charlaix", "Mehdi Rezagholizadeh"], "title": "Fully Quantized Transformer for Machine Translation", "url": "http://arxiv.org/pdf/1910.10485v3", "summary": "State-of-the-art neural machine translation methods employ massive amounts of parameters. Drastically reducing computational costs of such methods without affecting performance has been up to this point unsuccessful. To this end, we propose FullyQT: an all-inclusive quantization strategy for the Transformer. To the best of our knowledge, we are the first to show that it is possible to avoid any loss in translation quality with a fully quantized Transformer. Indeed, compared to full-precision, our 8-bit models score greater or equal BLEU on most tasks. Comparing ourselves to all previously proposed methods, we achieve state-of-the-art quantization results.", "published": "2019-10-17T01:29:12Z", "version": 3}, {"aid": "1910.09217", "authors": ["Bingyi Kang", "Saining Xie", "Marcus Rohrbach", "Zhicheng Yan", "Albert Gordo", "Jiashi Feng", "Yannis Kalantidis"], "title": "Decoupling Representation and Classifier for Long-Tailed Recognition", "url": "http://arxiv.org/pdf/1910.09217v2", "summary": "The long-tail distribution of the visual world poses great challenges for deep learning based classification models on how to handle the class imbalance problem. Existing solutions usually involve class-balancing strategies, e.g., by loss re-weighting, data re-sampling, or transfer learning from head- to tail-classes, but most of them adhere to the scheme of jointly learning representations and classifiers. In this work, we decouple the learning procedure into representation learning and classification, and systematically explore how different balancing strategies affect them for long-tailed recognition. The findings are surprising: (1) data imbalance might not be an issue in learning high-quality representations; (2) with representations learned with the simplest instance-balanced (natural) sampling, it is also possible to achieve strong long-tailed recognition ability by adjusting only the classifier. We conduct extensive experiments and set new state-of-the-art performance on common long-tailed benchmarks like ImageNet-LT, Places-LT and iNaturalist, showing that it is possible to outperform carefully designed losses, sampling strategies, even complex modules with memory, by using a straightforward approach that decouples representation and classification. Our code is available at https://github.com/facebookresearch/classifier-balancing.", "published": "2019-10-21T09:03:19Z", "version": 2}, {"aid": "1910.10232", "authors": ["Luckeciano C. Melo", "Marcos R. O. A. Maximo", "Adilson Marques da Cunha"], "title": "Bottom-Up Meta-Policy Search", "url": "http://arxiv.org/pdf/1910.10232v2", "summary": "Despite of the recent progress in agents that learn through interaction, there are several challenges in terms of sample efficiency and generalization across unseen behaviors during training. To mitigate these problems, we propose and apply a first-order Meta-Learning algorithm called Bottom-Up Meta-Policy Search (BUMPS), which works with two-phase optimization procedure: firstly, in a meta-training phase, it distills few expert policies to create a meta-policy capable of generalizing knowledge to unseen tasks during training; secondly, it applies a fast adaptation strategy named Policy Filtering, which evaluates few policies sampled from the meta-policy distribution and selects which best solves the task. We conducted all experiments in the RoboCup 3D Soccer Simulation domain, in the context of kick motion learning. We show that, given our experimental setup, BUMPS works in scenarios where simple multi-task Reinforcement Learning does not. Finally, we performed experiments in a way to evaluate each component of the algorithm.", "published": "2019-10-22T21:12:54Z", "version": 2}, {"aid": "1910.10579", "authors": ["Richard J. Preen", "Stewart W. Wilson", "Larry Bull"], "title": "Autoencoding with a Classifier System", "url": "http://arxiv.org/pdf/1910.10579v8", "summary": "Autoencoders are data-specific compression algorithms learned automatically from examples. The predominant approach has been to construct single large global models that cover the domain. However, training and evaluating models of increasing size comes at the price of additional time and computational cost. Conditional computation, sparsity, and model pruning techniques can reduce these costs while maintaining performance. Learning classifier systems (LCS) are a framework for adaptively subdividing input spaces into an ensemble of simpler local approximations that together cover the domain. LCS perform conditional computation through the use of a population of individual gating/guarding components, each associated with a local approximation. This article explores the use of an LCS to adaptively decompose the input domain into a collection of small autoencoders where local solutions of different complexity may emerge. In addition to benefits in convergence time and computational cost, it is shown possible to reduce code size as well as the resulting decoder computational cost when compared with the global model equivalent.", "published": "2019-10-23T14:27:29Z", "version": 8}, {"aid": "1910.11853", "authors": ["Bin Sun", "Jun Li", "Ming Shao", "Yun Fu"], "title": "LPRNet: Lightweight Deep Network by Low-rank Pointwise Residual Convolution", "url": "http://arxiv.org/pdf/1910.11853v3", "summary": "Deep learning has become popular in recent years primarily due to the powerful computing device such as GPUs. However, deploying these deep models to end-user devices, smart phones, or embedded systems with limited resources is challenging. To reduce the computation and memory costs, we propose a novel lightweight deep learning module by low-rank pointwise residual (LPR) convolution, called LPRNet. Essentially, LPR aims at using low-rank approximation in pointwise convolution to further reduce the module size, while keeping depthwise convolutions as the residual module to rectify the LPR module. This is critical when the low-rankness undermines the convolution process. We embody our design by replacing modules of identical input-output dimension in MobileNet and ShuffleNetv2. Experiments on visual recognition tasks including image classification and face alignment on popular benchmarks show that our LPRNet achieves competitive performance but with significant reduction of Flops and memory cost compared to the state-of-the-art deep models focusing on model compression.", "published": "2019-10-25T17:23:05Z", "version": 3}, {"aid": "1910.13931", "authors": ["Priyadarshini Panda", "Aparna Aketi", "Kaushik Roy"], "title": "Towards Scalable, Efficient and Accurate Deep Spiking Neural Networks with Backward Residual Connections, Stochastic Softmax and Hybridization", "url": "http://arxiv.org/pdf/1910.13931v1", "summary": "Spiking Neural Networks (SNNs) may offer an energy-efficient alternative for implementing deep learning applications. In recent years, there have been several proposals focused on supervised (conversion, spike-based gradient descent) and unsupervised (spike timing dependent plasticity) training methods to improve the accuracy of SNNs on large-scale tasks. However, each of these methods suffer from scalability, latency and accuracy limitations. In this paper, we propose novel algorithmic techniques of modifying the SNN configuration with backward residual connections, stochastic softmax and hybrid artificial-and-spiking neuronal activations to improve the learning ability of the training methodologies to yield competitive accuracy, while, yielding large efficiency gains over their artificial counterparts. Note, artificial counterparts refer to conventional deep learning/artificial neural networks. Our techniques apply to VGG/Residual architectures, and are compatible with all forms of training methodologies. Our analysis reveals that the proposed solutions yield near state-of-the-art accuracy with significant energy-efficiency and reduced parameter overhead translating to hardware improvements on complex visual recognition tasks, such as, CIFAR10, Imagenet datatsets.", "published": "2019-10-30T15:31:15Z", "version": 1}, {"aid": "1911.00640", "authors": ["Xiang Zou", "Lie Yao", "Donghua Zhao", "Liang Chen", "Ying Mao"], "title": "The Intrinsic Properties of Brain Based on the Network Structure", "url": "http://arxiv.org/pdf/1911.00640v1", "summary": "Objective: Brain is a fantastic organ that helps creature adapting to the environment. Network is the most essential structure of brain, but the capability of a simple network is still not very clear. In this study, we try to expound some brain functions only by the network property. Methods: Every network can be equivalent to a simplified network, which is expressed by an equation set. The dynamic of the equation set can be described by some basic equations, which is based on the mathematical derivation. Results (1) In a closed network, the stability is based on the excitatory/inhibitory synapse proportion. Spike probabilities in the assembly can meet the solution of a nonlinear equation set. (2) Network activity can spontaneously evolve into a certain distribution under different stimulation, which is closely related to decision making. (3) Short memory can be formed by coupling of network assemblies. Conclusion: The essential property of a network may contribute to some important brain functions.", "published": "2019-11-02T03:47:18Z", "version": 1}, {"aid": "1911.00809", "authors": ["Zhiyuan Li", "Ruosong Wang", "Dingli Yu", "Simon S. Du", "Wei Hu", "Ruslan Salakhutdinov", "Sanjeev Arora"], "title": "Enhanced Convolutional Neural Tangent Kernels", "url": "http://arxiv.org/pdf/1911.00809v1", "summary": "Recent research shows that for training with $\\ell_2$ loss, convolutional neural networks (CNNs) whose width (number of channels in convolutional layers) goes to infinity correspond to regression with respect to the CNN Gaussian Process kernel (CNN-GP) if only the last layer is trained, and correspond to regression with respect to the Convolutional Neural Tangent Kernel (CNTK) if all layers are trained. An exact algorithm to compute CNTK (Arora et al., 2019) yielded the finding that classification accuracy of CNTK on CIFAR-10 is within 6-7% of that of that of the corresponding CNN architecture (best figure being around 78%) which is interesting performance for a fixed kernel. Here we show how to significantly enhance the performance of these kernels using two ideas. (1) Modifying the kernel using a new operation called Local Average Pooling (LAP) which preserves efficient computability of the kernel and inherits the spirit of standard data augmentation using pixel shifts. Earlier papers were unable to incorporate naive data augmentation because of the quadratic training cost of kernel regression. This idea is inspired by Global Average Pooling (GAP), which we show for CNN-GP and CNTK is equivalent to full translation data augmentation. (2) Representing the input image using a pre-processing technique proposed by Coates et al. (2011), which uses a single convolutional layer composed of random image patches. On CIFAR-10, the resulting kernel, CNN-GP with LAP and horizontal flip data augmentation, achieves 89% accuracy, matching the performance of AlexNet (Krizhevsky et al., 2012). Note that this is the best such result we know of for a classifier that is not a trained neural network. Similar improvements are obtained for Fashion-MNIST.", "published": "2019-11-03T02:24:39Z", "version": 1}, {"aid": "1911.01005", "authors": ["Fan Yang", "Zijian Zhang", "Haofan Wang", "Yuening Li", "Xia Hu"], "title": "XDeep: An Interpretation Tool for Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.01005v1", "summary": "XDeep is an open-source Python package developed to interpret deep models for both practitioners and researchers. Overall, XDeep takes a trained deep neural network (DNN) as the input, and generates relevant interpretations as the output with the post-hoc manner. From the functionality perspective, XDeep integrates a wide range of interpretation algorithms from the state-of-the-arts, covering different types of methodologies, and is capable of providing both local explanation and global explanation for DNN when interpreting model behaviours. With the well-documented API designed in XDeep, end-users can easily obtain the interpretations for their deep models at hand with several lines of codes, and compare the results among different algorithms. XDeep is generally compatible with Python 3, and can be installed through Python Package Index (PyPI). The source codes are available at: https://github.com/datamllab/xdeep.", "published": "2019-11-04T01:59:41Z", "version": 1}, {"aid": "1911.01028", "authors": ["Dibakar Gope", "Jesse Beu", "Urmish Thakker", "Matthew Mattina"], "title": "Ternary MobileNets via Per-Layer Hybrid Filter Banks", "url": "http://arxiv.org/pdf/1911.01028v1", "summary": "MobileNets family of computer vision neural networks have fueled tremendous progress in the design and organization of resource-efficient architectures in recent years. New applications with stringent real-time requirements on highly constrained devices require further compression of MobileNets-like already compute-efficient networks. Model quantization is a widely used technique to compress and accelerate neural network inference and prior works have quantized MobileNets to 4-6 bits albeit with a modest to significant drop in accuracy. While quantization to sub-byte values (i.e. precision less than or equal to 8 bits) has been valuable, even further quantization of MobileNets to binary or ternary values is necessary to realize significant energy savings and possibly runtime speedups on specialized hardware, such as ASICs and FPGAs. Under the key observation that convolutional filters at each layer of a deep neural network may respond differently to ternary quantization, we propose a novel quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets. The layer-wise hybrid filter banks essentially combine the strengths of full-precision and ternary weight filters to derive a compact, energy-efficient architecture for MobileNets. Using this proposed quantization method, we quantized a substantial portion of weight filters of MobileNets to ternary values resulting in 27.98% savings in energy, and a 51.07% reduction in the model size, while achieving comparable accuracy and no degradation in throughput on specialized hardware in comparison to the baseline full-precision MobileNets.", "published": "2019-11-04T04:32:59Z", "version": 1}, {"aid": "1911.02362", "authors": ["Adam Safron"], "title": "Bayesian Analogical Cybernetics", "url": "http://arxiv.org/pdf/1911.02362v2", "summary": "It has been argued that all of cognition can be understood in terms of Bayesian inference. It has also been argued that analogy is the core of cognition. Here I will propose that these perspectives are fully compatible, in that analogical reasoning can be described in terms of Bayesian inference and vice versa, and that both of these positions require a thorough cybernetic grounding in order to fulfill their promise as unifying frameworks for understanding minds. From the Bayesian perspective of the Free Energy Principle and Active Inference framework, thought is constituted by dynamics of cascading belief propagation through the nodes of probabilistic generative models specified by a cortical heterarchy \"rooted\" in action-perception cycles that ground the mind as an embodied control system for an autonomous agent. From the analogical structure mapping perspective, thought is constituted by the alignment and comparison of heterogeneous structural representations. Here I will propose that this core cognitive process for analogical reasoning is naturally implemented by predictive coding mechanisms. However, both Bayesian cognitive science and models of cognitive development via analogical reasoning require rich base domains and priors (or reliably learnable posteriors) from which they can commence the process of bootstrapping minds. Here in the spirit of the work of George Lakoff and Mark Johnson, I propose that embodiment provides many of the inductive biases that are usually described in terms of innate core knowledge. (Please note: this manuscript was written and finalized in 2012.)", "published": "2019-11-04T06:17:55Z", "version": 2}, {"aid": "1911.01058", "authors": ["Sheng Shi", "Xinfeng Zhang", "Wei Fan"], "title": "Explaining the Predictions of Any Image Classifier via Decision Trees", "url": "http://arxiv.org/pdf/1911.01058v2", "summary": "Despite outstanding contribution to the significant progress of Artificial Intelligence (AI), deep learning models remain mostly black boxes, which are extremely weak in explainability of the reasoning process and prediction results. Explainability is not only a gateway between AI and society but also a powerful tool to detect flaws in the model and biases in the data. Local Interpretable Model-agnostic Explanation (LIME) is a recent approach that uses an interpretable model to form a local explanation for the individual prediction result. The current implementation of LIME adopts the linear regression as its interpretable function. However, being so restricted and usually over-simplifying the relationships, linear models fail in situations where nonlinear associations and interactions exist among features and prediction results. This paper implements a decision Tree-based LIME approach, which uses a decision tree model to form an interpretable representation that is locally faithful to the original model. Tree-LIME approach can capture nonlinear interactions among features in the data and creates plausible explanations. Various experiments show that the Tree-LIME explanation of multiple black-box models can achieve more reliable performance in terms of understandability, fidelity, and efficiency.", "published": "2019-11-04T07:31:30Z", "version": 2}, {"aid": "1911.04338", "authors": ["Xue Jiang", "Xiao Zhang", "Dongrui Wu"], "title": "Active Learning for Black-Box Adversarial Attacks in EEG-Based Brain-Computer Interfaces", "url": "http://arxiv.org/pdf/1911.04338v1", "summary": "Deep learning has made significant breakthroughs in many fields, including electroencephalogram (EEG) based brain-computer interfaces (BCIs). However, deep learning models are vulnerable to adversarial attacks, in which deliberately designed small perturbations are added to the benign input samples to fool the deep learning model and degrade its performance. This paper considers transferability-based black-box attacks, where the attacker trains a substitute model to approximate the target model, and then generates adversarial examples from the substitute model to attack the target model. Learning a good substitute model is critical to the success of these attacks, but it requires a large number of queries to the target model. We propose a novel framework which uses query synthesis based active learning to improve the query efficiency in training the substitute model. Experiments on three convolutional neural network (CNN) classifiers and three EEG datasets demonstrated that our method can improve the attack success rate with the same number of queries, or, in other words, our method requires fewer queries to achieve a desired attack performance. To our knowledge, this is the first work that integrates active learning and adversarial attacks for EEG-based BCIs.", "published": "2019-11-07T15:00:24Z", "version": 1}, {"aid": "1911.04255", "authors": ["Abhiram Singh", "Ashwin Gumaste"], "title": "Decoding Imagined Speech and Computer Control using Brain Waves", "url": "http://arxiv.org/pdf/1911.04255v4", "summary": "In this work, we explore the possibility of decoding Imagined Speech brain waves using machine learning techniques. We propose a covariance matrix of Electroencephalogram channels as input features, projection to tangent space of covariance matrices for obtaining vectors from covariance matrices, principal component analysis for dimension reduction of vectors, an artificial feed-forward neural network as a classification model and bootstrap aggregation for creating an ensemble of neural network models. After the classification, two different Finite State Machines are designed that create an interface for controlling a computer system using an Imagined Speech-based BCI system. The proposed approach is able to decode the Imagined Speech signal with a maximum mean classification accuracy of 85% on binary classification task of one long word and a short word. We also show that our proposed approach is able to differentiate between imagined speech brain signals and rest state brain signals with maximum mean classification accuracy of 94%. We compared our proposed method with other approaches for decoding imagined speech and show that our approach performs equivalent to the state of the art approach on decoding long vs. short words and outperforms it significantly on the other two tasks of decoding three short words and three vowels with an average margin of 11% and 9%, respectively. We also obtain an information transfer rate of 21-bits-per-minute when using an IS based system to operate a computer. These results show that the proposed approach is able to decode a wide variety of imagined speech signals without any human-designed features.", "published": "2019-11-08T12:18:36Z", "version": 4}, {"aid": "1911.03584", "authors": ["Jean-Baptiste Cordonnier", "Andreas Loukas", "Martin Jaggi"], "title": "On the Relationship between Self-Attention and Convolutional Layers", "url": "http://arxiv.org/pdf/1911.03584v2", "summary": "Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional layers as a primary building block. Beyond helping CNNs to handle long-range dependencies, Ramachandran et al. (2019) showed that attention can completely replace convolution and achieve state-of-the-art performance on vision tasks. This raises the question: do learned attention layers operate similarly to convolutional layers? This work provides evidence that attention layers can perform convolution and, indeed, they often learn to do so in practice. Specifically, we prove that a multi-head self-attention layer with sufficient number of heads is at least as expressive as any convolutional layer. Our numerical experiments then show that self-attention layers attend to pixel-grid patterns similarly to CNN layers, corroborating our analysis. Our code is publicly available.", "published": "2019-11-08T23:48:38Z", "version": 2}, {"aid": "1911.03599", "authors": ["Yuanyuan Xu", "Wan Yan", "Haixin Sun", "Genke Yang", "Jiliang Luo"], "title": "CenterFace: Joint Face Detection and Alignment Using Face as Point", "url": "http://arxiv.org/pdf/1911.03599v1", "summary": "Face detection and alignment in unconstrained environment is always deployed on edge devices which have limited memory storage and low computing power. This paper proposes a one-stage method named CenterFace to simultaneously predict facial box and landmark location with real-time speed and high accuracy. The proposed method also belongs to the anchor free category. This is achieved by: (a) learning face existing possibility by the semantic maps, (b) learning bounding box, offsets and five landmarks for each position that potentially contains a face. Specifically, the method can run in real-time on a single CPU core and 200 FPS using NVIDIA 2080TI for VGA-resolution images, and can simultaneously achieve superior accuracy (WIDER FACE Val/Test-Easy: 0.935/0.932, Medium: 0.924/0.921, Hard: 0.875/0.873 and FDDB discontinuous: 0.980, continuous: 0.732). A demo of CenterFace can be available at https://github.com/Star-Clouds/CenterFace.", "published": "2019-11-09T03:06:11Z", "version": 1}, {"aid": "1911.05701", "authors": ["Junyi Shen", "Hankz Hankui Zhuo", "Jin Xu", "Bin Zhong", "Sinno Jialin Pan"], "title": "Transfer Value Iteration Networks", "url": "http://arxiv.org/pdf/1911.05701v2", "summary": "Value iteration networks (VINs) have been demonstrated to have a good generalization ability for reinforcement learning tasks across similar domains. However, based on our experiments, a policy learned by VINs still fail to generalize well on the domain whose action space and feature space are not identical to those in the domain where it is trained. In this paper, we propose a transfer learning approach on top of VINs, termed Transfer VINs (TVINs), such that a learned policy from a source domain can be generalized to a target domain with only limited training data, even if the source domain and the target domain have domain-specific actions and features. We empirically verify that our proposed TVINs outperform VINs when the source and the target domains have similar but not identical action and feature spaces. Furthermore, we show that the performance improvement is consistent across different environments, maze sizes, dataset sizes as well as different values of hyperparameters such as number of iteration and kernel size.", "published": "2019-11-11T08:07:49Z", "version": 2}, {"aid": "1911.07925", "authors": ["Tianfu Li", "Zhibin Zhao", "Chuang Sun", "Li Cheng", "Xuefeng Chen", "Ruqiang Yan", "Robert X. Gao"], "title": "WaveletKernelNet: An Interpretable Deep Neural Network for Industrial Intelligent Diagnosis", "url": "http://arxiv.org/pdf/1911.07925v3", "summary": "Convolutional neural network (CNN), with ability of feature learning and nonlinear mapping, has demonstrated its effectiveness in prognostics and health management (PHM). However, explanation on the physical meaning of a CNN architecture has rarely been studied. In this paper, a novel wavelet driven deep neural network termed as WaveletKernelNet (WKN) is presented, where a continuous wavelet convolutional (CWConv) layer is designed to replace the first convolutional layer of the standard CNN. This enables the first CWConv layer to discover more meaningful filters. Furthermore, only the scale parameter and translation parameter are directly learned from raw data at this CWConv layer. This provides a very effective way to obtain a customized filter bank, specifically tuned for extracting defect-related impact component embedded in the vibration signal. In addition, three experimental verification using data from laboratory environment are carried out to verify effectiveness of the proposed method for mechanical fault diagnosis. The results show the importance of the designed CWConv layer and the output of CWConv layer is interpretable. Besides, it is found that WKN has fewer parameters, higher fault classification accuracy and faster convergence speed than standard CNN.", "published": "2019-11-12T07:22:56Z", "version": 3}, {"aid": "1911.05031", "authors": ["Maxwell A. Bertolero", "Danielle S. Bassett"], "title": "On the nature of explanations offered by network science: A perspective from and for practicing neuroscientists", "url": "http://arxiv.org/pdf/1911.05031v1", "summary": "Network neuroscience represents the brain as a collection of regions and inter-regional connections. Given its ability to formalize systems-level models, network neuroscience has generated unique explanations of neural function and behavior. The mechanistic status of these explanations and how they can contribute to and fit within the field of neuroscience as a whole has received careful treatment from philosophers. However, these philosophical contributions have not yet reached many neuroscientists. Here we complement formal philosophical efforts by providing an applied perspective from and for neuroscientists. We discuss the mechanistic status of the explanations offered by network neuroscience and how they contribute to, enhance, and interdigitate with other types of explanations in neuroscience. In doing so, we rely on philosophical work concerning the role of causality, scale, and mechanisms in scientific explanations. In particular, we make the distinction between an explanation and the evidence supporting that explanation, and we argue for a scale-free nature of mechanistic explanations. In the course of these discussions, we hope to provide a useful applied framework in which network neuroscience explanations can be exercised across scales and combined with other fields of neuroscience to gain deeper insights into the brain and behavior.", "published": "2019-11-12T17:49:10Z", "version": 1}, {"aid": "1911.05063", "authors": ["Krishna Murthy Jatavallabhula", "Edward Smith", "Jean-Francois Lafleche", "Clement Fuji Tsang", "Artem Rozantsev", "Wenzheng Chen", "Tommy Xiang", "Rev Lebaredian", "Sanja Fidler"], "title": "Kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research", "url": "http://arxiv.org/pdf/1911.05063v2", "summary": "We present Kaolin, a PyTorch library aiming to accelerate 3D deep learning research. Kaolin provides efficient implementations of differentiable 3D modules for use in deep learning systems. With functionality to load and preprocess several popular 3D datasets, and native functions to manipulate meshes, pointclouds, signed distance functions, and voxel grids, Kaolin mitigates the need to write wasteful boilerplate code. Kaolin packages together several differentiable graphics modules including rendering, lighting, shading, and view warping. Kaolin also supports an array of loss functions and evaluation metrics for seamless evaluation and provides visualization functionality to render the 3D results. Importantly, we curate a comprehensive model zoo comprising many state-of-the-art 3D deep learning architectures, to serve as a starting point for future research endeavours. Kaolin is available as open-source software at https://github.com/NVIDIAGameWorks/kaolin/.", "published": "2019-11-12T18:47:37Z", "version": 2}, {"aid": "1911.05856", "authors": ["Shunwang Gong", "Lei Chen", "Michael Bronstein", "Stefanos Zafeiriou"], "title": "SpiralNet++: A Fast and Highly Efficient Mesh Convolution Operator", "url": "http://arxiv.org/pdf/1911.05856v1", "summary": "Intrinsic graph convolution operators with differentiable kernel functions play a crucial role in analyzing 3D shape meshes. In this paper, we present a fast and efficient intrinsic mesh convolution operator that does not rely on the intricate design of kernel function. We explicitly formulate the order of aggregating neighboring vertices, instead of learning weights between nodes, and then a fully connected layer follows to fuse local geometric structure information with vertex features. We provide extensive evidence showing that models based on this convolution operator are easier to train, and can efficiently learn invariant shape features. Specifically, we evaluate our method on three different types of tasks of dense shape correspondence, 3D facial expression classification, and 3D shape reconstruction, and show that it significantly outperforms state-of-the-art approaches while being significantly faster, without relying on shape descriptors. Our source code is available on GitHub.", "published": "2019-11-13T22:59:19Z", "version": 1}, {"aid": "1911.05943", "authors": ["Shashwat Shukla", "Hideaki Shimazaki", "Udayan Ganguly"], "title": "Structured Mean-field Variational Inference and Learning in Winner-take-all Spiking Neural Networks", "url": "http://arxiv.org/pdf/1911.05943v1", "summary": "The Bayesian view of the brain hypothesizes that the brain constructs a generative model of the world, and uses it to make inferences via Bayes' rule. Although many types of approximate inference schemes have been proposed for hierarchical Bayesian models of the brain, the questions of how these distinct inference procedures can be realized by hierarchical networks of spiking neurons remains largely unresolved. Based on a previously proposed multi-compartment neuron model in which dendrites perform logarithmic compression, and stochastic spiking winner-take-all (WTA) circuits in which firing probability of each neuron is normalized by activities of other neurons, here we construct Spiking Neural Networks that perform \\emph{structured} mean-field variational inference and learning, on hierarchical directed probabilistic graphical models with discrete random variables. In these models, we do away with symmetric synaptic weights previously assumed for \\emph{unstructured} mean-field variational inference by learning both the feedback and feedforward weights separately. The resulting online learning rules take the form of an error-modulated local Spike-Timing-Dependent Plasticity rule. Importantly, we consider two types of WTA circuits in which only one neuron is allowed to fire at a time (hard WTA) or neurons can fire independently (soft WTA), which makes neurons in these circuits operate in regimes of temporal and rate coding respectively. We show how the hard WTA circuits can be used to perform Gibbs sampling whereas the soft WTA circuits can be used to implement a message passing algorithm that computes the marginals approximately. Notably, a simple change in the amount of lateral inhibition realizes switching between the hard and soft WTA spiking regimes. Hence the proposed network provides a unified view of the two previously disparate modes of inference and coding by spiking neurons.", "published": "2019-11-14T05:31:11Z", "version": 1}, {"aid": "1911.06276", "authors": ["Federico Bertoni", "Giovanna Citti", "Alessandro Sarti"], "title": "LGN-CNN: a biologically inspired CNN architecture", "url": "http://arxiv.org/pdf/1911.06276v3", "summary": "In this paper we introduce a biologically inspired Convolutional Neural Network (CNN) architecture called LGN-CNN that has a first convolutional layer composed by a single filter that mimics the role of the Lateral Geniculate Nucleus (LGN). The first layer of the neural network shows a rotational symmetric pattern justified by the structure of the net itself that turns up to be an approximation of a Laplacian of Gaussian (LoG). The latter function is in turn a good approximation of the receptive field profiles (RFPs) of the cells in the LGN. The analogy with the visual system is established, emerging directly from the architecture of the neural network. A proof of rotation invariance of the first layer is given on a fixed LGN-CNN architecture and the computational results are shown. Thus, contrast invariance capability of the LGN-CNN is investigated and a comparison between the Retinex effects of the first layer of LGN-CNN and the Retinex effects of a LoG is provided on different images. A statistical study is done on the filters of the second convolutional layer with respect to biological data. In conclusion, the model we have introduced approximates well the RFPs of both LGN and V1 attaining similar behavior as regards long range connections of LGN cells that show Retinex effects.", "published": "2019-11-14T18:00:14Z", "version": 3}, {"aid": "1911.06602", "authors": ["Toby B. St Clere Smithe"], "title": "Radically Compositional Cognitive Concepts", "url": "http://arxiv.org/pdf/1911.06602v1", "summary": "Despite ample evidence that our concepts, our cognitive architecture, and mathematics itself are all deeply compositional, few models take advantage of this structure. We therefore propose a radically compositional approach to computational neuroscience, drawing on the methods of applied category theory. We describe how these tools grant us a means to overcome complexity and improve interpretability, and supply a rigorous common language for scientific modelling, analogous to the type theories of computer science. As a case study, we sketch how to translate from compositional narrative concepts to neural circuits and back again.", "published": "2019-11-14T18:20:36Z", "version": 1}, {"aid": "1911.08583", "authors": ["Jahan N. Schad"], "title": "Mirror Neuron; A Beautiful Unnecessary Concept", "url": "http://arxiv.org/pdf/1911.08583v1", "summary": "The mirror neuron theory that has enjoyed continued validations was developed with no particular attention to the phenomenon of the vision. Understandably the perception of vision has always been thought to happen, naturally, as that for any of the other four senses. However, the reality that underlies this presumption is by no means obvious; vision perception is based on remote sensing of the ecology, fundamentally different form that of the other senses, which have tactile stimulation origin (contact with matter). While its reality, as explicated here, explains why the above presumption is true, it also bears heavily on the mirror neuron theory: the revelation of the nature of vision makes mirror neurons unnecessary. The extensive cognitive neurosciences investigation of primates and humans, over the past three decades, have experimentally validated the theory of mirror neurons which had been put forward early in the period (1980s and 1990s) based on the results of cognitive research experiments on the macaque monkeys. Based on further experimental works, phenomena such as learning, empathy, and some aspects of survival, are ascribed to the operations of this class of additional neurons. Here I reason that all the results of the efforts of the proponents of the theory can, not only find explanation in the context of the new theory of vision but also provide support for it. This new take of the phenomenon of vision is developed based on the nature of the experimental methods that have succeeded in developing some measure of vision for the blinds, and the inferences from the very likely nature of the computational strategy of the brain. I present evidence that the mental phenomena, which rendered the claim of the mirror neurons, are in essence the results of subjects beings variably touched by their ecology, through the coherent tactile operation of all senses.", "published": "2019-11-14T18:48:44Z", "version": 1}, {"aid": "1911.06396", "authors": ["V\u00edtor Albiero", "Kevin W. Bowyer", "Kushal Vangara", "Michael C. King"], "title": "Does Face Recognition Accuracy Get Better With Age? Deep Face Matchers Say No", "url": "http://arxiv.org/pdf/1911.06396v1", "summary": "Previous studies generally agree that face recognition accuracy is higher for older persons than for younger persons. But most previous studies were before the wave of deep learning matchers, and most considered accuracy only in terms of the verification rate for genuine pairs. This paper investigates accuracy for age groups 16-29, 30-49 and 50-70, using three modern deep CNN matchers, and considers differences in the impostor and genuine distributions as well as verification rates and ROC curves. We find that accuracy is lower for older persons and higher for younger persons. In contrast, a pre deep learning matcher on the same dataset shows the traditional result of higher accuracy for older persons, although its overall accuracy is much lower than that of the deep learning matchers. Comparing the impostor and genuine distributions, we conclude that impostor scores have a larger effect than genuine scores in causing lower accuracy for the older age group. We also investigate the effects of training data across the age groups. Our results show that fine-tuning the deep CNN models on additional images of older persons actually lowers accuracy for the older age group. Also, we fine-tune and train from scratch two models using age-balanced training datasets, and these results also show lower accuracy for older age group. These results argue that the lower accuracy for the older age group is not due to imbalance in the original training data.", "published": "2019-11-14T21:52:54Z", "version": 1}, {"aid": "1911.08585", "authors": ["Thomas Mesnard", "Gaetan Vignoud", "Joao Sacramento", "Walter Senn", "Yoshua Bengio"], "title": "Ghost Units Yield Biologically Plausible Backprop in Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.08585v1", "summary": "In the past few years, deep learning has transformed artificial intelligence research and led to impressive performance in various difficult tasks. However, it is still unclear how the brain can perform credit assignment across many areas as efficiently as backpropagation does in deep neural networks. In this paper, we introduce a model that relies on a new role for a neuronal inhibitory machinery, referred to as ghost units. By cancelling the feedback coming from the upper layer when no target signal is provided to the top layer, the ghost units enables the network to backpropagate errors and do efficient credit assignment in deep structures. While considering one-compartment neurons and requiring very few biological assumptions, it is able to approximate the error gradient and achieve good performance on classification tasks. Error backpropagation occurs through the recurrent dynamics of the network and thanks to biologically plausible local learning rules. In particular, it does not require separate feedforward and feedback circuits. Different mechanisms for cancelling the feedback were studied, ranging from complete duplication of the connectivity by long term processes to online replication of the feedback activity. This reduced system combines the essential elements to have a working biologically abstracted analogue of backpropagation with a simple formulation and proofs of the associated results. Therefore, this model is a step towards understanding how learning and memory are implemented in cortical multilayer structures, but it also raises interesting perspectives for neuromorphic hardware.", "published": "2019-11-15T17:47:00Z", "version": 1}, {"aid": "1911.06786", "authors": ["Akshay Kulkarni", "Navid Panchi", "Sharath Chandra Raparthy", "Shital Chiddarwar"], "title": "Data Efficient Stagewise Knowledge Distillation", "url": "http://arxiv.org/pdf/1911.06786v3", "summary": "Despite the success of Deep Learning (DL), the deployment of modern DL models requiring large computational power poses a significant problem for resource-constrained systems. This necessitates building compact networks that reduce computations while preserving performance. Traditional Knowledge Distillation (KD) methods that transfer knowledge from teacher to student (a) use a single-stage and (b) require the whole data set while distilling the knowledge to the student. In this work, we propose a new method called Stagewise Knowledge Distillation (SKD) which builds on traditional KD methods by progressive stagewise training to leverage the knowledge gained from the teacher, resulting in data-efficient distillation process. We evaluate our method on classification and semantic segmentation tasks. We show, across the tested tasks, significant performance gains even with a fraction of the data used in distillation, without compromising on the metric. We also compare our method with existing KD techniques and show that SKD outperforms them. Moreover, our method can be viewed as a generalized model compression technique that complements other model compression methods such as quantization or pruning.", "published": "2019-11-15T18:06:26Z", "version": 3}, {"aid": "1911.07072", "authors": ["Xuefei Cao", "Bor-Chun Chen", "Ser-Nam Lim"], "title": "Unsupervised Deep Metric Learning via Auxiliary Rotation Loss", "url": "http://arxiv.org/pdf/1911.07072v1", "summary": "Deep metric learning is an important area due to its applicability to many domains such as image retrieval and person re-identification. The main drawback of such models is the necessity for labeled data. In this work, we propose to generate pseudo-labels for deep metric learning directly from clustering assignment and we introduce unsupervised deep metric learning (UDML) regularized by a self-supervision (SS) task. In particular, we propose to regularize the training process by predicting image rotations. Our method (UDML-SS) jointly learns discriminative embeddings, unsupervised clustering assignments of the embeddings, as well as a self-supervised pretext task. UDML-SS iteratively cluster embeddings using traditional clustering algorithm (e.g., k-means), and sampling training pairs based on the cluster assignment for metric learning, while optimizing self-supervised pretext task in a multi-task fashion. The role of self-supervision is to stabilize the training process and encourages the model to learn meaningful feature representations that are not distorted due to unreliable clustering assignments. The proposed method performs well on standard benchmarks for metric learning, where it outperforms current state-of-the-art approaches by a large margin and it also shows competitive performance with various metric learning loss functions.", "published": "2019-11-16T18:28:45Z", "version": 1}, {"aid": "1911.07086", "authors": ["Saeid Asgari Taghanaki", "Kumar Abhishek", "Ghassan Hamarneh"], "title": "Signed Input Regularization", "url": "http://arxiv.org/pdf/1911.07086v3", "summary": "Over-parameterized deep models usually over-fit to a given training distribution, which makes them sensitive to small changes and out-of-distribution samples at inference time, leading to low generalization performance. To this end, several model-based and randomized data-dependent regularization methods are applied, such as data augmentation, which prevents a model from memorizing the training distribution. Instead of the random transformation of the input images, we propose SIGN, a new regularization method, which modifies the input variables using a linear transformation by estimating each variable's contribution to the final prediction. Our proposed technique maps the input data to a new manifold where the less important variables are de-emphasized. To test the effectiveness of the proposed idea and compare it with other competing methods, we design several test scenarios, such as classification performance, uncertainty, out-of-distribution, and robustness analyses. We compare the methods using three different datasets and four models. We find that SIGN encourages more compact class representations, which results in the model's robustness to random corruptions and out-of-distribution samples while also simultaneously achieving superior performance on normal data compared to other competing methods. Our experiments also demonstrate the successful transferability of the SIGN samples from one model to another.", "published": "2019-11-16T19:56:43Z", "version": 3}, {"aid": "1911.07346", "authors": ["Haichao Yu", "Haoxiang Li", "Honghui Shi", "Thomas S. Huang", "Gang Hua"], "title": "Any-Precision Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.07346v2", "summary": "We present any-precision deep neural networks (DNNs), which are trained with a new method that allows the learned DNNs to be flexible in numerical precision during inference. The same model in runtime can be flexibly and directly set to different bit-widths, by truncating the least significant bits, to support dynamic speed and accuracy trade-off. When all layers are set to low-bits, we show that the model achieved accuracy comparable to dedicated models trained at the same precision. This nice property facilitates flexible deployment of deep learning models in real-world applications, where in practice trade-offs between model accuracy and runtime efficiency are often sought. Previous literature presents solutions to train models at each individual fixed efficiency/accuracy trade-off point. But how to produce a model flexible in runtime precision is largely unexplored. When the demand of efficiency/accuracy trade-off varies from time to time or even dynamically changes in runtime, it is infeasible to re-train models accordingly, and the storage budget may forbid keeping multiple models. Our proposed framework achieves this flexibility without performance degradation. More importantly, we demonstrate that this achievement is agnostic to model architectures and applicable to multiple vision tasks. Our code is released at https://github.com/SHI-Labs/Any-Precision-DNNs.", "published": "2019-11-17T21:35:32Z", "version": 2}, {"aid": "1911.07381", "authors": ["Meng Zheng", "Srikrishna Karanam", "Terrence Chen", "Richard J. Radke", "Ziyan Wu"], "title": "Visual Similarity Attention", "url": "http://arxiv.org/pdf/1911.07381v2", "summary": "While there has been substantial progress in learning suitable distance metrics, these techniques in general lack transparency and decision reasoning, i.e., explaining why the input set of images is similar or dissimilar. In this work, we solve this key problem by proposing the first method to generate generic visual similarity explanations with gradient-based attention. We demonstrate that our technique is agnostic to the specific similarity model type, e.g., we show applicability to Siamese, triplet, and quadruplet models. Furthermore, we make our proposed similarity attention a principled part of the learning process, resulting in a new paradigm for learning similarity functions. We demonstrate that our learning mechanism results in more generalizable, as well as explainable, similarity models. Finally, we demonstrate the generality of our framework by means of experiments on a variety of tasks, including image retrieval, person re-identification, and low-shot semantic segmentation.", "published": "2019-11-18T00:46:40Z", "version": 2}, {"aid": "1911.07532", "authors": ["Michael Poli", "Stefano Massaroli", "Junyoung Park", "Atsushi Yamashita", "Hajime Asama", "Jinkyoo Park"], "title": "Graph Neural Ordinary Differential Equations", "url": "http://arxiv.org/pdf/1911.07532v4", "summary": "We introduce the framework of continuous--depth graph neural networks (GNNs). Graph neural ordinary differential equations (GDEs) are formalized as the counterpart to GNNs where the input-output relationship is determined by a continuum of GNN layers, blending discrete topological structures and differential equations. The proposed framework is shown to be compatible with various static and autoregressive GNN models. Results prove general effectiveness of GDEs: in static settings they offer computational advantages by incorporating numerical methods in their forward pass; in dynamic settings, on the other hand, they are shown to improve performance by exploiting the geometry of the underlying dynamics.", "published": "2019-11-18T10:46:15Z", "version": 4}, {"aid": "1911.07956", "authors": ["Xiaoxia Wu", "Edgar Dobriban", "Tongzheng Ren", "Shanshan Wu", "Zhiyuan Li", "Suriya Gunasekar", "Rachel Ward", "Qiang Liu"], "title": "Implicit Regularization and Convergence for Weight Normalization", "url": "http://arxiv.org/pdf/1911.07956v5", "summary": "Normalization methods such as batch [Ioffe and Szegedy, 2015], weight [Salimansand Kingma, 2016], instance [Ulyanov et al., 2016], and layer normalization [Baet al., 2016] have been widely used in modern machine learning. Here, we study the weight normalization (WN) method [Salimans and Kingma, 2016] and a variant called reparametrized projected gradient descent (rPGD) for overparametrized least-squares regression. WN and rPGD reparametrize the weights with a scale g and a unit vector w and thus the objective function becomes non-convex. We show that this non-convex formulation has beneficial regularization effects compared to gradient descent on the original objective. These methods adaptively regularize the weights and converge close to the minimum l2 norm solution, even for initializations far from zero. For certain stepsizes of g and w , we show that they can converge close to the minimum norm solution. This is different from the behavior of gradient descent, which converges to the minimum norm solution only when started at a point in the range space of the feature matrix, and is thus more sensitive to initialization.", "published": "2019-11-18T21:10:21Z", "version": 5}, {"aid": "1911.10979", "authors": ["Yong-Goo Shin", "Yoon-Jae Yeo", "Sung-Jea Ko"], "title": "Simple yet Effective Way for Improving the Performance of GAN", "url": "http://arxiv.org/pdf/1911.10979v4", "summary": "In adversarial learning, discriminator often fails to guide the generator successfully since it distinguishes between real and generated images using silly or non-robust features. To alleviate this problem, this brief presents a simple but effective way that improves the performance of generative adversarial network (GAN) without imposing the training overhead or modifying the network architectures of existing methods. The proposed method employs a novel cascading rejection (CR) module for discriminator, which extracts multiple non-overlapped features in an iterative manner using the vector rejection operation. Since the extracted diverse features prevent the discriminator from concentrating on non-meaningful features, the discriminator can guide the generator effectively to produce the images that are more similar to the real images. In addition, since the proposed CR module requires only a few simple vector operations, it can be readily applied to existing frameworks with marginal training overheads. Quantitative evaluations on various datasets including CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet confirm that the proposed method significantly improves the performance of GAN and conditional GAN in terms of Frechet inception distance (FID) indicating the diversity and visual appearance of the generated images.", "published": "2019-11-19T10:31:19Z", "version": 4}, {"aid": "1911.08265", "authors": ["Julian Schrittwieser", "Ioannis Antonoglou", "Thomas Hubert", "Karen Simonyan", "Laurent Sifre", "Simon Schmitt", "Arthur Guez", "Edward Lockhart", "Demis Hassabis", "Thore Graepel", "Timothy Lillicrap", "David Silver"], "title": "Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model", "url": "http://arxiv.org/pdf/1911.08265v2", "summary": "Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.", "published": "2019-11-19T13:58:52Z", "version": 2}, {"aid": "1911.08509", "authors": ["Dami\u00e1n G. Hern\u00e1ndez", "Samuel J. Sober", "Ilya Nemenman"], "title": "Unsupervised Bayesian Ising Approximation for revealing the neural dictionary in songbirds", "url": "http://arxiv.org/pdf/1911.08509v1", "summary": "The problem of deciphering how low-level patterns (action potentials in the brain, amino acids in a protein, etc.) drive high-level biological features (sensorimotor behavior, enzymatic function) represents the central challenge of quantitative biology. The lack of general methods for doing so from the size of datasets that can be collected experimentally severely limits our understanding of the biological world. For example, in neuroscience, some sensory and motor codes have been shown to consist of precisely timed multi-spike patterns. However, the combinatorial complexity of such pattern codes have precluded development of methods for their comprehensive analysis. Thus, just as it is hard to predict a protein's function based on its sequence, we still do not understand how to accurately predict an organism's behavior based on neural activity. Here we derive a method for solving this class of problems. We demonstrate its utility in an application to neural data, detecting precisely timed spike patterns that code for specific motor behaviors in a songbird vocal system. Our method detects such codewords with an arbitrary number of spikes, does so from small data sets, and accounts for dependencies in occurrences of codewords. Detecting such dictionaries of important spike patterns --- rather than merely identifying the timescale on which such patterns exist, as in some prior approaches --- opens the door for understanding fine motor control and the neural bases of sensorimotor learning in animals. For example, for the first time, we identify differences in encoding motor exploration versus typical behavior. Crucially, our method can be used not only for analysis of neural systems, but also for understanding the structure of correlations in other biological and nonbiological datasets.", "published": "2019-11-19T19:11:49Z", "version": 1}, {"aid": "1911.08691", "authors": ["Xiaolong Hu", "Zhulin An", "Chuanguang Yang", "Hui Zhu", "Kaiqaing Xu", "Yongjun Xu"], "title": "DRNet: Dissect and Reconstruct the Convolutional Neural Network via Interpretable Manners", "url": "http://arxiv.org/pdf/1911.08691v2", "summary": "Convolutional neural networks (ConvNets) are widely used in real life. People usually use ConvNets which pre-trained on a fixed number of classes. However, for different application scenarios, we usually do not need all of the classes, which means ConvNets are redundant when dealing with these tasks. This paper focuses on the redundancy of ConvNet channels. We proposed a novel idea: using an interpretable manner to find the most important channels for every single class (dissect), and dynamically run channels according to classes in need (reconstruct). For VGG16 pre-trained on CIFAR-10, we only run 11\\% parameters for two-classes sub-tasks on average with negligible accuracy loss. For VGG16 pre-trained on ImageNet, our method averagely gains 14.29\\% accuracy promotion for two-classes sub-tasks. In addition, analysis show that our method captures some semantic meanings of channels, and uses the context information more targeted for sub-tasks of ConvNets.", "published": "2019-11-20T03:52:28Z", "version": 2}, {"aid": "1911.08764", "authors": ["Matteo Testa", "Arslan Ali", "Tiziano Bianchi", "Enrico Magli"], "title": "Learning mappings onto regularized latent spaces for biometric authentication", "url": "http://arxiv.org/pdf/1911.08764v1", "summary": "We propose a novel architecture for generic biometric authentication based on deep neural networks: RegNet. Differently from other methods, RegNet learns a mapping of the input biometric traits onto a target distribution in a well-behaved space in which users can be separated by means of simple and tunable boundaries. More specifically, authorized and unauthorized users are mapped onto two different and well behaved Gaussian distributions. The novel approach of learning the mapping instead of the boundaries further avoids the problem encountered in typical classifiers for which the learnt boundaries may be complex and difficult to analyze. RegNet achieves high performance in terms of security metrics such as Equal Error Rate (EER), False Acceptance Rate (FAR) and Genuine Acceptance Rate (GAR). The experiments we conducted on publicly available datasets of face and fingerprint confirm the effectiveness of the proposed system.", "published": "2019-11-20T08:40:44Z", "version": 1}, {"aid": "1911.09071", "authors": ["Katherine L. Hermann", "Ting Chen", "Simon Kornblith"], "title": "The Origins and Prevalence of Texture Bias in Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1911.09071v3", "summary": "Recent work has indicated that, unlike humans, ImageNet-trained CNNs tend to classify images by texture rather than by shape. How pervasive is this bias, and where does it come from? We find that, when trained on datasets of images with conflicting shape and texture, CNNs learn to classify by shape at least as easily as by texture. What factors, then, produce the texture bias in CNNs trained on ImageNet? Different unsupervised training objectives and different architectures have small but significant and largely independent effects on the level of texture bias. However, all objectives and architectures still lead to models that make texture-based classification decisions a majority of the time, even if shape information is decodable from their hidden representations. The effect of data augmentation is much larger. By taking less aggressive random crops at training time and applying simple, naturalistic augmentation (color distortion, noise, and blur), we train models that classify ambiguous images by shape a majority of the time, and outperform baselines on out-of-distribution test sets. Our results indicate that apparent differences in the way humans and ImageNet-trained CNNs process images may arise not primarily from differences in their internal workings, but from differences in the data that they see.", "published": "2019-11-20T18:16:38Z", "version": 3}, {"aid": "1911.09257", "authors": ["Andrew Hryniowski", "Alexander Wong"], "title": "DeepLABNet: End-to-end Learning of Deep Radial Basis Networks with Fully Learnable Basis Functions", "url": "http://arxiv.org/pdf/1911.09257v1", "summary": "From fully connected neural networks to convolutional neural networks, the learned parameters within a neural network have been primarily relegated to the linear parameters (e.g., convolutional filters). The non-linear functions (e.g., activation functions) have largely remained, with few exceptions in recent years, parameter-less, static throughout training, and seen limited variation in design. Largely ignored by the deep learning community, radial basis function (RBF) networks provide an interesting mechanism for learning more complex non-linear activation functions in addition to the linear parameters in a network. However, the interest in RBF networks has waned over time due to the difficulty of integrating RBFs into more complex deep neural network architectures in a tractable and stable manner. In this work, we present a novel approach that enables end-to-end learning of deep RBF networks with fully learnable activation basis functions in an automatic and tractable manner. We demonstrate that our approach for enabling the use of learnable activation basis functions in deep neural networks, which we will refer to as DeepLABNet, is an effective tool for automated activation function learning within complex network architectures.", "published": "2019-11-21T03:06:15Z", "version": 1}, {"aid": "1911.09287", "authors": ["Adam Dziedzic", "John Paparrizos", "Sanjay Krishnan", "Aaron Elmore", "Michael Franklin"], "title": "Band-limited Training and Inference for Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1911.09287v1", "summary": "The convolutional layers are core building blocks of neural network architectures. In general, a convolutional filter applies to the entire frequency spectrum of the input data. We explore artificially constraining the frequency spectra of these filters and data, called band-limiting, during training. The frequency domain constraints apply to both the feed-forward and back-propagation steps. Experimentally, we observe that Convolutional Neural Networks (CNNs) are resilient to this compression scheme and results suggest that CNNs learn to leverage lower-frequency components. In particular, we found: (1) band-limited training can effectively control the resource usage (GPU and memory); (2) models trained with band-limited layers retain high prediction accuracy; and (3) requires no modification to existing training algorithms or neural network architectures to use unlike other compression schemes.", "published": "2019-11-21T04:43:02Z", "version": 1}, {"aid": "1911.09723", "authors": ["Erich Elsen", "Marat Dukhan", "Trevor Gale", "Karen Simonyan"], "title": "Fast Sparse ConvNets", "url": "http://arxiv.org/pdf/1911.09723v1", "summary": "Historically, the pursuit of efficient inference has been one of the driving forces behind research into new deep learning architectures and building blocks. Some recent examples include: the squeeze-and-excitation module, depthwise separable convolutions in Xception, and the inverted bottleneck in MobileNet v2. Notably, in all of these cases, the resulting building blocks enabled not only higher efficiency, but also higher accuracy, and found wide adoption in the field. In this work, we further expand the arsenal of efficient building blocks for neural network architectures; but instead of combining standard primitives (such as convolution), we advocate for the replacement of these dense primitives with their sparse counterparts. While the idea of using sparsity to decrease the parameter count is not new, the conventional wisdom is that this reduction in theoretical FLOPs does not translate into real-world efficiency gains. We aim to correct this misconception by introducing a family of efficient sparse kernels for ARM and WebAssembly, which we open-source for the benefit of the community as part of the XNNPACK library. Equipped with our efficient implementation of sparse primitives, we show that sparse versions of MobileNet v1, MobileNet v2 and EfficientNet architectures substantially outperform strong dense baselines on the efficiency-accuracy curve. On Snapdragon 835 our sparse networks outperform their dense equivalents by $1.3-2.4\\times$ -- equivalent to approximately one entire generation of MobileNet-family improvement. We hope that our findings will facilitate wider adoption of sparsity as a tool for creating efficient and accurate deep learning architectures.", "published": "2019-11-21T19:48:14Z", "version": 1}, {"aid": "1911.09737", "authors": ["Saurabh Singh", "Shankar Krishnan"], "title": "Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks", "url": "http://arxiv.org/pdf/1911.09737v2", "summary": "Batch Normalization (BN) uses mini-batch statistics to normalize the activations during training, introducing dependence between mini-batch elements. This dependency can hurt the performance if the mini-batch size is too small, or if the elements are correlated. Several alternatives, such as Batch Renormalization and Group Normalization (GN), have been proposed to address this issue. However, they either do not match the performance of BN for large batches, or still exhibit degradation in performance for smaller batches, or introduce artificial constraints on the model architecture. In this paper we propose the Filter Response Normalization (FRN) layer, a novel combination of a normalization and an activation function, that can be used as a replacement for other normalizations and activations. Our method operates on each activation channel of each batch element independently, eliminating the dependency on other batch elements. Our method outperforms BN and other alternatives in a variety of settings for all batch sizes. FRN layer performs $\\approx 0.7-1.0\\%$ better than BN on top-1 validation accuracy with large mini-batch sizes for Imagenet classification using InceptionV3 and ResnetV2-50 architectures. Further, it performs $>1\\%$ better than GN on the same problem in the small mini-batch size regime. For object detection problem on COCO dataset, FRN layer outperforms all other methods by at least $0.3-0.5\\%$ in all batch size regimes.", "published": "2019-11-21T20:32:04Z", "version": 2}, {"aid": "1911.09738", "authors": ["Siyuan Qiao", "Huiyu Wang", "Chenxi Liu", "Wei Shen", "Alan Yuille"], "title": "Rethinking Normalization and Elimination Singularity in Neural Networks", "url": "http://arxiv.org/pdf/1911.09738v1", "summary": "In this paper, we study normalization methods for neural networks from the perspective of elimination singularity. Elimination singularities correspond to the points on the training trajectory where neurons become consistently deactivated. They cause degenerate manifolds in the loss landscape which will slow down training and harm model performances. We show that channel-based normalizations (e.g. Layer Normalization and Group Normalization) are unable to guarantee a far distance from elimination singularities, in contrast with Batch Normalization which by design avoids models from getting too close to them. To address this issue, we propose BatchChannel Normalization (BCN), which uses batch knowledge to avoid the elimination singularities in the training of channel-normalized models. Unlike Batch Normalization, BCN is able to run in both large-batch and micro-batch training settings. The effectiveness of BCN is verified on many tasks, including image classification, object detection, instance segmentation, and semantic segmentation. The code is here: https://github.com/joe-siyuan-qiao/Batch-Channel-Normalization.", "published": "2019-11-21T20:36:04Z", "version": 1}, {"aid": "1911.09976", "authors": ["Xinshao Wang", "Elyor Kodirov", "Yang Hua", "Neil Robertson"], "title": "Instance Cross Entropy for Deep Metric Learning", "url": "http://arxiv.org/pdf/1911.09976v1", "summary": "Loss functions play a crucial role in deep metric learning thus a variety of them have been proposed. Some supervise the learning process by pairwise or tripletwise similarity constraints while others take advantage of structured similarity information among multiple data points. In this work, we approach deep metric learning from a novel perspective. We propose instance cross entropy (ICE) which measures the difference between an estimated instance-level matching distribution and its ground-truth one. ICE has three main appealing properties. Firstly, similar to categorical cross entropy (CCE), ICE has clear probabilistic interpretation and exploits structured semantic similarity information for learning supervision. Secondly, ICE is scalable to infinite training data as it learns on mini-batches iteratively and is independent of the training set size. Thirdly, motivated by our relative weight analysis, seamless sample reweighting is incorporated. It rescales samples' gradients to control the differentiation degree over training examples instead of truncating them by sample mining. In addition to its simplicity and intuitiveness, extensive experiments on three real-world benchmarks demonstrate the superiority of ICE.", "published": "2019-11-22T11:12:48Z", "version": 1}, {"aid": "1911.10129", "authors": ["Karthik Gopinath", "Christian Desrosiers", "Herve Lombaert"], "title": "Learnable Pooling in Graph Convolution Networks for Brain Surface Analysis", "url": "http://arxiv.org/pdf/1911.10129v1", "summary": "Brain surface analysis is essential to neuroscience, however, the complex geometry of the brain cortex hinders computational methods for this task. The difficulty arises from a discrepancy between 3D imaging data, which is represented in Euclidean space, and the non-Euclidean geometry of the highly-convoluted brain surface. Recent advances in machine learning have enabled the use of neural networks for non-Euclidean spaces. These facilitate the learning of surface data, yet pooling strategies often remain constrained to a single fixed-graph. This paper proposes a new learnable graph pooling method for processing multiple surface-valued data to output subject-based information. The proposed method innovates by learning an intrinsic aggregation of graph nodes based on graph spectral embedding. We illustrate the advantages of our approach with in-depth experiments on two large-scale benchmark datasets. The flexibility of the pooling strategy is evaluated on four different prediction tasks, namely, subject-sex classification, regression of cortical region sizes, classification of Alzheimer's disease stages, and brain age regression. Our experiments demonstrate the superiority of our learnable pooling approach compared to other pooling techniques for graph convolution networks, with results improving the state-of-the-art in brain surface analysis.", "published": "2019-11-22T16:34:58Z", "version": 1}, {"aid": "1911.10477", "authors": ["Jiancheng Yang", "Xiaoyang Huang", "Yi He", "Jingwei Xu", "Canqian Yang", "Guozheng Xu", "Bingbing Ni"], "title": "Reinventing 2D Convolutions for 3D Images", "url": "http://arxiv.org/pdf/1911.10477v4", "summary": "There have been considerable debates over 2D and 3D representation learning on 3D medical images. 2D approaches could benefit from large-scale 2D pretraining, whereas they are generally weak in capturing large 3D contexts. 3D approaches are natively strong in 3D contexts, however few publicly available 3D medical dataset is large and diverse enough for universal 3D pretraining. Even for hybrid (2D + 3D) approaches, the intrinsic disadvantages within the 2D / 3D parts still exist. In this study, we bridge the gap between 2D and 3D convolutions by reinventing the 2D convolutions. We propose ACS (axial-coronal-sagittal) convolutions to perform natively 3D representation learning, while utilizing the pretrained weights on 2D datasets. In ACS convolutions, 2D convolution kernels are split by channel into three parts, and convoluted separately on the three views (axial, coronal and sagittal) of 3D representations. Theoretically, ANY 2D CNN (ResNet, DenseNet, or DeepLab) is able to be converted into a 3D ACS CNN, with pretrained weight of a same parameter size. Extensive experiments on several medical benchmarks (including classification, segmentation and detection tasks) validate the consistent superiority of the pretrained ACS CNNs, over the 2D / 3D CNN counterparts with / without pretraining. Even without pretraining, the ACS convolution can be used as a plug-and-play replacement of standard 3D convolution, with smaller model size and less computation.", "published": "2019-11-24T09:05:06Z", "version": 4}, {"aid": "1911.10538", "authors": ["Ori Nizan", "Ayellet Tal"], "title": "Breaking the cycle -- Colleagues are all you need", "url": "http://arxiv.org/pdf/1911.10538v2", "summary": "This paper proposes a novel approach to performing image-to-image translation between unpaired domains. Rather than relying on a cycle constraint, our method takes advantage of collaboration between various GANs. This results in a multi-modal method, in which multiple optional and diverse images are produced for a given image. Our model addresses some of the shortcomings of classical GANs: (1) It is able to remove large objects, such as glasses. (2) Since it does not need to support the cycle constraint, no irrelevant traces of the input are left on the generated image. (3) It manages to translate between domains that require large shape modifications. Our results are shown to outperform those generated by state-of-the-art methods for several challenging applications on commonly-used datasets, both qualitatively and quantitatively.", "published": "2019-11-24T14:43:45Z", "version": 2}, {"aid": "1911.10572", "authors": ["Yongzhe Yan", "Stefan Duffner", "Priyanka Phutane", "Anthony Berthelier", "Christophe Blanc", "Christophe Garcia", "Thierry Chateau"], "title": "2D Wasserstein Loss for Robust Facial Landmark Detection", "url": "http://arxiv.org/pdf/1911.10572v2", "summary": "The recent performance of facial landmark detection has been significantly improved by using deep Convolutional Neural Networks (CNNs), especially the Heatmap Regression Models (HRMs). Although their performance on common benchmark datasets has reached a high level, the robustness of these models still remains a challenging problem in the practical use under noisy conditions of realistic environments. Contrary to most existing work focusing on the design of new models, we argue that improving the robustness requires rethinking many other aspects, including the use of datasets, the format of landmark annotation, the evaluation metric as well as the training and detection algorithm itself. In this paper, we propose a novel method for robust facial landmark detection, using a loss function based on the 2D Wasserstein distance combined with a new landmark coordinate sampling relying on the barycenter of the individual probability distributions. Our method can be plugged-and-play on most state-of-the-art HRMs with neither additional complexity nor structural modifications of the models. Further, with the large performance increase, we found that current evaluation metrics can no longer fully reflect the robustness of these models. Therefore, we propose several improvements to the standard evaluation protocol. Extensive experimental results on both traditional evaluation metrics and our evaluation metrics demonstrate that our approach significantly improves the robustness of state-of-the-art facial landmark detection models.", "published": "2019-11-24T16:56:10Z", "version": 2}, {"aid": "1911.11238", "authors": ["Ganesh Sundaramoorthi", "Timothy E. Wang"], "title": "Translation Insensitive CNNs", "url": "http://arxiv.org/pdf/1911.11238v1", "summary": "We address the problem that state-of-the-art Convolution Neural Networks (CNN) classifiers are not invariant to small shifts. The problem can be solved by the removal of sub-sampling operations such as stride and max pooling, but at a cost of severely degraded training and test efficiency. We present a novel usage of Gaussian-Hermite basis to efficiently approximate arbitrary filters within the CNN framework to obtain translation invariance. This is shown to be invariant to small shifts, and preserves the efficiency of training. Further, to improve efficiency in memory usage as well as computational speed, we show that it is still possible to sub-sample with this approach and retain a weaker form of invariance that we call \\emph{translation insensitivity}, which leads to stability with respect to shifts. We prove these claims analytically and empirically. Our analytic methods further provide a framework for understanding any architecture in terms of translation insensitivity, and provide guiding principles for design.", "published": "2019-11-25T21:22:06Z", "version": 1}, {"aid": "1911.11323", "authors": ["Yang Wang", "Yang Cao", "Zheng-Jun Zha", "Jing Zhang", "Zhiwei Xiong", "Wei Zhang", "Feng Wu"], "title": "Progressive Retinex: Mutually Reinforced Illumination-Noise Perception Network for Low Light Image Enhancement", "url": "http://arxiv.org/pdf/1911.11323v1", "summary": "Contrast enhancement and noise removal are coupled problems for low-light image enhancement. The existing Retinex based methods do not take the coupling relation into consideration, resulting in under or over-smoothing of the enhanced images. To address this issue, this paper presents a novel progressive Retinex framework, in which illumination and noise of low-light image are perceived in a mutually reinforced manner, leading to noise reduction low-light enhancement results. Specifically, two fully pointwise convolutional neural networks are devised to model the statistical regularities of ambient light and image noise respectively, and to leverage them as constraints to facilitate the mutual learning process. The proposed method not only suppresses the interference caused by the ambiguity between tiny textures and image noises, but also greatly improves the computational efficiency. Moreover, to solve the problem of insufficient training data, we propose an image synthesis strategy based on camera imaging model, which generates color images corrupted by illumination-dependent noises. Experimental results on both synthetic and real low-light images demonstrate the superiority of our proposed approaches against the State-Of-The-Art (SOTA) low-light enhancement methods.", "published": "2019-11-26T03:56:45Z", "version": 1}, {"aid": "1911.11759", "authors": ["Xiuye Gu", "Weixin Luo", "Michael S. Ryoo", "Yong Jae Lee"], "title": "Password-conditioned Anonymization and Deanonymization with Face Identity Transformers", "url": "http://arxiv.org/pdf/1911.11759v4", "summary": "Cameras are prevalent in our daily lives, and enable many useful systems built upon computer vision technologies such as smart cameras and home robots for service applications. However, there is also an increasing societal concern as the captured images/videos may contain privacy-sensitive information (e.g., face identity). We propose a novel face identity transformer which enables automated photo-realistic password-based anonymization as well as deanonymization of human faces appearing in visual data. Our face identity transformer is trained to (1) remove face identity information after anonymization, (2) make the recovery of the original face possible when given the correct password, and (3) return a wrong--but photo-realistic--face given a wrong password. Extensive experiments show that our approach enables multimodal password-conditioned face anonymizations and deanonymizations, without sacrificing privacy compared to existing anonymization approaches.", "published": "2019-11-26T18:50:53Z", "version": 4}, {"aid": "1911.11800", "authors": ["Hirunima Jayasekara", "Vinoj Jayasundara", "Mohamed Athif", "Jathushan Rajasegaran", "Sandaru Jayasekara", "Suranga Seneviratne", "Ranga Rodrigo"], "title": "TimeCaps: Capturing Time Series Data With Capsule Networks", "url": "http://arxiv.org/pdf/1911.11800v4", "summary": "Capsule networks excel in understanding spatial relationships in 2D data for vision related tasks. Even though they are not designed to capture 1D temporal relationships, with TimeCaps we demonstrate that given the ability, capsule networks excel in understanding temporal relationships. To this end, we generate capsules along the temporal and channel dimensions creating two temporal feature detectors which learn contrasting relationships. TimeCaps surpasses the state-of-the-art results by achieving 96.21% accuracy on identifying 13 Electrocardiogram (ECG) signal beat categories, while achieving on-par results on identifying 30 classes of short audio commands. Further, the instantiation parameters inherently learnt by the capsule networks allow us to completely parameterize 1D signals which opens various possibilities in signal processing.", "published": "2019-11-26T19:28:57Z", "version": 4}, {"aid": "1911.11907", "authors": ["Kai Han", "Yunhe Wang", "Qi Tian", "Jianyuan Guo", "Chunjing Xu", "Chang Xu"], "title": "GhostNet: More Features from Cheap Operations", "url": "http://arxiv.org/pdf/1911.11907v2", "summary": "Deploying convolutional neural networks (CNNs) on embedded devices is difficult due to the limited memory and computation resources. The redundancy in feature maps is an important characteristic of those successful CNNs, but has rarely been investigated in neural architecture design. This paper proposes a novel Ghost module to generate more feature maps from cheap operations. Based on a set of intrinsic feature maps, we apply a series of linear transformations with cheap cost to generate many ghost feature maps that could fully reveal information underlying intrinsic features. The proposed Ghost module can be taken as a plug-and-play component to upgrade existing convolutional neural networks. Ghost bottlenecks are designed to stack Ghost modules, and then the lightweight GhostNet can be easily established. Experiments conducted on benchmarks demonstrate that the proposed Ghost module is an impressive alternative of convolution layers in baseline models, and our GhostNet can achieve higher recognition performance (e.g. $75.7\\%$ top-1 accuracy) than MobileNetV3 with similar computational cost on the ImageNet ILSVRC-2012 classification dataset. Code is available at https://github.com/huawei-noah/ghostnet", "published": "2019-11-27T01:36:42Z", "version": 2}, {"aid": "1911.12110", "authors": ["Xin-Yu Zhang", "Le Zhang", "Zao-Yi Zheng", "Yun Liu", "Jia-Wang Bian", "Ming-Ming Cheng"], "title": "AdaSample: Adaptive Sampling of Hard Positives for Descriptor Learning", "url": "http://arxiv.org/pdf/1911.12110v1", "summary": "Triplet loss has been widely employed in a wide range of computer vision tasks, including local descriptor learning. The effectiveness of the triplet loss heavily relies on the triplet selection, in which a common practice is to first sample intra-class patches (positives) from the dataset for batch construction and then mine in-batch negatives to form triplets. For high-informativeness triplet collection, researchers mostly focus on mining hard negatives in the second stage, while paying relatively less attention to constructing informative batches. To alleviate this issue, we propose AdaSample, an adaptive online batch sampler, in this paper. Specifically, hard positives are sampled based on their informativeness. In this way, we formulate a hardness-aware positive mining pipeline within a novel maximum loss minimization training protocol. The efficacy of the proposed method is evaluated on several standard benchmarks, where it demonstrates a significant and consistent performance gain on top of the existing strong baselines.", "published": "2019-11-27T12:38:08Z", "version": 1}, {"aid": "1911.12116", "authors": ["Vanessa Buhrmester", "David M\u00fcnch", "Michael Arens"], "title": "Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey", "url": "http://arxiv.org/pdf/1911.12116v1", "summary": "Deep Learning is a state-of-the-art technique to make inference on extensive or complex data. As a black box model due to their multilayer nonlinear structure, Deep Neural Networks are often criticized to be non-transparent and their predictions not traceable by humans. Furthermore, the models learn from artificial datasets, often with bias or contaminated discriminating content. Through their increased distribution, decision-making algorithms can contribute promoting prejudge and unfairness which is not easy to notice due to lack of transparency. Hence, scientists developed several so-called explanators or explainers which try to point out the connection between input and output to represent in a simplified way the inner structure of machine learning black boxes. In this survey we differ the mechanisms and properties of explaining systems for Deep Neural Networks for Computer Vision tasks. We give a comprehensive overview about taxonomy of related studies and compare several survey papers that deal with explainability in general. We work out the drawbacks and gaps and summarize further research ideas.", "published": "2019-11-27T12:58:52Z", "version": 1}, {"aid": "1911.12207", "authors": ["Jiayun Wang", "Yubei Chen", "Rudrasis Chakraborty", "Stella X. Yu"], "title": "Orthogonal Convolutional Neural Networks", "url": "http://arxiv.org/pdf/1911.12207v3", "summary": "Deep convolutional neural networks are hindered by training instability and feature redundancy towards further performance improvement. A promising solution is to impose orthogonality on convolutional filters.   We develop an efficient approach to impose filter orthogonality on a convolutional layer based on the doubly block-Toeplitz matrix representation of the convolutional kernel instead of using the common kernel orthogonality approach, which we show is only necessary but not sufficient for ensuring orthogonal convolutions.   Our proposed orthogonal convolution requires no additional parameters and little computational overhead. This method consistently outperforms the kernel orthogonality alternative on a wide range of tasks such as image classification and inpainting under supervised, semi-supervised and unsupervised settings. Further, it learns more diverse and expressive features with better training stability, robustness, and generalization. Our code is publicly available at https://github.com/samaonline/Orthogonal-Convolutional-Neural-Networks.", "published": "2019-11-27T15:04:26Z", "version": 3}, {"aid": "1911.12287", "authors": ["Giannis Daras", "Augustus Odena", "Han Zhang", "Alexandros G. Dimakis"], "title": "Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models", "url": "http://arxiv.org/pdf/1911.12287v2", "summary": "We introduce a new local sparse attention layer that preserves two-dimensional geometry and locality. We show that by just replacing the dense attention layer of SAGAN with our construction, we obtain very significant FID, Inception score and pure visual improvements. FID score is improved from $18.65$ to $15.94$ on ImageNet, keeping all other parameters the same. The sparse attention patterns that we propose for our new layer are designed using a novel information theoretic criterion that uses information flow graphs. We also present a novel way to invert Generative Adversarial Networks with attention. Our method extracts from the attention layer of the discriminator a saliency map, which we use to construct a new loss function for the inversion. This allows us to visualize the newly introduced attention heads and show that they indeed capture interesting aspects of two-dimensional geometry of real images.", "published": "2019-11-27T17:03:16Z", "version": 2}, {"aid": "1911.12291", "authors": ["Mangal Prakash", "Manan Lalit", "Pavel Tomancak", "Alexander Krull", "Florian Jug"], "title": "Fully Unsupervised Probabilistic Noise2Void", "url": "http://arxiv.org/pdf/1911.12291v2", "summary": "Image denoising is the first step in many biomedical image analysis pipelines and Deep Learning (DL) based methods are currently best performing. A new category of DL methods such as Noise2Void or Noise2Self can be used fully unsupervised, requiring nothing but the noisy data. However, this comes at the price of reduced reconstruction quality. The recently proposed Probabilistic Noise2Void (PN2V) improves results, but requires an additional noise model for which calibration data needs to be acquired. Here, we present improvements to PN2V that (i) replace histogram based noise models by parametric noise models, and (ii) show how suitable noise models can be created even in the absence of calibration data. This is a major step since it actually renders PN2V fully unsupervised. We demonstrate that all proposed improvements are not only academic but indeed relevant.", "published": "2019-11-27T17:11:59Z", "version": 2}, {"aid": "1911.12675", "authors": ["Xu Shen", "Xinmei Tian", "Tongliang Liu", "Fang Xu", "Dacheng Tao"], "title": "Continuous Dropout", "url": "http://arxiv.org/pdf/1911.12675v1", "summary": "Dropout has been proven to be an effective algorithm for training robust deep networks because of its ability to prevent overfitting by avoiding the co-adaptation of feature detectors. Current explanations of dropout include bagging, naive Bayes, regularization, and sex in evolution. According to the activation patterns of neurons in the human brain, when faced with different situations, the firing rates of neurons are random and continuous, not binary as current dropout does. Inspired by this phenomenon, we extend the traditional binary dropout to continuous dropout. On the one hand, continuous dropout is considerably closer to the activation characteristics of neurons in the human brain than traditional binary dropout. On the other hand, we demonstrate that continuous dropout has the property of avoiding the co-adaptation of feature detectors, which suggests that we can extract more independent feature detectors for model averaging in the test stage. We introduce the proposed continuous dropout to a feedforward neural network and comprehensively compare it with binary dropout, adaptive dropout, and DropConnect on MNIST, CIFAR-10, SVHN, NORB, and ILSVRC-12. Thorough experiments demonstrate that our method performs better in preventing the co-adaptation of feature detectors and improves test performance. The code is available at: https://github.com/jasonustc/caffe-multigpu/tree/dropout.", "published": "2019-11-28T12:37:48Z", "version": 1}, {"aid": "1912.00009", "authors": ["Shiyuan Li"], "title": "MSTDP: A More Biologically Plausible Learning", "url": "http://arxiv.org/pdf/1912.00009v2", "summary": "Spike-timing dependent plasticity (STDP) which observed in the brain has proven to be important in biological learning. On the other hand, artificial neural networks use a different way to learn, such as Back-Propagation or Contrastive Hebbian Learning. In this work, we propose a new framework called mstdp that learn almost the same way biological learning use, it only uses STDP rules for supervised and unsupervised learning and don' t need a global loss or other supervise information. The framework works like an auto-encoder by making each input neuron also an output neuron. It can make predictions or generate patterns in one model without additional configuration. We also brought a new iterative inference method using momentum to make the framework more efficient, which can be used in training and testing phases. Finally, we verified our framework on MNIST dataset for classification and generation task.", "published": "2019-11-29T05:42:50Z", "version": 2}, {"aid": "1911.13135", "authors": ["Gabriel Turinici"], "title": "Radon Sobolev Variational Auto-Encoders", "url": "http://arxiv.org/pdf/1911.13135v3", "summary": "The quality of generative models (such as Generative adversarial networks and Variational Auto-Encoders) depends heavily on the choice of a good probability distance. However some popular metrics like the Wasserstein or the Sliced Wasserstein distances, the Jensen-Shannon divergence, the Kullback-Leibler divergence, lack convenient properties such as (geodesic) convexity, fast evaluation and so on. To address these shortcomings, we introduce a class of distances that have built-in convexity. We investigate the relationship with some known paradigms (sliced distances - a synonym for Radon distances -, reproducing kernel Hilbert spaces, energy distances). The distances are shown to possess fast implementations and are included in an adapted Variational Auto-Encoder termed Radon Sobolev Variational Auto-Encoder (RS-VAE) which produces high quality results on standard generative datasets.   Keywords: Variational Auto-Encoder; Generative model; Sobolev spaces; Radon Sobolev Variational Auto-Encoder;", "published": "2019-11-29T15:02:28Z", "version": 3}, {"aid": "1911.13173", "authors": ["Brendan Ruff", "Taylor Beck", "Joscha Bach"], "title": "Mean Shift Rejection: Training Deep Neural Networks Without Minibatch Statistics or Normalization", "url": "http://arxiv.org/pdf/1911.13173v1", "summary": "Deep convolutional neural networks are known to be unstable during training at high learning rate unless normalization techniques are employed. Normalizing weights or activations allows the use of higher learning rates, resulting in faster convergence and higher test accuracy. Batch normalization requires minibatch statistics that approximate the dataset statistics but this incurs additional compute and memory costs and causes a communication bottleneck for distributed training. Weight normalization and initialization-only schemes do not achieve comparable test accuracy.   We introduce a new understanding of the cause of training instability and provide a technique that is independent of normalization and minibatch statistics. Our approach treats training instability as a spatial common mode signal which is suppressed by placing the model on a channel-wise zero-mean isocline that is maintained throughout training. Firstly, we apply channel-wise zero-mean initialization of filter kernels with overall unity kernel magnitude. At each training step we modify the gradients of spatial kernels so that their weighted channel-wise mean is subtracted in order to maintain the common mode rejection condition. This prevents the onset of mean shift. This new technique allows direct training of the test graph so that training and test models are identical. We also demonstrate that injecting random noise throughout the network during training improves generalization. This is based on the idea that, as a side effect, batch normalization performs deep data augmentation by injecting minibatch noise due to the weakness of the dataset approximation.   Our technique achieves higher accuracy compared to batch normalization and for the first time shows that minibatches and normalization are unnecessary for state-of-the-art training.", "published": "2019-11-29T16:19:00Z", "version": 1}, {"aid": "1911.13175", "authors": ["Sean Moran", "Steven McDonagh", "Gregory Slabaugh"], "title": "CURL: Neural Curve Layers for Global Image Enhancement", "url": "http://arxiv.org/pdf/1911.13175v4", "summary": "We present a novel approach to adjust global image properties such as colour, saturation, and luminance using human-interpretable image enhancement curves, inspired by the Photoshop curves tool. Our method, dubbed neural CURve Layers (CURL), is designed as a multi-colour space neural retouching block trained jointly in three different colour spaces (HSV, CIELab, RGB) guided by a novel multi-colour space loss. The curves are fully differentiable and are trained end-to-end for different computer vision problems including photo enhancement (RGB-to-RGB) and as part of the image signal processing pipeline for image formation (RAW-to-RGB). To demonstrate the effectiveness of CURL we combine this global image transformation block with a pixel-level (local) image multi-scale encoder-decoder backbone network. In an extensive experimental evaluation we show that CURL produces state-of-the-art image quality versus recently proposed deep learning approaches in both objective and perceptual metrics, setting new state-of-the-art performance on multiple public datasets. Our code is publicly available at: https://github.com/sjmoran/CURL.", "published": "2019-11-29T16:20:05Z", "version": 4}, {"aid": "1912.00091", "authors": ["Liane Gabora"], "title": "Creativity", "url": "http://arxiv.org/pdf/1912.00091v1", "summary": "Creativity is perhaps what most differentiates humans from other species. It involves the capacity to shift between divergent and convergent modes of thought in response to task demands. Divergent thought has been characterized as the kind of thinking needed to generate multiple solutions, while convergent thought has been characterized as the kind of thinking needed for tasks in with one solution. Divergent thought has been conceived of as reflecting on the task from unconventional perspectives, while convergent thought has been conceived of as reflecting on it from conventional perspectives. Personality traits correlated with creativity include openness to experience, tolerance of ambiguity, and self-confidence. Evidence that creativity is linked with affective disorders is mixed. Neuroscientific research using electroencephalography (EEG) or functional magnetic resonance imaging (fMRI) suggests that creativity is associated with a loosening of cognitive control and decreased arousal. The distributed, content-addressable structure of associative memory is conducive to bringing task-relevant items to mind without the need for explicit search. Human creativity dates back to the earliest stone tools over three million years ago, with the Paleolithic marking the onset of art, science, and religion. Areas of controversy concern the relative contributions of expertise, chance, and intuition, the importance of process versus product, whether creativity is domain-specific versus domain-general, the extent to which creativity is correlated with affective disorders, and whether divergent thought entails the generation of multiple ideas or the honing of a single initially ambiguous mental representation that may manifest as different external outputs. Areas for further research include computational modeling, the biological basis of creativity, and studies that track ideation processes over time.", "published": "2019-11-29T23:17:03Z", "version": 1}, {"aid": "1912.00144", "authors": ["Huangxing Lin", "Weihong Zeng", "Xinghao Ding", "Yue Huang", "Chenxi Huang", "John Paisley"], "title": "Learning Rate Dropout", "url": "http://arxiv.org/pdf/1912.00144v2", "summary": "The performance of a deep neural network is highly dependent on its training, and finding better local optimal solutions is the goal of many optimization algorithms. However, existing optimization algorithms show a preference for descent paths that converge slowly and do not seek to avoid bad local optima. In this work, we propose Learning Rate Dropout (LRD), a simple gradient descent technique for training related to coordinate descent. LRD empirically aids the optimizer to actively explore in the parameter space by randomly setting some learning rates to zero; at each iteration, only parameters whose learning rate is not 0 are updated. As the learning rate of different parameters is dropped, the optimizer will sample a new loss descent path for the current update. The uncertainty of the descent path helps the model avoid saddle points and bad local minima. Experiments show that LRD is surprisingly effective in accelerating training while preventing overfitting.", "published": "2019-11-30T06:58:40Z", "version": 2}, {"aid": "1912.00226", "authors": ["Yoshiki Ito", "Taro Toyoizumi"], "title": "Learning poly-synaptic paths with traveling waves", "url": "http://arxiv.org/pdf/1912.00226v2", "summary": "Traveling waves are commonly observed across the brain. While previous studies have suggested the role of traveling waves in learning, the mechanism is still unclear. We adopted a computational approach to investigate the effect of traveling waves on synaptic plasticity. Our results indicate that traveling waves facilitate the learning of poly-synaptic network-paths when combined with a reward-dependent local synaptic plasticity rule. We also demonstrate that traveling waves expedite finding the shortest paths and learning nonlinear input/output-mapping, such as exclusive or (XOR) function.", "published": "2019-11-30T16:28:36Z", "version": 2}, {"aid": "1912.00385", "authors": ["Ismail Elezi", "Sebastiano Vascon", "Alessandro Torcinovich", "Marcello Pelillo", "Laura Leal-Taixe"], "title": "The Group Loss for Deep Metric Learning", "url": "http://arxiv.org/pdf/1912.00385v4", "summary": "Deep metric learning has yielded impressive results in tasks such as clustering and image retrieval by leveraging neural networks to obtain highly discriminative feature embeddings, which can be used to group samples into different classes. Much research has been devoted to the design of smart loss functions or data mining strategies for training such networks. Most methods consider only pairs or triplets of samples within a mini-batch to compute the loss function, which is commonly based on the distance between embeddings. We propose Group Loss, a loss function based on a differentiable label-propagation method that enforces embedding similarity across all samples of a group while promoting, at the same time, low-density regions amongst data points belonging to different groups. Guided by the smoothness assumption that \"similar objects should belong to the same group\", the proposed loss trains the neural network for a classification task, enforcing a consistent labelling amongst samples within a class. We show state-of-the-art results on clustering and image retrieval on several datasets, and show the potential of our method when combined with other techniques such as ensembles", "published": "2019-12-01T11:09:57Z", "version": 4}, {"aid": "2001.01680", "authors": ["Mingyuan Meng", "Xingyu Yang", "Lei Bi", "Jinman Kim", "Shanlin Xiao", "Zhiyi Yu"], "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised Feature Learning", "url": "http://arxiv.org/pdf/2001.01680v5", "summary": "Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine learning algorithms that have been widely recognized in producing ultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs based on synaptic plasticity, especially Spike-Timing-Dependent Plasticity (STDP), are considered to have great potential in imitating the learning process of the biological brain. Nevertheless, the existing STDP-based SNNs have limitations in constrained learning capability and/or slow learning speed. Most STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture and used a sub-optimal vote-based scheme for spike decoding. In this paper, we overcome these limitations with: 1) a design of high-parallelism network architecture, inspired by the Inception module in Artificial Neural Networks (ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the standard vote-based spike decoding scheme, to reduce the information loss in spike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism that accelerates SNNs' learning by enhancing spiking activities. Our experimental results on two established benchmark datasets (MNIST/EMNIST) show that our network architecture resulted in superior performance compared to the widely used FC architecture and a more advanced Locally-Connected (LC) architecture, and that our SNN achieved competitive results with state-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE dataset) while having superior learning efficiency and robustness against hardware damage. Our SNN achieved great classification accuracy with only hundreds of training iterations, and random destruction of large numbers of synapses or neurons only led to negligible performance degradation.", "published": "2019-12-02T17:19:17Z", "version": 5}, {"aid": "1912.01137", "authors": ["Pitoyo Hartono"], "title": "Mixing autoencoder with classifier: conceptual data visualization", "url": "http://arxiv.org/pdf/1912.01137v3", "summary": "In this short paper, a neural network that is able to form a low dimensional topological hidden representation is explained. The neural network can be trained as an autoencoder, a classifier or mix of both, and produces different low dimensional topological map for each of them. When it is trained as an autoencoder, the inherent topological structure of the data can be visualized, while when it is trained as a classifier, the topological structure is further constrained by the concept, for example the labels the data, hence the visualization is not only structural but also conceptual. The proposed neural network significantly differ from many dimensional reduction models, primarily in its ability to execute both supervised and unsupervised dimensional reduction. The neural network allows multi perspective visualization of the data, and thus giving more flexibility in data analysis. This paper is supported by preliminary but intuitive visualization experiments.", "published": "2019-12-03T00:33:26Z", "version": 3}, {"aid": "1912.01166", "authors": ["He He", "Dongrui Wu"], "title": "Different Set Domain Adaptation for Brain-Computer Interfaces: A Label Alignment Approach", "url": "http://arxiv.org/pdf/1912.01166v4", "summary": "A brain-computer interface (BCI) system usually needs a long calibration session for each new subject/task to adjust its parameters, which impedes its transition from the laboratory to real-world applications. Domain adaptation, which leverages labeled data from auxiliary subjects/tasks (source domains), has demonstrated its effectiveness in reducing such calibration effort. Currently, most domain adaptation approaches require the source domains to have the same feature space and label space as the target domain, which limits their applications, as the auxiliary data may have different feature spaces and/or different label spaces. This paper considers different set domain adaptation for BCIs, i.e., the source and target domains have different label spaces. We introduce a practical setting of different label sets for BCIs, and propose a novel label alignment (LA) approach to align the source label space with the target label space. It has three desirable properties: 1) LA only needs as few as one labeled sample from each class of the target subject; 2) LA can be used as a preprocessing step before different feature extraction and classification algorithms; and, 3) LA can be integrated with other domain adaptation approaches to achieve even better performance. Experiments on two motor imagery datasets demonstrated the effectiveness of LA.", "published": "2019-12-03T02:46:56Z", "version": 4}, {"aid": "1912.01171", "authors": ["Zihan Liu", "Lubin Meng", "Xiao Zhang", "Weili Fang", "Dongrui Wu"], "title": "Universal Adversarial Perturbations for CNN Classifiers in EEG-Based BCIs", "url": "http://arxiv.org/pdf/1912.01171v5", "summary": "Multiple convolutional neural network (CNN) classifiers have been proposed for electroencephalogram (EEG) based brain-computer interfaces (BCIs). However, CNN models have been found vulnerable to universal adversarial perturbations (UAPs), which are small and example-independent, yet powerful enough to degrade the performance of a CNN model, when added to a benign example. This paper proposes a novel total loss minimization (TLM) approach to generate UAPs for EEG-based BCIs. Experimental results demonstrated the effectiveness of TLM on three popular CNN classifiers for both target and non-target attacks. We also verified the transferability of UAPs in EEG-based BCI systems. To our knowledge, this is the first study on UAPs of CNN classifiers in EEG-based BCIs. UAPs are easy to construct, and can attack BCIs in real-time, exposing a potentially critical security concern of BCIs.", "published": "2019-12-03T03:00:08Z", "version": 5}, {"aid": "1912.01521", "authors": ["Oren Barkan"], "title": "Multiscale Self Attentive Convolutions for Vision and Language Modeling", "url": "http://arxiv.org/pdf/1912.01521v1", "summary": "Self attention mechanisms have become a key building block in many state-of-the-art language understanding models. In this paper, we show that the self attention operator can be formulated in terms of 1x1 convolution operations. Following this observation, we propose several novel operators: First, we introduce a 2D version of self attention that is applicable for 2D signals such as images. Second, we present the 1D and 2D Self Attentive Convolutions (SAC) operator that generalizes self attention beyond 1x1 convolutions to 1xm and nxm convolutions, respectively. While 1D and 2D self attention operate on individual words and pixels, SAC operates on m-grams and image patches, respectively. Third, we present a multiscale version of SAC (MSAC) which analyzes the input by employing multiple SAC operators that vary by filter size, in parallel. Finally, we explain how MSAC can be utilized for vision and language modeling, and further harness MSAC to form a cross attentive image similarity machinery.", "published": "2019-12-03T16:51:09Z", "version": 1}, {"aid": "1912.01839", "authors": ["Yuval Bahat", "Tomer Michaeli"], "title": "Explorable Super Resolution", "url": "http://arxiv.org/pdf/1912.01839v3", "summary": "Single image super resolution (SR) has seen major performance leaps in recent years. However, existing methods do not allow exploring the infinitely many plausible reconstructions that might have given rise to the observed low-resolution (LR) image. These different explanations to the LR image may dramatically vary in their textures and fine details, and may often encode completely different semantic information. In this paper, we introduce the task of explorable super resolution. We propose a framework comprising a graphical user interface with a neural network backend, allowing editing the SR output so as to explore the abundance of plausible HR explanations to the LR input. At the heart of our method is a novel module that can wrap any existing SR network, analytically guaranteeing that its SR outputs would precisely match the LR input, when downsampled. Besides its importance in our setting, this module is guaranteed to decrease the reconstruction error of any SR network it wraps, and can be used to cope with blur kernels that are different from the one the network was trained for. We illustrate our approach in a variety of use cases, ranging from medical imaging and forensics, to graphics.", "published": "2019-12-04T08:01:58Z", "version": 3}, {"aid": "1912.02040", "authors": ["Carlos Calvo Tapia", "Ivan Tyukin", "Valeri A. Makarov"], "title": "Universal principles justify the existence of concept cells", "url": "http://arxiv.org/pdf/1912.02040v1", "summary": "It is largely believed that complex cognitive phenomena require the perfect orchestrated collaboration of many neurons. However, this is not what converging experimental evidence suggests. Single neurons, the so-called concept cells, may be responsible for complex tasks performed by an individual. Here, starting from a few first principles, we layout physical foundations showing that concept cells are not only possible but highly likely, given that neurons work in a high dimensional space.", "published": "2019-12-04T15:06:17Z", "version": 1}, {"aid": "1912.02279", "authors": ["Beidi Chen", "Weiyang Liu", "Zhiding Yu", "Jan Kautz", "Anshumali Shrivastava", "Animesh Garg", "Anima Anandkumar"], "title": "Angular Visual Hardness", "url": "http://arxiv.org/pdf/1912.02279v4", "summary": "Recent convolutional neural networks (CNNs) have led to impressive performance but often suffer from poor calibration. They tend to be overconfident, with the model confidence not always reflecting the underlying true ambiguity and hardness. In this paper, we propose angular visual hardness (AVH), a score given by the normalized angular distance between the sample feature embedding and the target classifier to measure sample hardness. We validate this score with an in-depth and extensive scientific study, and observe that CNN models with the highest accuracy also have the best AVH scores. This agrees with an earlier finding that state-of-art models improve on the classification of harder examples. We observe that the training dynamics of AVH is vastly different compared to the training loss. Specifically, AVH quickly reaches a plateau for all samples even though the training loss keeps improving. This suggests the need for designing better loss functions that can target harder examples more effectively. We also find that AVH has a statistically significant correlation with human visual hardness. Finally, we demonstrate the benefit of AVH to a variety of applications such as self-training for domain adaptation and domain generalization.", "published": "2019-12-04T22:12:42Z", "version": 4}, {"aid": "1912.02413", "authors": ["Boyan Zhou", "Quan Cui", "Xiu-Shen Wei", "Zhao-Min Chen"], "title": "BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition", "url": "http://arxiv.org/pdf/1912.02413v4", "summary": "Our work focuses on tackling the challenging but natural visual recognition task of long-tailed data distribution (i.e., a few classes occupy most of the data, while most classes have rarely few samples). In the literature, class re-balancing strategies (e.g., re-weighting and re-sampling) are the prominent and effective methods proposed to alleviate the extreme imbalance for dealing with long-tailed problems. In this paper, we firstly discover that these re-balancing methods achieving satisfactory recognition accuracy owe to that they could significantly promote the classifier learning of deep networks. However, at the same time, they will unexpectedly damage the representative ability of the learned deep features to some extent. Therefore, we propose a unified Bilateral-Branch Network (BBN) to take care of both representation learning and classifier learning simultaneously, where each branch does perform its own duty separately. In particular, our BBN model is further equipped with a novel cumulative learning strategy, which is designed to first learn the universal patterns and then pay attention to the tail data gradually. Extensive experiments on four benchmark datasets, including the large-scale iNaturalist ones, justify that the proposed BBN can significantly outperform state-of-the-art methods. Furthermore, validation experiments can demonstrate both our preliminary discovery and effectiveness of tailored designs in BBN for long-tailed problems. Our method won the first place in the iNaturalist 2019 large scale species classification competition, and our code is open-source and available at https://github.com/Megvii-Nanjing/BBN.", "published": "2019-12-05T07:32:28Z", "version": 4}, {"aid": "1912.02745", "authors": ["Tiziana Cattai", "Stefania Colonnese", "Marie-Constance Corsi", "Danielle S. Bassett", "Gaetano Scarano", "Fabrizio De Vico Fallani"], "title": "Phase/amplitude synchronization of brain signals during motor imagery BCI tasks", "url": "http://arxiv.org/pdf/1912.02745v1", "summary": "The extraction of brain functioning features is a crucial step in the definition of brain-computer interfaces (BCIs). In the last decade, functional connectivity (FC) estimators have been increasingly explored based on their ability to capture synchronization between multivariate brain signals. However, the underlying neurophysiological mechanisms and the extent to which they can improve performance in BCI-related tasks, is still poorly understood. To address this gap in knowledge, we considered a group of 20 healthy subjects during an EEG-based hand motor imagery (MI) task. We studied two well-established FC estimators, i.e. spectral- and imaginary-coherence, and investigated how they were modulated by the MI task. We characterized the resulting FC networks by extracting the strength of connectivity of each EEG sensor and compared the discriminant power with respect to standard power spectrum features. At the group level, results showed that while spectral-coherence based network features were increasing the controlateral motor area, those based on imaginary-coherence were decreasing. We demonstrated that this opposite, but complementary, behavior was respectively determined by the increase in amplitude and phase synchronization between the brain signals. At the individual level, we proved that including these network connectivity features in the classification of MI mental states led to an overall improvement in accuracy. Taken together, our results provide fresh insights into the oscillatory mechanisms subserving brain network changes during MI and offer new perspectives to improve BCI performance.", "published": "2019-12-05T17:33:12Z", "version": 1}, {"aid": "1912.02762", "authors": ["George Papamakarios", "Eric Nalisnick", "Danilo Jimenez Rezende", "Shakir Mohamed", "Balaji Lakshminarayanan"], "title": "Normalizing Flows for Probabilistic Modeling and Inference", "url": "http://arxiv.org/pdf/1912.02762v2", "summary": "Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.", "published": "2019-12-05T17:55:27Z", "version": 2}, {"aid": "1912.03203", "authors": ["Thomas Verelst", "Tinne Tuytelaars"], "title": "Dynamic Convolutions: Exploiting Spatial Sparsity for Faster Inference", "url": "http://arxiv.org/pdf/1912.03203v3", "summary": "Modern convolutional neural networks apply the same operations on every pixel in an image. However, not all image regions are equally important. To address this inefficiency, we propose a method to dynamically apply convolutions conditioned on the input image. We introduce a residual block where a small gating branch learns which spatial positions should be evaluated. These discrete gating decisions are trained end-to-end using the Gumbel-Softmax trick, in combination with a sparsity criterion. Our experiments on CIFAR, ImageNet and MPII show that our method has better focus on the region of interest and better accuracy than existing methods, at a lower computational complexity. Moreover, we provide an efficient CUDA implementation of our dynamic convolutions using a gather-scatter approach, achieving a significant improvement in inference speed with MobileNetV2 residual blocks. On human pose estimation, a task that is inherently spatially sparse, the processing speed is increased by 60% with no loss in accuracy.", "published": "2019-12-06T16:11:16Z", "version": 3}, {"aid": "1912.03458", "authors": ["Yinpeng Chen", "Xiyang Dai", "Mengchen Liu", "Dongdong Chen", "Lu Yuan", "Zicheng Liu"], "title": "Dynamic Convolution: Attention over Convolution Kernels", "url": "http://arxiv.org/pdf/1912.03458v2", "summary": "Light-weight convolutional neural networks (CNNs) suffer performance degradation as their low computational budgets constrain both the depth (number of convolution layers) and the width (number of channels) of CNNs, resulting in limited representation capability. To address this issue, we present Dynamic Convolution, a new design that increases model complexity without increasing the network depth or width. Instead of using a single convolution kernel per layer, dynamic convolution aggregates multiple parallel convolution kernels dynamically based upon their attentions, which are input dependent. Assembling multiple kernels is not only computationally efficient due to the small kernel size, but also has more representation power since these kernels are aggregated in a non-linear way via attention. By simply using dynamic convolution for the state-of-the-art architecture MobileNetV3-Small, the top-1 accuracy of ImageNet classification is boosted by 2.9% with only 4% additional FLOPs and 2.9 AP gain is achieved on COCO keypoint detection.", "published": "2019-12-07T07:51:35Z", "version": 2}, {"aid": "1912.03467", "authors": ["Mohamed Karim Belaid"], "title": "Comparison of Neuronal Attention Models", "url": "http://arxiv.org/pdf/1912.03467v1", "summary": "Recent models for image processing are using the Convolutional neural network (CNN) which requires a pixel per pixel analysis of the input image. This method works well. However, it is time-consuming if we have large images. To increase the performance, by improving the training time or the accuracy, we need a size-independent method. As a solution, we can add a Neuronal Attention model (NAM). The power of this new approach is that it can efficiently choose several small regions from the initial image to focus on. The purpose of this paper is to explain and also test each of the NAM's parameters.", "published": "2019-12-07T09:00:18Z", "version": 1}, {"aid": "1912.03647", "authors": ["Dingheng Wang", "Guangshe Zhao", "Guoqi Li", "Lei Deng", "Yang Wu"], "title": "Compressing 3DCNNs Based on Tensor Train Decomposition", "url": "http://arxiv.org/pdf/1912.03647v2", "summary": "Three dimensional convolutional neural networks (3DCNNs) have been applied in many tasks, e.g., video and 3D point cloud recognition. However, due to the higher dimension of convolutional kernels, the space complexity of 3DCNNs is generally larger than that of traditional two dimensional convolutional neural networks (2DCNNs). To miniaturize 3DCNNs for the deployment in confining environments such as embedded devices, neural network compression is a promising approach. In this work, we adopt the tensor train (TT) decomposition, a straightforward and simple in situ training compression method, to shrink the 3DCNN models. Through proposing tensorizing 3D convolutional kernels in TT format, we investigate how to select appropriate TT ranks for achieving higher compression ratio. We have also discussed the redundancy of 3D convolutional kernels for compression, core significance and future directions of this work, as well as the theoretical computation complexity versus practical executing time of convolution in TT. In the light of multiple contrast experiments based on VIVA challenge, UCF11, and UCF101 datasets, we conclude that TT decomposition can compress 3DCNNs by around one hundred times without significant accuracy loss, which will enable its applications in extensive real world scenarios.", "published": "2019-12-08T09:51:08Z", "version": 2}, {"aid": "1912.03820", "authors": ["Mingzhang Yin", "George Tucker", "Mingyuan Zhou", "Sergey Levine", "Chelsea Finn"], "title": "Meta-Learning without Memorization", "url": "http://arxiv.org/pdf/1912.03820v3", "summary": "The ability to learn new concepts with small amounts of data is a critical aspect of intelligence that has proven challenging for deep learning methods. Meta-learning has emerged as a promising technique for leveraging data from previous tasks to enable efficient learning of new tasks. However, most meta-learning algorithms implicitly require that the meta-training tasks be mutually-exclusive, such that no single model can solve all of the tasks at once. For example, when creating tasks for few-shot image classification, prior work uses a per-task random assignment of image classes to N-way classification labels. If this is not done, the meta-learner can ignore the task training data and learn a single model that performs all of the meta-training tasks zero-shot, but does not adapt effectively to new image classes. This requirement means that the user must take great care in designing the tasks, for example by shuffling labels or removing task identifying information from the inputs. In some domains, this makes meta-learning entirely inapplicable. In this paper, we address this challenge by designing a meta-regularization objective using information theory that places precedence on data-driven adaptation. This causes the meta-learner to decide what must be learned from the task training data and what should be inferred from the task testing input. By doing so, our algorithm can successfully use data from non-mutually-exclusive tasks to efficiently adapt to novel tasks. We demonstrate its applicability to both contextual and gradient-based meta-learning algorithms, and apply it in practical settings where applying standard meta-learning has been difficult. Our approach substantially outperforms standard meta-learning algorithms in these settings.", "published": "2019-12-09T02:30:46Z", "version": 3}, {"aid": "1912.05743", "authors": ["Akanksha Atrey", "Kaleigh Clary", "David Jensen"], "title": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/1912.05743v2", "summary": "Saliency maps are frequently used to support explanations of the behavior of deep reinforcement learning (RL) agents. However, a review of how saliency maps are used in practice indicates that the derived explanations are often unfalsifiable and can be highly subjective. We introduce an empirical approach grounded in counterfactual reasoning to test the hypotheses generated from saliency maps and assess the degree to which they correspond to the semantics of RL environments. We use Atari games, a common benchmark for deep RL, to evaluate three types of saliency maps. Our results show the extent to which existing claims about Atari games can be evaluated and suggest that saliency maps are best viewed as an exploratory tool rather than an explanatory tool.", "published": "2019-12-09T12:42:07Z", "version": 2}, {"aid": "1912.04478", "authors": ["Pei Xie", "He-Feng Yin", "Xiao-Jun Wu"], "title": "Low-rank representations with incoherent dictionary for face recognition", "url": "http://arxiv.org/pdf/1912.04478v1", "summary": "Face recognition remains a hot topic in computer vision, and it is challenging to tackle the problem that both the training and testing images are corrupted. In this paper, we propose a novel semi-supervised method based on the theory of the low-rank matrix recovery for face recognition, which can simultaneously learn discriminative low-rank and sparse representations for both training and testing images. To this end, a correlation penalty term is introduced into the formulation of our proposed method to learn an incoherent dictionary. Experimental results on several face image databases demonstrate the effectiveness of our method, i.e., the proposed method is robust to the illumination, expression and pose variations, as well as images with noises such as block occlusion or uniform noises.", "published": "2019-12-10T03:44:25Z", "version": 1}, {"aid": "1912.04486", "authors": ["Junjie Zhang", "Lingqiao Liu", "Peng Wang", "Chunhua Shen"], "title": "To Balance or Not to Balance: A Simple-yet-Effective Approach for Learning with Long-Tailed Distributions", "url": "http://arxiv.org/pdf/1912.04486v2", "summary": "Real-world visual data often exhibits a long-tailed distribution, where some ''head'' classes have a large number of samples, yet only a few samples are available for ''tail'' classes. Such imbalanced distribution causes a great challenge for learning a deep neural network, which can be boiled down into a dilemma: on the one hand, we prefer to increase the exposure of tail class samples to avoid the excessive dominance of head classes in the classifier training. On the other hand, oversampling tail classes makes the network prone to over-fitting, since head class samples are often consequently under-represented. To resolve this dilemma, in this paper, we propose a simple-yet-effective auxiliary learning approach. The key idea is to split a network into a classifier part and a feature extractor part, and then employ different training strategies for each part. Specifically, to promote the awareness of tail-classes, a class-balanced sampling scheme is utilised for training both the classifier and the feature extractor. For the feature extractor, we also introduce an auxiliary training task, which is to train a classifier under the regular random sampling scheme. In this way, the feature extractor is jointly trained from both sampling strategies and thus can take advantage of all training data and avoid the over-fitting issue. Apart from this basic auxiliary task, we further explore the benefit of using self-supervised learning as the auxiliary task. Without using any bells and whistles, our model achieves superior performance over the state-of-the-art solutions.", "published": "2019-12-10T04:11:53Z", "version": 2}, {"aid": "1912.04518", "authors": ["Shuaicheng Liu", "Zehao Zhang", "Kai Song", "Bing Zeng"], "title": "Arithmetic addition of two integers by deep image classification networks: experiments to quantify their autonomous reasoning ability", "url": "http://arxiv.org/pdf/1912.04518v1", "summary": "The unprecedented performance achieved by deep convolutional neural networks for image classification is linked primarily to their ability of capturing rich structural features at various layers within networks. Here we design a series of experiments, inspired by children's learning of the arithmetic addition of two integers, to showcase that such deep networks can go beyond the structural features to learn deeper knowledge. In our experiments, a set of images is constructed, each image containing an arithmetic addition $n+m$ in its central area, and several classification networks are then trained over a subset of images, using the sum as the label. Tests on the excluded images show that, as the image set gets larger, the networks have well learnt the law of arithmetic additions so as to build up their autonomous reasoning ability strongly. For instance, networks trained over a small percentage of images can classify a big majority of the remaining images correctly, and many arithmetic additions involving some integers that have never been seen during the training can also be solved correctly by the trained networks.", "published": "2019-12-10T06:02:59Z", "version": 1}, {"aid": "1912.04564", "authors": ["Arnab Kumar Mondal", "Sankalan Pal Chowdhury", "Aravind Jayendran", "Parag Singla", "Himanshu Asnani", "Prathosh AP"], "title": "MaskAAE: Latent space optimization for Adversarial Auto-Encoders", "url": "http://arxiv.org/pdf/1912.04564v2", "summary": "The field of neural generative models is dominated by the highly successful Generative Adversarial Networks (GANs) despite their challenges, such as training instability and mode collapse. Auto-Encoders (AE) with regularized latent space provide an alternative framework for generative models, albeit their performance levels have not reached that of GANs. In this work, we hypothesise that the dimensionality of the AE model's latent space has a critical effect on the quality of generated data. Under the assumption that nature generates data by sampling from a \"true\" generative latent space followed by a deterministic function, we show that the optimal performance is obtained when the dimensionality of the latent space of the AE-model matches with that of the \"true\" generative latent space. Further, we propose an algorithm called the Mask Adversarial Auto-Encoder (MaskAAE), in which the dimensionality of the latent space of an adversarial auto encoder is brought closer to that of the \"true\" generative latent space, via a procedure to mask the spurious latent dimensions. We demonstrate through experiments on synthetic and several real-world datasets that the proposed formulation yields betterment in the generation quality.", "published": "2019-12-10T08:18:13Z", "version": 2}, {"aid": "1912.04591", "authors": ["Konstantinos Rematas", "Vittorio Ferrari"], "title": "Neural Voxel Renderer: Learning an Accurate and Controllable Rendering Tool", "url": "http://arxiv.org/pdf/1912.04591v2", "summary": "We present a neural rendering framework that maps a voxelized scene into a high quality image. Highly-textured objects and scene element interactions are realistically rendered by our method, despite having a rough representation as an input. Moreover, our approach allows controllable rendering: geometric and appearance modifications in the input are accurately propagated to the output. The user can move, rotate and scale an object, change its appearance and texture or modify the position of the light and all these edits are represented in the final rendering. We demonstrate the effectiveness of our approach by rendering scenes with varying appearance, from single color per object to complex, high-frequency textures. We show that our rerendering network can generate very detailed images that represent precisely the appearance of the input scene. Our experiments illustrate that our approach achieves more accurate image synthesis results compared to alternatives and can also handle low voxel grid resolutions. Finally, we show how our neural rendering framework can capture and faithfully render objects from real images and from a diverse set of classes.", "published": "2019-12-10T09:30:03Z", "version": 2}, {"aid": "1912.04749", "authors": ["Shoufa Chen", "Yunpeng Chen", "Shuicheng Yan", "Jiashi Feng"], "title": "Efficient Differentiable Neural Architecture Search with Meta Kernels", "url": "http://arxiv.org/pdf/1912.04749v1", "summary": "The searching procedure of neural architecture search (NAS) is notoriously time consuming and cost prohibitive.To make the search space continuous, most existing gradient-based NAS methods relax the categorical choice of a particular operation to a softmax over all possible operations and calculate the weighted sum of multiple features, resulting in a large memory requirement and a huge computation burden. In this work, we propose an efficient and novel search strategy with meta kernels. We directly encode the supernet from the perspective on convolution kernels and \"shrink\" multiple convolution kernel candidates into a single one before these candidates operate on the input feature. In this way, only a single feature is generated between two intermediate nodes. The memory for storing intermediate features and the resource budget for conducting convolution operations are both reduced remarkably. Despite high efficiency, our search strategy can search in a more fine-grained way than existing works and increases the capacity for representing possible networks. We demonstrate the effectiveness of our search strategy by conducting extensive experiments. Specifically, our method achieves 77.0% top-1 accuracy on ImageNet benchmark dataset with merely 357M FLOPs, outperforming both EfficientNet and MobileNetV3 under the same FLOPs constraints. Compared to models discovered by the start-of-the-art NAS method, our method achieves the same (sometimes even better) performance, while faster by three orders of magnitude.", "published": "2019-12-10T15:08:50Z", "version": 1}, {"aid": "1912.04964", "authors": ["Dimiter Dobrev"], "title": "Before we can find a model, we must forget about perfection", "url": "http://arxiv.org/pdf/1912.04964v1", "summary": "With Reinforcement Learning we assume that a model of the world does exist. We assume furthermore that the model in question is perfect (i.e. it describes the world completely and unambiguously). This article will demonstrate that it does not make sense to search for the perfect model because this model is too complicated and practically impossible to find. We will show that we should abandon the pursuit of perfection and pursue Event-Driven (ED) models instead. These models are generalization of Markov Decision Process (MDP) models. This generalization is essential because nothing can be found without it. Rather than a single MDP, we will aim to find a raft of neat simple ED models each one describing a simple dependency or property. In other words, we will replace the search for a singular and complex perfect model with a search for a large number of simple models.", "published": "2019-12-10T20:20:34Z", "version": 1}, {"aid": "1912.05035", "authors": ["Maria Ximena Bastidas Rodriguez", "Adrien Gruson", "Luisa F. Polania", "Shin Fujieda", "Flavio Prieto Ortiz", "Kohei Takayama", "Toshiya Hachisuka"], "title": "Deep Adaptive Wavelet Network", "url": "http://arxiv.org/pdf/1912.05035v1", "summary": "Even though convolutional neural networks have become the method of choice in many fields of computer vision, they still lack interpretability and are usually designed manually in a cumbersome trial-and-error process. This paper aims at overcoming those limitations by proposing a deep neural network, which is designed in a systematic fashion and is interpretable, by integrating multiresolution analysis at the core of the deep neural network design. By using the lifting scheme, it is possible to generate a wavelet representation and design a network capable of learning wavelet coefficients in an end-to-end form. Compared to state-of-the-art architectures, the proposed model requires less hyper-parameter tuning and achieves competitive accuracy in image classification tasks", "published": "2019-12-10T22:43:16Z", "version": 1}, {"aid": "1912.05074", "authors": ["Zongwei Zhou", "Md Mahfuzur Rahman Siddiquee", "Nima Tajbakhsh", "Jianming Liang"], "title": "UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation", "url": "http://arxiv.org/pdf/1912.05074v2", "summary": "The state-of-the-art models for medical image segmentation are variants of U-Net and fully convolutional networks (FCN). Despite their success, these models have two limitations: (1) their optimal depth is apriori unknown, requiring extensive architecture search or inefficient ensemble of models of varying depths; and (2) their skip connections impose an unnecessarily restrictive fusion scheme, forcing aggregation only at the same-scale feature maps of the encoder and decoder sub-networks. To overcome these two limitations, we propose UNet++, a new neural architecture for semantic and instance segmentation, by (1) alleviating the unknown network depth with an efficient ensemble of U-Nets of varying depths, which partially share an encoder and co-learn simultaneously using deep supervision; (2) redesigning skip connections to aggregate features of varying semantic scales at the decoder sub-networks, leading to a highly flexible feature fusion scheme; and (3) devising a pruning scheme to accelerate the inference speed of UNet++. We have evaluated UNet++ using six different medical image segmentation datasets, covering multiple imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and electron microscopy (EM), and demonstrating that (1) UNet++ consistently outperforms the baseline models for the task of semantic segmentation across different datasets and backbone architectures; (2) UNet++ enhances segmentation quality of varying-size objects -- an improvement over the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design) outperforms the original Mask R-CNN for the task of instance segmentation; and (4) pruned UNet++ models achieve significant speedup while showing only modest performance degradation. Our implementation and pre-trained models are available at https://github.com/MrGiovanni/UNetPlusPlus.", "published": "2019-12-11T01:26:22Z", "version": 2}, {"aid": "1912.05433", "authors": ["Tiberiu Tesileanu", "Mary M. Conte", "John J. Briguglio", "Ann M. Hermundstad", "Jonathan D. Victor", "Vijay Balasubramanian"], "title": "Efficient coding of natural scene statistics predicts discrimination thresholds for grayscale textures", "url": "http://arxiv.org/pdf/1912.05433v2", "summary": "Previously, in (Hermundstad et al., 2014), we showed that when sampling is limiting, the efficient coding principle leads to a \"variance is salience\" hypothesis, and that this hypothesis accounts for visual sensitivity to binary image statistics. Here, using extensive new psychophysical data and image analysis, we show that this hypothesis accounts for visual sensitivity to a large set of grayscale image statistics at a striking level of detail, and also identify the limits of the prediction. We define a 66-dimensional space of local grayscale light-intensity correlations, and measure the relevance of each direction to natural scenes. The \"variance is salience\" hypothesis predicts that two-point correlations are most salient, and predicts their relative salience. We tested these predictions in a texture-segregation task using un-natural, synthetic textures. As predicted, correlations beyond second order are not salient, and predicted thresholds for over 300 second-order correlations match psychophysical thresholds closely (median fractional error <0.13).", "published": "2019-12-11T16:41:27Z", "version": 2}, {"aid": "1912.05845", "authors": ["Anthony Ortiz", "Caleb Robinson", "Dan Morris", "Olac Fuentes", "Christopher Kiekintveld", "Md Mahmudulla Hassan", "Nebojsa Jojic"], "title": "Local Context Normalization: Revisiting Local Normalization", "url": "http://arxiv.org/pdf/1912.05845v3", "summary": "Normalization layers have been shown to improve convergence in deep neural networks, and even add useful inductive biases. In many vision applications the local spatial context of the features is important, but most common normalization schemes including Group Normalization (GN), Instance Normalization (IN), and Layer Normalization (LN) normalize over the entire spatial dimension of a feature. This can wash out important signals and degrade performance. For example, in applications that use satellite imagery, input images can be arbitrarily large; consequently, it is nonsensical to normalize over the entire area. Positional Normalization (PN), on the other hand, only normalizes over a single spatial position at a time. A natural compromise is to normalize features by local context, while also taking into account group level information. In this paper, we propose Local Context Normalization (LCN): a normalization layer where every feature is normalized based on a window around it and the filters in its group. We propose an algorithmic solution to make LCN efficient for arbitrary window sizes, even if every point in the image has a unique window. LCN outperforms its Batch Normalization (BN), GN, IN, and LN counterparts for object detection, semantic segmentation, and instance segmentation applications in several benchmark datasets, while keeping performance independent of the batch size and facilitating transfer learning.", "published": "2019-12-12T09:28:24Z", "version": 3}, {"aid": "1912.05864", "authors": ["Hichem Sahbi"], "title": "Totally Deep Support Vector Machines", "url": "http://arxiv.org/pdf/1912.05864v1", "summary": "Support vector machines (SVMs) have been successful in solving many computer vision tasks including image and video category recognition especially for small and mid-scale training problems. The principle of these non-parametric models is to learn hyperplanes that separate data belonging to different classes while maximizing their margins. However, SVMs constrain the learned hyperplanes to lie in the span of support vectors, fixed/taken from training data, and this reduces their representational power and may lead to limited generalization performances. In this paper, we relax this constraint and allow the support vectors to be learned (instead of being fixed/taken from training data) in order to better fit a given classification task. Our approach, referred to as deep total variation support vector machines, is parametric and relies on a novel deep architecture that learns not only the SVM and the kernel parameters but also the support vectors, resulting into highly effective classifiers. We also show (under a particular setting of the activation functions in this deep architecture) that a large class of kernels and their combinations can be learned. Experiments conducted on the challenging task of skeleton-based action recognition show the outperformance of our deep total variation SVMs w.r.t different baselines as well as the related work.", "published": "2019-12-12T10:18:17Z", "version": 1}, {"aid": "1912.05888", "authors": ["Aaron Wewior", "Joachim Weickert"], "title": "Variational Coupling Revisited: Simpler Models, Theoretical Connections, and Novel Applications", "url": "http://arxiv.org/pdf/1912.05888v1", "summary": "Variational models with coupling terms are becoming increasingly popular in image analysis. They involve auxiliary variables, such that their energy minimisation splits into multiple fractional steps that can be solved easier and more efficiently. In our paper we show that coupling models offer a number of interesting properties that go far beyond their obvious numerical benefits. We demonstrate that discontinuity-preserving denoising can be achieved even with quadratic data and smoothness terms, provided that the coupling term involves the $L^1$ norm. We show that such an $L^1$ coupling term provides additional information as a powerful edge detector that has remained unexplored so far. While coupling models in the literature approximate higher order regularisation, we argue that already first order coupling models can be useful. As a specific example, we present a first order coupling model that outperforms classical TV regularisation. It also establishes a theoretical connection between TV regularisation and the Mumford-Shah segmentation approach. Unlike other Mumford-Shah algorithms, it is a strictly convex approximation, for which we can guarantee convergence of a split Bregman algorithm.", "published": "2019-12-12T11:44:53Z", "version": 1}, {"aid": "1912.06044", "authors": ["Mor Avi-Aharon", "Assaf Arbelle", "Tammy Riklin Raviv"], "title": "Hue-Net: Intensity-based Image-to-Image Translation with Differentiable Histogram Loss Functions", "url": "http://arxiv.org/pdf/1912.06044v1", "summary": "We present the Hue-Net - a novel Deep Learning framework for Intensity-based Image-to-Image Translation. The key idea is a new technique termed network augmentation which allows a differentiable construction of intensity histograms from images. We further introduce differentiable representations of (1D) cyclic and joint (2D) histograms and use them for defining loss functions based on cyclic Earth Mover's Distance (EMD) and Mutual Information (MI). While the Hue-Net can be applied to several image-to-image translation tasks, we choose to demonstrate its strength on color transfer problems, where the aim is to paint a source image with the colors of a different target image. Note that the desired output image does not exist and therefore cannot be used for supervised pixel-to-pixel learning. This is accomplished by using the HSV color-space and defining an intensity-based loss that is built on the EMD between the cyclic hue histograms of the output and the target images. To enforce color-free similarity between the source and the output images, we define a semantic-based loss by a differentiable approximation of the MI of these images. The incorporation of histogram loss functions in addition to an adversarial loss enables the construction of semantically meaningful and realistic images. Promising results are presented for different datasets.", "published": "2019-12-12T15:48:55Z", "version": 1}, {"aid": "1912.06088", "authors": ["Dibya Ghosh", "Abhishek Gupta", "Ashwin Reddy", "Justin Fu", "Coline Devin", "Benjamin Eysenbach", "Sergey Levine"], "title": "Learning to Reach Goals via Iterated Supervised Learning", "url": "http://arxiv.org/pdf/1912.06088v4", "summary": "Current reinforcement learning (RL) algorithms can be brittle and difficult to use, especially when learning goal-reaching behaviors from sparse rewards. Although supervised imitation learning provides a simple and stable alternative, it requires access to demonstrations from a human supervisor. In this paper, we study RL algorithms that use imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. In lieu of demonstrations, we leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. We propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal-reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. We formally show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy, and empirically demonstrate improved goal-reaching performance and robustness over current RL algorithms in several benchmark tasks.", "published": "2019-12-12T17:26:47Z", "version": 4}, {"aid": "1912.06101", "authors": ["Carlos Purves", "C\u0103t\u0103lina Cangea", "Petar Veli\u010dkovi\u0107"], "title": "The PlayStation Reinforcement Learning Environment (PSXLE)", "url": "http://arxiv.org/pdf/1912.06101v1", "summary": "We propose a new benchmark environment for evaluating Reinforcement Learning (RL) algorithms: the PlayStation Learning Environment (PSXLE), a PlayStation emulator modified to expose a simple control API that enables rich game-state representations. We argue that the PlayStation serves as a suitable progression for agent evaluation and propose a framework for such an evaluation. We build an action-driven abstraction for a PlayStation game with support for the OpenAI Gym interface and demonstrate its use by running OpenAI Baselines.", "published": "2019-12-12T17:59:52Z", "version": 1}, {"aid": "1912.06126", "authors": ["Kyle Genova", "Forrester Cole", "Avneesh Sud", "Aaron Sarna", "Thomas Funkhouser"], "title": "Local Deep Implicit Functions for 3D Shape", "url": "http://arxiv.org/pdf/1912.06126v2", "summary": "The goal of this project is to learn a 3D shape representation that enables accurate surface reconstruction, compact storage, efficient computation, consistency for similar shapes, generalization across diverse shape categories, and inference from depth camera observations. Towards this end, we introduce Local Deep Implicit Functions (LDIF), a 3D shape representation that decomposes space into a structured set of learned implicit functions. We provide networks that infer the space decomposition and local deep implicit functions from a 3D mesh or posed depth image. During experiments, we find that it provides 10.3 points higher surface reconstruction accuracy (F-Score) than the state-of-the-art (OccNet), while requiring fewer than 1 percent of the network parameters. Experiments on posed depth image completion and generalization to unseen classes show 15.8 and 17.8 point improvements over the state-of-the-art, while producing a structured 3D representation for each input with consistency across diverse shape collections.", "published": "2019-12-12T18:50:46Z", "version": 2}, {"aid": "1912.06798", "authors": ["Xun Wang", "Haozhi Zhang", "Weilin Huang", "Matthew R. Scott"], "title": "Cross-Batch Memory for Embedding Learning", "url": "http://arxiv.org/pdf/1912.06798v3", "summary": "Mining informative negative instances are of central importance to deep metric learning (DML), however this task is intrinsically limited by mini-batch training, where only a mini-batch of instances is accessible at each iteration. In this paper, we identify a \"slow drift\" phenomena by observing that the embedding features drift exceptionally slow even as the model parameters are updating throughout the training process. This suggests that the features of instances computed at preceding iterations can be used to considerably approximate their features extracted by the current model. We propose a cross-batch memory (XBM) mechanism that memorizes the embeddings of past iterations, allowing the model to collect sufficient hard negative pairs across multiple mini-batches - even over the whole dataset. Our XBM can be directly integrated into a general pair-based DML framework, where the XBM augmented DML can boost performance considerably. In particular, without bells and whistles, a simple contrastive loss with our XBM can have large R@1 improvements of 12%-22.5% on three large-scale image retrieval datasets, surpassing the most sophisticated state-of-the-art methods, by a large margin. Our XBM is conceptually simple, easy to implement - using several lines of codes, and is memory efficient - with a negligible 0.2 GB extra GPU memory. Code is available at: https://github.com/MalongTech/research-xbm.", "published": "2019-12-14T07:38:53Z", "version": 3}, {"aid": "1912.11531", "authors": ["Luca Pasqualini", "Maurizio Parton"], "title": "Pseudo Random Number Generation: a Reinforcement Learning approach", "url": "http://arxiv.org/pdf/1912.11531v1", "summary": "Pseudo-Random Numbers Generators (PRNGs) are algorithms produced to generate long sequences of statistically uncorrelated numbers, i.e. Pseudo-Random Numbers (PRNs). These numbers are widely employed in mid-level cryptography and in software applications. Test suites are used to evaluate PRNGs quality by checking statistical properties of the generated sequences. Machine learning techniques are often used to break these generators, for instance approximating a certain generator or a certain sequence using a neural network. But what about using machine learning to generate PRNs generators? This paper proposes a Reinforcement Learning (RL) approach to the task of generating PRNGs from scratch by learning a policy to solve an N-dimensional navigation problem. In this context, N is the length of the period of the generated sequence, and the policy is iteratively improved using the average value of an appropriate test suite run over that period. Aim of this work is to demonstrate the feasibility of the proposed approach, to compare it with classical methods, and to lay the foundation of a research path which combines RL and PRNGs.", "published": "2019-12-15T13:32:07Z", "version": 1}, {"aid": "1912.12138", "authors": ["Zhao Zhang", "Yulin Sun", "Yang Wang", "Zhengjun Zha", "Shuicheng Yan", "Meng Wang"], "title": "Convolutional Dictionary Pair Learning Network for Image Representation Learning", "url": "http://arxiv.org/pdf/1912.12138v3", "summary": "Both the Dictionary Learning (DL) and Convolutional Neural Networks (CNN) are powerful image representation learning systems based on different mechanisms and principles, however whether we can seamlessly integrate them to improve the per-formance is noteworthy exploring. To address this issue, we propose a novel generalized end-to-end representation learning architecture, dubbed Convolutional Dictionary Pair Learning Network (CDPL-Net) in this paper, which integrates the learning schemes of the CNN and dictionary pair learning into a unified framework. Generally, the architecture of CDPL-Net includes two convolutional/pooling layers and two dictionary pair learn-ing (DPL) layers in the representation learning module. Besides, it uses two fully-connected layers as the multi-layer perception layer in the nonlinear classification module. In particular, the DPL layer can jointly formulate the discriminative synthesis and analysis representations driven by minimizing the batch based reconstruction error over the flatted feature maps from the convolution/pooling layer. Moreover, DPL layer uses l1-norm on the analysis dictionary so that sparse representation can be delivered, and the embedding process will also be robust to noise. To speed up the training process of DPL layer, the efficient stochastic gradient descent is used. Extensive simulations on real databases show that our CDPL-Net can deliver enhanced performance over other state-of-the-art methods.", "published": "2019-12-17T01:34:28Z", "version": 3}, {"aid": "1912.07863", "authors": ["Ye Yuan", "Wuyang Chen", "Yang Yang", "Zhangyang Wang"], "title": "In Defense of the Triplet Loss Again: Learning Robust Person Re-Identification with Fast Approximated Triplet Loss and Label Distillation", "url": "http://arxiv.org/pdf/1912.07863v2", "summary": "The comparative losses (typically, triplet loss) are appealing choices for learning person re-identification (ReID) features. However, the triplet loss is computationally much more expensive than the (practically more popular) classification loss, limiting their wider usage in massive datasets. Moreover, the abundance of label noise and outliers in ReID datasets may also put the margin-based loss in jeopardy. This work addresses the above two shortcomings of triplet loss, extending its effectiveness to large-scale ReID datasets with potentially noisy labels. We propose a fast-approximated triplet (FAT) loss, which provably converts the point-wise triplet loss into its upper bound form, consisting of a point-to-set loss term plus cluster compactness regularization. It preserves the effectiveness of triplet loss, while leading to linear complexity to the training set size. A label distillation strategy is further designed to learn refined soft-labels in place of the potentially noisy labels, from only an identified subset of confident examples, through teacher-student networks. We conduct extensive experiments on three most popular ReID benchmarks (Market-1501, DukeMTMC-reID, and MSMT17), and demonstrate that FAT loss with distilled labels lead to ReID features with remarkable accuracy, efficiency, robustness, and direct transferability to unseen datasets.", "published": "2019-12-17T08:16:45Z", "version": 2}, {"aid": "1912.08812", "authors": ["Frederico Guth", "Teofilo Emidio de-Campos"], "title": "Research Frontiers in Transfer Learning -- a systematic and bibliometric review", "url": "http://arxiv.org/pdf/1912.08812v1", "summary": "Humans can learn from very few samples, demonstrating an outstanding generalization ability that learning algorithms are still far from reaching. Currently, the most successful models demand enormous amounts of well-labeled data, which are expensive and difficult to obtain, becoming one of the biggest obstacles to the use of machine learning in practice. This scenario shows the massive potential for Transfer Learning, which aims to harness previously acquired knowledge to the learning of new tasks more effectively and efficiently. In this systematic review, we apply a quantitative method to select the main contributions to the field and make use of bibliographic coupling metrics to identify research frontiers. We further analyze the linguistic variation between the classics of the field and the frontier and map promising research directions.", "published": "2019-12-18T15:08:19Z", "version": 1}, {"aid": "1912.08795", "authors": ["Hongxu Yin", "Pavlo Molchanov", "Zhizhong Li", "Jose M. Alvarez", "Arun Mallya", "Derek Hoiem", "Niraj K. Jha", "Jan Kautz"], "title": "Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion", "url": "http://arxiv.org/pdf/1912.08795v2", "summary": "We introduce DeepInversion, a new method for synthesizing images from the image distribution used to train a deep neural network. We 'invert' a trained network (teacher) to synthesize class-conditional input images starting from random noise, without using any additional information about the training dataset. Keeping the teacher fixed, our method optimizes the input while regularizing the distribution of intermediate feature maps using information stored in the batch normalization layers of the teacher. Further, we improve the diversity of synthesized images using Adaptive DeepInversion, which maximizes the Jensen-Shannon divergence between the teacher and student network logits. The resulting synthesized images from networks trained on the CIFAR-10 and ImageNet datasets demonstrate high fidelity and degree of realism, and help enable a new breed of data-free applications - ones that do not require any real images or labeled data. We demonstrate the applicability of our proposed method to three tasks of immense practical importance -- (i) data-free network pruning, (ii) data-free knowledge transfer, and (iii) data-free continual learning. Code is available at https://github.com/NVlabs/DeepInversion", "published": "2019-12-18T18:50:10Z", "version": 2}, {"aid": "1912.08957", "authors": ["Ruoyu Sun"], "title": "Optimization for deep learning: theory and algorithms", "url": "http://arxiv.org/pdf/1912.08957v1", "summary": "When and why can a neural network be successfully trained? This article provides an overview of optimization algorithms and theory for training neural networks. First, we discuss the issue of gradient explosion/vanishing and the more general issue of undesirable spectrum, and then discuss practical solutions including careful initialization and normalization methods. Second, we review generic optimization methods used in training neural networks, such as SGD, adaptive gradient methods and distributed methods, and theoretical results for these algorithms. Third, we review existing research on the global issues of neural network training, including results on bad local minima, mode connectivity, lottery ticket hypothesis and infinite-width analysis.", "published": "2019-12-19T00:23:18Z", "version": 1}, {"aid": "1912.08998", "authors": ["Masahiro Kazama", "Yoshihiko Suhara", "Andrey Bogomolov", "Alex `Sandy' Pentland"], "title": "Understanding Human Judgments of Causality", "url": "http://arxiv.org/pdf/1912.08998v1", "summary": "Discriminating between causality and correlation is a major problem in machine learning, and theoretical tools for determining causality are still being developed. However, people commonly make causality judgments and are often correct, even in unfamiliar domains. What are humans doing to make these judgments? This paper examines differences in human experts' and non-experts' ability to attribute causality by comparing their performances to those of machine-learning algorithms. We collected human judgments by using Amazon Mechanical Turk (MTurk) and then divided the human subjects into two groups: experts and non-experts. We also prepared expert and non-expert machine algorithms based on different training of convolutional neural network (CNN) models. The results showed that human experts' judgments were similar to those made by an \"expert\" CNN model trained on a large number of examples from the target domain. The human non-experts' judgments resembled the prediction outputs of the CNN model that was trained on only the small number of examples used during the MTurk instruction. We also analyzed the differences between the expert and non-expert machine algorithms based on their neural representations to evaluate the performances, providing insight into the human experts' and non-experts' cognitive abilities.", "published": "2019-12-19T03:08:11Z", "version": 1}, {"aid": "1912.09336", "authors": ["Nilavra Bhattacharya", "Danna Gurari"], "title": "VizWiz Dataset Browser: A Tool for Visualizing Machine Learning Datasets", "url": "http://arxiv.org/pdf/1912.09336v1", "summary": "We present a visualization tool to exhaustively search and browse through a set of large-scale machine learning datasets. Built on the top of the VizWiz dataset, our dataset browser tool has the potential to support and enable a variety of qualitative and quantitative research, and open new directions for visualizing and researching with multimodal information. The tool is publicly available at https://vizwiz.org/browse.", "published": "2019-12-19T16:18:34Z", "version": 1}, {"aid": "1912.10891", "authors": ["Jingbin Liu", "Shuai Liu", "Xinyang Gu"], "title": "Soft Q Network", "url": "http://arxiv.org/pdf/1912.10891v2", "summary": "Deep Q Network (DQN) is a very successful algorithm, yet the inherent problem of reinforcement learning, i.e. the exploit-explore balance, remains. In this work, we introduce entropy regularization into DQN and propose SQN. We find that the backup equation of soft Q learning can enjoy the corrective feedback if we view the soft backup as policy improvement in the form of Q, instead of policy evaluation. We show that Soft Q Learning with Corrective Feedback (SQL-CF) underlies the on-plicy nature of SQL and the equivalence of SQL and Soft Policy Gradient (SPG). With these insights, we propose an on-policy version of deep Q learning algorithm, i.e. Q On-Policy (QOP). We experiment with QOP on a self-play environment called Google Research Football (GRF). The QOP algorithm exhibits great stability and efficiency in training GRF agents.", "published": "2019-12-20T01:55:40Z", "version": 2}, {"aid": "1912.12180", "authors": ["Jonathan Ho", "Nal Kalchbrenner", "Dirk Weissenborn", "Tim Salimans"], "title": "Axial Attention in Multidimensional Transformers", "url": "http://arxiv.org/pdf/1912.12180v1", "summary": "We propose Axial Transformers, a self-attention-based autoregressive model for images and other data organized as high dimensional tensors. Existing autoregressive models either suffer from excessively large computational resource requirements for high dimensional data, or make compromises in terms of distribution expressiveness or ease of implementation in order to decrease resource requirements. Our architecture, by contrast, maintains both full expressiveness over joint distributions over data and ease of implementation with standard deep learning frameworks, while requiring reasonable memory and computation and achieving state-of-the-art results on standard generative modeling benchmarks. Our models are based on axial attention, a simple generalization of self-attention that naturally aligns with the multiple dimensions of the tensors in both the encoding and the decoding settings. Notably the proposed structure of the layers allows for the vast majority of the context to be computed in parallel during decoding without introducing any independence assumptions. This semi-parallel structure goes a long way to making decoding from even a very large Axial Transformer broadly applicable. We demonstrate state-of-the-art results for the Axial Transformer on the ImageNet-32 and ImageNet-64 image benchmarks as well as on the BAIR Robotic Pushing video benchmark. We open source the implementation of Axial Transformers.", "published": "2019-12-20T13:27:27Z", "version": 1}, {"aid": "1912.10092", "authors": ["Cory J. Butz", "Jhonatan S. Oliveira", "Robert Peharz"], "title": "Sum-Product Network Decompilation", "url": "http://arxiv.org/pdf/1912.10092v2", "summary": "There exists a dichotomy between classical probabilistic graphical models, such as Bayesian networks (BNs), and modern tractable models, such as sum-product networks (SPNs). The former generally have intractable inference, but provide a high level of interpretability, while the latter admits a wide range of tractable inference routines, but are typically harder to interpret. Due to this dichotomy, tools to convert between BNs and SPNs are desirable. While one direction -- compiling BNs into SPNs -- is well discussed in Darwiche's seminal work on arithmetic circuit compilation, the converse direction -- decompiling SPNs into BNs -- has received surprisingly little attention.   In this paper, we fill this gap by proposing SPN2BN, an algorithm that decompiles an SPN into a BN. SPN2BN has several salient features when compared to the only other two works decompiling SPNs. Most significantly, the BNs returned by SPN2BN are minimal independence-maps that are more parsimonious with respect to the introduction of latent variables. Secondly, the output BN produced by SPN2BN can be precisely characterized with respect to a compiled BN. More specifically, a certain set of directed edges will be added to the input BN, giving what we will call the moral-closure. Lastly, it is established that our compilation-decompilation process is idempotent. This has practical significance as it limits the size of the decompiled SPN.", "published": "2019-12-20T20:39:28Z", "version": 2}, {"aid": "1912.11037", "authors": ["Ulysse C\u00f4t\u00e9-Allard", "Gabriel Gagnon-Turcotte", "Angkoon Phinyomark", "Kyrre Glette", "Erik Scheme", "Fran\u00e7ois Laviolette", "Benoit Gosselin"], "title": "Unsupervised Domain Adversarial Self-Calibration for Electromyographic-based Gesture Recognition", "url": "http://arxiv.org/pdf/1912.11037v5", "summary": "Surface electromyography (sEMG) provides an intuitive and non-invasive interface from which to control machines. However, preserving the myoelectric control system's performance over multiple days is challenging, due to the transient nature of the signals obtained with this recording technique. In practice, if the system is to remain usable, a time-consuming and periodic recalibration is necessary. In the case where the sEMG interface is employed every few days, the user might need to do this recalibration before every use. Thus, severely limiting the practicality of such a control method. Consequently, this paper proposes tackling the especially challenging task of unsupervised adaptation of sEMG signals, when multiple days have elapsed between each recording, by introducing Self-Calibrating Asynchronous Domain Adversarial Neural Network (SCADANN). SCADANN is compared with two state-of-the-art self-calibrating algorithms developed specifically for deep learning within the context of EMG-based gesture recognition and three state-of-the-art domain adversarial algorithms. The comparison is made both on an offline and a dynamic dataset (20 participants per dataset), using two different deep network architectures with two different input modalities (temporal-spatial descriptors and spectrograms). Overall, SCADANN is shown to substantially and systematically improves classification performances over no recalibration and obtains the highest average accuracy for all tested cases across all methods.", "published": "2019-12-21T17:42:26Z", "version": 5}, {"aid": "1912.10321", "authors": ["Ari Heljakka", "Yuxin Hou", "Juho Kannala", "Arno Solin"], "title": "Deep Automodulators", "url": "http://arxiv.org/pdf/1912.10321v4", "summary": "We introduce a new category of generative autoencoders called automodulators. These networks can faithfully reproduce individual real-world input images like regular autoencoders, but also generate a fused sample from an arbitrary combination of several such images, allowing instantaneous 'style-mixing' and other new applications. An automodulator decouples the data flow of decoder operations from statistical properties thereof and uses the latent vector to modulate the former by the latter, with a principled approach for mutual disentanglement of decoder layers. Prior work has explored similar decoder architecture with GANs, but their focus has been on random sampling. A corresponding autoencoder could operate on real input images. For the first time, we show how to train such a general-purpose model with sharp outputs in high resolution, using novel training techniques, demonstrated on four image data sets. Besides style-mixing, we show state-of-the-art results in autoencoder comparison, and visual image quality nearly indistinguishable from state-of-the-art GANs. We expect the automodulator variants to become a useful building block for image applications and other data domains.", "published": "2019-12-21T19:16:33Z", "version": 4}, {"aid": "2001.01686", "authors": ["Omolbanin Yazdanbakhsh", "Scott Dick"], "title": "A Deep Neuro-Fuzzy Network for Image Classification", "url": "http://arxiv.org/pdf/2001.01686v1", "summary": "The combination of neural network and fuzzy systems into neuro-fuzzy systems integrates fuzzy reasoning rules into the connectionist networks. However, the existing neuro-fuzzy systems are developed under shallow structures having lower generalization capacity. We propose the first end-to-end deep neuro-fuzzy network and investigate its application for image classification. Two new operations are developed based on definitions of Takagi-Sugeno-Kang (TSK) fuzzy model namely fuzzy inference operation and fuzzy pooling operations; stacks of these operations comprise the layers in this network. We evaluate the network on MNIST, CIFAR-10 and CIFAR-100 datasets, finding that the network has a reasonable accuracy in these benchmarks.", "published": "2019-12-22T03:28:05Z", "version": 1}, {"aid": "1912.10557", "authors": ["Vishal Monga", "Yuelong Li", "Yonina C. Eldar"], "title": "Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing", "url": "http://arxiv.org/pdf/1912.10557v3", "summary": "Deep neural networks provide unprecedented performance gains in many real world problems in signal and image processing. Despite these gains, future development and practical deployment of deep networks is hindered by their blackbox nature, i.e., lack of interpretability, and by the need for very large training sets. An emerging technique called algorithm unrolling or unfolding offers promise in eliminating these issues by providing a concrete and systematic connection between iterative algorithms that are used widely in signal processing and deep neural networks. Unrolling methods were first proposed to develop fast neural network approximations for sparse coding. More recently, this direction has attracted enormous attention and is rapidly growing both in theoretic investigations and practical applications. The growing popularity of unrolled deep networks is due in part to their potential in developing efficient, high-performance and yet interpretable network architectures from reasonable size training sets. In this article, we review algorithm unrolling for signal and image processing. We extensively cover popular techniques for algorithm unrolling in various domains of signal and image processing including imaging, vision and recognition, and speech processing. By reviewing previous works, we reveal the connections between iterative algorithms and neural networks and present recent theoretical results. Finally, we provide a discussion on current limitations of unrolling and suggest possible future research directions.", "published": "2019-12-22T23:02:18Z", "version": 3}, {"aid": "1912.10752", "authors": ["S. Balaji", "T. Kavya", "Natasha Sebastian"], "title": "Learn-able parameter guided Activation Functions", "url": "http://arxiv.org/pdf/1912.10752v1", "summary": "In this paper, we explore the concept of adding learn-able slope and mean shift parameters to an activation function to improve the total response region. The characteristics of an activation function depend highly on the value of parameters. Making the parameters learn-able, makes the activation function more dynamic and capable to adapt as per the requirements of its neighboring layers. The introduced slope parameter is independent of other parameters in the activation function. The concept was applied to ReLU to develop Dual Line and DualParametric ReLU activation function. Evaluation on MNIST and CIFAR10 show that the proposed activation function Dual Line achieves top-5 position for mean accuracy among 43 activation functions tested with LENET4, LENET5, and WideResNet architectures. This is the first time more than 40 activation functions were analyzed on MNIST andCIFAR10 dataset at the same time. The study on the distribution of positive slope parameter beta indicates that the activation function adapts as per the requirements of the neighboring layers. The study shows that model performance increases with the proposed activation functions", "published": "2019-12-23T11:54:05Z", "version": 1}, {"aid": "1912.11554", "authors": ["Du Phan", "Neeraj Pradhan", "Martin Jankowiak"], "title": "Composable Effects for Flexible and Accelerated Probabilistic Programming in NumPyro", "url": "http://arxiv.org/pdf/1912.11554v1", "summary": "NumPyro is a lightweight library that provides an alternate NumPy backend to the Pyro probabilistic programming language with the same modeling interface, language primitives and effect handling abstractions. Effect handlers allow Pyro's modeling API to be extended to NumPyro despite its being built atop a fundamentally different JAX-based functional backend. In this work, we demonstrate the power of composing Pyro's effect handlers with the program transformations that enable hardware acceleration, automatic differentiation, and vectorization in JAX. In particular, NumPyro provides an iterative formulation of the No-U-Turn Sampler (NUTS) that can be end-to-end JIT compiled, yielding an implementation that is much faster than existing alternatives in both the small and large dataset regimes.", "published": "2019-12-24T22:09:36Z", "version": 1}, {"aid": "1912.13200", "authors": ["Hanting Chen", "Yunhe Wang", "Chunjing Xu", "Boxin Shi", "Chao Xu", "Qi Tian", "Chang Xu"], "title": "AdderNet: Do We Really Need Multiplications in Deep Learning?", "url": "http://arxiv.org/pdf/1912.13200v6", "summary": "Compared with cheap addition operation, multiplication operation is of much higher computation complexity. The widely-used convolutions in deep neural networks are exactly cross-correlation to measure the similarity between input feature and convolution filters, which involves massive multiplications between float values. In this paper, we present adder networks (AdderNets) to trade these massive multiplications in deep neural networks, especially convolutional neural networks (CNNs), for much cheaper additions to reduce computation costs. In AdderNets, we take the $\\ell_1$-norm distance between filters and input feature as the output response. The influence of this new similarity measure on the optimization of neural network have been thoroughly analyzed. To achieve a better performance, we develop a special back-propagation approach for AdderNets by investigating the full-precision gradient. We then propose an adaptive learning rate strategy to enhance the training procedure of AdderNets according to the magnitude of each neuron's gradient. As a result, the proposed AdderNets can achieve 74.9% Top-1 accuracy 91.7% Top-5 accuracy using ResNet-50 on the ImageNet dataset without any multiplication in convolution layer. The codes are publicly available at: https://github.com/huaweinoah/AdderNet.", "published": "2019-12-31T06:56:47Z", "version": 6}, {"aid": "2001.00215", "authors": ["Joshua Peeples", "Weihuang Xu", "Alina Zare"], "title": "Histogram Layers for Texture Analysis", "url": "http://arxiv.org/pdf/2001.00215v12", "summary": "An essential aspect of texture analysis is the extraction of features that describe the distribution of values in local, spatial regions. We present a localized histogram layer for artificial neural networks. Instead of computing global histograms as done previously, the proposed histogram layer directly computes the local, spatial distribution of features for texture analysis and parameters for the layer are estimated during backpropagation. We compare our method with state-of-the-art texture encoding methods such as the Deep Encoding Network Pooling, Deep Texture Encoding Network, Fisher Vector convolutional neural network, and Multi-level Texture Encoding and Representation on three material/texture datasets: (1) the Describable Texture Dataset; (2) an extension of the ground terrain in outdoor scenes; (3) and a subset of the Materials in Context dataset. Results indicate that the inclusion of the proposed histogram layer improves performance. The source code for the histogram layer is publicly available: https://github.com/GatorSense/Histogram_Layer.", "published": "2020-01-01T14:41:54Z", "version": 12}, {"aid": "2001.01034", "authors": ["Yifei Li", "Kuangyan Song", "Yiming Sun", "Liao Zhu"], "title": "FrequentNet: A Novel Interpretable Deep Learning Model for Image Classification", "url": "http://arxiv.org/pdf/2001.01034v4", "summary": "This paper has proposed a new baseline deep learning model of more benefits for image classification. Different from the convolutional neural network(CNN) practice where filters are trained by back propagation to represent different patterns of an image, we are inspired by a method called \"PCANet\" in \"PCANet: A Simple Deep Learning Baseline for Image Classification?\" to choose filter vectors from basis vectors in frequency domain like Fourier coefficients or wavelets without back propagation. Researchers have demonstrated that those basis in frequency domain can usually provide physical insights, which adds to the interpretability of the model by analyzing the frequencies selected. Besides, the training process will also be more time efficient, mathematically clear and interpretable compared with the \"black-box\" training process of CNN.", "published": "2020-01-04T04:31:32Z", "version": 4}, {"aid": "2001.03288", "authors": ["Yury Pisarchyk", "Juhyun Lee"], "title": "Efficient Memory Management for Deep Neural Net Inference", "url": "http://arxiv.org/pdf/2001.03288v3", "summary": "While deep neural net inference was considered a task for servers only, latest advances in technology allow the task of inference to be moved to mobile and embedded devices, desired for various reasons ranging from latency to privacy. These devices are not only limited by their compute power and battery, but also by their inferior physical memory and cache, and thus, an efficient memory manager becomes a crucial component for deep neural net inference at the edge. We explore various strategies to smartly share memory buffers among intermediate tensors in deep neural nets. Employing these can result in up to 11% smaller memory footprint than the state of the art.", "published": "2020-01-10T02:45:41Z", "version": 3}, {"aid": "2001.03354", "authors": ["Chan Li", "Haiping Huang"], "title": "Learning credit assignment", "url": "http://arxiv.org/pdf/2001.03354v2", "summary": "Deep learning has achieved impressive prediction accuracies in a variety of scientific and industrial domains. However, the nested non-linear feature of deep learning makes the learning highly non-transparent, i.e., it is still unknown how the learning coordinates a huge number of parameters to achieve a decision making. To explain this hierarchical credit assignment, we propose a mean-field learning model by assuming that an ensemble of sub-networks, rather than a single network, are trained for a classification task. Surprisingly, our model reveals that apart from some deterministic synaptic weights connecting two neurons at neighboring layers, there exist a large number of connections that can be absent, and other connections can allow for a broad distribution of their weight values. Therefore, synaptic connections can be classified into three categories: very important ones, unimportant ones, and those of variability that may partially encode nuisance factors. Therefore, our model learns the credit assignment leading to the decision, and predicts an ensemble of sub-networks that can accomplish the same task, thereby providing insights toward understanding the macroscopic behavior of deep learning through the lens of distinct roles of synaptic weights.", "published": "2020-01-10T09:06:46Z", "version": 2}, {"aid": "2001.03698", "authors": ["Dongsheng An", "Yang Guo", "Min Zhang", "Xin Qi", "Na Lei", "Shing-Tung Yau", "Xianfeng Gu"], "title": "AE-OT-GAN: Training GANs from data specific latent distribution", "url": "http://arxiv.org/pdf/2001.03698v2", "summary": "Though generative adversarial networks (GANs) areprominent models to generate realistic and crisp images,they often encounter the mode collapse problems and arehard to train, which comes from approximating the intrinsicdiscontinuous distribution transform map with continuousDNNs. The recently proposed AE-OT model addresses thisproblem by explicitly computing the discontinuous distribu-tion transform map through solving a semi-discrete optimaltransport (OT) map in the latent space of the autoencoder.However the generated images are blurry. In this paper, wepropose the AE-OT-GAN model to utilize the advantages ofthe both models: generate high quality images and at thesame time overcome the mode collapse/mixture problems.Specifically, we first faithfully embed the low dimensionalimage manifold into the latent space by training an autoen-coder (AE). Then we compute the optimal transport (OT)map that pushes forward the uniform distribution to the la-tent distribution supported on the latent manifold. Finally,our GAN model is trained to generate high quality imagesfrom the latent distribution, the distribution transform mapfrom which to the empirical data distribution will be con-tinuous. The paired data between the latent code and thereal images gives us further constriction about the generator.Experiments on simple MNIST dataset and complex datasetslike Cifar-10 and CelebA show the efficacy and efficiency ofour proposed method.", "published": "2020-01-11T01:18:00Z", "version": 2}, {"aid": "2001.04147", "authors": ["Andrzej Bedychaj", "Przemys\u0142aw Spurek", "Aleksandra Nowak", "Jacek Tabor"], "title": "WICA: nonlinear weighted ICA", "url": "http://arxiv.org/pdf/2001.04147v2", "summary": "Independent Component Analysis (ICA) aims to find a coordinate system in which the components of the data are independent. In this paper we construct a new nonlinear ICA model, called WICA, which obtains better and more stable results than other algorithms. A crucial tool is given by a new efficient method of verifying nonlinear dependence with the use of computation of correlation coefficients for normally weighted data. In addition, authors propose a new baseline nonlinear mixing to perform comparable experiments, and a~reliable measure which allows fair comparison of nonlinear models. Our code for WICA is available on Github https://github.com/gmum/wica.", "published": "2020-01-13T10:38:03Z", "version": 2}, {"aid": "2001.04418", "authors": ["Michiel van der Meer", "Matteo Pirotta", "Elia Bruni"], "title": "Exploiting Language Instructions for Interpretable and Compositional Reinforcement Learning", "url": "http://arxiv.org/pdf/2001.04418v1", "summary": "In this work, we present an alternative approach to making an agent compositional through the use of a diagnostic classifier. Because of the need for explainable agents in automated decision processes, we attempt to interpret the latent space from an RL agent to identify its current objective in a complex language instruction. Results show that the classification process causes changes in the hidden states which makes them more easily interpretable, but also causes a shift in zero-shot performance to novel instructions. Lastly, we limit the supervisory signal on the classification, and observe a similar but less notable effect.", "published": "2020-01-13T17:35:56Z", "version": 1}, {"aid": "2001.05005", "authors": ["Erich Kobler", "Alexander Effland", "Karl Kunisch", "Thomas Pock"], "title": "Total Deep Variation for Linear Inverse Problems", "url": "http://arxiv.org/pdf/2001.05005v2", "summary": "Diverse inverse problems in imaging can be cast as variational problems composed of a task-specific data fidelity term and a regularization term. In this paper, we propose a novel learnable general-purpose regularizer exploiting recent architectural design patterns from deep learning. We cast the learning problem as a discrete sampled optimal control problem, for which we derive the adjoint state equations and an optimality condition. By exploiting the variational structure of our approach, we perform a sensitivity analysis with respect to the learned parameters obtained from different training datasets. Moreover, we carry out a nonlinear eigenfunction analysis, which reveals interesting properties of the learned regularizer. We show state-of-the-art performance for classical image restoration and medical image reconstruction problems.", "published": "2020-01-14T19:01:50Z", "version": 2}, {"aid": "2001.05868", "authors": ["Fanxu Meng", "Hao Cheng", "Ke Li", "Zhixin Xu", "Rongrong Ji", "Xing Sun", "Gaungming Lu"], "title": "Filter Grafting for Deep Neural Networks", "url": "http://arxiv.org/pdf/2001.05868v3", "summary": "This paper proposes a new learning paradigm called filter grafting, which aims to improve the representation capability of Deep Neural Networks (DNNs). The motivation is that DNNs have unimportant (invalid) filters (e.g., l1 norm close to 0). These filters limit the potential of DNNs since they are identified as having little effect on the network. While filter pruning removes these invalid filters for efficiency consideration, filter grafting re-activates them from an accuracy boosting perspective. The activation is processed by grafting external information (weights) into invalid filters. To better perform the grafting process, we develop an entropy-based criterion to measure the information of filters and an adaptive weighting strategy for balancing the grafted information among networks. After the grafting operation, the network has very few invalid filters compared with its untouched state, enpowering the model with more representation capacity. We also perform extensive experiments on the classification and recognition tasks to show the superiority of our method. For example, the grafted MobileNetV2 outperforms the non-grafted MobileNetV2 by about 7 percent on CIFAR-100 dataset. Code is available at https://github.com/fxmeng/filter-grafting.git.", "published": "2020-01-15T03:18:57Z", "version": 3}, {"aid": "2001.06769", "authors": ["Kaiyu Shan", "Yongtao Wang", "Zhuoying Wang", "Tingting Liang", "Zhi Tang", "Ying Chen", "Yangyan Li"], "title": "MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion", "url": "http://arxiv.org/pdf/2001.06769v3", "summary": "To efficiently extract spatiotemporal features of video for action recognition, most state-of-the-art methods integrate 1D temporal convolution into a conventional 2D CNN backbone. However, they all exploit 1D temporal convolution of fixed kernel size (i.e., 3) in the network building block, thus have suboptimal temporal modeling capability to handle both long-term and short-term actions. To address this problem, we first investigate the impacts of different kernel sizes for the 1D temporal convolutional filters. Then, we propose a simple yet efficient operation called Mixed Temporal Convolution (MixTConv), which consists of multiple depthwise 1D convolutional filters with different kernel sizes. By plugging MixTConv into the conventional 2D CNN backbone ResNet-50, we further propose an efficient and effective network architecture named MSTNet for action recognition, and achieve state-of-the-art results on multiple benchmarks.", "published": "2020-01-19T04:21:51Z", "version": 3}, {"aid": "2001.06782", "authors": ["Tianhe Yu", "Saurabh Kumar", "Abhishek Gupta", "Sergey Levine", "Karol Hausman", "Chelsea Finn"], "title": "Gradient Surgery for Multi-Task Learning", "url": "http://arxiv.org/pdf/2001.06782v4", "summary": "While deep learning and deep reinforcement learning (RL) systems have demonstrated impressive results in domains such as image classification, game playing, and robotic control, data efficiency remains a major challenge. Multi-task learning has emerged as a promising approach for sharing structure across multiple tasks to enable more efficient learning. However, the multi-task setting presents a number of optimization challenges, making it difficult to realize large efficiency gains compared to learning tasks independently. The reasons why multi-task learning is so challenging compared to single-task learning are not fully understood. In this work, we identify a set of three conditions of the multi-task optimization landscape that cause detrimental gradient interference, and develop a simple yet general approach for avoiding such interference between task gradients. We propose a form of gradient surgery that projects a task's gradient onto the normal plane of the gradient of any other task that has a conflicting gradient. On a series of challenging multi-task supervised and multi-task RL problems, this approach leads to substantial gains in efficiency and performance. Further, it is model-agnostic and can be combined with previously-proposed multi-task architectures for enhanced performance.", "published": "2020-01-19T06:33:47Z", "version": 4}, {"aid": "2001.06810", "authors": ["Xiankai Lu", "Wenguan Wang", "Chao Ma", "Jianbing Shen", "Ling Shao", "Fatih Porikli"], "title": "See More, Know More: Unsupervised Video Object Segmentation with Co-Attention Siamese Networks", "url": "http://arxiv.org/pdf/2001.06810v1", "summary": "We introduce a novel network, called CO-attention Siamese Network (COSNet), to address the unsupervised video object segmentation task from a holistic view. We emphasize the importance of inherent correlation among video frames and incorporate a global co-attention mechanism to improve further the state-of-the-art deep learning based solutions that primarily focus on learning discriminative foreground representations over appearance and motion in short-term temporal segments. The co-attention layers in our network provide efficient and competent stages for capturing global correlations and scene context by jointly computing and appending co-attention responses into a joint feature space. We train COSNet with pairs of video frames, which naturally augments training data and allows increased learning capacity. During the segmentation stage, the co-attention model encodes useful information by processing multiple reference frames together, which is leveraged to infer the frequently reappearing and salient foreground objects better. We propose a unified and end-to-end trainable framework where different co-attention variants can be derived for mining the rich context within videos. Our extensive experiments over three large benchmarks manifest that COSNet outperforms the current alternatives by a large margin.", "published": "2020-01-19T11:10:39Z", "version": 1}, {"aid": "2001.06838", "authors": ["Junjie Yan", "Ruosi Wan", "Xiangyu Zhang", "Wei Zhang", "Yichen Wei", "Jian Sun"], "title": "Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization", "url": "http://arxiv.org/pdf/2001.06838v2", "summary": "Batch Normalization (BN) is one of the most widely used techniques in Deep Learning field. But its performance can awfully degrade with insufficient batch size. This weakness limits the usage of BN on many computer vision tasks like detection or segmentation, where batch size is usually small due to the constraint of memory consumption. Therefore many modified normalization techniques have been proposed, which either fail to restore the performance of BN completely, or have to introduce additional nonlinear operations in inference procedure and increase huge consumption. In this paper, we reveal that there are two extra batch statistics involved in backward propagation of BN, on which has never been well discussed before. The extra batch statistics associated with gradients also can severely affect the training of deep neural network. Based on our analysis, we propose a novel normalization method, named Moving Average Batch Normalization (MABN). MABN can completely restore the performance of vanilla BN in small batch cases, without introducing any additional nonlinear operations in inference procedure. We prove the benefits of MABN by both theoretical analysis and experiments. Our experiments demonstrate the effectiveness of MABN in multiple computer vision tasks including ImageNet and COCO. The code has been released in https://github.com/megvii-model/MABN.", "published": "2020-01-19T14:41:22Z", "version": 2}, {"aid": "2001.06881", "authors": ["Maurizio De Pitt\u00e0"], "title": "Neuron-Glial Interactions", "url": "http://arxiv.org/pdf/2001.06881v1", "summary": "Although lagging behind classical computational neuroscience, theoretical and computational approaches are beginning to emerge to characterize different aspects of neuron-glial interactions. This chapter aims to provide essential knowledge on neuron-glial interactions in the mammalian brain, leveraging on computational studies that focus on structure (anatomy) and function (physiology) of such interactions in the healthy brain. Although our understanding of the need of neuron-glial interactions in the brain is still at its infancy, being mostly based on predictions that await for experimental validation, simple general modeling arguments borrowed from control theory are introduced to support the importance of including such interactions in traditional neuron-based modeling paradigms.", "published": "2020-01-19T18:30:07Z", "version": 1}, {"aid": "2001.07203", "authors": ["Lancelot Da Costa", "Thomas Parr", "Noor Sajid", "Sebastijan Veselic", "Victorita Neacsu", "Karl Friston"], "title": "Active inference on discrete state-spaces: a synthesis", "url": "http://arxiv.org/pdf/2001.07203v2", "summary": "Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.", "published": "2020-01-20T18:24:21Z", "version": 2}, {"aid": "2001.07342", "authors": ["Rajath S", "Sumukh Aithal K", "Natarajan Subramanyam"], "title": "Transfer Learning using Neural Ordinary Differential Equations", "url": "http://arxiv.org/pdf/2001.07342v1", "summary": "A concept of using Neural Ordinary Differential Equations(NODE) for Transfer Learning has been introduced. In this paper we use the EfficientNets to explore transfer learning on CIFAR-10 dataset. We use NODE for fine-tuning our model. Using NODE for fine tuning provides more stability during training and validation.These continuous depth blocks can also have a trade off between numerical precision and speed .Using Neural ODEs for transfer learning has resulted in much stable convergence of the loss function.", "published": "2020-01-21T04:59:08Z", "version": 1}, {"aid": "2001.08028", "authors": ["Lancelot Da Costa", "Thomas Parr", "Biswa Sengupta", "Karl Friston"], "title": "Neural dynamics under active inference: plausibility and efficiency of information processing", "url": "http://arxiv.org/pdf/2001.08028v2", "summary": "Active inference is a normative framework for explaining behaviour under the free energy principle -- a theory of self-organisation originating in neuroscience. It specifies neuronal dynamics for state-estimation in terms of a descent on (variational) free energy -- a measure of the fit between an internal (generative) model and sensory observations. The free energy gradient is a prediction error -- plausibly encoded in the average membrane potentials of neuronal populations. Conversely, the expected probability of a state can be expressed in terms of neuronal firing rates. We show that this is consistent with current models of neuronal dynamics and establish face validity by synthesising plausible electrophysiological responses. We then show that these neuronal dynamics approximate natural gradient descent, a well-known optimisation algorithm from information geometry that follows the steepest descent of the objective in information space. We compare the information length of belief updating in both schemes, a measure of the distance traveled in information space that has a direct interpretation in terms of metabolic cost. We show that neural dynamics under active inference are metabolically efficient and suggest that neural representations in biological agents may evolve by approximating steepest descent in information space towards the point of optimal inference.", "published": "2020-01-22T14:15:05Z", "version": 2}, {"aid": "2001.08248", "authors": ["Md Amirul Islam", "Sen Jia", "Neil D. B. Bruce"], "title": "How Much Position Information Do Convolutional Neural Networks Encode?", "url": "http://arxiv.org/pdf/2001.08248v1", "summary": "In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.", "published": "2020-01-22T19:44:43Z", "version": 1}, {"aid": "2001.08559", "authors": ["Zehao Wang", "Kaili Wang", "Tinne Tuytelaars", "Jose Oramas"], "title": "Information Compensation for Deep Conditional Generative Networks", "url": "http://arxiv.org/pdf/2001.08559v3", "summary": "In recent years, unsupervised/weakly-supervised conditional generative adversarial networks (GANs) have achieved many successes on the task of modeling and generating data. However, one of their weaknesses lies in their poor ability to separate, or disentangle, the different factors that characterize the representation encoded in their latent space. To address this issue, we propose a novel structure for unsupervised conditional GANs powered by a novel Information Compensation Connection (IC-Connection). The proposed IC-Connection enables GANs to compensate for information loss incurred during deconvolution operations. In addition, to quantify the degree of disentanglement on both discrete and continuous latent variables, we design a novel evaluation procedure. Our empirical results suggest that our method achieves better disentanglement compared to the state-of-the-art GANs in a conditional generation setting.", "published": "2020-01-23T14:39:53Z", "version": 3}, {"aid": "2001.08578", "authors": ["Mohammed Abuhamad", "Ahmed Abusnaina", "DaeHun Nyang", "David Mohaisen"], "title": "Sensor-based Continuous Authentication of Smartphones' Users Using Behavioral Biometrics: A Contemporary Survey", "url": "http://arxiv.org/pdf/2001.08578v2", "summary": "Mobile devices and technologies have become increasingly popular, offering comparable storage and computational capabilities to desktop computers allowing users to store and interact with sensitive and private information. The security and protection of such personal information are becoming more and more important since mobile devices are vulnerable to unauthorized access or theft. User authentication is a task of paramount importance that grants access to legitimate users at the point-of-entry and continuously through the usage session. This task is made possible with today's smartphones' embedded sensors that enable continuous and implicit user authentication by capturing behavioral biometrics and traits. In this paper, we survey more than 140 recent behavioral biometric-based approaches for continuous user authentication, including motion-based methods (28 studies), gait-based methods (19 studies), keystroke dynamics-based methods (20 studies), touch gesture-based methods (29 studies), voice-based methods (16 studies), and multimodal-based methods (34 studies). The survey provides an overview of the current state-of-the-art approaches for continuous user authentication using behavioral biometrics captured by smartphones' embedded sensors, including insights and open challenges for adoption, usability, and performance.", "published": "2020-01-23T15:07:28Z", "version": 2}, {"aid": "2001.08680", "authors": ["Zijie Zhuang", "Longhui Wei", "Lingxi Xie", "Tianyu Zhang", "Hengheng Zhang", "Haozhe Wu", "Haizhou Ai", "Qi Tian"], "title": "Rethinking the Distribution Gap of Person Re-identification with Camera-based Batch Normalization", "url": "http://arxiv.org/pdf/2001.08680v3", "summary": "The fundamental difficulty in person re-identification (ReID) lies in learning the correspondence among individual cameras. It strongly demands costly inter-camera annotations, yet the trained models are not guaranteed to transfer well to previously unseen cameras. These problems significantly limit the application of ReID. This paper rethinks the working mechanism of conventional ReID approaches and puts forward a new solution. With an effective operator named Camera-based Batch Normalization (CBN), we force the image data of all cameras to fall onto the same subspace, so that the distribution gap between any camera pair is largely shrunk. This alignment brings two benefits. First, the trained model enjoys better abilities to generalize across scenarios with unseen cameras as well as transfer across multiple training sets. Second, we can rely on intra-camera annotations, which have been undervalued before due to the lack of cross-camera information, to achieve competitive ReID performance. Experiments on a wide range of ReID tasks demonstrate the effectiveness of our approach. The code is available at https://github.com/automan000/Camera-based-Person-ReID.", "published": "2020-01-23T17:22:34Z", "version": 3}, {"aid": "2001.09219", "authors": ["Bhavya Ghai", "Q. Vera Liao", "Yunfeng Zhang", "Rachel Bellamy", "Klaus Mueller"], "title": "Explainable Active Learning (XAL): An Empirical Study of How Local Explanations Impact Annotator Experience", "url": "http://arxiv.org/pdf/2001.09219v4", "summary": "The wide adoption of Machine Learning technologies has created a rapidly growing demand for people who can train ML models. Some advocated the term \"machine teacher\" to refer to the role of people who inject domain knowledge into ML models. One promising learning paradigm is Active Learning (AL), by which the model intelligently selects instances to query the machine teacher for labels. However, in current AL settings, the human-AI interface remains minimal and opaque. We begin considering AI explanations as a core element of the human-AI interface for teaching machines. When a human student learns, it is a common pattern to present one's own reasoning and solicit feedback from the teacher. When a ML model learns and still makes mistakes, the human teacher should be able to understand the reasoning underlying the mistakes. When the model matures, the machine teacher should be able to recognize its progress in order to trust and feel confident about their teaching outcome. Toward this vision, we propose a novel paradigm of explainable active learning (XAL), by introducing techniques from the recently surging field of explainable AI (XAI) into an AL setting. We conducted an empirical study comparing the model learning outcomes, feedback content and experience with XAL, to that of traditional AL and coactive learning (providing the model's prediction without the explanation). Our study shows benefits of AI explanation as interfaces for machine teaching--supporting trust calibration and enabling rich forms of teaching feedback, and potential drawbacks--anchoring effect with the model judgment and cognitive workload. Our study also reveals important individual factors that mediate a machine teacher's reception to AI explanations, including task knowledge, AI experience and need for cognition. By reflecting on the results, we suggest future directions and design implications for XAL.", "published": "2020-01-24T22:52:18Z", "version": 4}, {"aid": "2001.09424", "authors": ["Matteo Demuru", "Matteo Fraschini"], "title": "EEG fingerprinting: subject specific signature based on the aperiodic component of power spectrum", "url": "http://arxiv.org/pdf/2001.09424v1", "summary": "During the last few years, there has been growing interest in the effects induced by individual variability on activation patterns and brain connectivity. The practical implications of individual variability is of basic relevance for both group level and subject level studies. The Electroencephalogram (EEG), still represents one of the most used recording techniques to investigate a wide range of brain related features. In this work, we aim to estimate the effect of individual variability on a set of very simple and easily interpretable features extracted from the EEG power spectra. In particular, in an identification scenario, we investigated how the aperiodic (1/f background) component of the EEG power spectra can accurately identify subjects from a large EEG dataset. The results of this study show that the aperiodic component of the EEG signal is characterized by strong subject-specific properties, that this feature is consistent across different experimental conditions (eyes-open and eyes-closed) and outperforms the canonically-defined frequency bands. These findings suggest that the simple features (slope and offset) extracted from the aperiodic component of the EEG signal are sensitive to individual traits and may help to characterize and make inferences at single subject level.", "published": "2020-01-26T09:04:26Z", "version": 1}, {"aid": "2002.00556", "authors": ["Jeong-Hyun Cho", "Ji-Hoon Jeong", "Dong-Joo Kim", "Seong-Whan Lee"], "title": "A novel approach to classify natural grasp actions by estimating muscle activity patterns from EEG signals", "url": "http://arxiv.org/pdf/2002.00556v1", "summary": "Developing electroencephalogram (EEG) based brain-computer interface (BCI) systems is challenging. In this study, we analyzed natural grasp actions from EEG. Ten healthy subjects participated in this experiment. They executed and imagined three sustained grasp actions. We proposed a novel approach which estimates muscle activity patterns from EEG signals to improve the overall classification accuracy. For implementation, we have recorded EEG and electromyogram (EMG) simultaneously. Using the similarity of the estimated pattern from EEG signals compare to the activity pattern from EMG signals showed higher classification accuracy than competitive methods. As a result, we obtained the average classification accuracy of 63.89($\\pm$7.54)% for actual movement and 46.96($\\pm$15.30)% for motor imagery. These are 21.59% and 5.66% higher than the result of the competitive model, respectively. This result is encouraging, and the proposed method could potentially be used in future applications, such as a BCI-driven robot control for handling various daily use objects.", "published": "2020-02-03T04:40:17Z", "version": 1}, {"aid": "2002.00623", "authors": ["Magomed Yu. Malsagov", "Emil M. Khayrov", "Maria M. Pushkareva", "Iakov M. Karandashev"], "title": "Exponential discretization of weights of neural network connections in pre-trained neural networks", "url": "http://arxiv.org/pdf/2002.00623v1", "summary": "To reduce random access memory (RAM) requirements and to increase speed of recognition algorithms we consider a weight discretization problem for trained neural networks. We show that an exponential discretization is preferable to a linear discretization since it allows one to achieve the same accuracy when the number of bits is 1 or 2 less. The quality of the neural network VGG-16 is already satisfactory (top5 accuracy 69%) in the case of 3 bit exponential discretization. The ResNet50 neural network shows top5 accuracy 84% at 4 bits. Other neural networks perform fairly well at 5 bits (top5 accuracies of Xception, Inception-v3, and MobileNet-v2 top5 were 87%, 90%, and 77%, respectively). At less number of bits, the accuracy decreases rapidly.", "published": "2020-02-03T09:41:24Z", "version": 1}, {"aid": "2002.02342", "authors": ["Xiaoliang Luo", "Brett D. Roads", "Bradley C. Love"], "title": "The Costs and Benefits of Goal-Directed Attention in Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2002.02342v3", "summary": "People deploy top-down, goal-directed attention to accomplish tasks, such as finding lost keys. By tuning the visual system to relevant information sources, object recognition can become more efficient (a benefit) and more biased toward the target (a potential cost). Motivated by selective attention in categorisation models, we developed a goal-directed attention mechanism that can process naturalistic (photographic) stimuli. Our attention mechanism can be incorporated into any existing deep convolutional neural network (DCNNs). The processing stages in DCNNs have been related to ventral visual stream. In that light, our attentional mechanism incorporates top-down influences from prefrontal cortex (PFC) to support goal-directed behaviour. Akin to how attention weights in categorisation models warp representational spaces, we introduce a layer of attention weights to the mid-level of a DCNN that amplify or attenuate activity to further a goal. We evaluated the attentional mechanism using photographic stimuli, varying the attentional target. We found that increasing goal-directed attention has benefits (increasing hit rates) and costs (increasing false alarm rates). At a moderate level, attention improves sensitivity (i.e., increases $d^\\prime$) at only a moderate increase in bias for tasks involving standard images, blended images, and natural adversarial images chosen to fool DCNNs. These results suggest that goal-directed attention can reconfigure general-purpose DCNNs to better suit the current task goal, much like PFC modulates activity along the ventral stream. In addition to being more parsimonious and brain consistent, the mid-level attention approach performed better than a standard machine learning approach for transfer learning, namely retraining the final network layer to accommodate the new task.", "published": "2020-02-06T16:42:00Z", "version": 3}, {"aid": "2002.03231", "authors": ["Aditya Kusupati", "Vivek Ramanujan", "Raghav Somani", "Mitchell Wortsman", "Prateek Jain", "Sham Kakade", "Ali Farhadi"], "title": "Soft Threshold Weight Reparameterization for Learnable Sparsity", "url": "http://arxiv.org/pdf/2002.03231v9", "summary": "Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus of maximizing prediction accuracy given an overall parameter budget. Existing methods rely on uniform or heuristic non-uniform sparsity budgets which have sub-optimal layer-wise parameter allocation resulting in a) lower prediction accuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold Reparameterization (STR), a novel use of the soft-threshold operator on DNN weights. STR smoothly induces sparsity while learning pruning thresholds thereby obtaining a non-uniform sparsity budget. Our method achieves state-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and MobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that empirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy over existing results by up to 10% in the ultra sparse (99%) regime and can also be used to induce low-rank (structured sparsity) in RNNs. In short, STR is a simple mechanism which learns effective sparsity budgets that contrast with popular heuristics. Code, pretrained models and sparsity budgets are at https://github.com/RAIVNLab/STR.", "published": "2020-02-08T21:31:25Z", "version": 9}, {"aid": "2002.04688", "authors": ["Jeremy Howard", "Sylvain Gugger"], "title": "fastai: A Layered API for Deep Learning", "url": "http://arxiv.org/pdf/2002.04688v2", "summary": "fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/", "published": "2020-02-11T21:16:48Z", "version": 2}, {"aid": "2002.05709", "authors": ["Ting Chen", "Simon Kornblith", "Mohammad Norouzi", "Geoffrey Hinton"], "title": "A Simple Framework for Contrastive Learning of Visual Representations", "url": "http://arxiv.org/pdf/2002.05709v3", "summary": "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels.", "published": "2020-02-13T18:50:45Z", "version": 3}, {"aid": "2002.06100", "authors": ["Emile van Krieken", "Erman Acar", "Frank van Harmelen"], "title": "Analyzing Differentiable Fuzzy Logic Operators", "url": "http://arxiv.org/pdf/2002.06100v2", "summary": "The AI community is increasingly putting its attention towards combining symbolic and neural approaches, as it is often argued that the strengths and weaknesses of these approaches are complementary. One recent trend in the literature are weakly supervised learning techniques that employ operators from fuzzy logics. In particular, these use prior background knowledge described in such logics to help the training of a neural network from unlabeled and noisy data. By interpreting logical symbols using neural networks, this background knowledge can be added to regular loss functions, hence making reasoning a part of learning. We study, both formally and empirically, how a large collection of logical operators from the fuzzy logic literature behave in a differentiable learning setting. We find that many of these operators, including some of the most well-known, are highly unsuitable in this setting. A further finding concerns the treatment of implication in these fuzzy logics, and shows a strong imbalance between gradients driven by the antecedent and the consequent of the implication. Furthermore, we introduce a new family of fuzzy implications (called sigmoidal implications) to tackle this phenomenon. Finally, we empirically show that it is possible to use Differentiable Fuzzy Logics for semi-supervised learning, and compare how different operators behave in practice. We find that, to achieve the largest performance improvement over a supervised baseline, we have to resort to non-standard combinations of logical operators which perform well in learning, but no longer satisfy the usual logical laws.", "published": "2020-02-14T16:11:36Z", "version": 2}, {"aid": "2002.06642", "authors": ["Tab Memmott", "Aziz Ko\u00e7anao\u011fullar\u0131", "Matthew Lawhead", "Daniel Klee", "Shiran Dudy", "Melanie Fried-Oken", "Barry Oken"], "title": "BciPy: Brain-Computer Interface Software in Python", "url": "http://arxiv.org/pdf/2002.06642v1", "summary": "There are high technological and software demands associated with conducting brain-computer interface (BCI) research. In order to accelerate the development and accessibility of BCI, it is worthwhile to focus on open-source and desired tooling. Python, a prominent computer language, has emerged as a language of choice for many research and engineering purposes. In this manuscript, we present BciPy, an open-source, Python-based software for conducting BCI research. It was developed with a focus on restoring communication using event-related potential (ERP) spelling interfaces, however, it may be used for other non-spelling and non-ERP BCI paradigms. Major modules in this system include support for data acquisition, data queries, stimuli presentation, signal processing, signal viewing and modeling, language modeling, task building, and a simple Graphical User Interface (GUI).", "published": "2020-02-16T18:36:43Z", "version": 1}, {"aid": "2002.08473", "authors": ["Karsten Roth", "Timo Milbich", "Samarth Sinha", "Prateek Gupta", "Bj\u00f6rn Ommer", "Joseph Paul Cohen"], "title": "Revisiting Training Strategies and Generalization Performance in Deep Metric Learning", "url": "http://arxiv.org/pdf/2002.08473v9", "summary": "Deep Metric Learning (DML) is arguably one of the most influential lines of research for learning visual similarities with many proposed approaches every year. Although the field benefits from the rapid progress, the divergence in training protocols, architectures, and parameter choices make an unbiased comparison difficult. To provide a consistent reference point, we revisit the most widely used DML objective functions and conduct a study of the crucial parameter choices as well as the commonly neglected mini-batch sampling process. Under consistent comparison, DML objectives show much higher saturation than indicated by literature. Further based on our analysis, we uncover a correlation between the embedding space density and compression to the generalization performance of DML models. Exploiting these insights, we propose a simple, yet effective, training regularization to reliably boost the performance of ranking-based DML models on various standard benchmark datasets. Code and a publicly accessible WandB-repo are available at https://github.com/Confusezius/Revisiting_Deep_Metric_Learning_PyTorch.", "published": "2020-02-19T22:16:12Z", "version": 9}, {"aid": "2003.00880", "authors": ["Stanton R. Price", "Steven R. Price", "Derek T. Anderson"], "title": "Introducing Fuzzy Layers for Deep Learning", "url": "http://arxiv.org/pdf/2003.00880v1", "summary": "Many state-of-the-art technologies developed in recent years have been influenced by machine learning to some extent. Most popular at the time of this writing are artificial intelligence methodologies that fall under the umbrella of deep learning. Deep learning has been shown across many applications to be extremely powerful and capable of handling problems that possess great complexity and difficulty. In this work, we introduce a new layer to deep learning: the fuzzy layer. Traditionally, the network architecture of neural networks is composed of an input layer, some combination of hidden layers, and an output layer. We propose the introduction of fuzzy layers into the deep learning architecture to exploit the powerful aggregation properties expressed through fuzzy methodologies, such as the Choquet and Sugueno fuzzy integrals. To date, fuzzy approaches taken to deep learning have been through the application of various fusion strategies at the decision level to aggregate outputs from state-of-the-art pre-trained models, e.g., AlexNet, VGG16, GoogLeNet, Inception-v3, ResNet-18, etc. While these strategies have been shown to improve accuracy performance for image classification tasks, none have explored the use of fuzzified intermediate, or hidden, layers. Herein, we present a new deep learning strategy that incorporates fuzzy strategies into the deep learning architecture focused on the application of semantic segmentation using per-pixel classification. Experiments are conducted on a benchmark data set as well as a data set collected via an unmanned aerial system at a U.S. Army test site for the task of automatic road segmentation, and preliminary results are promising.", "published": "2020-02-21T19:33:30Z", "version": 1}, {"aid": "2002.10319", "authors": ["Lang Huang", "Chao Zhang", "Hongyang Zhang"], "title": "Self-Adaptive Training: beyond Empirical Risk Minimization", "url": "http://arxiv.org/pdf/2002.10319v2", "summary": "We propose self-adaptive training---a new training algorithm that dynamically corrects problematic training labels by model predictions without incurring extra computational cost---to improve generalization of deep learning for potentially corrupted training data. This problem is crucial towards robustly learning from data that are corrupted by, e.g., label noises and out-of-distribution samples. The standard empirical risk minimization (ERM) for such data, however, may easily overfit noises and thus suffers from sub-optimal performance. In this paper, we observe that model predictions can substantially benefit the training process: self-adaptive training significantly improves generalization over ERM under various levels of noises, and mitigates the overfitting issue in both natural and adversarial training. We evaluate the error-capacity curve of self-adaptive training: the test error is monotonously decreasing w.r.t. model capacity. This is in sharp contrast to the recently-discovered double-descent phenomenon in ERM which might be a result of overfitting of noises. Experiments on CIFAR and ImageNet datasets verify the effectiveness of our approach in two applications: classification with label noise and selective classification. We release our code at https://github.com/LayneH/self-adaptive-training.", "published": "2020-02-24T15:47:10Z", "version": 2}, {"aid": "2003.03488", "authors": ["Zechun Liu", "Zhiqiang Shen", "Marios Savvides", "Kwang-Ting Cheng"], "title": "ReActNet: Towards Precise Binary Neural Network with Generalized Activation Functions", "url": "http://arxiv.org/pdf/2003.03488v2", "summary": "In this paper, we propose several ideas for enhancing a binary network to close its accuracy gap from real-valued networks without incurring any additional computational cost. We first construct a baseline network by modifying and binarizing a compact real-valued network with parameter-free shortcuts, bypassing all the intermediate convolutional layers including the downsampling layers. This baseline network strikes a good trade-off between accuracy and efficiency, achieving superior performance than most of existing binary networks at approximately half of the computational cost. Through extensive experiments and analysis, we observed that the performance of binary networks is sensitive to activation distribution variations. Based on this important observation, we propose to generalize the traditional Sign and PReLU functions, denoted as RSign and RPReLU for the respective generalized functions, to enable explicit learning of the distribution reshape and shift at near-zero extra cost. Lastly, we adopt a distributional loss to further enforce the binary network to learn similar output distributions as those of a real-valued network. We show that after incorporating all these ideas, the proposed ReActNet outperforms all the state-of-the-arts by a large margin. Specifically, it outperforms Real-to-Binary Net and MeliusNet29 by 4.0% and 3.6% respectively for the top-1 accuracy and also reduces the gap to its real-valued counterpart to within 3.0% top-1 accuracy on ImageNet dataset. Code and models are available at: https://github.com/liuzechun/ReActNet.", "published": "2020-03-07T02:12:02Z", "version": 2}, {"aid": "2003.04151", "authors": ["Pau Rodr\u00edguez", "Issam Laradji", "Alexandre Drouin", "Alexandre Lacoste"], "title": "Embedding Propagation: Smoother Manifold for Few-Shot Classification", "url": "http://arxiv.org/pdf/2003.04151v2", "summary": "Few-shot classification is challenging because the data distribution of the training set can be widely different to the test set as their classes are disjoint. This distribution shift often results in poor generalization. Manifold smoothing has been shown to address the distribution shift problem by extending the decision boundaries and reducing the noise of the class representations. Moreover, manifold smoothness is a key factor for semi-supervised learning and transductive learning algorithms. In this work, we propose to use embedding propagation as an unsupervised non-parametric regularizer for manifold smoothing in few-shot classification. Embedding propagation leverages interpolations between the extracted features of a neural network based on a similarity graph. We empirically show that embedding propagation yields a smoother embedding manifold. We also show that applying embedding propagation to a transductive classifier achieves new state-of-the-art results in mini-Imagenet, tiered-Imagenet, Imagenet-FS, and CUB. Furthermore, we show that embedding propagation consistently improves the accuracy of the models in multiple semi-supervised learning scenarios by up to 16\\% points. The proposed embedding propagation operation can be easily integrated as a non-parametric layer into a neural network. We provide the training code and usage examples at https://github.com/ElementAI/embedding-propagation.", "published": "2020-03-09T13:51:09Z", "version": 2}, {"aid": "2003.08505", "authors": ["Kevin Musgrave", "Serge Belongie", "Ser-Nam Lim"], "title": "A Metric Learning Reality Check", "url": "http://arxiv.org/pdf/2003.08505v3", "summary": "Deep metric learning papers from the past four years have consistently claimed great advances in accuracy, often more than doubling the performance of decade-old methods. In this paper, we take a closer look at the field to see if this is actually true. We find flaws in the experimental methodology of numerous metric learning papers, and show that the actual improvements over time have been marginal at best.", "published": "2020-03-18T23:28:04Z", "version": 3}, {"aid": "2003.08936", "authors": ["Muyang Li", "Ji Lin", "Yaoyao Ding", "Zhijian Liu", "Jun-Yan Zhu", "Song Han"], "title": "GAN Compression: Efficient Architectures for Interactive Conditional GANs", "url": "http://arxiv.org/pdf/2003.08936v4", "summary": "Conditional Generative Adversarial Networks (cGANs) have enabled controllable image synthesis for many vision and graphics applications. However, recent cGANs are 1-2 orders of magnitude more compute-intensive than modern recognition CNNs. For example, GauGAN consumes 281G MACs per image, compared to 0.44G MACs for MobileNet-v3, making it difficult for interactive deployment. In this work, we propose a general-purpose compression framework for reducing the inference time and model size of the generator in cGANs. Directly applying existing compression methods yields poor performance due to the difficulty of GAN training and the differences in generator architectures. We address these challenges in two ways. First, to stabilize GAN training, we transfer knowledge of multiple intermediate representations of the original model to its compressed model and unify unpaired and paired learning. Second, instead of reusing existing CNN designs, our method finds efficient architectures via neural architecture search. To accelerate the search process, we decouple the model training and search via weight sharing. Experiments demonstrate the effectiveness of our method across different supervision settings, network architectures, and learning methods. Without losing image quality, we reduce the computation of CycleGAN by 21x, Pix2pix by 12x, MUNIT by 29x, and GauGAN by 9x, paving the way for interactive image synthesis.", "published": "2020-03-19T17:59:05Z", "version": 4}, {"aid": "2003.08983", "authors": ["Malik Boudiaf", "J\u00e9r\u00f4me Rony", "Imtiaz Masud Ziko", "Eric Granger", "Marco Pedersoli", "Pablo Piantanida", "Ismail Ben Ayed"], "title": "A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses", "url": "http://arxiv.org/pdf/2003.08983v3", "summary": "Recently, substantial research efforts in Deep Metric Learning (DML) focused on designing complex pairwise-distance losses, which require convoluted schemes to ease optimization, such as sample mining or pair weighting. The standard cross-entropy loss for classification has been largely overlooked in DML. On the surface, the cross-entropy may seem unrelated and irrelevant to metric learning as it does not explicitly involve pairwise distances. However, we provide a theoretical analysis that links the cross-entropy to several well-known and recent pairwise losses. Our connections are drawn from two different perspectives: one based on an explicit optimization insight; the other on discriminative and generative views of the mutual information between the labels and the learned features. First, we explicitly demonstrate that the cross-entropy is an upper bound on a new pairwise loss, which has a structure similar to various pairwise losses: it minimizes intra-class distances while maximizing inter-class distances. As a result, minimizing the cross-entropy can be seen as an approximate bound-optimization (or Majorize-Minimize) algorithm for minimizing this pairwise loss. Second, we show that, more generally, minimizing the cross-entropy is actually equivalent to maximizing the mutual information, to which we connect several well-known pairwise losses. Furthermore, we show that various standard pairwise losses can be explicitly related to one another via bound relationships. Our findings indicate that the cross-entropy represents a proxy for maximizing the mutual information -- as pairwise losses do -- without the need for convoluted sample-mining heuristics. Our experiments over four standard DML benchmarks strongly support our findings. We obtain state-of-the-art results, outperforming recent and complex DML methods.", "published": "2020-03-19T18:59:54Z", "version": 3}, {"aid": "2003.10027", "authors": ["Yinpeng Chen", "Xiyang Dai", "Mengchen Liu", "Dongdong Chen", "Lu Yuan", "Zicheng Liu"], "title": "Dynamic ReLU", "url": "http://arxiv.org/pdf/2003.10027v2", "summary": "Rectified linear units (ReLU) are commonly used in deep neural networks. So far ReLU and its generalizations (non-parametric or parametric) are static, performing identically for all input samples. In this paper, we propose dynamic ReLU (DY-ReLU), a dynamic rectifier of which parameters are generated by a hyper function over all in-put elements. The key insight is that DY-ReLU encodes the global context into the hyper function, and adapts the piecewise linear activation function accordingly. Compared to its static counterpart, DY-ReLU has negligible extra computational cost, but significantly more representation capability, especially for light-weight neural networks. By simply using DY-ReLU for MobileNetV2, the top-1 accuracy on ImageNet classification is boosted from 72.0% to 76.2% with only 5% additional FLOPs.", "published": "2020-03-22T23:45:35Z", "version": 2}, {"aid": "2003.12039", "authors": ["Zachary Teed", "Jia Deng"], "title": "RAFT: Recurrent All-Pairs Field Transforms for Optical Flow", "url": "http://arxiv.org/pdf/2003.12039v3", "summary": "We introduce Recurrent All-Pairs Field Transforms (RAFT), a new deep network architecture for optical flow. RAFT extracts per-pixel features, builds multi-scale 4D correlation volumes for all pairs of pixels, and iteratively updates a flow field through a recurrent unit that performs lookups on the correlation volumes. RAFT achieves state-of-the-art performance. On KITTI, RAFT achieves an F1-all error of 5.10%, a 16% error reduction from the best published result (6.10%). On Sintel (final pass), RAFT obtains an end-point-error of 2.855 pixels, a 30% error reduction from the best published result (4.098 pixels). In addition, RAFT has strong cross-dataset generalization as well as high efficiency in inference time, training speed, and parameter count. Code is available at https://github.com/princeton-vl/RAFT.", "published": "2020-03-26T17:12:42Z", "version": 3}, {"aid": "2003.13630", "authors": ["Tal Ridnik", "Hussam Lawen", "Asaf Noy", "Emanuel Ben Baruch", "Gilad Sharir", "Itamar Friedman"], "title": "TResNet: High Performance GPU-Dedicated Architecture", "url": "http://arxiv.org/pdf/2003.13630v3", "summary": "Many deep learning models, developed in recent years, reach higher ImageNet accuracy than ResNet50, with fewer or comparable FLOPS count. While FLOPs are often seen as a proxy for network efficiency, when measuring actual GPU training and inference throughput, vanilla ResNet50 is usually significantly faster than its recent competitors, offering better throughput-accuracy trade-off.   In this work, we introduce a series of architecture modifications that aim to boost neural networks' accuracy, while retaining their GPU training and inference efficiency. We first demonstrate and discuss the bottlenecks induced by FLOPs-optimizations. We then suggest alternative designs that better utilize GPU structure and assets. Finally, we introduce a new family of GPU-dedicated models, called TResNet, which achieve better accuracy and efficiency than previous ConvNets.   Using a TResNet model, with similar GPU throughput to ResNet50, we reach 80.8 top-1 accuracy on ImageNet. Our TResNet models also transfer well and achieve state-of-the-art accuracy on competitive single-label classification datasets such as Stanford cars (96.0%), CIFAR-10 (99.0%), CIFAR-100 (91.5%) and Oxford-Flowers (99.1%). They also perform well on multi-label classification and object detection tasks. Implementation is available at: https://github.com/mrT23/TResNet.", "published": "2020-03-30T17:04:47Z", "version": 3}, {"aid": "2003.13985", "authors": ["Sean Moran", "Pierre Marza", "Steven McDonagh", "Sarah Parisot", "Gregory Slabaugh"], "title": "DeepLPF: Deep Local Parametric Filters for Image Enhancement", "url": "http://arxiv.org/pdf/2003.13985v1", "summary": "Digital artists often improve the aesthetic quality of digital photographs through manual retouching. Beyond global adjustments, professional image editing programs provide local adjustment tools operating on specific parts of an image. Options include parametric (graduated, radial filters) and unconstrained brush tools. These highly expressive tools enable a diverse set of local image enhancements. However, their use can be time consuming, and requires artistic capability. State-of-the-art automated image enhancement approaches typically focus on learning pixel-level or global enhancements. The former can be noisy and lack interpretability, while the latter can fail to capture fine-grained adjustments. In this paper, we introduce a novel approach to automatically enhance images using learned spatially local filters of three different types (Elliptical Filter, Graduated Filter, Polynomial Filter). We introduce a deep neural network, dubbed Deep Local Parametric Filters (DeepLPF), which regresses the parameters of these spatially localized filters that are then automatically applied to enhance the image. DeepLPF provides a natural form of model regularization and enables interpretable, intuitive adjustments that lead to visually pleasing results. We report on multiple benchmarks and show that DeepLPF produces state-of-the-art performance on two variants of the MIT-Adobe-5K dataset, often using a fraction of the parameters required for competing methods.", "published": "2020-03-31T06:51:21Z", "version": 1}, {"aid": "2004.00049", "authors": ["Jiapeng Zhu", "Yujun Shen", "Deli Zhao", "Bolei Zhou"], "title": "In-Domain GAN Inversion for Real Image Editing", "url": "http://arxiv.org/pdf/2004.00049v3", "summary": "Recent work has shown that a variety of semantics emerge in the latent space of Generative Adversarial Networks (GANs) when being trained to synthesize images. However, it is difficult to use these learned semantics for real image editing. A common practice of feeding a real image to a trained GAN generator is to invert it back to a latent code. However, existing inversion methods typically focus on reconstructing the target image by pixel values yet fail to land the inverted code in the semantic domain of the original latent space. As a result, the reconstructed image cannot well support semantic editing through varying the inverted code. To solve this problem, we propose an in-domain GAN inversion approach, which not only faithfully reconstructs the input image but also ensures the inverted code to be semantically meaningful for editing. We first learn a novel domain-guided encoder to project a given image to the native latent space of GANs. We then propose domain-regularized optimization by involving the encoder as a regularizer to fine-tune the code produced by the encoder and better recover the target image. Extensive experiments suggest that our inversion method achieves satisfying real image reconstruction and more importantly facilitates various image editing tasks, significantly outperforming start-of-the-arts.", "published": "2020-03-31T18:20:18Z", "version": 3}, {"aid": "2004.01461", "authors": ["Hongwei Yong", "Jianqiang Huang", "Xiansheng Hua", "Lei Zhang"], "title": "Gradient Centralization: A New Optimization Technique for Deep Neural Networks", "url": "http://arxiv.org/pdf/2004.01461v2", "summary": "Optimization techniques are of great importance to effectively and efficiently train a deep neural network (DNN). It has been shown that using the first and second order statistics (e.g., mean and variance) to perform Z-score standardization on network activations or weight vectors, such as batch normalization (BN) and weight standardization (WS), can improve the training performance. Different from these existing methods that mostly operate on activations or weights, we present a new optimization technique, namely gradient centralization (GC), which operates directly on gradients by centralizing the gradient vectors to have zero mean. GC can be viewed as a projected gradient descent method with a constrained loss function. We show that GC can regularize both the weight space and output feature space so that it can boost the generalization performance of DNNs. Moreover, GC improves the Lipschitzness of the loss function and its gradient so that the training process becomes more efficient and stable. GC is very simple to implement and can be easily embedded into existing gradient based DNN optimizers with only one line of code. It can also be directly used to fine-tune the pre-trained DNNs. Our experiments on various applications, including general image classification, fine-grained image classification, detection and segmentation, demonstrate that GC can consistently improve the performance of DNN learning. The code of GC can be found at https://github.com/Yonghongwei/Gradient-Centralization.", "published": "2020-04-03T10:25:00Z", "version": 2}, {"aid": "2004.02215", "authors": ["Jing Jin", "Junhui Hou", "Jie Chen", "Sam Kwong"], "title": "Light Field Spatial Super-resolution via Deep Combinatorial Geometry Embedding and Structural Consistency Regularization", "url": "http://arxiv.org/pdf/2004.02215v1", "summary": "Light field (LF) images acquired by hand-held devices usually suffer from low spatial resolution as the limited sampling resources have to be shared with the angular dimension. LF spatial super-resolution (SR) thus becomes an indispensable part of the LF camera processing pipeline. The high-dimensionality characteristic and complex geometrical structure of LF images make the problem more challenging than traditional single-image SR. The performance of existing methods is still limited as they fail to thoroughly explore the coherence among LF views and are insufficient in accurately preserving the parallax structure of the scene. In this paper, we propose a novel learning-based LF spatial SR framework, in which each view of an LF image is first individually super-resolved by exploring the complementary information among views with combinatorial geometry embedding. For accurate preservation of the parallax structure among the reconstructed views, a regularization network trained over a structure-aware loss function is subsequently appended to enforce correct parallax relationships over the intermediate estimation. Our proposed approach is evaluated over datasets with a large number of testing images including both synthetic and real-world scenes. Experimental results demonstrate the advantage of our approach over state-of-the-art methods, i.e., our method not only improves the average PSNR by more than 1.0 dB but also preserves more accurate parallax details, at a lower computational cost.", "published": "2020-04-05T14:39:57Z", "version": 1}, {"aid": "2004.02546", "authors": ["Erik H\u00e4rk\u00f6nen", "Aaron Hertzmann", "Jaakko Lehtinen", "Sylvain Paris"], "title": "GANSpace: Discovering Interpretable GAN Controls", "url": "http://arxiv.org/pdf/2004.02546v3", "summary": "This paper describes a simple technique to analyze Generative Adversarial Networks (GANs) and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day. We identify important latent directions based on Principal Components Analysis (PCA) applied either in latent space or feature space. Then, we show that a large number of interpretable controls can be defined by layer-wise perturbation along the principal directions. Moreover, we show that BigGAN can be controlled with layer-wise inputs in a StyleGAN-like manner. We show results on different GANs trained on various datasets, and demonstrate good qualitative matches to edit directions found through earlier supervised approaches.", "published": "2020-04-06T10:41:44Z", "version": 3}, {"aid": "2004.03791", "authors": ["Longguang Wang", "Yingqian Wang", "Zaiping Lin", "Jungang Yang", "Wei An", "Yulan Guo"], "title": "Learning A Single Network for Scale-Arbitrary Super-Resolution", "url": "http://arxiv.org/pdf/2004.03791v2", "summary": "Recently, the performance of single image super-resolution (SR) has been significantly improved with powerful networks. However, these networks are developed for image SR with a single specific integer scale (e.g., x2;x3,x4), and cannot be used for non-integer and asymmetric SR. In this paper, we propose to learn a scale-arbitrary image SR network from scale-specific networks. Specifically, we propose a plug-in module for existing SR networks to perform scale-arbitrary SR, which consists of multiple scale-aware feature adaption blocks and a scale-aware upsampling layer. Moreover, we introduce a scale-aware knowledge transfer paradigm to transfer knowledge from scale-specific networks to the scale-arbitrary network. Our plug-in module can be easily adapted to existing networks to achieve scale-arbitrary SR. These networks plugged with our module can achieve promising results for non-integer and asymmetric SR while maintaining state-of-the-art performance for SR with integer scale factors. Besides, the additional computational and memory cost of our module is very small.", "published": "2020-04-08T03:40:15Z", "version": 2}, {"aid": "2004.04433", "authors": ["Marcel C. B\u00fchler", "Andr\u00e9s Romero", "Radu Timofte"], "title": "DeepSEE: Deep Disentangled Semantic Explorative Extreme Super-Resolution", "url": "http://arxiv.org/pdf/2004.04433v3", "summary": "Super-resolution (SR) is by definition ill-posed. There are infinitely many plausible high-resolution variants for a given low-resolution natural image. Most of the current literature aims at a single deterministic solution of either high reconstruction fidelity or photo-realistic perceptual quality. In this work, we propose an explorative facial super-resolution framework, DeepSEE, for Deep disentangled Semantic Explorative Extreme super-resolution. To the best of our knowledge, DeepSEE is the first method to leverage semantic maps for explorative super-resolution. In particular, it provides control of the semantic regions, their disentangled appearance and it allows a broad range of image manipulations. We validate DeepSEE on faces, for up to 32x magnification and exploration of the space of super-resolution. Our code and models are available at: https://mcbuehler.github.io/DeepSEE/", "published": "2020-04-09T09:14:42Z", "version": 3}, {"aid": "2004.05479", "authors": ["Alper T. Erdogan", "Cengiz Pehlevan"], "title": "Blind Bounded Source Separation Using Neural Networks with Local Learning Rules", "url": "http://arxiv.org/pdf/2004.05479v1", "summary": "An important problem encountered by both natural and engineered signal processing systems is blind source separation. In many instances of the problem, the sources are bounded by their nature and known to be so, even though the particular bound may not be known. To separate such bounded sources from their mixtures, we propose a new optimization problem, Bounded Similarity Matching (BSM). A principled derivation of an adaptive BSM algorithm leads to a recurrent neural network with a clipping nonlinearity. The network adapts by local learning rules, satisfying an important constraint for both biological plausibility and implementability in neuromorphic hardware.", "published": "2020-04-11T20:20:22Z", "version": 1}, {"aid": "2004.07320", "authors": ["Angela Fan", "Pierre Stock", "Benjamin Graham", "Edouard Grave", "Remi Gribonval", "Herve Jegou", "Armand Joulin"], "title": "Training with Quantization Noise for Extreme Model Compression", "url": "http://arxiv.org/pdf/2004.07320v3", "summary": "We tackle the problem of producing compact models, maximizing their accuracy for a given model size. A standard solution is to train networks with Quantization Aware Training, where the weights are quantized during training and the gradients approximated with the Straight-Through Estimator. In this paper, we extend this approach to work beyond int8 fixed-point quantization with extreme compression methods where the approximations introduced by STE are severe, such as Product Quantization. Our proposal is to only quantize a different random subset of weights during each forward, allowing for unbiased gradients to flow through the other weights. Controlling the amount of noise and its form allows for extreme compression rates while maintaining the performance of the original model. As a result we establish new state-of-the-art compromises between accuracy and model size both in natural language processing and image classification. For example, applying our method to state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5% accuracy on MNLI by compressing RoBERTa to 14MB and 80.0 top-1 accuracy on ImageNet by compressing an EfficientNet-B3 to 3.3MB.", "published": "2020-04-15T20:10:53Z", "version": 3}, {"aid": "2004.08128", "authors": ["Beren Millidge", "Alexander Tschantz", "Christopher L Buckley"], "title": "Whence the Expected Free Energy?", "url": "http://arxiv.org/pdf/2004.08128v5", "summary": "The Expected Free Energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the Variational Free Energy (VFE) remain unclear. In this paper, we investigate the origins of the EFE in detail and show that it is not simply \"the free energy in the future\". We present a functional that we argue is the natural extension of the VFE, but which actively discourages exploratory behaviour, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the Free-Energy of the Expected Future (FEEF), which possesses both the epistemic component of the EFE as well as an intuitive mathematical grounding as the divergence between predicted and desired futures.", "published": "2020-04-17T09:06:56Z", "version": 5}, {"aid": "2004.09576", "authors": ["Yash Bhalgat", "Jinwon Lee", "Markus Nagel", "Tijmen Blankevoort", "Nojun Kwak"], "title": "LSQ+: Improving low-bit quantization through learnable offsets and better initialization", "url": "http://arxiv.org/pdf/2004.09576v1", "summary": "Unlike ReLU, newer activation functions (like Swish, H-swish, Mish) that are frequently employed in popular efficient architectures can also result in negative activation values, with skewed positive and negative ranges. Typical learnable quantization schemes [PACT, LSQ] assume unsigned quantization for activations and quantize all negative activations to zero which leads to significant loss in performance. Naively using signed quantization to accommodate these negative values requires an extra sign bit which is expensive for low-bit (2-, 3-, 4-bit) quantization. To solve this problem, we propose LSQ+, a natural extension of LSQ, wherein we introduce a general asymmetric quantization scheme with trainable scale and offset parameters that can learn to accommodate the negative activations. Gradient-based learnable quantization schemes also commonly suffer from high instability or variance in the final training performance, hence requiring a great deal of hyper-parameter tuning to reach a satisfactory performance. LSQ+ alleviates this problem by using an MSE-based initialization scheme for the quantization parameters. We show that this initialization leads to significantly lower variance in final performance across multiple training runs. Overall, LSQ+ shows state-of-the-art results for EfficientNet and MixNet and also significantly outperforms LSQ for low-bit quantization of neural nets with Swish activations (e.g.: 1.8% gain with W4A4 quantization and upto 5.6% gain with W2A2 quantization of EfficientNet-B0 on ImageNet dataset). To the best of our knowledge, ours is the first work to quantize such architectures to extremely low bit-widths.", "published": "2020-04-20T19:04:51Z", "version": 1}, {"aid": "2004.11362", "authors": ["Prannay Khosla", "Piotr Teterwak", "Chen Wang", "Aaron Sarna", "Yonglong Tian", "Phillip Isola", "Aaron Maschinot", "Ce Liu", "Dilip Krishnan"], "title": "Supervised Contrastive Learning", "url": "http://arxiv.org/pdf/2004.11362v5", "summary": "Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or significantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4% on the ImageNet dataset, which is 0.8% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows benefits for robustness to natural corruptions and is more stable to hyperparameter settings such as optimizers and data augmentations. Our loss function is simple to implement, and reference TensorFlow code is released at https://t.ly/supcon.", "published": "2020-04-23T17:58:56Z", "version": 5}, {"aid": "2004.12399", "authors": ["Jerry Zikun Chen"], "title": "Reinforcement Learning Generalization with Surprise Minimization", "url": "http://arxiv.org/pdf/2004.12399v2", "summary": "Generalization remains a challenging problem for deep reinforcement learning algorithms, which are often trained and tested on the same set of deterministic game environments. When test environments are unseen and perturbed but the nature of the task remains the same, generalization gaps can arise. In this work, we propose and evaluate a surprise minimizing agent on a generalization benchmark to show an additional reward learned from a simple density model can show robustness in procedurally generated game environments that provide constant source of entropy and stochasticity.", "published": "2020-04-26T14:50:59Z", "version": 2}, {"aid": "2004.13612", "authors": ["Calypso Herrera", "Florian Krach", "Anastasis Kratsios", "Pierre Ruyssen", "Josef Teichmann"], "title": "Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices", "url": "http://arxiv.org/pdf/2004.13612v4", "summary": "The robust PCA of covariance matrices plays an essential role when isolating key explanatory features. The currently available methods for performing such a low-rank plus sparse decomposition are matrix specific, meaning, those algorithms must re-run for every new matrix. Since these algorithms are computationally expensive, it is preferable to learn and store a function that nearly instantaneously performs this decomposition when evaluated. Therefore, we introduce Denise, a deep learning-based algorithm for robust PCA of covariance matrices, or more generally, of symmetric positive semidefinite matrices, which learns precisely such a function. Theoretical guarantees for Denise are provided. These include a novel universal approximation theorem adapted to our geometric deep learning problem and convergence to an optimal solution to the learning problem. Our experiments show that Denise matches state-of-the-art performance in terms of decomposition quality, while being approximately $2000\\times$ faster than the state-of-the-art, principal component pursuit (PCP), and $200 \\times$ faster than the current speed-optimized method, fast PCP.", "published": "2020-04-28T15:45:21Z", "version": 4}, {"aid": "2005.00695", "authors": ["Sen Wu", "Hongyang R. Zhang", "Gregory Valiant", "Christopher R\u00e9"], "title": "On the Generalization Effects of Linear Transformations in Data Augmentation", "url": "http://arxiv.org/pdf/2005.00695v3", "summary": "Data augmentation is a powerful technique to improve performance in applications such as image and text classification tasks. Yet, there is little rigorous understanding of why and how various augmentations work. In this work, we consider a family of linear transformations and study their effects on the ridge estimator in an over-parametrized linear regression setting. First, we show that transformations that preserve the labels of the data can improve estimation by enlarging the span of the training data. Second, we show that transformations that mix data can improve estimation by playing a regularization effect. Finally, we validate our theoretical insights on MNIST. Based on the insights, we propose an augmentation scheme that searches over the space of transformations by how uncertain the model is about the transformed data. We validate our proposed scheme on image and text datasets. For example, our method outperforms random sampling methods by 1.24% on CIFAR-100 using Wide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA Adversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.", "published": "2020-05-02T04:10:21Z", "version": 3}, {"aid": "2005.03098", "authors": ["Arne Decadt", "Jasper De Bock", "Gert de Cooman"], "title": "Inference with Choice Functions Made Practical", "url": "http://arxiv.org/pdf/2005.03098v3", "summary": "We study how to infer new choices from previous choices in a conservative manner. To make such inferences, we use the theory of choice functions: a unifying mathematical framework for conservative decision making that allows one to impose axioms directly on the represented decisions. We here adopt the coherence axioms of De Bock and De Cooman (2019). We show how to naturally extend any given choice assessment to such a coherent choice function, whenever possible, and use this natural extension to make new choices. We present a practical algorithm to compute this natural extension and provide several methods that can be used to improve its scalability.", "published": "2020-05-07T12:58:05Z", "version": 3}, {"aid": "2005.04298", "authors": ["Jinkyu Kim", "Mayank Bansal"], "title": "Attentional Bottleneck: Towards an Interpretable Deep Driving Network", "url": "http://arxiv.org/pdf/2005.04298v1", "summary": "Deep neural networks are a key component of behavior prediction and motion generation for self-driving cars. One of their main drawbacks is a lack of transparency: they should provide easy to interpret rationales for what triggers certain behaviors. We propose an architecture called Attentional Bottleneck with the goal of improving transparency. Our key idea is to combine visual attention, which identifies what aspects of the input the model is using, with an information bottleneck that enables the model to only use aspects of the input which are important. This not only provides sparse and interpretable attention maps (e.g. focusing only on specific vehicles in the scene), but it adds this transparency at no cost to model accuracy. In fact, we find slight improvements in accuracy when applying Attentional Bottleneck to the ChauffeurNet model, whereas we find that the accuracy deteriorates with a traditional visual attention model.", "published": "2020-05-08T21:51:15Z", "version": 1}, {"aid": "2005.04551", "authors": ["Yihui He", "Rui Yan", "Katerina Fragkiadaki", "Shoou-I Yu"], "title": "Epipolar Transformers", "url": "http://arxiv.org/pdf/2005.04551v1", "summary": "A common approach to localize 3D human joints in a synchronized and calibrated multi-view setup consists of two-steps: (1) apply a 2D detector separately on each view to localize joints in 2D, and (2) perform robust triangulation on 2D detections from each view to acquire the 3D joint locations. However, in step 1, the 2D detector is limited to solving challenging cases which could potentially be better resolved in 3D, such as occlusions and oblique viewing angles, purely in 2D without leveraging any 3D information. Therefore, we propose the differentiable \"epipolar transformer\", which enables the 2D detector to leverage 3D-aware features to improve 2D pose estimation. The intuition is: given a 2D location p in the current view, we would like to first find its corresponding point p' in a neighboring view, and then combine the features at p' with the features at p, thus leading to a 3D-aware feature at p. Inspired by stereo matching, the epipolar transformer leverages epipolar constraints and feature matching to approximate the features at p'. Experiments on InterHand and Human3.6M show that our approach has consistent improvements over the baselines. Specifically, in the condition where no external data is used, our Human3.6M model trained with ResNet-50 backbone and image size 256 x 256 outperforms state-of-the-art by 4.23 mm and achieves MPJPE 26.9 mm.", "published": "2020-05-10T02:22:54Z", "version": 1}, {"aid": "2005.04559", "authors": ["Mahdi Biparva", "John Tsotsos"], "title": "Compact Neural Representation Using Attentive Network Pruning", "url": "http://arxiv.org/pdf/2005.04559v1", "summary": "Deep neural networks have evolved to become power demanding and consequently difficult to apply to small-size mobile platforms. Network parameter reduction methods have been introduced to systematically deal with the computational and memory complexity of deep networks. We propose to examine the ability of attentive connection pruning to deal with redundancy reduction in neural networks as a contribution to the reduction of computational demand. In this work, we describe a Top-Down attention mechanism that is added to a Bottom-Up feedforward network to select important connections and subsequently prune redundant ones at all parametric layers. Our method not only introduces a novel hierarchical selection mechanism as the basis of pruning but also remains competitive with previous baseline methods in the experimental evaluation. We conduct experiments using different network architectures on popular benchmark datasets to show high compression ratio is achievable with negligible loss of accuracy.", "published": "2020-05-10T03:20:01Z", "version": 1}, {"aid": "2005.04573", "authors": ["Li Zhang", "Mingliang Wang", "Mingxia Liu", "Daoqiang Zhang"], "title": "A Survey on Deep Learning for Neuroimaging-based Brain Disorder Analysis", "url": "http://arxiv.org/pdf/2005.04573v1", "summary": "Deep learning has been recently used for the analysis of neuroimages, such as structural magnetic resonance imaging (MRI), functional MRI, and positron emission tomography (PET), and has achieved significant performance improvements over traditional machine learning in computer-aided diagnosis of brain disorders. This paper reviews the applications of deep learning methods for neuroimaging-based brain disorder analysis. We first provide a comprehensive overview of deep learning techniques and popular network architectures, by introducing various types of deep neural networks and recent developments. We then review deep learning methods for computer-aided analysis of four typical brain disorders, including Alzheimer's disease, Parkinson's disease, Autism spectrum disorder, and Schizophrenia, where the first two diseases are neurodegenerative disorders and the last two are neurodevelopmental and psychiatric disorders, respectively. More importantly, we discuss the limitations of existing studies and present possible future directions.", "published": "2020-05-10T04:20:50Z", "version": 1}, {"aid": "2005.04605", "authors": ["Miaohua Zhang", "Yongsheng Gao", "Changming Sun", "Michael Blumenstein"], "title": "Robust Tensor Decomposition for Image Representation Based on Generalized Correntropy", "url": "http://arxiv.org/pdf/2005.04605v1", "summary": "Traditional tensor decomposition methods, e.g., two dimensional principal component analysis and two dimensional singular value decomposition, that minimize mean square errors, are sensitive to outliers. To overcome this problem, in this paper we propose a new robust tensor decomposition method using generalized correntropy criterion (Corr-Tensor). A Lagrange multiplier method is used to effectively optimize the generalized correntropy objective function in an iterative manner. The Corr-Tensor can effectively improve the robustness of tensor decomposition with the existence of outliers without introducing any extra computational cost. Experimental results demonstrated that the proposed method significantly reduces the reconstruction error on face reconstruction and improves the accuracies on handwritten digit recognition and facial image clustering.", "published": "2020-05-10T08:46:52Z", "version": 1}, {"aid": "2005.04613", "authors": ["Vignesh Prasad", "Dipanjan Das", "Brojeshwar Bhowmick"], "title": "Variational Clustering: Leveraging Variational Autoencoders for Image Clustering", "url": "http://arxiv.org/pdf/2005.04613v1", "summary": "Recent advances in deep learning have shown their ability to learn strong feature representations for images. The task of image clustering naturally requires good feature representations to capture the distribution of the data and subsequently differentiate data points from one another. Often these two aspects are dealt with independently and thus traditional feature learning alone does not suffice in partitioning the data meaningfully. Variational Autoencoders (VAEs) naturally lend themselves to learning data distributions in a latent space. Since we wish to efficiently discriminate between different clusters in the data, we propose a method based on VAEs where we use a Gaussian Mixture prior to help cluster the images accurately. We jointly learn the parameters of both the prior and the posterior distributions. Our method represents a true Gaussian Mixture VAE. This way, our method simultaneously learns a prior that captures the latent distribution of the images and a posterior to help discriminate well between data points. We also propose a novel reparametrization of the latent space consisting of a mixture of discrete and continuous variables. One key takeaway is that our method generalizes better across different datasets without using any pre-training or learnt models, unlike existing methods, allowing it to be trained from scratch in an end-to-end manner. We verify our efficacy and generalizability experimentally by achieving state-of-the-art results among unsupervised methods on a variety of datasets. To the best of our knowledge, we are the first to pursue image clustering using VAEs in a purely unsupervised manner on real image datasets.", "published": "2020-05-10T09:34:48Z", "version": 1}, {"aid": "2005.04619", "authors": ["Miaohua Zhang", "Yongsheng Gao", "Jun Zhou"], "title": "A Unified Weight Learning and Low-Rank Regression Model for Robust Complex Error Modeling", "url": "http://arxiv.org/pdf/2005.04619v4", "summary": "One of the most important problems in regression-based error model is modeling the complex representation error caused by various corruptions and environment changes in images. For example, in robust face recognition, images are often affected by varying types and levels of corruptions, such as random pixel corruptions, block occlusions, or disguises. However, existing works are not robust enough to solve this problem due to they cannot model the complex corrupted errors very well. In this paper, we address this problem by a unified sparse weight learning and low-rank approximation regression model, which enables the random noises and contiguous occlusions in images to be treated simultaneously. For the random noise, we define a generalized correntropy (GC) function to match the error distribution. For the structured error caused by occlusions or disguises, we propose a GC function based rank approximation to measure the rank of error matrices. Since the proposed objective function is non-convex, an effective iterative optimization algorithm is developed to achieve the optimal weight learning and low-rank approximation. Extensive experimental results on three public face databases show that the proposed model can fit the error distribution and structure very well, thus obtain better recognition accuracies in comparison with the existing methods.", "published": "2020-05-10T09:50:14Z", "version": 4}, {"aid": "2005.04623", "authors": ["Mateusz Michalkiewicz", "Eugene Belilovsky", "Mahsa Baktashmotlagh", "Anders Eriksson"], "title": "A Simple and Scalable Shape Representation for 3D Reconstruction", "url": "http://arxiv.org/pdf/2005.04623v1", "summary": "Deep learning applied to the reconstruction of 3D shapes has seen growing interest. A popular approach to 3D reconstruction and generation in recent years has been the CNN encoder-decoder model usually applied in voxel space. However, this often scales very poorly with the resolution limiting the effectiveness of these models. Several sophisticated alternatives for decoding to 3D shapes have been proposed typically relying on complex deep learning architectures for the decoder model. In this work, we show that this additional complexity is not necessary, and that we can actually obtain high quality 3D reconstruction using a linear decoder, obtained from principal component analysis on the signed distance function (SDF) of the surface. This approach allows easily scaling to larger resolutions. We show in multiple experiments that our approach is competitive with state-of-the-art methods. It also allows the decoder to be fine-tuned on the target task using a loss designed specifically for SDF transforms, obtaining further gains.", "published": "2020-05-10T10:22:50Z", "version": 1}, {"aid": "2005.04625", "authors": ["Wang Zhu", "Hexiang Hu", "Jiacheng Chen", "Zhiwei Deng", "Vihan Jain", "Eugene Ie", "Fei Sha"], "title": "BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps", "url": "http://arxiv.org/pdf/2005.04625v2", "summary": "Learning to follow instructions is of fundamental importance to autonomous agents for vision-and-language navigation (VLN). In this paper, we study how an agent can navigate long paths when learning from a corpus that consists of shorter ones. We show that existing state-of-the-art agents do not generalize well. To this end, we propose BabyWalk, a new VLN agent that is learned to navigate by decomposing long instructions into shorter ones (BabySteps) and completing them sequentially. A special design memory buffer is used by the agent to turn its past experiences into contexts for future steps. The learning process is composed of two phases. In the first phase, the agent uses imitation learning from demonstration to accomplish BabySteps. In the second phase, the agent uses curriculum-based reinforcement learning to maximize rewards on navigation tasks with increasingly longer instructions. We create two new benchmark datasets (of long navigation tasks) and use them in conjunction with existing ones to examine BabyWalk's generalization ability. Empirical results show that BabyWalk achieves state-of-the-art results on several metrics, in particular, is able to follow long instructions better. The codes and the datasets are released on our project page https://github.com/Sha-Lab/babywalk.", "published": "2020-05-10T10:46:41Z", "version": 2}, {"aid": "2005.04735", "authors": ["Dan Shiebler"], "title": "Categorical Stochastic Processes and Likelihood", "url": "http://arxiv.org/pdf/2005.04735v5", "summary": "In this work we take a Category Theoretic perspective on the relationship between probabilistic modeling and function approximation. We begin by defining two extensions of function composition to stochastic process subordination: one based on the co-Kleisli category under the comonad (Omega x -) and one based on the parameterization of a category with a Lawvere theory. We show how these extensions relate to the category Stoch and other Markov Categories. Next, we apply the Para construction to extend stochastic processes to parameterized statistical models and we define a way to compose the likelihood functions of these models. We conclude with a demonstration of how the Maximum Likelihood Estimation procedure defines an identity-on-objects functor from the category of statistical models to the category of Learners. Code to accompany this paper can be found at https://github.com/dshieble/Categorical_Stochastic_Processes_and_Likelihood", "published": "2020-05-10T18:00:56Z", "version": 5}, {"aid": "2005.04945", "authors": ["Zhiqing Guo", "Gaobo Yang", "Jiyou Chen", "Xingming Sun"], "title": "Fake face detection via adaptive manipulation traces extraction network", "url": "http://arxiv.org/pdf/2005.04945v2", "summary": "With the proliferation of face image manipulation (FIM) techniques such as Face2Face and Deepfake, more fake face images are spreading over the internet, which brings serious challenges to public confidence. Face image forgery detection has made considerable progresses in exposing specific FIM, but it is still in scarcity of a robust fake face detector to expose face image forgeries under complex scenarios such as with further compression, blurring, scaling, etc. Due to the relatively fixed structure, convolutional neural network (CNN) tends to learn image content representations. However, CNN should learn subtle manipulation traces for image forensics tasks. Thus, we propose an adaptive manipulation traces extraction network (AMTEN), which serves as pre-processing to suppress image content and highlight manipulation traces. AMTEN exploits an adaptive convolution layer to predict manipulation traces in the image, which are reused in subsequent layers to maximize manipulation artifacts by updating weights during the back-propagation pass. A fake face detector, namely AMTENnet, is constructed by integrating AMTEN with CNN. Experimental results prove that the proposed AMTEN achieves desirable pre-processing. When detecting fake face images generated by various FIM techniques, AMTENnet achieves an average accuracy up to 98.52%, which outperforms the state-of-the-art works. When detecting face images with unknown post-processing operations, the detector also achieves an average accuracy of 95.17%.", "published": "2020-05-11T09:16:39Z", "version": 2}, {"aid": "2005.05274", "authors": ["Dongsuk Kim", "Geonhee Lee", "Myungjae Lee", "Shin Uk Kang", "Dongmin Kim"], "title": "Normalized Convolutional Neural Network", "url": "http://arxiv.org/pdf/2005.05274v4", "summary": "We introduce a Normalized Convolutional Neural Layer, a novel approach to normalization in convolutional networks. Unlike conventional methods, this layer normalizes the rows of the im2col matrix during convolution, making it inherently adaptive to sliced inputs and better aligned with kernel structures. This distinctive approach differentiates it from standard normalization techniques and prevents direct integration into existing deep learning frameworks optimized for traditional convolution operations. Our method has a universal property, making it applicable to any deep learning task involving convolutional layers. By inherently normalizing within the convolution process, it serves as a convolutional adaptation of Self-Normalizing Networks, maintaining their core principles without requiring additional normalization layers. Notably, in micro-batch training scenarios, it consistently outperforms other batch-independent normalization methods. This performance boost arises from standardizing the rows of the im2col matrix, which theoretically leads to a smoother loss gradient and improved training stability.", "published": "2020-05-11T17:20:26Z", "version": 4}, {"aid": "2005.05402", "authors": ["Jie Lei", "Liwei Wang", "Yelong Shen", "Dong Yu", "Tamara L. Berg", "Mohit Bansal"], "title": "MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning", "url": "http://arxiv.org/pdf/2005.05402v1", "summary": "Generating multi-sentence descriptions for videos is one of the most challenging captioning tasks due to its high requirements for not only visual relevance but also discourse-based coherence across the sentences in the paragraph. Towards this goal, we propose a new approach called Memory-Augmented Recurrent Transformer (MART), which uses a memory module to augment the transformer architecture. The memory module generates a highly summarized memory state from the video segments and the sentence history so as to help better prediction of the next sentence (w.r.t. coreference and repetition aspects), thus encouraging coherent paragraph generation. Extensive experiments, human evaluations, and qualitative analyses on two popular datasets ActivityNet Captions and YouCookII show that MART generates more coherent and less repetitive paragraph captions than baseline methods, while maintaining relevance to the input video events. All code is available open-source at: https://github.com/jayleicn/recurrent-transformer", "published": "2020-05-11T20:01:41Z", "version": 1}, {"aid": "2005.05650", "authors": ["Mingqing Xiao", "Shuxin Zheng", "Chang Liu", "Yaolong Wang", "Di He", "Guolin Ke", "Jiang Bian", "Zhouchen Lin", "Tie-Yan Liu"], "title": "Invertible Image Rescaling", "url": "http://arxiv.org/pdf/2005.05650v1", "summary": "High-resolution digital images are usually downscaled to fit various display screens or save the cost of storage and bandwidth, meanwhile the post-upscaling is adpoted to recover the original resolutions or the details in the zoom-in images. However, typical image downscaling is a non-injective mapping due to the loss of high-frequency information, which leads to the ill-posed problem of the inverse upscaling procedure and poses great challenges for recovering details from the downscaled low-resolution images. Simply upscaling with image super-resolution methods results in unsatisfactory recovering performance. In this work, we propose to solve this problem by modeling the downscaling and upscaling processes from a new perspective, i.e. an invertible bijective transformation, which can largely mitigate the ill-posed nature of image upscaling. We develop an Invertible Rescaling Net (IRN) with deliberately designed framework and objectives to produce visually-pleasing low-resolution images and meanwhile capture the distribution of the lost information using a latent variable following a specified distribution in the downscaling process. In this way, upscaling is made tractable by inversely passing a randomly-drawn latent variable with the low-resolution image through the network. Experimental results demonstrate the significant improvement of our model over existing methods in terms of both quantitative and qualitative evaluations of image upscaling reconstruction from downscaled images.", "published": "2020-05-12T09:55:53Z", "version": 1}, {"aid": "2005.05824", "authors": ["Aysan Aghazadeh", "Maryam Amirmazlaghani"], "title": "A Distributed Approximate Nearest Neighbor Method for Real-Time Face Recognition", "url": "http://arxiv.org/pdf/2005.05824v2", "summary": "Nowadays, face recognition and more generally image recognition have many applications in the modern world and are widely used in our daily tasks. This paper aims to propose a distributed approximate nearest neighbor (ANN) method for real-time face recognition using a big dataset that involves a lot of classes. The proposed approach is based on using a clustering method to separate the dataset into different clusters and on specifying the importance of each cluster by defining cluster weights. To this end, reference instances are selected from each cluster based on the cluster weights using a maximum likelihood approach. This process leads to a more informed selection of instances, so it enhances the performance of the algorithm. Experimental results confirm the efficiency of the proposed method and its out-performance in terms of accuracy and the processing time.", "published": "2020-05-12T14:39:31Z", "version": 2}, {"aid": "2005.10963", "authors": ["Yongxin Chen", "Tryphon T. Georgiou", "Michele Pavon"], "title": "Stochastic control liaisons: Richard Sinkhorn meets Gaspard Monge on a Schroedinger bridge", "url": "http://arxiv.org/pdf/2005.10963v3", "summary": "In 1931/32, Schroedinger studied a hot gas Gedankenexperiment, an instance of large deviations of the empirical distribution and an early example of the so-called maximum entropy inference method. This so-called Schroedinger bridge problem (SBP) was recently recognized as a regularization of the Monge-Kantorovich Optimal Mass Transport (OMT), leading to effective computation of the latter. Specifically, OMT with quadratic cost may be viewed as a zero-temperature limit of SBP, which amounts to minimization of the Helmholtz's free energy over probability distributions constrained to possess given marginals. The problem features a delicate compromise, mediated by a temperature parameter, between minimizing the internal energy and maximizing the entropy. These concepts are central to a rapidly expanding area of modern science dealing with the so-called {\\em Sinkhorn algorithm} which appears as a special case of an algorithm first studied by the French analyst Robert Fortet in 1938/40 specifically for Schroedinger bridges. Due to the constraint on end-point distributions, dynamic programming is not a suitable tool to attack these problems. Instead, Fortet's iterative algorithm and its discrete counterpart, the Sinkhorn iteration, permit computation by iteratively solving the so-called {\\em Schroedinger system}. In both the continuous as well as the discrete-time and space settings, {\\em stochastic control} provides a reformulation and dynamic versions of these problems. The formalism behind these control problems have attracted attention as they lead to a variety of new applications in spacecraft guidance, control of robot or biological swarms, sensing, active cooling, network routing as well as in computer and data science. This multifacet and versatile framework, intertwining SBP and OMT, provides the substrate for a historical and technical overview of the field taken up in this paper.", "published": "2020-05-22T01:34:56Z", "version": 3}, {"aid": "2005.11035", "authors": ["Jangho Kim", "KiYoon Yoo", "Nojun Kwak"], "title": "Position-based Scaled Gradient for Model Quantization and Pruning", "url": "http://arxiv.org/pdf/2005.11035v4", "summary": "We propose the position-based scaled gradient (PSG) that scales the gradient depending on the position of a weight vector to make it more compression-friendly. First, we theoretically show that applying PSG to the standard gradient descent (GD), which is called PSGD, is equivalent to the GD in the warped weight space, a space made by warping the original weight space via an appropriately designed invertible function. Second, we empirically show that PSG acting as a regularizer to a weight vector is favorable for model compression domains such as quantization and pruning. PSG reduces the gap between the weight distributions of a full-precision model and its compressed counterpart. This enables the versatile deployment of a model either as an uncompressed mode or as a compressed mode depending on the availability of resources. The experimental results on CIFAR-10/100 and ImageNet datasets show the effectiveness of the proposed PSG in both domains of pruning and quantization even for extremely low bits. The code is released in Github.", "published": "2020-05-22T07:11:27Z", "version": 4}, {"aid": "2005.12320", "authors": ["Wouter Van Gansbeke", "Simon Vandenhende", "Stamatios Georgoulis", "Marc Proesmans", "Luc Van Gool"], "title": "SCAN: Learning to Classify Images without Labels", "url": "http://arxiv.org/pdf/2005.12320v2", "summary": "Can we automatically group images into semantically meaningful clusters when ground-truth annotations are absent? The task of unsupervised image classification remains an important, and open challenge in computer vision. Several recent approaches have tried to tackle this problem in an end-to-end fashion. In this paper, we deviate from recent works, and advocate a two-step approach where feature learning and clustering are decoupled. First, a self-supervised task from representation learning is employed to obtain semantically meaningful features. Second, we use the obtained features as a prior in a learnable clustering approach. In doing so, we remove the ability for cluster learning to depend on low-level features, which is present in current end-to-end learning approaches. Experimental evaluation shows that we outperform state-of-the-art methods by large margins, in particular +26.6% on CIFAR10, +25.0% on CIFAR100-20 and +21.3% on STL10 in terms of classification accuracy. Furthermore, our method is the first to perform well on a large-scale dataset for image classification. In particular, we obtain promising results on ImageNet, and outperform several semi-supervised learning methods in the low-data regime without the use of any ground-truth annotations. The code is made publicly available at https://github.com/wvangansbeke/Unsupervised-Classification.", "published": "2020-05-25T18:12:33Z", "version": 2}, {"aid": "2006.01424", "authors": ["Yiqun Mei", "Yuchen Fan", "Yuqian Zhou", "Lichao Huang", "Thomas S. Huang", "Humphrey Shi"], "title": "Image Super-Resolution with Cross-Scale Non-Local Attention and Exhaustive Self-Exemplars Mining", "url": "http://arxiv.org/pdf/2006.01424v1", "summary": "Deep convolution-based single image super-resolution (SISR) networks embrace the benefits of learning from large-scale external image resources for local recovery, yet most existing works have ignored the long-range feature-wise similarities in natural images. Some recent works have successfully leveraged this intrinsic feature correlation by exploring non-local attention modules. However, none of the current deep models have studied another inherent property of images: cross-scale feature correlation. In this paper, we propose the first Cross-Scale Non-Local (CS-NL) attention module with integration into a recurrent neural network. By combining the new CS-NL prior with local and in-scale non-local priors in a powerful recurrent fusion cell, we can find more cross-scale feature correlations within a single low-resolution (LR) image. The performance of SISR is significantly improved by exhaustively integrating all possible priors. Extensive experiments demonstrate the effectiveness of the proposed CS-NL module by setting new state-of-the-arts on multiple SISR benchmarks.", "published": "2020-06-02T07:08:58Z", "version": 1}, {"aid": "2006.02361", "authors": ["Akshunna S. Dogra", "William T Redman"], "title": "Optimizing Neural Networks via Koopman Operator Theory", "url": "http://arxiv.org/pdf/2006.02361v3", "summary": "Koopman operator theory, a powerful framework for discovering the underlying dynamics of nonlinear dynamical systems, was recently shown to be intimately connected with neural network training. In this work, we take the first steps in making use of this connection. As Koopman operator theory is a linear theory, a successful implementation of it in evolving network weights and biases offers the promise of accelerated training, especially in the context of deep networks, where optimization is inherently a non-convex problem. We show that Koopman operator theoretic methods allow for accurate predictions of weights and biases of feedforward, fully connected deep networks over a non-trivial range of training time. During this window, we find that our approach is >10x faster than various gradient descent based methods (e.g. Adam, Adadelta, Adagrad), in line with our complexity analysis. We end by highlighting open questions in this exciting intersection between dynamical systems and neural network theory. We highlight additional methods by which our results could be expanded to broader classes of networks and larger training intervals, which shall be the focus of future work.", "published": "2020-06-03T16:23:07Z", "version": 3}, {"aid": "2006.02713", "authors": ["Yixiao Ge", "Feng Zhu", "Dapeng Chen", "Rui Zhao", "Hongsheng Li"], "title": "Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID", "url": "http://arxiv.org/pdf/2006.02713v2", "summary": "Domain adaptive object re-ID aims to transfer the learned knowledge from the labeled source domain to the unlabeled target domain to tackle the open-class re-identification problems. Although state-of-the-art pseudo-label-based methods have achieved great success, they did not make full use of all valuable information because of the domain gap and unsatisfying clustering performance. To solve these problems, we propose a novel self-paced contrastive learning framework with hybrid memory. The hybrid memory dynamically generates source-domain class-level, target-domain cluster-level and un-clustered instance-level supervisory signals for learning feature representations. Different from the conventional contrastive learning strategy, the proposed framework jointly distinguishes source-domain classes, and target-domain clusters and un-clustered instances. Most importantly, the proposed self-paced method gradually creates more reliable clusters to refine the hybrid memory and learning targets, and is shown to be the key to our outstanding performance. Our method outperforms state-of-the-arts on multiple domain adaptation tasks of object re-ID and even boosts the performance on the source domain without any extra annotations. Our generalized version on unsupervised object re-ID surpasses state-of-the-art algorithms by considerable 16.7% and 7.9% on Market-1501 and MSMT17 benchmarks.", "published": "2020-06-04T09:12:44Z", "version": 2}, {"aid": "2006.02854", "authors": ["Christian Anti\u0107"], "title": "Analogical proportions", "url": "http://arxiv.org/pdf/2006.02854v15", "summary": "Analogy-making is at the core of human and artificial intelligence and creativity with applications to such diverse tasks as proving mathematical theorems and building mathematical theories, common sense reasoning, learning, language acquisition, and story telling. This paper introduces from first principles an abstract algebraic framework of analogical proportions of the form `$a$ is to $b$ what $c$ is to $d$' in the general setting of universal algebra. This enables us to compare mathematical objects possibly across different domains in a uniform way which is crucial for AI-systems. It turns out that our notion of analogical proportions has appealing mathematical properties. As we construct our model from first principles using only elementary concepts of universal algebra, and since our model questions some basic properties of analogical proportions presupposed in the literature, to convince the reader of the plausibility of our model we show that it can be naturally embedded into first-order logic via model-theoretic types and prove from that perspective that analogical proportions are compatible with structure-preserving mappings. This provides conceptual evidence for its applicability. In a broader sense, this paper is a first step towards a theory of analogical reasoning and learning systems with potential applications to fundamental AI-problems like common sense reasoning and computational learning and creativity.", "published": "2020-06-04T13:44:36Z", "version": 15}, {"aid": "2006.03298", "authors": ["Javier Hernandez-Ortega", "Javier Galbally", "Julian Fierrez", "Laurent Beslay"], "title": "Biometric Quality: Review and Application to Face Recognition with FaceQnet", "url": "http://arxiv.org/pdf/2006.03298v3", "summary": "\"The output of a computerised system can only be as accurate as the information entered into it.\" This rather trivial statement is the basis behind one of the driving concepts in biometric recognition: biometric quality. Quality is nowadays widely regarded as the number one factor responsible for the good or bad performance of automated biometric systems. It refers to the ability of a biometric sample to be used for recognition purposes and produce consistent, accurate, and reliable results. Such a subjective term is objectively estimated by the so-called biometric quality metrics. These algorithms play nowadays a pivotal role in the correct functioning of systems, providing feedback to the users and working as invaluable audit tools. In spite of their unanimously accepted relevance, some of the most used and deployed biometric characteristics are lacking behind in the development of these methods. This is the case of face recognition. After a gentle introduction to the general topic of biometric quality and a review of past efforts in face quality metrics, in the present work, we address the need for better face quality metrics by developing FaceQnet. FaceQnet is a novel open-source face quality assessment tool, inspired and powered by deep learning technology, which assigns a scalar quality measure to facial images, as prediction of their recognition accuracy. Two versions of FaceQnet have been thoroughly evaluated both in this work and also independently by NIST, showing the soundness of the approach and its competitiveness with respect to current state-of-the-art metrics. Even though our work is presented here particularly in the framework of face biometrics, the proposed methodology for building a fully automated quality metric can be very useful and easily adapted to other artificial intelligence tasks.", "published": "2020-06-05T08:33:22Z", "version": 3}, {"aid": "2006.04139", "authors": ["Fuzhi Yang", "Huan Yang", "Jianlong Fu", "Hongtao Lu", "Baining Guo"], "title": "Learning Texture Transformer Network for Image Super-Resolution", "url": "http://arxiv.org/pdf/2006.04139v2", "summary": "We study on image super-resolution (SR), which aims to recover realistic textures from a low-resolution (LR) image. Recent progress has been made by taking high-resolution images as references (Ref), so that relevant textures can be transferred to LR images. However, existing SR approaches neglect to use attention mechanisms to transfer high-resolution (HR) textures from Ref images, which limits these approaches in challenging cases. In this paper, we propose a novel Texture Transformer Network for Image Super-Resolution (TTSR), in which the LR and Ref images are formulated as queries and keys in a transformer, respectively. TTSR consists of four closely-related modules optimized for image generation tasks, including a learnable texture extractor by DNN, a relevance embedding module, a hard-attention module for texture transfer, and a soft-attention module for texture synthesis. Such a design encourages joint feature learning across LR and Ref images, in which deep feature correspondences can be discovered by attention, and thus accurate texture features can be transferred. The proposed texture transformer can be further stacked in a cross-scale way, which enables texture recovery from different levels (e.g., from 1x to 4x magnification). Extensive experiments show that TTSR achieves significant improvements over state-of-the-art approaches on both quantitative and qualitative evaluations.", "published": "2020-06-07T12:55:34Z", "version": 2}, {"aid": "2006.04768", "authors": ["Sinong Wang", "Belinda Z. Li", "Madian Khabsa", "Han Fang", "Hao Ma"], "title": "Linformer: Self-Attention with Linear Complexity", "url": "http://arxiv.org/pdf/2006.04768v3", "summary": "Large transformer models have shown extraordinary success in achieving state-of-the-art results in many natural language processing applications. However, training and deploying these models can be prohibitively costly for long sequences, as the standard self-attention mechanism of the Transformer uses $O(n^2)$ time and space with respect to sequence length. In this paper, we demonstrate that the self-attention mechanism can be approximated by a low-rank matrix. We further exploit this finding to propose a new self-attention mechanism, which reduces the overall self-attention complexity from $O(n^2)$ to $O(n)$ in both time and space. The resulting linear transformer, the \\textit{Linformer}, performs on par with standard Transformer models, while being much more memory- and time-efficient.", "published": "2020-06-08T17:37:52Z", "version": 3}, {"aid": "2006.11161", "authors": ["Aman Chadha", "John Britto", "M. Mani Roja"], "title": "iSeeBetter: Spatio-temporal video super-resolution using recurrent generative back-projection networks", "url": "http://arxiv.org/pdf/2006.11161v4", "summary": "Recently, learning-based models have enhanced the performance of single-image super-resolution (SISR). However, applying SISR successively to each video frame leads to a lack of temporal coherency. Convolutional neural networks (CNNs) outperform traditional approaches in terms of image quality metrics such as peak signal to noise ratio (PSNR) and structural similarity (SSIM). However, generative adversarial networks (GANs) offer a competitive advantage by being able to mitigate the issue of a lack of finer texture details, usually seen with CNNs when super-resolving at large upscaling factors. We present iSeeBetter, a novel GAN-based spatio-temporal approach to video super-resolution (VSR) that renders temporally consistent super-resolution videos. iSeeBetter extracts spatial and temporal information from the current and neighboring frames using the concept of recurrent back-projection networks as its generator. Furthermore, to improve the \"naturality\" of the super-resolved image while eliminating artifacts seen with traditional algorithms, we utilize the discriminator from super-resolution generative adversarial network (SRGAN). Although mean squared error (MSE) as a primary loss-minimization objective improves PSNR/SSIM, these metrics may not capture fine details in the image resulting in misrepresentation of perceptual quality. To address this, we use a four-fold (MSE, perceptual, adversarial, and total-variation (TV)) loss function. Our results demonstrate that iSeeBetter offers superior VSR fidelity and surpasses state-of-the-art performance.", "published": "2020-06-13T01:36:30Z", "version": 4}, {"aid": "2006.07710", "authors": ["Harshay Shah", "Kaustav Tamuly", "Aditi Raghunathan", "Prateek Jain", "Praneeth Netrapalli"], "title": "The Pitfalls of Simplicity Bias in Neural Networks", "url": "http://arxiv.org/pdf/2006.07710v2", "summary": "Several works have proposed Simplicity Bias (SB)---the tendency of standard training procedures such as Stochastic Gradient Descent (SGD) to find simple models---to justify why neural networks generalize well [Arpit et al. 2017, Nakkiran et al. 2019, Soudry et al. 2018]. However, the precise notion of simplicity remains vague. Furthermore, previous settings that use SB to theoretically justify why neural networks generalize well do not simultaneously capture the non-robustness of neural networks---a widely observed phenomenon in practice [Goodfellow et al. 2014, Jo and Bengio 2017]. We attempt to reconcile SB and the superior standard generalization of neural networks with the non-robustness observed in practice by designing datasets that (a) incorporate a precise notion of simplicity, (b) comprise multiple predictive features with varying levels of simplicity, and (c) capture the non-robustness of neural networks trained on real data. Through theory and empirics on these datasets, we make four observations: (i) SB of SGD and variants can be extreme: neural networks can exclusively rely on the simplest feature and remain invariant to all predictive complex features. (ii) The extreme aspect of SB could explain why seemingly benign distribution shifts and small adversarial perturbations significantly degrade model performance. (iii) Contrary to conventional wisdom, SB can also hurt generalization on the same data distribution, as SB persists even when the simplest feature has less predictive power than the more complex features. (iv) Common approaches to improve generalization and robustness---ensembles and adversarial training---can fail in mitigating SB and its pitfalls. Given the role of SB in training neural networks, we hope that the proposed datasets and methods serve as an effective testbed to evaluate novel algorithmic approaches aimed at avoiding the pitfalls of SB.", "published": "2020-06-13T20:15:26Z", "version": 2}, {"aid": "2006.07776", "authors": ["Pengfei Ge", "Chuan-Xian Ren", "Dao-Qing Dai", "Hong Yan"], "title": "Domain Adaptation and Image Classification via Deep Conditional Adaptation Network", "url": "http://arxiv.org/pdf/2006.07776v2", "summary": "Unsupervised domain adaptation aims to generalize the supervised model trained on a source domain to an unlabeled target domain. Marginal distribution alignment of feature spaces is widely used to reduce the domain discrepancy between the source and target domains. However, it assumes that the source and target domains share the same label distribution, which limits their application scope. In this paper, we consider a more general application scenario where the label distributions of the source and target domains are not the same. In this scenario, marginal distribution alignment-based methods will be vulnerable to negative transfer. To address this issue, we propose a novel unsupervised domain adaptation method, Deep Conditional Adaptation Network (DCAN), based on conditional distribution alignment of feature spaces. To be specific, we reduce the domain discrepancy by minimizing the Conditional Maximum Mean Discrepancy between the conditional distributions of deep features on the source and target domains, and extract the discriminant information from target domain by maximizing the mutual information between samples and the prediction labels. In addition, DCAN can be used to address a special scenario, Partial unsupervised domain adaptation, where the target domain category is a subset of the source domain category. Experiments on both unsupervised domain adaptation and Partial unsupervised domain adaptation show that DCAN achieves superior classification performance over state-of-the-art methods.", "published": "2020-06-14T02:56:01Z", "version": 2}, {"aid": "2006.09661", "authors": ["Vincent Sitzmann", "Julien N. P. Martel", "Alexander W. Bergman", "David B. Lindell", "Gordon Wetzstein"], "title": "Implicit Neural Representations with Periodic Activation Functions", "url": "http://arxiv.org/pdf/2006.09661v1", "summary": "Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or Sirens, are ideally suited for representing complex natural signals and their derivatives. We analyze Siren activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how Sirens can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine Sirens with hypernetworks to learn priors over the space of Siren functions.", "published": "2020-06-17T05:13:33Z", "version": 1}, {"aid": "2006.11239", "authors": ["Jonathan Ho", "Ajay Jain", "Pieter Abbeel"], "title": "Denoising Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2006.11239v2", "summary": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion", "published": "2020-06-19T17:24:44Z", "version": 2}, {"aid": "2006.11751", "authors": ["Aleksei Petrenko", "Zhehui Huang", "Tushar Kumar", "Gaurav Sukhatme", "Vladlen Koltun"], "title": "Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning", "url": "http://arxiv.org/pdf/2006.11751v2", "summary": "Increasing the scale of reinforcement learning experiments has allowed researchers to achieve unprecedented results in both training sophisticated agents for video games, and in sim-to-real transfer for robotics. Typically such experiments rely on large distributed systems and require expensive hardware setups, limiting wider access to this exciting area of research. In this work we aim to solve this problem by optimizing the efficiency and resource utilization of reinforcement learning algorithms instead of relying on distributed computation. We present the \"Sample Factory\", a high-throughput training system optimized for a single-machine setting. Our architecture combines a highly efficient, asynchronous, GPU-based sampler with off-policy correction techniques, allowing us to achieve throughput higher than $10^5$ environment frames/second on non-trivial control problems in 3D without sacrificing sample efficiency. We extend Sample Factory to support self-play and population-based training and apply these techniques to train highly capable agents for a multiplayer first-person shooter game. The source code is available at https://github.com/alex-petrenko/sample-factory", "published": "2020-06-21T10:00:23Z", "version": 2}, {"aid": "2006.13554", "authors": ["Xingjun Ma", "Hanxun Huang", "Yisen Wang", "Simone Romano", "Sarah Erfani", "James Bailey"], "title": "Normalized Loss Functions for Deep Learning with Noisy Labels", "url": "http://arxiv.org/pdf/2006.13554v1", "summary": "Robust loss functions are essential for training accurate deep neural networks (DNNs) in the presence of noisy (incorrect) labels. It has been shown that the commonly used Cross Entropy (CE) loss is not robust to noisy labels. Whilst new loss functions have been designed, they are only partially robust. In this paper, we theoretically show by applying a simple normalization that: any loss can be made robust to noisy labels. However, in practice, simply being robust is not sufficient for a loss function to train accurate DNNs. By investigating several robust loss functions, we find that they suffer from a problem of underfitting. To address this, we propose a framework to build robust loss functions called Active Passive Loss (APL). APL combines two robust loss functions that mutually boost each other. Experiments on benchmark datasets demonstrate that the family of new loss functions created by our APL framework can consistently outperform state-of-the-art methods by large margins, especially under large noise rates such as 60% or 80% incorrect labels.", "published": "2020-06-24T08:25:46Z", "version": 1}, {"aid": "2006.13748", "authors": ["Arthur Douillard", "Eduardo Valle", "Charles Ollion", "Thomas Robert", "Matthieu Cord"], "title": "Insights from the Future for Continual Learning", "url": "http://arxiv.org/pdf/2006.13748v1", "summary": "Continual learning aims to learn tasks sequentially, with (often severe) constraints on the storage of old learning samples, without suffering from catastrophic forgetting. In this work, we propose prescient continual learning, a novel experimental setting, to incorporate existing information about the classes, prior to any training data. Usually, each task in a traditional continual learning setting evaluates the model on present and past classes, the latter with a limited number of training samples. Our setting adds future classes, with no training samples at all. We introduce Ghost Model, a representation-learning-based model for continual learning using ideas from zero-shot learning. A generative model of the representation space in concert with a careful adjustment of the losses allows us to exploit insights from future classes to constraint the spatial arrangement of the past and current classes. Quantitative results on the AwA2 and aP\\&Y datasets and detailed visualizations showcase the interest of this new setting and the method we propose to address it.", "published": "2020-06-24T14:05:45Z", "version": 1}, {"aid": "2006.15134", "authors": ["Ziyu Wang", "Alexander Novikov", "Konrad Zolna", "Jost Tobias Springenberg", "Scott Reed", "Bobak Shahriari", "Noah Siegel", "Josh Merel", "Caglar Gulcehre", "Nicolas Heess", "Nando de Freitas"], "title": "Critic Regularized Regression", "url": "http://arxiv.org/pdf/2006.15134v3", "summary": "Offline reinforcement learning (RL), also known as batch RL, offers the prospect of policy optimization from large pre-recorded datasets without online environment interaction. It addresses challenges with regard to the cost of data collection and safety, both of which are particularly pertinent to real-world applications of RL. Unfortunately, most off-policy algorithms perform poorly when learning from a fixed dataset. In this paper, we propose a novel offline RL algorithm to learn policies from data using a form of critic-regularized regression (CRR). We find that CRR performs surprisingly well and scales to tasks with high-dimensional state and action spaces -- outperforming several state-of-the-art offline RL algorithms by a significant margin on a wide range of benchmark tasks.", "published": "2020-06-26T17:50:26Z", "version": 3}, {"aid": "2006.15486", "authors": ["Imtiaz Masud Ziko", "Jose Dolz", "Eric Granger", "Ismail Ben Ayed"], "title": "Laplacian Regularized Few-Shot Learning", "url": "http://arxiv.org/pdf/2006.15486v3", "summary": "We propose a transductive Laplacian-regularized inference for few-shot tasks. Given any feature embedding learned from the base classes, we minimize a quadratic binary-assignment function containing two terms: (1) a unary term assigning query samples to the nearest class prototype, and (2) a pairwise Laplacian term encouraging nearby query samples to have consistent label assignments. Our transductive inference does not re-train the base model, and can be viewed as a graph clustering of the query set, subject to supervision constraints from the support set. We derive a computationally efficient bound optimizer of a relaxation of our function, which computes independent (parallel) updates for each query sample, while guaranteeing convergence. Following a simple cross-entropy training on the base classes, and without complex meta-learning strategies, we conducted comprehensive experiments over five few-shot learning benchmarks. Our LaplacianShot consistently outperforms state-of-the-art methods by significant margins across different models, settings, and data sets. Furthermore, our transductive inference is very fast, with computational times that are close to inductive inference, and can be used for large-scale few-shot tasks.", "published": "2020-06-28T02:17:52Z", "version": 3}, {"aid": "2006.16241", "authors": ["Dan Hendrycks", "Steven Basart", "Norman Mu", "Saurav Kadavath", "Frank Wang", "Evan Dorundo", "Rahul Desai", "Tyler Zhu", "Samyak Parajuli", "Mike Guo", "Dawn Song", "Jacob Steinhardt", "Justin Gilmer"], "title": "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization", "url": "http://arxiv.org/pdf/2006.16241v3", "summary": "We introduce four new real-world distribution shift datasets consisting of changes in image style, image blurriness, geographic location, camera operation, and more. With our new datasets, we take stock of previously proposed methods for improving out-of-distribution robustness and put them to the test. We find that using larger models and artificial data augmentations can improve robustness on real-world distribution shifts, contrary to claims in prior work. We find improvements in artificial robustness benchmarks can transfer to real-world distribution shifts, contrary to claims in prior work. Motivated by our observation that data augmentations can help with real-world distribution shifts, we also introduce a new data augmentation method which advances the state-of-the-art and outperforms models pretrained with 1000 times more labeled data. Overall we find that some methods consistently help with distribution shifts in texture and local image statistics, but these methods do not help with some other distribution shifts like geographic changes. Our results show that future research must study multiple distribution shifts simultaneously, as we demonstrate that no evaluated method consistently improves robustness.", "published": "2020-06-29T17:59:10Z", "version": 3}, {"aid": "2006.16669", "authors": ["Di Wu", "Qi Tang", "Yongle Zhao", "Ming Zhang", "Ying Fu", "Debing Zhang"], "title": "EasyQuant: Post-training Quantization via Scale Optimization", "url": "http://arxiv.org/pdf/2006.16669v1", "summary": "The 8 bits quantization has been widely applied to accelerate network inference in various deep learning applications. There are two kinds of quantization methods, training-based quantization and post-training quantization. Training-based approach suffers from a cumbersome training process, while post-training quantization may lead to unacceptable accuracy drop. In this paper, we present an efficient and simple post-training method via scale optimization, named EasyQuant (EQ),that could obtain comparable accuracy with the training-based method.Specifically, we first alternately optimize scales of weights and activations for all layers target at convolutional outputs to further obtain the high quantization precision. Then, we lower down bit width to INT7 both for weights and activations, and adopt INT16 intermediate storage and integer Winograd convolution implementation to accelerate inference.Experimental results on various computer vision tasks show that EQ outperforms the TensorRT method and can achieve near INT8 accuracy in 7 bits width post-training.", "published": "2020-06-30T10:43:02Z", "version": 1}, {"aid": "2007.00224", "authors": ["Ching-Yao Chuang", "Joshua Robinson", "Lin Yen-Chen", "Antonio Torralba", "Stefanie Jegelka"], "title": "Debiased Contrastive Learning", "url": "http://arxiv.org/pdf/2007.00224v3", "summary": "A prominent technique for self-supervised representation learning has been to contrast semantically similar and dissimilar pairs of samples. Without access to labels, dissimilar (negative) points are typically taken to be randomly sampled datapoints, implicitly accepting that these points may, in reality, actually have the same label. Perhaps unsurprisingly, we observe that sampling negative examples from truly different labels improves performance, in a synthetic setting where labels are available. Motivated by this observation, we develop a debiased contrastive objective that corrects for the sampling of same-label datapoints, even without knowledge of the true labels. Empirically, the proposed objective consistently outperforms the state-of-the-art for representation learning in vision, language, and reinforcement learning benchmarks. Theoretically, we establish generalization bounds for the downstream classification task.", "published": "2020-07-01T04:25:24Z", "version": 3}, {"aid": "2007.01378", "authors": ["Yonatan Sanz Perl", "Hern\u00e1n Boccacio", "Ignacio P\u00e9rez-Ipi\u00f1a", "Federico Zamberl\u00e1n", "Helmut Laufs", "Morten Kringelbach", "Gustavo Deco", "Enzo Tagliazucchi"], "title": "Generative embeddings of brain collective dynamics using variational autoencoders", "url": "http://arxiv.org/pdf/2007.01378v1", "summary": "We consider the problem of encoding pairwise correlations between coupled dynamical systems in a low-dimensional latent space based on few distinct observations. We used variational autoencoders (VAE) to embed temporal correlations between coupled nonlinear oscillators that model brain states in the wake-sleep cycle into a two-dimensional manifold. Training a VAE with samples generated using two different parameter combinations resulted in an embedding that represented the whole repertoire of collective dynamics, as well as the topology of the underlying connectivity network. We first followed this approach to infer the trajectory of brain states measured from wakefulness to deep sleep from the two endpoints of this trajectory; next, we showed that the same architecture was capable of representing the pairwise correlations of generic Landau-Stuart oscillators coupled by complex network topology", "published": "2020-07-02T20:43:52Z", "version": 1}, {"aid": "2007.01476", "authors": ["Shipeng Fu", "Zhen Li", "Jun Xu", "Ming-Ming Cheng", "Zitao Liu", "Xiaomin Yang"], "title": "Interactive Knowledge Distillation", "url": "http://arxiv.org/pdf/2007.01476v3", "summary": "Knowledge distillation is a standard teacher-student learning framework to train a light-weight student network under the guidance of a well-trained large teacher network. As an effective teaching strategy, interactive teaching has been widely employed at school to motivate students, in which teachers not only provide knowledge but also give constructive feedback to students upon their responses, to improve their learning performance. In this work, we propose an InterActive Knowledge Distillation (IAKD) scheme to leverage the interactive teaching strategy for efficient knowledge distillation. In the distillation process, the interaction between teacher and student networks is implemented by a swapping-in operation: randomly replacing the blocks in the student network with the corresponding blocks in the teacher network. In the way, we directly involve the teacher's powerful feature transformation ability to largely boost the student's performance. Experiments with typical settings of teacher-student networks demonstrate that the student networks trained by our IAKD achieve better performance than those trained by conventional knowledge distillation methods on diverse image classification datasets.", "published": "2020-07-03T03:22:04Z", "version": 3}, {"aid": "2007.01524", "authors": ["Youngeun Kim", "Donghyeon Cho", "Kyeongtak Han", "Priyadarshini Panda", "Sungeun Hong"], "title": "Domain Adaptation without Source Data", "url": "http://arxiv.org/pdf/2007.01524v4", "summary": "Domain adaptation assumes that samples from source and target domains are freely accessible during a training phase. However, such an assumption is rarely plausible in the real-world and possibly causes data-privacy issues, especially when the label of the source domain can be a sensitive attribute as an identifier. To avoid accessing source data that may contain sensitive information, we introduce Source data-Free Domain Adaptation (SFDA). Our key idea is to leverage a pre-trained model from the source domain and progressively update the target model in a self-learning manner. We observe that target samples with lower self-entropy measured by the pre-trained source model are more likely to be classified correctly. From this, we select the reliable samples with the self-entropy criterion and define these as class prototypes. We then assign pseudo labels for every target sample based on the similarity score with class prototypes. Furthermore, to reduce the uncertainty from the pseudo labeling process, we propose set-to-set distance-based filtering which does not require any tunable hyperparameters. Finally, we train the target model with the filtered pseudo labels with regularization from the pre-trained source model. Surprisingly, without direct usage of labeled source samples, our PrDA outperforms conventional domain adaptation methods on benchmark datasets. Our code is publicly available at https://github.com/youngryan1993/SFDA-SourceFreeDA", "published": "2020-07-03T07:21:30Z", "version": 4}, {"aid": "2007.01682", "authors": ["Miao Tian", "Dongyan Guo", "Ying Cui", "Xiang Pan", "Shengyong Chen"], "title": "Improving auto-encoder novelty detection using channel attention and entropy minimization", "url": "http://arxiv.org/pdf/2007.01682v2", "summary": "Novelty detection is a important research area which mainly solves the classification problem of inliers which usually consists of normal samples and outliers composed of abnormal samples. Auto-encoder is often used for novelty detection. However, the generalization ability of the auto-encoder may cause the undesirable reconstruction of abnormal elements and reduce the identification ability of the model. To solve the problem, we focus on the perspective of better reconstructing the normal samples as well as retaining the unique information of normal samples to improve the performance of auto-encoder for novelty detection. Firstly, we introduce attention mechanism into the task. Under the action of attention mechanism, auto-encoder can pay more attention to the representation of inlier samples through adversarial training. Secondly, we apply the information entropy into the latent layer to make it sparse and constrain the expression of diversity. Experimental results on three public datasets show that the proposed method achieves comparable performance compared with previous popular approaches.", "published": "2020-07-03T13:41:34Z", "version": 2}, {"aid": "2007.01755", "authors": ["Bin-Bin Gao", "Hong-Yu Zhou"], "title": "Learning to Discover Multi-Class Attentional Regions for Multi-Label Image Recognition", "url": "http://arxiv.org/pdf/2007.01755v3", "summary": "Multi-label image recognition is a practical and challenging task compared to single-label image classification. However, previous works may be suboptimal because of a great number of object proposals or complex attentional region generation modules. In this paper, we propose a simple but efficient two-stream framework to recognize multi-category objects from global image to local regions, similar to how human beings perceive objects. To bridge the gap between global and local streams, we propose a multi-class attentional region module which aims to make the number of attentional regions as small as possible and keep the diversity of these regions as high as possible. Our method can efficiently and effectively recognize multi-class objects with an affordable computation cost and a parameter-free region localization module. Over three benchmarks on multi-label image classification, we create new state-of-the-art results with a single model only using image semantics without label dependency. In addition, the effectiveness of the proposed method is extensively demonstrated under different factors such as global pooling strategy, input size and network architecture. Code has been made available at~\\url{https://github.com/gaobb/MCAR}.", "published": "2020-07-03T15:22:46Z", "version": 3}, {"aid": "2007.02443", "authors": ["Jary Pomponi", "Simone Scardapane", "Aurelio Uncini"], "title": "Pseudo-Rehearsal for Continual Learning with Normalizing Flows", "url": "http://arxiv.org/pdf/2007.02443v4", "summary": "Catastrophic forgetting (CF) happens whenever a neural network overwrites past knowledge while being trained on new tasks. Common techniques to handle CF include regularization of the weights (using, e.g., their importance on past tasks), and rehearsal strategies, where the network is constantly re-trained on past data. Generative models have also been applied for the latter, in order to have endless sources of data. In this paper, we propose a novel method that combines the strengths of regularization and generative-based rehearsal approaches. Our generative model consists of a normalizing flow (NF), a probabilistic and invertible neural network, trained on the internal embeddings of the network. By keeping a single NF conditioned on the task, we show that our memory overhead remains constant. In addition, exploiting the invertibility of the NF, we propose a simple approach to regularize the network's embeddings with respect to past tasks. We show that our method performs favorably with respect to state-of-the-art approaches in the literature, with bounded computational power and memory overheads.", "published": "2020-07-05T20:43:52Z", "version": 4}, {"aid": "2007.02454", "authors": ["Zeyi Huang", "Haohan Wang", "Eric P. Xing", "Dong Huang"], "title": "Self-Challenging Improves Cross-Domain Generalization", "url": "http://arxiv.org/pdf/2007.02454v1", "summary": "Convolutional Neural Networks (CNN) conduct image classification by activating dominant features that correlated with labels. When the training and testing data are under similar distributions, their dominant features are similar, which usually facilitates decent performance on the testing data. The performance is nonetheless unmet when tested on samples from different distributions, leading to the challenges in cross-domain image classification. We introduce a simple training heuristic, Representation Self-Challenging (RSC), that significantly improves the generalization of CNN to the out-of-domain data. RSC iteratively challenges (discards) the dominant features activated on the training data, and forces the network to activate remaining features that correlates with labels. This process appears to activate feature representations applicable to out-of-domain data without prior knowledge of new domain and without learning extra network parameters. We present theoretical properties and conditions of RSC for improving cross-domain generalization. The experiments endorse the simple, effective and architecture-agnostic nature of our RSC method.", "published": "2020-07-05T21:42:26Z", "version": 1}, {"aid": "2007.02731", "authors": ["Didrik Nielsen", "Priyank Jaini", "Emiel Hoogeboom", "Ole Winther", "Max Welling"], "title": "SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows", "url": "http://arxiv.org/pdf/2007.02731v2", "summary": "Normalizing flows and variational autoencoders are powerful generative models that can represent complicated density functions. However, they both impose constraints on the models: Normalizing flows use bijective transformations to model densities whereas VAEs learn stochastic transformations that are non-invertible and thus typically do not provide tractable estimates of the marginal likelihood. In this paper, we introduce SurVAE Flows: A modular framework of composable transformations that encompasses VAEs and normalizing flows. SurVAE Flows bridge the gap between normalizing flows and VAEs with surjective transformations, wherein the transformations are deterministic in one direction -- thereby allowing exact likelihood computation, and stochastic in the reverse direction -- hence providing a lower bound on the corresponding likelihood. We show that several recently proposed methods, including dequantization and augmented normalizing flows, can be expressed as SurVAE Flows. Finally, we introduce common operations such as the max value, the absolute value, sorting and stochastic permutation as composable layers in SurVAE Flows.", "published": "2020-07-06T13:13:22Z", "version": 2}, {"aid": "2007.02798", "authors": ["Sam Bond-Taylor", "Chris G. Willcocks"], "title": "Gradient Origin Networks", "url": "http://arxiv.org/pdf/2007.02798v5", "summary": "This paper proposes a new type of generative model that is able to quickly learn a latent representation without an encoder. This is achieved using empirical Bayes to calculate the expectation of the posterior, which is implemented by initialising a latent vector with zeros, then using the gradient of the log-likelihood of the data with respect to this zero vector as new latent points. The approach has similar characteristics to autoencoders, but with a simpler architecture, and is demonstrated in a variational autoencoder equivalent that permits sampling. This also allows implicit representation networks to learn a space of implicit functions without requiring a hypernetwork, retaining their representation advantages across datasets. The experiments show that the proposed method converges faster, with significantly lower reconstruction error than autoencoders, while requiring half the parameters.", "published": "2020-07-06T15:00:11Z", "version": 5}, {"aid": "2007.07797", "authors": ["Varun Saravanan", "Gordon J Berman", "Samuel J Sober"], "title": "Application of the hierarchical bootstrap to multi-level data in neuroscience", "url": "http://arxiv.org/pdf/2007.07797v2", "summary": "A common feature in many neuroscience datasets is the presence of hierarchical data structures, most commonly recording the activity of multiple neurons in multiple animals across multiple trials. Accordingly, the measurements constituting the dataset are not independent, even though the traditional statistical analyses often applied in such cases (e.g., Students t-test) treat them as such. The hierarchical bootstrap has been shown to be an effective tool to accurately analyze such data and while it has been used extensively in the statistical literature, its use is not widespread in neuroscience - despite the ubiquity of hierarchical datasets. In this paper, we illustrate the intuitiveness and utility of this approach to analyze hierarchically nested datasets. We use simulated neural data to show that traditional statistical tests can result in a false positive rate of over 45%, even if the Type-I error rate is set at 5%. While summarizing data across non-independent points (or lower levels) can potentially fix this problem, this approach greatly reduces the statistical power of the analysis. The hierarchical bootstrap, when applied sequentially over the levels of the hierarchical structure, keeps the Type-I error rate within the intended bound and retains more statistical power than summarizing methods. We conclude by demonstrating the effectiveness of the method in two real-world examples, first analyzing singing data in male Bengalese finches (Lonchura striata var. domestica) and second quantifying changes in behavior under optogenetic control in flies (Drosophila melanogaster).", "published": "2020-07-15T16:20:25Z", "version": 2}, {"aid": "2008.02217", "authors": ["Hubert Ramsauer", "Bernhard Sch\u00e4fl", "Johannes Lehner", "Philipp Seidl", "Michael Widrich", "Thomas Adler", "Lukas Gruber", "Markus Holzleitner", "Milena Pavlovi\u0107", "Geir Kjetil Sandve", "Victor Greiff", "David Kreil", "Michael Kopp", "G\u00fcnter Klambauer", "Johannes Brandstetter", "Sepp Hochreiter"], "title": "Hopfield Networks is All You Need", "url": "http://arxiv.org/pdf/2008.02217v3", "summary": "We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: https://github.com/ml-jku/hopfield-layers", "published": "2020-07-16T17:52:37Z", "version": 3}, {"aid": "2007.10412", "authors": ["Deniz Oktay", "Nick McGreivy", "Joshua Aduol", "Alex Beatson", "Ryan P. Adams"], "title": "Randomized Automatic Differentiation", "url": "http://arxiv.org/pdf/2007.10412v2", "summary": "The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which can allow unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.", "published": "2020-07-20T19:03:44Z", "version": 2}, {"aid": "2008.02496", "authors": ["Zihang Jiang", "Weihao Yu", "Daquan Zhou", "Yunpeng Chen", "Jiashi Feng", "Shuicheng Yan"], "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution", "url": "http://arxiv.org/pdf/2008.02496v3", "summary": "Pre-trained language models like BERT and its variants have recently achieved impressive performance in various natural language understanding tasks. However, BERT heavily relies on the global self-attention block and thus suffers large memory footprint and computation cost. Although all its attention heads query on the whole input sequence for generating the attention map from a global perspective, we observe some heads only need to learn local dependencies, which means the existence of computation redundancy. We therefore propose a novel span-based dynamic convolution to replace these self-attention heads to directly model local dependencies. The novel convolution heads, together with the rest self-attention heads, form a new mixed attention block that is more efficient at both global and local context learning. We equip BERT with this mixed attention design and build a ConvBERT model. Experiments have shown that ConvBERT significantly outperforms BERT and its variants in various downstream tasks, with lower training cost and fewer model parameters. Remarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than ELECTRAbase, while using less than 1/4 training cost. Code and pre-trained models will be released.", "published": "2020-08-06T07:43:19Z", "version": 3}, {"aid": "2008.03238", "authors": ["Maxwell J. D. Ramstead", "Casper Hesp", "Alec Tschantz", "Ryan Smith", "Axel Constant", "Karl Friston"], "title": "Neural and phenotypic representation under the free-energy principle", "url": "http://arxiv.org/pdf/2008.03238v2", "summary": "The aim of this paper is to leverage the free-energy principle and its corollary process theory, active inference, to develop a generic, generalizable model of the representational capacities of living creatures; that is, a theory of phenotypic representation. Given their ubiquity, we are concerned with distributed forms of representation (e.g., population codes), whereby patterns of ensemble activity in living tissue come to represent the causes of sensory input or data. The active inference framework rests on the Markov blanket formalism, which allows us to partition systems of interest, such as biological systems, into internal states, external states, and the blanket (active and sensory) states that render internal and external states conditionally independent of each other. In this framework, the representational capacity of living creatures emerges as a consequence of their Markovian structure and nonequilibrium dynamics, which together entail a dual-aspect information geometry. This entails a modest representational capacity: internal states have an intrinsic information geometry that describes their trajectory over time in state space, as well as an extrinsic information geometry that allows internal states to encode (the parameters of) probabilistic beliefs about (fictive) external states. Building on this, we describe here how, in an automatic and emergent manner, information about stimuli can come to be encoded by groups of neurons bound by a Markov blanket; what is known as the neuronal packet hypothesis. As a concrete demonstration of this type of emergent representation, we present numerical simulations showing that self-organizing ensembles of active inference agents sharing the right kind of probabilistic generative model are able to encode recoverable information about a stimulus array.", "published": "2020-08-07T15:55:42Z", "version": 2}, {"aid": "2008.06021", "authors": ["Arslan Ali", "Matteo Testa", "Tiziano Bianchi", "Enrico Magli"], "title": "BioMetricNet: deep unconstrained face verification through learning of metrics regularized onto Gaussian distributions", "url": "http://arxiv.org/pdf/2008.06021v1", "summary": "We present BioMetricNet: a novel framework for deep unconstrained face verification which learns a regularized metric to compare facial features. Differently from popular methods such as FaceNet, the proposed approach does not impose any specific metric on facial features; instead, it shapes the decision space by learning a latent representation in which matching and non-matching pairs are mapped onto clearly separated and well-behaved target distributions. In particular, the network jointly learns the best feature representation, and the best metric that follows the target distributions, to be used to discriminate face images. In this paper we present this general framework, first of its kind for facial verification, and tailor it to Gaussian distributions. This choice enables the use of a simple linear decision boundary that can be tuned to achieve the desired trade-off between false alarm and genuine acceptance rate, and leads to a loss function that can be written in closed form. Extensive analysis and experimentation on publicly available datasets such as Labeled Faces in the wild (LFW), Youtube faces (YTF), Celebrities in Frontal-Profile in the Wild (CFP), and challenging datasets like cross-age LFW (CALFW), cross-pose LFW (CPLFW), In-the-wild Age Dataset (AgeDB) show a significant performance improvement and confirms the effectiveness and superiority of BioMetricNet over existing state-of-the-art methods.", "published": "2020-08-13T17:22:46Z", "version": 1}, {"aid": "2009.01675", "authors": ["Zihao Wang", "Herv\u00e9 Delingette"], "title": "Quasi-symplectic Langevin Variational Autoencoder", "url": "http://arxiv.org/pdf/2009.01675v4", "summary": "Variational autoencoder (VAE) is a very popular and well-investigated generative model in neural learning research. To leverage VAE in practical tasks dealing with a massive dataset of large dimensions, it is required to deal with the difficulty of building low variance evidence lower bounds (ELBO). Markov Chain Monte Carlo (MCMC) is an effective approach to tighten the ELBO for approximating the posterior distribution and Hamiltonian Variational Autoencoder (HVAE) is an effective MCMC inspired approach for constructing a low-variance ELBO that is amenable to the reparameterization trick. The HVAE adapted the Hamiltonian dynamic flow into variational inference that significantly improves the performance of the posterior estimation. We propose in this work a Langevin dynamic flow-based inference approach by incorporating the gradients information in the inference process through the Langevin dynamic which is a kind of MCMC based method similar to HVAE. Specifically, we employ a quasi-symplectic integrator to cope with the prohibit problem of the Hessian computing in naive Langevin flow. We show the theoretical and practical effectiveness of the proposed framework with other gradient flow-based methods.", "published": "2020-09-02T12:13:27Z", "version": 4}, {"aid": "2009.04765", "authors": ["Nicolas Affolter", "Beni Egressy", "Damian Pascual", "Roger Wattenhofer"], "title": "Brain2Word: Decoding Brain Activity for Language Generation", "url": "http://arxiv.org/pdf/2009.04765v3", "summary": "Brain decoding, understood as the process of mapping brain activities to the stimuli that generated them, has been an active research area in the last years. In the case of language stimuli, recent studies have shown that it is possible to decode fMRI scans into an embedding of the word a subject is reading. However, such word embeddings are designed for natural language processing tasks rather than for brain decoding. Therefore, they limit our ability to recover the precise stimulus. In this work, we propose to directly classify an fMRI scan, mapping it to the corresponding word within a fixed vocabulary. Unlike existing work, we evaluate on scans from previously unseen subjects. We argue that this is a more realistic setup and we present a model that can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1 and 13.59% Top-5 accuracy in this challenging task, significantly outperforming all the considered competitive baselines. Furthermore, we use the decoded words to guide language generation with the GPT-2 model. This way, we advance the quest for a system that translates brain activities into coherent text.", "published": "2020-09-10T10:47:36Z", "version": 3}, {"aid": "2009.07888", "authors": ["Zhuangdi Zhu", "Kaixiang Lin", "Anil K. Jain", "Jiayu Zhou"], "title": "Transfer Learning in Deep Reinforcement Learning: A Survey", "url": "http://arxiv.org/pdf/2009.07888v7", "summary": "Reinforcement learning is a learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in reinforcement learning upon the fast development of deep neural networks. Along with the promising prospects of reinforcement learning in numerous domains such as robotics and game-playing, transfer learning has arisen to tackle various challenges faced by reinforcement learning, by transferring knowledge from external expertise to facilitate the efficiency and effectiveness of the learning process. In this survey, we systematically investigate the recent progress of transfer learning approaches in the context of deep reinforcement learning. Specifically, we provide a framework for categorizing the state-of-the-art transfer learning approaches, under which we analyze their goals, methodologies, compatible reinforcement learning backbones, and practical applications. We also draw connections between transfer learning and other relevant topics from the reinforcement learning perspective and explore their potential challenges that await future research progress.", "published": "2020-09-16T18:38:54Z", "version": 7}, {"aid": "2009.09321", "authors": ["Christopher Ick", "Vincent Lostanlen"], "title": "Learning a Lie Algebra from Unlabeled Data Pairs", "url": "http://arxiv.org/pdf/2009.09321v3", "summary": "Deep convolutional networks (convnets) show a remarkable ability to learn disentangled representations. In recent years, the generalization of deep learning to Lie groups beyond rigid motion in $\\mathbb{R}^n$ has allowed to build convnets over datasets with non-trivial symmetries, such as patterns over the surface of a sphere. However, one limitation of this approach is the need to explicitly define the Lie group underlying the desired invariance property before training the convnet. Whereas rotations on the sphere have a well-known symmetry group ($\\mathrm{SO}(3)$), the same cannot be said of many real-world factors of variability. For example, the disentanglement of pitch, intensity dynamics, and playing technique remains a challenging task in music information retrieval.   This article proposes a machine learning method to discover a nonlinear transformation of the space $\\mathbb{R}^n$ which maps a collection of $n$-dimensional vectors $(\\boldsymbol{x}_i)_i$ onto a collection of target vectors $(\\boldsymbol{y}_i)_i$. The key idea is to approximate every target $\\boldsymbol{y}_i$ by a matrix--vector product of the form $\\boldsymbol{\\widetilde{y}}_i = \\boldsymbol{\\phi}(t_i) \\boldsymbol{x}_i$, where the matrix $\\boldsymbol{\\phi}(t_i)$ belongs to a one-parameter subgroup of $\\mathrm{GL}_n (\\mathbb{R})$. Crucially, the value of the parameter $t_i \\in \\mathbb{R}$ may change between data pairs $(\\boldsymbol{x}_i, \\boldsymbol{y}_i)$ and does not need to be known in advance.", "published": "2020-09-19T23:23:52Z", "version": 3}, {"aid": "2009.10301", "authors": ["Benyamin Ghojogh", "Ali Ghodsi", "Fakhri Karray", "Mark Crowley"], "title": "Stochastic Neighbor Embedding with Gaussian and Student-t Distributions: Tutorial and Survey", "url": "http://arxiv.org/pdf/2009.10301v2", "summary": "Stochastic Neighbor Embedding (SNE) is a manifold learning and dimensionality reduction method with a probabilistic approach. In SNE, every point is consider to be the neighbor of all other points with some probability and this probability is tried to be preserved in the embedding space. SNE considers Gaussian distribution for the probability in both the input and embedding spaces. However, t-SNE uses the Student-t and Gaussian distributions in these spaces, respectively. In this tutorial and survey paper, we explain SNE, symmetric SNE, t-SNE (or Cauchy-SNE), and t-SNE with general degrees of freedom. We also cover the out-of-sample extension and acceleration for these methods.", "published": "2020-09-22T03:32:05Z", "version": 2}, {"aid": "2009.13472", "authors": ["Matthew James Vowels", "Necati Cihan Camgoz", "Richard Bowden"], "title": "Targeted VAE: Variational and Targeted Learning for Causal Inference", "url": "http://arxiv.org/pdf/2009.13472v5", "summary": "Undertaking causal inference with observational data is incredibly useful across a wide range of tasks including the development of medical treatments, advertisements and marketing, and policy making. There are two significant challenges associated with undertaking causal inference using observational data: treatment assignment heterogeneity (\\textit{i.e.}, differences between the treated and untreated groups), and an absence of counterfactual data (\\textit{i.e.}, not knowing what would have happened if an individual who did get treatment, were instead to have not been treated). We address these two challenges by combining structured inference and targeted learning. In terms of structure, we factorize the joint distribution into risk, confounding, instrumental, and miscellaneous factors, and in terms of targeted learning, we apply a regularizer derived from the influence curve in order to reduce residual bias. An ablation study is undertaken, and an evaluation on benchmark datasets demonstrates that TVAE has competitive and state of the art performance.", "published": "2020-09-28T16:55:24Z", "version": 5}, {"aid": "2009.14788", "authors": ["Matteo Ronchetti"], "title": "TorchRadon: Fast Differentiable Routines for Computed Tomography", "url": "http://arxiv.org/pdf/2009.14788v1", "summary": "This work presents TorchRadon -- an open source CUDA library which contains a set of differentiable routines for solving computed tomography (CT) reconstruction problems. The library is designed to help researchers working on CT problems to combine deep learning and model-based approaches. The package is developed as a PyTorch extension and can be seamlessly integrated into existing deep learning training code. Compared to the existing Astra Toolbox, TorchRadon is up to 125 faster. The operators implemented by TorchRadon allow the computation of gradients using PyTorch backward(), and can therefore be easily inserted inside existing neural networks architectures. Because of its speed and GPU support, TorchRadon can also be effectively used as a fast backend for the implementation of iterative algorithms. This paper presents the main functionalities of the library, compares results with existing libraries and provides examples of usage.", "published": "2020-09-29T09:20:22Z", "version": 1}, {"aid": "2009.14237", "authors": ["Andrew Head", "Kyle Lo", "Dongyeop Kang", "Raymond Fok", "Sam Skjonsberg", "Daniel S. Weld", "Marti A. Hearst"], "title": "Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols", "url": "http://arxiv.org/pdf/2009.14237v3", "summary": "Despite the central importance of research papers to scientific progress, they can be difficult to read. Comprehension is often stymied when the information needed to understand a passage resides somewhere else: in another section, or in another paper. In this work, we envision how interfaces can bring definitions of technical terms and symbols to readers when and where they need them most. We introduce ScholarPhi, an augmented reading interface with four novel features: (1) tooltips that surface position-sensitive definitions from elsewhere in a paper, (2) a filter over the paper that \"declutters\" it to reveal how the term or symbol is used across the paper, (3) automatic equation diagrams that expose multiple definitions in parallel, and (4) an automatically generated glossary of important terms and symbols. A usability study showed that the tool helps researchers of all experience levels read papers. Furthermore, researchers were eager to have ScholarPhi's definitions available to support their everyday reading.", "published": "2020-09-29T18:11:19Z", "version": 3}, {"aid": "2009.14264", "authors": ["Amitai Bickel", "Alexey Gavrilov", "Shimon Ivry", "Neta B Maimon", "Lior Molcho", "Nathan Intrator"], "title": "Reduced neural activity during volatile anesthesia compared to TIVA: evidence from a novel EEG signal processing analysis", "url": "http://arxiv.org/pdf/2009.14264v3", "summary": "Post-operative cognitive decline is a well-known phenomenon and of crucial importance especially in the elderly. General anesthesia can be accomplished by inhalation-based (volatile) or total intravenous anesthesia (TIVA). While their effects on post-operative symptoms have been investigated, little is known about their influence on brain functionalities during the surgery itself. To assess differences 17 patients were divided to receive either volatile anesthesia (n=9), or TIVA (n=8). The level of anesthesia was kept to be equal in both groups. A single bipolar EEG electrode (Neurosteer system) was placed on the participants foreheads. It presented real-time activity and collected their data during the surgery. The dependent variables included frequency bands (delta, theta, alpha, and beta), and three features (VC9, ST4, and A0) previously extracted with the device and provided by Neurosteer. All surgeries were uneventful, and all patients showed bispectral index (BIS) score less than 60. Feature activity under volatile anesthesia (in comparison to TIVA) was significantly lower for the delta, theta and alpha frequency bands and for the three features. Further analysis showed that the largest difference between anesthesia types was for feature A0. The EEG frequency bands and novel brain activity features provide evidence that volatile anesthesia further reduces components of brain activity in comparison to TIVA anesthesia. Specifically, A0, which previously showed a correlation with cognitive decline severity and cognitive load, exhibited the most prominent difference between anesthesia types. Together, this study suggests that measuring brain activity during anesthesia using sensitive features, enables revealing that different anesthesia types may affect brain activity differently, which could affect the recovery from anesthesia, and consequently reduce post-operative cognitive decline", "published": "2020-09-29T19:11:14Z", "version": 3}, {"aid": "2009.14385", "authors": ["Alexander Wong", "Mahmoud Famouri", "Mohammad Javad Shafiee"], "title": "AttendNets: Tiny Deep Image Recognition Neural Networks for the Edge via Visual Attention Condensers", "url": "http://arxiv.org/pdf/2009.14385v1", "summary": "While significant advances in deep learning has resulted in state-of-the-art performance across a large number of complex visual perception tasks, the widespread deployment of deep neural networks for TinyML applications involving on-device, low-power image recognition remains a big challenge given the complexity of deep neural networks. In this study, we introduce AttendNets, low-precision, highly compact deep neural networks tailored for on-device image recognition. More specifically, AttendNets possess deep self-attention architectures based on visual attention condensers, which extends on the recently introduced stand-alone attention condensers to improve spatial-channel selective attention. Furthermore, AttendNets have unique machine-designed macroarchitecture and microarchitecture designs achieved via a machine-driven design exploration strategy. Experimental results on ImageNet$_{50}$ benchmark dataset for the task of on-device image recognition showed that AttendNets have significantly lower architectural and computational complexity when compared to several deep neural networks in research literature designed for efficiency while achieving highest accuracies (with the smallest AttendNet achieving $\\sim$7.2% higher accuracy, while requiring $\\sim$3$\\times$ fewer multiply-add operations, $\\sim$4.17$\\times$ fewer parameters, and $\\sim$16.7$\\times$ lower weight memory requirements than MobileNet-V1). Based on these promising results, AttendNets illustrate the effectiveness of visual attention condensers as building blocks for enabling various on-device visual perception tasks for TinyML applications.", "published": "2020-09-30T01:53:17Z", "version": 1}, {"aid": "2009.14410", "authors": ["Fanxu Meng", "Hao Cheng", "Ke Li", "Huixiang Luo", "Xiaowei Guo", "Guangming Lu", "Xing Sun"], "title": "Pruning Filter in Filter", "url": "http://arxiv.org/pdf/2009.14410v3", "summary": "Pruning has become a very powerful and effective technique to compress and accelerate modern neural networks. Existing pruning methods can be grouped into two categories: filter pruning (FP) and weight pruning (WP). FP wins at hardware compatibility but loses at the compression ratio compared with WP. To converge the strength of both methods, we propose to prune the filter in the filter. Specifically, we treat a filter $F \\in \\mathbb{R}^{C\\times K\\times K}$ as $K \\times K$ stripes, i.e., $1\\times 1$ filters $\\in \\mathbb{R}^{C}$, then by pruning the stripes instead of the whole filter, we can achieve finer granularity than traditional FP while being hardware friendly. We term our method as SWP (\\emph{Stripe-Wise Pruning}). SWP is implemented by introducing a novel learnable matrix called Filter Skeleton, whose values reflect the shape of each filter. As some recent work has shown that the pruned architecture is more crucial than the inherited important weights, we argue that the architecture of a single filter, i.e., the shape, also matters. Through extensive experiments, we demonstrate that SWP is more effective compared to the previous FP-based methods and achieves the state-of-art pruning ratio on CIFAR-10 and ImageNet datasets without obvious accuracy drop. Code is available at https://github.com/fxmeng/Pruning-Filter-in-Filter", "published": "2020-09-30T03:35:16Z", "version": 3}, {"aid": "2009.14416", "authors": ["Qi Qian", "Hao Li", "Juhua Hu"], "title": "Improved Knowledge Distillation via Full Kernel Matrix Transfer", "url": "http://arxiv.org/pdf/2009.14416v2", "summary": "Knowledge distillation is an effective way for model compression in deep learning. Given a large model (i.e., teacher model), it aims to improve the performance of a compact model (i.e., student model) by transferring the information from the teacher. Various information for distillation has been studied. Recently, a number of works propose to transfer the pairwise similarity between examples to distill relative information. However, most of efforts are devoted to developing different similarity measurements, while only a small matrix consisting of examples within a mini-batch is transferred at each iteration that can be inefficient for optimizing the pairwise similarity over the whole data set. In this work, we aim to transfer the full similarity matrix effectively. The main challenge is from the size of the full matrix that is quadratic to the number of examples. To address the challenge, we decompose the original full matrix with Nystr{\\\"{o}}m method. By selecting appropriate landmark points, our theoretical analysis indicates that the loss for transfer can be further simplified. Concretely, we find that the difference between the original full kernel matrices between teacher and student can be well bounded by that of the corresponding partial matrices, which only consists of similarities between original examples and landmark points. Compared with the full matrix, the size of the partial matrix is linear in the number of examples, which improves the efficiency of optimization significantly. The empirical study on benchmark data sets demonstrates the effectiveness of the proposed algorithm. Code is available at \\url{https://github.com/idstcv/KDA}.", "published": "2020-09-30T04:03:09Z", "version": 2}, {"aid": "2009.14441", "authors": ["Shay Deutsch", "Stefano Soatto"], "title": "Spectral Embedding of Graph Networks", "url": "http://arxiv.org/pdf/2009.14441v1", "summary": "We introduce an unsupervised graph embedding that trades off local node similarity and connectivity, and global structure. The embedding is based on a generalized graph Laplacian, whose eigenvectors compactly capture both network structure and neighborhood proximity in a single representation. The key idea is to transform the given graph into one whose weights measure the centrality of an edge by the fraction of the number of shortest paths that pass through that edge, and employ its spectral proprieties in the representation. Testing the resulting graph network representation shows significant improvement over the sate of the art in data analysis tasks including social networks and material science. We also test our method on node classification from the human-SARS CoV-2 protein-protein interactome.", "published": "2020-09-30T04:59:10Z", "version": 1}, {"aid": "2009.14487", "authors": ["Arash Akbarinia", "Raquel Gil-Rodr\u00edguez", "Alban Flachot", "Matteo Toscani"], "title": "The Utility of Decorrelating Colour Spaces in Vector Quantised Variational Autoencoders", "url": "http://arxiv.org/pdf/2009.14487v1", "summary": "Vector quantised variational autoencoders (VQ-VAE) are characterised by three main components: 1) encoding visual data, 2) assigning $k$ different vectors in the so-called embedding space, and 3) decoding the learnt features. While images are often represented in RGB colour space, the specific organisation of colours in other spaces also offer interesting features, e.g. CIE L*a*b* decorrelates chromaticity into opponent axes. In this article, we propose colour space conversion, a simple quasi-unsupervised task, to enforce a network learning structured representations. To this end, we trained several instances of VQ-VAE whose input is an image in one colour space, and its output in another, e.g. from RGB to CIE L*a*b* (in total five colour spaces were considered). We examined the finite embedding space of trained networks in order to disentangle the colour representation in VQ-VAE models. Our analysis suggests that certain vectors encode hue and others luminance information. We further evaluated the quality of reconstructed images at low-level using pixel-wise colour metrics, and at high-level by inputting them to image classification and scene segmentation networks. We conducted experiments in three benchmark datasets: ImageNet, COCO and CelebA. Our results show, with respect to the baseline network (whose input and output are RGB), colour conversion to decorrelated spaces obtains 1-2 Delta-E lower colour difference and 5-10% higher classification accuracy. We also observed that the learnt embedding space is easier to interpret in colour opponent models.", "published": "2020-09-30T07:44:01Z", "version": 1}, {"aid": "2010.00029", "authors": ["Hong-Ye Hu", "Dian Wu", "Yi-Zhuang You", "Bruno Olshausen", "Yubei Chen"], "title": "RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior", "url": "http://arxiv.org/pdf/2010.00029v5", "summary": "Flow-based generative models have become an important class of unsupervised learning approaches. In this work, we incorporate the key ideas of renormalization group (RG) and sparse prior distribution to design a hierarchical flow-based generative model, RG-Flow, which can separate information at different scales of images and extract disentangled representations at each scale. We demonstrate our method on synthetic multi-scale image datasets and the CelebA dataset, showing that the disentangled representations enable semantic manipulation and style mixing of the images at different scales. To visualize the latent representations, we introduce receptive fields for flow-based models and show that the receptive fields of RG-Flow are similar to those of convolutional neural networks. In addition, we replace the widely adopted isotropic Gaussian prior distribution by the sparse Laplacian distribution to further enhance the disentanglement of representations. From a theoretical perspective, our proposed method has $O(\\log L)$ complexity for inpainting of an image with edge length $L$, compared to previous generative models with $O(L^2)$ complexity.", "published": "2020-09-30T18:04:04Z", "version": 5}, {"aid": "2010.00400", "authors": ["Javier Hernandez-Ortega", "Ruben Tolosana", "Julian Fierrez", "Aythami Morales"], "title": "DeepFakesON-Phys: DeepFakes Detection based on Heart Rate Estimation", "url": "http://arxiv.org/pdf/2010.00400v3", "summary": "This work introduces a novel DeepFake detection framework based on physiological measurement. In particular, we consider information related to the heart rate using remote photoplethysmography (rPPG). rPPG methods analyze video sequences looking for subtle color changes in the human skin, revealing the presence of human blood under the tissues. In this work we investigate to what extent rPPG is useful for the detection of DeepFake videos.   The proposed fake detector named DeepFakesON-Phys uses a Convolutional Attention Network (CAN), which extracts spatial and temporal information from video frames, analyzing and combining both sources to better detect fake videos. This detection approach has been experimentally evaluated using the latest public databases in the field: Celeb-DF and DFDC. The results achieved, above 98% AUC (Area Under the Curve) on both databases, outperform the state of the art and prove the success of fake detectors based on physiological measurement to detect the latest DeepFake videos.", "published": "2020-10-01T13:37:58Z", "version": 3}, {"aid": "2010.00516", "authors": ["Meenakshi Khosla", "Gia H. Ngo", "Keith Jamison", "Amy Kuceyeski", "Mert R. Sabuncu"], "title": "Neural encoding with visual attention", "url": "http://arxiv.org/pdf/2010.00516v1", "summary": "Visual perception is critically influenced by the focus of attention. Due to limited resources, it is well known that neural representations are biased in favor of attended locations. Using concurrent eye-tracking and functional Magnetic Resonance Imaging (fMRI) recordings from a large cohort of human subjects watching movies, we first demonstrate that leveraging gaze information, in the form of attentional masking, can significantly improve brain response prediction accuracy in a neural encoding model. Next, we propose a novel approach to neural encoding by including a trainable soft-attention module. Using our new approach, we demonstrate that it is possible to learn visual attention policies by end-to-end learning merely on fMRI response data, and without relying on any eye-tracking. Interestingly, we find that attention locations estimated by the model on independent data agree well with the corresponding eye fixation patterns, despite no explicit supervision to do so. Together, these findings suggest that attention modules can be instrumental in neural encoding models of visual stimuli.", "published": "2020-10-01T16:04:21Z", "version": 1}, {"aid": "2010.00525", "authors": ["David Lipshutz", "Yanis Bahroun", "Siavash Golkar", "Anirvan M. Sengupta", "Dmitri B. Chklovskii"], "title": "A biologically plausible neural network for multi-channel Canonical Correlation Analysis", "url": "http://arxiv.org/pdf/2010.00525v4", "summary": "Cortical pyramidal neurons receive inputs from multiple distinct neural populations and integrate these inputs in separate dendritic compartments. We explore the possibility that cortical microcircuits implement Canonical Correlation Analysis (CCA), an unsupervised learning method that projects the inputs onto a common subspace so as to maximize the correlations between the projections. To this end, we seek a multi-channel CCA algorithm that can be implemented in a biologically plausible neural network. For biological plausibility, we require that the network operates in the online setting and its synaptic update rules are local. Starting from a novel CCA objective function, we derive an online optimization algorithm whose optimization steps can be implemented in a single-layer neural network with multi-compartmental neurons and local non-Hebbian learning rules. We also derive an extension of our online CCA algorithm with adaptive output rank and output whitening. Interestingly, the extension maps onto a neural network whose neural architecture and synaptic updates resemble neural circuitry and synaptic plasticity observed experimentally in cortical pyramidal neurons.", "published": "2020-10-01T16:17:53Z", "version": 4}, {"aid": "2010.00541", "authors": ["Nicol\u00e1s Vattuone", "Thomas Wachtler", "In\u00e9s Samengo"], "title": "Perceptual spaces and their symmetries: The geometry of color space", "url": "http://arxiv.org/pdf/2010.00541v5", "summary": "Our sensory systems transform external signals into neural activity, thereby producing percepts. We are endowed with an intuitive notion of similarity between percepts, that need not reflect the proximity of the physical properties of the corresponding external stimuli. The quantitative characterization of the geometry of percepts is therefore an endeavour that must be accomplished behaviorally. Here we characterized the geometry of color space using discrimination and matching experiments. We proposed an individually tailored metric defined in terms of the minimal chromatic difference required for each observer to differentiate a stimulus from its surround. Next, we showed that this perceptual metric was particularly adequate to describe two additional experiments, since it revealed the natural symmetry of perceptual computations. In one of the experiments, observers were required to discriminate two stimuli surrounded by a chromaticity that differed from that of the tested stimuli. In the perceptual coordinates, the change in discrimination thresholds induced by the surround followed a simple law that only depended on the perceptual distance between the surround and each of the two compared stimuli. In the other experiment, subjects were asked to match the color of two stimuli surrounded by two different chromaticities. Again, in the perceptual coordinates the induction effect produced by surrounds followed a simple, symmetric law. We conclude that the individually-tailored notion of perceptual distance reveals the symmetry of the laws governing perceptual computations.", "published": "2020-10-01T16:52:29Z", "version": 5}, {"aid": "2010.00567", "authors": ["Hassan Ismail Fawaz"], "title": "Deep learning for time series classification", "url": "http://arxiv.org/pdf/2010.00567v1", "summary": "Time series analysis is a field of data science which is interested in analyzing sequences of numerical values ordered in time. Time series are particularly interesting because they allow us to visualize and understand the evolution of a process over time. Their analysis can reveal trends, relationships and similarities across the data. There exists numerous fields containing data in the form of time series: health care (electrocardiogram, blood sugar, etc.), activity recognition, remote sensing, finance (stock market price), industry (sensors), etc. Time series classification consists of constructing algorithms dedicated to automatically label time series data. The sequential aspect of time series data requires the development of algorithms that are able to harness this temporal property, thus making the existing off-the-shelf machine learning models for traditional tabular data suboptimal for solving the underlying task. In this context, deep learning has emerged in recent years as one of the most effective methods for tackling the supervised classification task, particularly in the field of computer vision. The main objective of this thesis was to study and develop deep neural networks specifically constructed for the classification of time series data. We thus carried out the first large scale experimental study allowing us to compare the existing deep methods and to position them compared other non-deep learning based state-of-the-art methods. Subsequently, we made numerous contributions in this area, notably in the context of transfer learning, data augmentation, ensembling and adversarial attacks. Finally, we have also proposed a novel architecture, based on the famous Inception network (Google), which ranks among the most efficient to date.", "published": "2020-10-01T17:38:40Z", "version": 1}, {"aid": "2010.00578", "authors": ["Yuandong Tian", "Lantao Yu", "Xinlei Chen", "Surya Ganguli"], "title": "Understanding Self-supervised Learning with Dual Deep Networks", "url": "http://arxiv.org/pdf/2010.00578v6", "summary": "We propose a novel theoretical framework to understand contrastive self-supervised learning (SSL) methods that employ dual pairs of deep ReLU networks (e.g., SimCLR). First, we prove that in each SGD update of SimCLR with various loss functions, including simple contrastive loss, soft Triplet loss and InfoNCE loss, the weights at each layer are updated by a \\emph{covariance operator} that specifically amplifies initial random selectivities that vary across data samples but survive averages over data augmentations. To further study what role the covariance operator plays and which features are learned in such a process, we model data generation and augmentation processes through a \\emph{hierarchical latent tree model} (HLTM) and prove that the hidden neurons of deep ReLU networks can learn the latent variables in HLTM, despite the fact that the network receives \\emph{no direct supervision} from these unobserved latent variables. This leads to a provable emergence of hierarchical features through the amplification of initially random selectivities through contrastive SSL. Extensive numerical studies justify our theoretical findings. Code is released in https://github.com/facebookresearch/luckmatters/tree/master/ssl.", "published": "2020-10-01T17:51:49Z", "version": 6}, {"aid": "2010.04434", "authors": ["Tielin Zhang", "Shuncheng Jia", "Xiang Cheng", "Bo Xu"], "title": "Tuning Convolutional Spiking Neural Network with Biologically-plausible Reward Propagation", "url": "http://arxiv.org/pdf/2010.04434v3", "summary": "Spiking Neural Networks (SNNs) contain more biologically realistic structures and biologically-inspired learning principles than those in standard Artificial Neural Networks (ANNs). SNNs are considered the third generation of ANNs, powerful on the robust computation with a low computational cost. The neurons in SNNs are non-differential, containing decayed historical states and generating event-based spikes after their states reaching the firing threshold. These dynamic characteristics of SNNs make it difficult to be directly trained with the standard backpropagation (BP), which is also considered not biologically plausible. In this paper, a Biologically-plausible Reward Propagation (BRP) algorithm is proposed and applied to the SNN architecture with both spiking-convolution (with both 1D and 2D convolutional kernels) and full-connection layers. Unlike the standard BP that propagates error signals from post to presynaptic neurons layer by layer, the BRP propagates target labels instead of errors directly from the output layer to all pre-hidden layers. This effort is more consistent with the top-down reward-guiding learning in cortical columns of the neocortex. Synaptic modifications with only local gradient differences are induced with pseudo-BP that might also be replaced with the Spike-Timing Dependent Plasticity (STDP). The performance of the proposed BRP-SNN is further verified on the spatial (including MNIST and Cifar-10) and temporal (including TIDigits and DvsGesture) tasks, where the SNN using BRP has reached a similar accuracy compared to other state-of-the-art BP-based SNNs and saved 50% more computational cost than ANNs. We think the introduction of biologically plausible learning rules to the training procedure of biologically realistic SNNs will give us more hints and inspirations toward a better understanding of the biological system's intelligent nature.", "published": "2020-10-09T08:42:13Z", "version": 3}, {"aid": "2010.05063", "authors": ["Yaoyao Liu", "Bernt Schiele", "Qianru Sun"], "title": "Adaptive Aggregation Networks for Class-Incremental Learning", "url": "http://arxiv.org/pdf/2010.05063v3", "summary": "Class-Incremental Learning (CIL) aims to learn a classification model with the number of classes increasing phase-by-phase. An inherent problem in CIL is the stability-plasticity dilemma between the learning of old and new classes, i.e., high-plasticity models easily forget old classes, but high-stability models are weak to learn new classes. We alleviate this issue by proposing a novel network architecture called Adaptive Aggregation Networks (AANets), in which we explicitly build two types of residual blocks at each residual level (taking ResNet as the baseline architecture): a stable block and a plastic block. We aggregate the output feature maps from these two blocks and then feed the results to the next-level blocks. We adapt the aggregation weights in order to balance these two types of blocks, i.e., to balance stability and plasticity, dynamically. We conduct extensive experiments on three CIL benchmarks: CIFAR-100, ImageNet-Subset, and ImageNet, and show that many existing CIL methods can be straightforwardly incorporated into the architecture of AANets to boost their performances.", "published": "2020-10-10T18:24:24Z", "version": 3}, {"aid": "2010.07468", "authors": ["Juntang Zhuang", "Tommy Tang", "Yifan Ding", "Sekhar Tatikonda", "Nicha Dvornek", "Xenophon Papademetris", "James S. Duncan"], "title": "AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients", "url": "http://arxiv.org/pdf/2010.07468v5", "summary": "Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient descent (SGD) with momentum). For many models such as convolutional neural networks (CNNs), adaptive methods typically converge faster but generalize worse compared to SGD; for complex settings such as generative adversarial networks (GANs), adaptive methods are typically the default because of their stability.We propose AdaBelief to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the \"belief\" in the current gradient direction. Viewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step. We validate AdaBelief in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on ImageNet, AdaBelief achieves comparable accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer. Code is available at https://github.com/juntang-zhuang/Adabelief-Optimizer", "published": "2020-10-15T01:46:13Z", "version": 5}, {"aid": "2010.07604", "authors": ["Dongjun Kim", "Kyungwoo Song", "YoonYeong Kim", "Yongjin Shin", "Wanmo Kang", "Il-Chul Moon", "Weonyoung Joo"], "title": "Sequential Likelihood-Free Inference with Neural Proposal", "url": "http://arxiv.org/pdf/2010.07604v3", "summary": "Bayesian inference without the likelihood evaluation, or likelihood-free inference, has been a key research topic in simulation studies for gaining quantitatively validated simulation models on real-world datasets. As the likelihood evaluation is inaccessible, previous papers train the amortized neural network to estimate the ground-truth posterior for the simulation of interest. Training the network and accumulating the dataset alternatively in a sequential manner could save the total simulation budget by orders of magnitude. In the data accumulation phase, the new simulation inputs are chosen within a portion of the total simulation budget to accumulate upon the collected dataset. This newly accumulated data degenerates because the set of simulation inputs is hardly mixed, and this degenerated data collection process ruins the posterior inference. This paper introduces a new sampling approach, called Neural Proposal (NP), of the simulation input that resolves the biased data collection as it guarantees the i.i.d. sampling. The experiments show the improved performance of our sampler, especially for the simulations with multi-modal posteriors.", "published": "2020-10-15T08:59:23Z", "version": 3}, {"aid": "2010.07726", "authors": ["Benlei Cui", "XueMei Dong", "Qiaoqiao Zhan", "Jiangtao Peng", "Weiwei Sun"], "title": "LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image Classification", "url": "http://arxiv.org/pdf/2010.07726v1", "summary": "Deep learning methods have shown considerable potential for hyperspectral image (HSI) classification, which can achieve high accuracy compared with traditional methods. However, they often need a large number of training samples and have a lot of parameters and high computational overhead. To solve these problems, this paper proposes a new network architecture, LiteDepthwiseNet, for HSI classification. Based on 3D depthwise convolution, LiteDepthwiseNet can decompose standard convolution into depthwise convolution and pointwise convolution, which can achieve high classification performance with minimal parameters. Moreover, we remove the ReLU layer and Batch Normalization layer in the original 3D depthwise convolution, which significantly improves the overfitting phenomenon of the model on small sized datasets. In addition, focal loss is used as the loss function to improve the model's attention on difficult samples and unbalanced data, and its training performance is significantly better than that of cross-entropy loss or balanced cross-entropy loss. Experiment results on three benchmark hyperspectral datasets show that LiteDepthwiseNet achieves state-of-the-art performance with a very small number of parameters and low computational cost.", "published": "2020-10-15T13:12:17Z", "version": 1}, {"aid": "2010.07810", "authors": ["Amil Merchant", "Barret Zoph", "Ekin Dogus Cubuk"], "title": "Does Data Augmentation Benefit from Split BatchNorms", "url": "http://arxiv.org/pdf/2010.07810v1", "summary": "Data augmentation has emerged as a powerful technique for improving the performance of deep neural networks and led to state-of-the-art results in computer vision. However, state-of-the-art data augmentation strongly distorts training images, leading to a disparity between examples seen during training and inference. In this work, we explore a recently proposed training paradigm in order to correct for this disparity: using an auxiliary BatchNorm for the potentially out-of-distribution, strongly augmented images. Our experiments then focus on how to define the BatchNorm parameters that are used at evaluation. To eliminate the train-test disparity, we experiment with using the batch statistics defined by clean training images only, yet surprisingly find that this does not yield improvements in model performance. Instead, we investigate using BatchNorm parameters defined by weak augmentations and find that this method significantly improves the performance of common image classification benchmarks such as CIFAR-10, CIFAR-100, and ImageNet. We then explore a fundamental trade-off between accuracy and robustness coming from using different BatchNorm parameters, providing greater insight into the benefits of data augmentation on model performance.", "published": "2020-10-15T15:00:43Z", "version": 1}, {"aid": "2010.09931", "authors": ["Gil I. Shamir", "Dong Lin", "Lorenzo Coviello"], "title": "Smooth activations and reproducibility in deep networks", "url": "http://arxiv.org/pdf/2010.09931v2", "summary": "Deep networks are gradually penetrating almost every domain in our lives due to their amazing success. However, with substantive performance accuracy improvements comes the price of \\emph{irreproducibility}. Two identical models, trained on the exact same training dataset may exhibit large differences in predictions on individual examples even when average accuracy is similar, especially when trained on highly distributed parallel systems. The popular Rectified Linear Unit (ReLU) activation has been key to recent success of deep networks. We demonstrate, however, that ReLU is also a catalyzer to irreproducibility in deep networks. We show that not only can activations smoother than ReLU provide better accuracy, but they can also provide better accuracy-reproducibility tradeoffs. We propose a new family of activations; Smooth ReLU (\\emph{SmeLU}), designed to give such better tradeoffs, while also keeping the mathematical expression simple, and thus implementation cheap. SmeLU is monotonic, mimics ReLU, while providing continuous gradients, yielding better reproducibility. We generalize SmeLU to give even more flexibility and then demonstrate that SmeLU and its generalized form are special cases of a more general methodology of REctified Smooth Continuous Unit (RESCU) activations. Empirical results demonstrate the superior accuracy-reproducibility tradeoffs with smooth activations, SmeLU in particular.", "published": "2020-10-20T00:06:47Z", "version": 2}, {"aid": "2010.10604", "authors": ["Xinjie Fan", "Shujian Zhang", "Bo Chen", "Mingyuan Zhou"], "title": "Bayesian Attention Modules", "url": "http://arxiv.org/pdf/2010.10604v1", "summary": "Attention modules, as simple and effective tools, have not only enabled deep neural networks to achieve state-of-the-art results in many domains, but also enhanced their interpretability. Most current models use deterministic attention modules due to their simplicity and ease of optimization. Stochastic counterparts, on the other hand, are less popular despite their potential benefits. The main reason is that stochastic attention often introduces optimization issues or requires significant model changes. In this paper, we propose a scalable stochastic version of attention that is easy to implement and optimize. We construct simplex-constrained attention distributions by normalizing reparameterizable distributions, making the training process differentiable. We learn their parameters in a Bayesian framework where a data-dependent prior is introduced for regularization. We apply the proposed stochastic attention modules to various attention-based models, with applications to graph node classification, visual question answering, image captioning, machine translation, and language understanding. Our experiments show the proposed method brings consistent improvements over the corresponding baselines.", "published": "2020-10-20T20:30:55Z", "version": 1}, {"aid": "2010.10687", "authors": ["Vinay Rao", "Jascha Sohl-Dickstein"], "title": "Is Batch Norm unique? An empirical investigation and prescription to emulate the best properties of common normalizers without batch dependence", "url": "http://arxiv.org/pdf/2010.10687v1", "summary": "We perform an extensive empirical study of the statistical properties of Batch Norm and other common normalizers. This includes an examination of the correlation between representations of minibatches, gradient norms, and Hessian spectra both at initialization and over the course of training. Through this analysis, we identify several statistical properties which appear linked to Batch Norm's superior performance. We propose two simple normalizers, PreLayerNorm and RegNorm, which better match these desirable properties without involving operations along the batch dimension. We show that PreLayerNorm and RegNorm achieve much of the performance of Batch Norm without requiring batch dependence, that they reliably outperform LayerNorm, and that they can be applied in situations where Batch Norm is ineffective.", "published": "2020-10-21T00:41:38Z", "version": 1}, {"aid": "2010.11248", "authors": ["Yuki Kawana", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Neural Star Domain as Primitive Representation", "url": "http://arxiv.org/pdf/2010.11248v2", "summary": "Reconstructing 3D objects from 2D images is a fundamental task in computer vision. Accurate structured reconstruction by parsimonious and semantic primitive representation further broadens its application. When reconstructing a target shape with multiple primitives, it is preferable that one can instantly access the union of basic properties of the shape such as collective volume and surface, treating the primitives as if they are one single shape. This becomes possible by primitive representation with unified implicit and explicit representations. However, primitive representations in current approaches do not satisfy all of the above requirements at the same time. To solve this problem, we propose a novel primitive representation named neural star domain (NSD) that learns primitive shapes in the star domain. We show that NSD is a universal approximator of the star domain and is not only parsimonious and semantic but also an implicit and explicit shape representation. We demonstrate that our approach outperforms existing methods in image reconstruction tasks, semantic capabilities, and speed and quality of sampling high-resolution meshes.", "published": "2020-10-21T19:05:16Z", "version": 2}, {"aid": "2010.11929", "authors": ["Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Mostafa Dehghani", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Jakob Uszkoreit", "Neil Houlsby"], "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "url": "http://arxiv.org/pdf/2010.11929v2", "summary": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.", "published": "2020-10-22T17:55:59Z", "version": 2}, {"aid": "2010.12785", "authors": ["Haoran You", "Xiaohan Chen", "Yongan Zhang", "Chaojian Li", "Sicheng Li", "Zihao Liu", "Zhangyang Wang", "Yingyan Celine Lin"], "title": "ShiftAddNet: A Hardware-Inspired Deep Network", "url": "http://arxiv.org/pdf/2010.12785v2", "summary": "Multiplication (e.g., convolution) is arguably a cornerstone of modern deep neural networks (DNNs). However, intensive multiplications cause expensive resource costs that challenge DNNs' deployment on resource-constrained edge devices, driving several attempts for multiplication-less deep networks. This paper presented ShiftAddNet, whose main inspiration is drawn from a common practice in energy-efficient hardware implementation, that is, multiplication can be instead performed with additions and logical bit-shifts. We leverage this idea to explicitly parameterize deep networks in this way, yielding a new type of deep network that involves only bit-shift and additive weight layers. This hardware-inspired ShiftAddNet immediately leads to both energy-efficient inference and training, without compromising the expressive capacity compared to standard DNNs. The two complementary operation types (bit-shift and add) additionally enable finer-grained control of the model's learning capacity, leading to more flexible trade-off between accuracy and (training) efficiency, as well as improved robustness to quantization and pruning. We conduct extensive experiments and ablation studies, all backed up by our FPGA-based ShiftAddNet implementation and energy measurements. Compared to existing DNNs or other multiplication-less models, ShiftAddNet aggressively reduces over 80% hardware-quantified energy cost of DNNs training and inference, while offering comparable or better accuracies. Codes and pre-trained models are available at https://github.com/RICE-EIC/ShiftAddNet.", "published": "2020-10-24T05:09:14Z", "version": 2}, {"aid": "2010.14819", "authors": ["Kai Han", "Yunhe Wang", "Qiulin Zhang", "Wei Zhang", "Chunjing Xu", "Tong Zhang"], "title": "Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets", "url": "http://arxiv.org/pdf/2010.14819v2", "summary": "To obtain excellent deep neural architectures, a series of techniques are carefully designed in EfficientNets. The giant formula for simultaneously enlarging the resolution, depth and width provides us a Rubik's cube for neural networks. So that we can find networks with high efficiency and excellent performance by twisting the three dimensions. This paper aims to explore the twisting rules for obtaining deep neural networks with minimum model sizes and computational costs. Different from the network enlarging, we observe that resolution and depth are more important than width for tiny networks. Therefore, the original method, i.e., the compound scaling in EfficientNet is no longer suitable. To this end, we summarize a tiny formula for downsizing neural architectures through a series of smaller models derived from the EfficientNet-B0 with the FLOPs constraint. Experimental results on the ImageNet benchmark illustrate that our TinyNet performs much better than the smaller version of EfficientNets using the inversed giant formula. For instance, our TinyNet-E achieves a 59.9% Top-1 accuracy with only 24M FLOPs, which is about 1.9% higher than that of the previous best MobileNetV3 with similar computational cost. Code will be available at https://github.com/huawei-noah/ghostnet/tree/master/tinynet_pytorch, and https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/tinynet.", "published": "2020-10-28T08:49:45Z", "version": 2}, {"aid": "2010.14831", "authors": ["Stan Z. Li", "Zelin Zang", "Lirong Wu"], "title": "Deep Manifold Transformation for Nonlinear Dimensionality Reduction", "url": "http://arxiv.org/pdf/2010.14831v3", "summary": "Manifold learning-based encoders have been playing important roles in nonlinear dimensionality reduction (NLDR) for data exploration. However, existing methods can often fail to preserve geometric, topological and/or distributional structures of data. In this paper, we propose a deep manifold learning framework, called deep manifold transformation (DMT) for unsupervised NLDR and embedding learning. DMT enhances deep neural networks by using cross-layer local geometry-preserving (LGP) constraints. The LGP constraints constitute the loss for deep manifold learning and serve as geometric regularizers for NLDR network training. Extensive experiments on synthetic and real-world data demonstrate that DMT networks outperform existing leading manifold-based NLDR methods in terms of preserving the structures of data.", "published": "2020-10-28T09:09:41Z", "version": 3}, {"aid": "2010.15487", "authors": ["Arslan Ali", "Andrea Migliorati", "Tiziano Bianchi", "Enrico Magli"], "title": "Beyond cross-entropy: learning highly separable feature distributions for robust and accurate classification", "url": "http://arxiv.org/pdf/2010.15487v1", "summary": "Deep learning has shown outstanding performance in several applications including image classification. However, deep classifiers are known to be highly vulnerable to adversarial attacks, in that a minor perturbation of the input can easily lead to an error. Providing robustness to adversarial attacks is a very challenging task especially in problems involving a large number of classes, as it typically comes at the expense of an accuracy decrease. In this work, we propose the Gaussian class-conditional simplex (GCCS) loss: a novel approach for training deep robust multiclass classifiers that provides adversarial robustness while at the same time achieving or even surpassing the classification accuracy of state-of-the-art methods. Differently from other frameworks, the proposed method learns a mapping of the input classes onto target distributions in a latent space such that the classes are linearly separable. Instead of maximizing the likelihood of target labels for individual samples, our objective function pushes the network to produce feature distributions yielding high inter-class separation. The mean values of the distributions are centered on the vertices of a simplex such that each class is at the same distance from every other class. We show that the regularization of the latent space based on our approach yields excellent classification accuracy and inherently provides robustness to multiple adversarial attacks, both targeted and untargeted, outperforming state-of-the-art approaches over challenging datasets.", "published": "2020-10-29T11:15:17Z", "version": 1}, {"aid": "2011.06496", "authors": ["Roshan Reddy Yedla", "Shiv Ram Dubey"], "title": "On the Performance of Convolutional Neural Networks under High and Low Frequency Information", "url": "http://arxiv.org/pdf/2011.06496v1", "summary": "Convolutional neural networks (CNNs) have shown very promising performance in recent years for different problems, including object recognition, face recognition, medical image analysis, etc. However, generally the trained CNN models are tested over the test set which is very similar to the trained set. The generalizability and robustness of the CNN models are very important aspects to make it to work for the unseen data. In this letter, we study the performance of CNN models over the high and low frequency information of the images. We observe that the trained CNN fails to generalize over the high and low frequency images. In order to make the CNN robust against high and low frequency images, we propose the stochastic filtering based data augmentation during training. A satisfactory performance improvement has been observed in terms of the high and low frequency generalization and robustness with the proposed stochastic filtering based data augmentation approach. The experimentations are performed using ResNet50 model over the CIFAR-10 dataset and ResNet101 model over Tiny-ImageNet dataset.", "published": "2020-10-30T17:54:45Z", "version": 1}, {"aid": "2011.00071", "authors": ["Arissa Wongpanich", "Hieu Pham", "James Demmel", "Mingxing Tan", "Quoc Le", "Yang You", "Sameer Kumar"], "title": "Training EfficientNets at Supercomputer Scale: 83% ImageNet Top-1 Accuracy in One Hour", "url": "http://arxiv.org/pdf/2011.00071v2", "summary": "EfficientNets are a family of state-of-the-art image classification models based on efficiently scaled convolutional neural networks. Currently, EfficientNets can take on the order of days to train; for example, training an EfficientNet-B0 model takes 23 hours on a Cloud TPU v2-8 node. In this paper, we explore techniques to scale up the training of EfficientNets on TPU-v3 Pods with 2048 cores, motivated by speedups that can be achieved when training at such scales. We discuss optimizations required to scale training to a batch size of 65536 on 1024 TPU-v3 cores, such as selecting large batch optimizers and learning rate schedules as well as utilizing distributed evaluation and batch normalization techniques. Additionally, we present timing and performance benchmarks for EfficientNet models trained on the ImageNet dataset in order to analyze the behavior of EfficientNets at scale. With our optimizations, we are able to train EfficientNet on ImageNet to an accuracy of 83% in 1 hour and 4 minutes.", "published": "2020-10-30T19:27:11Z", "version": 2}, {"aid": "2011.02785", "authors": ["Dingyi Zhang", "Yingming Li", "Zhongfei Zhang"], "title": "Deep Metric Learning with Spherical Embedding", "url": "http://arxiv.org/pdf/2011.02785v1", "summary": "Deep metric learning has attracted much attention in recent years, due to seamlessly combining the distance metric learning and deep neural network. Many endeavors are devoted to design different pair-based angular loss functions, which decouple the magnitude and direction information for embedding vectors and ensure the training and testing measure consistency. However, these traditional angular losses cannot guarantee that all the sample embeddings are on the surface of the same hypersphere during the training stage, which would result in unstable gradient in batch optimization and may influence the quick convergence of the embedding learning. In this paper, we first investigate the effect of the embedding norm for deep metric learning with angular distance, and then propose a spherical embedding constraint (SEC) to regularize the distribution of the norms. SEC adaptively adjusts the embeddings to fall on the same hypersphere and performs more balanced direction update. Extensive experiments on deep metric learning, face recognition, and contrastive self-supervised learning show that the SEC-based angular space learning strategy significantly improves the performance of the state-of-the-art.", "published": "2020-11-05T12:32:12Z", "version": 1}, {"aid": "2011.02803", "authors": ["Ting Chen", "Calvin Luo", "Lala Li"], "title": "Intriguing Properties of Contrastive Losses", "url": "http://arxiv.org/pdf/2011.02803v3", "summary": "We study three intriguing properties of contrastive learning. First, we generalize the standard contrastive loss to a broader family of losses, and we find that various instantiations of the generalized loss perform similarly under the presence of a multi-layer non-linear projection head. Second, we study if instance-based contrastive learning (with a global image representation) can learn well on images with multiple objects present. We find that meaningful hierarchical local features can be learned despite the fact that these objectives operate on global instance-level features. Finally, we study the phenomenon of feature suppression among competing features shared across augmented views, such as \"color distribution\" vs \"object class\". We construct datasets with explicit and controllable competing features, and show that, for contrastive learning, a few bits of easy-to-learn shared features can suppress, and even fully prevent, the learning of other sets of competing features. In scenarios where there are multiple objects in an image, the dominant object would suppress the learning of smaller objects. Existing contrastive learning methods critically rely on data augmentation to favor certain sets of features over others, and could suffer from learning saturation for scenarios where existing augmentations cannot fully address the feature suppression. This poses open challenges to existing contrastive learning techniques.", "published": "2020-11-05T13:19:48Z", "version": 3}, {"aid": "2011.02956", "authors": ["David Peer", "Sebastian Stabinger", "Antonio Rodriguez-Sanchez"], "title": "Conflicting Bundles: Adapting Architectures Towards the Improved Training of Deep Neural Networks", "url": "http://arxiv.org/pdf/2011.02956v1", "summary": "Designing neural network architectures is a challenging task and knowing which specific layers of a model must be adapted to improve the performance is almost a mystery. In this paper, we introduce a novel theory and metric to identify layers that decrease the test accuracy of the trained models, this identification is done as early as at the beginning of training. In the worst-case, such a layer could lead to a network that can not be trained at all. More precisely, we identified those layers that worsen the performance because they produce conflicting training bundles as we show in our novel theoretical analysis, complemented by our extensive empirical studies. Based on these findings, a novel algorithm is introduced to remove performance decreasing layers automatically. Architectures found by this algorithm achieve a competitive accuracy when compared against the state-of-the-art architectures. While keeping such high accuracy, our approach drastically reduces memory consumption and inference time for different computer vision tasks.", "published": "2020-11-05T16:41:04Z", "version": 1}, {"aid": "2011.04441", "authors": ["Luka Ribar", "Rodolphe Sepulchre"], "title": "Neuromorphic Control", "url": "http://arxiv.org/pdf/2011.04441v2", "summary": "Neuromorphic engineering is a rapidly developing field that aims to take inspiration from the biological organization of neural systems to develop novel technology for computing, sensing, and actuating. The unique properties of such systems call for new signal processing and control paradigms. The article introduces the mixed feedback organization of excitable neuronal systems, consisting of interlocked positive and negative feedback loops acting in distinct timescales. The principles of biological neuromodulation suggest a methodology for designing and controlling mixed-feedback systems neuromorphically. The proposed design consists of a parallel interconnection of elementary circuit elements that mirrors the organization of biological neurons and utilizes the hardware components of neuromorphic electronic circuits. The interconnection structure endows the neuromorphic systems with a simple control methodology that reframes the neuronal control as an input-output shaping problem. The potential of neuronal control is illustrated on elementary network examples that suggest the scalability of the mixed-feedback principles.", "published": "2020-11-09T14:06:06Z", "version": 2}, {"aid": "2011.06427", "authors": ["S. Rahimi Kari"], "title": "Realization of Stochastic Neural Networks and Its Potential Applications", "url": "http://arxiv.org/pdf/2011.06427v1", "summary": "Successive Cancellation Decoders have come a long way since the implementation of traditional SC decoders, but there still is a potential for improvement. The main struggle over the years was to find an optimal algorithm to implement them. Most of the proposed algorithms are not practical enough to be implemented in real-life. In this research, we aim to introduce the Efficiency of stochastic neural networks as an SC decoder and Find the possible ways of improving its performance and practicality. In this paper, after a brief introduction to stochastic neurons and SNNs, we introduce methods to realize Stochastic NNs on both deterministic and stochastic platforms.", "published": "2020-11-12T15:01:07Z", "version": 1}, {"aid": "2012.00695", "authors": ["W. A. Jacak", "J. E. Jacak"], "title": "The topological non-local braid-group concept of information processing in brain, the different role of the gray and white matter", "url": "http://arxiv.org/pdf/2012.00695v1", "summary": "The velocity of the action potential transduction along myelinated axons in the peripheral nervous system or in the white matter of brain and spinal cord reaches hundreds of meters per second to assure proper functioning of the body, which exceeds the ability of diffusive ion conduction. We propose the new model of the saltatory conduction based on a plasmon-polariton kinetics in myelinated axons, which excludes, however, the white matter form the information storage and its identification in the brain via e-m response. We propose a nonlocal topological approach to information processing in the cortex of brain in consistence with the ion electricity of the gray matter and a supplementary only communication role of the white matter.", "published": "2020-11-16T07:47:09Z", "version": 1}, {"aid": "2011.10566", "authors": ["Xinlei Chen", "Kaiming He"], "title": "Exploring Simple Siamese Representation Learning", "url": "http://arxiv.org/pdf/2011.10566v1", "summary": "Siamese networks have become a common structure in various recent models for unsupervised visual representation learning. These models maximize the similarity between two augmentations of one image, subject to certain conditions for avoiding collapsing solutions. In this paper, we report surprising empirical results that simple Siamese networks can learn meaningful representations even using none of the following: (i) negative sample pairs, (ii) large batches, (iii) momentum encoders. Our experiments show that collapsing solutions do exist for the loss and structure, but a stop-gradient operation plays an essential role in preventing collapsing. We provide a hypothesis on the implication of stop-gradient, and further show proof-of-concept experiments verifying it. Our \"SimSiam\" method achieves competitive results on ImageNet and downstream tasks. We hope this simple baseline will motivate people to rethink the roles of Siamese architectures for unsupervised representation learning. Code will be made available.", "published": "2020-11-20T18:59:33Z", "version": 1}, {"aid": "2011.11128", "authors": ["Shu Gong", "Kaibo Xing", "Andrzej Cichocki", "Junhua Li"], "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period", "url": "http://arxiv.org/pdf/2011.11128v3", "summary": "Deep learning has achieved excellent performance in a wide range of domains, especially in speech recognition and computer vision. Relatively less work has been done for EEG, but there is still significant progress attained in the last decade. Due to the lack of a comprehensive and topic widely covered survey for deep learning in EEG, we attempt to summarize recent progress to provide an overview, as well as perspectives for future developments. We first briefly mention the artifacts removal for EEG signal and then introduce deep learning models that have been utilized in EEG processing and classification. Subsequently, the applications of deep learning in EEG are reviewed by categorizing them into groups such as brain-computer interface, disease detection, and emotion recognition. They are followed by the discussion, in which the pros and cons of deep learning are presented and future directions and challenges for deep learning in EEG are proposed. We hope that this paper could serve as a summary of past work for deep learning in EEG and the beginning of further developments and achievements of EEG studies based on deep learning.", "published": "2020-11-22T22:34:26Z", "version": 3}, {"aid": "2012.00675", "authors": ["Tananun Songdechakraiwut", "Moo K. Chung"], "title": "Topological Learning for Brain Networks", "url": "http://arxiv.org/pdf/2012.00675v5", "summary": "This paper proposes a novel topological learning framework that integrates networks of different sizes and topology through persistent homology. Such challenging task is made possible through the introduction of a computationally efficient topological loss. The use of the proposed loss bypasses the intrinsic computational bottleneck associated with matching networks. We validate the method in extensive statistical simulations to assess its effectiveness when discriminating networks with different topology. The method is further demonstrated in a twin brain imaging study where we determine if brain networks are genetically heritable. The challenge here is due to the difficulty of overlaying the topologically different functional brain networks obtained from resting-state functional MRI onto the template structural brain network obtained through diffusion MRI.", "published": "2020-11-25T18:46:36Z", "version": 5}, {"aid": "2011.13456", "authors": ["Yang Song", "Jascha Sohl-Dickstein", "Diederik P. Kingma", "Abhishek Kumar", "Stefano Ermon", "Ben Poole"], "title": "Score-Based Generative Modeling through Stochastic Differential Equations", "url": "http://arxiv.org/pdf/2011.13456v2", "summary": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (\\aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.", "published": "2020-11-26T19:39:10Z", "version": 2}, {"aid": "2011.14285", "authors": ["Haoxi Ran", "Li Lu"], "title": "Deeper or Wider Networks of Point Clouds with Self-attention?", "url": "http://arxiv.org/pdf/2011.14285v2", "summary": "Prevalence of deeper networks driven by self-attention is in stark contrast to underexplored point-based methods. In this paper, we propose groupwise self-attention as the basic block to construct our network: SepNet. Our proposed module can effectively capture both local and global dependencies. This module computes the features of a group based on the summation of the weighted features of any point within the group. For convenience, we generalize groupwise operations to assemble this module. To further facilitate our networks, we deepen and widen SepNet on the tasks of segmentation and classification respectively, and verify its practicality. Specifically, SepNet achieves state-of-the-art for the tasks of classification and segmentation on most of the datasets. We show empirical evidence that SepNet can obtain extra accuracy in classification or segmentation from increased width or depth, respectively.", "published": "2020-11-29T05:03:06Z", "version": 2}, {"aid": "2012.00868", "authors": ["Srikar Appalaraju", "Yi Zhu", "Yusheng Xie", "Istv\u00e1n Feh\u00e9rv\u00e1ri"], "title": "Towards Good Practices in Self-supervised Representation Learning", "url": "http://arxiv.org/pdf/2012.00868v1", "summary": "Self-supervised representation learning has seen remarkable progress in the last few years. More recently, contrastive instance learning has shown impressive results compared to its supervised learning counterparts. However, even with the ever increased interest in contrastive instance learning, it is still largely unclear why these methods work so well. In this paper, we aim to unravel some of the mysteries behind their success, which are the good practices. Through an extensive empirical analysis, we hope to not only provide insights but also lay out a set of best practices that led to the success of recent work in self-supervised representation learning.", "published": "2020-12-01T22:13:43Z", "version": 1}, {"aid": "2012.01064", "authors": ["Ibrahim Merad", "Yiyang Yu", "Emmanuel Bacry", "St\u00e9phane Ga\u00efffas"], "title": "About contrastive unsupervised representation learning for classification and its convergence", "url": "http://arxiv.org/pdf/2012.01064v1", "summary": "Contrastive representation learning has been recently proved to be very efficient for self-supervised training. These methods have been successfully used to train encoders which perform comparably to supervised training on downstream classification tasks. A few works have started to build a theoretical framework around contrastive learning in which guarantees for its performance can be proven. We provide extensions of these results to training with multiple negative samples and for multiway classification. Furthermore, we provide convergence guarantees for the minimization of the contrastive training error with gradient descent of an overparametrized deep neural encoder, and provide some numerical experiments that complement our theoretical findings", "published": "2020-12-02T10:08:57Z", "version": 1}, {"aid": "2012.01074", "authors": ["Giulia Cisotto", "Alessio Zanga", "Joanna Chlebus", "Italo Zoppis", "Sara Manzoni", "Urszula Markowska-Kaczmar"], "title": "Comparison of Attention-based Deep Learning Models for EEG Classification", "url": "http://arxiv.org/pdf/2012.01074v1", "summary": "Objective: To evaluate the impact on Electroencephalography (EEG) classification of different kinds of attention mechanisms in Deep Learning (DL) models. Methods: We compared three attention-enhanced DL models, the brand-new InstaGATs, an LSTM with attention and a CNN with attention. We used these models to classify normal and abnormal (i.e., artifactual or pathological) EEG patterns. Results: We achieved the state of the art in all classification problems, regardless the large variability of the datasets and the simple architecture of the attention-enhanced models. We could also prove that, depending on how the attention mechanism is applied and where the attention layer is located in the model, we can alternatively leverage the information contained in the time, frequency or space domain of the dataset. Conclusions: with this work, we shed light over the role of different attention mechanisms in the classification of normal and abnormal EEG patterns. Moreover, we discussed how they can exploit the intrinsic relationships in the temporal, frequency and spatial domains of our brain activity. Significance: Attention represents a promising strategy to evaluate the quality of the EEG information, and its relevance, in different real-world scenarios. Moreover, it can make it easier to parallelize the computation and, thus, to speed up the analysis of big electrophysiological (e.g., EEG) datasets.", "published": "2020-12-02T10:43:41Z", "version": 1}, {"aid": "2012.03436", "authors": ["Jicong Fan", "Lijun Ding", "Chengrun Yang", "Zhao Zhang", "Madeleine Udell"], "title": "Euclidean-Norm-Induced Schatten-p Quasi-Norm Regularization for Low-Rank Tensor Completion and Tensor Robust Principal Component Analysis", "url": "http://arxiv.org/pdf/2012.03436v5", "summary": "The nuclear norm and Schatten-$p$ quasi-norm are popular rank proxies in low-rank matrix recovery. However, computing the nuclear norm or Schatten-$p$ quasi-norm of a tensor is hard in both theory and practice, hindering their application to low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA). In this paper, we propose a new class of tensor rank regularizers based on the Euclidean norms of the CP component vectors of a tensor and show that these regularizers are monotonic transformations of tensor Schatten-$p$ quasi-norm. This connection enables us to minimize the Schatten-$p$ quasi-norm in LRTC and TRPCA implicitly via the component vectors. The method scales to big tensors and provides an arbitrarily sharper rank proxy for low-rank tensor recovery compared to the nuclear norm. On the other hand, we study the generalization abilities of LRTC with the Schatten-$p$ quasi-norm regularizer and LRTC with the proposed regularizers. The theorems show that a relatively sharper regularizer leads to a tighter error bound, which is consistent with our numerical results. Particularly, we prove that for LRTC with Schatten-$p$ quasi-norm regularizer on $d$-order tensors, $p=1/d$ is always better than any $p>1/d$ in terms of the generalization ability. We also provide a recovery error bound to verify the usefulness of small $p$ in the Schatten-$p$ quasi-norm for TRPCA. Numerical results on synthetic data and real data demonstrate the effectiveness of the regularization methods and theorems.", "published": "2020-12-07T03:34:03Z", "version": 5}, {"aid": "2012.04112", "authors": ["Evgeny Hershkovitch Neiterman", "Michael Klyuchka", "Gil Ben-Artzi"], "title": "Adaptive Enhancement of Extreme Low-Light Images", "url": "http://arxiv.org/pdf/2012.04112v3", "summary": "Existing methods for enhancing dark images captured in a very low-light environment assume that the intensity level of the optimal output image is known and already included in the training set. However, this assumption often does not hold, leading to output images that contain visual imperfections such as dark regions or low contrast. To facilitate the training and evaluation of adaptive models that can overcome this limitation, we have created a dataset of 1500 raw images taken in both indoor and outdoor low-light conditions. Based on our dataset, we introduce a deep learning model capable of enhancing input images with a wide range of intensity levels at runtime, including ones that are not seen during training. Our experimental results demonstrate that our proposed dataset combined with our model can consistently and effectively enhance images across a wide range of diverse and challenging scenarios.", "published": "2020-12-07T23:31:59Z", "version": 3}, {"aid": "2012.06951", "authors": ["Qi Qi", "Yi Xu", "Rong Jin", "Wotao Yin", "Tianbao Yang"], "title": "Attentional-Biased Stochastic Gradient Descent", "url": "http://arxiv.org/pdf/2012.06951v5", "summary": "In this paper, we present a simple yet effective provable method (named ABSGD) for addressing the data imbalance or label noise problem in deep learning. Our method is a simple modification to momentum SGD where we assign an individual importance weight to each sample in the mini-batch. The individual-level weight of sampled data is systematically proportional to the exponential of a scaled loss value of the data, where the scaling factor is interpreted as the regularization parameter in the framework of distributionally robust optimization (DRO). Depending on whether the scaling factor is positive or negative, ABSGD is guaranteed to converge to a stationary point of an information-regularized min-max or min-min DRO problem, respectively. Compared with existing class-level weighting schemes, our method can capture the diversity between individual examples within each class. Compared with existing individual-level weighting methods using meta-learning that require three backward propagations for computing mini-batch stochastic gradients, our method is more efficient with only one backward propagation at each iteration as in standard deep learning methods. ABSGD is flexible enough to combine with other robust losses without any additional cost. Our empirical studies on several benchmark datasets demonstrate the effectiveness of the proposed method.\\footnote{Code is available at:\\url{https://github.com/qiqi-helloworld/ABSGD/}}", "published": "2020-12-13T03:41:52Z", "version": 5}, {"aid": "2012.07297", "authors": ["Jian Liang", "Dapeng Hu", "Yunbo Wang", "Ran He", "Jiashi Feng"], "title": "Source Data-absent Unsupervised Domain Adaptation through Hypothesis Transfer and Labeling Transfer", "url": "http://arxiv.org/pdf/2012.07297v3", "summary": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a related but different well-labeled source domain to a new unlabeled target domain. Most existing UDA methods require access to the source data, and thus are not applicable when the data are confidential and not shareable due to privacy concerns. This paper aims to tackle a realistic setting with only a classification model available trained over, instead of accessing to, the source data. To effectively utilize the source model for adaptation, we propose a novel approach called Source HypOthesis Transfer (SHOT), which learns the feature extraction module for the target domain by fitting the target data features to the frozen source classification module (representing classification hypothesis). Specifically, SHOT exploits both information maximization and self-supervised learning for the feature extraction module learning to ensure the target features are implicitly aligned with the features of unseen source data via the same hypothesis. Furthermore, we propose a new labeling transfer strategy, which separates the target data into two splits based on the confidence of predictions (labeling information), and then employ semi-supervised learning to improve the accuracy of less-confident predictions in the target domain. We denote labeling transfer as SHOT++ if the predictions are obtained by SHOT. Extensive experiments on both digit classification and object recognition tasks show that SHOT and SHOT++ achieve results surpassing or comparable to the state-of-the-arts, demonstrating the effectiveness of our approaches for various visual domain adaptation problems. Code is available at \\url{https://github.com/tim-learn/SHOT-plus}.", "published": "2020-12-14T07:28:50Z", "version": 3}, {"aid": "2012.07810", "authors": ["Shanchuan Lin", "Andrey Ryabtsev", "Soumyadip Sengupta", "Brian Curless", "Steve Seitz", "Ira Kemelmacher-Shlizerman"], "title": "Real-Time High-Resolution Background Matting", "url": "http://arxiv.org/pdf/2012.07810v1", "summary": "We introduce a real-time, high-resolution background replacement technique which operates at 30fps in 4K resolution, and 60fps for HD on a modern GPU. Our technique is based on background matting, where an additional frame of the background is captured and used in recovering the alpha matte and the foreground layer. The main challenge is to compute a high-quality alpha matte, preserving strand-level hair details, while processing high-resolution images in real-time. To achieve this goal, we employ two neural networks; a base network computes a low-resolution result which is refined by a second network operating at high-resolution on selective patches. We introduce two largescale video and image matting datasets: VideoMatte240K and PhotoMatte13K/85. Our approach yields higher quality results compared to the previous state-of-the-art in background matting, while simultaneously yielding a dramatic boost in both speed and resolution.", "published": "2020-12-14T18:43:32Z", "version": 1}, {"aid": "2012.12351", "authors": ["Erfan Nozari", "Maxwell A. Bertolero", "Jennifer Stiso", "Lorenzo Caciagli", "Eli J. Cornblath", "Xiaosong He", "Arun S. Mahadevan", "George J. Pappas", "Dani Smith Bassett"], "title": "Is the brain macroscopically linear? A system identification of resting state dynamics", "url": "http://arxiv.org/pdf/2012.12351v2", "summary": "A central challenge in the computational modeling of neural dynamics is the trade-off between accuracy and simplicity. At the level of individual neurons, nonlinear dynamics are both experimentally established and essential for neuronal functioning. An implicit assumption has thus formed that an accurate computational model of whole-brain dynamics must also be highly nonlinear, whereas linear models may provide a first-order approximation. Here, we provide a rigorous and data-driven investigation of this hypothesis at the level of whole-brain blood-oxygen-level-dependent (BOLD) and macroscopic field potential dynamics by leveraging the theory of system identification. Using functional MRI (fMRI) and intracranial EEG (iEEG), we model the resting state activity of 700 subjects in the Human Connectome Project (HCP) and 122 subjects from the Restoring Active Memory (RAM) project using state-of-the-art linear and nonlinear model families. We assess relative model fit using predictive power, computational complexity, and the extent of residual dynamics unexplained by the model. Contrary to our expectations, linear auto-regressive models achieve the best measures across all three metrics, eliminating the trade-off between accuracy and simplicity. To understand and explain this linearity, we highlight four properties of macroscopic neurodynamics which can counteract or mask microscopic nonlinear dynamics: averaging over space, averaging over time, observation noise, and limited data samples. Whereas the latter two are technological limitations and can improve in the future, the former two are inherent to aggregated macroscopic brain activity. Our results, together with the unparalleled interpretability of linear models, can greatly facilitate our understanding of macroscopic neural dynamics and the principled design of model-based interventions for the treatment of neuropsychiatric disorders.", "published": "2020-12-22T20:51:42Z", "version": 2}, {"aid": "2012.12899", "authors": ["Ramtin Hosseini", "Pengtao Xie"], "title": "Learning by Self-Explanation, with Application to Neural Architecture Search", "url": "http://arxiv.org/pdf/2012.12899v2", "summary": "Learning by self-explanation is an effective learning technique in human learning, where students explain a learned topic to themselves for deepening their understanding of this topic. It is interesting to investigate whether this explanation-driven learning methodology broadly used by humans is helpful for improving machine learning as well. Based on this inspiration, we propose a novel machine learning method called learning by self-explanation (LeaSE). In our approach, an explainer model improves its learning ability by trying to clearly explain to an audience model regarding how a prediction outcome is made. LeaSE is formulated as a four-level optimization problem involving a sequence of four learning stages which are conducted end-to-end in a unified framework: 1) explainer learns; 2) explainer explains; 3) audience learns; 4) explainer re-learns based on the performance of the audience. We develop an efficient algorithm to solve the LeaSE problem. We apply LeaSE for neural architecture search on CIFAR-100, CIFAR-10, and ImageNet. Experimental results strongly demonstrate the effectiveness of our method.", "published": "2020-12-23T07:39:54Z", "version": 2}, {"aid": "2012.12556", "authors": ["Kai Han", "Yunhe Wang", "Hanting Chen", "Xinghao Chen", "Jianyuan Guo", "Zhenhua Liu", "Yehui Tang", "An Xiao", "Chunjing Xu", "Yixing Xu", "Zhaohui Yang", "Yiman Zhang", "Dacheng Tao"], "title": "A Survey on Visual Transformer", "url": "http://arxiv.org/pdf/2012.12556v6", "summary": "Transformer, first applied to the field of natural language processing, is a type of deep neural network mainly based on the self-attention mechanism. Thanks to its strong representation capabilities, researchers are looking at ways to apply transformer to computer vision tasks. In a variety of visual benchmarks, transformer-based models perform similar to or better than other types of networks such as convolutional and recurrent neural networks. Given its high performance and less need for vision-specific inductive bias, transformer is receiving more and more attention from the computer vision community. In this paper, we review these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages. The main categories we explore include the backbone network, high/mid-level vision, low-level vision, and video processing. We also include efficient transformer methods for pushing transformer into real device-based applications. Furthermore, we also take a brief look at the self-attention mechanism in computer vision, as it is the base component in transformer. Toward the end of this paper, we discuss the challenges and provide several further research directions for vision transformers.", "published": "2020-12-23T09:37:54Z", "version": 6}, {"aid": "2012.13322", "authors": ["Yangyang Qu", "Chao liu", "Yongsheng Ou"], "title": "LEUGAN:Low-Light Image Enhancement by Unsupervised Generative Attentional Networks", "url": "http://arxiv.org/pdf/2012.13322v1", "summary": "Restoring images from low-light data is a challenging problem. Most existing deep-network based algorithms are designed to be trained with pairwise images. Due to the lack of real-world datasets, they usually perform poorly when generalized in practice in terms of loss of image edge and color information. In this paper, we propose an unsupervised generation network with attention-guidance to handle the low-light image enhancement task. Specifically, our network contains two parts: an edge auxiliary module that restores sharper edges and an attention guidance module that recovers more realistic colors. Moreover, we propose a novel loss function to make the edges of the generated images more visible. Experiments validate that our proposed algorithm performs favorably against state-of-the-art methods, especially for real-world images in terms of image clarity and noise control.", "published": "2020-12-24T16:49:19Z", "version": 1}, {"aid": "2012.15020", "authors": ["Zhangkai Ni", "Wenhan Yang", "Shiqi Wang", "Lin Ma", "Sam Kwong"], "title": "Towards Unsupervised Deep Image Enhancement with Generative Adversarial Network", "url": "http://arxiv.org/pdf/2012.15020v1", "summary": "Improving the aesthetic quality of images is challenging and eager for the public. To address this problem, most existing algorithms are based on supervised learning methods to learn an automatic photo enhancer for paired data, which consists of low-quality photos and corresponding expert-retouched versions. However, the style and characteristics of photos retouched by experts may not meet the needs or preferences of general users. In this paper, we present an unsupervised image enhancement generative adversarial network (UEGAN), which learns the corresponding image-to-image mapping from a set of images with desired characteristics in an unsupervised manner, rather than learning on a large number of paired images. The proposed model is based on single deep GAN which embeds the modulation and attention mechanisms to capture richer global and local features. Based on the proposed model, we introduce two losses to deal with the unsupervised image enhancement: (1) fidelity loss, which is defined as a L2 regularization in the feature domain of a pre-trained VGG network to ensure the content between the enhanced image and the input image is the same, and (2) quality loss that is formulated as a relativistic hinge adversarial loss to endow the input image the desired characteristics. Both quantitative and qualitative results show that the proposed model effectively improves the aesthetic quality of images. Our code is available at: https://github.com/eezkni/UEGAN.", "published": "2020-12-30T03:22:46Z", "version": 1}, {"aid": "2101.01011", "authors": ["Christian P. Robert", "Gareth O. Roberts"], "title": "Rao-Blackwellization in the MCMC era", "url": "http://arxiv.org/pdf/2101.01011v1", "summary": "Rao-Blackwellization is a notion often occurring in the MCMC literature, with possibly different meanings and connections with the original Rao--Blackwell theorem (Rao, 1945 and Blackwell,1947), including a reduction of the variance of the resulting Monte Carlo approximations. This survey reviews some of the meanings of the term.", "published": "2021-01-04T14:44:36Z", "version": 1}, {"aid": "2101.02824", "authors": ["Tao Huang", "Songjiang Li", "Xu Jia", "Huchuan Lu", "Jianzhuang Liu"], "title": "Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images", "url": "http://arxiv.org/pdf/2101.02824v3", "summary": "In the last few years, image denoising has benefited a lot from the fast development of neural networks. However, the requirement of large amounts of noisy-clean image pairs for supervision limits the wide use of these models. Although there have been a few attempts in training an image denoising model with only single noisy images, existing self-supervised denoising approaches suffer from inefficient network training, loss of useful information, or dependence on noise modeling. In this paper, we present a very simple yet effective method named Neighbor2Neighbor to train an effective image denoising model with only noisy images. Firstly, a random neighbor sub-sampler is proposed for the generation of training image pairs. In detail, input and target used to train a network are images sub-sampled from the same noisy image, satisfying the requirement that paired pixels of paired images are neighbors and have very similar appearance with each other. Secondly, a denoising network is trained on sub-sampled training pairs generated in the first stage, with a proposed regularizer as additional loss for better performance. The proposed Neighbor2Neighbor framework is able to enjoy the progress of state-of-the-art supervised denoising networks in network architecture design. Moreover, it avoids heavy dependence on the assumption of the noise distribution. We explain our approach from a theoretical perspective and further validate it through extensive experiments, including synthetic experiments with different noise distributions in sRGB space and real-world experiments on a denoising benchmark dataset in raw-RGB space.", "published": "2021-01-08T02:03:25Z", "version": 3}, {"aid": "2101.05278", "authors": ["Weihao Xia", "Yulun Zhang", "Yujiu Yang", "Jing-Hao Xue", "Bolei Zhou", "Ming-Hsuan Yang"], "title": "GAN Inversion: A Survey", "url": "http://arxiv.org/pdf/2101.05278v5", "summary": "GAN inversion aims to invert a given image back into the latent space of a pretrained GAN model, for the image to be faithfully reconstructed from the inverted code by the generator. As an emerging technique to bridge the real and fake image domains, GAN inversion plays an essential role in enabling the pretrained GAN models such as StyleGAN and BigGAN to be used for real image editing applications. Meanwhile, GAN inversion also provides insights on the interpretation of GAN's latent space and how the realistic images can be generated. In this paper, we provide an overview of GAN inversion with a focus on its recent algorithms and applications. We cover important techniques of GAN inversion and their applications to image restoration and image manipulation. We further elaborate on some trends and challenges for future directions.", "published": "2021-01-14T14:11:00Z", "version": 5}, {"aid": "2101.10953", "authors": ["Wei Zhong Goh", "Varun Ursekar", "Marc W. Howard"], "title": "Predicting the future with a scale-invariant temporal memory for the past", "url": "http://arxiv.org/pdf/2101.10953v3", "summary": "In recent years it has become clear that the brain maintains a temporal memory of recent events stretching far into the past. This paper presents a neurally-inspired algorithm to use a scale-invariant temporal representation of the past to predict a scale-invariant future. The result is a scale-invariant estimate of future events as a function of the time at which they are expected to occur. The algorithm is time-local, with credit assigned to the present event by observing how it affects the prediction of the future. To illustrate the potential utility of this approach, we test the model on simultaneous renewal processes with different time scales. The algorithm scales well on these problems despite the fact that the number of states needed to describe them as a Markov process grows exponentially.", "published": "2021-01-26T17:22:17Z", "version": 3}, {"aid": "2101.11075", "authors": ["Aaron Defazio", "Samy Jelassi"], "title": "Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic Optimization", "url": "http://arxiv.org/pdf/2101.11075v3", "summary": "We introduce MADGRAD, a novel optimization method in the family of AdaGrad adaptive gradient methods. MADGRAD shows excellent performance on deep learning optimization problems from multiple fields, including classification and image-to-image tasks in vision, and recurrent and bidirectionally-masked models in natural language processing. For each of these tasks, MADGRAD matches or outperforms both SGD and ADAM in test set performance, even on problems for which adaptive methods normally perform poorly.", "published": "2021-01-26T20:38:26Z", "version": 3}, {"aid": "2101.11605", "authors": ["Aravind Srinivas", "Tsung-Yi Lin", "Niki Parmar", "Jonathon Shlens", "Pieter Abbeel", "Ashish Vaswani"], "title": "Bottleneck Transformers for Visual Recognition", "url": "http://arxiv.org/pdf/2101.11605v2", "summary": "We present BoTNet, a conceptually simple yet powerful backbone architecture that incorporates self-attention for multiple computer vision tasks including image classification, object detection and instance segmentation. By just replacing the spatial convolutions with global self-attention in the final three bottleneck blocks of a ResNet and no other changes, our approach improves upon the baselines significantly on instance segmentation and object detection while also reducing the parameters, with minimal overhead in latency. Through the design of BoTNet, we also point out how ResNet bottleneck blocks with self-attention can be viewed as Transformer blocks. Without any bells and whistles, BoTNet achieves 44.4% Mask AP and 49.7% Box AP on the COCO Instance Segmentation benchmark using the Mask R-CNN framework; surpassing the previous best published single model and single scale results of ResNeSt evaluated on the COCO validation set. Finally, we present a simple adaptation of the BoTNet design for image classification, resulting in models that achieve a strong performance of 84.7% top-1 accuracy on the ImageNet benchmark while being up to 1.64x faster in compute time than the popular EfficientNet models on TPU-v3 hardware. We hope our simple and effective approach will serve as a strong baseline for future research in self-attention models for vision", "published": "2021-01-27T18:55:27Z", "version": 2}, {"aid": "2102.00160", "authors": ["S. H. Shabbeer Basha", "Mohammad Farazuddin", "Viswanath Pulabaigari", "Shiv Ram Dubey", "Snehasis Mukherjee"], "title": "Deep Model Compression based on the Training History", "url": "http://arxiv.org/pdf/2102.00160v2", "summary": "Deep Convolutional Neural Networks (DCNNs) have shown promising performances in several visual recognition problems which motivated the researchers to propose popular architectures such as LeNet, AlexNet, VGGNet, ResNet, and many more. These architectures come at a cost of high computational complexity and parameter storage. To get rid of storage and computational complexity, deep model compression methods have been evolved. We propose a \"History Based Filter Pruning (HBFP)\" method that utilizes network training history for filter pruning. Specifically, we prune the redundant filters by observing similar patterns in the filter's L1-norms (absolute sum of weights) over the training epochs. We iteratively prune the redundant filters of a CNN in three steps. First, we train the model and select the filter pairs with redundant filters in each pair. Next, we optimize the network to ensure an increased measure of similarity between the filters in a pair. This optimization of the network facilitates us to prune one filter from each pair based on its importance without much information loss. Finally, we retrain the network to regain the performance, which is dropped due to filter pruning. We test our approach on popular architectures such as LeNet-5 on MNIST dataset; VGG-16, ResNet-56, and ResNet-110 on CIFAR-10 dataset, and ResNet-50 on ImageNet. The proposed pruning method outperforms the state-of-the-art in terms of FLOPs reduction (floating-point operations) by 97.98%, 83.42%, 78.43%, 74.95%, and 75.45% for LeNet-5, VGG-16, ResNet-56, ResNet-110, and ResNet-50, respectively, while maintaining the less error rate.", "published": "2021-01-30T06:04:21Z", "version": 2}, {"aid": "2102.00719", "authors": ["Daniel Neimark", "Omri Bar", "Maya Zohar", "Dotan Asselmann"], "title": "Video Transformer Network", "url": "http://arxiv.org/pdf/2102.00719v3", "summary": "This paper presents VTN, a transformer-based framework for video recognition. Inspired by recent developments in vision transformers, we ditch the standard approach in video action recognition that relies on 3D ConvNets and introduce a method that classifies actions by attending to the entire video sequence information. Our approach is generic and builds on top of any given 2D spatial network. In terms of wall runtime, it trains $16.1\\times$ faster and runs $5.1\\times$ faster during inference while maintaining competitive accuracy compared to other state-of-the-art methods. It enables whole video analysis, via a single end-to-end pass, while requiring $1.5\\times$ fewer GFLOPs. We report competitive results on Kinetics-400 and present an ablation study of VTN properties and the trade-off between accuracy and inference speed. We hope our approach will serve as a new baseline and start a fresh line of research in the video recognition domain. Code and models are available at: https://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md", "published": "2021-02-01T09:29:10Z", "version": 3}, {"aid": "2102.02804", "authors": ["Ilke Cugu", "Emre Akbas"], "title": "A Deeper Look into Convolutions via Eigenvalue-based Pruning", "url": "http://arxiv.org/pdf/2102.02804v2", "summary": "Convolutional neural networks (CNNs) are able to attain better visual recognition performance than fully connected neural networks despite having much fewer parameters due to their parameter sharing principle. Modern architectures usually contain a small number of fully-connected layers, often at the end, after multiple layers of convolutions. In some cases, most of the convolutions can be eliminated without suffering any loss in recognition performance. However, there is no solid recipe to detect the hidden subset of convolutional neurons that is responsible for the majority of the recognition work. In this work, we formulate this as a pruning problem where the aim is to prune as many kernels as possible while preserving the vanilla generalization performance. To this end, we use the matrix characteristics based on eigenvalues for pruning, in comparison to the average absolute weight of a kernel which is the de facto standard in the literature to assess the importance of an individual convolutional kernel, to shed light on the internal mechanisms of a widely used family of CNNs, namely residual neural networks (ResNets), for the image classification problem using CIFAR-10, CIFAR-100 and Tiny ImageNet datasets.", "published": "2021-02-04T18:55:03Z", "version": 2}, {"aid": "2102.02811", "authors": ["Zhiqiang Tang", "Yunhe Gao", "Yi Zhu", "Zhi Zhang", "Mu Li", "Dimitris Metaxas"], "title": "CrossNorm and SelfNorm for Generalization under Distribution Shifts", "url": "http://arxiv.org/pdf/2102.02811v2", "summary": "Traditional normalization techniques (e.g., Batch Normalization and Instance Normalization) generally and simplistically assume that training and test data follow the same distribution. As distribution shifts are inevitable in real-world applications, well-trained models with previous normalization methods can perform badly in new environments. Can we develop new normalization methods to improve generalization robustness under distribution shifts? In this paper, we answer the question by proposing CrossNorm and SelfNorm. CrossNorm exchanges channel-wise mean and variance between feature maps to enlarge training distribution, while SelfNorm uses attention to recalibrate the statistics to bridge gaps between training and test distributions. CrossNorm and SelfNorm can complement each other, though exploring different directions in statistics usage. Extensive experiments on different fields (vision and language), tasks (classification and segmentation), settings (supervised and semi-supervised), and distribution shift types (synthetic and natural) show the effectiveness. Code is available at https://github.com/amazon-research/crossnorm-selfnorm", "published": "2021-02-04T18:59:20Z", "version": 2}, {"aid": "2102.03814", "authors": ["Phairot Autthasan", "Rattanaphon Chaisaen", "Thapanun Sudhawiyangkul", "Phurin Rangpong", "Suktipol Kiatthaveephong", "Nat Dilokthanakul", "Gun Bhakdisongkhram", "Huy Phan", "Cuntai Guan", "Theerawit Wilaiprasitporn"], "title": "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification", "url": "http://arxiv.org/pdf/2102.03814v4", "summary": "Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs) allow control of several applications by decoding neurophysiological phenomena, which are usually recorded by electroencephalography (EEG) using a non-invasive technique. Despite great advances in MI-based BCI, EEG rhythms are specific to a subject and various changes over time. These issues point to significant challenges to enhance the classification performance, especially in a subject-independent manner. To overcome these challenges, we propose MIN2Net, a novel end-to-end multi-task learning to tackle this task. We integrate deep metric learning into a multi-task autoencoder to learn a compact and discriminative latent representation from EEG and perform classification simultaneously. This approach reduces the complexity in pre-processing, results in significant performance improvement on EEG classification. Experimental results in a subject-independent manner show that MIN2Net outperforms the state-of-the-art techniques, achieving an F1-score improvement of 6.72%, and 2.23% on the SMR-BCI, and OpenBMI datasets, respectively. We demonstrate that MIN2Net improves discriminative information in the latent representation. This study indicates the possibility and practicality of using this model to develop MI-based BCI applications for new users without the need for calibration.", "published": "2021-02-07T15:20:23Z", "version": 4}, {"aid": "2102.04965", "authors": ["Michal Balazia", "S L Happy", "Francois Bremond", "Antitza Dantcheva"], "title": "How Unique Is a Face: An Investigative Study", "url": "http://arxiv.org/pdf/2102.04965v3", "summary": "Face recognition has been widely accepted as a means of identification in applications ranging from border control to security in the banking sector. Surprisingly, while widely accepted, we still lack the understanding of uniqueness or distinctiveness of faces as biometric modality. In this work, we study the impact of factors such as image resolution, feature representation, database size, age and gender on uniqueness denoted by the Kullback-Leibler divergence between genuine and impostor distributions. Towards understanding the impact, we present experimental results on the datasets AT&T, LFW, IMDb-Face, as well as ND-TWINS, with the feature extraction algorithms VGGFace, VGG16, ResNet50, InceptionV3, MobileNet and DenseNet121, that reveal the quantitative impact of the named factors. While these are early results, our findings indicate the need for a better understanding of the concept of biometric uniqueness and its implication on face recognition.", "published": "2021-02-09T17:35:39Z", "version": 3}, {"aid": "2102.05426", "authors": ["Yuhang Li", "Ruihao Gong", "Xu Tan", "Yang Yang", "Peng Hu", "Qi Zhang", "Fengwei Yu", "Wei Wang", "Shi Gu"], "title": "BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction", "url": "http://arxiv.org/pdf/2102.05426v2", "summary": "We study the challenging task of neural network quantization without end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually requires a small subset of training data but produces less powerful quantized models than Quantization-Aware Training (QAT). In this work, we propose a novel PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to INT2 for the first time. BRECQ leverages the basic building blocks in neural networks and reconstructs them one-by-one. In a comprehensive theoretical study of the second-order error, we show that BRECQ achieves a good balance between cross-layer dependency and generalization error. To further employ the power of quantization, the mixed precision technique is incorporated in our framework by approximating the inter-layer and intra-layer sensitivity. Extensive experiments on various handcrafted and searched neural architectures are conducted for both image classification and object detection tasks. And for the first time we prove that, without bells and whistles, PTQ can attain 4-bit ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster production of quantized models. Codes are available at https://github.com/yhhhli/BRECQ.", "published": "2021-02-10T13:46:16Z", "version": 2}, {"aid": "2102.08663", "authors": ["Yuhta Takida", "Wei-Hsiang Liao", "Chieh-Hsin Lai", "Toshimitsu Uesaka", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "Preventing Oversmoothing in VAE via Generalized Variance Parameterization", "url": "http://arxiv.org/pdf/2102.08663v2", "summary": "Variational autoencoders (VAEs) often suffer from posterior collapse, which is a phenomenon in which the learned latent space becomes uninformative. This is often related to the hyperparameter resembling the data variance. It can be shown that an inappropriate choice of this hyperparameter causes the oversmoothness in the linearly approximated case and can be empirically verified for the general cases. Moreover, determining such appropriate choice becomes infeasible if the data variance is non-uniform or conditional. Therefore, we propose VAE extensions with generalized parameterizations of the data variance and incorporate maximum likelihood estimation into the objective function to adaptively regularize the decoder smoothness. The images generated from proposed VAE extensions show improved Fr\\'echet inception distance (FID) on MNIST and CelebA datasets.", "published": "2021-02-17T10:00:49Z", "version": 2}, {"aid": "2102.13519", "authors": ["Stefan Bl\u00fccher", "Johanna Vielhaben", "Nils Strodthoff"], "title": "PredDiff: Explanations and Interactions from Conditional Expectations", "url": "http://arxiv.org/pdf/2102.13519v4", "summary": "PredDiff is a model-agnostic, local attribution method that is firmly rooted in probability theory. Its simple intuition is to measure prediction changes while marginalizing features. In this work, we clarify properties of PredDiff and its close connection to Shapley values. We stress important differences between classification and regression, which require a specific treatment within both formalisms. We extend PredDiff by introducing a new, well-founded measure for interaction effects between arbitrary feature subsets. The study of interaction effects represents an inevitable step towards a comprehensive understanding of black-box models and is particularly important for science applications. Equipped with our novel interaction measure, PredDiff is a promising model-agnostic approach for obtaining reliable, numerically inexpensive and theoretically sound attributions.", "published": "2021-02-26T14:46:47Z", "version": 4}, {"aid": "2103.00944", "authors": ["Dengyu Wu", "Xinping Yi", "Xiaowei Huang"], "title": "A Little Energy Goes a Long Way: Build an Energy-Efficient, Accurate Spiking Neural Network from Convolutional Neural Network", "url": "http://arxiv.org/pdf/2103.00944v3", "summary": "Spiking neural networks (SNNs) offer an inherent ability to process spatial-temporal data, or in other words, realworld sensory data, but suffer from the difficulty of training high accuracy models. A major thread of research on SNNs is on converting a pre-trained convolutional neural network (CNN) to an SNN of the same structure. State-of-the-art conversion methods are approaching the accuracy limit, i.e., the near-zero accuracy loss of SNN against the original CNN. However, we note that this is made possible only when significantly more energy is consumed to process an input. In this paper, we argue that this trend of \"energy for accuracy\" is not necessary -- a little energy can go a long way to achieve the near-zero accuracy loss. Specifically, we propose a novel CNN-to-SNN conversion method that is able to use a reasonably short spike train (e.g., 256 timesteps for CIFAR10 images) to achieve the near-zero accuracy loss. The new conversion method, named as explicit current control (ECC), contains three techniques (current normalisation, thresholding for residual elimination, and consistency maintenance for batch-normalisation), in order to explicitly control the currents flowing through the SNN when processing inputs. We implement ECC into a tool nicknamed SpKeras, which can conveniently import Keras CNN models and convert them into SNNs. We conduct an extensive set of experiments with the tool -- working with VGG16 and various datasets such as CIFAR10 and CIFAR100 -- and compare with state-of-the-art conversion methods. Results show that ECC is a promising method that can optimise over energy consumption and accuracy loss simultaneously.", "published": "2021-03-01T12:15:29Z", "version": 3}, {"aid": "2103.01209", "authors": ["Drew A. Hudson", "C. Lawrence Zitnick"], "title": "Generative Adversarial Transformers", "url": "http://arxiv.org/pdf/2103.01209v4", "summary": "We introduce the GANformer, a novel and efficient type of transformer, and explore it for the task of visual generative modeling. The network employs a bipartite structure that enables long-range interactions across the image, while maintaining computation of linear efficiency, that can readily scale to high-resolution synthesis. It iteratively propagates information from a set of latent variables to the evolving visual features and vice versa, to support the refinement of each in light of the other and encourage the emergence of compositional representations of objects and scenes. In contrast to the classic transformer architecture, it utilizes multiplicative integration that allows flexible region-based modulation, and can thus be seen as a generalization of the successful StyleGAN network. We demonstrate the model's strength and robustness through a careful evaluation over a range of datasets, from simulated multi-object environments to rich real-world indoor and outdoor scenes, showing it achieves state-of-the-art results in terms of image quality and diversity, while enjoying fast learning and better data-efficiency. Further qualitative and quantitative experiments offer us an insight into the model's inner workings, revealing improved interpretability and stronger disentanglement, and illustrating the benefits and efficacy of our approach. An implementation of the model is available at https://github.com/dorarad/gansformer.", "published": "2021-03-01T18:54:04Z", "version": 4}, {"aid": "2103.02339", "authors": ["Omar Chehab", "Alexandre Defossez", "Jean-Christophe Loiseau", "Alexandre Gramfort", "Jean-Remi King"], "title": "Deep Recurrent Encoder: A scalable end-to-end network to model brain signals", "url": "http://arxiv.org/pdf/2103.02339v3", "summary": "Understanding how the brain responds to sensory inputs is challenging: brain recordings are partial, noisy, and high dimensional; they vary across sessions and subjects and they capture highly nonlinear dynamics. These challenges have led the community to develop a variety of preprocessing and analytical (almost exclusively linear) methods, each designed to tackle one of these issues. Instead, we propose to address these challenges through a specific end-to-end deep learning architecture, trained to predict the brain responses of multiple subjects at once. We successfully test this approach on a large cohort of magnetoencephalography (MEG) recordings acquired during a one-hour reading task. Our Deep Recurrent Encoding (DRE) architecture reliably predicts MEG responses to words with a three-fold improvement over classic linear methods. To overcome the notorious issue of interpretability of deep learning, we describe a simple variable importance analysis. When applied to DRE, this method recovers the expected evoked responses to word length and word frequency. The quantitative improvement of the present deep learning approach paves the way to better understand the nonlinear dynamics of brain activity from large datasets.", "published": "2021-03-03T11:39:17Z", "version": 3}, {"aid": "2103.02503", "authors": ["Kaiyang Zhou", "Ziwei Liu", "Yu Qiao", "Tao Xiang", "Chen Change Loy"], "title": "Domain Generalization: A Survey", "url": "http://arxiv.org/pdf/2103.02503v7", "summary": "Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d.~assumption on source/target data, which is often violated in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Over the last ten years, research in DG has made great progress, leading to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, to name a few; DG has also been studied in various application areas including computer vision, speech recognition, natural language processing, medical imaging, and reinforcement learning. In this paper, for the first time a comprehensive literature review in DG is provided to summarize the developments over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other relevant fields like domain adaptation and transfer learning. Then, we conduct a thorough review into existing methods and theories. Finally, we conclude this survey with insights and discussions on future research directions.", "published": "2021-03-03T16:12:22Z", "version": 7}, {"aid": "2103.06132", "authors": ["Alexandre Rame", "Remy Sun", "Matthieu Cord"], "title": "MixMo: Mixing Multiple Inputs for Multiple Outputs via Deep Subnetworks", "url": "http://arxiv.org/pdf/2103.06132v3", "summary": "Recent strategies achieved ensembling \"for free\" by fitting concurrently diverse subnetworks inside a single base network. The main idea during training is that each subnetwork learns to classify only one of the multiple inputs simultaneously provided. However, the question of how to best mix these multiple inputs has not been studied so far. In this paper, we introduce MixMo, a new generalized framework for learning multi-input multi-output deep subnetworks. Our key motivation is to replace the suboptimal summing operation hidden in previous approaches by a more appropriate mixing mechanism. For that purpose, we draw inspiration from successful mixed sample data augmentations. We show that binary mixing in features - particularly with rectangular patches from CutMix - enhances results by making subnetworks stronger and more diverse. We improve state of the art for image classification on CIFAR-100 and Tiny ImageNet datasets. Our easy to implement models notably outperform data augmented deep ensembles, without the inference and memory overheads. As we operate in features and simply better leverage the expressiveness of large networks, we open a new line of research complementary to previous works.", "published": "2021-03-10T15:31:02Z", "version": 3}, {"aid": "2103.13870", "authors": ["Tianxiang Zhan", "Fuyuan Xiao"], "title": "A novel weighted approach for time series forecasting based on visibility graph", "url": "http://arxiv.org/pdf/2103.13870v6", "summary": "Time series has attracted a lot of attention in many fields today. Time series forecasting algorithm based on complex network analysis is a research hotspot. How to use time series information to achieve more accurate forecasting is a problem. To solve this problem, this paper proposes a weighted network forecasting method to improve the forecasting accuracy. Firstly, the time series will be transformed into a complex network, and the similarity between nodes will be found. Then, the similarity will be used as a weight to make weighted forecasting on the predicted values produced by different nodes. Compared with the previous method, the proposed method is more accurate. In order to verify the effect of the proposed method, the experimental part is tested on M1, M3 datasets and Construction Cost Index (CCI) dataset, which shows that the proposed method has more accurate forecasting performance.", "published": "2021-03-14T01:01:41Z", "version": 6}, {"aid": "2103.09656", "authors": ["Mateusz Jurewicz", "Leon Str\u00f8mberg-Derczynski"], "title": "Set-to-Sequence Methods in Machine Learning: a Review", "url": "http://arxiv.org/pdf/2103.09656v2", "summary": "Machine learning on sets towards sequential output is an important and ubiquitous task, with applications ranging from language modeling and meta-learning to multi-agent strategy games and power grid optimization. Combining elements of representation learning and structured prediction, its two primary challenges include obtaining a meaningful, permutation invariant set representation and subsequently utilizing this representation to output a complex target permutation. This paper provides a comprehensive introduction to the field as well as an overview of important machine learning methods tackling both of these key challenges, with a detailed qualitative comparison of selected model architectures.", "published": "2021-03-17T13:52:33Z", "version": 2}, {"aid": "2103.13630", "authors": ["Amir Gholami", "Sehoon Kim", "Zhen Dong", "Zhewei Yao", "Michael W. Mahoney", "Kurt Keutzer"], "title": "A Survey of Quantization Methods for Efficient Neural Network Inference", "url": "http://arxiv.org/pdf/2103.13630v3", "summary": "As soon as abstract mathematical computations were adapted to computation on digital computers, the problem of efficient representation, manipulation, and communication of the numerical values in those computations arose. Strongly related to the problem of numerical representation is the problem of quantization: in what manner should a set of continuous real-valued numbers be distributed over a fixed discrete set of numbers to minimize the number of bits required and also to maximize the accuracy of the attendant computations? This perennial problem of quantization is particularly relevant whenever memory and/or computational resources are severely restricted, and it has come to the forefront in recent years due to the remarkable performance of Neural Network models in computer vision, natural language processing, and related areas. Moving from floating-point representations to low-precision fixed integer values represented in four bits or less holds the potential to reduce the memory footprint and latency by a factor of 16x; and, in fact, reductions of 4x to 8x are often realized in practice in these applications. Thus, it is not surprising that quantization has emerged recently as an important and very active sub-area of research in the efficient implementation of computations associated with Neural Networks. In this article, we survey approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. With this survey and its organization, we hope to have presented a useful snapshot of the current research in quantization for Neural Networks and to have given an intelligent organization to ease the evaluation of future research in this area.", "published": "2021-03-25T06:57:11Z", "version": 3}, {"aid": "2103.13860", "authors": ["Domenico Maisto", "Francesco Gregoretti", "Karl Friston", "Giovanni Pezzulo"], "title": "Active Inference Tree Search in Large POMDPs", "url": "http://arxiv.org/pdf/2103.13860v6", "summary": "The ability to plan ahead efficiently is key for both living organisms and artificial systems. Model-based planning and prospection are widely studied in cognitive neuroscience and artificial intelligence (AI), but from different perspectives--and with different desiderata in mind (biological realism versus scalability) that are difficult to reconcile. Here, we introduce a novel method to plan in POMDPs--Active Inference Tree Search (AcT)--that combines the normative character and biological realism of a leading planning theory in neuroscience (Active Inference) and the scalability of tree search methods in AI. This unification enhances both approaches. On the one hand, tree searches enable the biologically grounded, first principle method of active inference to be applied to large-scale problems. On the other hand, active inference provides a principled solution to the exploration-exploitation dilemma, which is often addressed heuristically in tree search methods. Our simulations show that AcT successfully navigates binary trees that are challenging for sampling-based methods, problems that require adaptive exploration, and the large POMDP problem 'RockSample'--in which AcT reproduces state-of-the-art POMDP solutions. Furthermore, we illustrate how AcT can be used to simulate neurophysiological responses (e.g., in the hippocampus and prefrontal cortex) of humans and other animals that solve large planning problems. These numerical analyses show that Active Tree Search is a principled realisation of neuroscientific and AI planning theories, which offer both biological realism and scalability.", "published": "2021-03-25T14:17:09Z", "version": 6}, {"aid": "2103.14005", "authors": ["Klemen Kotar", "Gabriel Ilharco", "Ludwig Schmidt", "Kiana Ehsani", "Roozbeh Mottaghi"], "title": "Contrasting Contrastive Self-Supervised Representation Learning Pipelines", "url": "http://arxiv.org/pdf/2103.14005v2", "summary": "In the past few years, we have witnessed remarkable breakthroughs in self-supervised representation learning. Despite the success and adoption of representations learned through this paradigm, much is yet to be understood about how different training methods and datasets influence performance on downstream tasks. In this paper, we analyze contrastive approaches as one of the most successful and popular variants of self-supervised representation learning. We perform this analysis from the perspective of the training algorithms, pre-training datasets and end tasks. We examine over 700 training experiments including 30 encoders, 4 pre-training datasets and 20 diverse downstream tasks. Our experiments address various questions regarding the performance of self-supervised models compared to their supervised counterparts, current benchmarks used for evaluation, and the effect of the pre-training data on end task performance. Our Visual Representation Benchmark (ViRB) is available at: https://github.com/allenai/virb.", "published": "2021-03-25T17:40:38Z", "version": 2}, {"aid": "2103.14030", "authors": ["Ze Liu", "Yutong Lin", "Yue Cao", "Han Hu", "Yixuan Wei", "Zheng Zhang", "Stephen Lin", "Baining Guo"], "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows", "url": "http://arxiv.org/pdf/2103.14030v2", "summary": "This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with \\textbf{S}hifted \\textbf{win}dows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at~\\url{https://github.com/microsoft/Swin-Transformer}.", "published": "2021-03-25T17:59:31Z", "version": 2}, {"aid": "2103.14545", "authors": ["Zirui Liu", "Haifeng Jin", "Ting-Hsiang Wang", "Kaixiong Zhou", "Xia Hu"], "title": "DivAug: Plug-in Automated Data Augmentation with Explicit Diversity Maximization", "url": "http://arxiv.org/pdf/2103.14545v2", "summary": "Human-designed data augmentation strategies have been replaced by automatically learned augmentation policy in the past two years. Specifically, recent work has empirically shown that the superior performance of the automated data augmentation methods stems from increasing the diversity of augmented data \\cite{autoaug, randaug}. However, two factors regarding the diversity of augmented data are still missing: 1) the explicit definition (and thus measurement) of diversity and 2) the quantifiable relationship between diversity and its regularization effects. To bridge this gap, we propose a diversity measure called Variance Diversity and theoretically show that the regularization effect of data augmentation is promised by Variance Diversity. We validate in experiments that the relative gain from automated data augmentation in test accuracy is highly correlated to Variance Diversity. An unsupervised sampling-based framework, \\textbf{DivAug}, is designed to directly maximize Variance Diversity and hence strengthen the regularization effect. Without requiring a separate search process, the performance gain from DivAug is comparable with the state-of-the-art method with better efficiency. Moreover, under the semi-supervised setting, our framework can further improve the performance of semi-supervised learning algorithms compared to RandAugment, making it highly applicable to real-world problems, where labeled data is scarce. The code is available at \\texttt{\\url{https://github.com/warai-0toko/DivAug}}.", "published": "2021-03-26T16:00:01Z", "version": 2}, {"aid": "2103.17249", "authors": ["Or Patashnik", "Zongze Wu", "Eli Shechtman", "Daniel Cohen-Or", "Dani Lischinski"], "title": "StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery", "url": "http://arxiv.org/pdf/2103.17249v1", "summary": "Inspired by the ability of StyleGAN to generate highly realistic images in a variety of domains, much recent work has focused on understanding how to use the latent spaces of StyleGAN to manipulate generated and real images. However, discovering semantically meaningful latent manipulations typically involves painstaking human examination of the many degrees of freedom, or an annotated collection of images for each desired manipulation. In this work, we explore leveraging the power of recently introduced Contrastive Language-Image Pre-training (CLIP) models in order to develop a text-based interface for StyleGAN image manipulation that does not require such manual effort. We first introduce an optimization scheme that utilizes a CLIP-based loss to modify an input latent vector in response to a user-provided text prompt. Next, we describe a latent mapper that infers a text-guided latent manipulation step for a given input image, allowing faster and more stable text-based manipulation. Finally, we present a method for mapping a text prompts to input-agnostic directions in StyleGAN's style space, enabling interactive text-driven image manipulation. Extensive results and comparisons demonstrate the effectiveness of our approaches.", "published": "2021-03-31T17:51:25Z", "version": 1}, {"aid": "2104.00272", "authors": ["Kevin Lin", "Lijuan Wang", "Zicheng Liu"], "title": "Mesh Graphormer", "url": "http://arxiv.org/pdf/2104.00272v2", "summary": "We present a graph-convolution-reinforced transformer, named Mesh Graphormer, for 3D human pose and mesh reconstruction from a single image. Recently both transformers and graph convolutional neural networks (GCNNs) have shown promising progress in human mesh reconstruction. Transformer-based approaches are effective in modeling non-local interactions among 3D mesh vertices and body joints, whereas GCNNs are good at exploiting neighborhood vertex interactions based on a pre-specified mesh topology. In this paper, we study how to combine graph convolutions and self-attentions in a transformer to model both local and global interactions. Experimental results show that our proposed method, Mesh Graphormer, significantly outperforms the previous state-of-the-art methods on multiple benchmarks, including Human3.6M, 3DPW, and FreiHAND datasets. Code and pre-trained models are available at https://github.com/microsoft/MeshGraphormer", "published": "2021-04-01T06:16:36Z", "version": 2}, {"aid": "2104.00466", "authors": ["Zhisheng Zhong", "Jiequan Cui", "Shu Liu", "Jiaya Jia"], "title": "Improving Calibration for Long-Tailed Recognition", "url": "http://arxiv.org/pdf/2104.00466v1", "summary": "Deep neural networks may perform poorly when training datasets are heavily class-imbalanced. Recently, two-stage methods decouple representation learning and classifier learning to improve performance. But there is still the vital issue of miscalibration. To address it, we design two methods to improve calibration and performance in such scenarios. Motivated by the fact that predicted probability distributions of classes are highly related to the numbers of class instances, we propose label-aware smoothing to deal with different degrees of over-confidence for classes and improve classifier learning. For dataset bias between these two stages due to different samplers, we further propose shifted batch normalization in the decoupling framework. Our proposed methods set new records on multiple popular long-tailed recognition benchmark datasets, including CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, Places-LT, and iNaturalist 2018. Code will be available at https://github.com/Jia-Research-Lab/MiSLAS.", "published": "2021-04-01T13:55:21Z", "version": 1}, {"aid": "2104.04162", "authors": ["Ademola Okerinde", "Lior Shamir", "William Hsu", "Tom Theis", "Nasik Nafi"], "title": "eGAN: Unsupervised approach to class imbalance using transfer learning", "url": "http://arxiv.org/pdf/2104.04162v2", "summary": "Class imbalance is an inherent problem in many machine learning classification tasks. This often leads to trained models that are unusable for any practical purpose. In this study we explore an unsupervised approach to address these imbalances by leveraging transfer learning from pre-trained image classification models to encoder-based Generative Adversarial Network (eGAN). To the best of our knowledge, this is the first work to tackle this problem using GAN without needing to augment with synthesized fake images.   In the proposed approach we use the discriminator network to output a negative or positive score. We classify as minority, test samples with negative scores and as majority those with positive scores. Our approach eliminates epistemic uncertainty in model predictions, as the P(minority) + P(majority) need not sum up to 1. The impact of transfer learning and combinations of different pre-trained image classification models at the generator and discriminator is also explored. Best result of 0.69 F1-score was obtained on CIFAR-10 classification task with imbalance ratio of 1:2500.   Our approach also provides a mechanism of thresholding the specificity or sensitivity of our machine learning system. Keywords: Class imbalance, Transfer Learning, GAN, nash equilibrium", "published": "2021-04-09T02:37:55Z", "version": 2}, {"aid": "2104.05704", "authors": ["Ali Hassani", "Steven Walton", "Nikhil Shah", "Abulikemu Abuduweili", "Jiachen Li", "Humphrey Shi"], "title": "Escaping the Big Data Paradigm with Compact Transformers", "url": "http://arxiv.org/pdf/2104.05704v4", "summary": "With the rise of Transformers as the standard for language processing, and their advancements in computer vision, there has been a corresponding growth in parameter size and amounts of training data. Many have come to believe that because of this, transformers are not suitable for small sets of data. This trend leads to concerns such as: limited availability of data in certain scientific domains and the exclusion of those with limited resource from research in the field. In this paper, we aim to present an approach for small-scale learning by introducing Compact Transformers. We show for the first time that with the right size, convolutional tokenization, transformers can avoid overfitting and outperform state-of-the-art CNNs on small datasets. Our models are flexible in terms of model size, and can have as little as 0.28M parameters while achieving competitive results. Our best model can reach 98% accuracy when training from scratch on CIFAR-10 with only 3.7M parameters, which is a significant improvement in data-efficiency over previous Transformer based models being over 10x smaller than other transformers and is 15% the size of ResNet50 while achieving similar performance. CCT also outperforms many modern CNN based approaches, and even some recent NAS-based approaches. Additionally, we obtain a new SOTA result on Flowers-102 with 99.76% top-1 accuracy, and improve upon the existing baseline on ImageNet (82.71% accuracy with 29% as many parameters as ViT), as well as NLP tasks. Our simple and compact design for transformers makes them more feasible to study for those with limited computing resources and/or dealing with small datasets, while extending existing research efforts in data efficient transformers. Our code and pre-trained models are publicly available at https://github.com/SHI-Labs/Compact-Transformers.", "published": "2021-04-12T17:58:56Z", "version": 4}, {"aid": "2104.05988", "authors": ["Marcel C. B\u00fchler", "Abhimitra Meka", "Gengyan Li", "Thabo Beeler", "Otmar Hilliges"], "title": "VariTex: Variational Neural Face Textures", "url": "http://arxiv.org/pdf/2104.05988v3", "summary": "Deep generative models can synthesize photorealistic images of human faces with novel identities. However, a key challenge to the wide applicability of such techniques is to provide independent control over semantically meaningful parameters: appearance, head pose, face shape, and facial expressions. In this paper, we propose VariTex - to the best of our knowledge the first method that learns a variational latent feature space of neural face textures, which allows sampling of novel identities. We combine this generative model with a parametric face model and gain explicit control over head pose and facial expressions. To generate complete images of human heads, we propose an additive decoder that adds plausible details such as hair. A novel training scheme enforces a pose-independent latent space and in consequence, allows learning a one-to-many mapping between latent codes and pose-conditioned exterior regions. The resulting method can generate geometrically consistent images of novel identities under fine-grained control over head pose, face shape, and facial expressions. This facilitates a broad range of downstream tasks, like sampling novel identities, changing the head pose, expression transfer, and more. Code and models are available for research on https://mcbuehler.github.io/VariTex.", "published": "2021-04-13T07:47:53Z", "version": 3}, {"aid": "2104.07658", "authors": ["Charig Yang", "Hala Lamdouar", "Erika Lu", "Andrew Zisserman", "Weidi Xie"], "title": "Self-supervised Video Object Segmentation by Motion Grouping", "url": "http://arxiv.org/pdf/2104.07658v2", "summary": "Animals have evolved highly functional visual systems to understand motion, assisting perception even under complex environments. In this paper, we work towards developing a computer vision system able to segment objects by exploiting motion cues, i.e. motion segmentation. We make the following contributions: First, we introduce a simple variant of the Transformer to segment optical flow frames into primary objects and the background. Second, we train the architecture in a self-supervised manner, i.e. without using any manual annotations. Third, we analyze several critical components of our method and conduct thorough ablation studies to validate their necessity. Fourth, we evaluate the proposed architecture on public benchmarks (DAVIS2016, SegTrackv2, and FBMS59). Despite using only optical flow as input, our approach achieves superior or comparable results to previous state-of-the-art self-supervised methods, while being an order of magnitude faster. We additionally evaluate on a challenging camouflage dataset (MoCA), significantly outperforming the other self-supervised approaches, and comparing favourably to the top supervised approach, highlighting the importance of motion cues, and the potential bias towards visual appearance in existing video segmentation models.", "published": "2021-04-15T17:59:32Z", "version": 2}, {"aid": "2104.09493", "authors": ["Megh Shukla"], "title": "Bayesian Uncertainty and Expected Gradient Length -- Regression: Two Sides Of The Same Coin?", "url": "http://arxiv.org/pdf/2104.09493v3", "summary": "Active learning algorithms select a subset of data for annotation to maximize the model performance on a budget. One such algorithm is Expected Gradient Length, which as the name suggests uses the approximate gradient induced per example in the sampling process. While Expected Gradient Length has been successfully used for classification and regression, the formulation for regression remains intuitively driven. Hence, our theoretical contribution involves deriving this formulation, thereby supporting the experimental evidence. Subsequently, we show that expected gradient length in regression is equivalent to Bayesian uncertainty. If certain assumptions are infeasible, our algorithmic contribution (EGL++) approximates the effect of ensembles with a single deterministic network. Instead of computing multiple possible inferences per input, we leverage previously annotated samples to quantify the probability of previous labels being the true label. Such an approach allows us to extend expected gradient length to a new task: human pose estimation. We perform experimental validation on two human pose datasets (MPII and LSP/LSPET), highlighting the interpretability and competitiveness of EGL++ with different active learning algorithms for human pose estimation.", "published": "2021-04-19T17:56:59Z", "version": 3}, {"aid": "2104.10729", "authors": ["Chongyi Li", "Chunle Guo", "Linghao Han", "Jun Jiang", "Ming-Ming Cheng", "Jinwei Gu", "Chen Change Loy"], "title": "Low-Light Image and Video Enhancement Using Deep Learning: A Survey", "url": "http://arxiv.org/pdf/2104.10729v3", "summary": "Low-light image enhancement (LLIE) aims at improving the perception or interpretability of an image captured in an environment with poor illumination. Recent advances in this area are dominated by deep learning-based solutions, where many learning strategies, network structures, loss functions, training data, etc. have been employed. In this paper, we provide a comprehensive survey to cover various aspects ranging from algorithm taxonomy to open issues. To examine the generalization of existing methods, we propose a low-light image and video dataset, in which the images and videos are taken by different mobile phones' cameras under diverse illumination conditions. Besides, for the first time, we provide a unified online platform that covers many popular LLIE methods, of which the results can be produced through a user-friendly web interface. In addition to qualitative and quantitative evaluation of existing methods on publicly available and our proposed datasets, we also validate their performance in face detection in the dark.This survey together with the proposed dataset and online platform could serve as a reference source for future study and promote the development of this research field. The proposed platform and dataset as well as the collected methods, datasets, and evaluation metrics are publicly available and will be regularly updated.", "published": "2021-04-21T19:12:19Z", "version": 3}, {"aid": "2104.11178", "authors": ["Hassan Akbari", "Liangzhe Yuan", "Rui Qian", "Wei-Hong Chuang", "Shih-Fu Chang", "Yin Cui", "Boqing Gong"], "title": "VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text", "url": "http://arxiv.org/pdf/2104.11178v3", "summary": "We present a framework for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, our Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts multimodal representations that are rich enough to benefit a variety of downstream tasks. We train VATT end-to-end from scratch using multimodal contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text-to-video retrieval. Furthermore, we study a modality-agnostic, single-backbone Transformer by sharing weights among the three modalities. We show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream tasks. Especially, VATT's vision Transformer achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600, 72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding supervised pre-training. Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet compared to 64.7% by training the same Transformer from scratch, showing the generalizability of our model despite the domain gap between videos and images. VATT's audio Transformer also sets a new record on waveform-based audio event recognition by achieving the mAP of 39.4% on AudioSet without any supervised pre-training. VATT's source code is publicly available.", "published": "2021-04-22T17:07:41Z", "version": 3}, {"aid": "2104.13478", "authors": ["Michael M. Bronstein", "Joan Bruna", "Taco Cohen", "Petar Veli\u010dkovi\u0107"], "title": "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges", "url": "http://arxiv.org/pdf/2104.13478v2", "summary": "The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation.   While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications.   Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.", "published": "2021-04-27T21:09:51Z", "version": 2}, {"aid": "2105.02738", "authors": ["Marija Slavkovik", "Clemens Stachl", "Caroline Pitman", "Jonathan Askonas"], "title": "Digital Voodoo Dolls", "url": "http://arxiv.org/pdf/2105.02738v2", "summary": "An institution, be it a body of government, commercial enterprise, or a service, cannot interact directly with a person. Instead, a model is created to represent us. We argue the existence of a new high-fidelity type of person model which we call a digital voodoo doll. We conceptualize it and compare its features with existing models of persons. Digital voodoo dolls are distinguished by existing completely beyond the influence and control of the person they represent. We discuss the ethical issues that such a lack of accountability creates and argue how these concerns can be mitigated.", "published": "2021-05-06T14:56:54Z", "version": 2}, {"aid": "2105.07674", "authors": ["Andrea Cossu", "Davide Bacciu", "Antonio Carta", "Claudio Gallicchio", "Vincenzo Lomonaco"], "title": "Continual Learning with Echo State Networks", "url": "http://arxiv.org/pdf/2105.07674v3", "summary": "Continual Learning (CL) refers to a learning setup where data is non stationary and the model has to learn without forgetting existing knowledge. The study of CL for sequential patterns revolves around trained recurrent networks. In this work, instead, we introduce CL in the context of Echo State Networks (ESNs), where the recurrent component is kept fixed. We provide the first evaluation of catastrophic forgetting in ESNs and we highlight the benefits in using CL strategies which are not applicable to trained recurrent models. Our results confirm the ESN as a promising model for CL and open to its use in streaming scenarios.", "published": "2021-05-17T08:49:01Z", "version": 3}, {"aid": "2105.10404", "authors": ["Michael Rosenblum", "Arkady Pikovsky", "Andrea A. K\u00fchn", "Johannes L. Busch"], "title": "Real-time estimation of phase and amplitude with application to neural data", "url": "http://arxiv.org/pdf/2105.10404v1", "summary": "Computation of the instantaneous phase and amplitude via the Hilbert Transform is a powerful tool of data analysis. This approach finds many applications in various science and engineering branches but is not proper for causal estimation because it requires knowledge of the signal's past and future. However, several problems require real-time estimation of phase and amplitude; an illustrative example is phase-locked or amplitude-dependent stimulation in neuroscience. In this paper, we discuss and compare three causal algorithms that do not rely on the Hilbert Transform but exploit well-known physical phenomena, the synchronization and the resonance. After testing the algorithms on a synthetic data set, we illustrate their performance computing phase and amplitude for the accelerometer tremor measurements and a Parkinsonian patient's beta-band brain activity.", "published": "2021-05-20T12:21:33Z", "version": 1}, {"aid": "2105.10461", "authors": ["Jeffrey L. Krichmar"], "title": "Edelman's Steps Toward a Conscious Artifact", "url": "http://arxiv.org/pdf/2105.10461v2", "summary": "In 2006, during a meeting of a working group of scientists in La Jolla, California at The Neurosciences Institute (NSI), Gerald Edelman described a roadmap towards the creation of a Conscious Artifact. As far as I know, this roadmap was not published. However, it did shape my thinking and that of many others in the years since that meeting. This short paper, which is based on my notes taken during the meeting, describes the key steps in this roadmap. I believe it is as groundbreaking today as it was more than 15 years ago.", "published": "2021-05-22T00:13:06Z", "version": 2}, {"aid": "2105.14257", "authors": ["Sarthak Mittal", "Korbinian Abstreiter", "Stefan Bauer", "Bernhard Sch\u00f6lkopf", "Arash Mehrjou"], "title": "Diffusion-Based Representation Learning", "url": "http://arxiv.org/pdf/2105.14257v4", "summary": "Diffusion-based methods represented as stochastic differential equations on a continuous-time domain have recently proven successful as a non-adversarial generative model. Training such models relies on denoising score matching, which can be seen as multi-scale denoising autoencoders. Here, we augment the denoising score matching framework to enable representation learning without any supervised signal. GANs and VAEs learn representations by directly transforming latent codes to data samples. In contrast, the introduced diffusion-based representation learning relies on a new formulation of the denoising score matching objective and thus encodes the information needed for denoising. We illustrate how this difference allows for manual control of the level of details encoded in the representation. Using the same approach, we propose to learn an infinite-dimensional latent code that achieves improvements of state-of-the-art models on semi-supervised image classification. We also compare the quality of learned representations of diffusion score matching with other methods like autoencoder and contrastively trained systems through their performances on downstream tasks.", "published": "2021-05-29T09:26:02Z", "version": 4}, {"aid": "2107.09507", "authors": ["Jian Cui", "Zirui Lan", "Olga Sourina", "Wolfgang M\u00fcller-Wittig"], "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with an Interpretable Convolutional Neural Network", "url": "http://arxiv.org/pdf/2107.09507v4", "summary": "In the context of electroencephalogram (EEG)-based driver drowsiness recognition, it is still challenging to design a calibration-free system, since EEG signals vary significantly among different subjects and recording sessions. Many efforts have been made to use deep learning methods for mental state recognition from EEG signals. However, existing work mostly treats deep learning models as black-box classifiers, while what have been learned by the models and to which extent they are affected by the noise in EEG data are still underexplored. In this paper, we develop a novel convolutional neural network combined with an interpretation technique that allows sample-wise analysis of important features for classification. The network has a compact structure and takes advantage of separable convolutions to process the EEG signals in a spatial-temporal sequence. Results show that the model achieves an average accuracy of 78.35% on 11 subjects for leave-one-out cross-subject drowsiness recognition, which is higher than the conventional baseline methods of 53.40%-72.68% and state-of-the-art deep learning methods of 71.75%-75.19%. Interpretation results indicate the model has learned to recognize biologically meaningful features from EEG signals, e.g., Alpha spindles, as strong indicators of drowsiness across different subjects. In addition, we also explore reasons behind some wrongly classified samples with the interpretation technique and discuss potential ways to improve the recognition accuracy. Our work illustrates a promising direction on using interpretable deep learning models to discover meaningful patterns related to different mental states from complex EEG signals.", "published": "2021-05-30T14:47:20Z", "version": 4}, {"aid": "2106.01345", "authors": ["Lili Chen", "Kevin Lu", "Aravind Rajeswaran", "Kimin Lee", "Aditya Grover", "Michael Laskin", "Pieter Abbeel", "Aravind Srinivas", "Igor Mordatch"], "title": "Decision Transformer: Reinforcement Learning via Sequence Modeling", "url": "http://arxiv.org/pdf/2106.01345v2", "summary": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.", "published": "2021-06-02T17:53:39Z", "version": 2}, {"aid": "2106.02022", "authors": ["Micha\u00ebl Ramamonjisoa", "Michael Firman", "Jamie Watson", "Vincent Lepetit", "Daniyar Turmukhambetov"], "title": "Single Image Depth Prediction with Wavelet Decomposition", "url": "http://arxiv.org/pdf/2106.02022v2", "summary": "We present a novel method for predicting accurate depths from monocular images with high efficiency. This optimal efficiency is achieved by exploiting wavelet decomposition, which is integrated in a fully differentiable encoder-decoder architecture. We demonstrate that we can reconstruct high-fidelity depth maps by predicting sparse wavelet coefficients. In contrast with previous works, we show that wavelet coefficients can be learned without direct supervision on coefficients. Instead we supervise only the final depth image that is reconstructed through the inverse wavelet transform. We additionally show that wavelet coefficients can be learned in fully self-supervised scenarios, without access to ground-truth depth. Finally, we apply our method to different state-of-the-art monocular depth estimation models, in each case giving similar or better results compared to the original model, while requiring less than half the multiply-adds in the decoder network. Code at https://github.com/nianticlabs/wavelet-monodepth", "published": "2021-06-03T17:42:25Z", "version": 2}, {"aid": "2106.02299", "authors": ["Liying Lu", "Wenbo Li", "Xin Tao", "Jiangbo Lu", "Jiaya Jia"], "title": "MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution", "url": "http://arxiv.org/pdf/2106.02299v1", "summary": "Reference-based image super-resolution (RefSR) has shown promising success in recovering high-frequency details by utilizing an external reference image (Ref). In this task, texture details are transferred from the Ref image to the low-resolution (LR) image according to their point- or patch-wise correspondence. Therefore, high-quality correspondence matching is critical. It is also desired to be computationally efficient. Besides, existing RefSR methods tend to ignore the potential large disparity in distributions between the LR and Ref images, which hurts the effectiveness of the information utilization. In this paper, we propose the MASA network for RefSR, where two novel modules are designed to address these problems. The proposed Match & Extraction Module significantly reduces the computational cost by a coarse-to-fine correspondence matching scheme. The Spatial Adaptation Module learns the difference of distribution between the LR and Ref images, and remaps the distribution of Ref features to that of LR features in a spatially adaptive way. This scheme makes the network robust to handle different reference images. Extensive quantitative and qualitative experiments validate the effectiveness of our proposed model.", "published": "2021-06-04T07:15:32Z", "version": 1}, {"aid": "2106.02994", "authors": ["Alex Wong", "Safa Cicek", "Stefano Soatto"], "title": "Learning Topology from Synthetic Data for Unsupervised Depth Completion", "url": "http://arxiv.org/pdf/2106.02994v3", "summary": "We present a method for inferring dense depth maps from images and sparse depth measurements by leveraging synthetic data to learn the association of sparse point clouds with dense natural shapes, and using the image as evidence to validate the predicted depth map. Our learned prior for natural shapes uses only sparse depth as input, not images, so the method is not affected by the covariate shift when attempting to transfer learned models from synthetic data to real ones. This allows us to use abundant synthetic data with ground truth to learn the most difficult component of the reconstruction process, which is topology estimation, and use the image to refine the prediction based on photometric evidence. Our approach uses fewer parameters than previous methods, yet, achieves the state of the art on both indoor and outdoor benchmark datasets. Code available at: https://github.com/alexklwong/learning-topology-synthetic-data.", "published": "2021-06-06T00:21:12Z", "version": 3}, {"aid": "2106.03761", "authors": ["Tiago Salvador", "Stephanie Cairns", "Vikram Voleti", "Noah Marshall", "Adam Oberman"], "title": "FairCal: Fairness Calibration for Face Verification", "url": "http://arxiv.org/pdf/2106.03761v4", "summary": "Despite being widely used, face recognition models suffer from bias: the probability of a false positive (incorrect face match) strongly depends on sensitive attributes such as the ethnicity of the face. As a result, these models can disproportionately and negatively impact minority groups, particularly when used by law enforcement. The majority of bias reduction methods have several drawbacks: they use an end-to-end retraining approach, may not be feasible due to privacy issues, and often reduce accuracy. An alternative approach is post-processing methods that build fairer decision classifiers using the features of pre-trained models, thus avoiding the cost of retraining. However, they still have drawbacks: they reduce accuracy (AGENDA, PASS, FTC), or require retuning for different false positive rates (FSN). In this work, we introduce the Fairness Calibration (FairCal) method, a post-training approach that simultaneously: (i) increases model accuracy (improving the state-of-the-art), (ii) produces fairly-calibrated probabilities, (iii) significantly reduces the gap in the false positive rates, (iv) does not require knowledge of the sensitive attribute, and (v) does not require retraining, training an additional model, or retuning. We apply it to the task of Face Verification, and obtain state-of-the-art results with all the above advantages.", "published": "2021-06-07T16:26:26Z", "version": 4}, {"aid": "2106.04026", "authors": ["Dae-Hyeok Lee", "Dong-Kyun Han", "Sung-Jin Kim", "Ji-Hoon Jeong", "Seong-Whan Lee"], "title": "Subject-Independent Brain-Computer Interface for Decoding High-Level Visual Imagery Tasks", "url": "http://arxiv.org/pdf/2106.04026v2", "summary": "Brain-computer interface (BCI) is used for communication between humans and devices by recognizing status and intention of humans. Communication between humans and a drone using electroencephalogram (EEG) signals is one of the most challenging issues in the BCI domain. In particular, the control of drone swarms (the direction and formation) has more advantages compared to the control of a drone. The visual imagery (VI) paradigm is that subjects visually imagine specific objects or scenes. Reduction of the variability among EEG signals of subjects is essential for practical BCI-based systems. In this study, we proposed the subepoch-wise feature encoder (SEFE) to improve the performances in the subject-independent tasks by using the VI dataset. This study is the first attempt to demonstrate the possibility of generalization among subjects in the VI-based BCI. We used the leave-one-subject-out cross-validation for evaluating the performances. We obtained higher performances when including our proposed module than excluding our proposed module. The DeepConvNet with SEFE showed the highest performance of 0.72 among six different decoding models. Hence, we demonstrated the feasibility of decoding the VI dataset in the subject-independent task with robust performances by using our proposed module.", "published": "2021-06-08T00:39:31Z", "version": 2}, {"aid": "2106.05238", "authors": ["Matthew Willetts", "Brooks Paige"], "title": "I Don't Need u: Identifiable Non-Linear ICA Without Side Information", "url": "http://arxiv.org/pdf/2106.05238v4", "summary": "In this paper, we investigate the algorithmic stability of unsupervised representation learning with deep generative models, as a function of repeated re-training on the same input data. Algorithms for learning low dimensional linear representations -- for example principal components analysis (PCA), or linear independent components analysis (ICA) -- come with guarantees that they will always reveal the same latent representations (perhaps up to an arbitrary rotation or permutation). Unfortunately, for non-linear representation learning, such as in a variational auto-encoder (VAE) model trained by stochastic gradient descent, we have no such guarantees. Recent work on identifiability in non-linear ICA have introduced a family of deep generative models that have identifiable latent representations, achieved by conditioning on side information (e.g. informative labels). We empirically evaluate the stability of these models under repeated re-estimation of parameters, and compare them to both standard VAEs and deep generative models which learn to cluster in their latent space. Surprisingly, we discover side information is not necessary for algorithmic stability: using standard quantitative measures of identifiability, we find deep generative models with latent clusterings are empirically identifiable to the same degree as models which rely on auxiliary labels. We relate these results to the possibility of identifiable non-linear ICA.", "published": "2021-06-09T17:22:08Z", "version": 4}, {"aid": "2106.06112", "authors": ["Jingyi Zhang", "Jiaxing Huang", "Zichen Tian", "Shijian Lu"], "title": "Spectral Unsupervised Domain Adaptation for Visual Recognition", "url": "http://arxiv.org/pdf/2106.06112v3", "summary": "Though unsupervised domain adaptation (UDA) has achieved very impressive progress recently, it remains a great challenge due to missing target annotations and the rich discrepancy between source and target distributions. We propose Spectral UDA (SUDA), an effective and efficient UDA technique that works in the spectral space and can generalize across different visual recognition tasks. SUDA addresses the UDA challenges from two perspectives. First, it introduces a spectrum transformer (ST) that mitigates inter-domain discrepancies by enhancing domain-invariant spectra while suppressing domain-variant spectra of source and target samples simultaneously. Second, it introduces multi-view spectral learning that learns useful unsupervised representations by maximizing mutual information among multiple ST-generated spectral views of each target sample. Extensive experiments show that SUDA achieves superior accuracy consistently across different visual tasks in object detection, semantic segmentation and image classification. Additionally, SUDA also works with the transformer-based network and achieves state-of-the-art performance on object detection.", "published": "2021-06-11T01:31:52Z", "version": 3}, {"aid": "2106.07865", "authors": ["Brandon R. Munn", "Eli J. M\u00fcller", "James M. Shine"], "title": "Noradrenergic neuromodulation of nonlinear bursting neurons controls critical dynamics", "url": "http://arxiv.org/pdf/2106.07865v3", "summary": "In order to remain adaptable to a dynamic environment, neural activity must be simultaneously both sensitive and stable. To solve this problem, the brain has been hypothesised to sit near a critical boundary. Yet, precisely how criticality and these opposing information processing modes are implemented in the brain remains elusive. A potential solution to this problem involves modulating intrinsically nonlinear neurons within the cerebral cortex with neuromodulatory neurotransmitters such as noradrenaline, a highly-conserved chemical released from the pontine locus coeruleus. Here we confirm that neuronal spiking in mice is poised close to the critical point of a branching process and that time-varying signatures of criticality fluctuate with neuromodulatory tone, as assessed by dynamic alterations in pupil diameter. We explore these results theoretically by creating a dual-compartment model of non-linear pyramidal neurons - capable of both regular spike and bursting modes - that replicates our main empirical findings of slightly subcritical dynamics. We then probe our model at a resolution impossible in vivo to demonstrate that noradrenaline differentially alters spiking- and bursting-criticality to facilitate sensitive and stable dynamics following an inverted-U profile that peaks at intermediate noradrenergic tone. Finally, we demonstrate that this intermediate noradrenergic regime displays burst avalanches with power-law size and duration distributions and scaling relationship belonging to the universality class of self-organized criticality. Our results confirm that the noradrenergic ascending arousal system acts as a control parameter for emergent critical dynamics in the brain. This methodology could be extended to explore other neuromodulators as control parameters of the brain.", "published": "2021-06-15T03:59:16Z", "version": 3}, {"aid": "2106.08208", "authors": ["Feihu Huang", "Junyi Li", "Heng Huang"], "title": "SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients", "url": "http://arxiv.org/pdf/2106.08208v10", "summary": "Adaptive gradient methods have shown excellent performances for solving many machine learning problems. Although multiple adaptive gradient methods were recently studied, they mainly focus on either empirical or theoretical aspects and also only work for specific problems by using some specific adaptive learning rates. Thus, it is desired to design a universal framework for practical algorithms of adaptive gradients with theoretical guarantee to solve general problems. To fill this gap, we propose a faster and universal framework of adaptive gradients (i.e., SUPER-ADAM) by introducing a universal adaptive matrix that includes most existing adaptive gradient forms. Moreover, our framework can flexibly integrate the momentum and variance reduced techniques. In particular, our novel framework provides the convergence analysis support for adaptive gradient methods under the nonconvex setting. In theoretical analysis, we prove that our SUPER-ADAM algorithm can achieve the best known gradient (i.e., stochastic first-order oracle (SFO)) complexity of $\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point of nonconvex optimization, which matches the lower bound for stochastic smooth nonconvex optimization. In numerical experiments, we employ various deep learning tasks to validate that our algorithm consistently outperforms the existing adaptive algorithms. Code is available at https://github.com/LIJUNYI95/SuperAdam", "published": "2021-06-15T15:16:28Z", "version": 10}, {"aid": "2106.08693", "authors": ["Alexander Tsaregorodtsev", "Vasileios Belagiannis"], "title": "ParticleAugment: Sampling-Based Data Augmentation", "url": "http://arxiv.org/pdf/2106.08693v3", "summary": "We present an automated data augmentation approach for image classification. We formulate the problem as Monte Carlo sampling where our goal is to approximate the optimal augmentation policies. We propose a particle filtering scheme for the policy search where the probability of applying a set of augmentation operations forms the state of the filter. We measure the policy performance based on the loss function difference between a reference and the actual model, which we afterwards use to re-weight the particles and finally update the policy. In our experiments, we show that our formulation for automated augmentation reaches promising results on CIFAR-10, CIFAR-100, and ImageNet datasets using the standard network architectures for this problem. By comparing with the related work, our method reaches a balance between the computational cost of policy search and the model performance. Our code will be made publicly available.", "published": "2021-06-16T10:56:02Z", "version": 3}, {"aid": "2106.09563", "authors": ["Lucas Caccia", "Jing Xu", "Myle Ott", "Marc'Aurelio Ranzato", "Ludovic Denoyer"], "title": "On Anytime Learning at Macroscale", "url": "http://arxiv.org/pdf/2106.09563v5", "summary": "In many practical applications of machine learning data arrives sequentially over time in large chunks. Practitioners have then to decide how to allocate their computational budget in order to obtain the best performance at any point in time. Online learning theory for convex optimization suggests that the best strategy is to use data as soon as it arrives. However, this might not be the best strategy when using deep non-linear networks, particularly when these perform multiple passes over each chunk of data rendering the overall distribution non i.i.d.. In this paper, we formalize this learning setting in the simplest scenario in which each data chunk is drawn from the same underlying distribution, and make a first attempt at empirically answering the following questions: How long should the learner wait before training on the newly arrived chunks? What architecture should the learner adopt? Should the learner increase capacity over time as more data is observed? We probe this learning setting using convolutional neural networks trained on classic computer vision benchmarks as well as a large transformer model trained on a large-scale language modeling task. Code is available at \\url{www.github.com/facebookresearch/ALMA}.", "published": "2021-06-17T14:45:22Z", "version": 5}, {"aid": "2106.09701", "authors": ["James Smith", "Yen-Chang Hsu", "Jonathan Balloch", "Yilin Shen", "Hongxia Jin", "Zsolt Kira"], "title": "Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning", "url": "http://arxiv.org/pdf/2106.09701v2", "summary": "Modern computer vision applications suffer from catastrophic forgetting when incrementally learning new concepts over time. The most successful approaches to alleviate this forgetting require extensive replay of previously seen data, which is problematic when memory constraints or data legality concerns exist. In this work, we consider the high-impact problem of Data-Free Class-Incremental Learning (DFCIL), where an incremental learning agent must learn new concepts over time without storing generators or training data from past tasks. One approach for DFCIL is to replay synthetic images produced by inverting a frozen copy of the learner's classification model, but we show this approach fails for common class-incremental benchmarks when using standard distillation strategies. We diagnose the cause of this failure and propose a novel incremental distillation strategy for DFCIL, contributing a modified cross-entropy training and importance-weighted feature distillation, and show that our method results in up to a 25.1% increase in final task accuracy (absolute difference) compared to SOTA DFCIL methods for common class-incremental benchmarks. Our method even outperforms several standard replay based methods which store a coreset of images.", "published": "2021-06-17T17:56:08Z", "version": 2}, {"aid": "2106.10163", "authors": ["Erik Jenner", "Maurice Weiler"], "title": "Steerable Partial Differential Operators for Equivariant Neural Networks", "url": "http://arxiv.org/pdf/2106.10163v3", "summary": "Recent work in equivariant deep learning bears strong similarities to physics. Fields over a base space are fundamental entities in both subjects, as are equivariant maps between these fields. In deep learning, however, these maps are usually defined by convolutions with a kernel, whereas they are partial differential operators (PDOs) in physics. Developing the theory of equivariant PDOs in the context of deep learning could bring these subjects even closer together and lead to a stronger flow of ideas. In this work, we derive a $G$-steerability constraint that completely characterizes when a PDO between feature vector fields is equivariant, for arbitrary symmetry groups $G$. We then fully solve this constraint for several important groups. We use our solutions as equivariant drop-in replacements for convolutional layers and benchmark them in that role. Finally, we develop a framework for equivariant maps based on Schwartz distributions that unifies classical convolutions and differential operators and gives insight about the relation between the two.", "published": "2021-06-18T14:58:19Z", "version": 3}, {"aid": "2106.10165", "authors": ["Daniel A. Roberts", "Sho Yaida", "Boris Hanin"], "title": "The Principles of Deep Learning Theory", "url": "http://arxiv.org/pdf/2106.10165v2", "summary": "This book develops an effective theory approach to understanding deep neural networks of practical relevance. Beginning from a first-principles component-level picture of networks, we explain how to determine an accurate description of the output of trained networks by solving layer-to-layer iteration equations and nonlinear learning dynamics. A main result is that the predictions of networks are described by nearly-Gaussian distributions, with the depth-to-width aspect ratio of the network controlling the deviations from the infinite-width Gaussian description. We explain how these effectively-deep networks learn nontrivial representations from training and more broadly analyze the mechanism of representation learning for nonlinear models. From a nearly-kernel-methods perspective, we find that the dependence of such models' predictions on the underlying learning algorithm can be expressed in a simple and universal way. To obtain these results, we develop the notion of representation group flow (RG flow) to characterize the propagation of signals through the network. By tuning networks to criticality, we give a practical solution to the exploding and vanishing gradient problem. We further explain how RG flow leads to near-universal behavior and lets us categorize networks built from different activation functions into universality classes. Altogether, we show that the depth-to-width ratio governs the effective model complexity of the ensemble of trained networks. By using information-theoretic techniques, we estimate the optimal aspect ratio at which we expect the network to be practically most useful and show how residual connections can be used to push this scale to arbitrary depths. With these tools, we can learn in detail about the inductive bias of architectures, hyperparameters, and optimizers.", "published": "2021-06-18T15:00:00Z", "version": 2}, {"aid": "2106.11342", "authors": ["Aston Zhang", "Zachary C. Lipton", "Mu Li", "Alexander J. Smola"], "title": "Dive into Deep Learning", "url": "http://arxiv.org/pdf/2106.11342v5", "summary": "This open-source book represents our attempt to make deep learning approachable, teaching readers the concepts, the context, and the code. The entire book is drafted in Jupyter notebooks, seamlessly integrating exposition figures, math, and interactive examples with self-contained code. Our goal is to offer a resource that could (i) be freely available for everyone; (ii) offer sufficient technical depth to provide a starting point on the path to actually becoming an applied machine learning scientist; (iii) include runnable code, showing readers how to solve problems in practice; (iv) allow for rapid updates, both by us and also by the community at large; (v) be complemented by a forum for interactive discussion of technical details and to answer questions.", "published": "2021-06-21T18:19:46Z", "version": 5}, {"aid": "2106.11396", "authors": ["Feihu Huang", "Junyi Li", "Shangqian Gao"], "title": "BiAdam: Fast Adaptive Bilevel Optimization Methods", "url": "http://arxiv.org/pdf/2106.11396v4", "summary": "Bilevel optimization recently has attracted increased interest in machine learning due to its many applications such as hyper-parameter optimization and meta learning. Although many bilevel methods recently have been proposed, these methods do not consider using adaptive learning rates. It is well known that adaptive learning rates can accelerate optimization algorithms. To fill this gap, in the paper, we propose a novel fast adaptive bilevel framework to solve stochastic bilevel optimization problems that the outer problem is possibly nonconvex and the inner problem is strongly convex. Our framework uses unified adaptive matrices including many types of adaptive learning rates, and can flexibly use the momentum and variance reduced techniques. In particular, we provide a useful convergence analysis framework for the bilevel optimization. Specifically, we propose a fast single-loop adaptive bilevel optimization (BiAdam) algorithm, which achieves a sample complexity of $\\tilde{O}(\\epsilon^{-4})$ for finding an $\\epsilon$-stationary solution. Meanwhile, we propose an accelerated version of BiAdam algorithm (VR-BiAdam), which reaches the best known sample complexity of $\\tilde{O}(\\epsilon^{-3})$. To the best of our knowledge, we first study the adaptive bilevel optimization methods with adaptive learning rates. Experimental results on data hyper-cleaning and hyper-representation learning tasks demonstrate the efficiency of our algorithms.", "published": "2021-06-21T20:16:40Z", "version": 4}, {"aid": "2106.12423", "authors": ["Tero Karras", "Miika Aittala", "Samuli Laine", "Erik H\u00e4rk\u00f6nen", "Janne Hellsten", "Jaakko Lehtinen", "Timo Aila"], "title": "Alias-Free Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2106.12423v4", "summary": "We observe that despite their hierarchical convolutional nature, the synthesis process of typical generative adversarial networks depends on absolute pixel coordinates in an unhealthy manner. This manifests itself as, e.g., detail appearing to be glued to image coordinates instead of the surfaces of depicted objects. We trace the root cause to careless signal processing that causes aliasing in the generator network. Interpreting all signals in the network as continuous, we derive generally applicable, small architectural changes that guarantee that unwanted information cannot leak into the hierarchical synthesis process. The resulting networks match the FID of StyleGAN2 but differ dramatically in their internal representations, and they are fully equivariant to translation and rotation even at subpixel scales. Our results pave the way for generative models better suited for video and animation.", "published": "2021-06-23T14:20:01Z", "version": 4}, {"aid": "2106.13799", "authors": ["Yiding Jiang", "Vaishnavh Nagarajan", "Christina Baek", "J. Zico Kolter"], "title": "Assessing Generalization of SGD via Disagreement", "url": "http://arxiv.org/pdf/2106.13799v2", "summary": "We empirically show that the test error of deep networks can be estimated by simply training the same architecture on the same training set but with a different run of Stochastic Gradient Descent (SGD), and measuring the disagreement rate between the two networks on unlabeled test data. This builds on -- and is a stronger version of -- the observation in Nakkiran & Bansal '20, which requires the second run to be on an altogether fresh training set. We further theoretically show that this peculiar phenomenon arises from the \\emph{well-calibrated} nature of \\emph{ensembles} of SGD-trained models. This finding not only provides a simple empirical measure to directly predict the test error using unlabeled test data, but also establishes a new conceptual connection between generalization and calibration.", "published": "2021-06-25T17:53:09Z", "version": 2}, {"aid": "2106.14501", "authors": ["Jiang Hai", "Zhu Xuan", "Songchen Han", "Ren Yang", "Yutong Hao", "Fengzhu Zou", "Fang Lin"], "title": "R2RNet: Low-light Image Enhancement via Real-low to Real-normal Network", "url": "http://arxiv.org/pdf/2106.14501v2", "summary": "Images captured in weak illumination conditions could seriously degrade the image quality. Solving a series of degradation of low-light images can effectively improve the visual quality of images and the performance of high-level visual tasks. In this study, a novel Retinex-based Real-low to Real-normal Network (R2RNet) is proposed for low-light image enhancement, which includes three subnets: a Decom-Net, a Denoise-Net, and a Relight-Net. These three subnets are used for decomposing, denoising, contrast enhancement and detail preservation, respectively. Our R2RNet not only uses the spatial information of the image to improve the contrast but also uses the frequency information to preserve the details. Therefore, our model acheived more robust results for all degraded images. Unlike most previous methods that were trained on synthetic images, we collected the first Large-Scale Real-World paired low/normal-light images dataset (LSRW dataset) to satisfy the training requirements and make our model have better generalization performance in real-world scenes. Extensive experiments on publicly available datasets demonstrated that our method outperforms the existing state-of-the-art methods both quantitatively and visually. In addition, our results showed that the performance of the high-level visual task (i.e. face detection) can be effectively improved by using the enhanced results obtained by our method in low-light conditions. Our codes and the LSRW dataset are available at: https://github.com/abcdef2000/R2RNet.", "published": "2021-06-28T09:33:13Z", "version": 2}, {"aid": "2106.15419", "authors": ["Zhikang T. Wang", "Masahito Ueda"], "title": "Convergent and Efficient Deep Q Network Algorithm", "url": "http://arxiv.org/pdf/2106.15419v3", "summary": "Despite the empirical success of the deep Q network (DQN) reinforcement learning algorithm and its variants, DQN is still not well understood and it does not guarantee convergence. In this work, we show that DQN can indeed diverge and cease to operate in realistic settings. Although there exist gradient-based convergent methods, we show that they actually have inherent problems in learning dynamics which cause them to fail even in simple tasks. To overcome these problems, we propose a convergent DQN algorithm (C-DQN) that is guaranteed to converge and can work with large discount factors (0.9998). It learns robustly in difficult settings and can learn several difficult games in the Atari 2600 benchmark that DQN fails to solve. Our codes have been publicly released and can be used to reproduce our results.", "published": "2021-06-29T13:38:59Z", "version": 3}, {"aid": "2107.00627", "authors": ["Junqing Huang", "Haihui Wang", "Xuechao Wang", "Michael Ruzhansky"], "title": "Semi-Sparsity for Smoothing Filters", "url": "http://arxiv.org/pdf/2107.00627v3", "summary": "In this paper, we propose an interesting semi-sparsity smoothing algorithm based on a novel sparsity-inducing optimization framework. This method is derived from the multiple observations that semi-sparsity prior knowledge is more universally applicable, especially in areas where sparsity is not fully admitted, such as polynomial-smoothing surfaces. We illustrate that this semi-sparsity can be identified into a generalized $L_0$-norm minimization in higher-order gradient domains, thereby giving rise to a new \"feature-aware\" filtering method with a powerful simultaneous-fitting ability in both sparse features (singularities and sharpening edges) and non-sparse regions (polynomial-smoothing surfaces). Notice that a direct solver is always unavailable due to the non-convexity and combinatorial nature of $L_0$-norm minimization. Instead, we solve the model based on an efficient half-quadratic splitting minimization with fast Fourier transforms (FFTs) for acceleration. We finally demonstrate its versatility and many benefits to a series of signal/image processing and computer vision applications.", "published": "2021-07-01T17:31:42Z", "version": 3}, {"aid": "2107.04261", "authors": ["Jin Li", "Wanyun Li", "Zichen Xu", "Yuhao Wang", "Qiegen Liu"], "title": "Wavelet Transform-assisted Adaptive Generative Modeling for Colorization", "url": "http://arxiv.org/pdf/2107.04261v2", "summary": "Unsupervised deep learning has recently demonstrated the promise of producing high-quality samples. While it has tremendous potential to promote the image colorization task, the performance is limited owing to the high-dimension of data manifold and model capability. This study presents a novel scheme that exploits the score-based generative model in wavelet domain to address the issues. By taking advantage of the multi-scale and multi-channel representation via wavelet transform, the proposed model learns the richer priors from stacked coarse and detailed wavelet coefficient components jointly and effectively. This strategy also reduces the dimension of the original manifold and alleviates the curse of dimensionality, which is beneficial for estimation and sampling. Moreover, dual consistency terms in the wavelet domain, namely data-consistency and structure-consistency are devised to leverage colorization task better. Specifically, in the training phase, a set of multi-channel tensors consisting of wavelet coefficients is used as the input to train the network with denoising score matching. In the inference phase, samples are iteratively generated via annealed Langevin dynamics with data and structure consistencies. Experiments demonstrated remarkable improvements of the proposed method on both generation and colorization quality, particularly in colorization robustness and diversity.", "published": "2021-07-09T07:12:39Z", "version": 2}, {"aid": "2107.06154", "authors": ["Shuhao Cui", "Shuhui Wang", "Junbao Zhuo", "Liang Li", "Qingming Huang", "Qi Tian"], "title": "Fast Batch Nuclear-norm Maximization and Minimization for Robust Domain Adaptation", "url": "http://arxiv.org/pdf/2107.06154v4", "summary": "Due to the domain discrepancy in visual domain adaptation, the performance of source model degrades when bumping into the high data density near decision boundary in target domain. A common solution is to minimize the Shannon Entropy to push the decision boundary away from the high density area. However, entropy minimization also leads to severe reduction of prediction diversity, and unfortunately brings harm to the domain adaptation. In this paper, we investigate the prediction discriminability and diversity by studying the structure of the classification output matrix of a randomly selected data batch. We find by theoretical analysis that the prediction discriminability and diversity could be separately measured by the Frobenius-norm and rank of the batch output matrix. The nuclear-norm is an upperbound of the former, and a convex approximation of the latter. Accordingly, we propose Batch Nuclear-norm Maximization and Minimization, which performs nuclear-norm maximization on the target output matrix to enhance the target prediction ability, and nuclear-norm minimization on the source batch output matrix to increase applicability of the source domain knowledge. We further approximate the nuclear-norm by L_{1,2}-norm, and design multi-batch optimization for stable solution on large number of categories. The fast approximation method achieves O(n^2) computational complexity and better convergence property. Experiments show that our method could boost the adaptation accuracy and robustness under three typical domain adaptation scenarios. The code is available at https://github.com/cuishuhao/BNM.", "published": "2021-07-13T15:08:32Z", "version": 4}, {"aid": "2107.07110", "authors": ["Jiayun Wang", "Yubei Chen", "Stella X. Yu", "Brian Cheung", "Yann LeCun"], "title": "Compact and Optimal Deep Learning with Recurrent Parameter Generators", "url": "http://arxiv.org/pdf/2107.07110v3", "summary": "Deep learning has achieved tremendous success by training increasingly large models, which are then compressed for practical deployment. We propose a drastically different approach to compact and optimal deep learning: We decouple the Degrees of freedom (DoF) and the actual number of parameters of a model, optimize a small DoF with predefined random linear constraints for a large model of arbitrary architecture, in one-stage end-to-end learning. Specifically, we create a recurrent parameter generator (RPG), which repeatedly fetches parameters from a ring and unpacks them onto a large model with random permutation and sign flipping to promote parameter decorrelation. We show that gradient descent can automatically find the best model under constraints with faster convergence. Our extensive experimentation reveals a log-linear relationship between model DoF and accuracy. Our RPG demonstrates remarkable DoF reduction and can be further pruned and quantized for additional run-time performance gain. For example, in terms of top-1 accuracy on ImageNet, RPG achieves $96\\%$ of ResNet18's performance with only $18\\%$ DoF (the equivalent of one convolutional layer) and $52\\%$ of ResNet34's performance with only $0.25\\%$ DoF! Our work shows a significant potential of constrained neural optimization in compact and optimal deep learning.", "published": "2021-07-15T04:23:59Z", "version": 3}, {"aid": "2107.08430", "authors": ["Zheng Ge", "Songtao Liu", "Feng Wang", "Zeming Li", "Jian Sun"], "title": "YOLOX: Exceeding YOLO Series in 2021", "url": "http://arxiv.org/pdf/2107.08430v2", "summary": "In this report, we present some experienced improvements to YOLO series, forming a new high-performance detector -- YOLOX. We switch the YOLO detector to an anchor-free manner and conduct other advanced detection techniques, i.e., a decoupled head and the leading label assignment strategy SimOTA to achieve state-of-the-art results across a large scale range of models: For YOLO-Nano with only 0.91M parameters and 1.08G FLOPs, we get 25.3% AP on COCO, surpassing NanoDet by 1.8% AP; for YOLOv3, one of the most widely used detectors in industry, we boost it to 47.3% AP on COCO, outperforming the current best practice by 3.0% AP; for YOLOX-L with roughly the same amount of parameters as YOLOv4-CSP, YOLOv5-L, we achieve 50.0% AP on COCO at a speed of 68.9 FPS on Tesla V100, exceeding YOLOv5-L by 1.8% AP. Further, we won the 1st Place on Streaming Perception Challenge (Workshop on Autonomous Driving at CVPR 2021) using a single YOLOX-L model. We hope this report can provide useful experience for developers and researchers in practical scenes, and we also provide deploy versions with ONNX, TensorRT, NCNN, and Openvino supported. Source code is at https://github.com/Megvii-BaseDetection/YOLOX.", "published": "2021-07-18T12:55:11Z", "version": 2}, {"aid": "2107.12026", "authors": ["Eneko Uru\u00f1uela", "Thomas A. W. Bolton", "Dimitri Van De Ville", "C\u00e9sar Caballero-Gaudes"], "title": "Hemodynamic Deconvolution Demystified: Sparsity-Driven Regularization at Work", "url": "http://arxiv.org/pdf/2107.12026v4", "summary": "Deconvolution of the hemodynamic response is an important step to access short timescales of brain activity recorded by functional magnetic resonance imaging (fMRI). Albeit conventional deconvolution algorithms have been around for a long time (e.g., Wiener deconvolution), recent state-of-the-art methods based on sparsity-pursuing regularization are attracting increasing interest to investigate brain dynamics and connectivity with fMRI. This technical note revisits the main concepts underlying two main methods, Paradigm Free Mapping and Total Activation, in the most accessible way. Despite their apparent differences in the formulation, these methods are theoretically equivalent as they represent the synthesis and analysis sides of the same problem, respectively. We demonstrate this equivalence in practice with their best-available implementations using both simulations, with different signal-to-noise ratios, and experimental fMRI data acquired during a motor task and resting-state. We evaluate the parameter settings that lead to equivalent results, and showcase the potential of these algorithms compared to other common approaches. This note is useful for practitioners interested in gaining a better understanding of state-of-the-art hemodynamic deconvolution, and aims to answer questions that practitioners often have regarding the differences between the two methods.", "published": "2021-07-26T08:30:18Z", "version": 4}, {"aid": "2107.12028", "authors": ["Jiequan Cui", "Zhisheng Zhong", "Shu Liu", "Bei Yu", "Jiaya Jia"], "title": "Parametric Contrastive Learning", "url": "http://arxiv.org/pdf/2107.12028v2", "summary": "In this paper, we propose Parametric Contrastive Learning (PaCo) to tackle long-tailed recognition. Based on theoretical analysis, we observe supervised contrastive loss tends to bias on high-frequency classes and thus increases the difficulty of imbalanced learning. We introduce a set of parametric class-wise learnable centers to rebalance from an optimization perspective. Further, we analyze our PaCo loss under a balanced setting. Our analysis demonstrates that PaCo can adaptively enhance the intensity of pushing samples of the same class close as more samples are pulled together with their corresponding centers and benefit hard example learning. Experiments on long-tailed CIFAR, ImageNet, Places, and iNaturalist 2018 manifest the new state-of-the-art for long-tailed recognition. On full ImageNet, models trained with PaCo loss surpass supervised contrastive learning across various ResNet backbones, e.g., our ResNet-200 achieves 81.8% top-1 accuracy. Our code is available at https://github.com/dvlab-research/Parametric-Contrastive-Learning.", "published": "2021-07-26T08:37:23Z", "version": 2}, {"aid": "2107.12979", "authors": ["Beren Millidge", "Anil Seth", "Christopher L Buckley"], "title": "Predictive Coding: a Theoretical and Experimental Review", "url": "http://arxiv.org/pdf/2107.12979v4", "summary": "Predictive coding offers a potentially unifying account of cortical function -- postulating that the core function of the brain is to minimize prediction errors with respect to a generative model of the world. The theory is closely related to the Bayesian brain framework and, over the last two decades, has gained substantial influence in the fields of theoretical and cognitive neuroscience. A large body of research has arisen based on both empirically testing improved and extended theoretical and mathematical models of predictive coding, as well as in evaluating their potential biological plausibility for implementation in the brain and the concrete neurophysiological and psychological predictions made by the theory. Despite this enduring popularity, however, no comprehensive review of predictive coding theory, and especially of recent developments in this field, exists. Here, we provide a comprehensive review both of the core mathematical structure and logic of predictive coding, thus complementing recent tutorials in the literature. We also review a wide range of classic and recent work within the framework, ranging from the neurobiologically realistic microcircuits that could implement predictive coding, to the close relationship between predictive coding and the widely-used backpropagation of error algorithm, as well as surveying the close relationships between predictive coding and modern machine learning techniques.", "published": "2021-07-27T17:44:21Z", "version": 4}, {"aid": "2107.13473", "authors": ["Nicolas Valenchon", "Yann Bouteiller", "Hugo R. Jourde", "Xavier L'Heureux", "Milo Sobral", "Emily B. J. Coffey", "Giovanni Beltrame"], "title": "The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation", "url": "http://arxiv.org/pdf/2107.13473v3", "summary": "Closed-loop brain stimulation refers to capturing neurophysiological measures such as electroencephalography (EEG), quickly identifying neural events of interest, and producing auditory, magnetic or electrical stimulation so as to interact with brain processes precisely. It is a promising new method for fundamental neuroscience and perhaps for clinical applications such as restoring degraded memory function; however, existing tools are expensive, cumbersome, and offer limited experimental flexibility. In this article, we propose the Portiloop, a deep learning-based, portable and low-cost closed-loop stimulation system able to target specific brain oscillations. We first document open-hardware implementations that can be constructed from commercially available components. We also provide a fast, lightweight neural network model and an exploration algorithm that automatically optimizes the model hyperparameters to the desired brain oscillation. Finally, we validate the technology on a challenging test case of real-time sleep spindle detection, with results comparable to off-line expert performance on the Massive Online Data Annotation spindle dataset (MODA; group consensus). Software and plans are available to the community as an open science initiative to encourage further development and advance closed-loop neuroscience research.", "published": "2021-07-28T16:29:58Z", "version": 3}, {"aid": "2107.13704", "authors": ["Lenore Blum", "Manuel Blum"], "title": "A Theory of Consciousness from a Theoretical Computer Science Perspective: Insights from the Conscious Turing Machine", "url": "http://arxiv.org/pdf/2107.13704v10", "summary": "The quest to understand consciousness, once the purview of philosophers and theologians, is now actively pursued by scientists of many stripes. We examine consciousness from the perspective of theoretical computer science (TCS), a branch of mathematics concerned with understanding the underlying principles of computation and complexity, including the implications and surprising consequences of resource limitations. In the spirit of Alan Turing's simple yet powerful definition of a computer, the Turing Machine (TM), and perspective of computational complexity theory, we formalize a modified version of the Global Workspace Theory (GWT) of consciousness originated by cognitive neuroscientist Bernard Baars and further developed by him, Stanislas Dehaene, Jean-Pierre Changeaux and others. We are not looking for a complex model of the brain nor of cognition, but for a simple computational model of (the admittedly complex concept of) consciousness. We do this by defining the Conscious Turing Machine (CTM), also called a conscious AI, and then we define consciousness and related notions in the CTM. While these are only mathematical (TCS) definitions, we suggest why the CTM has the feeling of consciousness. The TCS perspective provides a simple formal framework to employ tools from computational complexity theory and machine learning to help us understand consciousness and related concepts. Previously we explored high level explanations for the feelings of pain and pleasure in the CTM. Here we consider three examples related to vision (blindsight, inattentional blindness, and change blindness), followed by discussions of dreams, free will, and altered states of consciousness.", "published": "2021-07-29T01:47:52Z", "version": 10}, {"aid": "2108.00298", "authors": ["Andrea Cini", "Ivan Marisca", "Cesare Alippi"], "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks", "url": "http://arxiv.org/pdf/2108.00298v3", "summary": "Dealing with missing values and incomplete time series is a labor-intensive, tedious, inevitable task when handling data coming from real-world applications. Effective spatio-temporal representations would allow imputation methods to reconstruct missing temporal data by exploiting information coming from sensors at different locations. However, standard methods fall short in capturing the nonlinear time and space dependencies existing within networks of interconnected sensors and do not take full advantage of the available - and often strong - relational information. Notably, most state-of-the-art imputation methods based on deep learning do not explicitly model relational aspects and, in any case, do not exploit processing frameworks able to adequately represent structured spatio-temporal data. Conversely, graph neural networks have recently surged in popularity as both expressive and scalable tools for processing sequential data with relational inductive biases. In this work, we present the first assessment of graph neural networks in the context of multivariate time series imputation. In particular, we introduce a novel graph neural network architecture, named GRIN, which aims at reconstructing missing data in the different channels of a multivariate time series by learning spatio-temporal representations through message passing. Empirical results show that our model outperforms state-of-the-art methods in the imputation task on relevant real-world benchmarks with mean absolute error improvements often higher than 20%.", "published": "2021-07-31T17:47:10Z", "version": 3}, {"aid": "2108.00996", "authors": ["Pedro C. Neto", "Fadi Boutros", "Jo\u00e3o Ribeiro Pinto", "Mohsen Saffari", "Naser Damer", "Ana F. Sequeira", "Jaime S. Cardoso"], "title": "My Eyes Are Up Here: Promoting Focus on Uncovered Regions in Masked Face Recognition", "url": "http://arxiv.org/pdf/2108.00996v3", "summary": "The recent Covid-19 pandemic and the fact that wearing masks in public is now mandatory in several countries, created challenges in the use of face recognition systems (FRS). In this work, we address the challenge of masked face recognition (MFR) and focus on evaluating the verification performance in FRS when verifying masked vs unmasked faces compared to verifying only unmasked faces. We propose a methodology that combines the traditional triplet loss and the mean squared error (MSE) intending to improve the robustness of an MFR system in the masked-unmasked comparison mode. The results obtained by our proposed method show improvements in a detailed step-wise ablation study. The conducted study showed significant performance gains induced by our proposed training paradigm and modified triplet loss on two evaluation databases.", "published": "2021-08-02T15:51:15Z", "version": 3}, {"aid": "2108.01073", "authors": ["Chenlin Meng", "Yutong He", "Yang Song", "Jiaming Song", "Jiajun Wu", "Jun-Yan Zhu", "Stefano Ermon"], "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations", "url": "http://arxiv.org/pdf/2108.01073v2", "summary": "Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user input (e.g., hand-drawn colored strokes) and realism of the synthesized image. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide of any type, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit significantly outperforms state-of-the-art GAN-based methods by up to 98.09% on realism and 91.72% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing.", "published": "2021-08-02T17:59:47Z", "version": 2}, {"aid": "2109.01594", "authors": ["Serkan Kiranyaz", "Junaid Malik", "Mehmet Yamac", "Mert Duman", "Ilke Adalioglu", "Esin Guldogan", "Turker Ince", "Moncef Gabbouj"], "title": "Super Neurons", "url": "http://arxiv.org/pdf/2109.01594v2", "summary": "Self-Organized Operational Neural Networks (Self-ONNs) have recently been proposed as new-generation neural network models with nonlinear learning units, i.e., the generative neurons that yield an elegant level of diversity; however, like its predecessor, conventional Convolutional Neural Networks (CNNs), they still have a common drawback: localized (fixed) kernel operations. This severely limits the receptive field and information flow between layers and thus brings the necessity for deep and complex models. It is highly desired to improve the receptive field size without increasing the kernel dimensions. This requires a significant upgrade over the generative neurons to achieve the non-localized kernel operations for each connection between consecutive layers. In this article, we present superior (generative) neuron models (or super neurons in short) that allow random or learnable kernel shifts and thus can increase the receptive field size of each connection. The kernel localization process varies among the two super-neuron models. The first model assumes randomly localized kernels within a range and the second one learns (optimizes) the kernel locations during training. An extensive set of comparative evaluations against conventional and deformable convolutional, along with the generative neurons demonstrates that super neurons can empower Self-ONNs to achieve a superior learning and generalization capability with a minimal computational complexity burden.", "published": "2021-08-03T16:17:45Z", "version": 2}, {"aid": "2108.02110", "authors": ["Minyi Zhao", "Yi Xu", "Shuigeng Zhou"], "title": "Recursive Fusion and Deformable Spatiotemporal Attention for Video Compression Artifact Reduction", "url": "http://arxiv.org/pdf/2108.02110v2", "summary": "A number of deep learning based algorithms have been proposed to recover high-quality videos from low-quality compressed ones. Among them, some restore the missing details of each frame via exploring the spatiotemporal information of neighboring frames. However, these methods usually suffer from a narrow temporal scope, thus may miss some useful details from some frames outside the neighboring ones. In this paper, to boost artifact removal, on the one hand, we propose a Recursive Fusion (RF) module to model the temporal dependency within a long temporal range. Specifically, RF utilizes both the current reference frames and the preceding hidden state to conduct better spatiotemporal compensation. On the other hand, we design an efficient and effective Deformable Spatiotemporal Attention (DSTA) module such that the model can pay more effort on restoring the artifact-rich areas like the boundary area of a moving object. Extensive experiments show that our method outperforms the existing ones on the MFQE 2.0 dataset in terms of both fidelity and perceptual effect. Code is available at https://github.com/zhaominyiz/RFDA-PyTorch.", "published": "2021-08-04T15:25:27Z", "version": 2}, {"aid": "2108.02451", "authors": ["Lei Zhu", "Qi She", "Duo Li", "Yanye Lu", "Xuejing Kang", "Jie Hu", "Changhu Wang"], "title": "Unifying Nonlocal Blocks for Neural Networks", "url": "http://arxiv.org/pdf/2108.02451v3", "summary": "The nonlocal-based blocks are designed for capturing long-range spatial-temporal dependencies in computer vision tasks. Although having shown excellent performance, they still lack the mechanism to encode the rich, structured information among elements in an image or video. In this paper, to theoretically analyze the property of these nonlocal-based blocks, we provide a new perspective to interpret them, where we view them as a set of graph filters generated on a fully-connected graph. Specifically, when choosing the Chebyshev graph filter, a unified formulation can be derived for explaining and analyzing the existing nonlocal-based blocks (e.g., nonlocal block, nonlocal stage, double attention block). Furthermore, by concerning the property of spectral, we propose an efficient and robust spectral nonlocal block, which can be more robust and flexible to catch long-range dependencies when inserted into deep neural networks than the existing nonlocal blocks. Experimental results demonstrate the clear-cut improvements and practical applicabilities of our method on image classification, action recognition, semantic segmentation, and person re-identification tasks.", "published": "2021-08-05T08:34:12Z", "version": 3}, {"aid": "2108.02456", "authors": ["Ke Zhu", "Jianxin Wu"], "title": "Residual Attention: A Simple but Effective Method for Multi-Label Recognition", "url": "http://arxiv.org/pdf/2108.02456v2", "summary": "Multi-label image recognition is a challenging computer vision task of practical use. Progresses in this area, however, are often characterized by complicated methods, heavy computations, and lack of intuitive explanations. To effectively capture different spatial regions occupied by objects from different categories, we propose an embarrassingly simple module, named class-specific residual attention (CSRA). CSRA generates class-specific features for every category by proposing a simple spatial attention score, and then combines it with the class-agnostic average pooling feature. CSRA achieves state-of-the-art results on multilabel recognition, and at the same time is much simpler than them. Furthermore, with only 4 lines of code, CSRA also leads to consistent improvement across many diverse pretrained models and datasets without any extra training. CSRA is both easy to implement and light in computations, which also enjoys intuitive explanations and visualizations.", "published": "2021-08-05T08:45:57Z", "version": 2}, {"aid": "2108.06396", "authors": ["Eric Sanchis"], "title": "Free Will: A New Formulation", "url": "http://arxiv.org/pdf/2108.06396v1", "summary": "Free will is sometimes summarised in the philosophical literature as the subjective impression felt by an individual that he or she is the ultimate source or cause of his or her own choices. The two most common arguments for denying the existence of free will come from philosophy and neuroscience. The first argument is the Consequence Argument. The second asserts that our decisions are first made by the brain and only then become conscious to the subject, taking away the control of the decision. The purpose of these two arguments is to demonstrate that an individual cannot be the source or primary cause of his or her choices. It is shown in this work that the concepts of primary cause and primary source are not adequate to state a solid characterisation of free will. A new formulation of this property is proposed in which it is seen as a three-stage decision-making process implemented by an individual to escape his or her own real or supposed alienation. This decision-making process is represented in the form of a computer model called the PSU (Predictability - Suspension - Unpredictability) model. The compatibility of this new formulation of free will with the feeling it provides and the analysis of various situations are then discussed.", "published": "2021-08-05T16:12:24Z", "version": 1}, {"aid": "2108.02874", "authors": ["Sen He", "Wentong Liao", "Michael Ying Yang", "Yi-Zhe Song", "Bodo Rosenhahn", "Tao Xiang"], "title": "Disentangled Lifespan Face Synthesis", "url": "http://arxiv.org/pdf/2108.02874v2", "summary": "A lifespan face synthesis (LFS) model aims to generate a set of photo-realistic face images of a person's whole life, given only one snapshot as reference. The generated face image given a target age code is expected to be age-sensitive reflected by bio-plausible transformations of shape and texture, while being identity preserving. This is extremely challenging because the shape and texture characteristics of a face undergo separate and highly nonlinear transformations w.r.t. age. Most recent LFS models are based on generative adversarial networks (GANs) whereby age code conditional transformations are applied to a latent face representation. They benefit greatly from the recent advancements of GANs. However, without explicitly disentangling their latent representations into the texture, shape and identity factors, they are fundamentally limited in modeling the nonlinear age-related transformation on texture and shape whilst preserving identity. In this work, a novel LFS model is proposed to disentangle the key face characteristics including shape, texture and identity so that the unique shape and texture age transformations can be modeled effectively. This is achieved by extracting shape, texture and identity features separately from an encoder. Critically, two transformation modules, one conditional convolution based and the other channel attention based, are designed for modeling the nonlinear shape and texture feature transformations respectively. This is to accommodate their rather distinct aging processes and ensure that our synthesized images are both age-sensitive and identity preserving. Extensive experiments show that our LFS model is clearly superior to the state-of-the-art alternatives. Codes and demo are available on our project website: \\url{https://senhe.github.io/projects/iccv_2021_lifespan_face}.", "published": "2021-08-05T22:33:14Z", "version": 2}, {"aid": "2108.02924", "authors": ["Xuejiao Tang", "Wenbin Zhang", "Yi Yu", "Kea Turner", "Tyler Derr", "Mengyu Wang", "Eirini Ntoutsi"], "title": "Interpretable Visual Understanding with Cognitive Attention Network", "url": "http://arxiv.org/pdf/2108.02924v3", "summary": "While image understanding on recognition-level has achieved remarkable advancements, reliable visual scene understanding requires comprehensive image understanding on recognition-level but also cognition-level, which calls for exploiting the multi-source information as well as learning different levels of understanding and extensive commonsense knowledge. In this paper, we propose a novel Cognitive Attention Network (CAN) for visual commonsense reasoning to achieve interpretable visual understanding. Specifically, we first introduce an image-text fusion module to fuse information from images and text collectively. Second, a novel inference module is designed to encode commonsense among image, query and response. Extensive experiments on large-scale Visual Commonsense Reasoning (VCR) benchmark dataset demonstrate the effectiveness of our approach. The implementation is publicly available at https://github.com/tanjatang/CAN", "published": "2021-08-06T02:57:43Z", "version": 3}, {"aid": "2108.03002", "authors": ["Hongbing Zhang", "Xinyi Liu", "Hongtao Fan", "Yajing Li", "Yinlin Ye"], "title": "Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm", "url": "http://arxiv.org/pdf/2108.03002v4", "summary": "The low rank tensor completion (LRTC) problem has attracted great attention in computer vision and signal processing. How to acquire high quality image recovery effect is still an urgent task to be solved at present. This paper proposes a new tensor $L_{2,1}$ norm minimization model (TLNM) that integrates sum nuclear norm (SNN) method, differing from the classical tensor nuclear norm (TNN)-based tensor completion method, with $L_{2,1}$ norm and Qatar Riyal decomposition for solving the LRTC problem. To improve the utilization rate of the local prior information of the image, a total variation (TV) regularization term is introduced, resulting in a new class of tensor $L_{2,1}$ norm minimization with total variation model (TLNMTV). Both proposed models are convex and therefore have global optimal solutions. Moreover, we adopt the Alternating Direction Multiplier Method (ADMM) to obtain the closed-form solution of each variable, thus ensuring the feasibility of the algorithm. Numerical experiments show that the two proposed algorithms are convergent and outperform compared methods. In particular, our method significantly outperforms the contrastive methods when the sampling rate of hyperspectral images is 2.5\\%.", "published": "2021-08-06T08:35:33Z", "version": 4}, {"aid": "2108.05713", "authors": ["Shu Ishida", "Jo\u00e3o F. Henriques"], "title": "Towards real-world navigation with deep differentiable planners", "url": "http://arxiv.org/pdf/2108.05713v2", "summary": "We train embodied neural networks to plan and navigate unseen complex 3D environments, emphasising real-world deployment. Rather than requiring prior knowledge of the agent or environment, the planner learns to model the state transitions and rewards. To avoid the potentially hazardous trial-and-error of reinforcement learning, we focus on differentiable planners such as Value Iteration Networks (VIN), which are trained offline from safe expert demonstrations. Although they work well in small simulations, we address two major limitations that hinder their deployment. First, we observed that current differentiable planners struggle to plan long-term in environments with a high branching complexity. While they should ideally learn to assign low rewards to obstacles to avoid collisions, we posit that the constraints imposed on the network are not strong enough to guarantee the network to learn sufficiently large penalties for every possible collision. We thus impose a structural constraint on the value iteration, which explicitly learns to model any impossible actions. Secondly, we extend the model to work with a limited perspective camera under translation and rotation, which is crucial for real robot deployment. Many VIN-like planners assume a 360 degrees or overhead view without rotation. In contrast, our method uses a memory-efficient lattice map to aggregate CNN embeddings of partial observations, and models the rotational dynamics explicitly using a 3D state-space grid (translation and rotation). Our proposals significantly improve semantic navigation and exploration on several 2D and 3D environments, succeeding in settings that are otherwise challenging for this class of methods. As far as we know, we are the first to successfully perform differentiable planning on the difficult Active Vision Dataset, consisting of real images captured from a robot.", "published": "2021-08-08T11:29:16Z", "version": 2}, {"aid": "2108.03830", "authors": ["Kun Wang", "Zhenyu Zhang", "Zhiqiang Yan", "Xiang Li", "Baobei Xu", "Jun Li", "Jian Yang"], "title": "Regularizing Nighttime Weirdness: Efficient Self-supervised Monocular Depth Estimation in the Dark", "url": "http://arxiv.org/pdf/2108.03830v2", "summary": "Monocular depth estimation aims at predicting depth from a single image or video. Recently, self-supervised methods draw much attention since they are free of depth annotations and achieve impressive performance on several daytime benchmarks. However, they produce weird outputs in more challenging nighttime scenarios because of low visibility and varying illuminations, which bring weak textures and break brightness-consistency assumption, respectively. To address these problems, in this paper we propose a novel framework with several improvements: (1) we introduce Priors-Based Regularization to learn distribution knowledge from unpaired depth maps and prevent model from being incorrectly trained; (2) we leverage Mapping-Consistent Image Enhancement module to enhance image visibility and contrast while maintaining brightness consistency; and (3) we present Statistics-Based Mask strategy to tune the number of removed pixels within textureless regions, using dynamic statistics. Experimental results demonstrate the effectiveness of each component. Meanwhile, our framework achieves remarkable improvements and state-of-the-art results on two nighttime datasets.", "published": "2021-08-09T06:24:35Z", "version": 2}, {"aid": "2108.04316", "authors": ["Ricardo Andres Diaz Rincon"], "title": "Generating Music and Generative Art from Brain activity", "url": "http://arxiv.org/pdf/2108.04316v2", "summary": "Nowadays, technological advances have influenced all human activities, creating new dynamics and ways of communication. In this context, some artists have incorporated these advances in their creative process, giving rise to unique aesthetic expressions referred to in the literature as Generative Art, which is characterized by assigning part of the creative process to a system that acts with certain autonomy (Galanter, 2003).   This research work introduces a computational system for creating generative art using a Brain-Computer Interface (BCI) which portrays the user's brain activity in a digital artwork. In this way, the user takes an active role in the creative process. In aims of showing that the proposed system materializes in an artistic piece the user's mental states by means of a visual and sound representation, several tests are carried out to ensure the reliability of the BCI device sent data.   The generated artwork uses brain signals and concepts of geometry, color and spatial location to give complexity to the autonomous construction. As an added value, the visual and auditory production is accompanied by an olfactory and kinesthetic component which complements the art pieces providing a multimodal communication character.", "published": "2021-08-09T19:33:45Z", "version": 2}, {"aid": "2108.04526", "authors": ["Qingpeng Cai", "Can Cui", "Yiyuan Xiong", "Wei Wang", "Zhongle Xie", "Meihui Zhang"], "title": "A Survey on Deep Reinforcement Learning for Data Processing and Analytics", "url": "http://arxiv.org/pdf/2108.04526v3", "summary": "Data processing and analytics are fundamental and pervasive. Algorithms play a vital role in data processing and analytics where many algorithm designs have incorporated heuristics and general rules from human knowledge and experience to improve their effectiveness. Recently, reinforcement learning, deep reinforcement learning (DRL) in particular, is increasingly explored and exploited in many areas because it can learn better strategies in complicated environments it is interacting with than statically designed algorithms. Motivated by this trend, we provide a comprehensive review of recent works focusing on utilizing DRL to improve data processing and analytics. First, we present an introduction to key concepts, theories, and methods in DRL. Next, we discuss DRL deployment on database systems, facilitating data processing and analytics in various aspects, including data organization, scheduling, tuning, and indexing. Then, we survey the application of DRL in data processing and analytics, ranging from data preparation, natural language processing to healthcare, fintech, etc. Finally, we discuss important open challenges and future research directions of using DRL in data processing and analytics.", "published": "2021-08-10T09:14:03Z", "version": 3}, {"aid": "2108.04893", "authors": ["Mahdi Pourmirzaei", "Farzaneh Esmaili", "Ebrahim Mousavi", "Sasan Karamizadeh", "Seyedehsamaneh Shojaeilangari"], "title": "How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?", "url": "http://arxiv.org/pdf/2108.04893v6", "summary": "The cost of head pose labeling is the main challenge of improving the fine-grained Head Pose Estimation (HPE). Although Self-Supervised Learning (SSL) can be a solution to the lack of huge amounts of labeled data, its efficacy for fine-grained HPE is not yet fully explored. This study aims to assess the usage of SSL in fine-grained HPE based on two scenarios: (1) using SSL for weights pre-training procedure, and (2) leveraging auxiliary SSL losses besides HPE. We design a Hybrid Multi-Task Learning (HMTL) architecture based on the ResNet50 backbone in which both strategies are applied. Our experimental results reveal that the combination of both scenarios is the best for HPE. Together, the average error rate is reduced up to 23.1% for AFLW2000 and 14.2% for BIWI benchmark compared to the baseline. Moreover, it is found that some SSL methods are more suitable for transfer learning, while others may be effective when they are considered as auxiliary tasks incorporated into supervised learning. Finally, it is shown that by using the proposed HMTL architecture, the average error is reduced with different types of initial weights: random, ImageNet and SSL pre-trained weights.", "published": "2021-08-10T19:34:45Z", "version": 6}, {"aid": "2108.04936", "authors": ["James V Stone"], "title": "Using Information Theory to Measure Psychophysical Performance", "url": "http://arxiv.org/pdf/2108.04936v3", "summary": "Most psychophysical experiments discard half the data collected. Specifically, experiments discard reaction time data, and use binary responses (e.g. yes/no) to measure performance. Here, Shannon's information theory is used to define Shannon competence $s'$, which depends on the mutual information between stimulus strength (e.g. luminance) and a combination of reaction times and binary responses. Mutual information is the entropy of the joint distribution of responses minus the residual entropy after a model has been fitted to these responses. Here, this model is instantiated as a proportional rate diffusion model, with the additional innovation that the full covariance structure of responses is taken into account. Results suggest information associated with reaction times is independent of (i.e. additional to) information associated with binary responses, and that reaction time and binary responses together provide substantially more than the sum of their individual contributions (i.e. they act synergistically). Consequently, the additional information supplied by reaction times suggests that using combined reaction time and binary responses requires fewer stimulus presentations, without loss of precision in psychophysical parameters. Finally, because s' takes account of both reaction time and binary responses, (and in contrast to d') $s'$ is immune to speed-accuracy trade-offs, which vary between observers and experimental designs.", "published": "2021-08-10T21:47:57Z", "version": 3}, {"aid": "2108.05061", "authors": ["Guangyi Xiao", "Weiwei Xiang", "Huan Liu", "Hao Chen", "Shun Peng", "Jingzhi Guo", "Zhiguo Gong"], "title": "NI-UDA: Graph Adversarial Domain Adaptation from Non-shared-and-Imbalanced Big Data to Small Imbalanced Applications", "url": "http://arxiv.org/pdf/2108.05061v2", "summary": "We propose a new general Graph Adversarial Domain Adaptation (GADA) based on semantic knowledge reasoning of class structure for solving the problem of unsupervised domain adaptation (UDA) from the big data with non-shared and imbalanced classes to specified small and imbalanced applications (NI-UDA), where non-shared classes mean the label space out of the target domain. Our goal is to leverage priori hierarchy knowledge to enhance domain adversarial aligned feature representation with graph reasoning. In this paper, to address two challenges in NI-UDA, we equip adversarial domain adaptation with Hierarchy Graph Reasoning (HGR) layer and the Source Classifier Filter (SCF). For sparse classes transfer challenge, our HGR layer can aggregate local feature to hierarchy graph nodes by node prediction and enhance domain adversarial aligned feature with hierarchy graph reasoning for sparse classes. Our HGR contributes to learn direct semantic patterns for sparse classes by hierarchy attention in self-attention, non-linear mapping and graph normalization. our SCF is proposed for the challenge of knowledge sharing from non-shared data without negative transfer effect by filtering low-confidence non-shared data in HGR layer. Experiments on two benchmark datasets show our GADA methods consistently improve the state-of-the-art adversarial UDA algorithms, e.g. GADA(HGR) can greatly improve f1 of the MDD by \\textbf{7.19\\%} and GVB-GD by \\textbf{7.89\\%} respectively on imbalanced source task in Meal300 dataset. The code is available at https://gadatransfer.wixsite.com/gada.", "published": "2021-08-11T07:01:13Z", "version": 2}, {"aid": "2108.05080", "authors": ["Hasam Khalid", "Shahroz Tariq", "Minha Kim", "Simon S. Woo"], "title": "FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset", "url": "http://arxiv.org/pdf/2108.05080v4", "summary": "While the significant advancements have made in the generation of deepfakes using deep learning technologies, its misuse is a well-known issue now. Deepfakes can cause severe security and privacy issues as they can be used to impersonate a person's identity in a video by replacing his/her face with another person's face. Recently, a new problem of generating synthesized human voice of a person is emerging, where AI-based deep learning models can synthesize any person's voice requiring just a few seconds of audio. With the emerging threat of impersonation attacks using deepfake audios and videos, a new generation of deepfake detectors is needed to focus on both video and audio collectively. To develop a competent deepfake detector, a large amount of high-quality data is typically required to capture real-world (or practical) scenarios. Existing deepfake datasets either contain deepfake videos or audios, which are racially biased as well. As a result, it is critical to develop a high-quality video and audio deepfake dataset that can be used to detect both audio and video deepfakes simultaneously. To fill this gap, we propose a novel Audio-Video Deepfake dataset, FakeAVCeleb, which contains not only deepfake videos but also respective synthesized lip-synced fake audios. We generate this dataset using the most popular deepfake generation methods. We selected real YouTube videos of celebrities with four ethnic backgrounds to develop a more realistic multimodal dataset that addresses racial bias, and further help develop multimodal deepfake detectors. We performed several experiments using state-of-the-art detection methods to evaluate our deepfake dataset and demonstrate the challenges and usefulness of our multimodal Audio-Video deepfake dataset.", "published": "2021-08-11T07:49:36Z", "version": 4}, {"aid": "2108.05278", "authors": ["Xin Mao", "Wenting Wang", "Yuanbin Wu", "Man Lan"], "title": "Are Negative Samples Necessary in Entity Alignment? An Approach with High Performance, Scalability and Robustness", "url": "http://arxiv.org/pdf/2108.05278v2", "summary": "Entity alignment (EA) aims to find the equivalent entities in different KGs, which is a crucial step in integrating multiple KGs. However, most existing EA methods have poor scalability and are unable to cope with large-scale datasets. We summarize three issues leading to such high time-space complexity in existing EA methods: (1) Inefficient graph encoders, (2) Dilemma of negative sampling, and (3) \"Catastrophic forgetting\" in semi-supervised learning. To address these challenges, we propose a novel EA method with three new components to enable high Performance, high Scalability, and high Robustness (PSR): (1) Simplified graph encoder with relational graph sampling, (2) Symmetric negative-free alignment loss, and (3) Incremental semi-supervised learning. Furthermore, we conduct detailed experiments on several public datasets to examine the effectiveness and efficiency of our proposed method. The experimental results show that PSR not only surpasses the previous SOTA in performance but also has impressive scalability and robustness.", "published": "2021-08-11T15:20:41Z", "version": 2}, {"aid": "2108.05305", "authors": ["Hong-Yu Zhou", "Chixiang Lu", "Sibei Yang", "Yizhou Yu"], "title": "ConvNets vs. Transformers: Whose Visual Representations are More Transferable?", "url": "http://arxiv.org/pdf/2108.05305v2", "summary": "Vision transformers have attracted much attention from computer vision researchers as they are not restricted to the spatial inductive bias of ConvNets. However, although Transformer-based backbones have achieved much progress on ImageNet classification, it is still unclear whether the learned representations are as transferable as or even more transferable than ConvNets' features. To address this point, we systematically investigate the transfer learning ability of ConvNets and vision transformers in 15 single-task and multi-task performance evaluations. Given the strong correlation between the performance of pre-trained models and transfer learning, we include 2 residual ConvNets (i.e., R-101x3 and R-152x4) and 3 Transformer-based visual backbones (i.e., ViT-B, ViT-L and Swin-B), which have close error rates on ImageNet, that indicate similar transfer learning performance on downstream datasets.   We observe consistent advantages of Transformer-based backbones on 13 downstream tasks (out of 15), including but not limited to fine-grained classification, scene recognition (classification, segmentation and depth estimation), open-domain classification, face recognition, etc. More specifically, we find that two ViT models heavily rely on whole network fine-tuning to achieve performance gains while Swin Transformer does not have such a requirement. Moreover, vision transformers behave more robustly in multi-task learning, i.e., bringing more improvements when managing mutually beneficial tasks and reducing performance losses when tackling irrelevant tasks. We hope our discoveries can facilitate the exploration and exploitation of vision transformers in the future.", "published": "2021-08-11T16:20:38Z", "version": 2}, {"aid": "2108.05390", "authors": ["Jiahao Chen", "Victor Storchan"], "title": "Seven challenges for harmonizing explainability requirements", "url": "http://arxiv.org/pdf/2108.05390v1", "summary": "Regulators have signalled an interest in adopting explainable AI(XAI) techniques to handle the diverse needs for model governance, operational servicing, and compliance in the financial services industry. In this short overview, we review the recent technical literature in XAI and argue that based on our current understanding of the field, the use of XAI techniques in practice necessitate a highly contextualized approach considering the specific needs of stakeholders for particular business applications.", "published": "2021-08-11T18:10:24Z", "version": 1}, {"aid": "2108.05449", "authors": ["Wei Zhu", "Haitian Zheng", "Haofu Liao", "Weijian Li", "Jiebo Luo"], "title": "Learning Bias-Invariant Representation by Cross-Sample Mutual Information Minimization", "url": "http://arxiv.org/pdf/2108.05449v2", "summary": "Deep learning algorithms mine knowledge from the training data and thus would likely inherit the dataset's bias information. As a result, the obtained model would generalize poorly and even mislead the decision process in real-life applications. We propose to remove the bias information misused by the target task with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly extracts target and bias features disentangled from the latent representation generated by a feature extractor and then learns to discover and remove the correlation between the target and bias features. The correlation measurement plays a critical role in adversarial debiasing and is conducted by a cross-sample neural mutual information estimator. Moreover, we propose joint content and local structural representation learning to boost mutual information estimation for better performance. We conduct thorough experiments on publicly available datasets to validate the advantages of the proposed method over state-of-the-art approaches.", "published": "2021-08-11T21:17:02Z", "version": 2}, {"aid": "2108.05479", "authors": ["Shreya Ghosh", "Abhinav Dhall", "Munawar Hayat", "Jarrod Knibbe", "Qiang Ji"], "title": "Automatic Gaze Analysis: A Survey of Deep Learning based Approaches", "url": "http://arxiv.org/pdf/2108.05479v3", "summary": "Eye gaze analysis is an important research problem in the field of Computer Vision and Human-Computer Interaction. Even with notable progress in the last 10 years, automatic gaze analysis still remains challenging due to the uniqueness of eye appearance, eye-head interplay, occlusion, image quality, and illumination conditions. There are several open questions, including what are the important cues to interpret gaze direction in an unconstrained environment without prior knowledge and how to encode them in real-time. We review the progress across a range of gaze analysis tasks and applications to elucidate these fundamental questions, identify effective methods in gaze analysis, and provide possible future directions. We analyze recent gaze estimation and segmentation methods, especially in the unsupervised and weakly supervised domain, based on their advantages and reported evaluation metrics. Our analysis shows that the development of a robust and generic gaze analysis method still needs to address real-world challenges such as unconstrained setup and learning with less supervision. We conclude by discussing future research directions for designing a real-world gaze analysis system that can propagate to other domains including Computer Vision, Augmented Reality (AR), Virtual Reality (VR), and Human Computer Interaction (HCI). Project Page: https://github.com/i-am-shreya/EyeGazeSurvey}{https://github.com/i-am-shreya/EyeGazeSurvey", "published": "2021-08-12T00:30:39Z", "version": 3}, {"aid": "2108.05494", "authors": ["Ananta Nair"], "title": "A Mathematical Approach to Constraining Neural Abstraction and the Mechanisms Needed to Scale to Higher-Order Cognition", "url": "http://arxiv.org/pdf/2108.05494v1", "summary": "Artificial intelligence has made great strides in the last decade but still falls short of the human brain, the best-known example of intelligence. Not much is known of the neural processes that allow the brain to make the leap to achieve so much from so little beyond its ability to create knowledge structures that can be flexibly and dynamically combined, recombined, and applied in new and novel ways. This paper proposes a mathematical approach using graph theory and spectral graph theory, to hypothesize how to constrain these neural clusters of information based on eigen-relationships. This same hypothesis is hierarchically applied to scale up from the smallest to the largest clusters of knowledge that eventually lead to model building and reasoning.", "published": "2021-08-12T02:13:22Z", "version": 1}, {"aid": "2108.05580", "authors": ["Aditya Rajagopal", "Christos-Savvas Bouganis"], "title": "perf4sight: A toolflow to model CNN training performance on Edge GPUs", "url": "http://arxiv.org/pdf/2108.05580v1", "summary": "The increased memory and processing capabilities of today's edge devices create opportunities for greater edge intelligence. In the domain of vision, the ability to adapt a Convolutional Neural Network's (CNN) structure and parameters to the input data distribution leads to systems with lower memory footprint, latency and power consumption. However, due to the limited compute resources and memory budget on edge devices, it is necessary for the system to be able to predict the latency and memory footprint of the training process in order to identify favourable training configurations of the network topology and device combination for efficient network adaptation. This work proposes perf4sight, an automated methodology for developing accurate models that predict CNN training memory footprint and latency given a target device and network. This enables rapid identification of network topologies that can be retrained on the edge device with low resource consumption. With PyTorch as the framework and NVIDIA Jetson TX2 as the target device, the developed models predict training memory footprint and latency with 95% and 91% accuracy respectively for a wide range of networks, opening the path towards efficient network adaptation on edge GPUs.", "published": "2021-08-12T07:55:37Z", "version": 1}, {"aid": "2108.05623", "authors": ["El Mehdi Achour", "Fran\u00e7ois Malgouyres", "Franck Mamalet"], "title": "Existence, Stability and Scalability of Orthogonal Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2108.05623v3", "summary": "Imposing orthogonality on the layers of neural networks is known to facilitate the learning by limiting the exploding/vanishing of the gradient; decorrelate the features; improve the robustness. This paper studies the theoretical properties of orthogonal convolutional layers.We establish necessary and sufficient conditions on the layer architecture guaranteeing the existence of an orthogonal convolutional transform. The conditions prove that orthogonal convolutional transforms exist for almost all architectures used in practice for 'circular' padding.We also exhibit limitations with 'valid' boundary conditions and 'same' boundary conditions with zero-padding.Recently, a regularization term imposing the orthogonality of convolutional layers has been proposed, and impressive empirical results have been obtained in different applications (Wang et al. 2020).The second motivation of the present paper is to specify the theory behind this.We make the link between this regularization term and orthogonality measures. In doing so, we show that this regularization strategy is stable with respect to numerical and optimization errors and that, in the presence of small errors and when the size of the signal/image is large, the convolutional layers remain close to isometric.The theoretical results are confirmed with experiments and the landscape of the regularization term is studied. Experiments on real data sets show that when orthogonality is used to enforce robustness, the parameter multiplying the regularization termcan be used to tune a tradeoff between accuracy and orthogonality, for the benefit of both accuracy and robustness.Altogether, the study guarantees that the regularization proposed in Wang et al. (2020) is an efficient, flexible and stable numerical strategy to learn orthogonal convolutional layers.", "published": "2021-08-12T09:30:53Z", "version": 3}, {"aid": "2108.05839", "authors": ["Aman Gupta", "Rohan Ramanath", "Jun Shi", "Anika Ramachandran", "Sirou Zhou", "Mingzhou Zhou", "S. Sathiya Keerthi"], "title": "Logit Attenuating Weight Normalization", "url": "http://arxiv.org/pdf/2108.05839v1", "summary": "Over-parameterized deep networks trained using gradient-based optimizers are a popular choice for solving classification and ranking problems. Without appropriately tuned $\\ell_2$ regularization or weight decay, such networks have the tendency to make output scores (logits) and network weights large, causing training loss to become too small and the network to lose its adaptivity (ability to move around) in the parameter space. Although regularization is typically understood from an overfitting perspective, we highlight its role in making the network more adaptive and enabling it to escape more easily from weights that generalize poorly. To provide such a capability, we propose a method called Logit Attenuating Weight Normalization (LAWN), that can be stacked onto any gradient-based optimizer. LAWN controls the logits by constraining the weight norms of layers in the final homogeneous sub-network. Empirically, we show that the resulting LAWN variant of the optimizer makes a deep network more adaptive to finding minimas with superior generalization performance on large-scale image classification and recommender systems. While LAWN is particularly impressive in improving Adam, it greatly improves all optimizers when used with large batch sizes", "published": "2021-08-12T16:44:24Z", "version": 1}, {"aid": "2108.05862", "authors": ["Duo Li", "Shang-Hua Gao"], "title": "m-RevNet: Deep Reversible Neural Networks with Momentum", "url": "http://arxiv.org/pdf/2108.05862v2", "summary": "In recent years, the connections between deep residual networks and first-order Ordinary Differential Equations (ODEs) have been disclosed. In this work, we further bridge the deep neural architecture design with the second-order ODEs and propose a novel reversible neural network, termed as m-RevNet, that is characterized by inserting momentum update to residual blocks. The reversible property allows us to perform backward pass without access to activation values of the forward pass, greatly relieving the storage burden during training. Furthermore, the theoretical foundation based on second-order ODEs grants m-RevNet with stronger representational power than vanilla residual networks, which potentially explains its performance gains. For certain learning scenarios, we analytically and empirically reveal that our m-RevNet succeeds while standard ResNet fails. Comprehensive experiments on various image classification and semantic segmentation benchmarks demonstrate the superiority of our m-RevNet over ResNet, concerning both memory efficiency and recognition performance.", "published": "2021-08-12T17:14:32Z", "version": 2}, {"aid": "2108.05889", "authors": ["Wenliang Zhao", "Yongming Rao", "Ziyi Wang", "Jiwen Lu", "Jie Zhou"], "title": "Towards Interpretable Deep Metric Learning with Structural Matching", "url": "http://arxiv.org/pdf/2108.05889v1", "summary": "How do the neural networks distinguish two images? It is of critical importance to understand the matching mechanism of deep models for developing reliable intelligent systems for many risky visual applications such as surveillance and access control. However, most existing deep metric learning methods match the images by comparing feature vectors, which ignores the spatial structure of images and thus lacks interpretability. In this paper, we present a deep interpretable metric learning (DIML) method for more transparent embedding learning. Unlike conventional metric learning methods based on feature vector comparison, we propose a structural matching strategy that explicitly aligns the spatial embeddings by computing an optimal matching flow between feature maps of the two images. Our method enables deep models to learn metrics in a more human-friendly way, where the similarity of two images can be decomposed to several part-wise similarities and their contributions to the overall similarity. Our method is model-agnostic, which can be applied to off-the-shelf backbone networks and metric learning methods. We evaluate our method on three major benchmarks of deep metric learning including CUB200-2011, Cars196, and Stanford Online Products, and achieve substantial improvements over popular metric learning methods with better interpretability. Code is available at https://github.com/wl-zhao/DIML", "published": "2021-08-12T17:59:09Z", "version": 1}, {"aid": "2108.05892", "authors": ["Chris Rockwell", "David F. Fouhey", "Justin Johnson"], "title": "PixelSynth: Generating a 3D-Consistent Experience from a Single Image", "url": "http://arxiv.org/pdf/2108.05892v1", "summary": "Recent advancements in differentiable rendering and 3D reasoning have driven exciting results in novel view synthesis from a single image. Despite realistic results, methods are limited to relatively small view change. In order to synthesize immersive scenes, models must also be able to extrapolate. We present an approach that fuses 3D reasoning with autoregressive modeling to outpaint large view changes in a 3D-consistent manner, enabling scene synthesis. We demonstrate considerable improvement in single image large-angle view synthesis results compared to a variety of methods and possible variants across simulated and real datasets. In addition, we show increased 3D consistency compared to alternative accumulation methods. Project website: https://crockwell.github.io/pixelsynth/", "published": "2021-08-12T17:59:31Z", "version": 1}, {"aid": "2108.05894", "authors": ["Yunsheng Li", "Yinpeng Chen", "Xiyang Dai", "Dongdong Chen", "Mengchen Liu", "Lu Yuan", "Zicheng Liu", "Lei Zhang", "Nuno Vasconcelos"], "title": "MicroNet: Improving Image Recognition with Extremely Low FLOPs", "url": "http://arxiv.org/pdf/2108.05894v1", "summary": "This paper aims at addressing the problem of substantial performance degradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet classification). We found that two factors, sparse connectivity and dynamic activation function, are effective to improve the accuracy. The former avoids the significant reduction of network width, while the latter mitigates the detriment of reduction in network depth. Technically, we propose micro-factorized convolution, which factorizes a convolution matrix into low rank matrices, to integrate sparse connectivity into convolution. We also present a new dynamic activation function, named Dynamic Shift Max, to improve the non-linearity via maxing out multiple dynamic fusions between an input feature map and its circular channel shift. Building upon these two new operators, we arrive at a family of networks, named MicroNet, that achieves significant performance gains over the state of the art in the low FLOP regime. For instance, under the constraint of 12M FLOPs, MicroNet achieves 59.4\\% top-1 accuracy on ImageNet classification, outperforming MobileNetV3 by 9.6\\%. Source code is at \\href{https://github.com/liyunsheng13/micronet}{https://github.com/liyunsheng13/micronet}.", "published": "2021-08-12T17:59:41Z", "version": 1}, {"aid": "2108.05895", "authors": ["Yinpeng Chen", "Xiyang Dai", "Dongdong Chen", "Mengchen Liu", "Xiaoyi Dong", "Lu Yuan", "Zicheng Liu"], "title": "Mobile-Former: Bridging MobileNet and Transformer", "url": "http://arxiv.org/pdf/2108.05895v3", "summary": "We present Mobile-Former, a parallel design of MobileNet and transformer with a two-way bridge in between. This structure leverages the advantages of MobileNet at local processing and transformer at global interaction. And the bridge enables bidirectional fusion of local and global features. Different from recent works on vision transformer, the transformer in Mobile-Former contains very few tokens (e.g. 6 or fewer tokens) that are randomly initialized to learn global priors, resulting in low computational cost. Combining with the proposed light-weight cross attention to model the bridge, Mobile-Former is not only computationally efficient, but also has more representation power. It outperforms MobileNetV3 at low FLOP regime from 25M to 500M FLOPs on ImageNet classification. For instance, Mobile-Former achieves 77.9\\% top-1 accuracy at 294M FLOPs, gaining 1.3\\% over MobileNetV3 but saving 17\\% of computations. When transferring to object detection, Mobile-Former outperforms MobileNetV3 by 8.6 AP in RetinaNet framework. Furthermore, we build an efficient end-to-end detector by replacing backbone, encoder and decoder in DETR with Mobile-Former, which outperforms DETR by 1.1 AP but saves 52\\% of computational cost and 36\\% of parameters.", "published": "2021-08-12T17:59:55Z", "version": 3}, {"aid": "2108.06065", "authors": ["John Rohrlich", "Randall C. O'Reilly"], "title": "Statistical Learning in Speech: A Biologically Based Predictive Learning Model", "url": "http://arxiv.org/pdf/2108.06065v1", "summary": "Infants, adults, non-human primates and non-primates all learn patterns implicitly, and they do so across modalities. The biological evidence supports the hypothesis that the mechanism for this learning is general but computationally local. We hypothesize that the mechanism itself is predictive error-driven learning. We build on recent work that advanced a biologically plausible model of error backpropagation learning which proposes that higher order thalamic nuclei provide a locale for a temporal difference between top-down predictions and an actual event outcome. Our neural network based on that work also models the auditory cortex hierarchy of core, belt and parabelt and the caudal-rostral axis within regions. We simulated two studies showing statistical learning in infants, a seminal study using synthesized speech and a more recent study using human speech. Before simulating these studies the network was trained on spoken sentences from the TIMIT corpus to emulate infant's experience listening to random speech. The implemented neural network, learning only by predicting the next brief speech segment, learned in both simulations to predict in-word syllables better than next-word syllables showing that prediction could be the basis for word segmentation and thus statistical learning.", "published": "2021-08-13T05:14:49Z", "version": 1}, {"aid": "2108.06128", "authors": ["Md Mohaimenuzzaman", "Christoph Bergmeir", "Bernd Meyer"], "title": "Pruning vs XNOR-Net: A Comprehensive Study of Deep Learning for Audio Classification on Edge-devices", "url": "http://arxiv.org/pdf/2108.06128v3", "summary": "Deep learning has celebrated resounding successes in many application areas of relevance to the Internet of Things (IoT), such as computer vision and machine listening. These technologies must ultimately be brought directly to the edge to fully harness the power of deep learning for the IoT. The obvious challenge is that deep learning techniques can only be implemented on strictly resource-constrained edge devices if the models are radically downsized. This task relies on different model compression techniques, such as network pruning, quantization, and the recent advancement of XNOR-Net. This study examines the suitability of these techniques for audio classification on microcontrollers. We present an application of XNOR-Net for end-to-end raw audio classification and a comprehensive empirical study comparing this approach with pruning-and-quantization methods. We show that raw audio classification with XNOR yields comparable performance to regular full precision networks for small numbers of classes while reducing memory requirements 32-fold and computation requirements 58-fold. However, as the number of classes increases significantly, performance degrades, and pruning-and-quantization based compression techniques take over as the preferred technique being able to satisfy the same space constraints but requiring approximately 8x more computation. We show that these insights are consistent between raw audio classification and image classification using standard benchmark sets. To the best of our knowledge, this is the first study to apply XNOR to end-to-end audio classification and evaluate it in the context of alternative techniques. All codes are publicly available on GitHub.", "published": "2021-08-13T09:07:45Z", "version": 3}, {"aid": "2108.06129", "authors": ["Zhongyi Han", "Haoliang Sun", "Yilong Yin"], "title": "Learning Transferable Parameters for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/2108.06129v1", "summary": "Unsupervised domain adaptation (UDA) enables a learning machine to adapt from a labeled source domain to an unlabeled domain under the distribution shift. Thanks to the strong representation ability of deep neural networks, recent remarkable achievements in UDA resort to learning domain-invariant features. Intuitively, the hope is that a good feature representation, together with the hypothesis learned from the source domain, can generalize well to the target domain. However, the learning processes of domain-invariant features and source hypothesis inevitably involve domain-specific information that would degrade the generalizability of UDA models on the target domain. In this paper, motivated by the lottery ticket hypothesis that only partial parameters are essential for generalization, we find that only partial parameters are essential for learning domain-invariant information and generalizing well in UDA. Such parameters are termed transferable parameters. In contrast, the other parameters tend to fit domain-specific details and often fail to generalize, which we term as untransferable parameters. Driven by this insight, we propose Transferable Parameter Learning (TransPar) to reduce the side effect brought by domain-specific information in the learning process and thus enhance the memorization of domain-invariant information. Specifically, according to the distribution discrepancy degree, we divide all parameters into transferable and untransferable ones in each training iteration. We then perform separate updates rules for the two types of parameters. Extensive experiments on image classification and regression tasks (keypoint detection) show that TransPar outperforms prior arts by non-trivial margins. Moreover, experiments demonstrate that TransPar can be integrated into the most popular deep UDA networks and be easily extended to handle any data distribution shift scenarios.", "published": "2021-08-13T09:09:15Z", "version": 1}, {"aid": "2108.06467", "authors": ["Khay Boon Hong"], "title": "Optimal Approximation with Sparse Neural Networks and Applications", "url": "http://arxiv.org/pdf/2108.06467v1", "summary": "We use deep sparsely connected neural networks to measure the complexity of a function class in $L^2(\\mathbb R^d)$ by restricting connectivity and memory requirement for storing the neural networks. We also introduce representation system - a countable collection of functions to guide neural networks, since approximation theory with representation system has been well developed in Mathematics. We then prove the fundamental bound theorem, implying a quantity intrinsic to the function class itself can give information about the approximation ability of neural networks and representation system. We also provides a method for transferring existing theories about approximation by representation systems to that of neural networks, greatly amplifying the practical values of neural networks. Finally, we use neural networks to approximate B-spline functions, which are used to generate the B-spline curves. Then, we analyse the complexity of a class called $\\beta$ cartoon-like functions using rate-distortion theory and wedgelets construction.", "published": "2021-08-14T05:14:13Z", "version": 1}, {"aid": "2108.06581", "authors": ["Puspita Majumdar", "Surbhi Mittal", "Richa Singh", "Mayank Vatsa"], "title": "Unravelling the Effect of Image Distortions for Biased Prediction of Pre-trained Face Recognition Models", "url": "http://arxiv.org/pdf/2108.06581v1", "summary": "Identifying and mitigating bias in deep learning algorithms has gained significant popularity in the past few years due to its impact on the society. Researchers argue that models trained on balanced datasets with good representation provide equal and unbiased performance across subgroups. However, \\textit{can seemingly unbiased pre-trained model become biased when input data undergoes certain distortions?} For the first time, we attempt to answer this question in the context of face recognition. We provide a systematic analysis to evaluate the performance of four state-of-the-art deep face recognition models in the presence of image distortions across different \\textit{gender} and \\textit{race} subgroups. We have observed that image distortions have a relationship with the performance gap of the model across different subgroups.", "published": "2021-08-14T16:49:05Z", "version": 1}, {"aid": "2108.06613", "authors": ["Andrea Burns", "Aaron Sarna", "Dilip Krishnan", "Aaron Maschinot"], "title": "Unsupervised Disentanglement without Autoencoding: Pitfalls and Future Directions", "url": "http://arxiv.org/pdf/2108.06613v1", "summary": "Disentangled visual representations have largely been studied with generative models such as Variational AutoEncoders (VAEs). While prior work has focused on generative methods for disentangled representation learning, these approaches do not scale to large datasets due to current limitations of generative models. Instead, we explore regularization methods with contrastive learning, which could result in disentangled representations that are powerful enough for large scale datasets and downstream applications. However, we find that unsupervised disentanglement is difficult to achieve due to optimization and initialization sensitivity, with trade-offs in task performance. We evaluate disentanglement with downstream tasks, analyze the benefits and disadvantages of each regularization used, and discuss future directions.", "published": "2021-08-14T21:06:42Z", "version": 1}, {"aid": "2108.06626", "authors": ["Dina Tantawy", "Mohamed Zahran", "Amr Wassal"], "title": "A Survey on GAN Acceleration Using Memory Compression Technique", "url": "http://arxiv.org/pdf/2108.06626v1", "summary": "Since its invention, Generative adversarial networks (GANs) have shown outstanding results in many applications. Generative Adversarial Networks are powerful yet, resource-hungry deep-learning models. Their main difference from ordinary deep learning models is the nature of their output. For example, GAN output can be a whole image versus other models detecting objects or classifying images. Thus, the architecture and numeric precision of the network affect the quality and speed of the solution. Hence, accelerating GANs is pivotal. Accelerating GANs can be classified into three main tracks: (1) Memory compression, (2) Computation optimization, and (3) Data-flow optimization. Because data transfer is the main source of energy usage, memory compression leads to the most savings. Thus, in this paper, we survey memory compression techniques for CNN-Based GANs. Additionally, the paper summarizes opportunities and challenges in GANs acceleration and suggests open research problems to be further investigated.", "published": "2021-08-14T23:03:14Z", "version": 1}, {"aid": "2108.06637", "authors": ["Yuelong Li", "Or Bar-Shira", "Vishal Monga", "Yonina C. Eldar"], "title": "Deep Algorithm Unrolling for Biomedical Imaging", "url": "http://arxiv.org/pdf/2108.06637v1", "summary": "In this chapter, we review biomedical applications and breakthroughs via leveraging algorithm unrolling, an important technique that bridges between traditional iterative algorithms and modern deep learning techniques. To provide context, we start by tracing the origin of algorithm unrolling and providing a comprehensive tutorial on how to unroll iterative algorithms into deep networks. We then extensively cover algorithm unrolling in a wide variety of biomedical imaging modalities and delve into several representative recent works in detail. Indeed, there is a rich history of iterative algorithms for biomedical image synthesis, which makes the field ripe for unrolling techniques. In addition, we put algorithm unrolling into a broad perspective, in order to understand why it is particularly effective and discuss recent trends. Finally, we conclude the chapter by discussing open challenges, and suggesting future research directions.", "published": "2021-08-15T01:06:26Z", "version": 1}, {"aid": "2108.06695", "authors": ["Benjamin Groisser", "Alon Wolf", "Ron Kimmel"], "title": "U-mesh: Human Correspondence Matching with Mesh Convolutional Networks", "url": "http://arxiv.org/pdf/2108.06695v2", "summary": "The proliferation of 3D scanning technology has driven a need for methods to interpret geometric data, particularly for human subjects. In this paper we propose an elegant fusion of regression (bottom-up) and generative (top-down) methods to fit a parametric template model to raw scan meshes.   Our first major contribution is an intrinsic convolutional mesh U-net architecture that predicts pointwise correspondence to a template surface. Soft-correspondence is formulated as coordinates in a newly-constructed Cartesian space. Modeling correspondence as Euclidean proximity enables efficient optimization, both for network training and for the next step of the algorithm.   Our second contribution is a generative optimization algorithm that uses the U-net correspondence predictions to guide a parametric Iterative Closest Point registration. By employing pre-trained human surface parametric models we maximally leverage domain-specific prior knowledge.   The pairing of a mesh-convolutional network with generative model fitting enables us to predict correspondence for real human surface scans including occlusions, partialities, and varying genus (e.g. from self-contact). We evaluate the proposed method on the FAUST correspondence challenge where we achieve 20% (33%) improvement over state of the art methods for inter- (intra-) subject correspondence.", "published": "2021-08-15T08:58:45Z", "version": 2}, {"aid": "2108.06797", "authors": ["Ren Wang", "Tianqi Chen", "Alfred Hero"], "title": "Deep Adversarially-Enhanced k-Nearest Neighbors", "url": "http://arxiv.org/pdf/2108.06797v2", "summary": "Recent works have theoretically and empirically shown that deep neural networks (DNNs) have an inherent vulnerability to small perturbations. Applying the Deep k-Nearest Neighbors (DkNN) classifier, we observe a dramatically increasing robustness-accuracy trade-off as the layer goes deeper. In this work, we propose a Deep Adversarially-Enhanced k-Nearest Neighbors (DAEkNN) method which achieves higher robustness than DkNN and mitigates the robustness-accuracy trade-off in deep layers through two key elements. First, DAEkNN is based on an adversarially trained model. Second, DAEkNN makes predictions by leveraging a weighted combination of benign and adversarial training data. Empirically, we find that DAEkNN improves both the robustness and the robustness-accuracy trade-off on MNIST and CIFAR-10 datasets.", "published": "2021-08-15T19:18:53Z", "version": 2}, {"aid": "2108.06858", "authors": ["S. Alireza Golestaneh", "Saba Dadsetan", "Kris M. Kitani"], "title": "No-Reference Image Quality Assessment via Transformers, Relative Ranking, and Self-Consistency", "url": "http://arxiv.org/pdf/2108.06858v2", "summary": "The goal of No-Reference Image Quality Assessment (NR-IQA) is to estimate the perceptual image quality in accordance with subjective evaluations, it is a complex and unsolved problem due to the absence of the pristine reference image. In this paper, we propose a novel model to address the NR-IQA task by leveraging a hybrid approach that benefits from Convolutional Neural Networks (CNNs) and self-attention mechanism in Transformers to extract both local and non-local features from the input image. We capture local structure information of the image via CNNs, then to circumvent the locality bias among the extracted CNNs features and obtain a non-local representation of the image, we utilize Transformers on the extracted features where we model them as a sequential input to the Transformer model. Furthermore, to improve the monotonicity correlation between the subjective and objective scores, we utilize the relative distance information among the images within each batch and enforce the relative ranking among them. Last but not least, we observe that the performance of NR-IQA models degrades when we apply equivariant transformations (e.g. horizontal flipping) to the inputs. Therefore, we propose a method that leverages self-consistency as a source of self-supervision to improve the robustness of NRIQA models. Specifically, we enforce self-consistency between the outputs of our quality assessment model for each image and its transformation (horizontally flipped) to utilize the rich self-supervisory information and reduce the uncertainty of the model. To demonstrate the effectiveness of our work, we evaluate it on seven standard IQA datasets (both synthetic and authentic) and show that our model achieves state-of-the-art results on various datasets.", "published": "2021-08-16T02:07:08Z", "version": 2}, {"aid": "2108.06885", "authors": ["Yanxi Li", "Zhaohui Yang", "Yunhe Wang", "Chang Xu"], "title": "Neural Architecture Dilation for Adversarial Robustness", "url": "http://arxiv.org/pdf/2108.06885v1", "summary": "With the tremendous advances in the architecture and scale of convolutional neural networks (CNNs) over the past few decades, they can easily reach or even exceed the performance of humans in certain tasks. However, a recently discovered shortcoming of CNNs is that they are vulnerable to adversarial attacks. Although the adversarial robustness of CNNs can be improved by adversarial training, there is a trade-off between standard accuracy and adversarial robustness. From the neural architecture perspective, this paper aims to improve the adversarial robustness of the backbone CNNs that have a satisfactory accuracy. Under a minimal computational overhead, the introduction of a dilation architecture is expected to be friendly with the standard performance of the backbone CNN while pursuing adversarial robustness. Theoretical analyses on the standard and adversarial error bounds naturally motivate the proposed neural architecture dilation algorithm. Experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and adversarial robustness.", "published": "2021-08-16T03:58:00Z", "version": 1}, {"aid": "2108.06889", "authors": ["Sihao Ding", "Fuli Feng", "Xiangnan He", "Yong Liao", "Jun Shi", "Yongdong Zhang"], "title": "Causal Incremental Graph Convolution for Recommender System Retraining", "url": "http://arxiv.org/pdf/2108.06889v2", "summary": "Real-world recommender system needs to be regularly retrained to keep with the new data. In this work, we consider how to efficiently retrain graph convolution network (GCN) based recommender models, which are state-of-the-art techniques for collaborative recommendation. To pursue high efficiency, we set the target as using only new data for model updating, meanwhile not sacrificing the recommendation accuracy compared with full model retraining. This is non-trivial to achieve, since the interaction data participates in both the graph structure for model construction and the loss function for model learning, whereas the old graph structure is not allowed to use in model updating. Towards the goal, we propose a \\textit{Causal Incremental Graph Convolution} approach, which consists of two new operators named \\textit{Incremental Graph Convolution} (IGC) and \\textit{Colliding Effect Distillation} (CED) to estimate the output of full graph convolution. In particular, we devise simple and effective modules for IGC to ingeniously combine the old representations and the incremental graph and effectively fuse the long-term and short-term preference signals. CED aims to avoid the out-of-date issue of inactive nodes that are not in the incremental graph, which connects the new data with inactive nodes through causal inference. In particular, CED estimates the causal effect of new data on the representation of inactive nodes through the control of their collider. Extensive experiments on three real-world datasets demonstrate both accuracy gains and significant speed-ups over the existing retraining mechanism.", "published": "2021-08-16T04:20:09Z", "version": 2}, {"aid": "2108.06912", "authors": ["Sin Kit Lo", "Yue Liu", "Qinghua Lu", "Chen Wang", "Xiwei Xu", "Hye-Young Paik", "Liming Zhu"], "title": "Blockchain-based Trustworthy Federated Learning Architecture", "url": "http://arxiv.org/pdf/2108.06912v2", "summary": "Federated learning is an emerging privacy-preserving AI technique where clients (i.e., organisations or devices) train models locally and formulate a global model based on the local model updates without transferring local data externally. However, federated learning systems struggle to achieve trustworthiness and embody responsible AI principles. In particular, federated learning systems face accountability and fairness challenges due to multi-stakeholder involvement and heterogeneity in client data distribution. To enhance the accountability and fairness of federated learning systems, we present a blockchain-based trustworthy federated learning architecture. We first design a smart contract-based data-model provenance registry to enable accountability. Additionally, we propose a weighted fair data sampler algorithm to enhance fairness in training data. We evaluate the proposed approach using a COVID-19 X-ray detection use case. The evaluation results show that the approach is feasible to enable accountability and improve fairness. The proposed algorithm can achieve better performance than the default federated learning setting in terms of the model's generalisation and accuracy.", "published": "2021-08-16T06:13:58Z", "version": 2}, {"aid": "2108.08296", "authors": ["Mengqi Zhang", "Yanqiao Zhu", "Qiang Liu", "Shu Wu", "Liang Wang"], "title": "Deep Contrastive Multiview Network Embedding", "url": "http://arxiv.org/pdf/2108.08296v2", "summary": "Multiview network embedding aims at projecting nodes in the network to low-dimensional vectors, while preserving their multiple relations and attribute information. Contrastive learning approaches have shown promising performance in this task. However, they neglect the semantic consistency between fused and view representations and have difficulty in modeling complementary information between different views. To deal with these deficiencies, this work presents a novel Contrastive leaRning framEwork for Multiview network Embedding (CREME). In our work, different views can be obtained based on the various relations among nodes. Then, we generate view embeddings via proper view encoders and utilize an attentive multiview aggregator to fuse these representations. Particularly, we design two collaborative contrastive objectives, view fusion InfoMax and inter-view InfoMin, to train the model in a self-supervised manner. The former objective distills information from embeddings generated from different views, while the latter captures complementary information among views to promote distinctive view embeddings. We also show that the two objectives can be unified into one objective for model training. Extensive experiments on three real-world datasets demonstrate that our proposed CREME is able to consistently outperform state-of-the-art methods.", "published": "2021-08-16T06:29:18Z", "version": 2}, {"aid": "2108.06925", "authors": ["Yu-Qi Yang", "Peng-Shuai Wang", "Yang Liu"], "title": "Interpolation-Aware Padding for 3D Sparse Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2108.06925v1", "summary": "Sparse voxel-based 3D convolutional neural networks (CNNs) are widely used for various 3D vision tasks. Sparse voxel-based 3D CNNs create sparse non-empty voxels from the 3D input and perform 3D convolution operations on them only. We propose a simple yet effective padding scheme --- interpolation-aware padding to pad a few empty voxels adjacent to the non-empty voxels and involve them in the 3D CNN computation so that all neighboring voxels exist when computing point-wise features via the trilinear interpolation. For fine-grained 3D vision tasks where point-wise features are essential, like semantic segmentation and 3D detection, our network achieves higher prediction accuracy than the existing networks using the nearest neighbor interpolation or the normalized trilinear interpolation with the zero-padding or the octree-padding scheme. Through extensive comparisons on various 3D segmentation and detection tasks, we demonstrate the superiority of 3D sparse CNNs with our padding scheme in conjunction with feature interpolation.", "published": "2021-08-16T07:00:42Z", "version": 1}, {"aid": "2108.06968", "authors": ["Ajian Liu", "Chenxu Zhao", "Zitong Yu", "Anyang Su", "Xing Liu", "Zijian Kong", "Jun Wan", "Sergio Escalera", "Hugo Jair Escalante", "Zhen Lei", "Guodong Guo"], "title": "3D High-Fidelity Mask Face Presentation Attack Detection Challenge", "url": "http://arxiv.org/pdf/2108.06968v1", "summary": "The threat of 3D masks to face recognition systems is increasingly serious and has been widely concerned by researchers. To facilitate the study of the algorithms, a large-scale High-Fidelity Mask dataset, namely CASIA-SURF HiFiMask (briefly HiFiMask) has been collected. Specifically, it consists of a total amount of 54, 600 videos which are recorded from 75 subjects with 225 realistic masks under 7 new kinds of sensors. Based on this dataset and Protocol 3 which evaluates both the discrimination and generalization ability of the algorithm under the open set scenarios, we organized a 3D High-Fidelity Mask Face Presentation Attack Detection Challenge to boost the research of 3D mask-based attack detection. It attracted 195 teams for the development phase with a total of 18 teams qualifying for the final round. All the results were verified and re-run by the organizing team, and the results were used for the final ranking. This paper presents an overview of the challenge, including the introduction of the dataset used, the definition of the protocol, the calculation of the evaluation criteria, and the summary and publication of the competition results. Finally, we focus on introducing and analyzing the top ranking algorithms, the conclusion summary, and the research ideas for mask attack detection provided by this competition.", "published": "2021-08-16T08:40:12Z", "version": 1}, {"aid": "2108.06983", "authors": ["Dohyung kim", "Junghyup Lee", "Bumsub Ham"], "title": "Distance-aware Quantization", "url": "http://arxiv.org/pdf/2108.06983v1", "summary": "We address the problem of network quantization, that is, reducing bit-widths of weights and/or activations to lighten network architectures. Quantization methods use a rounding function to map full-precision values to the nearest quantized ones, but this operation is not differentiable. There are mainly two approaches to training quantized networks with gradient-based optimizers. First, a straight-through estimator (STE) replaces the zero derivative of the rounding with that of an identity function, which causes a gradient mismatch problem. Second, soft quantizers approximate the rounding with continuous functions at training time, and exploit the rounding for quantization at test time. This alleviates the gradient mismatch, but causes a quantizer gap problem. We alleviate both problems in a unified framework. To this end, we introduce a novel quantizer, dubbed a distance-aware quantizer (DAQ), that mainly consists of a distance-aware soft rounding (DASR) and a temperature controller. To alleviate the gradient mismatch problem, DASR approximates the discrete rounding with the kernel soft argmax, which is based on our insight that the quantization can be formulated as a distance-based assignment problem between full-precision values and quantized ones. The controller adjusts the temperature parameter in DASR adaptively according to the input, addressing the quantizer gap problem. Experimental results on standard benchmarks show that DAQ outperforms the state of the art significantly for various bit-widths without bells and whistles.", "published": "2021-08-16T09:25:22Z", "version": 1}, {"aid": "2108.07049", "authors": ["Kirill Prokofiev", "Vladislav Sovrasov"], "title": "Towards Efficient and Data Agnostic Image Classification Training Pipeline for Embedded Systems", "url": "http://arxiv.org/pdf/2108.07049v1", "summary": "Nowadays deep learning-based methods have achieved a remarkable progress at the image classification task among a wide range of commonly used datasets (ImageNet, CIFAR, SVHN, Caltech 101, SUN397, etc.). SOTA performance on each of the mentioned datasets is obtained by careful tuning of the model architecture and training tricks according to the properties of the target data. Although this approach allows setting academic records, it is unrealistic that an average data scientist would have enough resources to build a sophisticated training pipeline for every image classification task he meets in practice. This work is focusing on reviewing the latest augmentation and regularization methods for the image classification and exploring ways to automatically choose some of the most important hyperparameters: total number of epochs, initial learning rate value and it's schedule. Having a training procedure equipped with a lightweight modern CNN architecture (like bileNetV3 or EfficientNet), sufficient level of regularization and adaptive to data learning rate schedule, we can achieve a reasonable performance on a variety of downstream image classification tasks without manual tuning of parameters to each particular task. Resulting models are computationally efficient and can be deployed to CPU using the OpenVINO toolkit. Source code is available as a part of the OpenVINO Training Extensions (https://github.com/openvinotoolkit/training_extensions).", "published": "2021-08-16T12:38:05Z", "version": 1}, {"aid": "2108.07380", "authors": ["Subhadeep Mukhopadhyay"], "title": "InfoGram and Admissible Machine Learning", "url": "http://arxiv.org/pdf/2108.07380v2", "summary": "We have entered a new era of machine learning (ML), where the most accurate algorithm with superior predictive power may not even be deployable, unless it is admissible under the regulatory constraints. This has led to great interest in developing fair, transparent and trustworthy ML methods. The purpose of this article is to introduce a new information-theoretic learning framework (admissible machine learning) and algorithmic risk-management tools (InfoGram, L-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf ML methods to be regulatory compliant, while maintaining good prediction accuracy. We have illustrated our approach using several real-data examples from financial sectors, biomedical research, marketing campaigns, and the criminal justice system.", "published": "2021-08-17T00:04:38Z", "version": 2}, {"aid": "2108.07387", "authors": ["Ionut Cosmin Duta", "Mariana Iuliana Georgescu", "Radu Tudor Ionescu"], "title": "Contextual Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2108.07387v1", "summary": "We propose contextual convolution (CoConv) for visual recognition. CoConv is a direct replacement of the standard convolution, which is the core component of convolutional neural networks. CoConv is implicitly equipped with the capability of incorporating contextual information while maintaining a similar number of parameters and computational cost compared to the standard convolution. CoConv is inspired by neuroscience studies indicating that (i) neurons, even from the primary visual cortex (V1 area), are involved in detection of contextual cues and that (ii) the activity of a visual neuron can be influenced by the stimuli placed entirely outside of its theoretical receptive field. On the one hand, we integrate CoConv in the widely-used residual networks and show improved recognition performance over baselines on the core tasks and benchmarks for visual recognition, namely image classification on the ImageNet data set and object detection on the MS COCO data set. On the other hand, we introduce CoConv in the generator of a state-of-the-art Generative Adversarial Network, showing improved generative results on CIFAR-10 and CelebA. Our code is available at https://github.com/iduta/coconv.", "published": "2021-08-17T00:42:11Z", "version": 1}, {"aid": "2108.07639", "authors": ["Jordi Armengol-Estap\u00e9", "Michael F. P. O'Boyle"], "title": "Learning C to x86 Translation: An Experiment in Neural Compilation", "url": "http://arxiv.org/pdf/2108.07639v2", "summary": "Deep learning has had a significant impact on many fields. Recently, code-to-code neural models have been used in code translation, code refinement and decompilation. However, the question of whether these models can automate compilation has yet to be investigated. In this work, we explore neural compilation, building and evaluating Transformer models that learn how to produce x86 assembler from C code. Although preliminary results are relatively weak, we make our data, models and code publicly available to encourage further research in this area.", "published": "2021-08-17T14:11:15Z", "version": 2}, {"aid": "2108.07839", "authors": ["Stefano Fusi"], "title": "Memory capacity of neural network models", "url": "http://arxiv.org/pdf/2108.07839v2", "summary": "Memory is a complex phenomenon that involves several distinct mechanisms. These mechanisms operate at different spatial and temporal levels. This chapter focuses on the theoretical framework and the mathematical models that have been developed to understand how these mechanisms are orchestrated to store, preserve and retrieve a large number of memories. In particular, this chapter reviews the theoretical studies on memory capacity, in which the investigators estimated how the number of storable memories scales with the number of neurons and synapses in the neural circuitry. The memory capacity depends on the complexity of the synapses, the sparseness of the representations, the spatial and temporal correlations between memories and the specific way memories are retrieved. Complexity is important when the synapses can only be modified with a limited precision, as in the case of biological synapses, and sparseness can greatly increase memory capacity and be particularly beneficial when memories are structured (correlated to each other). The theoretical tools discussed by this chapter can be harnessed to identify the important computational principles that underlie memory storage, preservation and retrieval and provide guidance in designing and interpreting memory experiments.", "published": "2021-08-17T19:08:25Z", "version": 2}, {"aid": "2108.07846", "authors": ["Xianyuan Liu", "Shuo Zhou", "Tao Lei", "Haiping Lu"], "title": "Channel-Temporal Attention for First-Person Video Domain Adaptation", "url": "http://arxiv.org/pdf/2108.07846v2", "summary": "Unsupervised Domain Adaptation (UDA) can transfer knowledge from labeled source data to unlabeled target data of the same categories. However, UDA for first-person action recognition is an under-explored problem, with lack of datasets and limited consideration of first-person video characteristics. This paper focuses on addressing this problem. Firstly, we propose two small-scale first-person video domain adaptation datasets: ADL$_{small}$ and GTEA-KITCHEN. Secondly, we introduce channel-temporal attention blocks to capture the channel-wise and temporal-wise relationships and model their inter-dependencies important to first-person vision. Finally, we propose a Channel-Temporal Attention Network (CTAN) to integrate these blocks into existing architectures. CTAN outperforms baselines on the two proposed datasets and one existing dataset EPIC$_{cvpr20}$.", "published": "2021-08-17T19:30:42Z", "version": 2}, {"aid": "2108.07908", "authors": ["Luca Parisi"], "title": "M-ar-K-Fast Independent Component Analysis", "url": "http://arxiv.org/pdf/2108.07908v1", "summary": "This study presents the m-arcsinh Kernel ('m-ar-K') Fast Independent Component Analysis ('FastICA') method ('m-ar-K-FastICA') for feature extraction. The kernel trick has enabled dimensionality reduction techniques to capture a higher extent of non-linearity in the data; however, reproducible, open-source kernels to aid with feature extraction are still limited and may not be reliable when projecting features from entropic data. The m-ar-K function, freely available in Python and compatible with its open-source library 'scikit-learn', is hereby coupled with FastICA to achieve more reliable feature extraction in presence of a high extent of randomness in the data, reducing the need for pre-whitening. Different classification tasks were considered, as related to five (N = 5) open access datasets of various degrees of information entropy, available from scikit-learn and the University California Irvine (UCI) Machine Learning repository. Experimental results demonstrate improvements in the classification performance brought by the proposed feature extraction. The novel m-ar-K-FastICA dimensionality reduction approach is compared to the 'FastICA' gold standard method, supporting its higher reliability and computational efficiency, regardless of the underlying uncertainty in the data.", "published": "2021-08-17T23:53:12Z", "version": 1}, {"aid": "2108.08000", "authors": ["Matthew L. Olson", "Thuy-Vy Nguyen", "Gaurav Dixit", "Neale Ratzlaff", "Weng-Keen Wong", "Minsuk Kahng"], "title": "Contrastive Identification of Covariate Shift in Image Data", "url": "http://arxiv.org/pdf/2108.08000v2", "summary": "Identifying covariate shift is crucial for making machine learning systems robust in the real world and for detecting training data biases that are not reflected in test data. However, detecting covariate shift is challenging, especially when the data consists of high-dimensional images, and when multiple types of localized covariate shift affect different subspaces of the data. Although automated techniques can be used to detect the existence of covariate shift, our goal is to help human users characterize the extent of covariate shift in large image datasets with interfaces that seamlessly integrate information obtained from the detection algorithms. In this paper, we design and evaluate a new visual interface that facilitates the comparison of the local distributions of training and test data. We conduct a quantitative user study on multi-attribute facial data to compare two different learned low-dimensional latent representations (pretrained ImageNet CNN vs. density ratio) and two user analytic workflows (nearest-neighbor vs. cluster-to-cluster). Our results indicate that the latent representation of our density ratio model, combined with a nearest-neighbor comparison, is the most effective at helping humans identify covariate shift.", "published": "2021-08-18T06:58:29Z", "version": 2}, {"aid": "2108.08046", "authors": ["Seong Jin Ahn", "Myoung Ho Kim"], "title": "Variational Graph Normalized Auto-Encoders", "url": "http://arxiv.org/pdf/2108.08046v2", "summary": "Link prediction is one of the key problems for graph-structured data. With the advancement of graph neural networks, graph autoencoders (GAEs) and variational graph autoencoders (VGAEs) have been proposed to learn graph embeddings in an unsupervised way. It has been shown that these methods are effective for link prediction tasks. However, they do not work well in link predictions when a node whose degree is zero (i.g., isolated node) is involved. We have found that GAEs/VGAEs make embeddings of isolated nodes close to zero regardless of their content features. In this paper, we propose a novel Variational Graph Normalized AutoEncoder (VGNAE) that utilize L2-normalization to derive better embeddings for isolated nodes. We show that our VGNAEs outperform the existing state-of-the-art models for link prediction tasks. The code is available at https://github.com/SeongJinAhn/VGNAE.", "published": "2021-08-18T08:56:04Z", "version": 2}, {"aid": "2108.08782", "authors": ["Tan Wang", "Chang Zhou", "Qianru Sun", "Hanwang Zhang"], "title": "Causal Attention for Unbiased Visual Recognition", "url": "http://arxiv.org/pdf/2108.08782v1", "summary": "Attention module does not always help deep models learn causal features that are robust in any confounding context, e.g., a foreground object feature is invariant to different backgrounds. This is because the confounders trick the attention to capture spurious correlations that benefit the prediction when the training and testing data are IID (identical & independent distribution); while harm the prediction when the data are OOD (out-of-distribution). The sole fundamental solution to learn causal attention is by causal intervention, which requires additional annotations of the confounders, e.g., a \"dog\" model is learned within \"grass+dog\" and \"road+dog\" respectively, so the \"grass\" and \"road\" contexts will no longer confound the \"dog\" recognition. However, such annotation is not only prohibitively expensive, but also inherently problematic, as the confounders are elusive in nature. In this paper, we propose a causal attention module (CaaM) that self-annotates the confounders in unsupervised fashion. In particular, multiple CaaMs can be stacked and integrated in conventional attention CNN and self-attention Vision Transformer. In OOD settings, deep models with CaaM outperform those without it significantly; even in IID settings, the attention localization is also improved by CaaM, showing a great potential in applications that require robust visual saliency. Codes are available at \\url{https://github.com/Wangt-CN/CaaM}.", "published": "2021-08-19T16:45:51Z", "version": 1}, {"aid": "2108.09598", "authors": ["Sayan Nag", "Mayukh Bhattacharyya"], "title": "SERF: Towards better training of deep neural networks using log-Softplus ERror activation Function", "url": "http://arxiv.org/pdf/2108.09598v3", "summary": "Activation functions play a pivotal role in determining the training dynamics and neural network performance. The widely adopted activation function ReLU despite being simple and effective has few disadvantages including the Dying ReLU problem. In order to tackle such problems, we propose a novel activation function called Serf which is self-regularized and nonmonotonic in nature. Like Mish, Serf also belongs to the Swish family of functions. Based on several experiments on computer vision (image classification and object detection) and natural language processing (machine translation, sentiment classification and multimodal entailment) tasks with different state-of-the-art architectures, it is observed that Serf vastly outperforms ReLU (baseline) and other activation functions including both Swish and Mish, with a markedly bigger margin on deeper architectures. Ablation studies further demonstrate that Serf based architectures perform better than those of Swish and Mish in varying scenarios, validating the effectiveness and compatibility of Serf with varying depth, complexity, optimizers, learning rates, batch sizes, initializers and dropout rates. Finally, we investigate the mathematical relation between Swish and Serf, thereby showing the impact of preconditioner function ingrained in the first derivative of Serf which provides a regularization effect making gradients smoother and optimization faster.", "published": "2021-08-21T23:33:57Z", "version": 3}, {"aid": "2108.10751", "authors": ["Ljubisa Stankovic", "Danilo Mandic"], "title": "Understanding the Basis of Graph Convolutional Neural Networks via an Intuitive Matched Filtering Approach", "url": "http://arxiv.org/pdf/2108.10751v1", "summary": "Graph Convolutional Neural Networks (GCNN) are becoming a preferred model for data processing on irregular domains, yet their analysis and principles of operation are rarely examined due to the black box nature of NNs. To this end, we revisit the operation of GCNNs and show that their convolution layers effectively perform matched filtering of input data with the chosen patterns (features). This allows us to provide a unifying account of GCNNs through a matched filter perspective, whereby the nonlinear ReLU and max-pooling layers are also discussed within the matched filtering framework. This is followed by a step-by-step guide on information propagation and learning in GCNNs. It is also shown that standard CNNs and fully connected NNs can be obtained as a special case of GCNNs. A carefully chosen numerical example guides the reader through the various steps of GCNN operation and learning both visually and numerically.", "published": "2021-08-23T12:41:06Z", "version": 1}, {"aid": "2108.10430", "authors": ["Yixin Hu", "Xingyu Li"], "title": "CoverTheFace: face covering monitoring and demonstrating using deep learning and statistical shape analysis", "url": "http://arxiv.org/pdf/2108.10430v1", "summary": "Wearing a mask is a strong protection against the COVID-19 pandemic, even though the vaccine has been successfully developed and is widely available. However, many people wear them incorrectly. This observation prompts us to devise an automated approach to monitor the condition of people wearing masks. Unlike previous studies, our work goes beyond mask detection; it focuses on generating a personalized demonstration on proper mask-wearing, which helps people use masks better through visual demonstration rather than text explanation. The pipeline starts from the detection of face covering. For images where faces are improperly covered, our mask overlay module incorporates statistical shape analysis (SSA) and dense landmark alignment to approximate the geometry of a face and generates corresponding face-covering examples. Our results show that the proposed system successfully identifies images with faces covered properly. Our ablation study on mask overlay suggests that the SSA model helps to address variations in face shapes, orientations, and scales. The final face-covering examples, especially half profile face images, surpass previous arts by a noticeable margin.", "published": "2021-08-23T22:11:07Z", "version": 1}, {"aid": "2108.10521", "authors": ["Tianlong Chen", "Kaixiong Zhou", "Keyu Duan", "Wenqing Zheng", "Peihao Wang", "Xia Hu", "Zhangyang Wang"], "title": "Bag of Tricks for Training Deeper Graph Neural Networks: A Comprehensive Benchmark Study", "url": "http://arxiv.org/pdf/2108.10521v2", "summary": "Training deep graph neural networks (GNNs) is notoriously hard. Besides the standard plights in training deep architectures such as vanishing gradients and overfitting, it also uniquely suffers from over-smoothing, information squashing, and so on, which limits their potential power for encoding the high-order neighbor structure in large-scale graphs. Although numerous efforts are proposed to address these limitations, such as various forms of skip connections, graph normalization, and random dropping, it is difficult to disentangle the advantages brought by a deep GNN architecture from those \"tricks\" necessary to train such an architecture. Moreover, the lack of a standardized benchmark with fair and consistent experimental settings poses an almost insurmountable obstacle to gauge the effectiveness of new mechanisms. In view of those, we present the first fair and reproducible benchmark dedicated to assessing the \"tricks\" of training deep GNNs. We categorize existing approaches, investigate their hyperparameter sensitivity, and unify the basic configuration. Comprehensive evaluations are then conducted on tens of representative graph datasets including the recent large-scale Open Graph Benchmark, with diverse deep GNN backbones. We demonstrate that an organic combo of initial connection, identity mapping, group and batch normalization attains the new state-of-the-art results for deep GNNs on large datasets. Codes are available: https://github.com/VITA-Group/Deep_GCN_Benchmarking.", "published": "2021-08-24T05:00:37Z", "version": 2}, {"aid": "2108.10612", "authors": ["Dawid Rymarczyk", "Adam Pardyl", "Jaros\u0142aw Kraus", "Aneta Kaczy\u0144ska", "Marek Skomorowski", "Bartosz Zieli\u0144ski"], "title": "ProtoMIL: Multiple Instance Learning with Prototypical Parts for Whole-Slide Image Classification", "url": "http://arxiv.org/pdf/2108.10612v2", "summary": "Multiple Instance Learning (MIL) gains popularity in many real-life machine learning applications due to its weakly supervised nature. However, the corresponding effort on explaining MIL lags behind, and it is usually limited to presenting instances of a bag that are crucial for a particular prediction. In this paper, we fill this gap by introducing ProtoMIL, a novel self-explainable MIL method inspired by the case-based reasoning process that operates on visual prototypes. Thanks to incorporating prototypical features into objects description, ProtoMIL unprecedentedly joins the model accuracy and fine-grained interpretability, which we present with the experiments on five recognized MIL datasets.", "published": "2021-08-24T10:02:31Z", "version": 2}, {"aid": "2108.10710", "authors": ["Fadi Boutros", "Patrick Siebke", "Marcel Klemt", "Naser Damer", "Florian Kirchbuchner", "Arjan Kuijper"], "title": "PocketNet: Extreme Lightweight Face Recognition Network using Neural Architecture Search and Multi-Step Knowledge Distillation", "url": "http://arxiv.org/pdf/2108.10710v2", "summary": "Deep neural networks have rapidly become the mainstream method for face recognition (FR). However, this limits the deployment of such models that contain an extremely large number of parameters to embedded and low-end devices. In this work, we present an extremely lightweight and accurate FR solution, namely PocketNet. We utilize neural architecture search to develop a new family of lightweight face-specific architectures. We additionally propose a novel training paradigm based on knowledge distillation (KD), the multi-step KD, where the knowledge is distilled from the teacher model to the student model at different stages of the training maturity. We conduct a detailed ablation study proving both, the sanity of using NAS for the specific task of FR rather than general object classification, and the benefits of our proposed multi-step KD. We present an extensive experimental evaluation and comparisons with the state-of-the-art (SOTA) compact FR models on nine different benchmarks including large-scale evaluation benchmarks such as IJB-B, IJB-C, and MegaFace. PocketNets have consistently advanced the SOTA FR performance on nine mainstream benchmarks when considering the same level of model compactness. With 0.92M parameters, our smallest network PocketNetS-128 achieved very competitive results to recent SOTA compacted models that contain up to 4M parameters.", "published": "2021-08-24T13:19:08Z", "version": 2}, {"aid": "2108.10733", "authors": ["Lilapati Waikhom", "Ripon Patgiri"], "title": "Graph Neural Networks: Methods, Applications, and Opportunities", "url": "http://arxiv.org/pdf/2108.10733v2", "summary": "In the last decade or so, we have witnessed deep learning reinvigorating the machine learning field. It has solved many problems in the domains of computer vision, speech recognition, natural language processing, and various other tasks with state-of-the-art performance. The data is generally represented in the Euclidean space in these domains. Various other domains conform to non-Euclidean space, for which graph is an ideal representation. Graphs are suitable for representing the dependencies and interrelationships between various entities. Traditionally, handcrafted features for graphs are incapable of providing the necessary inference for various tasks from this complex data representation. Recently, there is an emergence of employing various advances in deep learning to graph data-based tasks. This article provides a comprehensive survey of graph neural networks (GNNs) in each learning setting: supervised, unsupervised, semi-supervised, and self-supervised learning. Taxonomy of each graph based learning setting is provided with logical divisions of methods falling in the given learning setting. The approaches for each learning task are analyzed from both theoretical as well as empirical standpoints. Further, we provide general architecture guidelines for building GNNs. Various applications and benchmark datasets are also provided, along with open challenges still plaguing the general applicability of GNNs.", "published": "2021-08-24T13:46:19Z", "version": 2}, {"aid": "2108.10840", "authors": ["Shuhao Qiu", "Chuang Zhu", "Wenli Zhou"], "title": "Meta Self-Learning for Multi-Source Domain Adaptation: A Benchmark", "url": "http://arxiv.org/pdf/2108.10840v1", "summary": "In recent years, deep learning-based methods have shown promising results in computer vision area. However, a common deep learning model requires a large amount of labeled data, which is labor-intensive to collect and label. What's more, the model can be ruined due to the domain shift between training data and testing data. Text recognition is a broadly studied field in computer vision and suffers from the same problems noted above due to the diversity of fonts and complicated backgrounds. In this paper, we focus on the text recognition problem and mainly make three contributions toward these problems. First, we collect a multi-source domain adaptation dataset for text recognition, including five different domains with over five million images, which is the first multi-domain text recognition dataset to our best knowledge. Secondly, we propose a new method called Meta Self-Learning, which combines the self-learning method with the meta-learning paradigm and achieves a better recognition result under the scene of multi-domain adaptation. Thirdly, extensive experiments are conducted on the dataset to provide a benchmark and also show the effectiveness of our method. The code of our work and dataset are available soon at https://bupt-ai-cz.github.io/Meta-SelfLearning/.", "published": "2021-08-24T17:07:34Z", "version": 1}, {"aid": "2108.12043", "authors": ["Xiao Liu", "Pedro Sanchez", "Spyridon Thermos", "Alison Q. O'Neil", "Sotirios A. Tsaftaris"], "title": "Learning Disentangled Representations in the Imaging Domain", "url": "http://arxiv.org/pdf/2108.12043v6", "summary": "Disentangled representation learning has been proposed as an approach to learning general representations even in the absence of, or with limited, supervision. A good general representation can be fine-tuned for new target tasks using modest amounts of data, or used directly in unseen domains achieving remarkable performance in the corresponding task. This alleviation of the data and annotation requirements offers tantalising prospects for applications in computer vision and healthcare. In this tutorial paper, we motivate the need for disentangled representations, revisit key concepts, and describe practical building blocks and criteria for learning such representations. We survey applications in medical imaging emphasising choices made in exemplar key works, and then discuss links to computer vision applications. We conclude by presenting limitations, challenges, and opportunities.", "published": "2021-08-26T21:44:10Z", "version": 6}, {"aid": "2109.07161", "authors": ["Roman Suvorov", "Elizaveta Logacheva", "Anton Mashikhin", "Anastasia Remizova", "Arsenii Ashukha", "Aleksei Silvestrov", "Naejin Kong", "Harshith Goka", "Kiwoong Park", "Victor Lempitsky"], "title": "Resolution-robust Large Mask Inpainting with Fourier Convolutions", "url": "http://arxiv.org/pdf/2109.07161v2", "summary": "Modern image inpainting systems, despite the significant progress, often struggle with large missing areas, complex geometric structures, and high-resolution images. We find that one of the main reasons for that is the lack of an effective receptive field in both the inpainting network and the loss function. To alleviate this issue, we propose a new method called large mask inpainting (LaMa). LaMa is based on i) a new inpainting network architecture that uses fast Fourier convolutions (FFCs), which have the image-wide receptive field; ii) a high receptive field perceptual loss; iii) large training masks, which unlocks the potential of the first two components. Our inpainting network improves the state-of-the-art across a range of datasets and achieves excellent performance even in challenging scenarios, e.g. completion of periodic structures. Our model generalizes surprisingly well to resolutions that are higher than those seen at train time, and achieves this at lower parameter&time costs than the competitive baselines. The code is available at \\url{https://github.com/saic-mdal/lama}.", "published": "2021-09-15T08:54:29Z", "version": 2}, {"aid": "2109.08203", "authors": ["David Picard"], "title": "Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision", "url": "http://arxiv.org/pdf/2109.08203v2", "summary": "In this paper I investigate the effect of random seed selection on the accuracy when using popular deep learning architectures for computer vision. I scan a large amount of seeds (up to $10^4$) on CIFAR 10 and I also scan fewer seeds on Imagenet using pre-trained models to investigate large scale datasets. The conclusions are that even if the variance is not very large, it is surprisingly easy to find an outlier that performs much better or much worse than the average.", "published": "2021-09-16T20:10:12Z", "version": 2}, {"aid": "2109.09265", "authors": ["Aadyot Bhatnagar", "Paul Kassianik", "Chenghao Liu", "Tian Lan", "Wenzhuo Yang", "Rowan Cassius", "Doyen Sahoo", "Devansh Arpit", "Sri Subramanian", "Gerald Woo", "Amrita Saha", "Arun Kumar Jagota", "Gokulakrishnan Gopalakrishnan", "Manpreet Singh", "K C Krithika", "Sukumar Maddineni", "Daeki Cho", "Bo Zong", "Yingbo Zhou", "Caiming Xiong", "Silvio Savarese", "Steven Hoi", "Huan Wang"], "title": "Merlion: A Machine Learning Library for Time Series", "url": "http://arxiv.org/pdf/2109.09265v1", "summary": "We introduce Merlion, an open-source machine learning library for time series. It features a unified interface for many commonly used models and datasets for anomaly detection and forecasting on both univariate and multivariate time series, along with standard pre/post-processing layers. It has several modules to improve ease-of-use, including visualization, anomaly score calibration to improve interpetability, AutoML for hyperparameter tuning and model selection, and model ensembling. Merlion also provides a unique evaluation framework that simulates the live deployment and re-training of a model in production. This library aims to provide engineers and researchers a one-stop solution to rapidly develop models for their specific time series needs and benchmark them across multiple time series datasets. In this technical report, we highlight Merlion's architecture and major functionalities, and we report benchmark numbers across different baseline models and ensembles.", "published": "2021-09-20T02:03:43Z", "version": 1}, {"aid": "2109.10817", "authors": ["Wasim Ahmad", "Maha Shadaydeh", "Joachim Denzler"], "title": "Causal Inference in Non-linear Time-series using Deep Networks and Knockoff Counterfactuals", "url": "http://arxiv.org/pdf/2109.10817v3", "summary": "Estimating causal relations is vital in understanding the complex interactions in multivariate time series. Non-linear coupling of variables is one of the major challenges inaccurate estimation of cause-effect relations. In this paper, we propose to use deep autoregressive networks (DeepAR) in tandem with counterfactual analysis to infer nonlinear causal relations in multivariate time series. We extend the concept of Granger causality using probabilistic forecasting with DeepAR. Since deep networks can neither handle missing input nor out-of-distribution intervention, we propose to use the Knockoffs framework (Barberand Cand`es, 2015) for generating intervention variables and consequently counterfactual probabilistic forecasting. Knockoff samples are independent of their output given the observed variables and exchangeable with their counterpart variables without changing the underlying distribution of the data. We test our method on synthetic as well as real-world time series datasets. Overall our method outperforms the widely used vector autoregressive Granger causality and PCMCI in detecting nonlinear causal dependency in multivariate time series.", "published": "2021-09-22T16:07:27Z", "version": 3}, {"aid": "2109.10951", "authors": ["Morgan Schaefer", "Lauren Michelin", "Jeremy Kepner"], "title": "Naming Schema for a Human Brain-Scale Neural Network", "url": "http://arxiv.org/pdf/2109.10951v1", "summary": "Deep neural networks have become increasingly large and sparse, allowing for the storage of large-scale neural networks with decreased costs of storage and computation. Storage of a neural network with as many connections as the human brain is possible with current versions of the high-performance Apache Accumulo database and the Distributed Dimensional Data Model (D4M) software. Neural networks of such large scale may be of particular interest to scientists within the human brain Connectome community. To aid in research and understanding of artificial neural networks that parallel existing neural networks like the brain, a naming schema can be developed to label groups of neurons in the artificial network that parallel those in the brain. Groups of artificial neurons are able to be specifically labeled in small regions for future study.", "published": "2021-09-22T18:14:47Z", "version": 1}, {"aid": "2109.11358", "authors": ["Jari Pronold", "Jakob Jordan", "Brian J. N. Wylie", "Itaru Kitayama", "Markus Diesmann", "Susanne Kunkel"], "title": "Routing brain traffic through the von Neumann bottleneck: Parallel sorting and refactoring", "url": "http://arxiv.org/pdf/2109.11358v3", "summary": "Generic simulation code for spiking neuronal networks spends the major part of time in the phase where spikes have arrived at a compute node and need to be delivered to their target neurons. These spikes were emitted over the last interval between communication steps by source neurons distributed across many compute nodes and are inherently irregular with respect to their targets. For finding the targets, the spikes need to be dispatched to a three-dimensional data structure with decisions on target thread and synapse type to be made on the way. With growing network size a compute node receives spikes from an increasing number of different source neurons until in the limit each synapse on the compute node has a unique source. Here we show analytically how this sparsity emerges over the practically relevant range of network sizes from a hundred thousand to a billion neurons. By profiling a production code we investigate opportunities for algorithmic changes to avoid indirections and branching. Every thread hosts an equal share of the neurons on a compute node. In the original algorithm all threads search through all spikes to pick out the relevant ones. With increasing network size the fraction of hits remains invariant but the absolute number of rejections grows. An alternative algorithm equally divides the spikes among the threads and sorts them in parallel according to target thread and synapse type. After this every thread completes delivery solely of the section of spikes for its own neurons. The new algorithm halves the number of instructions in spike delivery which leads to a reduction of simulation time of up to 40 %. Thus, spike delivery is a fully parallelizable process with a single synchronization point and thereby well suited for many-core systems. Our analysis indicates that further progress requires a reduction of the latency instructions experience in accessing memory.", "published": "2021-09-23T13:15:34Z", "version": 3}, {"aid": "2109.11439", "authors": ["Phutphalla Kong", "Matei Mancas", "Bernard Gosselin", "Kimtho Po"], "title": "DeepRare: Generic Unsupervised Visual Attention Models", "url": "http://arxiv.org/pdf/2109.11439v1", "summary": "Human visual system is modeled in engineering field providing feature-engineered methods which detect contrasted/surprising/unusual data into images. This data is \"interesting\" for humans and leads to numerous applications. Deep learning (DNNs) drastically improved the algorithms efficiency on the main benchmark datasets. However, DNN-based models are counter-intuitive: surprising or unusual data is by definition difficult to learn because of its low occurrence probability. In reality, DNN-based models mainly learn top-down features such as faces, text, people, or animals which usually attract human attention, but they have low efficiency in extracting surprising or unusual data in the images. In this paper, we propose a new visual attention model called DeepRare2021 (DR21) which uses the power of DNNs feature extraction and the genericity of feature-engineered algorithms. This algorithm is an evolution of a previous version called DeepRare2019 (DR19) based on a common framework. DR21 1) does not need any training and uses the default ImageNet training, 2) is fast even on CPU, 3) is tested on four very different eye-tracking datasets showing that the DR21 is generic and is always in the within the top models on all datasets and metrics while no other model exhibits such a regularity and genericity. Finally DR21 4) is tested with several network architectures such as VGG16 (V16), VGG19 (V19) and MobileNetV2 (MN2) and 5) it provides explanation and transparency on which parts of the image are the most surprising at different levels despite the use of a DNN-based feature extractor. DeepRare2021 code can be found at https://github.com/numediart/VisualAttention-RareFamil}.", "published": "2021-09-23T15:28:43Z", "version": 1}, {"aid": "2109.12813", "authors": ["Yeshwanth Bethi", "Ying Xu", "Gregory Cohen", "Andre van Schaik", "Saeed Afshar"], "title": "An optimised deep spiking neural network architecture without gradients", "url": "http://arxiv.org/pdf/2109.12813v3", "summary": "We present an end-to-end trainable modular event-driven neural architecture that uses local synaptic and threshold adaptation rules to perform transformations between arbitrary spatio-temporal spike patterns. The architecture represents a highly abstracted model of existing Spiking Neural Network (SNN) architectures. The proposed Optimized Deep Event-driven Spiking neural network Architecture (ODESA) can simultaneously learn hierarchical spatio-temporal features at multiple arbitrary time scales. ODESA performs online learning without the use of error back-propagation or the calculation of gradients. Through the use of simple local adaptive selection thresholds at each node, the network rapidly learns to appropriately allocate its neuronal resources at each layer for any given problem without using a real-valued error measure. These adaptive selection thresholds are the central feature of ODESA, ensuring network stability and remarkable robustness to noise as well as to the selection of initial system parameters. Network activations are inherently sparse due to a hard Winner-Take-All (WTA) constraint at each layer. We evaluate the architecture on existing spatio-temporal datasets, including the spike-encoded IRIS and TIDIGITS datasets, as well as a novel set of tasks based on International Morse Code that we created. These tests demonstrate the hierarchical spatio-temporal learning capabilities of ODESA. Through these tests, we demonstrate ODESA can optimally solve practical and highly challenging hierarchical spatio-temporal learning tasks with the minimum possible number of computing nodes.", "published": "2021-09-27T05:59:12Z", "version": 3}, {"aid": "2109.13208", "authors": ["Saeed Reza Kheradpisheh", "Maryam Mirsadeghi", "Timoth\u00e9e Masquelier"], "title": "Spiking neural networks trained via proxy", "url": "http://arxiv.org/pdf/2109.13208v3", "summary": "We propose a new learning algorithm to train spiking neural networks (SNN) using conventional artificial neural networks (ANN) as proxy. We couple two SNN and ANN networks, respectively, made of integrate-and-fire (IF) and ReLU neurons with the same network architectures and shared synaptic weights. The forward passes of the two networks are totally independent. By assuming IF neuron with rate-coding as an approximation of ReLU, we backpropagate the error of the SNN in the proxy ANN to update the shared weights, simply by replacing the ANN final output with that of the SNN. We applied the proposed proxy learning to deep convolutional SNNs and evaluated it on two benchmarked datasets of Fashion-MNIST and Cifar10 with 94.56% and 93.11% classification accuracy, respectively. The proposed networks could outperform other deep SNNs trained with tandem learning, surrogate gradient learning, or converted from deep ANNs. Converted SNNs require long simulation times to reach reasonable accuracies while our proxy learning leads to efficient SNNs with much smaller simulation times. The source codes of the proposed method are publicly available at https://github.com/SRKH/ProxyLearning.", "published": "2021-09-27T17:29:51Z", "version": 3}, {"aid": "2109.13392", "authors": ["Volker Tresp", "Sahand Sharifzadeh", "Hang Li", "Dario Konopatzki", "Yunpu Ma"], "title": "The Tensor Brain: A Unified Theory of Perception, Memory and Semantic Decoding", "url": "http://arxiv.org/pdf/2109.13392v6", "summary": "We present a unified computational theory of an agent's perception and memory. In our model, perception, episodic memory, and semantic memory are realized by different operational modes of the oscillating interactions between a symbolic index layer and a subsymbolic representation layer. The two layers form a bilayer tensor network (BTN). Although memory appears to be about the past, its main purpose is to support the agent in the present and the future. Recent episodic memory provides the agent with a sense of the here and now. Remote episodic memory retrieves relevant past experiences to provide information about possible future scenarios. This aids the agent in decision-making. \"Future\" episodic memory, based on expected future events, guides planning and action. Semantic memory retrieves specific information, which is not delivered by current perception, and defines priors for future observations. We argue that it is important for the agent to encode individual entities, not just classes and attributes. We demonstrate that a form of self-supervised learning can acquire new concepts and refine existing ones. We test our model on a standard benchmark data set, which we expanded to contain richer representations for attributes, classes, and individuals. Our key hypothesis is that obtaining a better understanding of perception and memory is a crucial prerequisite to comprehending human-level intelligence.", "published": "2021-09-27T23:32:44Z", "version": 6}, {"aid": "2109.15089", "authors": ["Mufeng Tang", "Yibo Yang", "Yali Amit"], "title": "Biologically Plausible Training Mechanisms for Self-Supervised Learning in Deep Networks", "url": "http://arxiv.org/pdf/2109.15089v4", "summary": "We develop biologically plausible training mechanisms for self-supervised learning (SSL) in deep networks. Specifically, by biological plausible training we mean (i) All updates of weights are based on current activities of pre-synaptic units and current, or activity retrieved from short term memory of post synaptic units, including at the top-most error computing layer, (ii) Complex computations such as normalization, inner products and division are avoided (iii) Asymmetric connections between units, (iv) Most learning is carried out in an unsupervised manner. SSL with a contrastive loss satisfies the third condition as it does not require labelled data and it introduces robustness to observed perturbations of objects, which occur naturally as objects or observer move in 3d and with variable lighting over time. We propose a contrastive hinge based loss whose error involves simple local computations satisfying (ii), as opposed to the standard contrastive losses employed in the literature, which do not lend themselves easily to implementation in a network architecture due to complex computations involving ratios and inner products. Furthermore we show that learning can be performed with one of two more plausible alternatives to backpropagation that satisfy conditions (i) and (ii). The first is difference target propagation (DTP) and the second is layer-wise learning (LL), where each layer is directly connected to a layer computing the loss error. Both methods represent alternatives to the symmetric weight issue of backpropagation. By training convolutional neural networks (CNNs) with SSL and DTP, LL, we find that our proposed framework achieves comparable performance to standard BP learning downstream linear classifier evaluation of the learned embeddings.", "published": "2021-09-30T12:56:57Z", "version": 4}, {"aid": "2110.01640", "authors": ["Sreeraj Ramachandran", "Aakash Varma Nadimpalli", "Ajita Rattani"], "title": "An Experimental Evaluation on Deepfake Detection using Deep Face Recognition", "url": "http://arxiv.org/pdf/2110.01640v1", "summary": "Significant advances in deep learning have obtained hallmark accuracy rates for various computer vision applications. However, advances in deep generative models have also led to the generation of very realistic fake content, also known as deepfakes, causing a threat to privacy, democracy, and national security. Most of the current deepfake detection methods are deemed as a binary classification problem in distinguishing authentic images or videos from fake ones using two-class convolutional neural networks (CNNs). These methods are based on detecting visual artifacts, temporal or color inconsistencies produced by deep generative models. However, these methods require a large amount of real and fake data for model training and their performance drops significantly in cross dataset evaluation with samples generated using advanced deepfake generation techniques. In this paper, we thoroughly evaluate the efficacy of deep face recognition in identifying deepfakes, using different loss functions and deepfake generation techniques. Experimental investigations on challenging Celeb-DF and FaceForensics++ deepfake datasets suggest the efficacy of deep face recognition in identifying deepfakes over two-class CNNs and the ocular modality. Reported results suggest a maximum Area Under Curve (AUC) of 0.98 and an Equal Error Rate (EER) of 7.1% in detecting deepfakes using face recognition on the Celeb-DF dataset. This EER is lower by 16.6% compared to the EER obtained for the two-class CNN and the ocular modality on the Celeb-DF dataset. Further on the FaceForensics++ dataset, an AUC of 0.99 and EER of 2.04% were obtained. The use of biometric facial recognition technology has the advantage of bypassing the need for a large amount of fake data for model training and obtaining better generalizability to evolving deepfake creation techniques.", "published": "2021-10-04T18:02:56Z", "version": 1}, {"aid": "2110.01765", "authors": ["James Martens", "Andy Ballard", "Guillaume Desjardins", "Grzegorz Swirszcz", "Valentin Dalibard", "Jascha Sohl-Dickstein", "Samuel S. Schoenholz"], "title": "Rapid training of deep neural networks without skip connections or normalization layers using Deep Kernel Shaping", "url": "http://arxiv.org/pdf/2110.01765v1", "summary": "Using an extended and formalized version of the Q/C map analysis of Poole et al. (2016), along with Neural Tangent Kernel theory, we identify the main pathologies present in deep networks that prevent them from training fast and generalizing to unseen data, and show how these can be avoided by carefully controlling the \"shape\" of the network's initialization-time kernel function. We then develop a method called Deep Kernel Shaping (DKS), which accomplishes this using a combination of precise parameter initialization, activation function transformations, and small architectural tweaks, all of which preserve the model class. In our experiments we show that DKS enables SGD training of residual networks without normalization layers on Imagenet and CIFAR-10 classification tasks at speeds comparable to standard ResNetV2 and Wide-ResNet models, with only a small decrease in generalization performance. And when using K-FAC as the optimizer, we achieve similar results for networks without skip connections. Our results apply for a large variety of activation functions, including those which traditionally perform very badly, such as the logistic sigmoid. In addition to DKS, we contribute a detailed analysis of skip connections, normalization layers, special activation functions like RELU and SELU, and various initialization schemes, explaining their effectiveness as alternative (and ultimately incomplete) ways of \"shaping\" the network's initialization-time kernel.", "published": "2021-10-05T00:49:36Z", "version": 1}, {"aid": "2110.02861", "authors": ["Tim Dettmers", "Mike Lewis", "Sam Shleifer", "Luke Zettlemoyer"], "title": "8-bit Optimizers via Block-wise Quantization", "url": "http://arxiv.org/pdf/2110.02861v2", "summary": "Stateful optimizers maintain gradient statistics over time, e.g., the exponentially smoothed sum (SGD with momentum) or squared sum (Adam) of past gradient values. This state can be used to accelerate optimization compared to plain stochastic gradient descent but uses memory that might otherwise be allocated to model parameters, thereby limiting the maximum size of models trained in practice. In this paper, we develop the first optimizers that use 8-bit statistics while maintaining the performance levels of using 32-bit optimizer states. To overcome the resulting computational, quantization, and stability challenges, we develop block-wise dynamic quantization. Block-wise quantization divides input tensors into smaller blocks that are independently quantized. Each block is processed in parallel across cores, yielding faster optimization and high precision quantization. To maintain stability and performance, we combine block-wise quantization with two additional changes: (1) dynamic quantization, a form of non-linear optimization that is precise for both large and small magnitude values, and (2) a stable embedding layer to reduce gradient variance that comes from the highly non-uniform distribution of input tokens in language models. As a result, our 8-bit optimizers maintain 32-bit performance with a small fraction of the memory footprint on a range of tasks, including 1.5B parameter language modeling, GLUE finetuning, ImageNet classification, WMT'14 machine translation, MoCo v2 contrastive ImageNet pretraining+finetuning, and RoBERTa pretraining, without changes to the original optimizer hyperparameters. We open-source our 8-bit optimizers as a drop-in replacement that only requires a two-line code change.", "published": "2021-10-06T15:43:20Z", "version": 2}, {"aid": "2110.04181", "authors": ["Bo Zhao", "Hakan Bilen"], "title": "Dataset Condensation with Distribution Matching", "url": "http://arxiv.org/pdf/2110.04181v3", "summary": "Computational cost of training state-of-the-art deep models in many learning problems is rapidly increasing due to more sophisticated models and larger datasets. A recent promising direction for reducing training cost is dataset condensation that aims to replace the original large training set with a significantly smaller learned synthetic set while preserving the original information. While training deep models on the small set of condensed images can be extremely fast, their synthesis remains computationally expensive due to the complex bi-level optimization and second-order derivative computation. In this work, we propose a simple yet effective method that synthesizes condensed images by matching feature distributions of the synthetic and original training images in many sampled embedding spaces. Our method significantly reduces the synthesis cost while achieving comparable or better performance. Thanks to its efficiency, we apply our method to more realistic and larger datasets with sophisticated neural architectures and obtain a significant performance boost. We also show promising practical benefits of our method in continual learning and neural architecture search.", "published": "2021-10-08T15:02:30Z", "version": 3}, {"aid": "2110.06804", "authors": ["Chunyu Yuan", "Sos S. Agaian"], "title": "A comprehensive review of Binary Neural Network", "url": "http://arxiv.org/pdf/2110.06804v4", "summary": "Deep learning (DL) has recently changed the development of intelligent systems and is widely adopted in many real-life applications. Despite their various benefits and potentials, there is a high demand for DL processing in different computationally limited and energy-constrained devices. It is natural to study game-changing technologies such as Binary Neural Networks (BNN) to increase deep learning capabilities. Recently remarkable progress has been made in BNN since they can be implemented and embedded on tiny restricted devices and save a significant amount of storage, computation cost, and energy consumption. However, nearly all BNN acts trade with extra memory, computation cost, and higher performance. This article provides a complete overview of recent developments in BNN. This article focuses exclusively on 1-bit activations and weights 1-bit convolution networks, contrary to previous surveys in which low-bit works are mixed in. It conducted a complete investigation of BNN's development -from their predecessors to the latest BNN algorithms/techniques, presenting a broad design pipeline and discussing each module's variants. Along the way, it examines BNN (a) purpose: their early successes and challenges; (b) BNN optimization: selected representative works that contain essential optimization techniques; (c) deployment: open-source frameworks for BNN modeling and development; (d) terminal: efficient computing architectures and devices for BNN and (e) applications: diverse applications with BNN. Moreover, this paper discusses potential directions and future research opportunities in each section.", "published": "2021-10-11T22:44:15Z", "version": 4}, {"aid": "2110.05651", "authors": ["Felix Petersen", "Christian Borgelt", "Hilde Kuehne", "Oliver Deussen"], "title": "Learning with Algorithmic Supervision via Continuous Relaxations", "url": "http://arxiv.org/pdf/2110.05651v2", "summary": "The integration of algorithmic components into neural architectures has gained increased attention recently, as it allows training neural networks with new forms of supervision such as ordering constraints or silhouettes instead of using ground truth labels. Many approaches in the field focus on the continuous relaxation of a specific task and show promising results in this context. But the focus on single tasks also limits the applicability of the proposed concepts to a narrow range of applications. In this work, we build on those ideas to propose an approach that allows to integrate algorithms into end-to-end trainable neural network architectures based on a general approximation of discrete conditions. To this end, we relax these conditions in control structures such as conditional statements, loops, and indexing, so that resulting algorithms are smoothly differentiable. To obtain meaningful gradients, each relevant variable is perturbed via logistic distributions and the expectation value under this perturbation is approximated. We evaluate the proposed continuous relaxation model on four challenging tasks and show that it can keep up with relaxations specifically designed for each individual task.", "published": "2021-10-11T23:52:42Z", "version": 2}, {"aid": "2110.08649", "authors": ["Avishek Joey Bose", "Marcus Brubaker", "Ivan Kobyzev"], "title": "Equivariant Finite Normalizing Flows", "url": "http://arxiv.org/pdf/2110.08649v2", "summary": "Generative modeling seeks to uncover the underlying factors that give rise to observed data that can often be modeled as the natural symmetries that manifest themselves through invariances and equivariances to certain transformation laws. However, current approaches to representing these symmetries are couched in the formalism of continuous normalizing flows that require the construction of equivariant vector fields -- inhibiting their simple application to conventional higher dimensional generative modelling domains like natural images. In this paper, we focus on building equivariant normalizing flows using discrete layers. We first theoretically prove the existence of an equivariant map for compact groups whose actions are on compact spaces. We further introduce three new equivariant flows: $G$-Residual Flows, $G$-Coupling Flows, and $G$-Inverse Autoregressive Flows that elevate classical Residual, Coupling, and Inverse Autoregressive Flows with equivariant maps to a prescribed group $G$. Our construction of $G$-Residual Flows are also universal, in the sense that we prove an $G$-equivariant diffeomorphism can be exactly mapped by a $G$-residual flow. Finally, we complement our theoretical insights with demonstrative experiments -- for the first time -- on image datasets like CIFAR-10 and show $G$-Equivariant Finite Normalizing flows lead to increased data efficiency, faster convergence, and improved likelihood estimates.", "published": "2021-10-16T20:16:00Z", "version": 2}, {"aid": "2110.08890", "authors": ["Han Cai", "Chuang Gan", "Ji Lin", "Song Han"], "title": "Network Augmentation for Tiny Deep Learning", "url": "http://arxiv.org/pdf/2110.08890v2", "summary": "We introduce Network Augmentation (NetAug), a new training method for improving the performance of tiny neural networks. Existing regularization techniques (e.g., data augmentation, dropout) have shown much success on large neural networks by adding noise to overcome over-fitting. However, we found these techniques hurt the performance of tiny neural networks. We argue that training tiny models are different from large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, NetAug augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision, in addition to functioning as an independent model. At test time, only the tiny model is used for inference, incurring zero inference overhead. We demonstrate the effectiveness of NetAug on image classification and object detection. NetAug consistently improves the performance of tiny models, achieving up to 2.2% accuracy improvement on ImageNet. On object detection, achieving the same level of performance, NetAug requires 41% fewer MACs on Pascal VOC and 38% fewer MACs on COCO than the baseline.", "published": "2021-10-17T18:48:41Z", "version": 2}, {"aid": "2110.10303", "authors": ["Devansh Arpit", "Aadyot Bhatnagar", "Huan Wang", "Caiming Xiong"], "title": "Momentum Contrastive Autoencoder: Using Contrastive Learning for Latent Space Distribution Matching in WAE", "url": "http://arxiv.org/pdf/2110.10303v2", "summary": "Wasserstein autoencoder (WAE) shows that matching two distributions is equivalent to minimizing a simple autoencoder (AE) loss under the constraint that the latent space of this AE matches a pre-specified prior distribution. This latent space distribution matching is a core component of WAE, and a challenging task. In this paper, we propose to use the contrastive learning framework that has been shown to be effective for self-supervised representation learning, as a means to resolve this problem. We do so by exploiting the fact that contrastive learning objectives optimize the latent space distribution to be uniform over the unit hyper-sphere, which can be easily sampled from. We show that using the contrastive learning framework to optimize the WAE loss achieves faster convergence and more stable optimization compared with existing popular algorithms for WAE. This is also reflected in the FID scores on CelebA and CIFAR-10 datasets, and the realistic generated image quality on the CelebA-HQ dataset.", "published": "2021-10-19T22:55:47Z", "version": 2}, {"aid": "2110.11334", "authors": ["Jingkang Yang", "Kaiyang Zhou", "Yixuan Li", "Ziwei Liu"], "title": "Generalized Out-of-Distribution Detection: A Survey", "url": "http://arxiv.org/pdf/2110.11334v3", "summary": "Out-of-distribution (OOD) detection is critical to ensuring the reliability and safety of machine learning systems. For instance, in autonomous driving, we would like the driving system to issue an alert and hand over the control to humans when it detects unusual scenes or objects that it has never seen during training time and cannot make a safe decision. The term, OOD detection, first emerged in 2017 and since then has received increasing attention from the research community, leading to a plethora of methods developed, ranging from classification-based to density-based to distance-based ones. Meanwhile, several other problems, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD), are closely related to OOD detection in terms of motivation and methodology. Despite common goals, these topics develop in isolation, and their subtle differences in definition and problem setting often confuse readers and practitioners. In this survey, we first present a unified framework called generalized OOD detection, which encompasses the five aforementioned problems, i.e., AD, ND, OSR, OOD detection, and OD. Under our framework, these five problems can be seen as special cases or sub-tasks, and are easier to distinguish. We then review each of these five areas by summarizing their recent technical developments, with a special focus on OOD detection methodologies. We conclude this survey with open challenges and potential research directions.", "published": "2021-10-21T17:59:41Z", "version": 3}, {"aid": "2110.11940", "authors": ["Scott C. Lowe", "Robert Earle", "Jason d'Eon", "Thomas Trappenberg", "Sageev Oore"], "title": "Logical Activation Functions: Logit-space equivalents of Probabilistic Boolean Operators", "url": "http://arxiv.org/pdf/2110.11940v2", "summary": "The choice of activation functions and their motivation is a long-standing issue within the neural network community. Neuronal representations within artificial neural networks are commonly understood as logits, representing the log-odds score of presence of features within the stimulus. We derive logit-space operators equivalent to probabilistic Boolean logic-gates AND, OR, and XNOR for independent probabilities. Such theories are important to formalize more complex dendritic operations in real neurons, and these operations can be used as activation functions within a neural network, introducing probabilistic Boolean-logic as the core operation of the neural network. Since these functions involve taking multiple exponents and logarithms, they are computationally expensive and not well suited to be directly used within neural networks. Consequently, we construct efficient approximations named $\\text{AND}_\\text{AIL}$ (the AND operator Approximate for Independent Logits), $\\text{OR}_\\text{AIL}$, and $\\text{XNOR}_\\text{AIL}$, which utilize only comparison and addition operations, have well-behaved gradients, and can be deployed as activation functions in neural networks. Like MaxOut, $\\text{AND}_\\text{AIL}$ and $\\text{OR}_\\text{AIL}$ are generalizations of ReLU to two-dimensions. While our primary aim is to formalize dendritic computations within a logit-space probabilistic-Boolean framework, we deploy these new activation functions, both in isolation and in conjunction to demonstrate their effectiveness on a variety of tasks including image classification, transfer learning, abstract reasoning, and compositional zero-shot learning.", "published": "2021-10-22T17:49:42Z", "version": 2}, {"aid": "2110.12661", "authors": ["Jiawei Zhao", "Florian Sch\u00e4fer", "Anima Anandkumar"], "title": "ZerO Initialization: Initializing Neural Networks with only Zeros and Ones", "url": "http://arxiv.org/pdf/2110.12661v3", "summary": "Deep neural networks are usually initialized with random weights, with adequately selected initial variance to ensure stable signal propagation during training. However, selecting the appropriate variance becomes challenging especially as the number of layers grows. In this work, we replace random weight initialization with a fully deterministic initialization scheme, viz., ZerO, which initializes the weights of networks with only zeros and ones (up to a normalization factor), based on identity and Hadamard transforms. Through both theoretical and empirical studies, we demonstrate that ZerO is able to train networks without damaging their expressivity. Applying ZerO on ResNet achieves state-of-the-art performance on various datasets, including ImageNet, which suggests random weights may be unnecessary for network initialization. In addition, ZerO has many benefits, such as training ultra deep networks (without batch-normalization), exhibiting low-rank learning trajectories that result in low-rank and sparse solutions, and improving training reproducibility.", "published": "2021-10-25T06:17:33Z", "version": 3}, {"aid": "2111.00070", "authors": ["Feng Zhu", "Andrew R. Sedler", "Harrison A. Grier", "Nauman Ahad", "Mark A. Davenport", "Matthew T. Kaufman", "Andrea Giovannucci", "Chethan Pandarinath"], "title": "Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time", "url": "http://arxiv.org/pdf/2111.00070v1", "summary": "Modern neural interfaces allow access to the activity of up to a million neurons within brain circuits. However, bandwidth limits often create a trade-off between greater spatial sampling (more channels or pixels) and the temporal frequency of sampling. Here we demonstrate that it is possible to obtain spatio-temporal super-resolution in neuronal time series by exploiting relationships among neurons, embedded in latent low-dimensional population dynamics. Our novel neural network training strategy, selective backpropagation through time (SBTT), enables learning of deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. We test SBTT applied to sequential autoencoders and demonstrate more efficient and higher-fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data. In electrophysiology, SBTT enables accurate inference of neuronal population dynamics with lower interface bandwidths, providing an avenue to significant power savings for implanted neuroelectronic interfaces. In applications to two-photon calcium imaging, SBTT accurately uncovers high-frequency temporal structure underlying neural population activity, substantially outperforming the current state-of-the-art. Finally, we demonstrate that performance could be further improved by using limited, high-bandwidth sampling to pretrain dynamics models, and then using SBTT to adapt these models for sparsely-sampled data.", "published": "2021-10-29T20:18:29Z", "version": 1}, {"aid": "2111.00599", "authors": ["Armin Hadzic", "Grace M. Hwang", "Kechen Zhang", "Kevin M. Schultz", "Joseph D. Monaco"], "title": "Bayesian optimization of distributed neurodynamical controller models for spatial navigation", "url": "http://arxiv.org/pdf/2111.00599v1", "summary": "Dynamical systems models for controlling multi-agent swarms have demonstrated advances toward resilient, decentralized navigation algorithms. We previously introduced the NeuroSwarms controller, in which agent-based interactions were modeled by analogy to neuronal network interactions, including attractor dynamics and phase synchrony, that have been theorized to operate within hippocampal place-cell circuits in navigating rodents. This complexity precludes linear analyses of stability, controllability, and performance typically used to study conventional swarm models. Further, tuning dynamical controllers by hand or grid search is often inadequate due to the complexity of objectives, dimensionality of model parameters, and computational costs of simulation-based sampling. Here, we present a framework for tuning dynamical controller models of autonomous multi-agent systems based on Bayesian Optimization (BayesOpt). Our approach utilizes a task-dependent objective function to train Gaussian Processes (GPs) as surrogate models to achieve adaptive and efficient exploration of a dynamical controller model's parameter space. We demonstrate this approach by studying an objective function selecting for NeuroSwarms behaviors that cooperatively localize and capture spatially distributed rewards under time pressure. We generalized task performance across environments by combining scores for simulations in distinct geometries. To validate search performance, we compared high-dimensional clustering for high- vs. low-likelihood parameter points by visualizing sample trajectories in Uniform Manifold Approximation and Projection (UMAP) embeddings. Our findings show that adaptive, sample-efficient evaluation of the self-organizing behavioral capacities of complex systems, including dynamical swarm controllers, can accelerate the translation of neuroscientific theory to applied domains.", "published": "2021-10-31T21:43:06Z", "version": 1}, {"aid": "2111.00737", "authors": ["Roman Mikhailov"], "title": "Homotopy patterns in group theory", "url": "http://arxiv.org/pdf/2111.00737v1", "summary": "This is a survey. The main subject of this survey is the homotopical or homological nature of certain structures which appear in classical problems about groups, Lie rings and group rings. It is well known that the (generalized) dimension subgroups have complicated combinatorial theories. In this paper we show that, in certain cases, the complexity of these theories is based on homotopy theory. The derived functors of non-additive functors, homotopy groups of spheres, group homology etc appear naturally in problems formulated in purely group-theoretical terms. The variety of structures appearing in the considered context is very rich. In order to illustrate it, we present this survey as a trip passing through examples having a similar nature.", "published": "2021-11-01T07:22:17Z", "version": 1}, {"aid": "2111.00772", "authors": ["Alexandros Stergiou", "Ronald Poppe"], "title": "AdaPool: Exponential Adaptive Pooling for Information-Retaining Downsampling", "url": "http://arxiv.org/pdf/2111.00772v3", "summary": "Pooling layers are essential building blocks of convolutional neural networks (CNNs), to reduce computational overhead and increase the receptive fields of proceeding convolutional operations. Their goal is to produce downsampled volumes that closely resemble the input volume while, ideally, also being computationally and memory efficient. Meeting both these requirements remains a challenge. To this end, we propose an adaptive and exponentially weighted pooling method: adaPool. Our method learns a regional-specific fusion of two sets of pooling kernels that are based on the exponent of the Dice-Sorensen coefficient and the exponential maximum, respectively. AdaPool improves the preservation of detail on a range of tasks including image and video classification and object detection. A key property of adaPool is its bidirectional nature. In contrast to common pooling methods, the learned weights can also be used to upsample activation maps. We term this method adaUnPool. We evaluate adaUnPool on image and video super-resolution and frame interpolation. For benchmarking, we introduce Inter4K, a novel high-quality, high frame-rate video dataset. Our experiments demonstrate that adaPool systematically achieves better results across tasks and backbones, while introducing a minor additional computational and memory overhead.", "published": "2021-11-01T08:50:37Z", "version": 3}, {"aid": "2111.03122", "authors": ["Marie-Constance Corsi", "Sylvain Chevallier", "Fabrizio De Vico Fallani", "Florian Yger"], "title": "Functional connectivity ensemble method to enhance BCI performance (FUCONE)", "url": "http://arxiv.org/pdf/2111.03122v2", "summary": "Functional connectivity is a key approach to investigate oscillatory activities of the brain that provides important insights on the underlying dynamic of neuronal interactions and that is mostly applied for brain activity analysis. Building on the advances in information geometry for brain-computer interface, we propose a novel framework that combines functional connectivity estimators and covariance-based pipelines to classify mental states, such as motor imagery. A Riemannian classifier is trained for each estimator and an ensemble classifier combines the decisions in each feature space. A thorough assessment of the functional connectivity estimators is provided and the best performing pipeline, called FUCONE, is evaluated on different conditions and datasets. Using a meta-analysis to aggregate results across datasets, FUCONE performed significantly better than all state-of-the-art methods. The performance gain is mostly imputable to the improved diversity of the feature spaces, increasing the robustness of the ensemble classifier with respect to the inter- and intra-subject variability.", "published": "2021-11-04T19:40:08Z", "version": 2}, {"aid": "2111.03270", "authors": ["Virender Ranga", "Shivam Gupta", "Jyoti Meena", "Priyansh Agrawal"], "title": "Automated Human Mind Reading Using EEG Signals for Seizure Detection", "url": "http://arxiv.org/pdf/2111.03270v1", "summary": "Epilepsy is one of the most occurring neurological disease globally emerged back in 4000 BC. It is affecting around 50 million people of all ages these days. The trait of this disease is recurrent seizures. In the past few decades, the treatments available for seizure control have improved a lot with the advancements in the field of medical science and technology. Electroencephalogram (EEG) is a widely used technique for monitoring the brain activity and widely popular for seizure region detection. It is performed before surgery and also to predict seizure at the time operation which is useful in neuro stimulation device. But in most of cases visual examination is done by neurologist in order to detect and classify patterns of the disease but this requires a lot of pre-domain knowledge and experience. This all in turns put a pressure on neurosurgeons and leads to time wastage and also reduce their accuracy and efficiency. There is a need of some automated systems in arena of information technology like use of neural networks in deep learning which can assist neurologists. In the present paper, a model is proposed to give an accuracy of 98.33% which can be used for development of automated systems. The developed system will significantly help neurologists in their performance.", "published": "2021-11-05T05:31:33Z", "version": 1}, {"aid": "2111.04335", "authors": ["Pieter Adriaans"], "title": "Differential information theory", "url": "http://arxiv.org/pdf/2111.04335v2", "summary": "This paper presents a new foundational approach to information theory based on the concept of the information efficiency of a recursive function, which is defined as the difference between the information in the input and the output. The theory allows us to study planar representations of various infinite domains. Dilation theory studies the information effects of recursive operations in terms of topological deformations of the plane. I show that the well-known class of finite sets of natural numbers behaves erratically under such transformations. It is subject to phase transitions that in some cases have a fractal nature. The class is \\emph{semi-countable}: there is no intrinsic information theory for this class and there are no efficient methods for systematic search.   There is a relation between the information efficiency of the function and the time needed to compute it: a deterministic computational process can destroy information in linear time, but it can only generate information at logarithmic speed. Checking functions for problems in $NP$ are information discarding. Consequently, when we try to solve a decision problem based on an efficiently computable checking function, we need exponential time to reconstruct the information destroyed by such a function. At the end of the paper I sketch a systematic taxonomy for problems in $NP$.", "published": "2021-11-08T08:53:29Z", "version": 2}, {"aid": "2111.05826", "authors": ["Chitwan Saharia", "William Chan", "Huiwen Chang", "Chris A. Lee", "Jonathan Ho", "Tim Salimans", "David J. Fleet", "Mohammad Norouzi"], "title": "Palette: Image-to-Image Diffusion Models", "url": "http://arxiv.org/pdf/2111.05826v2", "summary": "This paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG restoration. Our simple implementation of image-to-image diffusion models outperforms strong GAN and regression baselines on all tasks, without task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss or sophisticated new techniques needed. We uncover the impact of an L2 vs. L1 loss in the denoising diffusion objective on sample diversity, and demonstrate the importance of self-attention in the neural architecture through empirical studies. Importantly, we advocate a unified evaluation protocol based on ImageNet, with human evaluation and sample quality scores (FID, Inception Score, Classification Accuracy of a pre-trained ResNet-50, and Perceptual Distance against original images). We expect this standardized evaluation protocol to play a role in advancing image-to-image translation research. Finally, we show that a generalist, multi-task diffusion model performs as well or better than task-specific specialist counterparts. Check out https://diffusion-palette.github.io for an overview of the results.", "published": "2021-11-10T17:49:29Z", "version": 2}, {"aid": "2111.06021", "authors": ["Junjie Li", "Yixin Zhang", "Zilei Wang", "Saihui Hou", "Keyu Tu", "Man Zhang"], "title": "Probabilistic Contrastive Learning for Domain Adaptation", "url": "http://arxiv.org/pdf/2111.06021v6", "summary": "Contrastive learning has shown impressive success in enhancing feature discriminability for various visual tasks in a self-supervised manner, but the standard contrastive paradigm (features+$\\ell_{2}$ normalization) has limited benefits when applied in domain adaptation. We find that this is mainly because the class weights (weights of the final fully connected layer) are ignored in the domain adaptation optimization process, which makes it difficult for features to cluster around the corresponding class weights. To solve this problem, we propose the \\emph{simple but powerful} Probabilistic Contrastive Learning (PCL), which moves beyond the standard paradigm by removing $\\ell_{2}$ normalization and replacing the features with probabilities. PCL can guide the probability distribution towards a one-hot configuration, thus minimizing the discrepancy between features and class weights. We conduct extensive experiments to validate the effectiveness of PCL and observe consistent performance gains on five tasks, i.e., Unsupervised/Semi-Supervised Domain Adaptation (UDA/SSDA), Semi-Supervised Learning (SSL), UDA Detection and Semantic Segmentation. Notably, for UDA Semantic Segmentation on SYNTHIA, PCL surpasses the sophisticated CPSL-D by $>\\!2\\%$ in terms of mean IoU with a much lower training cost (PCL: 1*3090, 5 days v.s. CPSL-D: 4*V100, 11 days). Code is available at https://github.com/ljjcoder/Probabilistic-Contrastive-Learning.", "published": "2021-11-11T02:08:07Z", "version": 6}, {"aid": "2111.09266", "authors": ["Yoshua Bengio", "Salem Lahlou", "Tristan Deleu", "Edward J. Hu", "Mo Tiwari", "Emmanuel Bengio"], "title": "GFlowNet Foundations", "url": "http://arxiv.org/pdf/2111.09266v4", "summary": "Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entropy and mutual information, sampling from a Pareto frontier, connections to reward-maximizing policies, and extensions to stochastic environments, continuous actions and modular energy functions.", "published": "2021-11-17T17:59:54Z", "version": 4}, {"aid": "2111.09953", "authors": ["Mark A. Kramer"], "title": "Golden rhythms as a theoretical framework for cross-frequency organization", "url": "http://arxiv.org/pdf/2111.09953v6", "summary": "While brain rhythms appear fundamental to brain function, why brain rhythms consistently organize into the small set of discrete frequency bands observed remains unknown. Here we propose that rhythms separated by factors of the golden ratio ($\\phi=(1+ \\sqrt{5})/2$) optimally support segregation and cross-frequency integration of information transmission in the brain. Organized by the golden ratio, pairs of transient rhythms support multiplexing by reducing interference between separate communication channels, and triplets of transient rhythms support integration of signals to establish a hierarchy of cross-frequency interactions. We illustrate this framework in simulation and apply this framework to propose four hypotheses.", "published": "2021-11-18T21:50:54Z", "version": 6}, {"aid": "2111.09996", "authors": ["Daniel Rebain", "Mark Matthews", "Kwang Moo Yi", "Dmitry Lagun", "Andrea Tagliasacchi"], "title": "LOLNeRF: Learn from One Look", "url": "http://arxiv.org/pdf/2111.09996v2", "summary": "We present a method for learning a generative 3D model based on neural radiance fields, trained solely from data with only single views of each object. While generating realistic images is no longer a difficult task, producing the corresponding 3D structure such that they can be rendered from different views is non-trivial. We show that, unlike existing methods, one does not need multi-view data to achieve this goal. Specifically, we show that by reconstructing many images aligned to an approximate canonical pose with a single network conditioned on a shared latent space, you can learn a space of radiance fields that models shape and appearance for a class of objects. We demonstrate this by training models to reconstruct object categories using datasets that contain only one view of each subject without depth or geometry information. Our experiments show that we achieve state-of-the-art results in novel view synthesis and high-quality results for monocular depth prediction.", "published": "2021-11-19T01:20:01Z", "version": 2}, {"aid": "2111.10694", "authors": ["Sergei O. Ivanov"], "title": "An overview of rationalization theories of non-simply connected spaces and non-nilpotent groups", "url": "http://arxiv.org/pdf/2111.10694v3", "summary": "We give an overview of five rationalization theories for spaces (Bousfield-Kan's $\\mathbb Q$-completion; Sullivan's rationalization; Bousfield's homology rationalization; Casacuberta-Peschke's $\\Omega$-rationalization; G\\'{o}mez-Tato-Halperin-Tanr\\'{e}'s $\\pi_1$-fiberwise rationalization) that extend the classical rationalization of simply connected spaces. We also give an overview of the corresponding rationalization theories for groups ($\\mathbb Q$-completion; $H\\mathbb Q$-localization; Baumslag rationalization) that extend the classical Malcev completion.", "published": "2021-11-20T22:35:57Z", "version": 3}, {"aid": "2111.10734", "authors": ["Sheng Liu", "Aakash Kaku", "Weicheng Zhu", "Matan Leibovich", "Sreyas Mohan", "Boyang Yu", "Haoxiang Huang", "Laure Zanna", "Narges Razavian", "Jonathan Niles-Weed", "Carlos Fernandez-Granda"], "title": "Deep Probability Estimation", "url": "http://arxiv.org/pdf/2111.10734v4", "summary": "Reliable probability estimation is of crucial importance in many real-world applications where there is inherent (aleatoric) uncertainty. Probability-estimation models are trained on observed outcomes (e.g. whether it has rained or not, or whether a patient has died or not), because the ground-truth probabilities of the events of interest are typically unknown. The problem is therefore analogous to binary classification, with the difference that the objective is to estimate probabilities rather than predicting the specific outcome. This work investigates probability estimation from high-dimensional data using deep neural networks. There exist several methods to improve the probabilities generated by these models but they mostly focus on model (epistemic) uncertainty. For problems with inherent uncertainty, it is challenging to evaluate performance without access to ground-truth probabilities. To address this, we build a synthetic dataset to study and compare different computable metrics. We evaluate existing methods on the synthetic data as well as on three real-world probability estimation tasks, all of which involve inherent uncertainty: precipitation forecasting from radar images, predicting cancer patient survival from histopathology images, and predicting car crashes from dashcam videos. We also give a theoretical analysis of a model for high-dimensional probability estimation which reproduces several of the phenomena evinced in our experiments. Finally, we propose a new method for probability estimation using neural networks, which modifies the training process to promote output probabilities that are consistent with empirical probabilities computed from the data. The method outperforms existing approaches on most metrics on the simulated as well as real-world data.", "published": "2021-11-21T03:55:50Z", "version": 4}, {"aid": "2111.12417", "authors": ["Chenfei Wu", "Jian Liang", "Lei Ji", "Fan Yang", "Yuejian Fang", "Daxin Jiang", "Nan Duan"], "title": "N\u00dcWA: Visual Synthesis Pre-training for Neural visUal World creAtion", "url": "http://arxiv.org/pdf/2111.12417v1", "summary": "This paper presents a unified multimodal pre-trained model called N\\\"UWA that can generate new or manipulate existing visual data (i.e., images and videos) for various visual synthesis tasks. To cover language, image, and video at the same time for different scenarios, a 3D transformer encoder-decoder framework is designed, which can not only deal with videos as 3D data but also adapt to texts and images as 1D and 2D data, respectively. A 3D Nearby Attention (3DNA) mechanism is also proposed to consider the nature of the visual data and reduce the computational complexity. We evaluate N\\\"UWA on 8 downstream tasks. Compared to several strong baselines, N\\\"UWA achieves state-of-the-art results on text-to-image generation, text-to-video generation, video prediction, etc. Furthermore, it also shows surprisingly good zero-shot capabilities on text-guided image and video manipulation tasks. Project repo is https://github.com/microsoft/NUWA.", "published": "2021-11-24T11:02:12Z", "version": 1}, {"aid": "2111.12933", "authors": ["Tal Ridnik", "Gilad Sharir", "Avi Ben-Cohen", "Emanuel Ben-Baruch", "Asaf Noy"], "title": "ML-Decoder: Scalable and Versatile Classification Head", "url": "http://arxiv.org/pdf/2111.12933v2", "summary": "In this paper, we introduce ML-Decoder, a new attention-based classification head. ML-Decoder predicts the existence of class labels via queries, and enables better utilization of spatial data compared to global average pooling. By redesigning the decoder architecture, and using a novel group-decoding scheme, ML-Decoder is highly efficient, and can scale well to thousands of classes. Compared to using a larger backbone, ML-Decoder consistently provides a better speed-accuracy trade-off. ML-Decoder is also versatile - it can be used as a drop-in replacement for various classification heads, and generalize to unseen classes when operated with word queries. Novel query augmentations further improve its generalization ability. Using ML-Decoder, we achieve state-of-the-art results on several classification tasks: on MS-COCO multi-label, we reach 91.4% mAP; on NUS-WIDE zero-shot, we reach 31.1% ZSL mAP; and on ImageNet single-label, we reach with vanilla ResNet50 backbone a new top score of 80.7%, without extra data or distillation. Public code is available at: https://github.com/Alibaba-MIIL/ML_Decoder", "published": "2021-11-25T06:25:30Z", "version": 2}, {"aid": "2111.13470", "authors": ["Shantanu Jaiswal", "Basura Fernando", "Cheston Tan"], "title": "TDAM: Top-Down Attention Module for Contextually Guided Feature Selection in CNNs", "url": "http://arxiv.org/pdf/2111.13470v3", "summary": "Attention modules for Convolutional Neural Networks (CNNs) are an effective method to enhance performance on multiple computer-vision tasks. While existing methods appropriately model channel-, spatial- and self-attention, they primarily operate in a feedforward bottom-up manner. Consequently, the attention mechanism strongly depends on the local information of a single input feature map and does not incorporate relatively semantically-richer contextual information available at higher layers that can specify \"what and where to look\" in lower-level feature maps through top-down information flow.   Accordingly, in this work, we propose a lightweight top-down attention module (TDAM) that iteratively generates a \"visual searchlight\" to perform channel and spatial modulation of its inputs and outputs more contextually-relevant feature maps at each computation step. Our experiments indicate that TDAM enhances the performance of CNNs across multiple object-recognition benchmarks and outperforms prominent attention modules while being more parameter and memory efficient. Further, TDAM-based models learn to \"shift attention\" by localizing individual objects or features at each computation step without any explicit supervision resulting in a 5% improvement for ResNet50 on weakly-supervised object localization. Source code and models are publicly available at: https://github.com/shantanuj/TDAM_Top_down_attention_module .", "published": "2021-11-26T12:35:17Z", "version": 3}, {"aid": "2112.00390", "authors": ["Tomer Amit", "Tal Shaharbany", "Eliya Nachmani", "Lior Wolf"], "title": "SegDiff: Image Segmentation with Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2112.00390v3", "summary": "Diffusion Probabilistic Methods are employed for state-of-the-art image generation. In this work, we present a method for extending such models for performing image segmentation. The method learns end-to-end, without relying on a pre-trained backbone. The information in the input image and in the current estimation of the segmentation map is merged by summing the output of two encoders. Additional encoding layers and a decoder are then used to iteratively refine the segmentation map, using a diffusion model. Since the diffusion model is probabilistic, it is applied multiple times, and the results are merged into a final segmentation map. The new method produces state-of-the-art results on the Cityscapes validation set, the Vaihingen building segmentation benchmark, and the MoNuSeg dataset.", "published": "2021-12-01T10:17:25Z", "version": 3}, {"aid": "2112.01526", "authors": ["Yanghao Li", "Chao-Yuan Wu", "Haoqi Fan", "Karttikeya Mangalam", "Bo Xiong", "Jitendra Malik", "Christoph Feichtenhofer"], "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and Detection", "url": "http://arxiv.org/pdf/2112.01526v2", "summary": "In this paper, we study Multiscale Vision Transformers (MViTv2) as a unified architecture for image and video classification, as well as object detection. We present an improved version of MViT that incorporates decomposed relative positional embeddings and residual pooling connections. We instantiate this architecture in five sizes and evaluate it for ImageNet classification, COCO detection and Kinetics video recognition where it outperforms prior work. We further compare MViTv2s' pooling attention to window attention mechanisms where it outperforms the latter in accuracy/compute. Without bells-and-whistles, MViTv2 has state-of-the-art performance in 3 domains: 88.8% accuracy on ImageNet classification, 58.7 boxAP on COCO object detection as well as 86.1% on Kinetics-400 video classification. Code and models are available at https://github.com/facebookresearch/mvit.", "published": "2021-12-02T18:59:57Z", "version": 2}, {"aid": "2112.02902", "authors": ["Dawid Rymarczyk", "\u0141ukasz Struski", "Micha\u0142 G\u00f3rszczak", "Koryna Lewandowska", "Jacek Tabor", "Bartosz Zieli\u0144ski"], "title": "Interpretable Image Classification with Differentiable Prototypes Assignment", "url": "http://arxiv.org/pdf/2112.02902v2", "summary": "We introduce ProtoPool, an interpretable image classification model with a pool of prototypes shared by the classes. The training is more straightforward than in the existing methods because it does not require the pruning stage. It is obtained by introducing a fully differentiable assignment of prototypes to particular classes. Moreover, we introduce a novel focal similarity function to focus the model on the rare foreground features. We show that ProtoPool obtains state-of-the-art accuracy on the CUB-200-2011 and the Stanford Cars datasets, substantially reducing the number of prototypes. We provide a theoretical analysis of the method and a user study to show that our prototypes are more distinctive than those obtained with competitive methods.", "published": "2021-12-06T10:03:32Z", "version": 2}, {"aid": "2112.03860", "authors": ["Dongzhuo Li"], "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized by Deep Generative Models", "url": "http://arxiv.org/pdf/2112.03860v5", "summary": "Deep generative models such as GANs, normalizing flows, and diffusion models are powerful regularizers for inverse problems. They exhibit great potential for helping reduce ill-posedness and attain high-quality results. However, the latent tensors of such deep generative models can fall out of the desired high-dimensional standard Gaussian distribution during inversion, particularly in the presence of data noise and inaccurate forward models, leading to low-fidelity solutions. To address this issue, we propose to reparameterize and Gaussianize the latent tensors using novel differentiable data-dependent layers wherein custom operators are defined by solving optimization problems. These proposed layers constrain inverse problems to obtain high-fidelity in-distribution solutions. We validate our technique on three inversion tasks: compressive-sensing MRI, image deblurring, and eikonal tomography (a nonlinear PDE-constrained inverse problem) using two representative deep generative models: StyleGAN2 and Glow. Our approach achieves state-of-the-art performance in terms of accuracy and consistency.", "published": "2021-12-07T17:53:09Z", "version": 5}, {"aid": "2112.05149", "authors": ["Boah Kim", "Inhwa Han", "Jong Chul Ye"], "title": "DiffuseMorph: Unsupervised Deformable Image Registration Using Diffusion Model", "url": "http://arxiv.org/pdf/2112.05149v2", "summary": "Deformable image registration is one of the fundamental tasks in medical imaging. Classical registration algorithms usually require a high computational cost for iterative optimizations. Although deep-learning-based methods have been developed for fast image registration, it is still challenging to obtain realistic continuous deformations from a moving image to a fixed image with less topological folding problem. To address this, here we present a novel diffusion-model-based image registration method, called DiffuseMorph. DiffuseMorph not only generates synthetic deformed images through reverse diffusion but also allows image registration by deformation fields. Specifically, the deformation fields are generated by the conditional score function of the deformation between the moving and fixed images, so that the registration can be performed from continuous deformation by simply scaling the latent feature of the score. Experimental results on 2D facial and 3D medical image registration tasks demonstrate that our method provides flexible deformations with topology preservation capability.", "published": "2021-12-09T08:41:23Z", "version": 2}, {"aid": "2201.00308", "authors": ["Kushagra Pandey", "Avideep Mukherjee", "Piyush Rai", "Abhishek Kumar"], "title": "DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents", "url": "http://arxiv.org/pdf/2201.00308v3", "summary": "Diffusion probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, standard Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design novel conditional parameterizations for diffusion models. We show that the resulting model equips diffusion models with a low-dimensional VAE inferred latent code which can be used for downstream tasks like controllable synthesis. The proposed method also improves upon the speed vs quality tradeoff exhibited in standard unconditional DDPM/DDIM models (for instance, FID of 16.47 vs 34.36 using a standard DDIM on the CelebA-HQ-128 benchmark using T=10 reverse process steps) without having explicitly trained for such an objective. Furthermore, the proposed model exhibits synthesis quality comparable to state-of-the-art models on standard image synthesis benchmarks like CIFAR-10 and CelebA-64 while outperforming most existing VAE-based methods. Lastly, we show that the proposed method exhibits inherent generalization to different types of noise in the conditioning signal. For reproducibility, our source code is publicly available at https://github.com/kpandey008/DiffuseVAE.", "published": "2022-01-02T06:44:23Z", "version": 3}, {"aid": "2201.02233", "authors": ["Xuan Luo", "Zhen Han", "Lingkang Yang", "Lingling Zhang"], "title": "Consistent Style Transfer", "url": "http://arxiv.org/pdf/2201.02233v1", "summary": "Recently, attentional arbitrary style transfer methods have been proposed to achieve fine-grained results, which manipulates the point-wise similarity between content and style features for stylization. However, the attention mechanism based on feature points ignores the feature multi-manifold distribution, where each feature manifold corresponds to a semantic region in the image. Consequently, a uniform content semantic region is rendered by highly different patterns from various style semantic regions, producing inconsistent stylization results with visual artifacts. We proposed the progressive attentional manifold alignment (PAMA) to alleviate this problem, which repeatedly applies attention operations and space-aware interpolations. The attention operation rearranges style features dynamically according to the spatial distribution of content features. This makes the content and style manifolds correspond on the feature map. Then the space-aware interpolation adaptively interpolates between the corresponding content and style manifolds to increase their similarity. By gradually aligning the content manifolds to style manifolds, the proposed PAMA achieves state-of-the-art performance while avoiding the inconsistency of semantic regions. Codes are available at https://github.com/computer-vision2022/PAMA.", "published": "2022-01-06T20:19:35Z", "version": 1}, {"aid": "2201.02863", "authors": ["Jaewoo Song", "Fangzhen Lin"], "title": "PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++", "url": "http://arxiv.org/pdf/2201.02863v6", "summary": "Standard deep learning algorithms are implemented using floating-point real numbers. This presents an obstacle for implementing them on low-end devices which may not have dedicated floating-point units (FPUs). As a result, researchers in tinyML have considered machine learning algorithms that can train and run a deep neural network (DNN) on a low-end device using integer operations only. In this paper we propose PocketNN, a light and self-contained proof-of-concept framework in pure C++ for the training and inference of DNNs using only integers. Unlike other approaches, PocketNN directly operates on integers without requiring any explicit quantization algorithms or customized fixed-point formats. This was made possible by pocket activations, which are a family of activation functions devised for integer-only DNNs, and an emerging DNN training algorithm called direct feedback alignment (DFA). Unlike the standard backpropagation (BP), DFA trains each layer independently, thus avoiding integer overflow which is a key problem when using BP with integer-only operations. We used PocketNN to train some DNNs on two well-known datasets, MNIST and Fashion-MNIST. Our experiments show that the DNNs trained with our PocketNN achieved 96.98% and 87.7% accuracies on MNIST and Fashion-MNIST datasets, respectively. The accuracies are very close to the equivalent DNNs trained using BP with floating-point real number operations, such that accuracy degradations were just 1.02%p and 2.09%p, respectively. Finally, our PocketNN has high compatibility and portability for low-end devices as it is open source and implemented in pure C++ without any dependencies.", "published": "2022-01-08T16:52:34Z", "version": 6}, {"aid": "2201.03529", "authors": ["Utku Evci", "Vincent Dumoulin", "Hugo Larochelle", "Michael C. Mozer"], "title": "Head2Toe: Utilizing Intermediate Representations for Better Transfer Learning", "url": "http://arxiv.org/pdf/2201.03529v2", "summary": "Transfer-learning methods aim to improve performance in a data-scarce target domain using a model pretrained on a data-rich source domain. A cost-efficient strategy, linear probing, involves freezing the source model and training a new classification head for the target domain. This strategy is outperformed by a more costly but state-of-the-art method -- fine-tuning all parameters of the source model to the target domain -- possibly because fine-tuning allows the model to leverage useful information from intermediate layers which is otherwise discarded by the later pretrained layers. We explore the hypothesis that these intermediate layers might be directly exploited. We propose a method, Head-to-Toe probing (Head2Toe), that selects features from all layers of the source model to train a classification head for the target-domain. In evaluations on the VTAB-1k, Head2Toe matches performance obtained with fine-tuning on average while reducing training and storage cost hundred folds or more, but critically, for out-of-distribution transfer, Head2Toe outperforms fine-tuning.", "published": "2022-01-10T18:40:07Z", "version": 2}, {"aid": "2201.03545", "authors": ["Zhuang Liu", "Hanzi Mao", "Chao-Yuan Wu", "Christoph Feichtenhofer", "Trevor Darrell", "Saining Xie"], "title": "A ConvNet for the 2020s", "url": "http://arxiv.org/pdf/2201.03545v2", "summary": "The \"Roaring 20s\" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually \"modernize\" a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.", "published": "2022-01-10T18:59:10Z", "version": 2}, {"aid": "2201.03904", "authors": ["Conor Heins", "Beren Millidge", "Daphne Demekas", "Brennan Klein", "Karl Friston", "Iain Couzin", "Alexander Tschantz"], "title": "pymdp: A Python library for active inference in discrete state spaces", "url": "http://arxiv.org/pdf/2201.03904v2", "summary": "Active inference is an account of cognition and behavior in complex systems which brings together action, perception, and learning under the theoretical mantle of Bayesian inference. Active inference has seen growing applications in academic research, especially in fields that seek to model human or animal behavior. While in recent years, some of the code arising from the active inference literature has been written in open source languages like Python and Julia, to-date, the most popular software for simulating active inference agents is the DEM toolbox of SPM, a MATLAB library originally developed for the statistical analysis and modelling of neuroimaging data. Increasing interest in active inference, manifested both in terms of sheer number as well as diversifying applications across scientific disciplines, has thus created a need for generic, widely-available, and user-friendly code for simulating active inference in open-source scientific computing languages like Python. The Python package we present here, pymdp (see https://github.com/infer-actively/pymdp), represents a significant step in this direction: namely, we provide the first open-source package for simulating active inference with partially-observable Markov Decision Processes or POMDPs. We review the package's structure and explain its advantages like modular design and customizability, while providing in-text code blocks along the way to demonstrate how it can be used to build and run active inference processes with ease. We developed pymdp to increase the accessibility and exposure of the active inference framework to researchers, engineers, and developers with diverse disciplinary backgrounds. In the spirit of open-source software, we also hope that it spurs new innovation, development, and collaboration in the growing active inference community.", "published": "2022-01-11T12:18:44Z", "version": 2}, {"aid": "2201.05624", "authors": ["Salvatore Cuomo", "Vincenzo Schiano di Cola", "Fabio Giampaolo", "Gianluigi Rozza", "Maziar Raissi", "Francesco Piccialli"], "title": "Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next", "url": "http://arxiv.org/pdf/2201.05624v4", "summary": "Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved.", "published": "2022-01-14T19:05:44Z", "version": 4}, {"aid": "2201.05818", "authors": ["Florian Ellsaesser", "Guido Fioretti", "Gail E. James"], "title": "Measuring Non-Probabilistic Uncertainty: A cognitive, logical and computational assessment of known and unknown unknowns", "url": "http://arxiv.org/pdf/2201.05818v5", "summary": "There are two reasons why uncertainty may not be adequately described by Probability Theory. The first one is due to unique or nearly-unique events, that either never realized or occurred too seldom for frequencies to be reliably measured. The second one arises when one fears that something may happen, that one is not even able to figure out, e.g., if one asks: \"Climate change, financial crises, pandemic, war, what next?\"   In both cases, simple one-to-one cognitive maps between available alternatives and possible consequences eventually melt down. However, such destructions reflect into the changing narratives of business executives, employees and other stakeholders in specific, identifiable and differential ways. In particular, texts such as consultants' reports or letters to shareholders can be analysed in order to detect the impact of both sorts of uncertainty onto the causal relations that normally guide decision-making.   We propose structural measures of cognitive maps as a means to measure non-probabilistic uncertainty, eventually suggesting that automated text analysis can greatly augment the possibilities offered by these techniques. Prospective applications may concern actors ranging from statistical institutes to businesses as well as the general public.", "published": "2022-01-15T10:04:05Z", "version": 5}, {"aid": "2201.10801", "authors": ["Guangting Wang", "Yucheng Zhao", "Chuanxin Tang", "Chong Luo", "Wenjun Zeng"], "title": "When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism", "url": "http://arxiv.org/pdf/2201.10801v1", "summary": "Attention mechanism has been widely believed as the key to success of vision transformers (ViTs), since it provides a flexible and powerful way to model spatial relationships. However, is the attention mechanism truly an indispensable part of ViT? Can it be replaced by some other alternatives? To demystify the role of attention mechanism, we simplify it into an extremely simple case: ZERO FLOP and ZERO parameter. Concretely, we revisit the shift operation. It does not contain any parameter or arithmetic calculation. The only operation is to exchange a small portion of the channels between neighboring features. Based on this simple operation, we construct a new backbone network, namely ShiftViT, where the attention layers in ViT are substituted by shift operations. Surprisingly, ShiftViT works quite well in several mainstream tasks, e.g., classification, detection, and segmentation. The performance is on par with or even better than the strong baseline Swin Transformer. These results suggest that the attention mechanism might not be the vital factor that makes ViT successful. It can be even replaced by a zero-parameter operation. We should pay more attentions to the remaining parts of ViT in the future work. Code is available at github.com/microsoft/SPACH.", "published": "2022-01-26T08:17:06Z", "version": 1}, {"aid": "2201.11793", "authors": ["Bahjat Kawar", "Michael Elad", "Stefano Ermon", "Jiaming Song"], "title": "Denoising Diffusion Restoration Models", "url": "http://arxiv.org/pdf/2201.11793v3", "summary": "Many interesting tasks in image restoration can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion Restoration Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.", "published": "2022-01-27T20:19:07Z", "version": 3}, {"aid": "2201.12680", "authors": ["Yuandong Tian"], "title": "Understanding Deep Contrastive Learning via Coordinate-wise Optimization", "url": "http://arxiv.org/pdf/2201.12680v7", "summary": "We show that Contrastive Learning (CL) under a broad family of loss functions (including InfoNCE) has a unified formulation of coordinate-wise optimization on the network parameter $\\boldsymbol{\\theta}$ and pairwise importance $\\alpha$, where the \\emph{max player} $\\boldsymbol{\\theta}$ learns representation for contrastiveness, and the \\emph{min player} $\\alpha$ puts more weights on pairs of distinct samples that share similar representations. The resulting formulation, called $\\alpha$-CL, unifies not only various existing contrastive losses, which differ by how sample-pair importance $\\alpha$ is constructed, but also is able to extrapolate to give novel contrastive losses beyond popular ones, opening a new avenue of contrastive loss design. These novel losses yield comparable (or better) performance on CIFAR10, STL-10 and CIFAR-100 than classic InfoNCE. Furthermore, we also analyze the max player in detail: we prove that with fixed $\\alpha$, max player is equivalent to Principal Component Analysis (PCA) for deep linear network, and almost all local minima are global and rank-1, recovering optimal PCA solutions. Finally, we extend our analysis on max player to 2-layer ReLU networks, showing that its fixed points can have higher ranks.", "published": "2022-01-29T23:08:34Z", "version": 7}, {"aid": "2202.00512", "authors": ["Tim Salimans", "Jonathan Ho"], "title": "Progressive Distillation for Fast Sampling of Diffusion Models", "url": "http://arxiv.org/pdf/2202.00512v2", "summary": "Diffusion models have recently shown great promise for generative modeling, outperforming GANs on perceptual quality and autoregressive models at density estimation. A remaining downside is their slow sampling time: generating high quality samples takes many hundreds or thousands of model evaluations. Here we make two contributions to help eliminate this downside: First, we present new parameterizations of diffusion models that provide increased stability when using few sampling steps. Second, we present a method to distill a trained deterministic diffusion sampler, using many steps, into a new diffusion model that takes half as many sampling steps. We then keep progressively applying this distillation procedure to our model, halving the number of required sampling steps each time. On standard image generation benchmarks like CIFAR-10, ImageNet, and LSUN, we start out with state-of-the-art samplers taking as many as 8192 steps, and are able to distill down to models taking as few as 4 steps without losing much perceptual quality; achieving, for example, a FID of 3.0 on CIFAR-10 in 4 steps. Finally, we show that the full progressive distillation procedure does not take more time than it takes to train the original model, thus representing an efficient solution for generative modeling using diffusion at both train and test time.", "published": "2022-02-01T16:07:25Z", "version": 2}, {"aid": "2202.00666", "authors": ["Clara Meister", "Tiago Pimentel", "Gian Wiher", "Ryan Cotterell"], "title": "Locally Typical Sampling", "url": "http://arxiv.org/pdf/2202.00666v6", "summary": "Today's probabilistic language generators fall short when it comes to producing coherent and fluent text despite the fact that the underlying models perform well under standard metrics, e.g., perplexity. This discrepancy has puzzled the language generation community for the last few years. In this work, we posit that the abstraction of natural language generation as a discrete stochastic process--which allows for an information-theoretic analysis--can provide new insights into the behavior of probabilistic language generators, e.g., why high-probability texts can be dull or repetitive. Humans use language as a means of communicating information, aiming to do so in a simultaneously efficient and error-minimizing manner; in fact, psycholinguistics research suggests humans choose each word in a string with this subconscious goal in mind. We formally define the set of strings that meet this criterion: those for which each word has an information content close to the expected information content, i.e., the conditional entropy of our model. We then propose a simple and efficient procedure for enforcing this criterion when generating from probabilistic models, which we call locally typical sampling. Automatic and human evaluations show that, in comparison to nucleus and top-k sampling, locally typical sampling offers competitive performance (in both abstractive summarization and story generation) in terms of quality while consistently reducing degenerate repetitions.", "published": "2022-02-01T18:58:45Z", "version": 6}, {"aid": "2202.04110", "authors": ["Guangyao Zhou", "Antoine Dedieu", "Nishanth Kumar", "Wolfgang Lehrach", "Miguel L\u00e1zaro-Gredilla", "Shrinu Kushagra", "Dileep George"], "title": "PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and Loopy Belief Propagation in JAX", "url": "http://arxiv.org/pdf/2202.04110v4", "summary": "PGMax is an open-source Python package for (a) easily specifying discrete Probabilistic Graphical Models (PGMs) as factor graphs; and (b) automatically running efficient and scalable loopy belief propagation (LBP) in JAX. PGMax supports general factor graphs with tractable factors, and leverages modern accelerators like GPUs for inference. Compared with existing alternatives, PGMax obtains higher-quality inference results with up to three orders-of-magnitude inference time speedups. PGMax additionally interacts seamlessly with the rapidly growing JAX ecosystem, opening up new research possibilities. Our source code, examples and documentation are available at https://github.com/deepmind/PGMax.", "published": "2022-02-08T19:27:48Z", "version": 4}, {"aid": "2202.04324", "authors": ["Edgar Y Walker", "Stephan Pohl", "Rachel N Denison", "David L Barack", "Jennifer Lee", "Ned Block", "Wei Ji Ma", "Florent Meyniel"], "title": "Studying the neural representations of uncertainty", "url": "http://arxiv.org/pdf/2202.04324v4", "summary": "The study of the brain's representations of uncertainty is a central topic in neuroscience. Unlike most quantities of which the neural representation is studied, uncertainty is a property of an observer's beliefs about the world, which poses specific methodological challenges. We analyze how the literature on the neural representations of uncertainty addresses those challenges and distinguish between \"code-driven\" and \"correlational\" approaches. Code-driven approaches make assumptions about the neural code for representing world states and the associated uncertainty. By contrast, correlational approaches search for relationships between uncertainty and neural activity without constraints on the neural representation of the world state that this uncertainty accompanies. To compare these two approaches, we apply several criteria for neural representations: sensitivity, specificity, invariance, functionality. Our analysis reveals that the two approaches lead to different, but complementary findings, shaping new research questions and guiding future experiments.", "published": "2022-02-09T08:13:36Z", "version": 4}, {"aid": "2202.06709", "authors": ["Namuk Park", "Songkuk Kim"], "title": "How Do Vision Transformers Work?", "url": "http://arxiv.org/pdf/2202.06709v4", "summary": "The success of multi-head self-attentions (MSAs) for computer vision is now indisputable. However, little is known about how MSAs work. We present fundamental explanations to help better understand the nature of MSAs. In particular, we demonstrate the following properties of MSAs and Vision Transformers (ViTs): (1) MSAs improve not only accuracy but also generalization by flattening the loss landscapes. Such improvement is primarily attributable to their data specificity, not long-range dependency. On the other hand, ViTs suffer from non-convex losses. Large datasets and loss landscape smoothing methods alleviate this problem; (2) MSAs and Convs exhibit opposite behaviors. For example, MSAs are low-pass filters, but Convs are high-pass filters. Therefore, MSAs and Convs are complementary; (3) Multi-stage neural networks behave like a series connection of small individual models. In addition, MSAs at the end of a stage play a key role in prediction. Based on these insights, we propose AlterNet, a model in which Conv blocks at the end of a stage are replaced with MSA blocks. AlterNet outperforms CNNs not only in large data regimes but also in small data regimes. The code is available at https://github.com/xxxnell/how-do-vits-work.", "published": "2022-02-14T13:58:43Z", "version": 4}, {"aid": "2202.06768", "authors": ["Ivan Karpukhin", "Stanislav Dereka", "Sergey Kolesnikov"], "title": "Probabilistic Embeddings Revisited", "url": "http://arxiv.org/pdf/2202.06768v2", "summary": "In recent years, deep metric learning and its probabilistic extensions claimed state-of-the-art results in the face verification task. Despite improvements in face verification, probabilistic methods received little attention in the research community and practical applications. In this paper, we, for the first time, perform an in-depth analysis of known probabilistic methods in verification and retrieval tasks. We study different design choices and propose a simple extension, achieving new state-of-the-art results among probabilistic methods. Finally, we study confidence prediction and show that it correlates with data quality, but contains little information about prediction error probability. We thus provide a new confidence evaluation benchmark and establish a baseline for future confidence prediction research. PyTorch implementation is publicly released.", "published": "2022-02-14T14:37:54Z", "version": 2}, {"aid": "2202.06997", "authors": ["Guoyang Xie", "Yawen Huang", "Jinbao Wang", "Jiayi Lyu", "Feng Zheng", "Yefeng Zheng", "Yaochu Jin"], "title": "Cross-Modality Neuroimage Synthesis: A Survey", "url": "http://arxiv.org/pdf/2202.06997v7", "summary": "Multi-modality imaging improves disease diagnosis and reveals distinct deviations in tissues with anatomical properties. The existence of completely aligned and paired multi-modality neuroimaging data has proved its effectiveness in brain research. However, collecting fully aligned and paired data is expensive or even impractical, since it faces many difficulties, including high cost, long acquisition time, image corruption, and privacy issues. An alternative solution is to explore unsupervised or weakly supervised learning methods to synthesize the absent neuroimaging data. In this paper, we provide a comprehensive review of cross-modality synthesis for neuroimages, from the perspectives of weakly supervised and unsupervised settings, loss functions, evaluation metrics, imaging modalities, datasets, and downstream applications based on synthesis. We begin by highlighting several opening challenges for cross-modality neuroimage synthesis. Then, we discuss representative architectures of cross-modality synthesis methods under different supervisions. This is followed by a stepwise in-depth analysis to evaluate how cross-modality neuroimage synthesis improves the performance of its downstream tasks. Finally, we summarize the existing research findings and point out future research directions. All resources are available at https://github.com/M-3LAB/awesome-multimodal-brain-image-systhesis", "published": "2022-02-14T19:29:08Z", "version": 7}, {"aid": "2202.07643", "authors": ["Johannes Brandstetter", "Max Welling", "Daniel E. Worrall"], "title": "Lie Point Symmetry Data Augmentation for Neural PDE Solvers", "url": "http://arxiv.org/pdf/2202.07643v2", "summary": "Neural networks are increasingly being used to solve partial differential equations (PDEs), replacing slower numerical solvers. However, a critical issue is that neural PDE solvers require high-quality ground truth data, which usually must come from the very solvers they are designed to replace. Thus, we are presented with a proverbial chicken-and-egg problem. In this paper, we present a method, which can partially alleviate this problem, by improving neural PDE solver sample complexity -- Lie point symmetry data augmentation (LPSDA). In the context of PDEs, it turns out that we are able to quantitatively derive an exhaustive list of data transformations, based on the Lie point symmetry group of the PDEs in question, something not possible in other application areas. We present this framework and demonstrate how it can easily be deployed to improve neural PDE solver sample complexity by an order of magnitude.", "published": "2022-02-15T18:43:17Z", "version": 2}, {"aid": "2202.08345", "authors": ["Hsueh-Ti Derek Liu", "Francis Williams", "Alec Jacobson", "Sanja Fidler", "Or Litany"], "title": "Learning Smooth Neural Functions via Lipschitz Regularization", "url": "http://arxiv.org/pdf/2202.08345v2", "summary": "Neural implicit fields have recently emerged as a useful representation for 3D shapes. These fields are commonly represented as neural networks which map latent descriptors and 3D coordinates to implicit function values. The latent descriptor of a neural field acts as a deformation handle for the 3D shape it represents. Thus, smoothness with respect to this descriptor is paramount for performing shape-editing operations. In this work, we introduce a novel regularization designed to encourage smooth latent spaces in neural fields by penalizing the upper bound on the field's Lipschitz constant. Compared with prior Lipschitz regularized networks, ours is computationally fast, can be implemented in four lines of code, and requires minimal hyperparameter tuning for geometric applications. We demonstrate the effectiveness of our approach on shape interpolation and extrapolation as well as partial shape reconstruction from 3D point clouds, showing both qualitative and quantitative improvements over existing state-of-the-art and non-regularized baselines.", "published": "2022-02-16T21:24:54Z", "version": 2}, {"aid": "2202.10688", "authors": ["Falih Gozi Febrinanto", "Feng Xia", "Kristen Moore", "Chandra Thapa", "Charu Aggarwal"], "title": "Graph Lifelong Learning: A Survey", "url": "http://arxiv.org/pdf/2202.10688v2", "summary": "Graph learning is a popular approach for performing machine learning on graph-structured data. It has revolutionized the machine learning ability to model graph data to address downstream tasks. Its application is wide due to the availability of graph data ranging from all types of networks to information systems. Most graph learning methods assume that the graph is static and its complete structure is known during training. This limits their applicability since they cannot be applied to problems where the underlying graph grows over time and/or new tasks emerge incrementally. Such applications require a lifelong learning approach that can learn the graph continuously and accommodate new information whilst retaining previously learned knowledge. Lifelong learning methods that enable continuous learning in regular domains like images and text cannot be directly applied to continuously evolving graph data, due to its irregular structure. As a result, graph lifelong learning is gaining attention from the research community. This survey paper provides a comprehensive overview of recent advancements in graph lifelong learning, including the categorization of existing methods, and the discussions of potential applications and open research problems.", "published": "2022-02-22T06:14:07Z", "version": 2}, {"aid": "2202.10793", "authors": ["Yixuan He", "Xitong Zhang", "Junjie Huang", "Benedek Rozemberczki", "Mihai Cucuringu", "Gesine Reinert"], "title": "PyTorch Geometric Signed Directed: A Software Package on Graph Neural Networks for Signed and Directed Graphs", "url": "http://arxiv.org/pdf/2202.10793v6", "summary": "Networks are ubiquitous in many real-world applications (e.g., social networks encoding trust/distrust relationships, correlation networks arising from time series data). While many networks are signed or directed, or both, there is a lack of unified software packages on graph neural networks (GNNs) specially designed for signed and directed networks. In this paper, we present PyTorch Geometric Signed Directed (PyGSD), a software package which fills this gap. Along the way, we evaluate the implemented methods with experiments with a view to providing insights into which method to choose for a given task. The deep learning framework consists of easy-to-use GNN models, synthetic and real-world data, as well as task-specific evaluation metrics and loss functions for signed and directed networks. As an extension library for PyG, our proposed software is maintained with open-source releases, detailed documentation, continuous integration, unit tests and code coverage checks. The GitHub repository of the library is https://github.com/SherylHYX/pytorch_geometric_signed_directed.", "published": "2022-02-22T10:25:59Z", "version": 6}, {"aid": "2202.12387", "authors": ["Zhuoning Yuan", "Yuexin Wu", "Zi-Hao Qiu", "Xianzhi Du", "Lijun Zhang", "Denny Zhou", "Tianbao Yang"], "title": "Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance", "url": "http://arxiv.org/pdf/2202.12387v4", "summary": "In this paper, we study contrastive learning from an optimization perspective, aiming to analyze and address a fundamental issue of existing contrastive learning methods that either rely on a large batch size or a large dictionary of feature vectors. We consider a global objective for contrastive learning, which contrasts each positive pair with all negative pairs for an anchor point. From the optimization perspective, we explain why existing methods such as SimCLR require a large batch size in order to achieve a satisfactory result. In order to remove such requirement, we propose a memory-efficient Stochastic Optimization algorithm for solving the Global objective of Contrastive Learning of Representations, named SogCLR. We show that its optimization error is negligible under a reasonable condition after a sufficient number of iterations or is diminishing for a slightly different global contrastive objective. Empirically, we demonstrate that SogCLR with small batch size (e.g., 256) can achieve similar performance as SimCLR with large batch size (e.g., 8192) on self-supervised learning task on ImageNet-1K. We also attempt to show that the proposed optimization technique is generic and can be applied to solving other contrastive losses, e.g., two-way contrastive losses for bimodal contrastive learning. The proposed method is implemented in our open-sourced library LibAUC (www.libauc.org).", "published": "2022-02-24T22:16:53Z", "version": 4}, {"aid": "2202.12498", "authors": ["Kun Han", "Shanlin sun", "Xiangyi Yan", "Chenyu You", "Hao Tang", "Junayed Naushad", "Haoyu Ma", "Deying Kong", "Xiaohui Xie"], "title": "Diffeomorphic Image Registration with Neural Velocity Field", "url": "http://arxiv.org/pdf/2202.12498v5", "summary": "Diffeomorphic image registration, offering smooth transformation and topology preservation, is required in many medical image analysis tasks.Traditional methods impose certain modeling constraints on the space of admissible transformations and use optimization to find the optimal transformation between two images. Specifying the right space of admissible transformations is challenging: the registration quality can be poor if the space is too restrictive, while the optimization can be hard to solve if the space is too general. Recent learning-based methods, utilizing deep neural networks to learn the transformation directly, achieve fast inference, but face challenges in accuracy due to the difficulties in capturing the small local deformations and generalization ability. Here we propose a new optimization-based method named DNVF (Diffeomorphic Image Registration with Neural Velocity Field) which utilizes deep neural network to model the space of admissible transformations. A multilayer perceptron (MLP) with sinusoidal activation function is used to represent the continuous velocity field and assigns a velocity vector to every point in space, providing the flexibility of modeling complex deformations as well as the convenience of optimization. Moreover, we propose a cascaded image registration framework (Cas-DNVF) by combining the benefits of both optimization and learning based methods, where a fully convolutional neural network (FCN) is trained to predict the initial deformation, followed by DNVF for further refinement. Experiments on two large-scale 3D MR brain scan datasets demonstrate that our proposed methods significantly outperform the state-of-the-art registration methods.", "published": "2022-02-25T05:04:29Z", "version": 5}, {"aid": "2203.04946", "authors": ["Manoj Kumar", "Neil Houlsby", "Nal Kalchbrenner", "Ekin D. Cubuk"], "title": "Do better ImageNet classifiers assess perceptual similarity better?", "url": "http://arxiv.org/pdf/2203.04946v3", "summary": "Perceptual distances between images, as measured in the space of pre-trained deep features, have outperformed prior low-level, pixel-based metrics on assessing perceptual similarity. While the capabilities of older and less accurate models such as AlexNet and VGG to capture perceptual similarity are well known, modern and more accurate models are less studied. In this paper, we present a large-scale empirical study to assess how well ImageNet classifiers perform on perceptual similarity. First, we observe a inverse correlation between ImageNet accuracy and Perceptual Scores of modern networks such as ResNets, EfficientNets, and Vision Transformers: that is better classifiers achieve worse Perceptual Scores. Then, we examine the ImageNet accuracy/Perceptual Score relationship on varying the depth, width, number of training steps, weight decay, label smoothing, and dropout. Higher accuracy improves Perceptual Score up to a certain point, but we uncover a Pareto frontier between accuracies and Perceptual Score in the mid-to-high accuracy regime. We explore this relationship further using a number of plausible hypotheses such as distortion invariance, spatial frequency sensitivity, and alternative perceptual functions. Interestingly we discover shallow ResNets and ResNets trained for less than 5 epochs only on ImageNet, whose emergent Perceptual Score matches the prior best networks trained directly on supervised human perceptual judgements. The checkpoints for the models in our study are available at https://console.cloud.google.com/storage/browser/gresearch/perceptual_similarity.", "published": "2022-03-09T18:45:41Z", "version": 3}, {"aid": "2203.05328", "authors": ["Boyu Chen", "Peixia Li", "Lei Bai", "Lei Qiao", "Qiuhong Shen", "Bo Li", "Weihao Gan", "Wei Wu", "Wanli Ouyang"], "title": "Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking", "url": "http://arxiv.org/pdf/2203.05328v2", "summary": "Exploiting a general-purpose neural architecture to replace hand-wired designs or inductive biases has recently drawn extensive interest. However, existing tracking approaches rely on customized sub-modules and need prior knowledge for architecture selection, hindering the tracking development in a more general system. This paper presents a Simplified Tracking architecture (SimTrack) by leveraging a transformer backbone for joint feature extraction and interaction. Unlike existing Siamese trackers, we serialize the input images and concatenate them directly before the one-branch backbone. Feature interaction in the backbone helps to remove well-designed interaction modules and produce a more efficient and effective framework. To reduce the information loss from down-sampling in vision transformers, we further propose a foveal window strategy, providing more diverse input patches with acceptable computational costs. Our SimTrack improves the baseline with 2.5%/2.6% AUC gains on LaSOT/TNL2K and gets results competitive with other specialized tracking algorithms without bells and whistles.", "published": "2022-03-10T12:20:58Z", "version": 2}, {"aid": "2203.05483", "authors": ["Bobak Kiani", "Randall Balestriero", "Yann LeCun", "Seth Lloyd"], "title": "projUNN: efficient method for training deep networks with unitary matrices", "url": "http://arxiv.org/pdf/2203.05483v3", "summary": "In learning with recurrent or very deep feed-forward networks, employing unitary matrices in each layer can be very effective at maintaining long-range stability. However, restricting network parameters to be unitary typically comes at the cost of expensive parameterizations or increased training runtime. We propose instead an efficient method based on rank-$k$ updates -- or their rank-$k$ approximation -- that maintains performance at a nearly optimal training runtime. We introduce two variants of this method, named Direct (projUNN-D) and Tangent (projUNN-T) projected Unitary Neural Networks, that can parameterize full $N$-dimensional unitary or orthogonal matrices with a training runtime scaling as $O(kN^2)$. Our method either projects low-rank gradients onto the closest unitary matrix (projUNN-T) or transports unitary matrices in the direction of the low-rank gradient (projUNN-D). Even in the fastest setting ($k=1$), projUNN is able to train a model's unitary parameters to reach comparable performances against baseline implementations. In recurrent neural network settings, projUNN closely matches or exceeds benchmarked results from prior unitary neural networks. Finally, we preliminarily explore projUNN in training orthogonal convolutional neural networks, which are currently unable to outperform state of the art models but can potentially enhance stability and robustness at large depth.", "published": "2022-03-10T17:04:41Z", "version": 3}, {"aid": "2203.08207", "authors": ["Pei Xu", "Jean-Bernard Hayet", "Ioannis Karamouzas"], "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents", "url": "http://arxiv.org/pdf/2203.08207v4", "summary": "Predicting pedestrian movement is critical for human behavior analysis and also for safe and efficient human-agent interactions. However, despite significant advancements, it is still challenging for existing approaches to capture the uncertainty and multimodality of human navigation decision making. In this paper, we propose SocialVAE, a novel approach for human trajectory prediction. The core of SocialVAE is a timewise variational autoencoder architecture that exploits stochastic recurrent neural networks to perform prediction, combined with a social attention mechanism and a backward posterior approximation to allow for better extraction of pedestrian navigation strategies. We show that SocialVAE improves current state-of-the-art performance on several pedestrian trajectory prediction benchmarks, including the ETH/UCY benchmark, Stanford Drone Dataset, and SportVU NBA movement dataset. Code is available at: https://github.com/xupei0610/SocialVAE.", "published": "2022-03-15T19:14:33Z", "version": 4}, {"aid": "2203.08382", "authors": ["Xuan Su", "Jiaming Song", "Chenlin Meng", "Stefano Ermon"], "title": "Dual Diffusion Implicit Bridges for Image-to-Image Translation", "url": "http://arxiv.org/pdf/2203.08382v4", "summary": "Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new domain pairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation method based on diffusion models, that circumvents training on domain pairs. Image translation with DDIBs relies on two diffusion models trained independently on each domain, and is a two-step process: DDIBs first obtain latent encodings for source images with the source diffusion model, and then decode such encodings using the target model to construct target images. Both steps are defined via ordinary differential equations (ODEs), thus the process is cycle consistent only up to discretization errors of the ODE solvers. Theoretically, we interpret DDIBs as concatenation of source to latent, and latent to target Schrodinger Bridges, a form of entropy-regularized optimal transport, to explain the efficacy of the method. Experimentally, we apply DDIBs on synthetic and high-resolution image datasets, to demonstrate their utility in a wide variety of translation tasks and their inherent optimal transport properties.", "published": "2022-03-16T04:10:45Z", "version": 4}, {"aid": "2203.09081", "authors": ["Yibo Yang", "Shixiang Chen", "Xiangtai Li", "Liang Xie", "Zhouchen Lin", "Dacheng Tao"], "title": "Inducing Neural Collapse in Imbalanced Learning: Do We Really Need a Learnable Classifier at the End of Deep Neural Network?", "url": "http://arxiv.org/pdf/2203.09081v3", "summary": "Modern deep neural networks for classification usually jointly learn a backbone for representation and a linear classifier to output the logit of each class. A recent study has shown a phenomenon called neural collapse that the within-class means of features and the classifier vectors converge to the vertices of a simplex equiangular tight frame (ETF) at the terminal phase of training on a balanced dataset. Since the ETF geometric structure maximally separates the pair-wise angles of all classes in the classifier, it is natural to raise the question, why do we spend an effort to learn a classifier when we know its optimal geometric structure? In this paper, we study the potential of learning a neural network for classification with the classifier randomly initialized as an ETF and fixed during training. Our analytical work based on the layer-peeled model indicates that the feature learning with a fixed ETF classifier naturally leads to the neural collapse state even when the dataset is imbalanced among classes. We further show that in this case the cross entropy (CE) loss is not necessary and can be replaced by a simple squared loss that shares the same global optimality but enjoys a better convergence property. Our experimental results show that our method is able to bring significant improvements with faster convergence on multiple imbalanced datasets.", "published": "2022-03-17T04:34:28Z", "version": 3}, {"aid": "2203.11200", "authors": ["Jie Chen", "Shouzhen Chen", "Junbin Gao", "Zengfeng Huang", "Junping Zhang", "Jian Pu"], "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily", "url": "http://arxiv.org/pdf/2203.11200v3", "summary": "Due to the homophily assumption in graph convolution networks (GNNs), a common consensus in the graph node classification task is that GNNs perform well on homophilic graphs but may fail on heterophilic graphs with many inter-class edges. However, the previous inter-class edges perspective and related homo-ratio metrics cannot well explain the GNNs performance under some heterophilic datasets, which implies that not all the inter-class edges are harmful to GNNs. In this work, we propose a new metric based on von Neumann entropy to re-examine the heterophily problem of GNNs and investigate the feature aggregation of inter-class edges from an entire neighbor identifiable perspective. Moreover, we propose a simple yet effective Conv-Agnostic GNN framework (CAGNNs) to enhance the performance of most GNNs on heterophily datasets by learning the neighbor effect for each node. Specifically, we first decouple the feature of each node into the discriminative feature for downstream tasks and the aggregation feature for graph convolution. Then, we propose a shared mixer module to adaptively evaluate the neighbor effect of each node to incorporate the neighbor information. The proposed framework can be regarded as a plug-in component and is compatible with most GNNs. The experimental results over nine well-known benchmark datasets indicate that our framework can significantly improve performance, especially for the heterophily graphs. The average performance gain is 9.81%, 25.81%, and 20.61% compared with GIN, GAT, and GCN, respectively. Extensive ablation studies and robustness analysis further verify the effectiveness, robustness, and interpretability of our framework. Code is available at https://github.com/JC-202/CAGNN.", "published": "2022-03-19T14:26:43Z", "version": 3}, {"aid": "2203.10761", "authors": ["Zicheng Liu", "Siyuan Li", "Ge Wang", "Cheng Tan", "Lirong Wu", "Stan Z. Li"], "title": "Harnessing Hard Mixed Samples with Decoupled Regularizer", "url": "http://arxiv.org/pdf/2203.10761v3", "summary": "Mixup is an efficient data augmentation approach that improves the generalization of neural networks by smoothing the decision boundary with mixed data. Recently, dynamic mixup methods have improved previous static policies effectively (e.g., linear interpolation) by maximizing target-related salient regions in mixed samples, but excessive additional time costs are not acceptable. These additional computational overheads mainly come from optimizing the mixed samples according to the mixed labels. However, we found that the extra optimizing step may be redundant because label-mismatched mixed samples are informative hard mixed samples for deep models to localize discriminative features. In this paper, we thus are not trying to propose a more complicated dynamic mixup policy but rather an efficient mixup objective function with a decoupled regularizer named Decoupled Mixup (DM). The primary effect is that DM can adaptively utilize those hard mixed samples to mine discriminative features without losing the original smoothness of mixup. As a result, DM enables static mixup methods to achieve comparable or even exceed the performance of dynamic methods without any extra computation. This also leads to an interesting objective design problem for mixup training that we need to focus on both smoothing the decision boundaries and identifying discriminative features. Extensive experiments on supervised and semi-supervised learning benchmarks across seven datasets validate the effectiveness of DM as a plug-and-play module. Source code and models are available at https://github.com/Westlake-AI/openmixup", "published": "2022-03-21T07:12:18Z", "version": 3}, {"aid": "2203.10810", "authors": ["Patricia Wollstadt", "Daniel L. Rathbun", "W. Martin Usrey and", "Andr\u00e9 Moraes Bastos", "Michael Lindner", "Viola Priesemann", "Michael Wibral"], "title": "Information-theoretic analyses of neural data to minimize the effect of researchers' assumptions in predictive coding studies", "url": "http://arxiv.org/pdf/2203.10810v3", "summary": "Studies investigating neural information processing often implicitly ask both, which processing strategy out of several alternatives is used and how this strategy is implemented in neural dynamics. A prime example are studies on predictive coding. These often ask if confirmed predictions about inputs or predictions errors between internal predictions and inputs are passed on in a hierarchical neural system--while at the same time looking for the neural correlates of coding for errors and predictions. If we do not know exactly what a neural system predicts at any given moment, this results in a circular analysis--as has been criticized correctly. To circumvent such circular analysis, we propose to express information processing strategies (such as predictive coding) by local information-theoretic quantities, such that they can be estimated directly from neural data. We demonstrate our approach by investigating two opposing accounts of predictive coding-like processing strategies, where we quantify the building blocks of predictive coding, namely predictability of inputs and transfer of information, by local active information storage and local transfer entropy. We define testable hypotheses on the relationship of both quantities to identify which of the assumed strategies was used. We demonstrate our approach on spiking data from the retinogeniculate synapse of the cat. Applying our local information dynamics framework, we are able to show that the synapse codes for predictable rather than surprising input. To support our findings, we apply measures from partial information decomposition, which allow to differentiate if the transferred information is primarily bottom-up sensory input or information transferred conditionally on the current state of the synapse. Supporting our local information-theoretic results, we find that the synapse preferentially transfers bottom-up information.", "published": "2022-03-21T09:03:53Z", "version": 3}, {"aid": "2203.11156", "authors": ["Junqi Tang", "Subhadip Mukherjee", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Operator Sketching for Deep Unrolling Networks", "url": "http://arxiv.org/pdf/2203.11156v3", "summary": "In this work we propose a new paradigm for designing efficient deep unrolling networks using operator sketching. The deep unrolling networks are currently the state-of-the-art solutions for imaging inverse problems. However, for high-dimensional imaging tasks, especially the 3D cone-beam X-ray CT and 4D MRI imaging, the deep unrolling schemes typically become inefficient both in terms of memory and computation, due to the need of computing multiple times the high-dimensional forward and adjoint operators. Recently researchers have found that such limitations can be partially addressed by stochastic unrolling with subsets of operators, inspired by the success of stochastic first-order optimization. In this work, we propose a further acceleration upon stochastic unrolling, using sketching techniques to approximate products in the high-dimensional image space. The operator sketching can be jointly applied with stochastic unrolling for the best acceleration and compression performance. Our numerical experiments on X-ray CT image reconstruction demonstrate the remarkable effectiveness of our sketched unrolling schemes.", "published": "2022-03-21T17:34:18Z", "version": 3}, {"aid": "2203.11862", "authors": ["Ariel Elnekave", "Yair Weiss"], "title": "Generating natural images with direct Patch Distributions Matching", "url": "http://arxiv.org/pdf/2203.11862v3", "summary": "Many traditional computer vision algorithms generate realistic images by requiring that each patch in the generated image be similar to a patch in a training image and vice versa. Recently, this classical approach has been replaced by adversarial training with a patch discriminator. The adversarial approach avoids the computational burden of finding nearest neighbors of patches but often requires very long training times and may fail to match the distribution of patches. In this paper we leverage the recently developed Sliced Wasserstein Distance and develop an algorithm that explicitly and efficiently minimizes the distance between patch distributions in two images. Our method is conceptually simple, requires no training and can be implemented in a few lines of codes. On a number of image generation tasks we show that our results are often superior to single-image-GANs, require no training, and can generate high quality images in a few seconds. Our implementation is available at https://github.com/ariel415el/GPDM", "published": "2022-03-22T16:38:52Z", "version": 3}, {"aid": "2204.05133", "authors": ["Arthur Juliani", "Kai Arulkumaran", "Shuntaro Sasai", "Ryota Kanai"], "title": "On the link between conscious function and general intelligence in humans and machines", "url": "http://arxiv.org/pdf/2204.05133v2", "summary": "In popular media, there is often a connection drawn between the advent of awareness in artificial agents and those same agents simultaneously achieving human or superhuman level intelligence. In this work, we explore the validity and potential application of this seemingly intuitive link between consciousness and intelligence. We do so by examining the cognitive abilities associated with three contemporary theories of conscious function: Global Workspace Theory (GWT), Information Generation Theory (IGT), and Attention Schema Theory (AST). We find that all three theories specifically relate conscious function to some aspect of domain-general intelligence in humans. With this insight, we turn to the field of Artificial Intelligence (AI) and find that, while still far from demonstrating general intelligence, many state-of-the-art deep learning methods have begun to incorporate key aspects of each of the three functional theories. Having identified this trend, we use the motivating example of mental time travel in humans to propose ways in which insights from each of the three theories may be combined into a single unified and implementable model. Given that it is made possible by cognitive abilities underlying each of the three functional theories, artificial agents capable of mental time travel would not only possess greater general intelligence than current approaches, but also be more consistent with our current understanding of the functional role of consciousness in humans, thus making it a promising near-term goal for AI research.", "published": "2022-03-24T02:22:23Z", "version": 2}, {"aid": "2203.14194", "authors": ["Chang Sub Kim"], "title": "Free energy and inference in living systems", "url": "http://arxiv.org/pdf/2203.14194v2", "summary": "Organisms are nonequilibrium, stationary systems self-organized via spontaneous symmetry breaking and undergoing metabolic cycles with broken detailed balance in the environment. The thermodynamic free-energy principle describes an organism's homeostasis as the regulation of biochemical work constrained by the physical free-energy cost. In contrast, recent research in neuroscience and theoretical biology explains a higher organism's homeostasis and allostasis as Bayesian inference facilitated by the informational free energy. As an integrated approach to living systems, this study presents a free-energy minimization theory overarching the essential features of both the thermodynamic and neuroscientific free-energy principles. Our results reveal that the perception and action of animals result from active inference entailed by free-energy minimization in the brain, and the brain operates as Schr{\\\"o}dinger's machine conducting the neural mechanics of minimizing sensory uncertainty. A parsimonious model suggests that the Bayesian brain develops the optimal trajectories in neural manifolds and induces a dynamic bifurcation between neural attractors in the process of active inference.", "published": "2022-03-27T03:16:06Z", "version": 2}, {"aid": "2203.14495", "authors": ["Hiroki Naganuma", "Hideaki Iiduka"], "title": "Conjugate Gradient Method for Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2203.14495v3", "summary": "One of the training strategies of generative models is to minimize the Jensen--Shannon divergence between the model distribution and the data distribution. Since data distribution is unknown, generative adversarial networks (GANs) formulate this problem as a game between two models, a generator and a discriminator. The training can be formulated in the context of game theory and the local Nash equilibrium (LNE). It does not seem feasible to derive guarantees of stability or optimality for the existing methods. This optimization problem is far more challenging than the single objective setting. Here, we use the conjugate gradient method to reliably and efficiently solve the LNE problem in GANs. We give a proof and convergence analysis under mild assumptions showing that the proposed method converges to a LNE with three different learning rate update rules, including a constant learning rate. Finally, we demonstrate that the proposed method outperforms stochastic gradient descent (SGD) and momentum SGD in terms of best Frechet inception distance (FID) score and outperforms Adam on average. The code is available at \\url{https://github.com/Hiroki11x/ConjugateGradient_GAN}.", "published": "2022-03-28T04:44:45Z", "version": 3}, {"aid": "2203.15544", "authors": ["Andrew Dudzik", "Petar Veli\u010dkovi\u0107"], "title": "Graph Neural Networks are Dynamic Programmers", "url": "http://arxiv.org/pdf/2203.15544v3", "summary": "Recent advances in neural algorithmic reasoning with graph neural networks (GNNs) are propped up by the notion of algorithmic alignment. Broadly, a neural network will be better at learning to execute a reasoning task (in terms of sample complexity) if its individual components align well with the target algorithm. Specifically, GNNs are claimed to align with dynamic programming (DP), a general problem-solving strategy which expresses many polynomial-time algorithms. However, has this alignment truly been demonstrated and theoretically quantified? Here we show, using methods from category theory and abstract algebra, that there exists an intricate connection between GNNs and DP, going well beyond the initial observations over individual algorithms such as Bellman-Ford. Exposing this connection, we easily verify several prior findings in the literature, produce better-grounded GNN architectures for edge-centric tasks, and demonstrate empirical results on the CLRS algorithmic reasoning benchmark. We hope our exposition will serve as a foundation for building stronger algorithmically aligned GNNs.", "published": "2022-03-29T13:27:28Z", "version": 3}, {"aid": "2203.17255", "authors": ["Jared Edward Reser"], "title": "A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Thought Is Structured by the Iterative Updating of Working Memory", "url": "http://arxiv.org/pdf/2203.17255v7", "summary": "This article provides an analytical framework for how to simulate human-like thought processes within a computer. It describes how attention and memory should be structured, updated, and utilized to search for associative additions to the stream of thought. The focus is on replicating the dynamics of the mammalian working memory system, which features two forms of persistent activity: sustained firing (preserving information on the order of seconds) and synaptic potentiation (preserving information from minutes to hours). The article uses a series of figures to systematically demonstrate how the iterative updating of these working memory stores provides functional organization to behavior, cognition, and awareness.   In a machine learning implementation, these two memory stores should be updated continuously and in an iterative fashion. This means each state should preserve a proportion of the coactive representations from the state before it (where each representation is an ensemble of neural network nodes). This makes each state a revised iteration of the preceding state and causes successive configurations to overlap and blend with respect to the information they contain. Thus, the set of concepts in working memory will evolve gradually and incrementally over time. Transitions between states happen as persistent activity spreads activation energy throughout the hierarchical network, searching long-term memory for the most appropriate representation to be added to the global workspace. The result is a chain of associatively linked intermediate states capable of advancing toward a solution or goal. Iterative updating is conceptualized here as an information processing strategy, a model of working memory, a theory of consciousness, and an algorithm for designing and programming artificial intelligence (AI, AGI, and ASI).", "published": "2022-03-29T22:28:30Z", "version": 7}, {"aid": "2203.17271", "authors": ["Tian Yun", "Usha Bhalla", "Ellie Pavlick", "Chen Sun"], "title": "Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?", "url": "http://arxiv.org/pdf/2203.17271v3", "summary": "Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive concepts--such as colors, shapes, or the attributes of object parts--emerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap first asks a VL model to generate primitive concept activations with text prompts, and then learns to construct a composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to composite concepts (e.g. a red-winged blackbird). We show that a composition model can be reliably learn from ground truth primitive concepts. We thus hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept activations can be used to learn a composition model similar to the one designed by experts. We propose a quantitative metric to measure the degree of similarity, and refer to the metric as the interpretability metric. We also measure the classification accuracy when using the primitive concept activations and the learned composition model to predict the composite concepts, and refer to it as the usefulness metric. Our study reveals that state-of-the-art VL pretrained models learn primitive concepts that are highly useful for fine-grained visual recognition on the CUB dataset, and compositional generalization tasks on the MIT-States dataset. However, we observe that the learned composition models have low interpretability in our qualitative analyses. Our results reveal the limitations of existing VL models, and the necessity of pretraining objectives that encourage the acquisition of primitive concepts.", "published": "2022-03-31T17:59:05Z", "version": 3}, {"aid": "2204.00964", "authors": ["Minchul Kim", "Anil K. Jain", "Xiaoming Liu"], "title": "AdaFace: Quality Adaptive Margin for Face Recognition", "url": "http://arxiv.org/pdf/2204.00964v2", "summary": "Recognition in low quality face datasets is challenging because facial attributes are obscured and degraded. Advances in margin-based loss functions have resulted in enhanced discriminability of faces in the embedding space. Further, previous studies have studied the effect of adaptive losses to assign more importance to misclassified (hard) examples. In this work, we introduce another aspect of adaptiveness in the loss function, namely the image quality. We argue that the strategy to emphasize misclassified samples should be adjusted according to their image quality. Specifically, the relative importance of easy or hard samples should be based on the sample's image quality. We propose a new loss function that emphasizes samples of different difficulties based on their image quality. Our method achieves this in the form of an adaptive margin function by approximating the image quality with feature norms. Extensive experiments show that our method, AdaFace, improves the face recognition performance over the state-of-the-art (SoTA) on four datasets (IJB-B, IJB-C, IJB-S and TinyFace). Code and models are released in https://github.com/mk-minchul/AdaFace.", "published": "2022-04-03T01:23:41Z", "version": 2}, {"aid": "2204.01723", "authors": ["Adam Kohan", "Edward A. Rietman", "Hava T. Siegelmann"], "title": "Signal Propagation: A Framework for Learning and Inference In a Forward Pass", "url": "http://arxiv.org/pdf/2204.01723v2", "summary": "We propose a new learning framework, signal propagation (sigprop), for propagating a learning signal and updating neural network parameters via a forward pass, as an alternative to backpropagation. In sigprop, there is only the forward path for inference and learning. So, there are no structural or computational constraints necessary for learning to take place, beyond the inference model itself, such as feedback connectivity, weight transport, or a backward pass, which exist under backpropagation based approaches. That is, sigprop enables global supervised learning with only a forward path. This is ideal for parallel training of layers or modules. In biology, this explains how neurons without feedback connections can still receive a global learning signal. In hardware, this provides an approach for global supervised learning without backward connectivity. Sigprop by construction has compatibility with models of learning in the brain and in hardware than backpropagation, including alternative approaches relaxing learning constraints. We also demonstrate that sigprop is more efficient in time and memory than they are. To further explain the behavior of sigprop, we provide evidence that sigprop provides useful learning signals in context to backpropagation. To further support relevance to biological and hardware learning, we use sigprop to train continuous time neural networks with Hebbian updates, and train spiking neural networks with only the voltage or with biologically and hardware compatible surrogate functions.", "published": "2022-04-04T04:41:59Z", "version": 2}, {"aid": "2204.03740", "authors": ["Federico Adolfi", "Jeffrey S. Bowers", "David Poeppel"], "title": "Successes and critical failures of neural networks in capturing human-like speech recognition", "url": "http://arxiv.org/pdf/2204.03740v4", "summary": "Natural and artificial audition can in principle acquire different solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would potentially enrich artificial hearing systems and process models of the mind and brain. Speech recognition - an area ripe for such exploration - is inherently robust in humans to a number transformations at various spectrotemporal granularities. To what extent are these robustness profiles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus-computable, optimized observers. In a series of experiments, we (1) clarify how influential speech manipulations in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-distribution robustness, reproducing classical perceptual phenomena in humans, (3) identify the specific conditions where model predictions of human performance differ, and (4) demonstrate a crucial failure of all artificial systems to perceptually recover where humans do, suggesting alternative directions for theory and model building. These findings encourage a tighter synergy between the cognitive science and engineering of audition.", "published": "2022-04-06T06:35:10Z", "version": 4}, {"aid": "2204.02849", "authors": ["Shelly Sheynin", "Oron Ashual", "Adam Polyak", "Uriel Singer", "Oran Gafni", "Eliya Nachmani", "Yaniv Taigman"], "title": "KNN-Diffusion: Image Generation via Large-Scale Retrieval", "url": "http://arxiv.org/pdf/2204.02849v2", "summary": "Recent text-to-image models have achieved impressive results. However, since they require large-scale datasets of text-image pairs, it is impractical to train them on new domains where data is scarce or not labeled. In this work, we propose using large-scale retrieval methods, in particular, efficient k-Nearest-Neighbors (kNN), which offers novel capabilities: (1) training a substantially small and efficient text-to-image diffusion model without any text, (2) generating out-of-distribution images by simply swapping the retrieval database at inference time, and (3) performing text-driven local semantic manipulations while preserving object identity. To demonstrate the robustness of our method, we apply our kNN approach on two state-of-the-art diffusion backbones, and show results on several different datasets. As evaluated by human studies and automatic metrics, our method achieves state-of-the-art results compared to existing approaches that train text-to-image generation models using images only (without paired text data)", "published": "2022-04-06T14:13:35Z", "version": 2}, {"aid": "2204.03354", "authors": ["Achim Schilling", "William Sedley", "Richard Gerum", "Claus Metzner", "Konstantin Tziridis", "Andreas Maier", "Holger Schulze", "Fan-Gang Zeng", "Karl J. Friston", "Patrick Krauss"], "title": "Predictive coding and stochastic resonance as fundamental principles of auditory perception", "url": "http://arxiv.org/pdf/2204.03354v2", "summary": "How is information processed in the brain during perception? Mechanistic insight is achieved only when experiments are employed to test formal or computational models. In analogy to lesion studies, phantom perception may serve as a vehicle to understand the fundamental processing principles underlying auditory perception. With a special focus on tinnitus -- as the prime example of auditory phantom perception -- we review recent work at the intersection of artificial intelligence, psychology, and neuroscience. In particular, we discuss why everyone with tinnitus suffers from hearing loss, but not everyone with hearing loss suffers from tinnitus. We argue that the increase of sensory precision due to Bayesian inference could be caused by intrinsic neural noise and lead to a prediction error in the cerebral cortex. Hence, two fundamental processing principles - being ubiquitous in the brain - provide the most explanatory power for the emergence of tinnitus: predictive coding as a top-down, and stochastic resonance as a complementary bottom-up mechanism. We conclude that both principles play a crucial role in healthy auditory perception.", "published": "2022-04-07T10:47:58Z", "version": 2}, {"aid": "2204.03475", "authors": ["Tal Ridnik", "Hussam Lawen", "Emanuel Ben-Baruch", "Asaf Noy"], "title": "Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results", "url": "http://arxiv.org/pdf/2204.03475v2", "summary": "ImageNet serves as the primary dataset for evaluating the quality of computer-vision models. The common practice today is training each architecture with a tailor-made scheme, designed and tuned by an expert. In this paper, we present a unified scheme for training any backbone on ImageNet. The scheme, named USI (Unified Scheme for ImageNet), is based on knowledge distillation and modern tricks. It requires no adjustments or hyper-parameters tuning between different models, and is efficient in terms of training times. We test USI on a wide variety of architectures, including CNNs, Transformers, Mobile-oriented and MLP-only. On all models tested, USI outperforms previous state-of-the-art results. Hence, we are able to transform training on ImageNet from an expert-oriented task to an automatic seamless routine. Since USI accepts any backbone and trains it to top results, it also enables to perform methodical comparisons, and identify the most efficient backbones along the speed-accuracy Pareto curve. Implementation is available at:https://github.com/Alibaba-MIIL/Solving_ImageNet", "published": "2022-04-07T14:43:58Z", "version": 2}, {"aid": "2204.03638", "authors": ["Songwei Ge", "Thomas Hayes", "Harry Yang", "Xi Yin", "Guan Pang", "David Jacobs", "Jia-Bin Huang", "Devi Parikh"], "title": "Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer", "url": "http://arxiv.org/pdf/2204.03638v4", "summary": "Videos are created to express emotion, exchange information, and share experiences. Video synthesis has intrigued researchers for a long time. Despite the rapid progress driven by advances in visual synthesis, most existing studies focus on improving the frames' quality and the transitions between them, while little progress has been made in generating longer videos. In this paper, we present a method that builds on 3D-VQGAN and transformers to generate videos with thousands of frames. Our evaluation shows that our model trained on 16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse, and Taichi-HD datasets can generate diverse, coherent, and high-quality long videos. We also showcase conditional extensions of our approach for generating meaningful long videos by incorporating temporal information with text and audio. Videos and code can be found at https://songweige.github.io/projects/tats/index.html.", "published": "2022-04-07T17:59:02Z", "version": 4}, {"aid": "2204.06108", "authors": ["Nicholas Richardson", "Hayden Schaeffer", "Giang Tran"], "title": "SRMD: Sparse Random Mode Decomposition", "url": "http://arxiv.org/pdf/2204.06108v2", "summary": "Signal decomposition and multiscale signal analysis provide many useful tools for time-frequency analysis. We proposed a random feature method for analyzing time-series data by constructing a sparse approximation to the spectrogram. The randomization is both in the time window locations and the frequency sampling, which lowers the overall sampling and computational cost. The sparsification of the spectrogram leads to a sharp separation between time-frequency clusters which makes it easier to identify intrinsic modes, and thus leads to a new data-driven mode decomposition. The applications include signal representation, outlier removal, and mode decomposition. On the benchmark tests, we show that our approach outperforms other state-of-the-art decomposition methods.", "published": "2022-04-12T22:40:10Z", "version": 2}, {"aid": "2204.06552", "authors": ["Edoardo Mello Rella", "Ajad Chhatkuli", "Ender Konukoglu", "Luc Van Gool"], "title": "Neural Vector Fields for Implicit Surface Representation and Inference", "url": "http://arxiv.org/pdf/2204.06552v3", "summary": "Implicit fields have recently shown increasing success in representing and learning 3D shapes accurately. Signed distance fields and occupancy fields are decades old and still the preferred representations, both with well-studied properties, despite their restriction to closed surfaces. With neural networks, several other variations and training principles have been proposed with the goal to represent all classes of shapes. In this paper, we develop a novel and yet a fundamental representation considering unit vectors in 3D space and call it Vector Field (VF): at each point in $\\mathbb{R}^3$, VF is directed at the closest point on the surface. We theoretically demonstrate that VF can be easily transformed to surface density by computing the flux density. Unlike other standard representations, VF directly encodes an important physical property of the surface, its normal. We further show the advantages of VF representation, in learning open, closed, or multi-layered as well as piecewise planar surfaces. We compare our method on several datasets including ShapeNet where the proposed new neural implicit field shows superior accuracy in representing any type of shape, outperforming other standard methods. Code is available at https://github.com/edomel/ImplicitVF.", "published": "2022-04-13T17:53:34Z", "version": 3}, {"aid": "2204.06645", "authors": ["Keaton Hamm", "Nick Henscheid", "Shujie Kang"], "title": "Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning", "url": "http://arxiv.org/pdf/2204.06645v3", "summary": "In this paper, we propose Wasserstein Isometric Mapping (Wassmap), a nonlinear dimensionality reduction technique that provides solutions to some drawbacks in existing global nonlinear dimensionality reduction algorithms in imaging applications. Wassmap represents images via probability measures in Wasserstein space, then uses pairwise Wasserstein distances between the associated measures to produce a low-dimensional, approximately isometric embedding. We show that the algorithm is able to exactly recover parameters of some image manifolds including those generated by translations or dilations of a fixed generating measure. Additionally, we show that a discrete version of the algorithm retrieves parameters from manifolds generated from discrete measures by providing a theoretical bridge to transfer recovery results from functional data to discrete data. Testing of the proposed algorithms on various image data manifolds show that Wassmap yields good embeddings compared with other global and local techniques.", "published": "2022-04-13T21:43:28Z", "version": 3}, {"aid": "2204.06718", "authors": ["Hengyue Pan", "Yixin Chen", "Xin Niu", "Wenbo Zhou", "Dongsheng Li"], "title": "Learning Convolutional Neural Networks in the Frequency Domain", "url": "http://arxiv.org/pdf/2204.06718v10", "summary": "Convolutional neural network (CNN) has achieved impressive success in computer vision during the past few decades. The image convolution operation helps CNNs to get good performance on image-related tasks. However, the image convolution has high computation complexity and hard to be implemented. This paper proposes the CEMNet, which can be trained in the frequency domain. The most important motivation of this research is that we can use the straightforward element-wise multiplication operation to replace the image convolution in the frequency domain based on the Cross-Correlation Theorem, which obviously reduces the computation complexity. We further introduce a Weight Fixation mechanism to alleviate the problem of over-fitting, and analyze the working behavior of Batch Normalization, Leaky ReLU, and Dropout in the frequency domain to design their counterparts for CEMNet. Also, to deal with complex inputs brought by Discrete Fourier Transform, we design a two-branches network structure for CEMNet. Experimental results imply that CEMNet achieves good performance on MNIST and CIFAR-10 databases.", "published": "2022-04-14T03:08:40Z", "version": 10}, {"aid": "2204.07156", "authors": ["Lucy Chai", "Michael Gharbi", "Eli Shechtman", "Phillip Isola", "Richard Zhang"], "title": "Any-resolution Training for High-resolution Image Synthesis", "url": "http://arxiv.org/pdf/2204.07156v2", "summary": "Generative models operate at fixed resolution, even though natural images come in a variety of sizes. As high-resolution details are downsampled away and low-resolution images are discarded altogether, precious supervision is lost. We argue that every pixel matters and create datasets with variable-size images, collected at their native resolutions. To take advantage of varied-size data, we introduce continuous-scale training, a process that samples patches at random scales to train a new generator with variable output resolutions. First, conditioning the generator on a target scale allows us to generate higher resolution images than previously possible, without adding layers to the model. Second, by conditioning on continuous coordinates, we can sample patches that still obey a consistent global layout, which also allows for scalable training at higher resolutions. Controlled FFHQ experiments show that our method can take advantage of multi-resolution training data better than discrete multi-scale approaches, achieving better FID scores and cleaner high-frequency details. We also train on other natural image domains including churches, mountains, and birds, and demonstrate arbitrary scale synthesis with both coherent global layouts and realistic local details, going beyond 2K resolution in our experiments. Our project page is available at: https://chail.github.io/anyres-gan/.", "published": "2022-04-14T17:59:31Z", "version": 2}, {"aid": "2204.07356", "authors": ["Siqu Long", "Feiqi Cao", "Soyeon Caren Han", "Haiqin Yang"], "title": "Vision-and-Language Pretrained Models: A Survey", "url": "http://arxiv.org/pdf/2204.07356v5", "summary": "Pretrained models have produced great success in both Computer Vision (CV) and Natural Language Processing (NLP). This progress leads to learning joint representations of vision and language pretraining by feeding visual and linguistic contents into a multi-layer transformer, Visual-Language Pretrained Models (VLPMs). In this paper, we present an overview of the major advances achieved in VLPMs for producing joint representations of vision and language. As the preliminaries, we briefly describe the general task definition and genetic architecture of VLPMs. We first discuss the language and vision data encoding methods and then present the mainstream VLPM structure as the core content. We further summarise several essential pretraining and fine-tuning strategies. Finally, we highlight three future directions for both CV and NLP researchers to provide insightful guidance.", "published": "2022-04-15T07:33:06Z", "version": 5}, {"aid": "2204.07610", "authors": ["Odd Erik Gundersen", "Kevin Coakley", "Christine Kirkpatrick", "Yolanda Gil"], "title": "Sources of Irreproducibility in Machine Learning: A Review", "url": "http://arxiv.org/pdf/2204.07610v2", "summary": "Background: Many published machine learning studies are irreproducible. Issues with methodology and not properly accounting for variation introduced by the algorithm themselves or their implementations are attributed as the main contributors to the irreproducibility.Problem: There exist no theoretical framework that relates experiment design choices to potential effects on the conclusions. Without such a framework, it is much harder for practitioners and researchers to evaluate experiment results and describe the limitations of experiments. The lack of such a framework also makes it harder for independent researchers to systematically attribute the causes of failed reproducibility experiments. Objective: The objective of this paper is to develop a framework that enable applied data science practitioners and researchers to understand which experiment design choices can lead to false findings and how and by this help in analyzing the conclusions of reproducibility experiments. Method: We have compiled an extensive list of factors reported in the literature that can lead to machine learning studies being irreproducible. These factors are organized and categorized in a reproducibility framework motivated by the stages of the scientific method. The factors are analyzed for how they can affect the conclusions drawn from experiments. A model comparison study is used as an example. Conclusion: We provide a framework that describes machine learning methodology from experimental design decisions to the conclusions inferred from them.", "published": "2022-04-15T18:26:03Z", "version": 2}, {"aid": "2204.08583", "authors": ["Katherine Crowson", "Stella Biderman", "Daniel Kornis", "Dashiell Stander", "Eric Hallahan", "Louis Castricato", "Edward Raff"], "title": "VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance", "url": "http://arxiv.org/pdf/2204.08583v2", "summary": "Generating and editing images from open domain text prompts is a challenging task that heretofore has required expensive and specially trained models. We demonstrate a novel methodology for both tasks which is capable of producing images of high visual quality from text prompts of significant semantic complexity without any training by using a multimodal encoder to guide image generations. We demonstrate on a variety of tasks how using CLIP [37] to guide VQGAN [11] produces higher visual quality outputs than prior, less flexible approaches like DALL-E [38], GLIDE [33] and Open-Edit [24], despite not being trained for the tasks presented. Our code is available in a public repository.", "published": "2022-04-18T22:57:29Z", "version": 2}, {"aid": "2204.10105", "authors": ["Binjie Qin", "Haohao Mao", "Ruipeng Zhang", "Yueqi Zhu", "Song Ding", "Xu Chen"], "title": "Working memory inspired hierarchical video decomposition with transformative representations", "url": "http://arxiv.org/pdf/2204.10105v3", "summary": "Video decomposition is very important to extract moving foreground objects from complex backgrounds in computer vision, machine learning, and medical imaging, e.g., extracting moving contrast-filled vessels from the complex and noisy backgrounds of X-ray coronary angiography (XCA). However, the challenges caused by dynamic backgrounds, overlapping heterogeneous environments and complex noises still exist in video decomposition. To solve these problems, this study is the first to introduce a flexible visual working memory model in video decomposition tasks to provide interpretable and high-performance hierarchical deep architecture, integrating the transformative representations between sensory and control layers from the perspective of visual and cognitive neuroscience. Specifically, robust PCA unrolling networks acting as a structure-regularized sensor layer decompose XCA into sparse/low-rank structured representations to separate moving contrast-filled vessels from noisy and complex backgrounds. Then, patch recurrent convolutional LSTM networks with a backprojection module embody unstructured random representations of the control layer in working memory, recurrently projecting spatiotemporally decomposed nonlocal patches into orthogonal subspaces for heterogeneous vessel retrieval and interference suppression. This video decomposition deep architecture effectively restores the heterogeneous profiles of intensity and the geometries of moving objects against the complex background interferences. Experiments show that the proposed method significantly outperforms state-of-the-art methods in accurate moving contrast-filled vessel extraction with excellent flexibility and computational efficiency.", "published": "2022-04-21T13:49:43Z", "version": 3}, {"aid": "2204.10588", "authors": ["Andreas Habring", "Martin Holler"], "title": "A Note on the Regularity of Images Generated by Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2204.10588v2", "summary": "The regularity of images generated by convolutional neural networks, such as the U-net, generative networks, or the deep image prior, is analyzed. In a resolution-independent, infinite dimensional setting, it is shown that such images, represented as functions, are always continuous and, in some circumstances, even continuously differentiable, contradicting the widely accepted modeling of sharp edges in images via jump discontinuities. While such statements require an infinite dimensional setting, the connection to (discretized) neural networks used in practice is made by considering the limit as the resolution approaches infinity. As practical consequence, the results of this paper in particular provide analytical evidence that basic L2 regularization of network weights might lead to over-smoothed outputs.", "published": "2022-04-22T09:19:49Z", "version": 2}, {"aid": "2204.11795", "authors": ["Ella Lan"], "title": "Performer: A Novel PPG-to-ECG Reconstruction Transformer for a Digital Biomarker of Cardiovascular Disease Detection", "url": "http://arxiv.org/pdf/2204.11795v3", "summary": "Electrocardiography (ECG), an electrical measurement which captures cardiac activities, is the gold standard for diagnosing cardiovascular disease (CVD). However, ECG is infeasible for continuous cardiac monitoring due to its requirement for user participation. By contrast, photoplethysmography (PPG) provides easy-to-collect data, but its limited accuracy constrains its clinical usage. To combine the advantages of both signals, recent studies incorporate various deep learning techniques for the reconstruction of PPG signals to ECG; however, the lack of contextual information as well as the limited abilities to denoise biomedical signals ultimately constrain model performance. In this research, we propose Performer, a novel Transformer-based architecture that reconstructs ECG from PPG and combines the PPG and reconstructed ECG as multiple modalities for CVD detection. This method is the first time that Transformer sequence-to-sequence translation has been performed on biomedical waveform reconstruction, combining the advantages of both PPG and ECG. We also create Shifted Patch-based Attention (SPA), an effective method to encode/decode the biomedical waveforms. Through fetching the various sequence lengths and capturing cross-patch connections, SPA maximizes the signal processing for both local features and global contextual representations. The proposed architecture generates a state-of-the-art performance of 0.29 RMSE for the reconstruction of PPG to ECG on the BIDMC database, surpassing prior studies. We also evaluated this model on the MIMIC-III dataset, achieving a 95.9% accuracy in CVD detection, and on the PPG-BP dataset, achieving 75.9% accuracy in related CVD diabetes detection, indicating its generalizability. As a proof of concept, an earring wearable named PEARL (prototype), was designed to scale up the point-of-care (POC) healthcare system.", "published": "2022-04-25T17:10:13Z", "version": 3}, {"aid": "2204.11824", "authors": ["Andreas Blattmann", "Robin Rombach", "Kaan Oktay", "Jonas M\u00fcller", "Bj\u00f6rn Ommer"], "title": "Semi-Parametric Neural Image Synthesis", "url": "http://arxiv.org/pdf/2204.11824v3", "summary": "Novel architectures have recently improved generative image synthesis leading to excellent visual quality in various tasks. Much of this success is due to the scalability of these architectures and hence caused by a dramatic increase in model complexity and in the computational resources invested in training these models. Our work questions the underlying paradigm of compressing large training data into ever growing parametric representations. We rather present an orthogonal, semi-parametric approach. We complement comparably small diffusion or autoregressive models with a separate image database and a retrieval strategy. During training we retrieve a set of nearest neighbors from this external database for each training instance and condition the generative model on these informative samples. While the retrieval approach is providing the (local) content, the model is focusing on learning the composition of scenes based on this content. As demonstrated by our experiments, simply swapping the database for one with different contents transfers a trained model post-hoc to a novel domain. The evaluation shows competitive performance on tasks which the generative model has not been trained on, such as class-conditional synthesis, zero-shot stylization or text-to-image synthesis without requiring paired text-image data. With negligible memory and computational overhead for the external database and retrieval we can significantly reduce the parameter count of the generative model and still outperform the state-of-the-art.", "published": "2022-04-25T17:55:26Z", "version": 3}, {"aid": "2204.11830", "authors": ["Monish Keswani", "Sriranjani Ramakrishnan", "Nishant Reddy", "Vineeth N Balasubramanian"], "title": "Proto2Proto: Can you recognize the car, the way I do?", "url": "http://arxiv.org/pdf/2204.11830v2", "summary": "Prototypical methods have recently gained a lot of attention due to their intrinsic interpretable nature, which is obtained through the prototypes. With growing use cases of model reuse and distillation, there is a need to also study transfer of interpretability from one model to another. We present Proto2Proto, a novel method to transfer interpretability of one prototypical part network to another via knowledge distillation. Our approach aims to add interpretability to the \"dark\" knowledge transferred from the teacher to the shallower student model. We propose two novel losses: \"Global Explanation\" loss and \"Patch-Prototype Correspondence\" loss to facilitate such a transfer. Global Explanation loss forces the student prototypes to be close to teacher prototypes, and Patch-Prototype Correspondence loss enforces the local representations of the student to be similar to that of the teacher. Further, we propose three novel metrics to evaluate the student's proximity to the teacher as measures of interpretability transfer in our settings. We qualitatively and quantitatively demonstrate the effectiveness of our method on CUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed method indeed achieves interpretability transfer from teacher to student while simultaneously exhibiting competitive performance.", "published": "2022-04-25T17:59:30Z", "version": 2}, {"aid": "2204.13620", "authors": ["Chunwei Tian", "Xuanyu Zhang", "Qi Zhu", "Bob Zhang", "Jerry Chun-Wei Lin"], "title": "Generative Adversarial Networks for Image Super-Resolution: A Survey", "url": "http://arxiv.org/pdf/2204.13620v4", "summary": "Single image super-resolution (SISR) has played an important role in the field of image processing. Recent generative adversarial networks (GANs) can achieve excellent results on low-resolution images with small samples. However, there are little literatures summarizing different GANs in SISR. In this paper, we conduct a comparative study of GANs from different perspectives. We first take a look at developments of GANs. Second, we present popular architectures for GANs in big and small samples for image applications. Then, we analyze motivations, implementations and differences of GANs based optimization methods and discriminative learning for image super-resolution in terms of supervised, semi-supervised and unsupervised manners, where these GANs are analyzed via integrating different network architectures, prior knowledge, loss functions and multiple tasks. Next, we compare performance of these popular GANs on public datasets via quantitative and qualitative analysis in SISR. Finally, we highlight challenges of GANs and potential research points for SISR.", "published": "2022-04-28T16:35:04Z", "version": 4}, {"aid": "2205.01490", "authors": ["Bowen Jing", "Gabriele Corso", "Renato Berlinghieri", "Tommi Jaakkola"], "title": "Subspace Diffusion Generative Models", "url": "http://arxiv.org/pdf/2205.01490v2", "summary": "Score-based models generate samples by mapping noise to data (and vice versa) via a high-dimensional diffusion process. We question whether it is necessary to run this entire process at high dimensionality and incur all the inconveniences thereof. Instead, we restrict the diffusion via projections onto subspaces as the data distribution evolves toward noise. When applied to state-of-the-art models, our framework simultaneously improves sample quality -- reaching an FID of 2.17 on unconditional CIFAR-10 -- and reduces the computational cost of inference for the same number of denoising steps. Our framework is fully compatible with continuous-time diffusion and retains its flexible capabilities, including exact log-likelihoods and controllable generation. Code is available at https://github.com/bjing2016/subspace-diffusion.", "published": "2022-05-03T13:43:47Z", "version": 2}, {"aid": "2205.01491", "authors": ["Mingle Xu", "Sook Yoon", "Alvaro Fuentes", "Dong Sun Park"], "title": "A Comprehensive Survey of Image Augmentation Techniques for Deep Learning", "url": "http://arxiv.org/pdf/2205.01491v2", "summary": "Deep learning has been achieving decent performance in computer vision requiring a large volume of images, however, collecting images is expensive and difficult in many scenarios. To alleviate this issue, many image augmentation algorithms have been proposed as effective and efficient strategies. Understanding current algorithms is essential to find suitable methods or develop novel techniques for given tasks. In this paper, we perform a comprehensive survey on image augmentation for deep learning with a novel informative taxonomy. To get the basic idea why we need image augmentation, we introduce the challenges in computer vision tasks and vicinity distribution. Then, the algorithms are split into three categories; model-free, model-based, and optimizing policy-based. The model-free category employs image processing methods while the model-based method leverages trainable image generation models. In contrast, the optimizing policy-based approach aims to find the optimal operations or their combinations. Furthermore, we discuss the current trend of common applications with two more active topics, leveraging different ways to understand image augmentation, such as group and kernel theory, and deploying image augmentation for unsupervised learning. Based on the analysis, we believe that our survey gives a better understanding helpful to choose suitable methods or design novel algorithms for practical applications.", "published": "2022-05-03T13:45:04Z", "version": 2}, {"aid": "2205.01508", "authors": ["Weichao Lan", "Yiu-ming Cheung", "Juyong Jiang"], "title": "Compact Neural Networks via Stacking Designed Basic Units", "url": "http://arxiv.org/pdf/2205.01508v1", "summary": "Unstructured pruning has the limitation of dealing with the sparse and irregular weights. By contrast, structured pruning can help eliminate this drawback but it requires complex criterion to determine which components to be pruned. To this end, this paper presents a new method termed TissueNet, which directly constructs compact neural networks with fewer weight parameters by independently stacking designed basic units, without requiring additional judgement criteria anymore. Given the basic units of various architectures, they are combined and stacked in a certain form to build up compact neural networks. We formulate TissueNet in diverse popular backbones for comparison with the state-of-the-art pruning methods on different benchmark datasets. Moreover, two new metrics are proposed to evaluate compression performance. Experiment results show that TissueNet can achieve comparable classification accuracy while saving up to around 80% FLOPs and 89.7% parameters. That is, stacking basic units provides a new promising way for network compression.", "published": "2022-05-03T14:04:49Z", "version": 1}, {"aid": "2205.01586", "authors": ["Francesco Pelosin"], "title": "Simpler is Better: off-the-shelf Continual Learning Through Pretrained Backbones", "url": "http://arxiv.org/pdf/2205.01586v2", "summary": "In this short paper, we propose a baseline (off-the-shelf) for Continual Learning of Computer Vision problems, by leveraging the power of pretrained models. By doing so, we devise a simple approach achieving strong performance for most of the common benchmarks. Our approach is fast since requires no parameters updates and has minimal memory requirements (order of KBytes). In particular, the \"training\" phase reorders data and exploit the power of pretrained models to compute a class prototype and fill a memory bank. At inference time we match the closest prototype through a knn-like approach, providing us the prediction. We will see how this naive solution can act as an off-the-shelf continual learning system. In order to better consolidate our results, we compare the devised pipeline with common CNN models and show the superiority of Vision Transformers, suggesting that such architectures have the ability to produce features of higher quality. Moreover, this simple pipeline, raises the same questions raised by previous works \\cite{gdumb} on the effective progresses made by the CL community especially in the dataset considered and the usage of pretrained models. Code is live at https://github.com/francesco-p/off-the-shelf-cl", "published": "2022-05-03T16:03:46Z", "version": 2}, {"aid": "2205.01733", "authors": ["Ling Huang", "Su Ruan", "Thierry Denoeux"], "title": "Application of belief functions to medical image segmentation: A review", "url": "http://arxiv.org/pdf/2205.01733v4", "summary": "The investigation of uncertainty is of major importance in risk-critical applications, such as medical image segmentation. Belief function theory, a formal framework for uncertainty analysis and multiple evidence fusion, has made significant contributions to medical image segmentation, especially since the development of deep learning. In this paper, we provide an introduction to the topic of medical image segmentation methods using belief function theory. We classify the methods according to the fusion step and explain how information with uncertainty or imprecision is modeled and fused with belief function theory. In addition, we discuss the challenges and limitations of present belief function-based medical image segmentation and propose orientations for future research. Future research could investigate both belief function theory and deep learning to achieve more promising and reliable segmentation results.", "published": "2022-05-03T19:06:45Z", "version": 4}, {"aid": "2205.01818", "authors": ["Ziyi Yang", "Yuwei Fang", "Chenguang Zhu", "Reid Pryzant", "Dongdong Chen", "Yu Shi", "Yichong Xu", "Yao Qian", "Mei Gao", "Yi-Ling Chen", "Liyang Lu", "Yujia Xie", "Robert Gmyr", "Noel Codella", "Naoyuki Kanda", "Bin Xiao", "Lu Yuan", "Takuya Yoshioka", "Michael Zeng", "Xuedong Huang"], "title": "i-Code: An Integrative and Composable Multimodal Learning Framework", "url": "http://arxiv.org/pdf/2205.01818v2", "summary": "Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The encoder outputs are then integrated with a multimodal fusion network, which uses novel attention mechanisms and other architectural innovations to effectively combine information from the different modalities. The entire system is pretrained end-to-end with new objectives including masked modality unit modeling and cross-modality contrastive learning. Unlike previous research using only video for pretraining, the i-Code framework can dynamically process single, dual, and triple-modality data during training and inference, flexibly projecting different combinations of modalities into a single representation space. Experimental results demonstrate how i-Code can outperform state-of-the-art techniques on five video understanding tasks and the GLUE NLP benchmark, improving by as much as 11% and demonstrating the power of integrative multimodal pretraining.", "published": "2022-05-03T23:38:50Z", "version": 2}, {"aid": "2205.01903", "authors": ["Sungyeon Kim", "Dongwon Kim", "Minsu Cho", "Suha Kwak"], "title": "Self-Taught Metric Learning without Labels", "url": "http://arxiv.org/pdf/2205.01903v1", "summary": "We present a novel self-taught framework for unsupervised metric learning, which alternates between predicting class-equivalence relations between data through a moving average of an embedding model and learning the model with the predicted relations as pseudo labels. At the heart of our framework lies an algorithm that investigates contexts of data on the embedding space to predict their class-equivalence relations as pseudo labels. The algorithm enables efficient end-to-end training since it demands no off-the-shelf module for pseudo labeling. Also, the class-equivalence relations provide rich supervisory signals for learning an embedding space. On standard benchmarks for metric learning, it clearly outperforms existing unsupervised learning methods and sometimes even beats supervised learning models using the same backbone network. It is also applied to semi-supervised metric learning as a way of exploiting additional unlabeled data, and achieves the state of the art by boosting performance of supervised learning substantially.", "published": "2022-05-04T05:48:40Z", "version": 1}, {"aid": "2205.02084", "authors": ["Yunzhi Zhang", "Jiajun Wu"], "title": "Video Extrapolation in Space and Time", "url": "http://arxiv.org/pdf/2205.02084v3", "summary": "Novel view synthesis (NVS) and video prediction (VP) are typically considered disjoint tasks in computer vision. However, they can both be seen as ways to observe the spatial-temporal world: NVS aims to synthesize a scene from a new point of view, while VP aims to see a scene from a new point of time. These two tasks provide complementary signals to obtain a scene representation, as viewpoint changes from spatial observations inform depth, and temporal observations inform the motion of cameras and individual objects. Inspired by these observations, we propose to study the problem of Video Extrapolation in Space and Time (VEST). We propose a model that leverages the self-supervision and the complementary cues from both tasks, while existing methods can only solve one of them. Experiments show that our method achieves performance better than or comparable to several state-of-the-art NVS and VP methods on indoor and outdoor real-world datasets.", "published": "2022-05-04T14:25:08Z", "version": 3}, {"aid": "2205.02131", "authors": ["Kaveena Persand", "Andrew Anderson", "David Gregg"], "title": "Domino Saliency Metrics: Improving Existing Channel Saliency Metrics with Structural Information", "url": "http://arxiv.org/pdf/2205.02131v2", "summary": "Channel pruning is used to reduce the number of weights in a Convolutional Neural Network (CNN). Channel pruning removes slices of the weight tensor so that the convolution layer remains dense. The removal of these weight slices from a single layer causes mismatching number of feature maps between layers of the network. A simple solution is to force the number of feature map between layers to match through the removal of weight slices from subsequent layers. This additional constraint becomes more apparent in DNNs with branches where multiple channels need to be pruned together to keep the network dense. Popular pruning saliency metrics do not factor in the structural dependencies that arise in DNNs with branches. We propose Domino metrics (built on existing channel saliency metrics) to reflect these structural constraints. We test Domino saliency metrics against the baseline channel saliency metrics on multiple networks with branches. Domino saliency metrics improved pruning rates in most tested networks and up to 25% in AlexNet on CIFAR-10.", "published": "2022-05-04T15:37:51Z", "version": 2}, {"aid": "2205.02698", "authors": ["Konstantin Kobs", "Michael Steininger", "Andrzej Dulny", "Andreas Hotho"], "title": "Do Different Deep Metric Learning Losses Lead to Similar Learned Features?", "url": "http://arxiv.org/pdf/2205.02698v1", "summary": "Recent studies have shown that many deep metric learning loss functions perform very similarly under the same experimental conditions. One potential reason for this unexpected result is that all losses let the network focus on similar image regions or properties. In this paper, we investigate this by conducting a two-step analysis to extract and compare the learned visual features of the same model architecture trained with different loss functions: First, we compare the learned features on the pixel level by correlating saliency maps of the same input images. Second, we compare the clustering of embeddings for several image properties, e.g. object color or illumination. To provide independent control over these properties, photo-realistic 3D car renders similar to images in the Cars196 dataset are generated. In our analysis, we compare 14 pretrained models from a recent study and find that, even though all models perform similarly, different loss functions can guide the model to learn different features. We especially find differences between classification and ranking based losses. Our analysis also shows that some seemingly irrelevant properties can have significant influence on the resulting embedding. We encourage researchers from the deep metric learning community to use our methods to get insights into the features learned by their proposed methods.", "published": "2022-05-05T15:07:19Z", "version": 1}, {"aid": "2205.02767", "authors": ["Zulun Zhu", "Jiaying Peng", "Jintang Li", "Liang Chen", "Qi Yu", "Siqiang Luo"], "title": "Spiking Graph Convolutional Networks", "url": "http://arxiv.org/pdf/2205.02767v2", "summary": "Graph Convolutional Networks (GCNs) achieve an impressive performance due to the remarkable representation ability in learning the graph information. However, GCNs, when implemented on a deep network, require expensive computation power, making them difficult to be deployed on battery-powered devices. In contrast, Spiking Neural Networks (SNNs), which perform a bio-fidelity inference process, offer an energy-efficient neural architecture. In this work, we propose SpikingGCN, an end-to-end framework that aims to integrate the embedding of GCNs with the biofidelity characteristics of SNNs. The original graph data are encoded into spike trains based on the incorporation of graph convolution. We further model biological information processing by utilizing a fully connected layer combined with neuron nodes. In a wide range of scenarios (e.g. citation networks, image graph classification, and recommender systems), our experimental results show that the proposed method could gain competitive performance against state-of-the-art approaches. Furthermore, we show that SpikingGCN on a neuromorphic chip can bring a clear advantage of energy efficiency into graph data analysis, which demonstrates its great potential to construct environment-friendly machine learning models.", "published": "2022-05-05T16:44:36Z", "version": 2}, {"aid": "2205.04545", "authors": ["Eli Sennesh", "Tom Xu", "Yoshihiro Maruyama"], "title": "A Probabilistic Generative Model of Free Categories", "url": "http://arxiv.org/pdf/2205.04545v2", "summary": "Applied category theory has recently developed libraries for computing with morphisms in interesting categories, while machine learning has developed ways of learning programs in interesting languages. Taking the analogy between categories and languages seriously, this paper defines a probabilistic generative model of morphisms in free monoidal categories over domain-specific generating objects and morphisms. The paper shows how acyclic directed wiring diagrams can model specifications for morphisms, which the model can use to generate morphisms. Amortized variational inference in the generative model then enables learning of parameters (by maximum likelihood) and inference of latent variables (by Bayesian inversion). A concrete experiment shows that the free category prior achieves competitive reconstruction performance on the Omniglot dataset.", "published": "2022-05-09T20:35:08Z", "version": 2}, {"aid": "2205.04596", "authors": ["Vijay Vasudevan", "Benjamin Caine", "Raphael Gontijo-Lopes", "Sara Fridovich-Keil", "Rebecca Roelofs"], "title": "When does dough become a bagel? Analyzing the remaining mistakes on ImageNet", "url": "http://arxiv.org/pdf/2205.04596v2", "summary": "Image classification accuracy on the ImageNet dataset has been a barometer for progress in computer vision over the last decade. Several recent papers have questioned the degree to which the benchmark remains useful to the community, yet innovations continue to contribute gains to performance, with today's largest models achieving 90%+ top-1 accuracy. To help contextualize progress on ImageNet and provide a more meaningful evaluation for today's state-of-the-art models, we manually review and categorize every remaining mistake that a few top models make in order to provide insight into the long-tail of errors on one of the most benchmarked datasets in computer vision. We focus on the multi-label subset evaluation of ImageNet, where today's best models achieve upwards of 97% top-1 accuracy. Our analysis reveals that nearly half of the supposed mistakes are not mistakes at all, and we uncover new valid multi-labels, demonstrating that, without careful review, we are significantly underestimating the performance of these models. On the other hand, we also find that today's best models still make a significant number of mistakes (40%) that are obviously wrong to human reviewers. To calibrate future progress on ImageNet, we provide an updated multi-label evaluation set, and we curate ImageNet-Major: a 68-example \"major error\" slice of the obvious mistakes made by today's top models -- a slice where models should achieve near perfection, but today are far from doing so.", "published": "2022-05-09T23:25:45Z", "version": 2}, {"aid": "2205.05303", "authors": ["Fabian A. Mikulasch", "Lucas Rudelt", "Michael Wibral", "Viola Priesemann"], "title": "Dendritic predictive coding: A theory of cortical computation with spiking neurons", "url": "http://arxiv.org/pdf/2205.05303v1", "summary": "Top-down feedback in cortex is critical for guiding sensory processing, which has prominently been formalized in the theory of hierarchical predictive coding (hPC). However, experimental evidence for error units, which are central to the theory, is inconclusive, and it remains unclear how hPC can be implemented with spiking neurons. To address this, we connect hPC to existing work on efficient coding in balanced networks with lateral inhibition, and predictive computation at apical dendrites. Together, this work points to an efficient implementation of hPC with spiking neurons, where prediction errors are computed not in separate units, but locally in dendritic compartments. The implied model shows a remarkable correspondence to experimentally observed cortical connectivity patterns, plasticity and dynamics, and at the same time can explain hallmarks of predictive processing, such as mismatch responses, in cortex. We thus propose dendritic predictive coding as one of the main organizational principles of cortex.", "published": "2022-05-11T07:08:19Z", "version": 1}, {"aid": "2205.05671", "authors": ["Xintao Wang", "Chao Dong", "Ying Shan"], "title": "RepSR: Training Efficient VGG-style Super-Resolution Networks with Structural Re-Parameterization and Batch Normalization", "url": "http://arxiv.org/pdf/2205.05671v1", "summary": "This paper explores training efficient VGG-style super-resolution (SR) networks with the structural re-parameterization technique. The general pipeline of re-parameterization is to train networks with multi-branch topology first, and then merge them into standard 3x3 convolutions for efficient inference. In this work, we revisit those primary designs and investigate essential components for re-parameterizing SR networks. First of all, we find that batch normalization (BN) is important to bring training non-linearity and improve the final performance. However, BN is typically ignored in SR, as it usually degrades the performance and introduces unpleasant artifacts. We carefully analyze the cause of BN issue and then propose a straightforward yet effective solution. In particular, we first train SR networks with mini-batch statistics as usual, and then switch to using population statistics at the later training period. While we have successfully re-introduced BN into SR, we further design a new re-parameterizable block tailored for SR, namely RepSR. It consists of a clean residual path and two expand-and-squeeze convolution paths with the modified BN. Extensive experiments demonstrate that our simple RepSR is capable of achieving superior performance to previous SR re-parameterization methods among different model sizes. In addition, our RepSR can achieve a better trade-off between performance and actual running time (throughput) than previous SR methods. Codes will be available at https://github.com/TencentARC/RepSR.", "published": "2022-05-11T17:55:49Z", "version": 1}, {"aid": "2205.05874", "authors": ["David Mac\u00eado", "Cleber Zanchettin", "Teresa Ludermir"], "title": "Distinction Maximization Loss: Efficiently Improving Out-of-Distribution Detection and Uncertainty Estimation by Replacing the Loss and Calibrating", "url": "http://arxiv.org/pdf/2205.05874v5", "summary": "Building robust deterministic neural networks remains a challenge. On the one hand, some approaches improve out-of-distribution detection at the cost of reducing classification accuracy in some situations. On the other hand, some methods simultaneously increase classification accuracy, uncertainty estimation, and out-of-distribution detection at the expense of reducing the inference efficiency. In this paper, we propose training deterministic neural networks using our DisMax loss, which works as a drop-in replacement for the usual SoftMax loss (i.e., the combination of the linear output layer, the SoftMax activation, and the cross-entropy loss). Starting from the IsoMax+ loss, we create each logit based on the distances to all prototypes, rather than just the one associated with the correct class. We also introduce a mechanism to combine images to construct what we call fractional probability regularization. Moreover, we present a fast way to calibrate the network after training. Finally, we propose a composite score to perform out-of-distribution detection. Our experiments show that DisMax usually outperforms current approaches simultaneously in classification accuracy, uncertainty estimation, and out-of-distribution detection while maintaining deterministic neural network inference efficiency. The code to reproduce the results is available at https://github.com/dlmacedo/distinction-maximization-loss.", "published": "2022-05-12T04:37:35Z", "version": 5}, {"aid": "2205.06254", "authors": ["Enric Corona", "Gerard Pons-Moll", "Guillem Aleny\u00e0", "Francesc Moreno-Noguer"], "title": "Learned Vertex Descent: A New Direction for 3D Human Model Fitting", "url": "http://arxiv.org/pdf/2205.06254v2", "summary": "We propose a novel optimization-based paradigm for 3D human model fitting on images and scans. In contrast to existing approaches that directly regress the parameters of a low-dimensional statistical body model (e.g. SMPL) from input images, we train an ensemble of per-vertex neural fields network. The network predicts, in a distributed manner, the vertex descent direction towards the ground truth, based on neural features extracted at the current vertex projection. At inference, we employ this network, dubbed LVD, within a gradient-descent optimization pipeline until its convergence, which typically occurs in a fraction of a second even when initializing all vertices into a single point. An exhaustive evaluation demonstrates that our approach is able to capture the underlying body of clothed people with very different body shapes, achieving a significant improvement compared to state-of-the-art. LVD is also applicable to 3D model fitting of humans and hands, for which we show a significant improvement to the SOTA with a much simpler and faster method.", "published": "2022-05-12T17:55:51Z", "version": 2}, {"aid": "2205.06769", "authors": ["W. Jeffrey Johnston", "Justin M. Fine", "Seng Bum Michael Yoo", "R. Becket Ebitz", "Benjamin Y. Hayden"], "title": "Subspace orthogonalization as a mechanism for binding values to space", "url": "http://arxiv.org/pdf/2205.06769v2", "summary": "When choosing between options, we must solve an important binding problem. The values of the options must be associated with information about the action needed to select them. We hypothesize that the brain solves this binding problem through use of distinct population subspaces. To test this hypothesis, we examined the responses of single neurons in five reward-sensitive regions in rhesus macaques performing a risky choice task. In all areas, neurons encoded the value of the offers presented on both the left and the right side of the display in semi-orthogonal subspaces, which served to bind the values of the two offers to their positions in space. Supporting the idea that this orthogonalization is functionally meaningful, we observed a session-to-session covariation between choice behavior and the orthogonalization of the two value subspaces: trials with less orthogonalized subspaces were associated with greater likelihood of choosing the less valued option. Further inspection revealed that these semi-orthogonal subspaces arose from a combination of linear and nonlinear mixed selectivity in the neural population. We show this combination of selectivity balances reliable binding with an ability to generalize value across different spatial locations. These results support the hypothesis that semi-orthogonal subspaces support reliable binding, which is essential to flexible behavior in the face of multiple options.", "published": "2022-05-13T16:57:54Z", "version": 2}, {"aid": "2205.06929", "authors": ["Mohamed R. Ibrahim", "Terry Lyons"], "title": "ImageSig: A signature transform for ultra-lightweight image recognition", "url": "http://arxiv.org/pdf/2205.06929v1", "summary": "This paper introduces a new lightweight method for image recognition. ImageSig is based on computing signatures and does not require a convolutional structure or an attention-based encoder. It is striking to the authors that it achieves: a) an accuracy for 64 X 64 RGB images that exceeds many of the state-of-the-art methods and simultaneously b) requires orders of magnitude less FLOPS, power and memory footprint. The pretrained model can be as small as 44.2 KB in size. ImageSig shows unprecedented performance on hardware such as Raspberry Pi and Jetson-nano. ImageSig treats images as streams with multiple channels. These streams are parameterized by spatial directions. We contribute to the functionality of signature and rough path theory to stream-like data and vision tasks on static images beyond temporal streams. With very few parameters and small size models, the key advantage is that one could have many of these \"detectors\" assembled on the same chip; moreover, the feature acquisition can be performed once and shared between different models of different tasks - further accelerating the process. This contributes to energy efficiency and the advancements of embedded AI at the edge.", "published": "2022-05-13T23:48:32Z", "version": 1}, {"aid": "2205.06978", "authors": ["Yang Ni", "Danny Abraham", "Mariam Issa", "Yeseong Kim", "Pietro Mercati", "Mohsen Imani"], "title": "Efficient Off-Policy Reinforcement Learning via Brain-Inspired Computing", "url": "http://arxiv.org/pdf/2205.06978v3", "summary": "Reinforcement Learning (RL) has opened up new opportunities to enhance existing smart systems that generally include a complex decision-making process. However, modern RL algorithms, e.g., Deep Q-Networks (DQN), are based on deep neural networks, resulting in high computational costs. In this paper, we propose QHD, an off-policy value-based Hyperdimensional Reinforcement Learning, that mimics brain properties toward robust and real-time learning. QHD relies on a lightweight brain-inspired model to learn an optimal policy in an unknown environment. On both desktop and power-limited embedded platforms, QHD achieves significantly better overall efficiency than DQN while providing higher or comparable rewards. QHD is also suitable for highly-efficient reinforcement learning with great potential for online and real-time learning. Our solution supports a small experience replay batch size that provides 12.3 times speedup compared to DQN while ensuring minimal quality loss. Our evaluation shows QHD capability for real-time learning, providing 34.6 times speedup and significantly better quality of learning than DQN.", "published": "2022-05-14T05:50:54Z", "version": 3}, {"aid": "2205.07019", "authors": ["Yihao Liu", "Hengyuan Zhao", "Jinjin Gu", "Yu Qiao", "Chao Dong"], "title": "Evaluating the Generalization Ability of Super-Resolution Networks", "url": "http://arxiv.org/pdf/2205.07019v2", "summary": "Performance and generalization ability are two important aspects to evaluate the deep learning models. However, research on the generalization ability of Super-Resolution (SR) networks is currently absent. Assessing the generalization ability of deep models not only helps us to understand their intrinsic mechanisms, but also allows us to quantitatively measure their applicability boundaries, which is important for unrestricted real-world applications. To this end, we make the first attempt to propose a Generalization Assessment Index for SR networks, namely SRGA. SRGA exploits the statistical characteristics of the internal features of deep networks to measure the generalization ability. Specially, it is a non-parametric and non-learning metric. To better validate our method, we collect a patch-based image evaluation set (PIES) that includes both synthetic and real-world images, covering a wide range of degradations. With SRGA and PIES dataset, we benchmark existing SR models on the generalization ability. This work provides insights and tools for future research on model generalization in low-level vision.", "published": "2022-05-14T09:33:20Z", "version": 2}, {"aid": "2205.07060", "authors": ["Anssi Kanervisto", "Tomi Kinnunen", "Ville Hautam\u00e4ki"], "title": "GAN-Aimbots: Using Machine Learning for Cheating in First Person Shooters", "url": "http://arxiv.org/pdf/2205.07060v1", "summary": "Playing games with cheaters is not fun, and in a multi-billion-dollar video game industry with hundreds of millions of players, game developers aim to improve the security and, consequently, the user experience of their games by preventing cheating. Both traditional software-based methods and statistical systems have been successful in protecting against cheating, but recent advances in the automatic generation of content, such as images or speech, threaten the video game industry; they could be used to generate artificial gameplay indistinguishable from that of legitimate human players. To better understand this threat, we begin by reviewing the current state of multiplayer video game cheating, and then proceed to build a proof-of-concept method, GAN-Aimbot. By gathering data from various players in a first-person shooter game we show that the method improves players' performance while remaining hidden from automatic and manual protection mechanisms. By sharing this work we hope to raise awareness on this issue and encourage further research into protecting the gaming communities.", "published": "2022-05-14T13:33:23Z", "version": 1}, {"aid": "2205.07384", "authors": ["Ziyang Jiang", "Tongshu Zheng", "Yiling Liu", "David Carlson"], "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel", "url": "http://arxiv.org/pdf/2205.07384v8", "summary": "It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping based on the Nystrom approximation, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demonstrate that ICK has superior performance and flexibility on both synthetic and real-world data sets. We believe that ICK framework can be used to include prior information into neural networks in many applications.", "published": "2022-05-15T21:32:44Z", "version": 8}, {"aid": "2205.07467", "authors": ["Lingwei Zhu", "Zheng Chen", "Eiji Uchibe", "Takamitsu Matsubara"], "title": "$q$-Munchausen Reinforcement Learning", "url": "http://arxiv.org/pdf/2205.07467v1", "summary": "The recently successful Munchausen Reinforcement Learning (M-RL) features implicit Kullback-Leibler (KL) regularization by augmenting the reward function with logarithm of the current stochastic policy. Though significant improvement has been shown with the Boltzmann softmax policy, when the Tsallis sparsemax policy is considered, the augmentation leads to a flat learning curve for almost every problem considered. We show that it is due to the mismatch between the conventional logarithm and the non-logarithmic (generalized) nature of Tsallis entropy. Drawing inspiration from the Tsallis statistics literature, we propose to correct the mismatch of M-RL with the help of $q$-logarithm/exponential functions. The proposed formulation leads to implicit Tsallis KL regularization under the maximum Tsallis entropy framework. We show such formulation of M-RL again achieves superior performance on benchmark problems and sheds light on more general M-RL with various entropic indices $q$.", "published": "2022-05-16T06:26:10Z", "version": 1}, {"aid": "2205.07547", "authors": ["Yuhta Takida", "Takashi Shibuya", "WeiHsiang Liao", "Chieh-Hsin Lai", "Junki Ohmura", "Toshimitsu Uesaka", "Naoki Murata", "Shusuke Takahashi", "Toshiyuki Kumakura", "Yuki Mitsufuji"], "title": "SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization", "url": "http://arxiv.org/pdf/2205.07547v2", "summary": "One noted issue of vector-quantized variational autoencoder (VQ-VAE) is that the learned discrete representation uses only a fraction of the full capacity of the codebook, also known as codebook collapse. We hypothesize that the training scheme of VQ-VAE, which involves some carefully designed heuristics, underlies this issue. In this paper, we propose a new training scheme that extends the standard VAE via novel stochastic dequantization and quantization, called stochastically quantized variational autoencoder (SQ-VAE). In SQ-VAE, we observe a trend that the quantization is stochastic at the initial stage of the training but gradually converges toward a deterministic quantization, which we call self-annealing. Our experiments show that SQ-VAE improves codebook utilization without using common heuristics. Furthermore, we empirically show that SQ-VAE is superior to VAE and VQ-VAE in vision- and speech-related tasks.", "published": "2022-05-16T09:49:37Z", "version": 2}, {"aid": "2205.08413", "authors": ["Max Dabagia", "Konrad P Kording", "Eva L Dyer"], "title": "Comparing high-dimensional neural recordings by aligning their low-dimensional latent representations", "url": "http://arxiv.org/pdf/2205.08413v1", "summary": "Many questions in neuroscience involve understanding of the responses of large populations of neurons. However, when dealing with large-scale neural activity, interpretation becomes difficult, and comparisons between two animals, or across different time points becomes challenging. One major challenge that we face in modern neuroscience is that of correspondence, e.g. we do not record the exact same neurons at the exact same times. Without some way to link two or more datasets, comparing different collections of neural activity patterns becomes impossible. Here, we describe approaches for leveraging shared latent structure across neural recordings to tackle this correspondence challenge. We review algorithms that map two datasets into a shared space where they can be directly compared, and argue that alignment is key for comparing high-dimensional neural activities across times, subsets of neurons, and individuals.", "published": "2022-05-17T14:52:09Z", "version": 1}, {"aid": "2205.09435", "authors": ["David S. Watson", "Kristin Blesch", "Jan Kapar", "Marvin N. Wright"], "title": "Adversarial random forests for density estimation and generative modeling", "url": "http://arxiv.org/pdf/2205.09435v4", "summary": "We propose methods for density estimation and data synthesis using a novel form of unsupervised random forests. Inspired by generative adversarial networks, we implement a recursive procedure in which trees gradually learn structural properties of the data through alternating rounds of generation and discrimination. The method is provably consistent under minimal assumptions. Unlike classic tree-based alternatives, our approach provides smooth (un)conditional densities and allows for fully synthetic data generation. We achieve comparable or superior performance to state-of-the-art probabilistic circuits and deep learning models on various tabular data benchmarks while executing about two orders of magnitude faster on average. An accompanying $\\texttt{R}$ package, $\\texttt{arf}$, is available on $\\texttt{CRAN}$.", "published": "2022-05-19T09:50:25Z", "version": 4}, {"aid": "2205.09801", "authors": ["Charilaos I. Kanatsoulis", "Alejandro Ribeiro"], "title": "Representation Power of Graph Neural Networks: Improved Expressivity via Algebraic Analysis", "url": "http://arxiv.org/pdf/2205.09801v3", "summary": "Despite the remarkable success of Graph Neural Networks (GNNs), the common belief is that their representation power is limited and that they are at most as expressive as the Weisfeiler-Lehman (WL) algorithm. In this paper, we argue the opposite and show that standard GNNs, with anonymous inputs, produce more discriminative representations than the WL algorithm. Our novel analysis employs linear algebraic tools and characterizes the representation power of GNNs with respect to the eigenvalue decomposition of the graph operators. We prove that GNNs are able to generate distinctive outputs from white uninformative inputs, for, at least, all graphs that have different eigenvalues. We also show that simple convolutional architectures with white inputs, produce equivariant features that count the closed paths in the graph and are provably more expressive than the WL representations. Thorough experimental analysis on graph isomorphism and graph classification datasets corroborates our theoretical results and demonstrates the effectiveness of the proposed approach.", "published": "2022-05-19T18:40:25Z", "version": 3}, {"aid": "2205.09821", "authors": ["Dipan Mandal", "Abhilash Jain"], "title": "Unsupervised Learning of Depth, Camera Pose and Optical Flow from Monocular Video", "url": "http://arxiv.org/pdf/2205.09821v2", "summary": "We propose DFPNet -- an unsupervised, joint learning system for monocular Depth, Optical Flow and egomotion (Camera Pose) estimation from monocular image sequences. Due to the nature of 3D scene geometry these three components are coupled. We leverage this fact to jointly train all the three components in an end-to-end manner. A single composite loss function -- which involves image reconstruction-based loss for depth & optical flow, bidirectional consistency checks and smoothness loss components -- is used to train the network. Using hyperparameter tuning, we are able to reduce the model size to less than 5% (8.4M parameters) of state-of-the-art DFP models. Evaluation on KITTI and Cityscapes driving datasets reveals that our model achieves results comparable to state-of-the-art in all of the three tasks, even with the significantly smaller model size.", "published": "2022-05-19T19:47:41Z", "version": 2}, {"aid": "2205.09875", "authors": ["James Seale Smith", "Zachary Seymour", "Han-Pang Chiu"], "title": "Incremental Learning with Differentiable Architecture and Forgetting Search", "url": "http://arxiv.org/pdf/2205.09875v1", "summary": "As progress is made on training machine learning models on incrementally expanding classification tasks (i.e., incremental learning), a next step is to translate this progress to industry expectations. One technique missing from incremental learning is automatic architecture design via Neural Architecture Search (NAS). In this paper, we show that leveraging NAS for incremental learning results in strong performance gains for classification tasks. Specifically, we contribute the following: first, we create a strong baseline approach for incremental learning based on Differentiable Architecture Search (DARTS) and state-of-the-art incremental learning strategies, outperforming many existing strategies trained with similar-sized popular architectures; second, we extend the idea of architecture search to regularize architecture forgetting, boosting performance past our proposed baseline. We evaluate our method on both RF signal and image classification tasks, and demonstrate we can achieve up to a 10% performance increase over state-of-the-art methods. Most importantly, our contribution enables learning from continuous distributions on real-world application data for which the complexity of the data distribution is unknown, or the modality less explored (such as RF signal classification).", "published": "2022-05-19T21:47:26Z", "version": 1}, {"aid": "2205.09909", "authors": ["Michael Minyi Zhang"], "title": "Sparse Infinite Random Feature Latent Variable Modeling", "url": "http://arxiv.org/pdf/2205.09909v2", "summary": "We propose a non-linear, Bayesian non-parametric latent variable model where the latent space is assumed to be sparse and infinite dimensional a priori using an Indian buffet process prior. A posteriori, the number of instantiated dimensions in the latent space is guaranteed to be finite. The purpose of placing the Indian buffet process on the latent variables is to: 1.) Automatically and probabilistically select the number of latent dimensions. 2.) Impose sparsity in the latent space, where the Indian buffet process will select which elements are exactly zero. Our proposed model allows for sparse, non-linear latent variable modeling where the number of latent dimensions is selected automatically. Inference is made tractable using the random Fourier approximation and we can easily implement posterior inference through Markov chain Monte Carlo sampling. This approach is amenable to many observation models beyond the Gaussian setting. We demonstrate the utility of our method on a variety of synthetic, biological and text datasets and show that we can obtain superior test set performance compared to previous latent variable models.", "published": "2022-05-20T00:29:28Z", "version": 2}, {"aid": "2205.09930", "authors": ["Jason Yoo", "Frank Wood"], "title": "BayesPCN: A Continually Learnable Predictive Coding Associative Memory", "url": "http://arxiv.org/pdf/2205.09930v3", "summary": "Associative memory plays an important role in human intelligence and its mechanisms have been linked to attention in machine learning. While the machine learning community's interest in associative memories has recently been rekindled, most work has focused on memory recall ($read$) over memory learning ($write$). In this paper, we present BayesPCN, a hierarchical associative memory capable of performing continual one-shot memory writes without meta-learning. Moreover, BayesPCN is able to gradually forget past observations ($forget$) to free its memory. Experiments show that BayesPCN can recall corrupted i.i.d. high-dimensional data observed hundreds to a thousand ``timesteps'' ago without a large drop in recall ability compared to the state-of-the-art offline-learned parametric memory models.", "published": "2022-05-20T02:28:11Z", "version": 3}, {"aid": "2205.10044", "authors": ["Cristiano Capone", "Pier Stanislao Paolucci"], "title": "Towards biologically plausible Dreaming and Planning in recurrent spiking networks", "url": "http://arxiv.org/pdf/2205.10044v3", "summary": "Humans and animals can learn new skills after practicing for a few hours, while current reinforcement learning algorithms require a large amount of data to achieve good performances. Recent model-based approaches show promising results by reducing the number of necessary interactions with the environment to learn a desirable policy. However, these methods require biological implausible ingredients, such as the detailed storage of older experiences, and long periods of offline learning. The optimal way to learn and exploit word-models is still an open question. Taking inspiration from biology, we suggest that dreaming might be an efficient expedient to use an inner model. We propose a two-module (agent and model) spiking neural network in which \"dreaming\" (living new experiences in a model-based simulated environment) significantly boosts learning. We also explore \"planning\", an online alternative to dreaming, that shows comparable performances. Importantly, our model does not require the detailed storage of experiences, and learns online the world-model and the policy. Moreover, we stress that our network is composed of spiking neurons, further increasing the biological plausibility and implementability in neuromorphic hardware.", "published": "2022-05-20T09:35:26Z", "version": 3}, {"aid": "2205.10089", "authors": ["Reza Nasirigerdeh", "Reihaneh Torkzadehmahani", "Daniel Rueckert", "Georgios Kaissis"], "title": "Kernel Normalized Convolutional Networks", "url": "http://arxiv.org/pdf/2205.10089v4", "summary": "Existing convolutional neural network architectures frequently rely upon batch normalization (BatchNorm) to effectively train the model. BatchNorm, however, performs poorly with small batch sizes, and is inapplicable to differential privacy. To address these limitations, we propose the kernel normalization (KernelNorm) and kernel normalized convolutional layers, and incorporate them into kernel normalized convolutional networks (KNConvNets) as the main building blocks. We implement KNConvNets corresponding to the state-of-the-art ResNets while forgoing the BatchNorm layers. Through extensive experiments, we illustrate that KNConvNets achieve higher or competitive performance compared to the BatchNorm counterparts in image classification and semantic segmentation. They also significantly outperform their batch-independent competitors including those based on layer and group normalization in non-private and differentially private training. Given that, KernelNorm combines the batch-independence property of layer and group normalization with the performance advantage of BatchNorm.", "published": "2022-05-20T11:18:05Z", "version": 4}, {"aid": "2205.10268", "authors": ["Moritz B\u00f6hle", "Mario Fritz", "Bernt Schiele"], "title": "B-cos Networks: Alignment is All We Need for Interpretability", "url": "http://arxiv.org/pdf/2205.10268v1", "summary": "We present a new direction for increasing the interpretability of deep neural networks (DNNs) by promoting weight-input alignment during training. For this, we propose to replace the linear transforms in DNNs by our B-cos transform. As we show, a sequence (network) of such transforms induces a single linear transform that faithfully summarises the full model computations. Moreover, the B-cos transform introduces alignment pressure on the weights during optimisation. As a result, those induced linear transforms become highly interpretable and align with task-relevant features. Importantly, the B-cos transform is designed to be compatible with existing architectures and we show that it can easily be integrated into common models such as VGGs, ResNets, InceptionNets, and DenseNets, whilst maintaining similar performance on ImageNet. The resulting explanations are of high visual quality and perform well under quantitative metrics for interpretability. Code available at https://www.github.com/moboehle/B-cos.", "published": "2022-05-20T16:03:29Z", "version": 1}, {"aid": "2205.10279", "authors": ["Ravid Shwartz-Ziv", "Micah Goldblum", "Hossein Souri", "Sanyam Kapoor", "Chen Zhu", "Yann LeCun", "Andrew Gordon Wilson"], "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors", "url": "http://arxiv.org/pdf/2205.10279v1", "summary": "Deep learning is increasingly moving towards a transfer learning paradigm whereby large foundation models are fine-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task. Instead, we show that we can learn highly informative posteriors from the source task, through supervised or self-supervised approaches, which then serve as the basis for priors that modify the whole loss surface on the downstream task. This simple modular approach enables significant performance gains and more data-efficient learning on a variety of downstream classification and segmentation tasks, serving as a drop-in replacement for standard pre-training strategies. These highly informative priors also can be saved for future use, similar to pre-trained weights, and stand in contrast to the zero-mean isotropic uninformative priors that are typically used in Bayesian deep learning.", "published": "2022-05-20T16:19:30Z", "version": 1}, {"aid": "2205.10316", "authors": ["Jorge Ram\u00edrez-Ruiz", "Dmytro Grytskyy", "Chiara Mastrogiuseppe", "Yamen Habib", "Rub\u00e9n Moreno-Bote"], "title": "Complex behavior from intrinsic motivation to occupy action-state path space", "url": "http://arxiv.org/pdf/2205.10316v2", "summary": "Most theories of behavior posit that agents tend to maximize some form of reward or utility. However, animals very often move with curiosity and seem to be motivated in a reward-free manner. Here we abandon the idea of reward maximization, and propose that the goal of behavior is maximizing occupancy of future paths of actions and states. According to this maximum occupancy principle, rewards are the means to occupy path space, not the goal per se; goal-directedness simply emerges as rational ways of searching for resources so that movement, understood amply, never ends. We find that action-state path entropy is the only measure consistent with additivity and other intuitive properties of expected future action-state path occupancy. We provide analytical expressions that relate the optimal policy and state-value function, and prove convergence of our value iteration algorithm. Using discrete and continuous state tasks, including a high--dimensional controller, we show that complex behaviors such as `dancing', hide-and-seek and a basic form of altruistic behavior naturally result from the intrinsic motivation to occupy path space. All in all, we present a theory of behavior that generates both variability and goal-directedness in the absence of reward maximization.", "published": "2022-05-20T17:32:41Z", "version": 2}, {"aid": "2205.10347", "authors": ["Jean Prost", "Antoine Houdard", "Andr\u00e9s Almansa", "Nicolas Papadakis"], "title": "Diverse super-resolution with pretrained deep hiererarchical VAEs", "url": "http://arxiv.org/pdf/2205.10347v4", "summary": "We investigate the problem of producing diverse solutions to an image super-resolution problem. From a probabilistic perspective, this can be done by sampling from the posterior distribution of an inverse problem, which requires the definition of a prior distribution on the high-resolution images. In this work, we propose to use a pretrained hierarchical variational autoencoder (HVAE) as a prior. We train a lightweight stochastic encoder to encode low-resolution images in the latent space of a pretrained HVAE. At inference, we combine the low-resolution encoder and the pretrained generative model to super-resolve an image. We demonstrate on the task of face super-resolution that our method provides an advantageous trade-off between the computational efficiency of conditional normalizing flows techniques and the sample quality of diffusion based methods.", "published": "2022-05-20T17:57:41Z", "version": 4}, {"aid": "2205.10760", "authors": ["Vamshi C. Madala", "Shivkumar Chandrasekaran", "Jason Bunk"], "title": "CNNs Avoid Curse of Dimensionality by Learning on Patches", "url": "http://arxiv.org/pdf/2205.10760v4", "summary": "Despite the success of convolutional neural networks (CNNs) in numerous computer vision tasks and their extraordinary generalization performances, several attempts to predict the generalization errors of CNNs have only been limited to a posteriori analyses thus far. A priori theories explaining the generalization performances of deep neural networks have mostly ignored the convolutionality aspect and do not specify why CNNs are able to seemingly overcome curse of dimensionality on computer vision tasks like image classification where the image dimensions are in thousands. Our work attempts to explain the generalization performance of CNNs on image classification under the hypothesis that CNNs operate on the domain of image patches. Ours is the first work we are aware of to derive an a priori error bound for the generalization error of CNNs and we present both quantitative and qualitative evidences in the support of our theory. Our patch-based theory also offers explanation for why data augmentation techniques like Cutout, CutMix and random cropping are effective in improving the generalization error of CNNs.", "published": "2022-05-22T06:22:27Z", "version": 4}, {"aid": "2205.12524", "authors": ["Zhaoyang Lyu", "Xudong XU", "Ceyuan Yang", "Dahua Lin", "Bo Dai"], "title": "Accelerating Diffusion Models via Early Stop of the Diffusion Process", "url": "http://arxiv.org/pdf/2205.12524v2", "summary": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved impressive performance on various generation tasks. By modeling the reverse process of gradually diffusing the data distribution into a Gaussian distribution, generating a sample in DDPMs can be regarded as iteratively denoising a randomly sampled Gaussian noise. However, in practice DDPMs often need hundreds even thousands of denoising steps to obtain a high-quality sample from the Gaussian noise, leading to extremely low inference efficiency. In this work, we propose a principled acceleration strategy, referred to as Early-Stopped DDPM (ES-DDPM), for DDPMs. The key idea is to stop the diffusion process early where only the few initial diffusing steps are considered and the reverse denoising process starts from a non-Gaussian distribution. By further adopting a powerful pre-trained generative model, such as GAN and VAE, in ES-DDPM, sampling from the target non-Gaussian distribution can be efficiently achieved by diffusing samples obtained from the pre-trained generative model. In this way, the number of required denoising steps is significantly reduced. In the meantime, the sample quality of ES-DDPM also improves substantially, outperforming both the vanilla DDPM and the adopted pre-trained generative model. On extensive experiments across CIFAR-10, CelebA, ImageNet, LSUN-Bedroom and LSUN-Cat, ES-DDPM obtains promising acceleration effect and performance improvement over representative baseline methods. Moreover, ES-DDPM also demonstrates several attractive properties, including being orthogonal to existing acceleration methods, as well as simultaneously enabling both global semantic and local pixel-level control in image generation.", "published": "2022-05-25T06:40:09Z", "version": 2}, {"aid": "2205.12533", "authors": ["James Langley", "Miguel Monteiro", "Charles Jones", "Nick Pawlowski", "Ben Glocker"], "title": "Structured Uncertainty in the Observation Space of Variational Autoencoders", "url": "http://arxiv.org/pdf/2205.12533v2", "summary": "Variational autoencoders (VAEs) are a popular class of deep generative models with many variants and a wide range of applications. Improvements upon the standard VAE mostly focus on the modelling of the posterior distribution over the latent space and the properties of the neural network decoder. In contrast, improving the model for the observational distribution is rarely considered and typically defaults to a pixel-wise independent categorical or normal distribution. In image synthesis, sampling from such distributions produces spatially-incoherent results with uncorrelated pixel noise, resulting in only the sample mean being somewhat useful as an output prediction. In this paper, we aim to stay true to VAE theory by improving the samples from the observational distribution. We propose SOS-VAE, an alternative model for the observation space, encoding spatial dependencies via a low-rank parameterisation. We demonstrate that this new observational distribution has the ability to capture relevant covariance between pixels, resulting in spatially-coherent samples. In contrast to pixel-wise independent distributions, our samples seem to contain semantically-meaningful variations from the mean allowing the prediction of multiple plausible outputs with a single forward pass.", "published": "2022-05-25T07:12:50Z", "version": 2}, {"aid": "2205.12956", "authors": ["Chenyang Si", "Weihao Yu", "Pan Zhou", "Yichen Zhou", "Xinchao Wang", "Shuicheng Yan"], "title": "Inception Transformer", "url": "http://arxiv.org/pdf/2205.12956v2", "summary": "Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high- and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of convolution and max-pooling for capturing the high-frequency information to Transformers. Different from recent hybrid frameworks, the Inception mixer brings greater efficiency through a channel splitting mechanism to adopt parallel convolution/max-pooling path and self-attention path as high- and low-frequency mixers, while having the flexibility to model discriminative information scattered within a wide frequency range. Considering that bottom layers play more roles in capturing high-frequency details while top layers more in modeling low-frequency global information, we further introduce a frequency ramp structure, i.e. gradually decreasing the dimensions fed to the high-frequency mixer and increasing those to the low-frequency mixer, which can effectively trade-off high- and low-frequency components across different layers. We benchmark the iFormer on a series of vision tasks, and showcase that it achieves impressive performance on image classification, COCO detection and ADE20K segmentation. For example, our iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than DeiT-S by 3.6%, and even slightly better than much bigger model Swin-B (83.3%) with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at https://github.com/sail-sg/iFormer.", "published": "2022-05-25T17:59:54Z", "version": 2}, {"aid": "2205.13076", "authors": ["Amir Joudaki", "Hadi Daneshmand", "Francis Bach"], "title": "On Bridging the Gap between Mean Field and Finite Width in Deep Random Neural Networks with Batch Normalization", "url": "http://arxiv.org/pdf/2205.13076v3", "summary": "Mean field theory is widely used in the theoretical studies of neural networks. In this paper, we analyze the role of depth in the concentration of mean-field predictions, specifically for deep multilayer perceptron (MLP) with batch normalization (BN) at initialization. By scaling the network width to infinity, it is postulated that the mean-field predictions suffer from layer-wise errors that amplify with depth. We demonstrate that BN stabilizes the distribution of representations that avoids the error propagation of mean-field predictions. This stabilization, which is characterized by a geometric mixing property, allows us to establish concentration bounds for mean field predictions in infinitely-deep neural networks with a finite width.", "published": "2022-05-25T23:00:26Z", "version": 3}, {"aid": "2205.13147", "authors": ["Aditya Kusupati", "Gantavya Bhatt", "Aniket Rege", "Matthew Wallingford", "Aditya Sinha", "Vivek Ramanujan", "William Howard-Snyder", "Kaifeng Chen", "Sham Kakade", "Prateek Jain", "Ali Farhadi"], "title": "Matryoshka Representation Learning", "url": "http://arxiv.org/pdf/2205.13147v4", "summary": "Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context rigid, fixed capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying computational resources? Our main contribution is Matryoshka Representation Learning (MRL) which encodes information at different granularities and allows a single embedding to adapt to the computational constraints of downstream tasks. MRL minimally modifies existing representation learning pipelines and imposes no additional cost during inference and deployment. MRL learns coarse-to-fine representations that are at least as accurate and rich as independently trained low-dimensional representations. The flexibility within the learned Matryoshka Representations offer: (a) up to 14x smaller embedding size for ImageNet-1K classification at the same level of accuracy; (b) up to 14x real-world speed-ups for large-scale retrieval on ImageNet-1K and 4K; and (c) up to 2% accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations. Finally, we show that MRL extends seamlessly to web-scale datasets (ImageNet, JFT) across various modalities -- vision (ViT, ResNet), vision + language (ALIGN) and language (BERT). MRL code and pretrained models are open-sourced at https://github.com/RAIVNLab/MRL.", "published": "2022-05-26T04:33:56Z", "version": 4}, {"aid": "2205.13554", "authors": ["Andy Shih", "Dorsa Sadigh", "Stefano Ermon"], "title": "Training and Inference on Any-Order Autoregressive Models the Right Way", "url": "http://arxiv.org/pdf/2205.13554v2", "summary": "Conditional inference on arbitrary subsets of variables is a core problem in probabilistic inference with important applications such as masked language modeling and image inpainting. In recent years, the family of Any-Order Autoregressive Models (AO-ARMs) -- closely related to popular models such as BERT and XLNet -- has shown breakthrough performance in arbitrary conditional tasks across a sweeping range of domains. But, in spite of their success, in this paper we identify significant improvements to be made to previous formulations of AO-ARMs. First, we show that AO-ARMs suffer from redundancy in their probabilistic model, i.e., they define the same distribution in multiple different ways. We alleviate this redundancy by training on a smaller set of univariate conditionals that still maintains support for efficient arbitrary conditional inference. Second, we upweight the training loss for univariate conditionals that are evaluated more frequently during inference. Our method leads to improved performance with no compromises on tractability, giving state-of-the-art likelihoods in arbitrary conditional modeling on text (Text8), image (CIFAR10, ImageNet32), and continuous tabular data domains.", "published": "2022-05-26T18:00:02Z", "version": 2}, {"aid": "2205.13599", "authors": ["Selena Ling", "Nicholas Sharp", "Alec Jacobson"], "title": "VectorAdam for Rotation Equivariant Geometry Optimization", "url": "http://arxiv.org/pdf/2205.13599v4", "summary": "The Adam optimization algorithm has proven remarkably effective for optimization problems across machine learning and even traditional tasks in geometry processing. At the same time, the development of equivariant methods, which preserve their output under the action of rotation or some other transformation, has proven to be important for geometry problems across these domains. In this work, we observe that Adam $-$ when treated as a function that maps initial conditions to optimized results $-$ is not rotation equivariant for vector-valued parameters due to per-coordinate moment updates. This leads to significant artifacts and biases in practice. We propose to resolve this deficiency with VectorAdam, a simple modification which makes Adam rotation-equivariant by accounting for the vector structure of optimization variables. We demonstrate this approach on problems in machine learning and traditional geometric optimization, showing that equivariant VectorAdam resolves the artifacts and biases of traditional Adam when applied to vector-valued data, with equivalent or even improved rates of convergence.", "published": "2022-05-26T20:11:05Z", "version": 4}, {"aid": "2205.13863", "authors": ["Binghui Li", "Jikai Jin", "Han Zhong", "John E. Hopcroft", "Liwei Wang"], "title": "Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power", "url": "http://arxiv.org/pdf/2205.13863v3", "summary": "It is well-known that modern neural networks are vulnerable to adversarial examples. To mitigate this problem, a series of robust learning algorithms have been proposed. However, although the robust training error can be near zero via some methods, all existing algorithms lead to a high robust generalization error. In this paper, we provide a theoretical understanding of this puzzling phenomenon from the perspective of expressive power for deep neural networks. Specifically, for binary classification problems with well-separated data, we show that, for ReLU networks, while mild over-parameterization is sufficient for high robust training accuracy, there exists a constant robust generalization gap unless the size of the neural network is exponential in the data dimension $d$. This result holds even if the data is linear separable (which means achieving standard generalization is easy), and more generally for any parameterized function classes as long as their VC dimension is at most polynomial in the number of parameters. Moreover, we establish an improved upper bound of $\\exp({\\mathcal{O}}(k))$ for the network size to achieve low robust generalization error when the data lies on a manifold with intrinsic dimension $k$ ($k \\ll d$). Nonetheless, we also have a lower bound that grows exponentially with respect to $k$ -- the curse of dimensionality is inevitable. By demonstrating an exponential separation between the network size for achieving low robust training and generalization error, our results reveal that the hardness of robust generalization may stem from the expressive power of practical models.", "published": "2022-05-27T09:53:04Z", "version": 3}, {"aid": "2205.13913", "authors": ["Zhishu Sun", "Zhifeng Shen", "Luojun Lin", "Yuanlong Yu", "Zhifeng Yang", "Shicai Yang", "Weijie Chen"], "title": "Dynamic Domain Generalization", "url": "http://arxiv.org/pdf/2205.13913v1", "summary": "Domain generalization (DG) is a fundamental yet very challenging research topic in machine learning. The existing arts mainly focus on learning domain-invariant features with limited source domains in a static model. Unfortunately, there is a lack of training-free mechanism to adjust the model when generalized to the agnostic target domains. To tackle this problem, we develop a brand-new DG variant, namely Dynamic Domain Generalization (DDG), in which the model learns to twist the network parameters to adapt the data from different domains. Specifically, we leverage a meta-adjuster to twist the network parameters based on the static model with respect to different data from different domains. In this way, the static model is optimized to learn domain-shared features, while the meta-adjuster is designed to learn domain-specific features. To enable this process, DomainMix is exploited to simulate data from diverse domains during teaching the meta-adjuster to adapt to the upcoming agnostic target domains. This learning mechanism urges the model to generalize to different agnostic target domains via adjusting the model without training. Extensive experiments demonstrate the effectiveness of our proposed method. Code is available at: https://github.com/MetaVisionLab/DDG", "published": "2022-05-27T11:29:03Z", "version": 1}, {"aid": "2205.14540", "authors": ["Feng Liang", "Yangguang Li", "Diana Marculescu"], "title": "SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners", "url": "http://arxiv.org/pdf/2205.14540v3", "summary": "Recently, self-supervised Masked Autoencoders (MAE) have attracted unprecedented attention for their impressive representation learning ability. However, the pretext task, Masked Image Modeling (MIM), reconstructs the missing local patches, lacking the global understanding of the image. This paper extends MAE to a fully supervised setting by adding a supervised classification branch, thereby enabling MAE to learn global features from golden labels effectively. The proposed Supervised MAE (SupMAE) only exploits a visible subset of image patches for classification, unlike the standard supervised pre-training where all image patches are used. Through experiments, we demonstrate that SupMAE is not only more training efficient but it also learns more robust and transferable features. Specifically, SupMAE achieves comparable performance with MAE using only 30% of compute when evaluated on ImageNet with the ViT-B/16 model. SupMAE's robustness on ImageNet variants and transfer learning performance outperforms MAE and standard supervised pre-training counterparts. Codes are available at https://github.com/enyac-group/supmae.", "published": "2022-05-28T23:05:03Z", "version": 3}, {"aid": "2205.14871", "authors": ["Ziteng Cui", "Kunchang Li", "Lin Gu", "Shenghan Su", "Peng Gao", "Zhengkai Jiang", "Yu Qiao", "Tatsuya Harada"], "title": "You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image Enhancement and Exposure Correction", "url": "http://arxiv.org/pdf/2205.14871v4", "summary": "Challenging illumination conditions (low-light, under-exposure and over-exposure) in the real world not only cast an unpleasant visual appearance but also taint the computer vision tasks. After camera captures the raw-RGB data, it renders standard sRGB images with image signal processor (ISP). By decomposing ISP pipeline into local and global image components, we propose a lightweight fast Illumination Adaptive Transformer (IAT) to restore the normal lit sRGB image from either low-light or under/over-exposure conditions. Specifically, IAT uses attention queries to represent and adjust the ISP-related parameters such as colour correction, gamma correction. With only ~90k parameters and ~0.004s processing speed, our IAT consistently achieves superior performance over SOTA on the current benchmark low-light enhancement and exposure correction datasets. Competitive experimental performance also demonstrates that our IAT significantly enhances object detection and semantic segmentation tasks under various light conditions. Training code and pretrained model is available at https://github.com/cuiziteng/Illumination-Adaptive-Transformer.", "published": "2022-05-30T06:21:52Z", "version": 4}, {"aid": "2205.15146", "authors": ["Zhanpeng Zhou", "Wen Shen", "Huixin Chen", "Ling Tang", "Quanshi Zhang"], "title": "Batch Normalization Is Blind to the First and Second Derivatives of the Loss", "url": "http://arxiv.org/pdf/2205.15146v2", "summary": "In this paper, we prove the effects of the BN operation on the back-propagation of the first and second derivatives of the loss. When we do the Taylor series expansion of the loss function, we prove that the BN operation will block the influence of the first-order term and most influence of the second-order term of the loss. We also find that such a problem is caused by the standardization phase of the BN operation. Experimental results have verified our theoretical conclusions, and we have found that the BN operation significantly affects feature representations in specific tasks, where losses of different samples share similar analytic formulas.", "published": "2022-05-30T14:43:51Z", "version": 2}, {"aid": "2205.15242", "authors": ["Xiaohan Ding", "Honghao Chen", "Xiangyu Zhang", "Kaiqi Huang", "Jungong Han", "Guiguang Ding"], "title": "Re-parameterizing Your Optimizers rather than Architectures", "url": "http://arxiv.org/pdf/2205.15242v4", "summary": "The well-designed structures in neural networks reflect the prior knowledge incorporated into the models. However, though different models have various priors, we are used to training them with model-agnostic optimizers such as SGD. In this paper, we propose to incorporate model-specific prior knowledge into optimizers by modifying the gradients according to a set of model-specific hyper-parameters. Such a methodology is referred to as Gradient Re-parameterization, and the optimizers are named RepOptimizers. For the extreme simplicity of model structure, we focus on a VGG-style plain model and showcase that such a simple model trained with a RepOptimizer, which is referred to as RepOpt-VGG, performs on par with or better than the recent well-designed models. From a practical perspective, RepOpt-VGG is a favorable base model because of its simple structure, high inference speed and training efficiency. Compared to Structural Re-parameterization, which adds priors into models via constructing extra training-time structures, RepOptimizers require no extra forward/backward computations and solve the problem of quantization. We hope to spark further research beyond the realms of model structure design. Code and models \\url{https://github.com/DingXiaoH/RepOptimizers}.", "published": "2022-05-30T16:55:59Z", "version": 4}, {"aid": "2205.15894", "authors": ["Kashif Rasul", "Young-Jin Park", "Max Nihl\u00e9n Ramstr\u00f6m", "Kyung-Min Kim"], "title": "VQ-AR: Vector Quantized Autoregressive Probabilistic Time Series Forecasting", "url": "http://arxiv.org/pdf/2205.15894v1", "summary": "Time series models aim for accurate predictions of the future given the past, where the forecasts are used for important downstream tasks like business decision making. In practice, deep learning based time series models come in many forms, but at a high level learn some continuous representation of the past and use it to output point or probabilistic forecasts. In this paper, we introduce a novel autoregressive architecture, VQ-AR, which instead learns a \\emph{discrete} set of representations that are used to predict the future. Extensive empirical comparison with other competitive deep learning models shows that surprisingly such a discrete set of representations gives state-of-the-art or equivalent results on a wide variety of time series datasets. We also highlight the shortcomings of this approach, explore its zero-shot generalization capabilities, and present an ablation study on the number of representations. The full source code of the method will be available at the time of publication with the hope that researchers can further investigate this important but overlooked inductive bias for the time series domain.", "published": "2022-05-31T15:43:46Z", "version": 1}, {"aid": "2205.16007", "authors": ["Zhicong Tang", "Shuyang Gu", "Jianmin Bao", "Dong Chen", "Fang Wen"], "title": "Improved Vector Quantized Diffusion Models", "url": "http://arxiv.org/pdf/2205.16007v2", "summary": "Vector quantized diffusion (VQ-Diffusion) is a powerful generative model for text-to-image synthesis, but sometimes can still generate low-quality samples or weakly correlated images with text input. We find these issues are mainly due to the flawed sampling strategy. In this paper, we propose two important techniques to further improve the sample quality of VQ-Diffusion. 1) We explore classifier-free guidance sampling for discrete denoising diffusion model and propose a more general and effective implementation of classifier-free guidance. 2) We present a high-quality inference strategy to alleviate the joint distribution issue in VQ-Diffusion. Finally, we conduct experiments on various datasets to validate their effectiveness and show that the improved VQ-Diffusion suppresses the vanilla version by large margins. We achieve an 8.44 FID score on MSCOCO, surpassing VQ-Diffusion by 5.42 FID score. When trained on ImageNet, we dramatically improve the FID score from 11.89 to 4.83, demonstrating the superiority of our proposed techniques.", "published": "2022-05-31T17:59:53Z", "version": 2}, {"aid": "2206.02629", "authors": ["Beren Millidge", "Yuhang Song", "Tommaso Salvatori", "Thomas Lukasiewicz", "Rafal Bogacz"], "title": "Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning", "url": "http://arxiv.org/pdf/2206.02629v3", "summary": "How the brain performs credit assignment is a fundamental unsolved problem in neuroscience. Many `biologically plausible' algorithms have been proposed, which compute gradients that approximate those computed by backpropagation (BP), and which operate in ways that more closely satisfy the constraints imposed by neural circuitry. Many such algorithms utilize the framework of energy-based models (EBMs), in which all free variables in the model are optimized to minimize a global energy function. However, in the literature, these algorithms exist in isolation and no unified theory exists linking them together. Here, we provide a comprehensive theory of the conditions under which EBMs can approximate BP, which lets us unify many of the BP approximation results in the literature (namely, predictive coding, equilibrium propagation, and contrastive Hebbian learning) and demonstrate that their approximation to BP arises from a simple and general mathematical property of EBMs at free-phase equilibrium. This property can then be exploited in different ways with different energy functions, and these specific choices yield a family of BP-approximating algorithms, which both includes the known results in the literature and can be used to derive new ones.", "published": "2022-05-31T20:48:52Z", "version": 3}, {"aid": "2206.00182", "authors": ["Ali Athar", "Jonathon Luiten", "Alexander Hermans", "Deva Ramanan", "Bastian Leibe"], "title": "Differentiable Soft-Masked Attention", "url": "http://arxiv.org/pdf/2206.00182v2", "summary": "Transformers have become prevalent in computer vision due to their performance and flexibility in modelling complex operations. Of particular significance is the 'cross-attention' operation, which allows a vector representation (e.g. of an object in an image) to be learned by attending to an arbitrarily sized set of input features. Recently, \"Masked Attention\" was proposed in which a given object representation only attends to those image pixel features for which the segmentation mask of that object is active. This specialization of attention proved beneficial for various image and video segmentation tasks. In this paper, we propose another specialization of attention which enables attending over `soft-masks' (those with continuous mask probabilities instead of binary values), and is also differentiable through these mask probabilities, thus allowing the mask used for attention to be learned within the network without requiring direct loss supervision. This can be useful for several applications. Specifically, we employ our \"Differentiable Soft-Masked Attention\" for the task of Weakly-Supervised Video Object Segmentation (VOS), where we develop a transformer-based network for VOS which only requires a single annotated image frame for training, but can also benefit from cycle consistency training on a video with just one annotated frame. Although there is no loss for masks in unlabeled frames, the network is still able to segment objects in those frames due to our novel attention formulation. Code: https://github.com/Ali2500/HODOR/blob/main/hodor/modelling/encoder/soft_masked_attention.py", "published": "2022-06-01T02:05:13Z", "version": 2}, {"aid": "2206.00244", "authors": ["Jiuk Hong", "Chaehyeon Lee", "Soyoun Bang", "Heechul Jung"], "title": "Fair Comparison between Efficient Attentions", "url": "http://arxiv.org/pdf/2206.00244v1", "summary": "Transformers have been successfully used in various fields and are becoming the standard tools in computer vision. However, self-attention, a core component of transformers, has a quadratic complexity problem, which limits the use of transformers in various vision tasks that require dense prediction. Many studies aiming at solving this problem have been reported proposed. However, no comparative study of these methods using the same scale has been reported due to different model configurations, training schemes, and new methods. In our paper, we validate these efficient attention models on the ImageNet1K classification task by changing only the attention operation and examining which efficient attention is better.", "published": "2022-06-01T06:00:13Z", "version": 1}, {"aid": "2206.00272", "authors": ["Kai Han", "Yunhe Wang", "Jianyuan Guo", "Yehui Tang", "Enhua Wu"], "title": "Vision GNN: An Image is Worth Graph of Nodes", "url": "http://arxiv.org/pdf/2206.00272v3", "summary": "Network architecture plays a key role in the deep learning-based computer vision system. The widely-used convolutional neural network and transformer treat the image as a grid or sequence structure, which is not flexible to capture irregular and complex objects. In this paper, we propose to represent the image as a graph structure and introduce a new Vision GNN (ViG) architecture to extract graph-level feature for visual tasks. We first split the image to a number of patches which are viewed as nodes, and construct a graph by connecting the nearest neighbors. Based on the graph representation of images, we build our ViG model to transform and exchange information among all the nodes. ViG consists of two basic modules: Grapher module with graph convolution for aggregating and updating graph information, and FFN module with two linear layers for node feature transformation. Both isotropic and pyramid architectures of ViG are built with different model sizes. Extensive experiments on image recognition and object detection tasks demonstrate the superiority of our ViG architecture. We hope this pioneering study of GNN on general visual tasks will provide useful inspiration and experience for future research. The PyTorch code is available at https://github.com/huawei-noah/Efficient-AI-Backbones and the MindSpore code is available at https://gitee.com/mindspore/models.", "published": "2022-06-01T07:01:04Z", "version": 3}, {"aid": "2206.01730", "authors": ["J\u00e9r\u00f4me Bolte", "Ryan Boustany", "Edouard Pauwels", "B\u00e9atrice Pesquet-Popescu"], "title": "On the complexity of nonsmooth automatic differentiation", "url": "http://arxiv.org/pdf/2206.01730v2", "summary": "Using the notion of conservative gradient, we provide a simple model to estimate the computational costs of the backward and forward modes of algorithmic differentiation for a wide class of nonsmooth programs. The overhead complexity of the backward mode turns out to be independent of the dimension when using programs with locally Lipschitz semi-algebraic or definable elementary functions. This considerably extends Baur-Strassen's smooth cheap gradient principle. We illustrate our results by establishing fast backpropagation results of conservative gradients through feedforward neural networks with standard activation and loss functions. Nonsmooth backpropagation's cheapness contrasts with concurrent forward approaches, which have, to this day, dimensional-dependent worst-case overhead estimates. We provide further results suggesting the superiority of backward propagation of conservative gradients. Indeed, we relate the complexity of computing a large number of directional derivatives to that of matrix multiplication, and we show that finding two subgradients in the Clarke subdifferential of a function is an NP-hard problem.", "published": "2022-06-01T08:43:35Z", "version": 2}, {"aid": "2206.00384", "authors": ["Jaewon Kim", "Hyukjong Lee", "Jooyoung Chang", "Sang Min Park"], "title": "Generalized Supervised Contrastive Learning", "url": "http://arxiv.org/pdf/2206.00384v2", "summary": "With the recent promising results of contrastive learning in the self-supervised learning paradigm, supervised contrastive learning has successfully extended these contrastive approaches to supervised contexts, outperforming cross-entropy on various datasets. However, supervised contrastive learning inherently employs label information in a binary form--either positive or negative--using a one-hot target vector. This structure struggles to adapt to methods that exploit label information as a probability distribution, such as CutMix and knowledge distillation. In this paper, we introduce a generalized supervised contrastive loss, which measures cross-entropy between label similarity and latent similarity. This concept enhances the capabilities of supervised contrastive loss by fully utilizing the label distribution and enabling the adaptation of various existing techniques for training modern neural networks. Leveraging this generalized supervised contrastive loss, we construct a tailored framework: the Generalized Supervised Contrastive Learning (GenSCL). Compared to existing contrastive learning frameworks, GenSCL incorporates additional enhancements, including advanced image-based regularization techniques and an arbitrary teacher classifier. When applied to ResNet50 with the Momentum Contrast technique, GenSCL achieves a top-1 accuracy of 77.3% on ImageNet, a 4.1% relative improvement over traditional supervised contrastive learning. Moreover, our method establishes new state-of-the-art accuracies of 98.2% and 87.0% on CIFAR10 and CIFAR100 respectively when applied to ResNet50, marking the highest reported figures for this architecture.", "published": "2022-06-01T10:38:21Z", "version": 2}, {"aid": "2206.00746", "authors": ["Shayan Shekarforoush", "David B. Lindell", "David J. Fleet", "Marcus A. Brubaker"], "title": "Residual Multiplicative Filter Networks for Multiscale Reconstruction", "url": "http://arxiv.org/pdf/2206.00746v2", "summary": "Coordinate networks like Multiplicative Filter Networks (MFNs) and BACON offer some control over the frequency spectrum used to represent continuous signals such as images or 3D volumes. Yet, they are not readily applicable to problems for which coarse-to-fine estimation is required, including various inverse problems in which coarse-to-fine optimization plays a key role in avoiding poor local minima. We introduce a new coordinate network architecture and training scheme that enables coarse-to-fine optimization with fine-grained control over the frequency support of learned reconstructions. This is achieved with two key innovations. First, we incorporate skip connections so that structure at one scale is preserved when fitting finer-scale structure. Second, we propose a novel initialization scheme to provide control over the model frequency spectrum at each stage of optimization. We demonstrate how these modifications enable multiscale optimization for coarse-to-fine fitting to natural images. We then evaluate our model on synthetically generated datasets for the the problem of single-particle cryo-EM reconstruction. We learn high resolution multiscale structures, on par with the state-of-the art.", "published": "2022-06-01T20:16:28Z", "version": 2}, {"aid": "2206.00823", "authors": ["Yuhan Helena Liu", "Arna Ghosh", "Blake A. Richards", "Eric Shea-Brown", "Guillaume Lajoie"], "title": "Beyond accuracy: generalization properties of bio-plausible temporal credit assignment rules", "url": "http://arxiv.org/pdf/2206.00823v3", "summary": "To unveil how the brain learns, ongoing work seeks biologically-plausible approximations of gradient descent algorithms for training recurrent neural networks (RNNs). Yet, beyond task accuracy, it is unclear if such learning rules converge to solutions that exhibit different levels of generalization than their nonbiologically-plausible counterparts. Leveraging results from deep learning theory based on loss landscape curvature, we ask: how do biologically-plausible gradient approximations affect generalization? We first demonstrate that state-of-the-art biologically-plausible learning rules for training RNNs exhibit worse and more variable generalization performance compared to their machine learning counterparts that follow the true gradient more closely. Next, we verify that such generalization performance is correlated significantly with loss landscape curvature, and we show that biologically-plausible learning rules tend to approach high-curvature regions in synaptic weight space. Using tools from dynamical systems, we derive theoretical arguments and present a theorem explaining this phenomenon. This predicts our numerical results, and explains why biologically-plausible rules lead to worse and more variable generalization properties. Finally, we suggest potential remedies that could be used by the brain to mitigate this effect. To our knowledge, our analysis is the first to identify the reason for this generalization gap between artificial and biologically-plausible learning rules, which can help guide future investigations into how the brain learns solutions that generalize.", "published": "2022-06-02T01:39:08Z", "version": 3}, {"aid": "2206.00941", "authors": ["Hyungjin Chung", "Byeongsu Sim", "Dohoon Ryu", "Jong Chul Ye"], "title": "Improving Diffusion Models for Inverse Problems using Manifold Constraints", "url": "http://arxiv.org/pdf/2206.00941v3", "summary": "Recently, diffusion models have been used to solve various inverse problems in an unsupervised manner with appropriate modifications to the sampling process. However, the current solvers, which recursively apply a reverse diffusion step followed by a projection-based measurement consistency step, often produce suboptimal results. By studying the generative sampling path, here we show that current solvers throw the sample path off the data manifold, and hence the error accumulates. To address this, we propose an additional correction term inspired by the manifold constraint, which can be used synergistically with the previous solvers to make the iterations close to the manifold. The proposed manifold constraint is straightforward to implement within a few lines of code, yet boosts the performance by a surprisingly large margin. With extensive experiments, we show that our method is superior to the previous methods both theoretically and empirically, producing promising results in many applications such as image inpainting, colorization, and sparse-view computed tomography. Code available https://github.com/HJ-harry/MCG_diffusion", "published": "2022-06-02T09:06:10Z", "version": 3}, {"aid": "2206.01338", "authors": ["Yuhan Helena Liu", "Stephen Smith", "Stefan Mihalas", "Eric Shea-Brown", "Uygar S\u00fcmb\u00fcl"], "title": "Biologically-plausible backpropagation through arbitrary timespans via local neuromodulators", "url": "http://arxiv.org/pdf/2206.01338v4", "summary": "The spectacular successes of recurrent neural network models where key parameters are adjusted via backpropagation-based gradient descent have inspired much thought as to how biological neuronal networks might solve the corresponding synaptic credit assignment problem. There is so far little agreement, however, as to how biological networks could implement the necessary backpropagation through time, given widely recognized constraints of biological synaptic network signaling architectures. Here, we propose that extra-synaptic diffusion of local neuromodulators such as neuropeptides may afford an effective mode of backpropagation lying within the bounds of biological plausibility. Going beyond existing temporal truncation-based gradient approximations, our approximate gradient-based update rule, ModProp, propagates credit information through arbitrary time steps. ModProp suggests that modulatory signals can act on receiving cells by convolving their eligibility traces via causal, time-invariant and synapse-type-specific filter taps. Our mathematical analysis of ModProp learning, together with simulation results on benchmark temporal tasks, demonstrate the advantage of ModProp over existing biologically-plausible temporal credit assignment rules. These results suggest a potential neuronal mechanism for signaling credit information related to recurrent interactions over a longer time horizon. Finally, we derive an in-silico implementation of ModProp that could serve as a low-complexity and causal alternative to backpropagation through time.", "published": "2022-06-02T23:38:10Z", "version": 4}, {"aid": "2206.01342", "authors": ["Yuandong Tian"], "title": "Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning", "url": "http://arxiv.org/pdf/2206.01342v3", "summary": "While the empirical success of self-supervised learning (SSL) heavily relies on the usage of deep nonlinear models, existing theoretical works on SSL understanding still focus on linear ones. In this paper, we study the role of nonlinearity in the training dynamics of contrastive learning (CL) on one and two-layer nonlinear networks with homogeneous activation $h(x) = h'(x)x$. We have two major theoretical discoveries. First, the presence of nonlinearity can lead to many local optima even in 1-layer setting, each corresponding to certain patterns from the data distribution, while with linear activation, only one major pattern can be learned. This suggests that models with lots of parameters can be regarded as a \\emph{brute-force} way to find these local optima induced by nonlinearity. Second, in the 2-layer case, linear activation is proven not capable of learning specialized weights into diverse patterns, demonstrating the importance of nonlinearity. In addition, for 2-layer setting, we also discover \\emph{global modulation}: those local patterns discriminative from the perspective of global-level patterns are prioritized to learn, further characterizing the learning process. Simulation verifies our theoretical findings.", "published": "2022-06-02T23:52:35Z", "version": 3}, {"aid": "2206.02574", "authors": ["Quentin Garrido", "Yubei Chen", "Adrien Bardes", "Laurent Najman", "Yann Lecun"], "title": "On the duality between contrastive and non-contrastive self-supervised learning", "url": "http://arxiv.org/pdf/2206.02574v3", "summary": "Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning.", "published": "2022-06-03T08:04:12Z", "version": 3}, {"aid": "2206.01714", "authors": ["Nan Liu", "Shuang Li", "Yilun Du", "Antonio Torralba", "Joshua B. Tenenbaum"], "title": "Compositional Visual Generation with Composable Diffusion Models", "url": "http://arxiv.org/pdf/2206.01714v6", "summary": "Large text-guided diffusion models, such as DALLE-2, are able to generate stunning photorealistic images given natural language descriptions. While such models are highly flexible, they struggle to understand the composition of certain concepts, such as confusing the attributes of different objects or relations between objects. In this paper, we propose an alternative structured approach for compositional generation using diffusion models. An image is generated by composing a set of diffusion models, with each of them modeling a certain component of the image. To do this, we interpret diffusion models as energy-based models in which the data distributions defined by the energy functions may be explicitly combined. The proposed method can generate scenes at test time that are substantially more complex than those seen in training, composing sentence descriptions, object relations, human facial attributes, and even generalizing to new combinations that are rarely seen in the real world. We further illustrate how our approach may be used to compose pre-trained text-guided diffusion models and generate photorealistic images containing all the details described in the input descriptions, including the binding of certain object attributes that have been shown difficult for DALLE-2. These results point to the effectiveness of the proposed method in promoting structured generalization for visual generation. Project page: https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/", "published": "2022-06-03T17:47:04Z", "version": 6}, {"aid": "2206.01934", "authors": ["Hoang Phan", "Ngoc Tran", "Trung Le", "Toan Tran", "Nhat Ho", "Dinh Phung"], "title": "Stochastic Multiple Target Sampling Gradient Descent", "url": "http://arxiv.org/pdf/2206.01934v4", "summary": "Sampling from an unnormalized target distribution is an essential problem with many applications in probabilistic inference. Stein Variational Gradient Descent (SVGD) has been shown to be a powerful method that iteratively updates a set of particles to approximate the distribution of interest. Furthermore, when analysing its asymptotic properties, SVGD reduces exactly to a single-objective optimization problem and can be viewed as a probabilistic version of this single-objective optimization problem. A natural question then arises: \"Can we derive a probabilistic version of the multi-objective optimization?\". To answer this question, we propose Stochastic Multiple Target Sampling Gradient Descent (MT-SGD), enabling us to sample from multiple unnormalized target distributions. Specifically, our MT-SGD conducts a flow of intermediate distributions gradually orienting to multiple target distributions, which allows the sampled particles to move to the joint high-likelihood region of the target distributions. Interestingly, the asymptotic analysis shows that our approach reduces exactly to the multiple-gradient descent algorithm for multi-objective optimization, as expected. Finally, we conduct comprehensive experiments to demonstrate the merit of our approach to multi-task learning.", "published": "2022-06-04T07:54:35Z", "version": 4}, {"aid": "2206.02061", "authors": ["Sai Sukruth Bezugam", "Ahmed Shaban", "Manan Suri"], "title": "Low Power Neuromorphic EMG Gesture Classification", "url": "http://arxiv.org/pdf/2206.02061v1", "summary": "EMG (Electromyograph) signal based gesture recognition can prove vital for applications such as smart wearables and bio-medical neuro-prosthetic control. Spiking Neural Networks (SNNs) are promising for low-power, real-time EMG gesture recognition, owing to their inherent spike/event driven spatio-temporal dynamics. In literature, there are limited demonstrations of neuromorphic hardware implementation (at full chip/board/system scale) for EMG gesture classification. Moreover, most literature attempts exploit primitive SNNs based on LIF (Leaky Integrate and Fire) neurons. In this work, we address the aforementioned gaps with following key contributions: (1) Low-power, high accuracy demonstration of EMG-signal based gesture recognition using neuromorphic Recurrent Spiking Neural Networks (RSNN). In particular, we propose a multi-time scale recurrent neuromorphic system based on special double-exponential adaptive threshold (DEXAT) neurons. Our network achieves state-of-the-art classification accuracy (90%) while using ~53% lesser neurons than best reported prior art on Roshambo EMG dataset. (2) A new multi-channel spike encoder scheme for efficient processing of real-valued EMG data on neuromorphic systems. (3) Unique multi-compartment methodology to implement complex adaptive neurons on Intel's dedicated neuromorphic Loihi chip is shown. (4) RSNN implementation on Loihi (Nahuku 32) achieves significant energy/latency benefits of ~983X/19X compared to GPU for batch size as 50.", "published": "2022-06-04T22:09:34Z", "version": 1}, {"aid": "2206.02070", "authors": ["Yunfan Lu", "Yiqi Lin", "Hao Wu", "Yunhao Luo", "Xu Zheng", "Hui Xiong", "Lin Wang"], "title": "Priors in Deep Image Restoration and Enhancement: A Survey", "url": "http://arxiv.org/pdf/2206.02070v2", "summary": "Image restoration and enhancement is a process of improving the image quality by removing degradations, such as noise, blur, and resolution degradation. Deep learning (DL) has recently been applied to image restoration and enhancement. Due to its ill-posed property, plenty of works have been explored priors to facilitate training deep neural networks (DNNs). However, the importance of priors has not been systematically studied and analyzed by far in the research community. Therefore, this paper serves as the first study that provides a comprehensive overview of recent advancements in priors for deep image restoration and enhancement. Our work covers five primary contents: (1) A theoretical analysis of priors for deep image restoration and enhancement; (2) A hierarchical and structural taxonomy of priors commonly used in the DL-based methods; (3) An insightful discussion on each prior regarding its principle, potential, and applications; (4) A summary of crucial problems by highlighting the potential future directions, especially adopting the large-scale foundation models as prior, to spark more research in the community; (5) An open-source repository that provides a taxonomy of all mentioned works and code links.", "published": "2022-06-04T23:33:34Z", "version": 2}, {"aid": "2206.02102", "authors": ["Difeng Cai", "Yuliang Ji", "Huan He", "Qiang Ye", "Yuanzhe Xi"], "title": "AUTM Flow: Atomic Unrestricted Time Machine for Monotonic Normalizing Flows", "url": "http://arxiv.org/pdf/2206.02102v1", "summary": "Nonlinear monotone transformations are used extensively in normalizing flows to construct invertible triangular mappings from simple distributions to complex ones. In existing literature, monotonicity is usually enforced by restricting function classes or model parameters and the inverse transformation is often approximated by root-finding algorithms as a closed-form inverse is unavailable. In this paper, we introduce a new integral-based approach termed \"Atomic Unrestricted Time Machine (AUTM)\", equipped with unrestricted integrands and easy-to-compute explicit inverse. AUTM offers a versatile and efficient way to the design of normalizing flows with explicit inverse and unrestricted function classes or parameters. Theoretically, we present a constructive proof that AUTM is universal: all monotonic normalizing flows can be viewed as limits of AUTM flows. We provide a concrete example to show how to approximate any given monotonic normalizing flow using AUTM flows with guaranteed convergence. The result implies that AUTM can be used to transform an existing flow into a new one equipped with explicit inverse and unrestricted parameters. The performance of the new approach is evaluated on high dimensional density estimation, variational inference and image generation. Experiments demonstrate superior speed and memory efficiency of AUTM.", "published": "2022-06-05T05:58:04Z", "version": 1}, {"aid": "2206.02200", "authors": ["Abhishek Kumar", "Oladayo S. Ajani", "Swagatam Das", "Rammohan Mallipeddi"], "title": "GridShift: A Faster Mode-seeking Algorithm for Image Segmentation and Object Tracking", "url": "http://arxiv.org/pdf/2206.02200v1", "summary": "In machine learning and computer vision, mean shift (MS) qualifies as one of the most popular mode-seeking algorithms used for clustering and image segmentation. It iteratively moves each data point to the weighted mean of its neighborhood data points. The computational cost required to find the neighbors of each data point is quadratic to the number of data points. Consequently, the vanilla MS appears to be very slow for large-scale datasets. To address this issue, we propose a mode-seeking algorithm called GridShift, with significant speedup and principally based on MS. To accelerate, GridShift employs a grid-based approach for neighbor search, which is linear in the number of data points. In addition, GridShift moves the active grid cells (grid cells associated with at least one data point) in place of data points towards the higher density, a step that provides more speedup. The runtime of GridShift is linear in the number of active grid cells and exponential in the number of features. Therefore, it is ideal for large-scale low-dimensional applications such as object tracking and image segmentation. Through extensive experiments, we showcase the superior performance of GridShift compared to other MS-based as well as state-of-the-art algorithms in terms of accuracy and runtime on benchmark datasets for image segmentation. Finally, we provide a new object-tracking algorithm based on GridShift and show promising results for object tracking compared to CamShift and meanshift++.", "published": "2022-06-05T15:08:34Z", "version": 1}, {"aid": "2206.02916", "authors": ["Zhiwei Deng", "Olga Russakovsky"], "title": "Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks", "url": "http://arxiv.org/pdf/2206.02916v2", "summary": "We propose an algorithm that compresses the critical information of a large dataset into compact addressable memories. These memories can then be recalled to quickly re-train a neural network and recover the performance (instead of storing and re-training on the full original dataset). Building upon the dataset distillation framework, we make a key observation that a shared common representation allows for more efficient and effective distillation. Concretely, we learn a set of bases (aka ``memories'') which are shared between classes and combined through learned flexible addressing functions to generate a diverse set of training examples. This leads to several benefits: 1) the size of compressed data does not necessarily grow linearly with the number of classes; 2) an overall higher compression rate with more effective distillation is achieved; and 3) more generalized queries are allowed beyond recalling the original classes. We demonstrate state-of-the-art results on the dataset distillation task across six benchmarks, including up to 16.5% and 9.7% in retained accuracy improvement when distilling CIFAR10 and CIFAR100 respectively. We then leverage our framework to perform continual learning, achieving state-of-the-art results on four benchmarks, with 23.2% accuracy improvement on MANY. The code is released on our project webpage https://github.com/princetonvisualai/RememberThePast-DatasetDistillation.", "published": "2022-06-06T21:32:26Z", "version": 2}, {"aid": "2206.03065", "authors": ["Joan Serr\u00e0", "Santiago Pascual", "Jordi Pons", "R. Oguz Araz", "Davide Scaini"], "title": "Universal Speech Enhancement with Score-based Diffusion", "url": "http://arxiv.org/pdf/2206.03065v2", "summary": "Removing background noise from speech audio has been the subject of considerable effort, especially in recent years due to the rise of virtual communication and amateur recordings. Yet background noise is not the only unpleasant disturbance that can prevent intelligibility: reverb, clipping, codec artifacts, problematic equalization, limited bandwidth, or inconsistent loudness are equally disturbing and ubiquitous. In this work, we propose to consider the task of speech enhancement as a holistic endeavor, and present a universal speech enhancement system that tackles 55 different distortions at the same time. Our approach consists of a generative model that employs score-based diffusion, together with a multi-resolution conditioning network that performs enhancement with mixture density networks. We show that this approach significantly outperforms the state of the art in a subjective test performed by expert listeners. We also show that it achieves competitive objective scores with just 4-8 diffusion steps, despite not considering any particular strategy for fast sampling. We hope that both our methodology and technical contributions encourage researchers and practitioners to adopt a universal approach to speech enhancement, possibly framing it as a generative task.", "published": "2022-06-07T07:32:32Z", "version": 2}, {"aid": "2206.03179", "authors": ["Ignacio Aguilera-Martos", "\u00c1ngel M. Garc\u00eda-Vico", "Juli\u00e1n Luengo", "Sergio Damas", "Francisco J. Melero", "Jos\u00e9 Javier Valle-Alonso", "Francisco Herrera"], "title": "TSFEDL: A Python Library for Time Series Spatio-Temporal Feature Extraction and Prediction using Deep Learning (with Appendices on Detailed Network Architectures and Experimental Cases of Study)", "url": "http://arxiv.org/pdf/2206.03179v2", "summary": "The combination of convolutional and recurrent neural networks is a promising framework that allows the extraction of high-quality spatio-temporal features together with its temporal dependencies, which is key for time series prediction problems such as forecasting, classification or anomaly detection, amongst others. In this paper, the TSFEDL library is introduced. It compiles 20 state-of-the-art methods for both time series feature extraction and prediction, employing convolutional and recurrent deep neural networks for its use in several data mining tasks. The library is built upon a set of Tensorflow+Keras and PyTorch modules under the AGPLv3 license. The performance validation of the architectures included in this proposal confirms the usefulness of this Python package.", "published": "2022-06-07T10:58:33Z", "version": 2}, {"aid": "2206.03951", "authors": ["Kohitij Kar", "Simon Kornblith", "Evelina Fedorenko"], "title": "Interpretability of artificial neural network models in artificial Intelligence vs. neuroscience", "url": "http://arxiv.org/pdf/2206.03951v1", "summary": "Computationally explicit hypotheses of brain function derived from machine learning (ML)-based models have recently revolutionized neuroscience. Despite the unprecedented ability of these artificial neural networks (ANNs) to capture responses in biological neural networks (brains), and our full access to all internal model components (unlike the brain), ANNs are often referred to as black-boxes with limited interpretability. Interpretability, however, is a multi-faceted construct that is used differently across fields. In particular, interpretability, or explainability, efforts in Artificial Intelligence (AI) focus on understanding how different model components contribute to its output (i.e., decision making). In contrast, the neuroscientific interpretability of ANNs requires explicit alignment between model components and neuroscientific constructs (e.g., different brain areas or phenomena, like recurrence or top-down feedback). Given the widespread calls to improve the interpretability of AI systems, we here highlight these different notions of interpretability and argue that the neuroscientific interpretability of ANNs can be pursued in parallel with, but independently from, the ongoing efforts in AI. Certain ML techniques (e.g., deep dream) can be leveraged in both fields, to ask what stimulus optimally activates the specific model features (feature visualization by optimization), or how different features contribute to the model's output (feature attribution). However, without appropriate brain alignment, certain features will remain uninterpretable to neuroscientists.", "published": "2022-06-07T15:33:45Z", "version": 1}, {"aid": "2206.03429", "authors": ["Tim Brooks", "Janne Hellsten", "Miika Aittala", "Ting-Chun Wang", "Timo Aila", "Jaakko Lehtinen", "Ming-Yu Liu", "Alexei A. Efros", "Tero Karras"], "title": "Generating Long Videos of Dynamic Scenes", "url": "http://arxiv.org/pdf/2206.03429v2", "summary": "We present a video generation model that accurately reproduces object motion, changes in camera viewpoint, and new content that arises over time. Existing video generation methods often fail to produce new content as a function of time while maintaining consistencies expected in real environments, such as plausible dynamics and object persistence. A common failure case is for content to never change due to over-reliance on inductive biases to provide temporal consistency, such as a single latent code that dictates content for the entire video. On the other extreme, without long-term consistency, generated videos may morph unrealistically between different scenes. To address these limitations, we prioritize the time axis by redesigning the temporal latent representation and learning long-term consistency from data by training on longer videos. To this end, we leverage a two-phase training strategy, where we separately train using longer videos at a low resolution and shorter videos at a high resolution. To evaluate the capabilities of our model, we introduce two new benchmark datasets with explicit focus on long-term temporal dynamics.", "published": "2022-06-07T16:29:51Z", "version": 2}, {"aid": "2206.03727", "authors": ["Jun Yan", "Huilin Yin", "Xiaoyang Deng", "Ziming Zhao", "Wancheng Ge", "Hao Zhang", "Gerhard Rigoll"], "title": "Wavelet Regularization Benefits Adversarial Training", "url": "http://arxiv.org/pdf/2206.03727v1", "summary": "Adversarial training methods are state-of-the-art (SOTA) empirical defense methods against adversarial examples. Many regularization methods have been proven to be effective with the combination of adversarial training. Nevertheless, such regularization methods are implemented in the time domain. Since adversarial vulnerability can be regarded as a high-frequency phenomenon, it is essential to regulate the adversarially-trained neural network models in the frequency domain. Faced with these challenges, we make a theoretical analysis on the regularization property of wavelets which can enhance adversarial training. We propose a wavelet regularization method based on the Haar wavelet decomposition which is named Wavelet Average Pooling. This wavelet regularization module is integrated into the wide residual neural network so that a new WideWaveletResNet model is formed. On the datasets of CIFAR-10 and CIFAR-100, our proposed Adversarial Wavelet Training method realizes considerable robustness under different types of attacks. It verifies the assumption that our wavelet regularization method can enhance adversarial robustness especially in the deep wide neural networks. The visualization experiments of the Frequency Principle (F-Principle) and interpretability are implemented to show the effectiveness of our method. A detailed comparison based on different wavelet base functions is presented. The code is available at the repository: \\url{https://github.com/momo1986/AdversarialWaveletTraining}.", "published": "2022-06-08T08:00:30Z", "version": 1}, {"aid": "2206.04040", "authors": ["Pavan Kumar Anasosalu Vasu", "James Gabriel", "Jeff Zhu", "Oncel Tuzel", "Anurag Ranjan"], "title": "MobileOne: An Improved One millisecond Mobile Backbone", "url": "http://arxiv.org/pdf/2206.04040v2", "summary": "Efficient neural network backbones for mobile devices are often optimized for metrics such as FLOPs or parameter count. However, these metrics may not correlate well with latency of the network when deployed on a mobile device. Therefore, we perform extensive analysis of different metrics by deploying several mobile-friendly networks on a mobile device. We identify and analyze architectural and optimization bottlenecks in recent efficient neural networks and provide ways to mitigate these bottlenecks. To this end, we design an efficient backbone MobileOne, with variants achieving an inference time under 1 ms on an iPhone12 with 75.9% top-1 accuracy on ImageNet. We show that MobileOne achieves state-of-the-art performance within the efficient architectures while being many times faster on mobile. Our best model obtains similar performance on ImageNet as MobileFormer while being 38x faster. Our model obtains 2.3% better top-1 accuracy on ImageNet than EfficientNet at similar latency. Furthermore, we show that our model generalizes to multiple tasks - image classification, object detection, and semantic segmentation with significant improvements in latency and accuracy as compared to existing efficient architectures when deployed on a mobile device. Code and models are available at https://github.com/apple/ml-mobileone", "published": "2022-06-08T17:55:11Z", "version": 2}, {"aid": "2206.04355", "authors": ["Wentao Zhang", "Ziqi Yin", "Zeang Sheng", "Yang Li", "Wen Ouyang", "Xiaosen Li", "Yangyu Tao", "Zhi Yang", "Bin Cui"], "title": "Graph Attention Multi-Layer Perceptron", "url": "http://arxiv.org/pdf/2206.04355v1", "summary": "Graph neural networks (GNNs) have achieved great success in many graph-based applications. However, the enormous size and high sparsity level of graphs hinder their applications under industrial scenarios. Although some scalable GNNs are proposed for large-scale graphs, they adopt a fixed $K$-hop neighborhood for each node, thus facing the over-smoothing issue when adopting large propagation depths for nodes within sparse regions. To tackle the above issue, we propose a new GNN architecture -- Graph Attention Multi-Layer Perceptron (GAMLP), which can capture the underlying correlations between different scales of graph knowledge. We have deployed GAMLP in Tencent with the Angel platform, and we further evaluate GAMLP on both real-world datasets and large-scale industrial datasets. Extensive experiments on these 14 graph datasets demonstrate that GAMLP achieves state-of-the-art performance while enjoying high scalability and efficiency. Specifically, it outperforms GAT by 1.3\\% regarding predictive accuracy on our large-scale Tencent Video dataset while achieving up to $50\\times$ training speedup. Besides, it ranks top-1 on both the leaderboards of the largest homogeneous and heterogeneous graph (i.e., ogbn-papers100M and ogbn-mag) of Open Graph Benchmark.", "published": "2022-06-09T08:56:11Z", "version": 1}, {"aid": "2206.04363", "authors": ["Wei Lu", "Wei Sun", "Xiongkuo Min", "Wenhan Zhu", "Quan Zhou", "Jun He", "Qiyuan Wang", "Zicheng Zhang", "Tao Wang", "Guangtao Zhai"], "title": "Deep Neural Network for Blind Visual Quality Assessment of 4K Content", "url": "http://arxiv.org/pdf/2206.04363v1", "summary": "The 4K content can deliver a more immersive visual experience to consumers due to the huge improvement of spatial resolution. However, existing blind image quality assessment (BIQA) methods are not suitable for the original and upscaled 4K contents due to the expanded resolution and specific distortions. In this paper, we propose a deep learning-based BIQA model for 4K content, which on one hand can recognize true and pseudo 4K content and on the other hand can evaluate their perceptual visual quality. Considering the characteristic that high spatial resolution can represent more abundant high-frequency information, we first propose a Grey-level Co-occurrence Matrix (GLCM) based texture complexity measure to select three representative image patches from a 4K image, which can reduce the computational complexity and is proven to be very effective for the overall quality prediction through experiments. Then we extract different kinds of visual features from the intermediate layers of the convolutional neural network (CNN) and integrate them into the quality-aware feature representation. Finally, two multilayer perception (MLP) networks are utilized to map the quality-aware features into the class probability and the quality score for each patch respectively. The overall quality index is obtained through the average pooling of patch results. The proposed model is trained through the multi-task learning manner and we introduce an uncertainty principle to balance the losses of the classification and regression tasks. The experimental results show that the proposed model outperforms all compared BIQA metrics on four 4K content quality assessment databases.", "published": "2022-06-09T09:10:54Z", "version": 1}, {"aid": "2206.04394", "authors": ["Thomas Fel", "Lucas Hervier", "David Vigouroux", "Antonin Poche", "Justin Plakoo", "Remi Cadene", "Mathieu Chalvidal", "Julien Colin", "Thibaut Boissin", "Louis Bethune", "Agustin Picard", "Claire Nicodeme", "Laurent Gardes", "Gregory Flandin", "Thomas Serre"], "title": "Xplique: A Deep Learning Explainability Toolbox", "url": "http://arxiv.org/pdf/2206.04394v1", "summary": "Today's most advanced machine-learning models are hardly scrutable. The key challenge for explainability methods is to help assisting researchers in opening up these black boxes, by revealing the strategy that led to a given decision, by characterizing their internal states or by studying the underlying data representation. To address this challenge, we have developed Xplique: a software library for explainability which includes representative explainability methods as well as associated evaluation metrics. It interfaces with one of the most popular learning libraries: Tensorflow as well as other libraries including PyTorch, scikit-learn and Theano. The code is licensed under the MIT license and is freely available at github.com/deel-ai/xplique.", "published": "2022-06-09T10:16:07Z", "version": 1}, {"aid": "2206.04406", "authors": ["Tamara G. Grossmann", "S\u00f6ren Dittmer", "Yury Korolev", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Unsupervised Learning of the Total Variation Flow", "url": "http://arxiv.org/pdf/2206.04406v2", "summary": "The total variation (TV) flow generates a scale-space representation of an image based on the TV functional. This gradient flow observes desirable features for images, such as sharp edges and enables spectral, scale, and texture analysis. Solving the TV flow is challenging; one reason is the the non-uniqueness of the subgradients. The standard numerical approach for TV flow requires solving multiple non-smooth optimisation problems. Even with state-of-the-art convex optimisation techniques, this is often prohibitively expensive and strongly motivates the use of alternative, faster approaches. Inspired by and extending the framework of physics-informed neural networks (PINNs), we propose the TVflowNET, an unsupervised neural network approach, to approximate the solution of the TV flow given an initial image and a time instance. The TVflowNET requires no ground truth data but rather makes use of the PDE for optimisation of the network parameters. We circumvent the challenges related to the non-uniqueness of the subgradients by additionally learning the related diffusivity term. Our approach significantly speeds up the computation time and we show that the TVflowNET approximates the TV flow solution with high fidelity for different image sizes and image types. Additionally, we give a full comparison of different network architecture designs as well as training regimes to underscore the effectiveness of our approach.", "published": "2022-06-09T10:39:44Z", "version": 2}, {"aid": "2206.04459", "authors": ["Xijie Huang", "Zhiqiang Shen", "Shichao Li", "Zechun Liu", "Xianghong Hu", "Jeffry Wicaksana", "Eric Xing", "Kwang-Ting Cheng"], "title": "SDQ: Stochastic Differentiable Quantization with Mixed Precision", "url": "http://arxiv.org/pdf/2206.04459v3", "summary": "In order to deploy deep models in a computationally efficient manner, model quantization approaches have been frequently used. In addition, as new hardware that supports mixed bitwidth arithmetic operations, recent research on mixed precision quantization (MPQ) begins to fully leverage the capacity of representation by searching optimized bitwidths for different layers and modules in a network. However, previous studies mainly search the MPQ strategy in a costly scheme using reinforcement learning, neural architecture search, etc., or simply utilize partial prior knowledge for bitwidth assignment, which might be biased and sub-optimal. In this work, we present a novel Stochastic Differentiable Quantization (SDQ) method that can automatically learn the MPQ strategy in a more flexible and globally-optimized space with smoother gradient approximation. Particularly, Differentiable Bitwidth Parameters (DBPs) are employed as the probability factors in stochastic quantization between adjacent bitwidth choices. After the optimal MPQ strategy is acquired, we further train our network with entropy-aware bin regularization and knowledge distillation. We extensively evaluate our method for several networks on different hardware (GPUs and FPGA) and datasets. SDQ outperforms all state-of-the-art mixed or single precision quantization with a lower bitwidth and is even better than the full-precision counterparts across various ResNet and MobileNet families, demonstrating the effectiveness and superiority of our method.", "published": "2022-06-09T12:38:18Z", "version": 3}, {"aid": "2206.05897", "authors": ["Lin Tian", "Hastings Greer", "Fran\u00e7ois-Xavier Vialard", "Roland Kwitt", "Ra\u00fal San Jos\u00e9 Est\u00e9par", "Richard Jarrett Rushmore", "Nikolaos Makris", "Sylvain Bouix", "Marc Niethammer"], "title": "$\\texttt{GradICON}$: Approximate Diffeomorphisms via Gradient Inverse Consistency", "url": "http://arxiv.org/pdf/2206.05897v4", "summary": "We present an approach to learning regular spatial transformations between image pairs in the context of medical image registration. Contrary to optimization-based registration techniques and many modern learning-based methods, we do not directly penalize transformation irregularities but instead promote transformation regularity via an inverse consistency penalty. We use a neural network to predict a map between a source and a target image as well as the map when swapping the source and target images. Different from existing approaches, we compose these two resulting maps and regularize deviations of the $\\bf{Jacobian}$ of this composition from the identity matrix. This regularizer -- $\\texttt{GradICON}$ -- results in much better convergence when training registration models compared to promoting inverse consistency of the composition of maps directly while retaining the desirable implicit regularization effects of the latter. We achieve state-of-the-art registration performance on a variety of real-world medical image datasets using a single set of hyperparameters and a single non-dataset-specific training protocol.", "published": "2022-06-13T04:03:49Z", "version": 4}, {"aid": "2206.06214", "authors": ["Yingqian Wang", "Zhengyu Liang", "Longguang Wang", "Jungang Yang", "Wei An", "Yulan Guo"], "title": "Real-World Light Field Image Super-Resolution via Degradation Modulation", "url": "http://arxiv.org/pdf/2206.06214v2", "summary": "Recent years have witnessed the great advances of deep neural networks (DNNs) in light field (LF) image super-resolution (SR). However, existing DNN-based LF image SR methods are developed on a single fixed degradation (e.g., bicubic downsampling), and thus cannot be applied to super-resolve real LF images with diverse degradation. In this paper, we propose a simple yet effective method for real-world LF image SR. In our method, a practical LF degradation model is developed to formulate the degradation process of real LF images. Then, a convolutional neural network is designed to incorporate the degradation prior into the SR process. By training on LF images using our formulated degradation, our network can learn to modulate different degradation while incorporating both spatial and angular information in LF images. Extensive experiments on both synthetically degraded and real-world LF images demonstrate the effectiveness of our method. Compared with existing state-of-the-art single and LF image SR methods, our method achieves superior SR performance under a wide range of degradation, and generalizes better to real LF images. Codes and models are available at https://yingqianwang.github.io/LF-DMnet/.", "published": "2022-06-13T14:44:46Z", "version": 2}, {"aid": "2206.08933", "authors": ["Weishun Zhong", "Ben Sorscher", "Daniel D Lee", "Haim Sompolinsky"], "title": "A theory of learning with constrained weight-distribution", "url": "http://arxiv.org/pdf/2206.08933v2", "summary": "A central question in computational neuroscience is how structure determines function in neural networks. The emerging high-quality large-scale connectomic datasets raise the question of what general functional principles can be gleaned from structural information such as the distribution of excitatory/inhibitory synapse types and the distribution of synaptic weights. Motivated by this question, we developed a statistical mechanical theory of learning in neural networks that incorporates structural information as constraints. We derived an analytical solution for the memory capacity of the perceptron, a basic feedforward model of supervised learning, with constraint on the distribution of its weights. Our theory predicts that the reduction in capacity due to the constrained weight-distribution is related to the Wasserstein distance between the imposed distribution and that of the standard normal distribution. To test the theoretical predictions, we use optimal transport theory and information geometry to develop an SGD-based algorithm to find weights that simultaneously learn the input-output task and satisfy the distribution constraint. We show that training in our algorithm can be interpreted as geodesic flows in the Wasserstein space of probability distributions. We further developed a statistical mechanical theory for teacher-student perceptron rule learning and ask for the best way for the student to incorporate prior knowledge of the rule. Our theory shows that it is beneficial for the learner to adopt different prior weight distributions during learning, and shows that distribution-constrained learning outperforms unconstrained and sign-constrained learning. Our theory and algorithm provide novel strategies for incorporating prior knowledge about weights into learning, and reveal a powerful connection between structure and function in neural networks.", "published": "2022-06-14T00:43:34Z", "version": 2}, {"aid": "2206.07568", "authors": ["Benjamin Eysenbach", "Tianjun Zhang", "Ruslan Salakhutdinov", "Sergey Levine"], "title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning", "url": "http://arxiv.org/pdf/2206.07568v2", "summary": "In reinforcement learning (RL), it is easier to solve a task if given a good representation. While deep RL should automatically acquire such good representations, prior work often finds that learning representations in an end-to-end fashion is unstable and instead equip RL algorithms with additional representation learning parts (e.g., auxiliary losses, data augmentation). How can we design RL algorithms that directly acquire good representations? In this paper, instead of adding representation learning parts to an existing RL algorithm, we show (contrastive) representation learning methods can be cast as RL algorithms in their own right. To do this, we build upon prior work and apply contrastive representation learning to action-labeled trajectories, in such a way that the (inner product of) learned representations exactly corresponds to a goal-conditioned value function. We use this idea to reinterpret a prior RL method as performing contrastive learning, and then use the idea to propose a much simpler method that achieves similar performance. Across a range of goal-conditioned RL tasks, we demonstrate that contrastive RL methods achieve higher success rates than prior non-contrastive methods, including in the offline RL setting. We also show that contrastive RL outperforms prior methods on image-based tasks, without using data augmentation or auxiliary objectives.", "published": "2022-06-15T14:34:15Z", "version": 2}, {"aid": "2206.07741", "authors": ["Clemens JS Schaefer", "Siddharth Joshi", "Shan Li", "Raul Blazquez"], "title": "Edge Inference with Fully Differentiable Quantized Mixed Precision Neural Networks", "url": "http://arxiv.org/pdf/2206.07741v2", "summary": "The large computing and memory cost of deep neural networks (DNNs) often precludes their use in resource-constrained devices. Quantizing the parameters and operations to lower bit-precision offers substantial memory and energy savings for neural network inference, facilitating the use of DNNs on edge computing platforms. Recent efforts at quantizing DNNs have employed a range of techniques encompassing progressive quantization, step-size adaptation, and gradient scaling. This paper proposes a new quantization approach for mixed precision convolutional neural networks (CNNs) targeting edge-computing. Our method establishes a new pareto frontier in model accuracy and memory footprint demonstrating a range of quantized models, delivering best-in-class accuracy below 4.3 MB of weights (wgts.) and activations (acts.). Our main contributions are: (i) hardware-aware heterogeneous differentiable quantization with tensor-sliced learned precision, (ii) targeted gradient modification for wgts. and acts. to mitigate quantization errors, and (iii) a multi-phase learning schedule to address instability in learning arising from updates to the learned quantizer and model parameters. We demonstrate the effectiveness of our techniques on the ImageNet dataset across a range of models including EfficientNet-Lite0 (e.g., 4.14MB of wgts. and acts. at 67.66% accuracy) and MobileNetV2 (e.g., 3.51MB wgts. and acts. at 65.39% accuracy).", "published": "2022-06-15T18:11:37Z", "version": 2}, {"aid": "2206.07751", "authors": ["Yujia Zheng", "Ignavier Ng", "Kun Zhang"], "title": "On the Identifiability of Nonlinear ICA: Sparsity and Beyond", "url": "http://arxiv.org/pdf/2206.07751v5", "summary": "Nonlinear independent component analysis (ICA) aims to recover the underlying independent latent sources from their observable nonlinear mixtures. How to make the nonlinear ICA model identifiable up to certain trivial indeterminacies is a long-standing problem in unsupervised learning. Recent breakthroughs reformulate the standard independence assumption of sources as conditional independence given some auxiliary variables (e.g., class labels and/or domain/time indexes) as weak supervision or inductive bias. However, nonlinear ICA with unconditional priors cannot benefit from such developments. We explore an alternative path and consider only assumptions on the mixing process, such as Structural Sparsity. We show that under specific instantiations of such constraints, the independent latent sources can be identified from their nonlinear mixtures up to a permutation and a component-wise transformation, thus achieving nontrivial identifiability of nonlinear ICA without auxiliary variables. We provide estimation methods and validate the theoretical results experimentally. The results on image data suggest that our conditions may hold in a number of practical data generating processes.", "published": "2022-06-15T18:24:22Z", "version": 5}, {"aid": "2206.07758", "authors": ["Niv Haim", "Gal Vardi", "Gilad Yehudai", "Ohad Shamir", "Michal Irani"], "title": "Reconstructing Training Data from Trained Neural Networks", "url": "http://arxiv.org/pdf/2206.07758v3", "summary": "Understanding to what extent neural networks memorize training data is an intriguing question with practical and theoretical implications. In this paper we show that in some cases a significant fraction of the training data can in fact be reconstructed from the parameters of a trained neural network classifier. We propose a novel reconstruction scheme that stems from recent theoretical results about the implicit bias in training neural networks with gradient-based methods. To the best of our knowledge, our results are the first to show that reconstructing a large portion of the actual training samples from a trained neural network classifier is generally possible. This has negative implications on privacy, as it can be used as an attack for revealing sensitive training data. We demonstrate our method for binary MLP classifiers on a few standard computer vision datasets.", "published": "2022-06-15T18:35:16Z", "version": 3}, {"aid": "2206.08094", "authors": ["Sabera Talukder", "Jennifer J. Sun", "Matthew Leonard", "Bingni W. Brunton", "Yisong Yue"], "title": "Deep Neural Imputation: A Framework for Recovering Incomplete Brain Recordings", "url": "http://arxiv.org/pdf/2206.08094v1", "summary": "Neuroscientists and neuroengineers have long relied on multielectrode neural recordings to study the brain. However, in a typical experiment, many factors corrupt neural recordings from individual electrodes, including electrical noise, movement artifacts, and faulty manufacturing. Currently, common practice is to discard these corrupted recordings, reducing already limited data that is difficult to collect. To address this challenge, we propose Deep Neural Imputation (DNI), a framework to recover missing values from electrodes by learning from data collected across spatial locations, days, and participants. We explore our framework with a linear nearest-neighbor approach and two deep generative autoencoders, demonstrating DNI's flexibility. One deep autoencoder models participants individually, while the other extends this architecture to model many participants jointly. We evaluate our models across 12 human participants implanted with multielectrode intracranial electrocorticography arrays; participants had no explicit task and behaved naturally across hundreds of recording hours. We show that DNI recovers not only time series but also frequency content, and further establish DNI's practical value by recovering significant performance on a scientifically-relevant downstream neural decoding task.", "published": "2022-06-16T11:20:11Z", "version": 1}, {"aid": "2206.08107", "authors": ["I\u00f1igo Martinez", "Elisabeth Viles", "Igor G. Olaizola"], "title": "Closed-Form Diffeomorphic Transformations for Time Series Alignment", "url": "http://arxiv.org/pdf/2206.08107v1", "summary": "Time series alignment methods call for highly expressive, differentiable and invertible warping functions which preserve temporal topology, i.e diffeomorphisms. Diffeomorphic warping functions can be generated from the integration of velocity fields governed by an ordinary differential equation (ODE). Gradient-based optimization frameworks containing diffeomorphic transformations require to calculate derivatives to the differential equation's solution with respect to the model parameters, i.e. sensitivity analysis. Unfortunately, deep learning frameworks typically lack automatic-differentiation-compatible sensitivity analysis methods; and implicit functions, such as the solution of ODE, require particular care. Current solutions appeal to adjoint sensitivity methods, ad-hoc numerical solvers or ResNet's Eulerian discretization. In this work, we present a closed-form expression for the ODE solution and its gradient under continuous piecewise-affine (CPA) velocity functions. We present a highly optimized implementation of the results on CPU and GPU. Furthermore, we conduct extensive experiments on several datasets to validate the generalization ability of our model to unseen data for time-series joint alignment. Results show significant improvements both in terms of efficiency and accuracy.", "published": "2022-06-16T12:02:12Z", "version": 1}, {"aid": "2206.11233", "authors": ["Parisa Moridian", "Navid Ghassemi", "Mahboobeh Jafari", "Salam Salloum-Asfar", "Delaram Sadeghi", "Marjane Khodatars", "Afshin Shoeibi", "Abbas Khosravi", "Sai Ho Ling", "Abdulhamit Subasi", "Roohallah Alizadehsani", "Juan M. Gorriz", "Sara A Abdulla", "U. Rajendra Acharya"], "title": "Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: A review", "url": "http://arxiv.org/pdf/2206.11233v3", "summary": "Autism spectrum disorder (ASD) is a brain condition characterized by diverse signs and symptoms that appear in early childhood. ASD is also associated with communication deficits and repetitive behavior in affected individuals. Various ASD detection methods have been developed, including neuroimaging modalities and psychological tests. Among these methods, magnetic resonance imaging (MRI) imaging modalities are of paramount importance to physicians. Clinicians rely on MRI modalities to diagnose ASD accurately. The MRI modalities are non-invasive methods that include functional (fMRI) and structural (sMRI) neuroimaging methods. However, diagnosing ASD with fMRI and sMRI for specialists is often laborious and time-consuming; therefore, several computer-aided design systems (CADS) based on artificial intelligence (AI) have been developed to assist specialist physicians. Conventional machine learning (ML) and deep learning (DL) are the most popular schemes of AI used for diagnosing ASD. This study aims to review the automated detection of ASD using AI. We review several CADS that have been developed using ML techniques for the automated diagnosis of ASD using MRI modalities. There has been very limited work on the use of DL techniques to develop automated diagnostic models for ASD. A summary of the studies developed using DL is provided in the Supplementary Appendix. Then, the challenges encountered during the automated diagnosis of ASD using MRI and AI techniques are described in detail. Additionally, a graphical comparison of studies using ML and DL to diagnose ASD automatically is discussed. We suggest future approaches to detecting ASDs using AI techniques and MRI neuroimaging.", "published": "2022-06-20T16:14:21Z", "version": 3}, {"aid": "2206.13397", "authors": ["Severi Rissanen", "Markus Heinonen", "Arno Solin"], "title": "Generative Modelling With Inverse Heat Dissipation", "url": "http://arxiv.org/pdf/2206.13397v7", "summary": "While diffusion models have shown great success in image generation, their noise-inverting generative process does not explicitly consider the structure of images, such as their inherent multi-scale nature. Inspired by diffusion models and the empirical success of coarse-to-fine modelling, we propose a new diffusion-like model that generates images through stochastically reversing the heat equation, a PDE that locally erases fine-scale information when run over the 2D plane of the image. We interpret the solution of the forward heat equation with constant additive noise as a variational approximation in the diffusion latent variable model. Our new model shows emergent qualitative properties not seen in standard diffusion models, such as disentanglement of overall colour and shape in images. Spectral analysis on natural images highlights connections to diffusion models and reveals an implicit coarse-to-fine inductive bias in them.", "published": "2022-06-21T13:40:38Z", "version": 7}, {"aid": "2206.12361", "authors": ["Xi Wang", "Laurence Aitchison"], "title": "Robustness to corruption in pre-trained Bayesian neural networks", "url": "http://arxiv.org/pdf/2206.12361v3", "summary": "We develop ShiftMatch, a new training-data-dependent likelihood for robustness to corruption in Bayesian neural networks (BNNs). ShiftMatch is inspired by the training-data-dependent \"EmpCov\" priors from Izmailov et al. (2021a), and efficiently matches test-time spatial correlations to those at training time. Critically, ShiftMatch is designed to leave the neural network's training time likelihood unchanged, allowing it to use publicly available samples from pre-trained BNNs. Using pre-trained HMC samples, ShiftMatch gives strong performance improvements on CIFAR-10-C, outperforms EmpCov priors (though ShiftMatch uses extra information from a minibatch of corrupted test points), and is perhaps the first Bayesian method capable of convincingly outperforming plain deep ensembles.", "published": "2022-06-24T16:08:46Z", "version": 3}, {"aid": "2206.13508", "authors": ["Guillermo Iglesias", "Edgar Talavera", "\u00c1ngel Gonz\u00e1lez-Prieto", "Alberto Mozo", "Sandra G\u00f3mez-Canaval"], "title": "Data Augmentation techniques in time series domain: A survey and taxonomy", "url": "http://arxiv.org/pdf/2206.13508v4", "summary": "With the latest advances in Deep Learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using Data Augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state-of-the-art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.", "published": "2022-06-25T17:09:00Z", "version": 4}, {"aid": "2206.14483", "authors": ["C\u00e9dric Rommel", "Joseph Paillard", "Thomas Moreau", "Alexandre Gramfort"], "title": "Data augmentation for learning predictive models on EEG: a systematic comparison", "url": "http://arxiv.org/pdf/2206.14483v2", "summary": "Objective: The use of deep learning for electroencephalography (EEG) classification tasks has been rapidly growing in the last years, yet its application has been limited by the relatively small size of EEG datasets. Data augmentation, which consists in artificially increasing the size of the dataset during training, can be employed to alleviate this problem. While a few augmentation transformations for EEG data have been proposed in the literature, their positive impact on performance is often evaluated on a single dataset and compared to one or two competing augmentation methods. This work proposes to better validate the existing data augmentation approaches through a unified and exhaustive analysis. Approach: We compare quantitatively 13 different augmentations with two different predictive tasks, datasets and models, using three different types of experiments. Main results: We demonstrate that employing the adequate data augmentations can bring up to 45% accuracy improvements in low data regimes compared to the same model trained without any augmentation. Our experiments also show that there is no single best augmentation strategy, as the good augmentations differ on each task. Significance: Our results highlight the best data augmentations to consider for sleep stage classification and motor imagery brain-computer interfaces. More broadly, it demonstrates that EEG classification tasks benefit from adequate data augmentation", "published": "2022-06-29T09:18:15Z", "version": 2}, {"aid": "2207.00713", "authors": ["Yanwei Jia", "Xun Yu Zhou"], "title": "q-Learning in Continuous Time", "url": "http://arxiv.org/pdf/2207.00713v4", "summary": "We study the continuous-time counterpart of Q-learning for reinforcement learning (RL) under the entropy-regularized, exploratory diffusion process formulation introduced by Wang et al. (2020). As the conventional (big) Q-function collapses in continuous time, we consider its first-order approximation and coin the term ``(little) q-function\". This function is related to the instantaneous advantage rate function as well as the Hamiltonian. We develop a ``q-learning\" theory around the q-function that is independent of time discretization. Given a stochastic policy, we jointly characterize the associated q-function and value function by martingale conditions of certain stochastic processes, in both on-policy and off-policy settings. We then apply the theory to devise different actor-critic algorithms for solving underlying RL problems, depending on whether or not the density function of the Gibbs measure generated from the q-function can be computed explicitly. One of our algorithms interprets the well-known Q-learning algorithm SARSA, and another recovers a policy gradient (PG) based continuous-time algorithm proposed in Jia and Zhou (2022b). Finally, we conduct simulation experiments to compare the performance of our algorithms with those of PG-based algorithms in Jia and Zhou (2022b) and time-discretized conventional Q-learning algorithms.", "published": "2022-07-02T02:20:41Z", "version": 4}, {"aid": "2207.02849", "authors": ["Sang Keun Choe", "Willie Neiswanger", "Pengtao Xie", "Eric Xing"], "title": "Betty: An Automatic Differentiation Library for Multilevel Optimization", "url": "http://arxiv.org/pdf/2207.02849v2", "summary": "Gradient-based multilevel optimization (MLO) has gained attention as a framework for studying numerous problems, ranging from hyperparameter optimization and meta-learning to neural architecture search and reinforcement learning. However, gradients in MLO, which are obtained by composing best-response Jacobians via the chain rule, are notoriously difficult to implement and memory/compute intensive. We take an initial step towards closing this gap by introducing Betty, a software library for large-scale MLO. At its core, we devise a novel dataflow graph for MLO, which allows us to (1) develop efficient automatic differentiation for MLO that reduces the computational complexity from O(d^3) to O(d^2), (2) incorporate systems support such as mixed-precision and data-parallel training for scalability, and (3) facilitate implementation of MLO programs of arbitrary complexity while allowing a modular interface for diverse algorithmic and systems design choices. We empirically demonstrate that Betty can be used to implement an array of MLO programs, while also observing up to 11% increase in test accuracy, 14% decrease in GPU memory usage, and 20% decrease in training wall time over existing implementations on multiple benchmarks. We also showcase that Betty enables scaling MLO to models with hundreds of millions of parameters. We open-source the code at https://github.com/leopard-ai/betty.", "published": "2022-07-05T14:01:15Z", "version": 2}, {"aid": "2207.02625", "authors": ["Zhennan Wang", "Kehan Li", "Runyi Yu", "Yian Zhao", "Pengchong Qiao", "Chang Liu", "Fan Xu", "Xiangyang Ji", "Guoli Song", "Jie Chen"], "title": "$L_2$BN: Enhancing Batch Normalization by Equalizing the $L_2$ Norms of Features", "url": "http://arxiv.org/pdf/2207.02625v6", "summary": "In this paper, we analyze batch normalization from the perspective of discriminability and find the disadvantages ignored by previous studies: the difference in $l_2$ norms of sample features can hinder batch normalization from obtaining more distinguished inter-class features and more compact intra-class features. To address this issue, we propose a simple yet effective method to equalize the $l_2$ norms of sample features. Concretely, we $l_2$-normalize each sample feature before feeding them into batch normalization, and therefore the features are of the same magnitude. Since the proposed method combines the $l_2$ normalization and batch normalization, we name our method $L_2$BN. The $L_2$BN can strengthen the compactness of intra-class features and enlarge the discrepancy of inter-class features. The $L_2$BN is easy to implement and can exert its effect without any additional parameters or hyper-parameters. We evaluate the effectiveness of $L_2$BN through extensive experiments with various models on image classification and acoustic scene classification tasks. The results demonstrate that the $L_2$BN can boost the generalization ability of various neural network models and achieve considerable performance improvements.", "published": "2022-07-06T12:34:33Z", "version": 6}, {"aid": "2207.03620", "authors": ["Shiwei Liu", "Tianlong Chen", "Xiaohan Chen", "Xuxi Chen", "Qiao Xiao", "Boqian Wu", "Tommi K\u00e4rkk\u00e4inen", "Mykola Pechenizkiy", "Decebal Mocanu", "Zhangyang Wang"], "title": "More ConvNets in the 2020s: Scaling up Kernels Beyond 51x51 using Sparsity", "url": "http://arxiv.org/pdf/2207.03620v3", "summary": "Transformers have quickly shined in the computer vision world since the emergence of Vision Transformers (ViTs). The dominant role of convolutional neural networks (CNNs) seems to be challenged by increasingly effective transformer-based models. Very recently, a couple of advanced convolutional models strike back with large kernels motivated by the local-window attention mechanism, showing appealing performance and efficiency. While one of them, i.e. RepLKNet, impressively manages to scale the kernel size to 31x31 with improved performance, the performance starts to saturate as the kernel size continues growing, compared to the scaling trend of advanced ViTs such as Swin Transformer. In this paper, we explore the possibility of training extreme convolutions larger than 31x31 and test whether the performance gap can be eliminated by strategically enlarging convolutions. This study ends up with a recipe for applying extremely large kernels from the perspective of sparsity, which can smoothly scale up kernels to 61x61 with better performance. Built on this recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with sparse factorized 51x51 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as well as a wide range of downstream tasks including semantic segmentation on ADE20K, object detection on PASCAL VOC 2007, and object detection/segmentation on MS COCO.", "published": "2022-07-07T23:55:52Z", "version": 3}, {"aid": "2207.05197", "authors": ["Matthieu Gilson", "Enzo Tagliazucchi", "Rodrigo Cofre"], "title": "Entropy production of Multivariate Ornstein-Uhlenbeck processes correlates with consciousness levels in the human brain", "url": "http://arxiv.org/pdf/2207.05197v2", "summary": "Consciousness is supported by complex patterns of brain activity which are indicative of irreversible non-equilibrium dynamics. While the framework of stochastic thermodynamics has facilitated the understanding of physical systems of this kind, its application to infer the level of consciousness from empirical data remains elusive. We faced this challenge by calculating entropy production in a multivariate Ornstein-Uhlenbeck process fitted to fMRI brain activity recordings. To test this approach, we focused on the transition from wakefulness to deep sleep, revealing a monotonous relationship between entropy production and the level of consciousness. Our results constitute robust signatures of consciousness while also advancing our understanding of the link between consciousness and complexity from the fundamental perspective of statistical physics.", "published": "2022-07-11T21:27:27Z", "version": 2}, {"aid": "2207.05543", "authors": ["Harrison Zhu", "Carles Balsells Rodas", "Yingzhen Li"], "title": "Markovian Gaussian Process Variational Autoencoders", "url": "http://arxiv.org/pdf/2207.05543v3", "summary": "Sequential VAEs have been successfully considered for many high-dimensional time series modelling problems, with many variant models relying on discrete-time mechanisms such as recurrent neural networks (RNNs). On the other hand, continuous-time methods have recently gained attraction, especially in the context of irregularly-sampled time series, where they can better handle the data than discrete-time methods. One such class are Gaussian process variational autoencoders (GPVAEs), where the VAE prior is set as a Gaussian process (GP). However, a major limitation of GPVAEs is that it inherits the cubic computational cost as GPs, making it unattractive to practioners. In this work, we leverage the equivalent discrete state space representation of Markovian GPs to enable linear time GPVAE training via Kalman filtering and smoothing. For our model, Markovian GPVAE (MGPVAE), we show on a variety of high-dimensional temporal and spatiotemporal tasks that our method performs favourably compared to existing approaches whilst being computationally highly scalable.", "published": "2022-07-12T14:10:01Z", "version": 3}, {"aid": "2207.06066", "authors": ["Suneghyeon Cho", "Sanghyun Hong", "Kookjin Lee", "Noseong Park"], "title": "AdamNODEs: When Neural ODE Meets Adaptive Moment Estimation", "url": "http://arxiv.org/pdf/2207.06066v1", "summary": "Recent work by Xia et al. leveraged the continuous-limit of the classical momentum accelerated gradient descent and proposed heavy-ball neural ODEs. While this model offers computational efficiency and high utility over vanilla neural ODEs, this approach often causes the overshooting of internal dynamics, leading to unstable training of a model. Prior work addresses this issue by using ad-hoc approaches, e.g., bounding the internal dynamics using specific activation functions, but the resulting models do not satisfy the exact heavy-ball ODE. In this work, we propose adaptive momentum estimation neural ODEs (AdamNODEs) that adaptively control the acceleration of the classical momentum-based approach. We find that its adjoint states also satisfy AdamODE and do not require ad-hoc solutions that the prior work employs. In evaluation, we show that AdamNODEs achieve the lowest training loss and efficacy over existing neural ODEs. We also show that AdamNODEs have better training stability than classical momentum-based neural ODEs. This result sheds some light on adapting the techniques proposed in the optimization community to improving the training and inference of neural ODEs further. Our code is available at https://github.com/pmcsh04/AdamNODE.", "published": "2022-07-13T09:20:38Z", "version": 1}, {"aid": "2207.06114", "authors": ["Mario Lezcano-Casado"], "title": "Automatic Differentiation: Theory and Practice", "url": "http://arxiv.org/pdf/2207.06114v1", "summary": "We present the classical coordinate-free formalism for forward and backward mode ad in the real and complex setting. We show how to formally derive the forward and backward formulae for a number of matrix functions starting from basic principles.", "published": "2022-07-13T10:39:58Z", "version": 1}, {"aid": "2207.06635", "authors": ["Min Zhao", "Fan Bao", "Chongxuan Li", "Jun Zhu"], "title": "EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations", "url": "http://arxiv.org/pdf/2207.06635v5", "summary": "Score-based diffusion models (SBDMs) have achieved the SOTA FID results in unpaired image-to-image translation (I2I). However, we notice that existing methods totally ignore the training data in the source domain, leading to sub-optimal solutions for unpaired I2I. To this end, we propose energy-guided stochastic differential equations (EGSDE) that employs an energy function pretrained on both the source and target domains to guide the inference process of a pretrained SDE for realistic and faithful unpaired I2I. Building upon two feature extractors, we carefully design the energy function such that it encourages the transferred image to preserve the domain-independent features and discard domain-specific ones. Further, we provide an alternative explanation of the EGSDE as a product of experts, where each of the three experts (corresponding to the SDE and two feature extractors) solely contributes to faithfulness or realism. Empirically, we compare EGSDE to a large family of baselines on three widely-adopted unpaired I2I tasks under four metrics. EGSDE not only consistently outperforms existing SBDMs-based methods in almost all settings but also achieves the SOTA realism results without harming the faithful performance. Furthermore, EGSDE allows for flexible trade-offs between realism and faithfulness and we improve the realism results further (e.g., FID of 51.04 in Cat to Dog and FID of 50.43 in Wild to Dog on AFHQ) by tuning hyper-parameters. The code is available at https://github.com/ML-GSAI/EGSDE.", "published": "2022-07-14T03:08:33Z", "version": 5}, {"aid": "2207.07730", "authors": ["Jorge A. Mendez", "Eric Eaton"], "title": "How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition", "url": "http://arxiv.org/pdf/2207.07730v2", "summary": "A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.", "published": "2022-07-15T19:53:20Z", "version": 2}, {"aid": "2207.09455", "authors": ["Andrea Bragagnolo", "Enzo Tartaglione", "Marco Grangetto"], "title": "To update or not to update? Neurons at equilibrium in deep models", "url": "http://arxiv.org/pdf/2207.09455v3", "summary": "Recent advances in deep learning optimization showed that, with some a-posteriori information on fully-trained models, it is possible to match the same performance by simply training a subset of their parameters. Such a discovery has a broad impact from theory to applications, driving the research towards methods to identify the minimum subset of parameters to train without look-ahead information exploitation. However, the methods proposed do not match the state-of-the-art performance, and rely on unstructured sparsely connected models. In this work we shift our focus from the single parameters to the behavior of the whole neuron, exploiting the concept of neuronal equilibrium (NEq). When a neuron is in a configuration at equilibrium (meaning that it has learned a specific input-output relationship), we can halt its update; on the contrary, when a neuron is at non-equilibrium, we let its state evolve towards an equilibrium state, updating its parameters. The proposed approach has been tested on different state-of-the-art learning strategies and tasks, validating NEq and observing that the neuronal equilibrium depends on the specific learning setup.", "published": "2022-07-19T08:07:53Z", "version": 3}, {"aid": "2207.09193", "authors": ["Ruiqi Zhang", "Jie Chen"], "title": "NDF: Neural Deformable Fields for Dynamic Human Modelling", "url": "http://arxiv.org/pdf/2207.09193v1", "summary": "We propose Neural Deformable Fields (NDF), a new representation for dynamic human digitization from a multi-view video. Recent works proposed to represent a dynamic human body with shared canonical neural radiance fields which links to the observation space with deformation fields estimations. However, the learned canonical representation is static and the current design of the deformation fields is not able to represent large movements or detailed geometry changes. In this paper, we propose to learn a neural deformable field wrapped around a fitted parametric body model to represent the dynamic human. The NDF is spatially aligned by the underlying reference surface. A neural network is then learned to map pose to the dynamics of NDF. The proposed NDF representation can synthesize the digitized performer with novel views and novel poses with a detailed and reasonable dynamic appearance. Experiments show that our method significantly outperforms recent human synthesis methods.", "published": "2022-07-19T10:55:41Z", "version": 1}, {"aid": "2207.09238", "authors": ["Mary Phuong", "Marcus Hutter"], "title": "Formal Algorithms for Transformers", "url": "http://arxiv.org/pdf/2207.09238v1", "summary": "This document aims to be a self-contained, mathematically precise overview of transformer architectures and algorithms (*not* results). It covers what transformers are, how they are trained, what they are used for, their key architectural components, and a preview of the most prominent models. The reader is assumed to be familiar with basic ML terminology and simpler neural network architectures such as MLPs.", "published": "2022-07-19T12:49:02Z", "version": 1}, {"aid": "2207.09442", "authors": ["Luis Pineda", "Taosha Fan", "Maurizio Monge", "Shobha Venkataraman", "Paloma Sodhi", "Ricky T. Q. Chen", "Joseph Ortiz", "Daniel DeTone", "Austin Wang", "Stuart Anderson", "Jing Dong", "Brandon Amos", "Mustafa Mukadam"], "title": "Theseus: A Library for Differentiable Nonlinear Optimization", "url": "http://arxiv.org/pdf/2207.09442v3", "summary": "We present Theseus, an efficient application-agnostic open source library for differentiable nonlinear least squares (DNLS) optimization built on PyTorch, providing a common framework for end-to-end structured learning in robotics and vision. Existing DNLS implementations are application specific and do not always incorporate many ingredients important for efficiency. Theseus is application-agnostic, as we illustrate with several example applications that are built using the same underlying differentiable components, such as second-order optimizers, standard costs functions, and Lie groups. For efficiency, Theseus incorporates support for sparse solvers, automatic vectorization, batching, GPU acceleration, and gradient computation with implicit differentiation and direct loss minimization. We do extensive performance evaluation in a set of applications, demonstrating significant efficiency gains and better scalability when these features are incorporated. Project page: https://sites.google.com/view/theseus-ai", "published": "2022-07-19T17:57:40Z", "version": 3}, {"aid": "2207.09542", "authors": ["Shiyu Wang", "Yuanqi Du", "Xiaojie Guo", "Bo Pan", "Zhaohui Qin", "Liang Zhao"], "title": "Controllable Data Generation by Deep Learning: A Review", "url": "http://arxiv.org/pdf/2207.09542v6", "summary": "Designing and generating new data under targeted properties has been attracting various critical applications such as molecule design, image editing and speech synthesis. Traditional hand-crafted approaches heavily rely on expertise experience and intensive human efforts, yet still suffer from the insufficiency of scientific knowledge and low throughput to support effective and efficient data generation. Recently, the advancement of deep learning has created the opportunity for expressive methods to learn the underlying representation and properties of data. Such capability provides new ways of determining the mutual relationship between the structural patterns and functional properties of the data and leveraging such relationships to generate structural data, given the desired properties. This article is a systematic review that explains this promising research area, commonly known as controllable deep data generation. First, the article raises the potential challenges and provides preliminaries. Then the article formally defines controllable deep data generation, proposes a taxonomy on various techniques and summarizes the evaluation metrics in this specific domain. After that, the article introduces exciting applications of controllable deep data generation, experimentally analyzes and compares existing works. Finally, this article highlights the promising future directions of controllable deep data generation and identifies five potential challenges.", "published": "2022-07-19T20:44:42Z", "version": 6}, {"aid": "2207.09610", "authors": ["Dongliang Cao", "Florian Bernard"], "title": "Unsupervised Deep Multi-Shape Matching", "url": "http://arxiv.org/pdf/2207.09610v1", "summary": "3D shape matching is a long-standing problem in computer vision and computer graphics. While deep neural networks were shown to lead to state-of-the-art results in shape matching, existing learning-based approaches are limited in the context of multi-shape matching: (i) either they focus on matching pairs of shapes only and thus suffer from cycle-inconsistent multi-matchings, or (ii) they require an explicit template shape to address the matching of a collection of shapes. In this paper, we present a novel approach for deep multi-shape matching that ensures cycle-consistent multi-matchings while not depending on an explicit template shape. To this end, we utilise a shape-to-universe multi-matching representation that we combine with powerful functional map regularisation, so that our multi-shape matching neural network can be trained in a fully unsupervised manner. While the functional map regularisation is only considered during training time, functional maps are not computed for predicting correspondences, thereby allowing for fast inference. We demonstrate that our method achieves state-of-the-art results on several challenging benchmark datasets, and, most remarkably, that our unsupervised method even outperforms recent supervised methods.", "published": "2022-07-20T01:22:08Z", "version": 1}, {"aid": "2207.09734", "authors": ["Chris Fields", "Karl Friston", "James F. Glazebrook", "Michael Levin", "Antonino Marcian\u00f2"], "title": "The Free Energy Principle drives neuromorphic development", "url": "http://arxiv.org/pdf/2207.09734v1", "summary": "We show how any system with morphological degrees of freedom and locally limited free energy will, under the constraints of the free energy principle, evolve toward a neuromorphic morphology that supports hierarchical computations in which each level of the hierarchy enacts a coarse-graining of its inputs, and dually a fine-graining of its outputs. Such hierarchies occur throughout biology, from the architectures of intracellular signal transduction pathways to the large-scale organization of perception and action cycles in the mammalian brain. Formally, the close formal connections between cone-cocone diagrams (CCCD) as models of quantum reference frames on the one hand, and between CCCDs and topological quantum field theories on the other, allow the representation of such computations in the fully-general quantum-computational framework of topological quantum neural networks.", "published": "2022-07-20T08:22:03Z", "version": 1}, {"aid": "2207.09897", "authors": ["Beren Millidge", "Christopher L Buckley"], "title": "Successor Representation Active Inference", "url": "http://arxiv.org/pdf/2207.09897v1", "summary": "Recent work has uncovered close links between between classical reinforcement learning algorithms, Bayesian filtering, and Active Inference which lets us understand value functions in terms of Bayesian posteriors. An alternative, but less explored, model-free RL algorithm is the successor representation, which expresses the value function in terms of a successor matrix of expected future state occupancies. In this paper, we derive the probabilistic interpretation of the successor representation in terms of Bayesian filtering and thus design a novel active inference agent architecture utilizing successor representations instead of model-based planning. We demonstrate that active inference successor representations have significant advantages over current active inference agents in terms of planning horizon and computational cost. Moreover, we demonstrate how the successor representation agent can generalize to changing reward functions such as variants of the expected free energy.", "published": "2022-07-20T13:50:27Z", "version": 1}, {"aid": "2207.09944", "authors": ["Cian Eastwood", "Alexander Robey", "Shashank Singh", "Julius von K\u00fcgelgen", "Hamed Hassani", "George J. Pappas", "Bernhard Sch\u00f6lkopf"], "title": "Probable Domain Generalization via Quantile Risk Minimization", "url": "http://arxiv.org/pdf/2207.09944v4", "summary": "Domain generalization (DG) seeks predictors which perform well on unseen test distributions by leveraging data drawn from multiple related training distributions or domains. To achieve this, DG is commonly formulated as an average- or worst-case problem over the set of possible domains. However, predictors that perform well on average lack robustness while predictors that perform well in the worst case tend to be overly-conservative. To address this, we propose a new probabilistic framework for DG where the goal is to learn predictors that perform well with high probability. Our key idea is that distribution shifts seen during training should inform us of probable shifts at test time, which we realize by explicitly relating training and test domains as draws from the same underlying meta-distribution. To achieve probable DG, we propose a new optimization problem called Quantile Risk Minimization (QRM). By minimizing the $\\alpha$-quantile of predictor's risk distribution over domains, QRM seeks predictors that perform well with probability $\\alpha$. To solve QRM in practice, we propose the Empirical QRM (EQRM) algorithm and provide: (i) a generalization bound for EQRM; and (ii) the conditions under which EQRM recovers the causal predictor as $\\alpha \\to 1$. In our experiments, we introduce a more holistic quantile-focused evaluation protocol for DG and demonstrate that EQRM outperforms state-of-the-art baselines on datasets from WILDS and DomainBed.", "published": "2022-07-20T14:41:09Z", "version": 4}, {"aid": "2207.10271", "authors": ["Yan Hong", "Li Niu", "Jianfu Zhang", "Liqing Zhang"], "title": "DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific Delta", "url": "http://arxiv.org/pdf/2207.10271v3", "summary": "Learning to generate new images for a novel category based on only a few images, named as few-shot image generation, has attracted increasing research interest. Several state-of-the-art works have yielded impressive results, but the diversity is still limited. In this work, we propose a novel Delta Generative Adversarial Network (DeltaGAN), which consists of a reconstruction subnetwork and a generation subnetwork. The reconstruction subnetwork captures intra-category transformation, i.e., delta, between same-category pairs. The generation subnetwork generates sample-specific delta for an input image, which is combined with this input image to generate a new image within the same category. Besides, an adversarial delta matching loss is designed to link the above two subnetworks together. Extensive experiments on six benchmark datasets demonstrate the effectiveness of our proposed method. Our code is available at https://github.com/bcmi/DeltaGAN-Few-Shot-Image-Generation.", "published": "2022-07-21T02:44:30Z", "version": 3}, {"aid": "2207.12941", "authors": ["Fengjun Li", "Xin Feng", "Fanglin Chen", "Guangming Lu", "Wenjie Pei"], "title": "Learning Generalizable Latent Representations for Novel Degradations in Super Resolution", "url": "http://arxiv.org/pdf/2207.12941v1", "summary": "Typical methods for blind image super-resolution (SR) focus on dealing with unknown degradations by directly estimating them or learning the degradation representations in a latent space. A potential limitation of these methods is that they assume the unknown degradations can be simulated by the integration of various handcrafted degradations (e.g., bicubic downsampling), which is not necessarily true. The real-world degradations can be beyond the simulation scope by the handcrafted degradations, which are referred to as novel degradations. In this work, we propose to learn a latent representation space for degradations, which can be generalized from handcrafted (base) degradations to novel degradations. The obtained representations for a novel degradation in this latent space are then leveraged to generate degraded images consistent with the novel degradation to compose paired training data for SR model. Furthermore, we perform variational inference to match the posterior of degradations in latent representation space with a prior distribution (e.g., Gaussian distribution). Consequently, we are able to sample more high-quality representations for a novel degradation to augment the training data for SR model. We conduct extensive experiments on both synthetic and real-world datasets to validate the effectiveness and advantages of our method for blind super-resolution with novel degradations.", "published": "2022-07-25T16:22:30Z", "version": 1}, {"aid": "2207.12599", "authors": ["Yiqiao Li", "Jianlong Zhou", "Sunny Verma", "Fang Chen"], "title": "A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics", "url": "http://arxiv.org/pdf/2207.12599v2", "summary": "Graph neural networks (GNNs) have demonstrated a significant boost in prediction performance on graph data. At the same time, the predictions made by these models are often hard to interpret. In that regard, many efforts have been made to explain the prediction mechanisms of these models from perspectives such as GNNExplainer, XGNN and PGExplainer. Although such works present systematic frameworks to interpret GNNs, a holistic review for explainable GNNs is unavailable. In this survey, we present a comprehensive review of explainability techniques developed for GNNs. We focus on explainable graph neural networks and categorize them based on the use of explainable methods. We further provide the common performance metrics for GNNs explanations and point out several future research directions.", "published": "2022-07-26T01:45:54Z", "version": 2}, {"aid": "2207.13050", "authors": ["Arian Bakhtiarnia", "Qi Zhang", "Alexandros Iosifidis"], "title": "Efficient High-Resolution Deep Learning: A Survey", "url": "http://arxiv.org/pdf/2207.13050v2", "summary": "Cameras in modern devices such as smartphones, satellites and medical equipment are capable of capturing very high resolution images and videos. Such high-resolution data often need to be processed by deep learning models for cancer detection, automated road navigation, weather prediction, surveillance, optimizing agricultural processes and many other applications. Using high-resolution images and videos as direct inputs for deep learning models creates many challenges due to their high number of parameters, computation cost, inference latency and GPU memory consumption. Simple approaches such as resizing the images to a lower resolution are common in the literature, however, they typically significantly decrease accuracy. Several works in the literature propose better alternatives in order to deal with the challenges of high-resolution data and improve accuracy and speed while complying with hardware limitations and time restrictions. This survey describes such efficient high-resolution deep learning methods, summarizes real-world applications of high-resolution deep learning, and provides comprehensive information about available high-resolution datasets.", "published": "2022-07-26T17:13:53Z", "version": 2}, {"aid": "2207.13190", "authors": ["Julia Berezutskaya", "Anne-Lise Saive", "Karim Jerbi", "Marcel van Gerven"], "title": "How does artificial intelligence contribute to iEEG research?", "url": "http://arxiv.org/pdf/2207.13190v1", "summary": "Artificial intelligence (AI) is a fast-growing field focused on modeling and machine implementation of various cognitive functions with an increasing number of applications in computer vision, text processing, robotics, neurotechnology, bio-inspired computing and others. In this chapter, we describe how AI methods can be applied in the context of intracranial electroencephalography (iEEG) research. IEEG data is unique as it provides extremely high-quality signals recorded directly from brain tissue. Applying advanced AI models to these data carries the potential to further our understanding of many fundamental questions in neuroscience. At the same time, as an invasive technique, iEEG lends itself well to long-term, mobile brain-computer interface applications, particularly for communication in severely paralyzed individuals. We provide a detailed overview of these two research directions in the application of AI techniques to iEEG. That is, (1) the development of computational models that target fundamental questions about the neurobiological nature of cognition (AI-iEEG for neuroscience) and (2) applied research on monitoring and identification of event-driven brain states for the development of clinical brain-computer interface systems (AI-iEEG for neurotechnology). We explain key machine learning concepts, specifics of processing and modeling iEEG data and details of state-of-the-art iEEG-based neurotechnology and brain-computer interfaces.", "published": "2022-07-26T21:38:01Z", "version": 1}, {"aid": "2207.13243", "authors": ["Tilman R\u00e4uker", "Anson Ho", "Stephen Casper", "Dylan Hadfield-Menell"], "title": "Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks", "url": "http://arxiv.org/pdf/2207.13243v6", "summary": "The last decade of machine learning has seen drastic increases in scale and capabilities. Deep neural networks (DNNs) are increasingly being deployed in the real world. However, they are difficult to analyze, raising concerns about using them without a rigorous understanding of how they function. Effective tools for interpreting them will be important for building more trustworthy AI by helping to identify problems, fix bugs, and improve basic understanding. In particular, \"inner\" interpretability techniques, which focus on explaining the internal components of DNNs, are well-suited for developing a mechanistic understanding, guiding manual modifications, and reverse engineering solutions.   Much recent work has focused on DNN interpretability, and rapid progress has thus far made a thorough systematization of methods difficult. In this survey, we review over 300 works with a focus on inner interpretability tools. We introduce a taxonomy that classifies methods by what part of the network they help to explain (weights, neurons, subnetworks, or latent representations) and whether they are implemented during (intrinsic) or after (post hoc) training. To our knowledge, we are also the first to survey a number of connections between interpretability research and work in adversarial robustness, continual learning, modularity, network compression, and studying the human visual system. We discuss key challenges and argue that the status quo in interpretability research is largely unproductive. Finally, we highlight the importance of future work that emphasizes diagnostics, debugging, adversaries, and benchmarking in order to make interpretability tools more useful to engineers in practical applications.", "published": "2022-07-27T01:59:13Z", "version": 6}, {"aid": "2207.14491", "authors": ["Chaerin Kong", "Nojun Kwak"], "title": "Conservative Generator, Progressive Discriminator: Coordination of Adversaries in Few-shot Incremental Image Synthesis", "url": "http://arxiv.org/pdf/2207.14491v2", "summary": "The capacity to learn incrementally from an online stream of data is an envied trait of human learners, as deep neural networks typically suffer from catastrophic forgetting and stability-plasticity dilemma. Several works have previously explored incremental few-shot learning, a task with greater challenges due to data constraint, mostly in classification setting with mild success. In this work, we study the underrepresented task of generative incremental few-shot learning. To effectively handle the inherent challenges of incremental learning and few-shot learning, we propose a novel framework named ConPro that leverages the two-player nature of GANs. Specifically, we design a conservative generator that preserves past knowledge in parameter and compute efficient manner, and a progressive discriminator that learns to reason semantic distances between past and present task samples, minimizing overfitting with few data points and pursuing good forward transfer. We present experiments to validate the effectiveness of ConPro.", "published": "2022-07-29T06:00:29Z", "version": 2}, {"aid": "2207.14545", "authors": ["Yanchen Li", "Qingzhong Ai", "Fumihiko Ino"], "title": "A One-Shot Reparameterization Method for Reducing the Loss of Tile Pruning on DNNs", "url": "http://arxiv.org/pdf/2207.14545v1", "summary": "Recently, tile pruning has been widely studied to accelerate the inference of deep neural networks (DNNs). However, we found that the loss due to tile pruning, which can eliminate important elements together with unimportant elements, is large on trained DNNs. In this study, we propose a one-shot reparameterization method, called TileTrans, to reduce the loss of tile pruning. Specifically, we repermute the rows or columns of the weight matrix such that the model architecture can be kept unchanged after reparameterization. This repermutation realizes the reparameterization of the DNN model without any retraining. The proposed reparameterization method combines important elements into the same tile; thus, preserving the important elements after the tile pruning. Furthermore, TileTrans can be seamlessly integrated into existing tile pruning methods because it is a pre-processing method executed before pruning, which is orthogonal to most existing methods. The experimental results demonstrate that our method is essential in reducing the loss of tile pruning on DNNs. Specifically, the accuracy is improved by up to 17% for AlexNet while 5% for ResNet-34, where both models are pre-trained on ImageNet.", "published": "2022-07-29T08:27:15Z", "version": 1}, {"aid": "2208.00338", "authors": ["Sein Park", "Yeongsang Jang", "Eunhyeok Park"], "title": "Symmetry Regularization and Saturating Nonlinearity for Robust Quantization", "url": "http://arxiv.org/pdf/2208.00338v1", "summary": "Robust quantization improves the tolerance of networks for various implementations, allowing reliable output in different bit-widths or fragmented low-precision arithmetic. In this work, we perform extensive analyses to identify the sources of quantization error and present three insights to robustify a network against quantization: reduction of error propagation, range clamping for error minimization, and inherited robustness against quantization. Based on these insights, we propose two novel methods called symmetry regularization (SymReg) and saturating nonlinearity (SatNL). Applying the proposed methods during training can enhance the robustness of arbitrary neural networks against quantization on existing post-training quantization (PTQ) and quantization-aware training (QAT) algorithms and enables us to obtain a single weight flexible enough to maintain the output quality under various conditions. We conduct extensive studies on CIFAR and ImageNet datasets and validate the effectiveness of the proposed methods.", "published": "2022-07-31T02:12:28Z", "version": 1}, {"aid": "2208.00508", "authors": ["Kinyua Gikunda"], "title": "Deep Active Learning with Budget Annotation", "url": "http://arxiv.org/pdf/2208.00508v1", "summary": "Digital data collected over the decades and data currently being produced with use of information technology is vastly the unlabeled data or data without description. The unlabeled data is relatively easy to acquire but expensive to label even with use of domain experts. Most of the recent works focus on use of active learning with uncertainty metrics measure to address this problem. Although most uncertainty selection strategies are very effective, they fail to take informativeness of the unlabeled instances into account and are prone to querying outliers. In order to address these challenges we propose an hybrid approach of computing both the uncertainty and informativeness of an instance, then automaticaly label the computed instances using budget annotator. To reduce the annotation cost, we employ the state-of-the-art pre-trained models in order to avoid querying information already contained in those models. Our extensive experiments on different sets of datasets demonstrate the efficacy of the proposed approach.", "published": "2022-07-31T20:20:44Z", "version": 1}, {"aid": "2208.00587", "authors": ["Dai Hai Nguyen", "Tetsuya Sakurai"], "title": "A Particle-Based Algorithm for Distributional Optimization on \\textit{Constrained Domains} via Variational Transport and Mirror Descent", "url": "http://arxiv.org/pdf/2208.00587v3", "summary": "We consider the optimization problem of minimizing an objective functional, which admits a variational form and is defined over probability distributions on the constrained domain, which poses challenges to both theoretical analysis and algorithmic design. Inspired by the mirror descent algorithm for constrained optimization, we propose an iterative particle-based algorithm, named Mirrored Variational Transport (mirrorVT), extended from the Variational Transport framework [7] for dealing with the constrained domain. In particular, for each iteration, mirrorVT maps particles to an unconstrained dual domain induced by a mirror map and then approximately perform Wasserstein gradient descent on the manifold of distributions defined over the dual space by pushing particles. At the end of iteration, particles are mapped back to the original constrained domain. Through simulated experiments, we demonstrate the effectiveness of mirrorVT for minimizing the functionals over probability distributions on the simplex- and Euclidean ball-constrained domains. We also analyze its theoretical properties and characterize its convergence to the global minimum of the objective functional.", "published": "2022-08-01T03:25:01Z", "version": 3}, {"aid": "2208.01195", "authors": ["Wenxuan Ma", "Jinming Zhang", "Shuang Li", "Chi Harold Liu", "Yulin Wang", "Wei Li"], "title": "Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation", "url": "http://arxiv.org/pdf/2208.01195v1", "summary": "Extensive studies on Unsupervised Domain Adaptation (UDA) have propelled the deployment of deep learning from limited experimental datasets into real-world unconstrained domains. Most UDA approaches align features within a common embedding space and apply a shared classifier for target prediction. However, since a perfectly aligned feature space may not exist when the domain discrepancy is large, these methods suffer from two limitations. First, the coercive domain alignment deteriorates target domain discriminability due to lacking target label supervision. Second, the source-supervised classifier is inevitably biased to source data, thus it may underperform in target domain. To alleviate these issues, we propose to simultaneously conduct feature alignment in two individual spaces focusing on different domains, and create for each space a domain-oriented classifier tailored specifically for that domain. Specifically, we design a Domain-Oriented Transformer (DOT) that has two individual classification tokens to learn different domain-oriented representations, and two classifiers to preserve domain-wise discriminability. Theoretical guaranteed contrastive-based alignment and the source-guided pseudo-label refinement strategy are utilized to explore both domain-invariant and specific information. Comprehensive experiments validate that our method achieves state-of-the-art on several benchmarks.", "published": "2022-08-02T01:38:37Z", "version": 1}, {"aid": "2208.01204", "authors": ["Peter G. Stratton", "Andrew Wabnitz", "Chip Essam", "Allen Cheung", "Tara J. Hamilton"], "title": "Making a Spiking Net Work: Robust brain-like unsupervised machine learning", "url": "http://arxiv.org/pdf/2208.01204v2", "summary": "The surge in interest in Artificial Intelligence (AI) over the past decade has been driven almost exclusively by advances in Artificial Neural Networks (ANNs). While ANNs set state-of-the-art performance for many previously intractable problems, the use of global gradient descent necessitates large datasets and computational resources for training, potentially limiting their scalability for real-world domains. Spiking Neural Networks (SNNs) are an alternative to ANNs that use more brain-like artificial neurons and can use local unsupervised learning to rapidly discover sparse recognizable features in the input data. SNNs, however, struggle with dynamical stability and have failed to match the accuracy of ANNs. Here we show how an SNN can overcome many of the shortcomings that have been identified in the literature, including offering a principled solution to the dynamical \"vanishing spike problem\", to outperform all existing shallow SNNs and equal the performance of an ANN. It accomplishes this while using unsupervised learning with unlabeled data and only 1/50th of the training epochs (labeled data is used only for a simple linear readout layer). This result makes SNNs a viable new method for fast, accurate, efficient, explainable, and re-deployable machine learning with unlabeled data.", "published": "2022-08-02T02:10:00Z", "version": 2}, {"aid": "2208.01265", "authors": ["Soroush Sheikh Gargar"], "title": "Explicit Use of Fourier Spectrum in Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2208.01265v1", "summary": "Generative Adversarial Networks have got the researchers' attention due to their state-of-the-art performance in generating new images with only a dataset of the target distribution. It has been shown that there is a dissimilarity between the spectrum of authentic images and fake ones. Since the Fourier transform is a bijective mapping, saying that the model has a significant problem in learning the original distribution is a fair conclusion. In this work, we investigate the possible reasons for the mentioned drawback in the architecture and mathematical theory of the current GANs. Then we propose a new model to reduce the discrepancies between the spectrum of the actual and fake images. To that end, we design a brand new architecture for the frequency domain using the blueprint of geometric deep learning. Then, we experimentally show promising improvements in the quality of the generated images by considering the Fourier domain representation of the original data as a principal feature in the training process.", "published": "2022-08-02T06:26:44Z", "version": 1}, {"aid": "2208.01358", "authors": ["Olivier Risser-Maroix", "Benjamin Chamand"], "title": "What can we Learn by Predicting Accuracy?", "url": "http://arxiv.org/pdf/2208.01358v2", "summary": "This paper seeks to answer the following question: \\textit{\"What can we learn by predicting accuracy?\"}.   Indeed, classification is one of the most popular tasks in machine learning, and many loss functions have been developed to maximize this non-differentiable objective function.   Unlike past work on loss function design, which was guided mainly by intuition and theory before being validated by experimentation, here we propose to approach this problem in the opposite way: we seek to extract knowledge by experimentation.   This data-driven approach is similar to that used in physics to discover general laws from data.   We used a symbolic regression method to automatically find a mathematical expression highly correlated with a linear classifier's accuracy.   The formula discovered on more than 260 datasets of embeddings has a Pearson's correlation of 0.96 and a $r^2$ of 0.93.   More interestingly, this formula is highly explainable and confirms insights from various previous papers on loss design.   We hope this work will open new perspectives in the search for new heuristics leading to a deeper understanding of machine learning theory.", "published": "2022-08-02T10:58:17Z", "version": 2}, {"aid": "2208.01369", "authors": ["Christian S. Pilz", "Benjamin Clemens", "Inka C. Hiss", "Christoph Weiss", "Ulrich Canzler", "Jarek Krajewski", "Ute Habel", "Steffen Leonhardt"], "title": "The Face of Affective Disorders", "url": "http://arxiv.org/pdf/2208.01369v3", "summary": "We study the statistical properties of facial behaviour altered by the regulation of brain arousal in the clinical domain of psychiatry. The underlying mechanism is linked to the empirical interpretation of the vigilance continuum as behavioral surrogate measurement for certain states of mind. Referring to the classical scalp-based obtrusive measurements, we name the presented method Opto-Electronic Encephalography (OEG) which solely relies on modern camera-based real-time signal processing and computer vision. Based upon a stochastic representation as coherence of the face dynamics, reflecting the hemifacial asymmetry in emotion expressions, we demonstrate an almost flawless distinction between patients and healthy controls as well as between the mental disorders depression and schizophrenia and the symptom severity. In contrast to the standard diagnostic process, which is time-consuming, subjective and does not incorporate neurobiological data such as real-time face dynamics, the objective stochastic modeling of the affective responsiveness only requires a few minutes of video-based facial recordings. We also highlight the potential of the methodology as a causal inference model in transdiagnostic analysis to predict the outcome of pharmacological treatment. All results are obtained on a clinical longitudinal data collection with an amount of 99 patients and 43 controls.", "published": "2022-08-02T11:28:17Z", "version": 3}, {"aid": "2208.01424", "authors": ["Rui-Yang Ju", "Jen-Shiun Chiang", "Chih-Chia Chen", "Yu-Shian Lin"], "title": "Connection Reduction of DenseNet for Image Recognition", "url": "http://arxiv.org/pdf/2208.01424v3", "summary": "Convolutional Neural Networks (CNN) increase depth by stacking convolutional layers, and deeper network models perform better in image recognition. Empirical research shows that simply stacking convolutional layers does not make the network train better, and skip connection (residual learning) can improve network model performance. For the image classification task, models with global densely connected architectures perform well in large datasets like ImageNet, but are not suitable for small datasets such as CIFAR-10 and SVHN. Different from dense connections, we propose two new algorithms to connect layers. Baseline is a densely connected network, and the networks connected by the two new algorithms are named ShortNet1 and ShortNet2 respectively. The experimental results of image classification on CIFAR-10 and SVHN show that ShortNet1 has a 5% lower test error rate and 25% faster inference time than Baseline. ShortNet2 speeds up inference time by 40% with less loss in test accuracy. Code and pre-trained models are available at https://github.com/RuiyangJu/Connection_Reduction.", "published": "2022-08-02T13:00:35Z", "version": 3}, {"aid": "2208.01753", "authors": ["Edward Fish", "Jon Weinbren", "Andrew Gilbert"], "title": "Two-Stream Transformer Architecture for Long Video Understanding", "url": "http://arxiv.org/pdf/2208.01753v1", "summary": "Pure vision transformer architectures are highly effective for short video classification and action recognition tasks. However, due to the quadratic complexity of self attention and lack of inductive bias, transformers are resource intensive and suffer from data inefficiencies. Long form video understanding tasks amplify data and memory efficiency problems in transformers making current approaches unfeasible to implement on data or memory restricted domains. This paper introduces an efficient Spatio-Temporal Attention Network (STAN) which uses a two-stream transformer architecture to model dependencies between static image features and temporal contextual features. Our proposed approach can classify videos up to two minutes in length on a single GPU, is data efficient, and achieves SOTA performance on several long video understanding tasks.", "published": "2022-08-02T21:03:48Z", "version": 1}, {"aid": "2208.01864", "authors": ["Dohoon Ryu", "Jong Chul Ye"], "title": "Pyramidal Denoising Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2208.01864v3", "summary": "Recently, diffusion model have demonstrated impressive image generation performances, and have been extensively studied in various computer vision tasks. Unfortunately, training and evaluating diffusion models consume a lot of time and computational resources. To address this problem, here we present a novel pyramidal diffusion model that can generate high resolution images starting from much coarser resolution images using a {\\em single} score function trained with a positional embedding. This enables a neural network to be much lighter and also enables time-efficient image generation without compromising its performances. Furthermore, we show that the proposed approach can be also efficiently used for multi-scale super-resolution problem using a single score function.", "published": "2022-08-03T06:26:18Z", "version": 3}, {"aid": "2208.01903", "authors": ["Jo\u017ee M Ro\u017eanec", "Bojan Nemec"], "title": "Neural Dynamic Movement Primitives -- a survey", "url": "http://arxiv.org/pdf/2208.01903v1", "summary": "One of the most important challenges in robotics is producing accurate trajectories and controlling their dynamic parameters so that the robots can perform different tasks. The ability to provide such motion control is closely related to how such movements are encoded. Advances on deep learning have had a strong repercussion in the development of novel approaches for Dynamic Movement Primitives. In this work, we survey scientific literature related to Neural Dynamic Movement Primitives, to complement existing surveys on Dynamic Movement Primitives.", "published": "2022-08-03T08:11:08Z", "version": 1}, {"aid": "2208.01996", "authors": ["Xin Zhang", "Ying-Cong Chen"], "title": "Adaptive Domain Generalization via Online Disagreement Minimization", "url": "http://arxiv.org/pdf/2208.01996v2", "summary": "Deep neural networks suffer from significant performance deterioration when there exists distribution shift between deployment and training. Domain Generalization (DG) aims to safely transfer a model to unseen target domains by only relying on a set of source domains. Although various DG approaches have been proposed, a recent study named DomainBed, reveals that most of them do not beat the simple Empirical Risk Minimization (ERM). To this end, we propose a general framework that is orthogonal to existing DG algorithms and could improve their performance consistently. Unlike previous DG works that stake on a static source model to be hopefully a universal one, our proposed AdaODM adaptively modifies the source model at test time for different target domains. Specifically, we create multiple domain-specific classifiers upon a shared domain-generic feature extractor. The feature extractor and classifiers are trained in an adversarial way, where the feature extractor embeds the input samples into a domain-invariant space, and the multiple classifiers capture the distinct decision boundaries that each of them relates to a specific source domain. During testing, distribution differences between target and source domains could be effectively measured by leveraging prediction disagreement among source classifiers. By fine-tuning source models to minimize the disagreement at test time, target domain features are well aligned to the invariant feature space. We verify AdaODM on two popular DG methods, namely ERM and CORAL, and four DG benchmarks, namely VLCS, PACS, OfficeHome, and TerraIncognita. The results show AdaODM stably improves the generalization capacity on unseen domains and achieves state-of-the-art performance.", "published": "2022-08-03T11:51:11Z", "version": 2}, {"aid": "2208.02246", "authors": ["Qiyang Li", "Ajay Jain", "Pieter Abbeel"], "title": "AdaCat: Adaptive Categorical Discretization for Autoregressive Models", "url": "http://arxiv.org/pdf/2208.02246v1", "summary": "Autoregressive generative models can estimate complex continuous data distributions, like trajectory rollouts in an RL environment, image intensities, and audio. Most state-of-the-art models discretize continuous data into several bins and use categorical distributions over the bins to approximate the continuous data distribution. The advantage is that the categorical distribution can easily express multiple modes and are straightforward to optimize. However, such approximation cannot express sharp changes in density without using significantly more bins, making it parameter inefficient. We propose an efficient, expressive, multimodal parameterization called Adaptive Categorical Discretization (AdaCat). AdaCat discretizes each dimension of an autoregressive model adaptively, which allows the model to allocate density to fine intervals of interest, improving parameter efficiency. AdaCat generalizes both categoricals and quantile-based regression. AdaCat is a simple add-on to any discretization-based distribution estimator. In experiments, AdaCat improves density estimation for real-world tabular data, images, audio, and trajectories, and improves planning in model-based offline RL.", "published": "2022-08-03T17:53:46Z", "version": 1}, {"aid": "2208.02845", "authors": ["Qinhua Jenny Sun", "Khuong Vo", "Kitty Lui", "Michael Nunez", "Joachim Vandekerckhove", "Ramesh Srinivasan"], "title": "Decision SincNet: Neurocognitive models of decision making that predict cognitive processes from neural signals", "url": "http://arxiv.org/pdf/2208.02845v2", "summary": "Human decision making behavior is observed with choice-response time data during psychological experiments. Drift-diffusion models of this data consist of a Wiener first-passage time (WFPT) distribution and are described by cognitive parameters: drift rate, boundary separation, and starting point. These estimated parameters are of interest to neuroscientists as they can be mapped to features of cognitive processes of decision making (such as speed, caution, and bias) and related to brain activity. The observed patterns of RT also reflect the variability of cognitive processes from trial to trial mediated by neural dynamics. We adapted a SincNet-based shallow neural network architecture to fit the Drift-Diffusion model using EEG signals on every experimental trial. The model consists of a SincNet layer, a depthwise spatial convolution layer, and two separate FC layers that predict drift rate and boundary for each trial in-parallel. The SincNet layer parametrized the kernels in order to directly learn the low and high cutoff frequencies of bandpass filters that are applied to the EEG data to predict drift and boundary parameters. During training, model parameters were updated by minimizing the negative log likelihood function of WFPT distribution given trial RT. We developed separate decision SincNet models for each participant performing a two-alternative forced-choice task. Our results showed that single-trial estimates of drift and boundary performed better at predicting RTs than the median estimates in both training and test data sets, suggesting that our model can successfully use EEG features to estimate meaningful single-trial Diffusion model parameters. Furthermore, the shallow SincNet architecture identified time windows of information processing related to evidence accumulation and caution and the EEG frequency bands that reflect these processes within each participant.", "published": "2022-08-04T18:51:29Z", "version": 2}, {"aid": "2208.02879", "authors": ["Wenxuan Wu", "Li Fuxin", "Qi Shan"], "title": "PointConvFormer: Revenge of the Point-based Convolution", "url": "http://arxiv.org/pdf/2208.02879v3", "summary": "We introduce PointConvFormer, a novel building block for point cloud based deep network architectures. Inspired by generalization theory, PointConvFormer combines ideas from point convolution, where filter weights are only based on relative position, and Transformers which utilize feature-based attention. In PointConvFormer, attention computed from feature difference between points in the neighborhood is used to modify the convolutional weights at each point. Hence, we preserved the invariances from point convolution, whereas attention helps to select relevant points in the neighborhood for convolution. PointConvFormer is suitable for multiple tasks that require details at the point level, such as segmentation and scene flow estimation tasks. We experiment on both tasks with multiple datasets including ScanNet, SemanticKitti, FlyingThings3D and KITTI. Our results show that PointConvFormer offers a better accuracy-speed tradeoff than classic convolutions, regular transformers, and voxelized sparse convolution approaches. Visualizations show that PointConvFormer performs similarly to convolution on flat areas, whereas the neighborhood selection effect is stronger on object boundaries, showing that it has got the best of both worlds.", "published": "2022-08-04T20:31:46Z", "version": 3}, {"aid": "2208.02896", "authors": ["Neha Hulkund", "Nicolo Fusi", "Jennifer Wortman Vaughan", "David Alvarez-Melis"], "title": "Interpretable Distribution Shift Detection using Optimal Transport", "url": "http://arxiv.org/pdf/2208.02896v1", "summary": "We propose a method to identify and characterize distribution shifts in classification datasets based on optimal transport. It allows the user to identify the extent to which each class is affected by the shift, and retrieves corresponding pairs of samples to provide insights on its nature. We illustrate its use on synthetic and natural shift examples. While the results we present are preliminary, we hope that this inspires future work on interpretable methods for analyzing distribution shifts.", "published": "2022-08-04T21:55:29Z", "version": 1}, {"aid": "2208.03211", "authors": ["Qingyang Wang", "Michael A. Powell", "Ali Geisa", "Eric Bridgeford", "Carey E. Priebe", "Joshua T. Vogelstein"], "title": "Why do networks have inhibitory/negative connections?", "url": "http://arxiv.org/pdf/2208.03211v8", "summary": "Why do brains have inhibitory connections? Why do deep networks have negative weights? We propose an answer from the perspective of representation capacity. We believe representing functions is the primary role of both (i) the brain in natural intelligence, and (ii) deep networks in artificial intelligence. Our answer to why there are inhibitory/negative weights is: to learn more functions. We prove that, in the absence of negative weights, neural networks with non-decreasing activation functions are not universal approximators. While this may be an intuitive result to some, to the best of our knowledge, there is no formal theory, in either machine learning or neuroscience, that demonstrates why negative weights are crucial in the context of representation capacity. Further, we provide insights on the geometric properties of the representation space that non-negative deep networks cannot represent. We expect these insights will yield a deeper understanding of more sophisticated inductive priors imposed on the distribution of weights that lead to more efficient biological and machine learning.", "published": "2022-08-05T14:54:08Z", "version": 8}, {"aid": "2208.05785", "authors": ["Shubhendu Jena", "Franck Multon", "Adnane Boukhayma"], "title": "Neural Mesh-Based Graphics", "url": "http://arxiv.org/pdf/2208.05785v3", "summary": "We revisit NPBG, the popular approach to novel view synthesis that introduced the ubiquitous point feature neural rendering paradigm. We are interested in particular in data-efficient learning with fast view synthesis. We achieve this through a view-dependent mesh-based denser point descriptor rasterization, in addition to a foreground/background scene rendering split, and an improved loss. By training solely on a single scene, we outperform NPBG, which has been trained on ScanNet and then scene finetuned. We also perform competitively with respect to the state-of-the-art method SVS, which has been trained on the full dataset (DTU and Tanks and Temples) and then scene finetuned, in spite of their deeper neural renderer.", "published": "2022-08-10T09:18:28Z", "version": 3}, {"aid": "2208.07422", "authors": ["Xiaofeng Liu", "Chaehwa Yoo", "Fangxu Xing", "Hyejin Oh", "Georges El Fakhri", "Je-Won Kang", "Jonghye Woo"], "title": "Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives", "url": "http://arxiv.org/pdf/2208.07422v1", "summary": "Deep learning has become the method of choice to tackle real-world problems in different domains, partly because of its ability to learn from data and achieve impressive performance on a wide range of applications. However, its success usually relies on two assumptions: (i) vast troves of labeled datasets are required for accurate model fitting, and (ii) training and testing data are independent and identically distributed. Its performance on unseen target domains, thus, is not guaranteed, especially when encountering out-of-distribution data at the adaptation stage. The performance drop on data in a target domain is a critical problem in deploying deep neural networks that are successfully trained on data in a source domain. Unsupervised domain adaptation (UDA) is proposed to counter this, by leveraging both labeled source domain data and unlabeled target domain data to carry out various tasks in the target domain. UDA has yielded promising results on natural image processing, video analysis, natural language processing, time-series data analysis, medical image analysis, etc. In this review, as a rapidly evolving topic, we provide a systematic comparison of its methods and applications. In addition, the connection of UDA with its closely related tasks, e.g., domain generalization and out-of-distribution detection, has also been discussed. Furthermore, deficiencies in current methods and possible promising directions are highlighted.", "published": "2022-08-15T20:05:07Z", "version": 1}, {"aid": "2208.07463", "authors": ["Hao Chen", "Ran Tao", "Han Zhang", "Yidong Wang", "Xiang Li", "Wei Ye", "Jindong Wang", "Guosheng Hu", "Marios Savvides"], "title": "Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets", "url": "http://arxiv.org/pdf/2208.07463v4", "summary": "While parameter efficient tuning (PET) methods have shown great potential with transformer architecture on Natural Language Processing (NLP) tasks, their effectiveness with large-scale ConvNets is still under-studied on Computer Vision (CV) tasks. This paper proposes Conv-Adapter, a PET module designed for ConvNets. Conv-Adapter is light-weight, domain-transferable, and architecture-agnostic with generalized performance on different tasks. When transferring on downstream tasks, Conv-Adapter learns tasks-specific feature modulation to the intermediate representations of backbones while keeping the pre-trained parameters frozen. By introducing only a tiny amount of learnable parameters, e.g., only 3.5% full fine-tuning parameters of ResNet50. It can also be applied for transformer-based backbones. Conv-Adapter outperforms previous PET baseline methods and achieves comparable or surpasses the performance of full fine-tuning on 23 classification tasks of various domains. It also presents superior performance on the few-shot classification with an average margin of 3.39%. Beyond classification, Conv-Adapter can generalize to detection and segmentation tasks with more than 50% reduction of parameters but comparable performance to the traditional full fine-tuning.", "published": "2022-08-15T22:51:23Z", "version": 4}, {"aid": "2208.07591", "authors": ["Subhankar Roy", "Martin Trapp", "Andrea Pilzer", "Juho Kannala", "Nicu Sebe", "Elisa Ricci", "Arno Solin"], "title": "Uncertainty-guided Source-free Domain Adaptation", "url": "http://arxiv.org/pdf/2208.07591v1", "summary": "Source-free domain adaptation (SFDA) aims to adapt a classifier to an unlabelled target data set by only using a pre-trained source model. However, the absence of the source data and the domain shift makes the predictions on the target data unreliable. We propose quantifying the uncertainty in the source model predictions and utilizing it to guide the target adaptation. For this, we construct a probabilistic source model by incorporating priors on the network parameters inducing a distribution over the model predictions. Uncertainties are estimated by employing a Laplace approximation and incorporated to identify target data points that do not lie in the source manifold and to down-weight them when maximizing the mutual information on the target data. Unlike recent works, our probabilistic treatment is computationally lightweight, decouples source training and target adaptation, and requires no specialized source training or changes of the model architecture. We show the advantages of uncertainty-guided SFDA over traditional SFDA in the closed-set and open-set settings and provide empirical evidence that our approach is more robust to strong domain shifts even without tuning.", "published": "2022-08-16T08:03:30Z", "version": 1}, {"aid": "2208.07765", "authors": ["Taewoo Kim", "Chaeyeon Chung", "Yoonseo Kim", "Sunghyun Park", "Kangyeol Kim", "Jaegul Choo"], "title": "Style Your Hair: Latent Optimization for Pose-Invariant Hairstyle Transfer via Local-Style-Aware Hair Alignment", "url": "http://arxiv.org/pdf/2208.07765v1", "summary": "Editing hairstyle is unique and challenging due to the complexity and delicacy of hairstyle. Although recent approaches significantly improved the hair details, these models often produce undesirable outputs when a pose of a source image is considerably different from that of a target hair image, limiting their real-world applications. HairFIT, a pose-invariant hairstyle transfer model, alleviates this limitation yet still shows unsatisfactory quality in preserving delicate hair textures. To solve these limitations, we propose a high-performing pose-invariant hairstyle transfer model equipped with latent optimization and a newly presented local-style-matching loss. In the StyleGAN2 latent space, we first explore a pose-aligned latent code of a target hair with the detailed textures preserved based on local style matching. Then, our model inpaints the occlusions of the source considering the aligned target hair and blends both images to produce a final output. The experimental results demonstrate that our model has strengths in transferring a hairstyle under larger pose differences and preserving local hairstyle textures.", "published": "2022-08-16T14:23:54Z", "version": 1}, {"aid": "2208.07769", "authors": ["Xiaofeng Liu", "Chaehwa Yoo", "Fangxu Xing", "C. -C. Jay Kuo", "Georges El Fakhri", "Jonghye Woo"], "title": "Unsupervised Domain Adaptation for Segmentation with Black-box Source Model", "url": "http://arxiv.org/pdf/2208.07769v1", "summary": "Unsupervised domain adaptation (UDA) has been widely used to transfer knowledge from a labeled source domain to an unlabeled target domain to counter the difficulty of labeling in a new domain. The training of conventional solutions usually relies on the existence of both source and target domain data. However, privacy of the large-scale and well-labeled data in the source domain and trained model parameters can become the major concern of cross center/domain collaborations. In this work, to address this, we propose a practical solution to UDA for segmentation with a black-box segmentation model trained in the source domain only, rather than original source data or a white-box source model. Specifically, we resort to a knowledge distillation scheme with exponential mixup decay (EMD) to gradually learn target-specific representations. In addition, unsupervised entropy minimization is further applied to regularization of the target domain confidence. We evaluated our framework on the BraTS 2018 database, achieving performance on par with white-box source model adaptation approaches.", "published": "2022-08-16T14:29:15Z", "version": 1}, {"aid": "2208.07791", "authors": ["Xiulong Yang", "Sheng-Min Shih", "Yinlin Fu", "Xiaoting Zhao", "Shihao Ji"], "title": "Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model", "url": "http://arxiv.org/pdf/2208.07791v1", "summary": "Diffusion Denoising Probability Models (DDPM) and Vision Transformer (ViT) have demonstrated significant progress in generative tasks and discriminative tasks, respectively, and thus far these models have largely been developed in their own domains. In this paper, we establish a direct connection between DDPM and ViT by integrating the ViT architecture into DDPM, and introduce a new generative model called Generative ViT (GenViT). The modeling flexibility of ViT enables us to further extend GenViT to hybrid discriminative-generative modeling, and introduce a Hybrid ViT (HybViT). Our work is among the first to explore a single ViT for image generation and classification jointly. We conduct a series of experiments to analyze the performance of proposed models and demonstrate their superiority over prior state-of-the-arts in both generative and discriminative tasks. Our code and pre-trained models can be found in https://github.com/sndnyang/Diffusion_ViT .", "published": "2022-08-16T15:02:21Z", "version": 1}, {"aid": "2208.07862", "authors": ["Haonan Qiu", "Yuming Jiang", "Hang Zhou", "Wayne Wu", "Ziwei Liu"], "title": "StyleFaceV: Face Video Generation via Decomposing and Recomposing Pretrained StyleGAN3", "url": "http://arxiv.org/pdf/2208.07862v1", "summary": "Realistic generative face video synthesis has long been a pursuit in both computer vision and graphics community. However, existing face video generation methods tend to produce low-quality frames with drifted facial identities and unnatural movements. To tackle these challenges, we propose a principled framework named StyleFaceV, which produces high-fidelity identity-preserving face videos with vivid movements. Our core insight is to decompose appearance and pose information and recompose them in the latent space of StyleGAN3 to produce stable and dynamic results. Specifically, StyleGAN3 provides strong priors for high-fidelity facial image generation, but the latent space is intrinsically entangled. By carefully examining its latent properties, we propose our decomposition and recomposition designs which allow for the disentangled combination of facial appearance and movements. Moreover, a temporal-dependent model is built upon the decomposed latent features, and samples reasonable sequences of motions that are capable of generating realistic and temporally coherent face videos. Particularly, our pipeline is trained with a joint training strategy on both static images and high-quality video data, which is of higher data efficiency. Extensive experiments demonstrate that our framework achieves state-of-the-art face video generation results both qualitatively and quantitatively. Notably, StyleFaceV is capable of generating realistic $1024\\times1024$ face videos even without high-resolution training videos.", "published": "2022-08-16T17:47:03Z", "version": 1}, {"aid": "2208.07934", "authors": ["Povilas Daniu\u0161is", "Shubham Juneja", "Lukas Kuzma", "Virginijus Marcinkevi\u010dius"], "title": "Measuring Statistical Dependencies via Maximum Norm and Characteristic Functions", "url": "http://arxiv.org/pdf/2208.07934v1", "summary": "In this paper, we focus on the problem of statistical dependence estimation using characteristic functions. We propose a statistical dependence measure, based on the maximum-norm of the difference between joint and product-marginal characteristic functions. The proposed measure can detect arbitrary statistical dependence between two random vectors of possibly different dimensions, is differentiable, and easily integrable into modern machine learning and deep learning pipelines. We also conduct experiments both with simulated and real data. Our simulations show, that the proposed method can measure statistical dependencies in high-dimensional, non-linear data, and is less affected by the curse of dimensionality, compared to the previous work in this line of research. The experiments with real data demonstrate the potential applicability of our statistical measure for two different empirical inference scenarios, showing statistically significant improvement in the performance characteristics when applied for supervised feature extraction and deep neural network regularization. In addition, we provide a link to the accompanying open-source repository https://bit.ly/3d4ch5I.", "published": "2022-08-16T20:24:31Z", "version": 1}, {"aid": "2208.08083", "authors": ["Zongyuan Zhang", "Qingwen Bu", "Tianyang Duan", "Zheng Lin", "Yuhao Qing", "Zihan Fang", "Heming Cui", "Dong Huang"], "title": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models", "url": "http://arxiv.org/pdf/2208.08083v2", "summary": "Deep neural networks (DNNs) are vulnerable to adversarial examples, in which DNNs are misled to false outputs due to inputs containing imperceptible perturbations. Adversarial training, a reliable and effective method of defense, may significantly reduce the vulnerability of neural networks and becomes the de facto standard for robust learning. While many recent works practice the data-centric philosophy, such as how to generate better adversarial examples or use generative models to produce additional training data, we look back to the models themselves and revisit the adversarial robustness from the perspective of deep feature distribution as an insightful complementarity. In this paper, we propose \\textit{Branch Orthogonality adveRsarial Training} (BORT) to obtain state-of-the-art performance with solely the original dataset for adversarial training. To practice our design idea of integrating multiple orthogonal solution spaces, we leverage a simple and straightforward multi-branch neural network that eclipses adversarial attacks with no increase in inference time. We heuristically propose a corresponding loss function, branch-orthogonal loss, to make each solution space of the multi-branch model orthogonal. We evaluate our approach on CIFAR-10, CIFAR-100 and SVHN against $\\ell_{\\infty}$ norm-bounded perturbations of size $\\epsilon = 8/255$, respectively. Exhaustive experiments are conducted to show that our method goes beyond all state-of-the-art methods without any tricks. Compared to all methods that do not use additional data for training, our models achieve 67.3\\% and 41.5\\% robust accuracy on CIFAR-10 and CIFAR-100 (improving upon the state-of-the-art by +7.23\\% and +9.07\\%). We also outperform methods using a training set with a far larger scale than ours.", "published": "2022-08-17T05:42:59Z", "version": 2}, {"aid": "2208.08092", "authors": ["Jaskirat Singh", "Liang Zheng", "Cameron Smith", "Jose Echevarria"], "title": "Paint2Pix: Interactive Painting based Progressive Image Synthesis and Editing", "url": "http://arxiv.org/pdf/2208.08092v1", "summary": "Controllable image synthesis with user scribbles is a topic of keen interest in the computer vision community. In this paper, for the first time we study the problem of photorealistic image synthesis from incomplete and primitive human paintings. In particular, we propose a novel approach paint2pix, which learns to predict (and adapt) \"what a user wants to draw\" from rudimentary brushstroke inputs, by learning a mapping from the manifold of incomplete human paintings to their realistic renderings. When used in conjunction with recent works in autonomous painting agents, we show that paint2pix can be used for progressive image synthesis from scratch. During this process, paint2pix allows a novice user to progressively synthesize the desired image output, while requiring just few coarse user scribbles to accurately steer the trajectory of the synthesis process. Furthermore, we find that our approach also forms a surprisingly convenient approach for real image editing, and allows the user to perform a diverse range of custom fine-grained edits through the addition of only a few well-placed brushstrokes. Supplemental video and demo are available at https://1jsingh.github.io/paint2pix", "published": "2022-08-17T06:08:11Z", "version": 1}, {"aid": "2208.08160", "authors": ["Luke Thorburn", "Maria Polukarov", "Carmine Ventre"], "title": "Error in the Euclidean Preference Model", "url": "http://arxiv.org/pdf/2208.08160v3", "summary": "Spatial models of preference, in the form of vector embeddings, are learned by many deep learning and multiagent systems, including recommender systems. Often these models are assumed to approximate a Euclidean structure, where an individual prefers alternatives positioned closer to their \"ideal point\", as measured by the Euclidean metric. However, Bogomolnaia and Laslier (2007) showed that there exist ordinal preference profiles that cannot be represented with this structure if the Euclidean space has two fewer dimensions than there are individuals or alternatives. We extend this result, showing that there are situations in which almost all preference profiles cannot be represented with the Euclidean model, and derive a theoretical lower bound on the expected error when using the Euclidean model to approximate non-Euclidean preference profiles. Our results have implications for the interpretation and use of vector embeddings, because in some cases close approximation of arbitrary, true ordinal relationships can be expected only if the dimensionality of the embeddings is a substantial fraction of the number of entities represented.", "published": "2022-08-17T09:01:17Z", "version": 3}, {"aid": "2208.08161", "authors": ["Dongyang Kuang", "Craig Michoski"], "title": "KAM -- a Kernel Attention Module for Emotion Classification with EEG Data", "url": "http://arxiv.org/pdf/2208.08161v2", "summary": "In this work, a kernel attention module is presented for the task of EEG-based emotion classification with neural networks. The proposed module utilizes a self-attention mechanism by performing a kernel trick, demanding significantly fewer trainable parameters and computations than standard attention modules. The design also provides a scalar for quantitatively examining the amount of attention assigned during deep feature refinement, hence help better interpret a trained model. Using EEGNet as the backbone model, extensive experiments are conducted on the SEED dataset to assess the module's performance on within-subject classification tasks compared to other SOTA attention modules. Requiring only one extra parameter, the inserted module is shown to boost the base model's mean prediction accuracy up to more than 1\\% across 15 subjects. A key component of the method is the interpretability of solutions, which is addressed using several different techniques, and is included throughout as part of the dependency analysis.", "published": "2022-08-17T09:02:09Z", "version": 2}, {"aid": "2208.08661", "authors": ["Yi-Fan Zhang", "Jindong Wang", "Jian Liang", "Zhang Zhang", "Baosheng Yu", "Liang Wang", "Dacheng Tao", "Xing Xie"], "title": "Domain-Specific Risk Minimization for Out-of-Distribution Generalization", "url": "http://arxiv.org/pdf/2208.08661v4", "summary": "Recent domain generalization (DG) approaches typically use the hypothesis learned on source domains for inference on the unseen target domain. However, such a hypothesis can be arbitrarily far from the optimal one for the target domain, induced by a gap termed ``adaptivity gap''. Without exploiting the domain information from the unseen test samples, adaptivity gap estimation and minimization are intractable, which hinders us to robustify a model to any unknown distribution. In this paper, we first establish a generalization bound that explicitly considers the adaptivity gap. Our bound motivates two strategies to reduce the gap: the first one is ensembling multiple classifiers to enrich the hypothesis space, then we propose effective gap estimation methods for guiding the selection of a better hypothesis for the target. The other method is minimizing the gap directly by adapting model parameters using online target samples. We thus propose \\textbf{Domain-specific Risk Minimization (DRM)}. During training, DRM models the distributions of different source domains separately; for inference, DRM performs online model steering using the source hypothesis for each arriving target sample. Extensive experiments demonstrate the effectiveness of the proposed DRM for domain generalization with the following advantages: 1) it significantly outperforms competitive baselines on different distributional shift settings; 2) it achieves either comparable or superior accuracies on all source domains compared to vanilla empirical risk minimization; 3) it remains simple and efficient during training, and 4) it is complementary to invariant learning approaches.", "published": "2022-08-18T06:42:49Z", "version": 4}, {"aid": "2208.08713", "authors": ["Samuel T. Wauthier", "Bram Vanhecke", "Tim Verbelen", "Bart Dhoedt"], "title": "Learning Generative Models for Active Inference using Tensor Networks", "url": "http://arxiv.org/pdf/2208.08713v2", "summary": "Active inference provides a general framework for behavior and learning in autonomous agents. It states that an agent will attempt to minimize its variational free energy, defined in terms of beliefs over observations, internal states and policies. Traditionally, every aspect of a discrete active inference model must be specified by hand, i.e. by manually defining the hidden state space structure, as well as the required distributions such as likelihood and transition probabilities. Recently, efforts have been made to learn state space representations automatically from observations using deep neural networks. In this paper, we present a novel approach of learning state spaces using quantum physics-inspired tensor networks. The ability of tensor networks to represent the probabilistic nature of quantum states as well as to reduce large state spaces makes tensor networks a natural candidate for active inference. We show how tensor networks can be used as a generative model for sequential data. Furthermore, we show how one can obtain beliefs from such a generative model and how an active inference agent can use these to compute the expected free energy. Finally, we demonstrate our method on the classic T-maze environment.", "published": "2022-08-18T08:55:06Z", "version": 2}, {"aid": "2208.08932", "authors": ["Janis Postels", "Martin Danelljan", "Luc Van Gool", "Federico Tombari"], "title": "ManiFlow: Implicitly Representing Manifolds with Normalizing Flows", "url": "http://arxiv.org/pdf/2208.08932v1", "summary": "Normalizing Flows (NFs) are flexible explicit generative models that have been shown to accurately model complex real-world data distributions. However, their invertibility constraint imposes limitations on data distributions that reside on lower dimensional manifolds embedded in higher dimensional space. Practically, this shortcoming is often bypassed by adding noise to the data which impacts the quality of the generated samples. In contrast to prior work, we approach this problem by generating samples from the original data distribution given full knowledge about the perturbed distribution and the noise model. To this end, we establish that NFs trained on perturbed data implicitly represent the manifold in regions of maximum likelihood. Then, we propose an optimization objective that recovers the most likely point on the manifold given a sample from the perturbed distribution. Finally, we focus on 3D point clouds for which we utilize the explicit nature of NFs, i.e. surface normals extracted from the gradient of the log-likelihood and the log-likelihood itself, to apply Poisson surface reconstruction to refine generated point sets.", "published": "2022-08-18T16:07:59Z", "version": 1}, {"aid": "2208.09058", "authors": ["Mahault Albarracin", "Riddhi J. Pitliya", "Maxwell J. D. Ramstead", "Jeffrey Yoshimi"], "title": "Mapping Husserlian phenomenology onto active inference", "url": "http://arxiv.org/pdf/2208.09058v3", "summary": "Phenomenology is the rigorous descriptive study of conscious experience. Recent attempts to formalize Husserlian phenomenology provide us with a mathematical model of perception as a function of prior knowledge and expectation. In this paper, we re-examine elements of Husserlian phenomenology through the lens of active inference. In doing so, we aim to advance the project of computational phenomenology, as recently outlined by proponents of active inference. We propose that key aspects of Husserl's descriptions of consciousness can be mapped onto aspects of the generative models associated with the active inference approach. We first briefly review active inference. We then discuss Husserl's phenomenology, with a focus on time consciousness. Finally, we present our mapping from Husserlian phenomenology to active inference.", "published": "2022-08-18T20:55:42Z", "version": 3}, {"aid": "2208.09203", "authors": ["Riccardo Renzulli", "Marco Grangetto"], "title": "Towards Efficient Capsule Networks", "url": "http://arxiv.org/pdf/2208.09203v1", "summary": "From the moment Neural Networks dominated the scene for image processing, the computational complexity needed to solve the targeted tasks skyrocketed: against such an unsustainable trend, many strategies have been developed, ambitiously targeting performance's preservation. Promoting sparse topologies, for example, allows the deployment of deep neural networks models on embedded, resource-constrained devices. Recently, Capsule Networks were introduced to enhance explainability of a model, where each capsule is an explicit representation of an object or its parts. These models show promising results on toy datasets, but their low scalability prevents deployment on more complex tasks. In this work, we explore sparsity besides capsule representations to improve their computational efficiency by reducing the number of capsules. We show how pruning with Capsule Network achieves high generalization with less memory requirements, computational effort, and inference and training time.", "published": "2022-08-19T08:03:25Z", "version": 1}, {"aid": "2208.09392", "authors": ["Arpit Bansal", "Eitan Borgnia", "Hong-Min Chu", "Jie S. Li", "Hamid Kazemi", "Furong Huang", "Micah Goldblum", "Jonas Geiping", "Tom Goldstein"], "title": "Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise", "url": "http://arxiv.org/pdf/2208.09392v1", "summary": "Standard diffusion models involve an image transform -- adding Gaussian noise -- and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community's understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference, and paves the way for generalized diffusion models that invert arbitrary processes. Our code is available at https://github.com/arpitbansal297/Cold-Diffusion-Models", "published": "2022-08-19T15:18:39Z", "version": 1}, {"aid": "2208.09801", "authors": ["Jiachen Sun", "Weili Nie", "Zhiding Yu", "Z. Morley Mao", "Chaowei Xiao"], "title": "PointDP: Diffusion-driven Purification against Adversarial Attacks on 3D Point Cloud Recognition", "url": "http://arxiv.org/pdf/2208.09801v1", "summary": "3D Point cloud is becoming a critical data representation in many real-world applications like autonomous driving, robotics, and medical imaging. Although the success of deep learning further accelerates the adoption of 3D point clouds in the physical world, deep learning is notorious for its vulnerability to adversarial attacks. In this work, we first identify that the state-of-the-art empirical defense, adversarial training, has a major limitation in applying to 3D point cloud models due to gradient obfuscation. We further propose PointDP, a purification strategy that leverages diffusion models to defend against 3D adversarial attacks. We extensively evaluate PointDP on six representative 3D point cloud architectures, and leverage 10+ strong and adaptive attacks to demonstrate its lower-bound robustness. Our evaluation shows that PointDP achieves significantly better robustness than state-of-the-art purification methods under strong attacks. Results of certified defenses on randomized smoothing combined with PointDP will be included in the near future.", "published": "2022-08-21T04:49:17Z", "version": 1}, {"aid": "2208.10498", "authors": ["Dalin Zhang", "Kaixuan Chen", "Yan Zhao", "Bin Yang", "Lina Yao", "Christian S. Jensen"], "title": "Design Automation for Fast, Lightweight, and Effective Deep Learning Models: A Survey", "url": "http://arxiv.org/pdf/2208.10498v1", "summary": "Deep learning technologies have demonstrated remarkable effectiveness in a wide range of tasks, and deep learning holds the potential to advance a multitude of applications, including in edge computing, where deep models are deployed on edge devices to enable instant data processing and response. A key challenge is that while the application of deep models often incurs substantial memory and computational costs, edge devices typically offer only very limited storage and computational capabilities that may vary substantially across devices. These characteristics make it difficult to build deep learning solutions that unleash the potential of edge devices while complying with their constraints. A promising approach to addressing this challenge is to automate the design of effective deep learning models that are lightweight, require only a little storage, and incur only low computational overheads. This survey offers comprehensive coverage of studies of design automation techniques for deep learning models targeting edge computing. It offers an overview and comparison of key metrics that are used commonly to quantify the proficiency of models in terms of effectiveness, lightness, and computational costs. The survey then proceeds to cover three categories of the state-of-the-art of deep model design automation techniques: automated neural architecture search, automated model compression, and joint automated design and compression. Finally, the survey covers open issues and directions for future research.", "published": "2022-08-22T12:12:43Z", "version": 1}, {"aid": "2208.10531", "authors": ["Qucheng Peng", "Zhengming Ding", "Lingjuan Lyu", "Lichao Sun", "Chen Chen"], "title": "RAIN: RegulArization on Input and Network for Black-Box Domain Adaptation", "url": "http://arxiv.org/pdf/2208.10531v4", "summary": "Source-Free domain adaptation transits the source-trained model towards target domain without exposing the source data, trying to dispel these concerns about data privacy and security. However, this paradigm is still at risk of data leakage due to adversarial attacks on the source model. Hence, the Black-Box setting only allows to use the outputs of source model, but still suffers from overfitting on the source domain more severely due to source model's unseen weights. In this paper, we propose a novel approach named RAIN (RegulArization on Input and Network) for Black-Box domain adaptation from both input-level and network-level regularization. For the input-level, we design a new data augmentation technique as Phase MixUp, which highlights task-relevant objects in the interpolations, thus enhancing input-level regularization and class consistency for target models. For network-level, we develop a Subnetwork Distillation mechanism to transfer knowledge from the target subnetwork to the full target network via knowledge distillation, which thus alleviates overfitting on the source domain by learning diverse target representations. Extensive experiments show that our method achieves state-of-the-art performance on several cross-domain benchmarks under both single- and multi-source black-box domain adaptation.", "published": "2022-08-22T18:18:47Z", "version": 4}, {"aid": "2208.10668", "authors": ["Anna A. Ivanova", "Martin Schrimpf", "Stefano Anzellotti", "Noga Zaslavsky", "Evelina Fedorenko", "Leyla Isik"], "title": "Beyond linear regression: mapping models in cognitive neuroscience should align with research goals", "url": "http://arxiv.org/pdf/2208.10668v1", "summary": "Many cognitive neuroscience studies use large feature sets to predict and interpret brain activity patterns. Feature sets take many forms, from human stimulus annotations to representations in deep neural networks. Of crucial importance in all these studies is the mapping model, which defines the space of possible relationships between features and neural data. Until recently, most encoding and decoding studies have used linear mapping models. Increasing availability of large datasets and computing resources has recently allowed some researchers to employ more flexible nonlinear mapping models instead; however, the question of whether nonlinear mapping models can yield meaningful scientific insights remains debated. Here, we discuss the choice of a mapping model in the context of three overarching desiderata: predictive accuracy, interpretability, and biological plausibility. We show that, contrary to popular intuition, these desiderata do not map cleanly onto the linear/nonlinear divide; instead, each desideratum can refer to multiple research goals, each of which imposes its own constraints on the mapping model. Moreover, we argue that, instead of categorically treating the mapping models as linear or nonlinear, we should instead aim to estimate the complexity of these models. We show that, in many cases, complexity provides a more accurate reflection of restrictions imposed by various research goals. Finally, we outline several complexity metrics that can be used to effectively evaluate mapping models.", "published": "2022-08-23T01:25:26Z", "version": 1}, {"aid": "2208.11511", "authors": ["Taewook Ko", "Chong-Kwon Kim"], "title": "A Graph Convolution for Signed Directed Graphs", "url": "http://arxiv.org/pdf/2208.11511v3", "summary": "A signed directed graph is a graph with sign and direction information on the edges. Even though signed directed graphs are more informative than unsigned or undirected graphs, they are more complicated to analyze and have received less research attention. This paper investigates a spectral graph convolution model to fully utilize the information embedded in signed directed edges. We propose a novel complex Hermitian adjacency matrix that encodes graph information via complex numbers. Compared to a simple connection-based adjacency matrix, the complex Hermitian can represent edge direction, sign, and connectivity via its phases and magnitudes. Then, we define a magnetic Laplacian of the proposed adjacency matrix and prove that it is positive semi-definite (PSD) for the analyses using spectral graph convolution. We perform extensive experiments on four real-world datasets. Our experiments show that the proposed scheme outperforms several state-of-the-art techniques.", "published": "2022-08-23T01:58:35Z", "version": 3}, {"aid": "2208.10716", "authors": ["Weihao Yan", "Yeqiang Qian", "Chunxiang Wang", "Ming Yang"], "title": "Threshold-adaptive Unsupervised Focal Loss for Domain Adaptation of Semantic Segmentation", "url": "http://arxiv.org/pdf/2208.10716v1", "summary": "Semantic segmentation is an important task for intelligent vehicles to understand the environment. Current deep learning methods require large amounts of labeled data for training. Manual annotation is expensive, while simulators can provide accurate annotations. However, the performance of the semantic segmentation model trained with the data of the simulator will significantly decrease when applied in the actual scene. Unsupervised domain adaptation (UDA) for semantic segmentation has recently gained increasing research attention, aiming to reduce the domain gap and improve the performance on the target domain. In this paper, we propose a novel two-stage entropy-based UDA method for semantic segmentation. In stage one, we design a threshold-adaptative unsupervised focal loss to regularize the prediction in the target domain, which has a mild gradient neutralization mechanism and mitigates the problem that hard samples are barely optimized in entropy-based methods. In stage two, we introduce a data augmentation method named cross-domain image mixing (CIM) to bridge the semantic knowledge from two domains. Our method achieves state-of-the-art 58.4% and 59.6% mIoUs on SYNTHIA-to-Cityscapes and GTA5-to-Cityscapes using DeepLabV2 and competitive performance using the lightweight BiSeNet.", "published": "2022-08-23T03:48:48Z", "version": 1}, {"aid": "2208.10730", "authors": ["Ming-Yang Ho", "Min-Sheng Wu", "Che-Ming Wu"], "title": "Ultra-high-resolution unpaired stain transformation via Kernelized Instance Normalization", "url": "http://arxiv.org/pdf/2208.10730v1", "summary": "While hematoxylin and eosin (H&E) is a standard staining procedure, immunohistochemistry (IHC) staining further serves as a diagnostic and prognostic method. However, acquiring special staining results requires substantial costs.   Hence, we proposed a strategy for ultra-high-resolution unpaired image-to-image translation: Kernelized Instance Normalization (KIN), which preserves local information and successfully achieves seamless stain transformation with constant GPU memory usage. Given a patch, corresponding position, and a kernel, KIN computes local statistics using convolution operation. In addition, KIN can be easily plugged into most currently developed frameworks without re-training.   We demonstrate that KIN achieves state-of-the-art stain transformation by replacing instance normalization (IN) layers with KIN layers in three popular frameworks and testing on two histopathological datasets. Furthermore, we manifest the generalizability of KIN with high-resolution natural images. Finally, human evaluation and several objective metrics are used to compare the performance of different approaches.   Overall, this is the first successful study for the ultra-high-resolution unpaired image-to-image translation with constant space complexity. Code is available at: https://github.com/Kaminyou/URUST", "published": "2022-08-23T04:47:43Z", "version": 1}, {"aid": "2208.10758", "authors": ["Tianwei Chen", "Noa Garcia", "Mayu Otani", "Chenhui Chu", "Yuta Nakashima", "Hajime Nagahara"], "title": "Learning More May Not Be Better: Knowledge Transferability in Vision and Language Tasks", "url": "http://arxiv.org/pdf/2208.10758v1", "summary": "Is more data always better to train vision-and-language models? We study knowledge transferability in multi-modal tasks. The current tendency in machine learning is to assume that by joining multiple datasets from different tasks their overall performance will improve. However, we show that not all the knowledge transfers well or has a positive impact on related tasks, even when they share a common goal. We conduct an exhaustive analysis based on hundreds of cross-experiments on 12 vision-and-language tasks categorized in 4 groups. Whereas tasks in the same group are prone to improve each other, results show that this is not always the case. Other factors such as dataset size or pre-training stage have also a great impact on how well the knowledge is transferred.", "published": "2022-08-23T06:39:18Z", "version": 1}, {"aid": "2208.11308", "authors": ["Evgenii Indenbom", "Nicolae-C\u0103t\u0103lin Ristea", "Ando Saabas", "Tanel P\u00e4rnamaa", "Jegor Gu\u017evin"], "title": "Deep model with built-in cross-attention alignment for acoustic echo cancellation", "url": "http://arxiv.org/pdf/2208.11308v2", "summary": "With recent research advances, deep learning models have become an attractive choice for acoustic echo cancellation (AEC) in real-time teleconferencing applications. Since acoustic echo is one of the major sources of poor audio quality, a wide variety of deep models have been proposed. However, an important but often omitted requirement for good echo cancellation quality is the synchronization of the microphone and far end signals. Typically implemented using classical algorithms based on cross-correlation, the alignment module is a separate functional block with known design limitations. In our work we propose a deep learning architecture with built-in self-attention based alignment, which is able to handle unaligned inputs, improving echo cancellation performance while simplifying the communication pipeline. Moreover, we show that our approach achieves significant improvements for difficult delay estimation cases on real recordings from AEC Challenge data set.", "published": "2022-08-24T05:29:47Z", "version": 2}, {"aid": "2208.12055", "authors": ["Haozhe Liu", "Bing Li", "Haoqian Wu", "Hanbang Liang", "Yawen Huang", "Yuexiang Li", "Bernard Ghanem", "Yefeng Zheng"], "title": "Combating Mode Collapse in GANs via Manifold Entropy Estimation", "url": "http://arxiv.org/pdf/2208.12055v6", "summary": "Generative Adversarial Networks (GANs) have shown compelling results in various tasks and applications in recent years. However, mode collapse remains a critical problem in GANs. In this paper, we propose a novel training pipeline to address the mode collapse issue of GANs. Different from existing methods, we propose to generalize the discriminator as feature embedding and maximize the entropy of distributions in the embedding space learned by the discriminator. Specifically, two regularization terms, i.e., Deep Local Linear Embedding (DLLE) and Deep Isometric feature Mapping (DIsoMap), are designed to encourage the discriminator to learn the structural information embedded in the data, such that the embedding space learned by the discriminator can be well-formed. Based on the well-learned embedding space supported by the discriminator, a non-parametric entropy estimator is designed to efficiently maximize the entropy of embedding vectors, playing as an approximation of maximizing the entropy of the generated distribution. By improving the discriminator and maximizing the distance of the most similar samples in the embedding space, our pipeline effectively reduces the mode collapse without sacrificing the quality of generated samples. Extensive experimental results show the effectiveness of our method, which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs. 12.43 in FID) and surpasses the recent state-of-the-art energy-based model on the ANIME-FACE dataset (2.80 vs. 2.26 in Inception score). The code is available at https://github.com/HaozheLiu-ST/MEE", "published": "2022-08-25T12:33:31Z", "version": 6}, {"aid": "2208.13040", "authors": ["Ziheng Wu", "Xinyi Zou", "Wenmeng Zhou", "Jun Huang"], "title": "YOLOX-PAI: An Improved YOLOX, Stronger and Faster than YOLOv6", "url": "http://arxiv.org/pdf/2208.13040v3", "summary": "We develop an all-in-one computer vision toolbox named EasyCV to facilitate the use of various SOTA computer vision methods. Recently, we add YOLOX-PAI, an improved version of YOLOX, into EasyCV. We conduct ablation studies to investigate the influence of some detection methods on YOLOX. We also provide an easy use for PAI-Blade which is used to accelerate the inference process based on BladeDISC and TensorRT. Finally, we receive 42.8 mAP on COCO dateset within 1.0 ms on a single NVIDIA V100 GPU, which is a bit faster than YOLOv6. A simple but efficient predictor api is also designed in EasyCV to conduct end2end object detection. Codes and models are now available at: https://github.com/alibaba/EasyCV.", "published": "2022-08-27T15:37:26Z", "version": 3}, {"aid": "2208.13056", "authors": ["Zhihao Duan", "Ming Lu", "Zhan Ma", "Fengqing Zhu"], "title": "Lossy Image Compression with Quantized Hierarchical VAEs", "url": "http://arxiv.org/pdf/2208.13056v2", "summary": "Recent research has shown a strong theoretical connection between variational autoencoders (VAEs) and the rate-distortion theory. Motivated by this, we consider the problem of lossy image compression from the perspective of generative modeling. Starting with ResNet VAEs, which are originally designed for data (image) distribution modeling, we redesign their latent variable model using a quantization-aware posterior and prior, enabling easy quantization and entropy coding at test time. Along with improved neural network architecture, we present a powerful and efficient model that outperforms previous methods on natural image lossy compression. Our model compresses images in a coarse-to-fine fashion and supports parallel encoding and decoding, leading to fast execution on GPUs. Code is available at https://github.com/duanzhiihao/lossy-vae.", "published": "2022-08-27T17:15:38Z", "version": 2}, {"aid": "2208.13975", "authors": ["Shlok Mohta", "Hisahiro Suganuma", "Yoshiki Tanaka"], "title": "MRL: Learning to Mix with Attention and Convolutions", "url": "http://arxiv.org/pdf/2208.13975v1", "summary": "In this paper, we present a new neural architectural block for the vision domain, named Mixing Regionally and Locally (MRL), developed with the aim of effectively and efficiently mixing the provided input features. We bifurcate the input feature mixing task as mixing at a regional and local scale. To achieve an efficient mix, we exploit the domain-wide receptive field provided by self-attention for regional-scale mixing and convolutional kernels restricted to local scale for local-scale mixing. More specifically, our proposed method mixes regional features associated with local features within a defined region, followed by a local-scale features mix augmented by regional features. Experiments show that this hybridization of self-attention and convolution brings improved capacity, generalization (right inductive bias), and efficiency. Under similar network settings, MRL outperforms or is at par with its counterparts in classification, object detection, and segmentation tasks. We also show that our MRL-based network architecture achieves state-of-the-art performance for H&E histology datasets. We achieved DICE of 0.843, 0.855, and 0.892 for Kumar, CoNSep, and CPM-17 datasets, respectively, while highlighting the versatility offered by the MRL framework by incorporating layers like group convolutions to improve dataset-specific generalization.", "published": "2022-08-30T03:42:29Z", "version": 1}, {"aid": "2208.14039", "authors": ["Woon-Ha Yeo", "Wang-Taek Oh", "Kyung-Su Kang", "Young-Il Kim", "Han-Cheol Ryu"], "title": "CAIR: Fast and Lightweight Multi-Scale Color Attention Network for Instagram Filter Removal", "url": "http://arxiv.org/pdf/2208.14039v1", "summary": "Image restoration is an important and challenging task in computer vision. Reverting a filtered image to its original image is helpful in various computer vision tasks. We employ a nonlinear activation function free network (NAFNet) for a fast and lightweight model and add a color attention module that extracts useful color information for better accuracy. We propose an accurate, fast, lightweight network with multi-scale and color attention for Instagram filter removal (CAIR). Experiment results show that the proposed CAIR outperforms existing Instagram filter removal networks in fast and lightweight ways, about 11$\\times$ faster and 2.4$\\times$ lighter while exceeding 3.69 dB PSNR on IFFI dataset. CAIR can successfully remove the Instagram filter with high quality and restore color information in qualitative results. The source code and pretrained weights are available at \\url{https://github.com/HnV-Lab/CAIR}.", "published": "2022-08-30T07:42:45Z", "version": 1}, {"aid": "2208.14133", "authors": ["Yong Zhong", "Hongtao Liu", "Xiaodong Liu", "Fan Bao", "Weiran Shen", "Chongxuan Li"], "title": "Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models", "url": "http://arxiv.org/pdf/2208.14133v3", "summary": "Deep generative models (DGMs) are data-eager because learning a complex model on limited data suffers from a large variance and easily overfits. Inspired by the classical perspective of the bias-variance tradeoff, we propose regularized deep generative model (Reg-DGM), which leverages a nontransferable pre-trained model to reduce the variance of generative modeling with limited data. Formally, Reg-DGM optimizes a weighted sum of a certain divergence and the expectation of an energy function, where the divergence is between the data and the model distributions, and the energy function is defined by the pre-trained model w.r.t. the model distribution. We analyze a simple yet representative Gaussian-fitting case to demonstrate how the weighting hyperparameter trades off the bias and the variance. Theoretically, we characterize the existence and the uniqueness of the global minimum of Reg-DGM in a non-parametric setting and prove its convergence with neural networks trained by gradient-based methods. Empirically, with various pre-trained feature extractors and a data-dependent energy function, Reg-DGM consistently improves the generation performance of strong DGMs with limited data and achieves competitive results to the state-of-the-art methods. Our implementation is available at https://github.com/ML-GSAI/Reg-ADA-APA.", "published": "2022-08-30T10:28:50Z", "version": 3}, {"aid": "2208.14360", "authors": ["Mostafa Mehdipour Ghazi", "Mads Nielsen"], "title": "FAST-AID Brain: Fast and Accurate Segmentation Tool using Artificial Intelligence Developed for Brain", "url": "http://arxiv.org/pdf/2208.14360v1", "summary": "Medical images used in clinical practice are heterogeneous and not the same quality as scans studied in academic research. Preprocessing breaks down in extreme cases when anatomy, artifacts, or imaging parameters are unusual or protocols are different. Methods robust to these variations are most needed. A novel deep learning method is proposed for fast and accurate segmentation of the human brain into 132 regions. The proposed model uses an efficient U-Net-like network and benefits from the intersection points of different views and hierarchical relations for the fusion of the orthogonal 2D planes and brain labels during the end-to-end training. Weakly supervised learning is deployed to take the advantage of partially labeled data for the whole brain segmentation and estimation of the intracranial volume (ICV). Moreover, data augmentation is used to expand the magnetic resonance imaging (MRI) data by generating realistic brain scans with high variability for robust training of the model while preserving data privacy. The proposed method can be applied to brain MRI data including skull or any other artifacts without preprocessing the images or a drop in performance. Several experiments using different atlases are conducted to evaluate the segmentation performance of the trained model compared to the state-of-the-art, and the results show higher segmentation accuracy and robustness of the proposed model compared to the existing methods across different intra- and inter-domain datasets.", "published": "2022-08-30T16:06:07Z", "version": 1}, {"aid": "2208.14699", "authors": ["Xingchao Liu", "Lemeng Wu", "Mao Ye", "Qiang Liu"], "title": "Let us Build Bridges: Understanding and Extending Diffusion Generative Models", "url": "http://arxiv.org/pdf/2208.14699v1", "summary": "Diffusion-based generative models have achieved promising results recently, but raise an array of open questions in terms of conceptual understanding, theoretical analysis, algorithm improvement and extensions to discrete, structured, non-Euclidean domains. This work tries to re-exam the overall framework, in order to gain better theoretical understandings and develop algorithmic extensions for data from arbitrary domains. By viewing diffusion models as latent variable models with unobserved diffusion trajectories and applying maximum likelihood estimation (MLE) with latent trajectories imputed from an auxiliary distribution, we show that both the model construction and the imputation of latent trajectories amount to constructing diffusion bridge processes that achieve deterministic values and constraints at end point, for which we provide a systematic study and a suit of tools. Leveraging our framework, we present 1) a first theoretical error analysis for learning diffusion generation models, and 2) a simple and unified approach to learning on data from different discrete and constrained domains. Experiments show that our methods perform superbly on generating images, semantic segments and 3D point clouds.", "published": "2022-08-31T08:58:10Z", "version": 1}, {"aid": "2208.14706", "authors": ["Zhaowen Li", "Xu Zhao", "Chaoyang Zhao", "Ming Tang", "Jinqiao Wang"], "title": "Transfering Low-Frequency Features for Domain Adaptation", "url": "http://arxiv.org/pdf/2208.14706v1", "summary": "Previous unsupervised domain adaptation methods did not handle the cross-domain problem from the perspective of frequency for computer vision. The images or feature maps of different domains can be decomposed into the low-frequency component and high-frequency component. This paper proposes the assumption that low-frequency information is more domain-invariant while the high-frequency information contains domain-related information. Hence, we introduce an approach, named low-frequency module (LFM), to extract domain-invariant feature representations. The LFM is constructed with the digital Gaussian low-pass filter. Our method is easy to implement and introduces no extra hyperparameter. We design two effective ways to utilize the LFM for domain adaptation, and our method is complementary to other existing methods and formulated as a plug-and-play unit that can be combined with these methods. Experimental results demonstrate that our LFM outperforms state-of-the-art methods for various computer vision tasks, including image classification and object detection.", "published": "2022-08-31T09:13:25Z", "version": 1}, {"aid": "2208.14784", "authors": ["Junqi Tang", "Guixian Xu", "Subhadip Mukherjee", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Practical Operator Sketching Framework for Accelerating Iterative Data-Driven Solutions in Inverse Problems", "url": "http://arxiv.org/pdf/2208.14784v2", "summary": "We propose a new operator-sketching paradigm for designing efficient iterative data-driven reconstruction (IDR) schemes, e.g. Plug-and-Play algorithms and deep unrolling networks. These IDR schemes are currently the state-of-the-art solutions for imaging inverse problems. However, for high-dimensional imaging tasks, especially X-ray CT and MRI imaging, these IDR schemes typically become inefficient both in terms of computation, due to the need of computing multiple times the high-dimensional forward and adjoint operators. In this work, we explore and propose a universal dimensionality reduction framework for accelerating IDR schemes in solving imaging inverse problems, based on leveraging the sketching techniques from stochastic optimization. Using this framework, we derive a number of accelerated IDR schemes, such as the plug-and-play multi-stage sketched gradient (PnP-MS2G) and sketching-based primal-dual (LSPD and Sk-LSPD) deep unrolling networks. Meanwhile, for fully accelerating PnP schemes when the denoisers are computationally expensive, we provide novel stochastic lazy denoising schemes (Lazy-PnP and Lazy-PnP-EQ), leveraging the ProxSkip scheme in optimization and equivariant image denoisers, which can massively accelerate the PnP algorithms with improved practicality. We provide theoretical analysis for recovery guarantees of instances of the proposed framework. Our numerical experiments on natural image processing and tomographic image reconstruction demonstrate the remarkable effectiveness of our sketched IDR schemes.", "published": "2022-08-31T11:45:21Z", "version": 2}, {"aid": "2209.00232", "authors": ["Pourya Shamsolmoali", "Masoumeh Zareapoor", "Swagatam Das", "Eric Granger", "Salvador Garcia"], "title": "Hybrid Gromov-Wasserstein Embedding for Capsule Learning", "url": "http://arxiv.org/pdf/2209.00232v2", "summary": "Capsule networks (CapsNets) aim to parse images into a hierarchy of objects, parts, and their relations using a two-step process involving part-whole transformation and hierarchical component routing. However, this hierarchical relationship modeling is computationally expensive, which has limited the wider use of CapsNet despite its potential advantages. The current state of CapsNet models primarily focuses on comparing their performance with capsule baselines, falling short of achieving the same level of proficiency as deep CNN variants in intricate tasks. To address this limitation, we present an efficient approach for learning capsules that surpasses canonical baseline models and even demonstrates superior performance compared to high-performing convolution models. Our contribution can be outlined in two aspects: firstly, we introduce a group of subcapsules onto which an input vector is projected. Subsequently, we present the Hybrid Gromov-Wasserstein framework, which initially quantifies the dissimilarity between the input and the components modeled by the subcapsules, followed by determining their alignment degree through optimal transport. This innovative mechanism capitalizes on new insights into defining alignment between the input and subcapsules, based on the similarity of their respective component distributions. This approach enhances CapsNets' capacity to learn from intricate, high-dimensional data while retaining their interpretability and hierarchical structure. Our proposed model offers two distinct advantages: (i) its lightweight nature facilitates the application of capsules to more intricate vision tasks, including object detection; (ii) it outperforms baseline approaches in these demanding tasks.", "published": "2022-09-01T05:26:32Z", "version": 2}, {"aid": "2209.00796", "authors": ["Ling Yang", "Zhilong Zhang", "Yang Song", "Shenda Hong", "Runsheng Xu", "Yue Zhao", "Wentao Zhang", "Bin Cui", "Ming-Hsuan Yang"], "title": "Diffusion Models: A Comprehensive Survey of Methods and Applications", "url": "http://arxiv.org/pdf/2209.00796v14", "summary": "Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language generation, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.", "published": "2022-09-02T02:59:10Z", "version": 14}, {"aid": "2209.01398", "authors": ["Zitai Wang", "Qianqian Xu", "Zhiyong Yang", "Yuan He", "Xiaochun Cao", "Qingming Huang"], "title": "Optimizing Partial Area Under the Top-k Curve: Theory and Practice", "url": "http://arxiv.org/pdf/2209.01398v1", "summary": "Top-k error has become a popular metric for large-scale classification benchmarks due to the inevitable semantic ambiguity among classes. Existing literature on top-k optimization generally focuses on the optimization method of the top-k objective, while ignoring the limitations of the metric itself. In this paper, we point out that the top-k objective lacks enough discrimination such that the induced predictions may give a totally irrelevant label a top rank. To fix this issue, we develop a novel metric named partial Area Under the top-k Curve (AUTKC). Theoretical analysis shows that AUTKC has a better discrimination ability, and its Bayes optimal score function could give a correct top-K ranking with respect to the conditional probability. This shows that AUTKC does not allow irrelevant labels to appear in the top list. Furthermore, we present an empirical surrogate risk minimization framework to optimize the proposed metric. Theoretically, we present (1) a sufficient condition for Fisher consistency of the Bayes optimal score function; (2) a generalization upper bound which is insensitive to the number of classes under a simple hyperparameter setting. Finally, the experimental results on four benchmark datasets validate the effectiveness of our proposed framework.", "published": "2022-09-03T11:09:13Z", "version": 1}, {"aid": "2209.02567", "authors": ["Alex B. Kiefer", "Beren Millidge", "Alexander Tschantz", "Christopher L. Buckley"], "title": "Capsule Networks as Generative Models", "url": "http://arxiv.org/pdf/2209.02567v2", "summary": "Capsule networks are a neural network architecture specialized for visual scene recognition. Features and pose information are extracted from a scene and then dynamically routed through a hierarchy of vector-valued nodes called 'capsules' to create an implicit scene graph, with the ultimate aim of learning vision directly as inverse graphics. Despite these intuitions, however, capsule networks are not formulated as explicit probabilistic generative models; moreover, the routing algorithms typically used are ad-hoc and primarily motivated by algorithmic intuition. In this paper, we derive an alternative capsule routing algorithm utilizing iterative inference under sparsity constraints. We then introduce an explicit probabilistic generative model for capsule networks based on the self-attention operation in transformer networks and show how it is related to a variant of predictive coding networks using Von-Mises-Fisher (VMF) circular Gaussian distributions.", "published": "2022-09-06T15:21:28Z", "version": 2}, {"aid": "2209.03355", "authors": ["Simone Angarano", "Francesco Salvetti", "Mauro Martini", "Marcello Chiaberge"], "title": "Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation", "url": "http://arxiv.org/pdf/2209.03355v2", "summary": "Single-Image Super-Resolution can support robotic tasks in environments where a reliable visual stream is required to monitor the mission, handle teleoperation or study relevant visual details. In this work, we propose an efficient Generative Adversarial Network model for real-time Super-Resolution, called EdgeSRGAN (code available at https://github.com/PIC4SeR/EdgeSRGAN). We adopt a tailored architecture of the original SRGAN and model quantization to boost the execution on CPU and Edge TPU devices, achieving up to 200 fps inference. We further optimize our model by distilling its knowledge to a smaller version of the network and obtain remarkable improvements compared to the standard training approach. Our experiments show that our fast and lightweight model preserves considerably satisfying image quality compared to heavier state-of-the-art models. Finally, we conduct experiments on image transmission with bandwidth degradation to highlight the advantages of the proposed system for mobile robotic applications.", "published": "2022-09-07T10:58:41Z", "version": 2}, {"aid": "2209.03456", "authors": ["Mohammad Saeed Ebrahimi Saadabadi", "Sahar Rahimi Malakshan", "Sobhan Soleymani", "Moktari Mostofa", "Nasser M. Nasrabadi"], "title": "Information Maximization for Extreme Pose Face Recognition", "url": "http://arxiv.org/pdf/2209.03456v1", "summary": "In this paper, we seek to draw connections between the frontal and profile face images in an abstract embedding space. We exploit this connection using a coupled-encoder network to project frontal/profile face images into a common latent embedding space. The proposed model forces the similarity of representations in the embedding space by maximizing the mutual information between two views of the face. The proposed coupled-encoder benefits from three contributions for matching faces with extreme pose disparities. First, we leverage our pose-aware contrastive learning to maximize the mutual information between frontal and profile representations of identities. Second, a memory buffer, which consists of latent representations accumulated over past iterations, is integrated into the model so it can refer to relatively much more instances than the mini-batch size. Third, a novel pose-aware adversarial domain adaptation method forces the model to learn an asymmetric mapping from profile to frontal representation. In our framework, the coupled-encoder learns to enlarge the margin between the distribution of genuine and imposter faces, which results in high mutual information between different views of the same identity. The effectiveness of the proposed model is investigated through extensive experiments, evaluations, and ablation studies on four benchmark datasets, and comparison with the compelling state-of-the-art algorithms.", "published": "2022-09-07T20:30:06Z", "version": 1}, {"aid": "2209.03704", "authors": ["Vijay Srinivas Tida", "Sai Venkatesh Chilukoti", "Xiali Hei", "Sonya Hsu"], "title": "Kernel-Segregated Transpose Convolution Operation", "url": "http://arxiv.org/pdf/2209.03704v3", "summary": "Transpose convolution has shown prominence in many deep learning applications. However, transpose convolution layers are computationally intensive due to the increased feature map size due to adding zeros after each element in each row and column. Thus, convolution operation on the expanded input feature map leads to poor utilization of hardware resources. The main reason for unnecessary multiplication operations is zeros at predefined positions in the input feature map. We propose an algorithmic-level optimization technique for the effective transpose convolution implementation to solve these problems. Based on kernel activations, we segregated the original kernel into four sub-kernels. This scheme could reduce memory requirements and unnecessary multiplications. Our proposed method was $3.09 (3.02) \\times$ faster computation using the Titan X GPU (Intel Dual Core CPU) with a flower dataset from the Kaggle website. Furthermore, the proposed optimization method can be generalized to existing devices without additional hardware requirements. A simple deep learning model containing one transpose convolution layer was used to evaluate the optimization method. It showed $2.2 \\times$ faster training using the MNIST dataset with an Intel Dual-core CPU than the conventional implementation.", "published": "2022-09-08T10:42:49Z", "version": 3}, {"aid": "2209.03793", "authors": ["Bowen Li", "Thomas Lukasiewicz"], "title": "Lightweight Long-Range Generative Adversarial Networks", "url": "http://arxiv.org/pdf/2209.03793v1", "summary": "In this paper, we introduce novel lightweight generative adversarial networks, which can effectively capture long-range dependencies in the image generation process, and produce high-quality results with a much simpler architecture. To achieve this, we first introduce a long-range module, allowing the network to dynamically adjust the number of focused sampling pixels and to also augment sampling locations. Thus, it can break the limitation of the fixed geometric structure of the convolution operator, and capture long-range dependencies in both spatial and channel-wise directions. Also, the proposed long-range module can highlight negative relations between pixels, working as a regularization to stabilize training. Furthermore, we propose a new generation strategy through which we introduce metadata into the image generation process to provide basic information about target images, which can stabilize and speed up the training process. Our novel long-range module only introduces few additional parameters and is easily inserted into existing models to capture long-range dependencies. Extensive experiments demonstrate the competitive performance of our method with a lightweight architecture.", "published": "2022-09-08T13:05:01Z", "version": 1}, {"aid": "2209.04934", "authors": ["Johannes Brandstetter", "Rianne van den Berg", "Max Welling", "Jayesh K. Gupta"], "title": "Clifford Neural Layers for PDE Modeling", "url": "http://arxiv.org/pdf/2209.04934v2", "summary": "Partial differential equations (PDEs) see widespread use in sciences and engineering to describe simulation of physical processes as scalar and vector fields interacting and coevolving over time. Due to the computationally expensive nature of their standard solution methods, neural PDE surrogates have become an active research topic to accelerate these simulations. However, current methods do not explicitly take into account the relationship between different fields and their internal components, which are often correlated. Viewing the time evolution of such correlated fields through the lens of multivector fields allows us to overcome these limitations. Multivector fields consist of scalar, vector, as well as higher-order components, such as bivectors and trivectors. Their algebraic properties, such as multiplication, addition and other arithmetic operations can be described by Clifford algebras. To our knowledge, this paper presents the first usage of such multivector representations together with Clifford convolutions and Clifford Fourier transforms in the context of deep learning. The resulting Clifford neural layers are universally applicable and will find direct use in the areas of fluid dynamics, weather forecasting, and the modeling of physical systems in general. We empirically evaluate the benefit of Clifford neural layers by replacing convolution and Fourier operations in common neural PDE surrogates by their Clifford counterparts on 2D Navier-Stokes and weather modeling tasks, as well as 3D Maxwell equations. For similar parameter count, Clifford neural layers consistently improve generalization capabilities of the tested neural PDE surrogates. Source code for our PyTorch implementation is available at https://microsoft.github.io/cliffordlayers/.", "published": "2022-09-08T17:35:30Z", "version": 2}, {"aid": "2209.04049", "authors": ["Masataro Asai"], "title": "Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics", "url": "http://arxiv.org/pdf/2209.04049v8", "summary": "The symbolic AI community is increasingly trying to embrace machine learning in neuro-symbolic architectures, yet is still struggling due to cultural barriers. To break the barrier, this rather opinionated personal memo attempts to explain and rectify the conventions in Statistics, Machine Learning, and Deep Learning from the viewpoint of outsiders. It provides a step-by-step protocol for designing a machine learning system that satisfies a minimum theoretical guarantee necessary for being taken seriously by the symbolic AI community, i.e., it discusses \"in what condition we can stop worrying and accept statistical machine learning.\" Unlike most textbooks which are written for students trying to specialize in Stat/ML/DL and willing to accept jargons, this memo is written for experienced symbolic researchers that hear a lot of buzz but are still uncertain and skeptical. Information on Stat/ML/DL is currently too scattered or too noisy to invest in. This memo prioritizes compactness, citations to old papers (many in early 20th century), and concepts that resonate well with symbolic paradigms in order to offer time savings. It prioritizes general mathematical modeling and does not discuss any specific function approximator, such as neural networks (NNs), SVMs, decision trees, etc. Finally, it is open to corrections. Consider this memo as something similar to a blog post taking the form of a paper on Arxiv.", "published": "2022-09-08T22:15:20Z", "version": 8}, {"aid": "2209.05442", "authors": ["Giannis Daras", "Mauricio Delbracio", "Hossein Talebi", "Alexandros G. Dimakis", "Peyman Milanfar"], "title": "Soft Diffusion: Score Matching for General Corruptions", "url": "http://arxiv.org/pdf/2209.05442v2", "summary": "We define a broader family of corruption processes that generalizes previously known diffusion models. To reverse these general diffusions, we propose a new objective called Soft Score Matching that provably learns the score function for any linear corruption process and yields state of the art results for CelebA. Soft Score Matching incorporates the degradation process in the network. Our new loss trains the model to predict a clean image, \\textit{that after corruption}, matches the diffused observation. We show that our objective learns the gradient of the likelihood under suitable regularity conditions for a family of corruption processes. We further develop a principled way to select the corruption levels for general diffusion processes and a novel sampling method that we call Momentum Sampler. We show experimentally that our framework works for general linear corruption processes, such as Gaussian blur and masking. We achieve state-of-the-art FID score $1.85$ on CelebA-64, outperforming all previous linear diffusion models. We also show significant computational benefits compared to vanilla denoising diffusion.", "published": "2022-09-12T17:45:03Z", "version": 2}, {"aid": "2209.05557", "authors": ["Emiel Hoogeboom", "Tim Salimans"], "title": "Blurring Diffusion Models", "url": "http://arxiv.org/pdf/2209.05557v3", "summary": "Recently, Rissanen et al., (2022) have presented a new type of diffusion process for generative modeling based on heat dissipation, or blurring, as an alternative to isotropic Gaussian diffusion. Here, we show that blurring can equivalently be defined through a Gaussian diffusion process with non-isotropic noise. In making this connection, we bridge the gap between inverse heat dissipation and denoising diffusion, and we shed light on the inductive bias that results from this modeling choice. Finally, we propose a generalized class of diffusion models that offers the best of both standard Gaussian denoising diffusion and inverse heat dissipation, which we call Blurring Diffusion Models.", "published": "2022-09-12T19:16:48Z", "version": 3}, {"aid": "2209.05732", "authors": ["Weipeng Huang", "Junjie Tao", "Changbo Deng", "Ming Fan", "Wenqiang Wan", "Qi Xiong", "Guangyuan Piao"], "title": "R\u00e9nyi Divergence Deep Mutual Learning", "url": "http://arxiv.org/pdf/2209.05732v7", "summary": "This paper revisits Deep Mutual Learning (DML), a simple yet effective computing paradigm. We propose using R\\'{e}nyi divergence instead of the KL divergence, which is more flexible and tunable, to improve vanilla DML. This modification is able to consistently improve performance over vanilla DML with limited additional complexity. The convergence properties of the proposed paradigm are analyzed theoretically, and Stochastic Gradient Descent with a constant learning rate is shown to converge with $\\mathcal{O}(1)$-bias in the worst case scenario for nonconvex optimization tasks. That is, learning will reach nearby local optima but continue searching within a bounded scope, which may help mitigate overfitting. Finally, our extensive empirical results demonstrate the advantage of combining DML and R\\'{e}nyi divergence, leading to further improvement in model generalization.", "published": "2022-09-13T04:58:35Z", "version": 7}, {"aid": "2209.05829", "authors": ["Vito Dichio", "Fabrizio De Vico Fallani"], "title": "Statistical models of complex brain networks: a maximum entropy approach", "url": "http://arxiv.org/pdf/2209.05829v4", "summary": "The brain is a highly complex system. Most of such complexity stems from the intermingled connections between its parts, which give rise to rich dynamics and to the emergence of high-level cognitive functions. Disentangling the underlying network structure is crucial to understand the brain functioning under both healthy and pathological conditions. Yet, analyzing brain networks is challenging, in part because their structure represents only one possible realization of a generative stochastic process which is in general unknown. Having a formal way to cope with such intrinsic variability is therefore central for the characterization of brain network properties. Addressing this issue entails the development of appropriate tools mostly adapted from network science and statistics. Here, we focus on a particular class of maximum entropy models for networks, i.e. exponential random graph models (ERGMs), as a parsimonious approach to identify the local connection mechanisms behind observed global network structure. Efforts are reviewed on the quest for basic organizational properties of human brain networks, as well as on the identification of predictive biomarkers of neurological diseases such as stroke. We conclude with a discussion on how emerging results and tools from statistical graph modeling, associated with forthcoming improvements in experimental data acquisition, could lead to a finer probabilistic description of complex systems in network neuroscience.", "published": "2022-09-13T09:08:38Z", "version": 4}, {"aid": "2209.06168", "authors": ["Lewis Belcher", "Johan Gudmundsson", "Michael Green"], "title": "Borch: A Deep Universal Probabilistic Programming Language", "url": "http://arxiv.org/pdf/2209.06168v1", "summary": "Ever since the Multilayered Perceptron was first introduced the connectionist community has struggled with the concept of uncertainty and how this could be represented in these types of models. This past decade has seen a lot of effort in trying to join the principled approach of probabilistic modeling with the scalable nature of deep neural networks. While the theoretical benefits of this consolidation are clear, there are also several important practical aspects of these endeavors; namely to force the models we create to represent, learn, and report uncertainty in every prediction that is made. Many of these efforts have been based on extending existing frameworks with additional structures. We present Borch, a scalable deep universal probabilistic programming language, built on top of PyTorch. The code is available for download and use in our repository https://gitlab.com/desupervised/borch.", "published": "2022-09-13T17:18:01Z", "version": 1}, {"aid": "2209.06383", "authors": ["Lingran Zhao", "Zhen Dong", "Kurt Keutzer"], "title": "Analysis of Quantization on MLP-based Vision Models", "url": "http://arxiv.org/pdf/2209.06383v1", "summary": "Quantization is wildly taken as a model compression technique, which obtains efficient models by converting floating-point weights and activations in the neural network into lower-bit integers. Quantization has been proven to work well on convolutional neural networks and transformer-based models. Despite the decency of these models, recent works have shown that MLP-based models are able to achieve comparable results on various tasks ranging from computer vision, NLP to 3D point cloud, while achieving higher throughput due to the parallelism and network simplicity. However, as we show in the paper, directly applying quantization to MLP-based models will lead to significant accuracy degradation. Based on our analysis, two major issues account for the accuracy gap: 1) the range of activations in MLP-based models can be too large to quantize, and 2) specific components in the MLP-based models are sensitive to quantization. Consequently, we propose to 1) apply LayerNorm to control the quantization range of activations, 2) utilize bounded activation functions, 3) apply percentile quantization on activations, 4) use our improved module named multiple token-mixing MLPs, and 5) apply linear asymmetric quantizer for sensitive operations. Equipped with the abovementioned techniques, our Q-MLP models can achieve 79.68% accuracy on ImageNet with 8-bit uniform quantization (model size 30 MB) and 78.47% with 4-bit quantization (15 MB).", "published": "2022-09-14T02:55:57Z", "version": 1}, {"aid": "2209.06823", "authors": ["Yonglong Jiang", "Liangliang Li", "Yuan Xue", "Hongbing Ma"], "title": "DEANet: Decomposition Enhancement and Adjustment Network for Low-Light Image Enhancement", "url": "http://arxiv.org/pdf/2209.06823v1", "summary": "Images obtained under low-light conditions will seriously affect the quality of the images. Solving the problem of poor low-light image quality can effectively improve the visual quality of images and better improve the usability of computer vision. In addition, it has very important applications in many fields. This paper proposes a DEANet based on Retinex for low-light image enhancement. It combines the frequency information and content information of the image into three sub-networks: decomposition network, enhancement network and adjustment network. These three sub-networks are respectively used for decomposition, denoising, contrast enhancement and detail preservation, adjustment, and image generation. Our model has good robust results for all low-light images. The model is trained on the public data set LOL, and the experimental results show that our method is better than the existing state-of-the-art methods in terms of vision and quality.", "published": "2022-09-14T03:01:55Z", "version": 1}, {"aid": "2209.06405", "authors": ["Xiaomeng Wu", "Takahito Kawanishi", "Kunio Kashino"], "title": "Reflectance-Guided, Contrast-Accumulated Histogram Equalization", "url": "http://arxiv.org/pdf/2209.06405v1", "summary": "Existing image enhancement methods fall short of expectations because with them it is difficult to improve global and local image contrast simultaneously. To address this problem, we propose a histogram equalization-based method that adapts to the data-dependent requirements of brightness enhancement and improves the visibility of details without losing the global contrast. This method incorporates the spatial information provided by image context in density estimation for discriminative histogram equalization. To minimize the adverse effect of non-uniform illumination, we propose defining spatial information on the basis of image reflectance estimated with edge preserving smoothing. Our method works particularly well for determining how the background brightness should be adaptively adjusted and for revealing useful image details hidden in the dark.", "published": "2022-09-14T04:14:30Z", "version": 1}, {"aid": "2209.07659", "authors": ["Fang Chen", "Gourav Datta", "Souvik Kundu", "Peter Beerel"], "title": "Self-Attentive Pooling for Efficient Deep Learning", "url": "http://arxiv.org/pdf/2209.07659v3", "summary": "Efficient custom pooling techniques that can aggressively trim the dimensions of a feature map and thereby reduce inference compute and memory footprint for resource-constrained computer vision applications have recently gained significant traction. However, prior pooling works extract only the local context of the activation maps, limiting their effectiveness. In contrast, we propose a novel non-local self-attentive pooling method that can be used as a drop-in replacement to the standard pooling layers, such as max/average pooling or strided convolution. The proposed self-attention module uses patch embedding, multi-head self-attention, and spatial-channel restoration, followed by sigmoid activation and exponential soft-max. This self-attention mechanism efficiently aggregates dependencies between non-local activation patches during down-sampling. Extensive experiments on standard object classification and detection tasks with various convolutional neural network (CNN) architectures demonstrate the superiority of our proposed mechanism over the state-of-the-art (SOTA) pooling techniques. In particular, we surpass the test accuracy of existing pooling techniques on different variants of MobileNet-V2 on ImageNet by an average of 1.2%. With the aggressive down-sampling of the activation maps in the initial layers (providing up to 22x reduction in memory consumption), our approach achieves 1.43% higher test accuracy compared to SOTA techniques with iso-memory footprints. This enables the deployment of our models in memory-constrained devices, such as micro-controllers (without losing significant accuracy), because the initial activation maps consume a significant amount of on-chip memory for high-resolution images required for complex vision tasks. Our proposed pooling method also leverages the idea of channel pruning to further reduce memory footprints.", "published": "2022-09-16T00:35:14Z", "version": 3}, {"aid": "2209.07738", "authors": ["Zimian Wei", "Hengyue Pan", "Lujun Li", "Menglong Lu", "Xin Niu", "Peijie Dong", "Dongsheng Li"], "title": "DMFormer: Closing the Gap Between CNN and Vision Transformers", "url": "http://arxiv.org/pdf/2209.07738v3", "summary": "Vision transformers have shown excellent performance in computer vision tasks. As the computation cost of their self-attention mechanism is expensive, recent works tried to replace the self-attention mechanism in vision transformers with convolutional operations, which is more efficient with built-in inductive bias. However, these efforts either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a Dynamic Multi-level Attention mechanism (DMA), which captures different patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on DMA, we present an efficient backbone network named DMFormer. DMFormer adopts the overall architecture of vision transformers, while replacing the self-attention mechanism with our proposed DMA. Extensive experimental results on ImageNet-1K and ADE20K datasets demonstrated that DMFormer achieves state-of-the-art performance, which outperforms similar-sized vision transformers(ViTs) and convolutional neural networks (CNNs).", "published": "2022-09-16T06:45:01Z", "version": 3}, {"aid": "2209.07947", "authors": ["Chao Li", "Aojun Zhou", "Anbang Yao"], "title": "Omni-Dimensional Dynamic Convolution", "url": "http://arxiv.org/pdf/2209.07947v1", "summary": "Learning a single static convolutional kernel in each convolutional layer is the common training paradigm of modern Convolutional Neural Networks (CNNs). Instead, recent research in dynamic convolution shows that learning a linear combination of $n$ convolutional kernels weighted with their input-dependent attentions can significantly improve the accuracy of light-weight CNNs, while maintaining efficient inference. However, we observe that existing works endow convolutional kernels with the dynamic property through one dimension (regarding the convolutional kernel number) of the kernel space, but the other three dimensions (regarding the spatial size, the input channel number and the output channel number for each convolutional kernel) are overlooked. Inspired by this, we present Omni-dimensional Dynamic Convolution (ODConv), a more generalized yet elegant dynamic convolution design, to advance this line of research. ODConv leverages a novel multi-dimensional attention mechanism with a parallel strategy to learn complementary attentions for convolutional kernels along all four dimensions of the kernel space at any convolutional layer. As a drop-in replacement of regular convolutions, ODConv can be plugged into many CNN architectures. Extensive experiments on the ImageNet and MS-COCO datasets show that ODConv brings solid accuracy boosts for various prevailing CNN backbones including both light-weight and large ones, e.g., 3.77%~5.71%|1.86%~3.72% absolute top-1 improvements to MobivleNetV2|ResNet family on the ImageNet dataset. Intriguingly, thanks to its improved feature learning ability, ODConv with even one single kernel can compete with or outperform existing dynamic convolution counterparts with multiple kernels, substantially reducing extra parameters. Furthermore, ODConv is also superior to other attention modules for modulating the output features or the convolutional weights.", "published": "2022-09-16T14:05:38Z", "version": 1}, {"aid": "2209.09422", "authors": ["Tongda Xu", "Han Gao", "Chenjian Gao", "Yuanyuan Wang", "Dailan He", "Jinyong Pi", "Jixiang Luo", "Ziyu Zhu", "Mao Ye", "Hongwei Qin", "Yan Wang", "Jingjing Liu", "Ya-Qin Zhang"], "title": "Bit Allocation using Optimization", "url": "http://arxiv.org/pdf/2209.09422v5", "summary": "In this paper, we consider the problem of bit allocation in Neural Video Compression (NVC). First, we reveal a fundamental relationship between bit allocation in NVC and Semi-Amortized Variational Inference (SAVI). Specifically, we show that SAVI with GoP (Group-of-Picture)-level likelihood is equivalent to pixel-level bit allocation with precise rate \\& quality dependency model. Based on this equivalence, we establish a new paradigm of bit allocation using SAVI. Different from previous bit allocation methods, our approach requires no empirical model and is thus optimal. Moreover, as the original SAVI using gradient ascent only applies to single-level latent, we extend the SAVI to multi-level such as NVC by recursively applying back-propagating through gradient ascent. Finally, we propose a tractable approximation for practical implementation. Our method can be applied to scenarios where performance outweights encoding speed, and serves as an empirical bound on the R-D performance of bit allocation. Experimental results show that current state-of-the-art bit allocation algorithms still have a room of $\\approx 0.5$ dB PSNR to improve compared with ours. Code is available at \\url{https://github.com/tongdaxu/Bit-Allocation-Using-Optimization}.", "published": "2022-09-20T02:40:52Z", "version": 5}, {"aid": "2209.10512", "authors": ["Marius Millea"], "title": "Improved Marginal Unbiased Score Expansion (MUSE) via Implicit Differentiation", "url": "http://arxiv.org/pdf/2209.10512v1", "summary": "We apply the technique of implicit differentiation to boost performance, reduce numerical error, and remove required user-tuning in the Marginal Unbiased Score Expansion (MUSE) algorithm for hierarchical Bayesian inference. We demonstrate these improvements on three representative inference problems: 1) an extended Neal's funnel 2) Bayesian neural networks, and 3) probabilistic principal component analysis. On our particular test cases, MUSE with implicit differentiation is faster than Hamiltonian Monte Carlo by factors of 155, 397, and 5, respectively, or factors of 65, 278, and 1 without implicit differentiation, and yields good approximate marginal posteriors. The Julia and Python MUSE packages have been updated to use implicit differentiation, and can solve problems defined by hand or with any of a number of popular probabilistic programming languages and automatic differentiation backends.", "published": "2022-09-21T17:20:20Z", "version": 1}, {"aid": "2209.11178", "authors": ["Yilun Xu", "Ziming Liu", "Max Tegmark", "Tommi Jaakkola"], "title": "Poisson Flow Generative Models", "url": "http://arxiv.org/pdf/2209.11178v4", "summary": "We propose a new \"Poisson flow\" generative model (PFGM) that maps a uniform distribution on a high-dimensional hemisphere into any data distribution. We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation). We prove that if these charges flow upward along electric field lines, their initial distribution in the $z=0$ plane transforms into a distribution on the hemisphere of radius $r$ that becomes uniform in the $r \\to\\infty$ limit. To learn the bijective transformation, we estimate the normalized field in the augmented space. For sampling, we devise a backward ODE that is anchored by the physically meaningful additional dimension: the samples hit the unaugmented data manifold when the $z$ reaches zero. Experimentally, PFGM achieves current state-of-the-art performance among the normalizing flow models on CIFAR-10, with an Inception score of $9.68$ and a FID score of $2.35$. It also performs on par with the state-of-the-art SDE approaches while offering $10\\times $ to $20 \\times$ acceleration on image generation tasks. Additionally, PFGM appears more tolerant of estimation errors on a weaker network architecture and robust to the step size in the Euler method. The code is available at https://github.com/Newbeeer/poisson_flow .", "published": "2022-09-22T17:26:58Z", "version": 4}, {"aid": "2209.12753", "authors": ["Chen-Hao Chao", "Wei-Fang Sun", "Bo-Wun Cheng", "Chun-Yi Lee"], "title": "On Investigating the Conservative Property of Score-Based Generative Models", "url": "http://arxiv.org/pdf/2209.12753v3", "summary": "Existing Score-Based Models (SBMs) can be categorized into constrained SBMs (CSBMs) or unconstrained SBMs (USBMs) according to their parameterization approaches. CSBMs model probability density functions as Boltzmann distributions, and assign their predictions as the negative gradients of some scalar-valued energy functions. On the other hand, USBMs employ flexible architectures capable of directly estimating scores without the need to explicitly model energy functions. In this paper, we demonstrate that the architectural constraints of CSBMs may limit their modeling ability. In addition, we show that USBMs' inability to preserve the property of conservativeness may lead to degraded performance in practice. To address the above issues, we propose Quasi-Conservative Score-Based Models (QCSBMs) for keeping the advantages of both CSBMs and USBMs. Our theoretical derivations demonstrate that the training objective of QCSBMs can be efficiently integrated into the training processes by leveraging the Hutchinson's trace estimator. In addition, our experimental results on the CIFAR-10, CIFAR-100, ImageNet, and SVHN datasets validate the effectiveness of QCSBMs. Finally, we justify the advantage of QCSBMs using an example of a one-layered autoencoder.", "published": "2022-09-26T15:00:18Z", "version": 3}, {"aid": "2209.13131", "authors": ["Brian Moser", "Federico Raue", "Stanislav Frolov", "J\u00f6rn Hees", "Sebastian Palacio", "Andreas Dengel"], "title": "Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances", "url": "http://arxiv.org/pdf/2209.13131v2", "summary": "With the advent of Deep Learning (DL), Super-Resolution (SR) has also become a thriving research area. However, despite promising results, the field still faces challenges that require further research e.g., allowing flexible upsampling, more effective loss functions, and better evaluation metrics. We review the domain of SR in light of recent advances, and examine state-of-the-art models such as diffusion (DDPM) and transformer-based SR models. We present a critical discussion on contemporary strategies used in SR, and identify promising yet unexplored research directions. We complement previous surveys by incorporating the latest developments in the field such as uncertainty-driven losses, wavelet networks, neural architecture search, novel normalization methods, and the latests evaluation techniques. We also include several visualizations for the models and methods throughout each chapter in order to facilitate a global understanding of the trends in the field. This review is ultimately aimed at helping researchers to push the boundaries of DL applied to SR.", "published": "2022-09-27T03:28:34Z", "version": 2}, {"aid": "2209.13774", "authors": ["Chenlin Meng", "Linqi Zhou", "Kristy Choi", "Tri Dao", "Stefano Ermon"], "title": "ButterflyFlow: Building Invertible Layers with Butterfly Matrices", "url": "http://arxiv.org/pdf/2209.13774v1", "summary": "Normalizing flows model complex probability distributions using maps obtained by composing invertible layers. Special linear layers such as masked and 1x1 convolutions play a key role in existing architectures because they increase expressive power while having tractable Jacobians and inverses. We propose a new family of invertible linear layers based on butterfly layers, which are known to theoretically capture complex linear structures including permutations and periodicity, yet can be inverted efficiently. This representational power is a key advantage of our approach, as such structures are common in many real-world datasets. Based on our invertible butterfly layers, we construct a new class of normalizing flow models called ButterflyFlow. Empirically, we demonstrate that ButterflyFlows not only achieve strong density estimation results on natural images such as MNIST, CIFAR-10, and ImageNet 32x32, but also obtain significantly better log-likelihoods on structured datasets such as galaxy images and MIMIC-III patient cohorts -- all while being more efficient in terms of memory and computation than relevant baselines.", "published": "2022-09-28T01:58:18Z", "version": 1}, {"aid": "2209.13929", "authors": ["Man Yao", "Guangshe Zhao", "Hengyu Zhang", "Yifan Hu", "Lei Deng", "Yonghong Tian", "Bo Xu", "Guoqi Li"], "title": "Attention Spiking Neural Networks", "url": "http://arxiv.org/pdf/2209.13929v1", "summary": "Benefiting from the event-driven and sparse spiking characteristics of the brain, spiking neural networks (SNNs) are becoming an energy-efficient alternative to artificial neural networks (ANNs). However, the performance gap between SNNs and ANNs has been a great hindrance to deploying SNNs ubiquitously for a long time. To leverage the full potential of SNNs, we study the effect of attention mechanisms in SNNs. We first present our idea of attention with a plug-and-play kit, termed the Multi-dimensional Attention (MA). Then, a new attention SNN architecture with end-to-end training called \"MA-SNN\" is proposed, which infers attention weights along the temporal, channel, as well as spatial dimensions separately or simultaneously. Based on the existing neuroscience theories, we exploit the attention weights to optimize membrane potentials, which in turn regulate the spiking response in a data-dependent way. At the cost of negligible additional parameters, MA facilitates vanilla SNNs to achieve sparser spiking activity, better performance, and energy efficiency concurrently. Experiments are conducted in event-based DVS128 Gesture/Gait action recognition and ImageNet-1k image classification. On Gesture/Gait, the spike counts are reduced by 84.9%/81.6%, and the task accuracy and energy efficiency are improved by 5.9%/4.7% and 3.4$\\times$/3.2$\\times$. On ImageNet-1K, we achieve top-1 accuracy of 75.92% and 77.08% on single/4-step Res-SNN-104, which are state-of-the-art results in SNNs. To our best knowledge, this is for the first time, that the SNN community achieves comparable or even better performance compared with its ANN counterpart in the large-scale dataset. Our work lights up SNN's potential as a general backbone to support various applications for SNNs, with a great balance between effectiveness and efficiency.", "published": "2022-09-28T09:00:45Z", "version": 1}, {"aid": "2209.14593", "authors": ["Beomsu Kim", "Jong Chul Ye"], "title": "Denoising MCMC for Accelerating Diffusion-Based Generative Models", "url": "http://arxiv.org/pdf/2209.14593v1", "summary": "Diffusion models are powerful generative models that simulate the reverse of diffusion processes using score functions to synthesize data from noise. The sampling process of diffusion models can be interpreted as solving the reverse stochastic differential equation (SDE) or the ordinary differential equation (ODE) of the diffusion process, which often requires up to thousands of discretization steps to generate a single image. This has sparked a great interest in developing efficient integration techniques for reverse-S/ODEs. Here, we propose an orthogonal approach to accelerating score-based sampling: Denoising MCMC (DMCMC). DMCMC first uses MCMC to produce samples in the product space of data and variance (or diffusion time). Then, a reverse-S/ODE integrator is used to denoise the MCMC samples. Since MCMC traverses close to the data manifold, the computation cost of producing a clean sample for DMCMC is much less than that of producing a clean sample from noise. To verify the proposed concept, we show that Denoising Langevin Gibbs (DLG), an instance of DMCMC, successfully accelerates all six reverse-S/ODE integrators considered in this work on the tasks of CIFAR10 and CelebA-HQ-256 image generation. Notably, combined with integrators of Karras et al. (2022) and pre-trained score models of Song et al. (2021b), DLG achieves SOTA results. In the limited number of score function evaluation (NFE) settings on CIFAR10, we have $3.86$ FID with $\\approx 10$ NFE and $2.63$ FID with $\\approx 20$ NFE. On CelebA-HQ-256, we have $6.99$ FID with $\\approx 160$ NFE, which beats the current best record of Kim et al. (2022) among score-based models, $7.16$ FID with $4000$ NFE. Code: https://github.com/1202kbs/DMCMC", "published": "2022-09-29T07:16:10Z", "version": 1}, {"aid": "2209.14687", "authors": ["Hyungjin Chung", "Jeongsol Kim", "Michael T. Mccann", "Marc L. Klasky", "Jong Chul Ye"], "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems", "url": "http://arxiv.org/pdf/2209.14687v4", "summary": "Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring. Code available at https://github.com/DPS2022/diffusion-posterior-sampling", "published": "2022-09-29T11:12:27Z", "version": 4}, {"aid": "2209.14751", "authors": ["Ulises Chialva", "Vicente Gonz\u00e1lez Bosc\u00e1", "Horacio G. Rotstein"], "title": "Low-dimensional models of single neurons: A review", "url": "http://arxiv.org/pdf/2209.14751v3", "summary": "The classical Hodgkin-Huxley (HH) point-neuron model of action potential generation is four-dimensional. It consists of four ordinary differential equations describing the dynamics of the membrane potential and three gating variables associated to a transient sodium and a delayed-rectifier potassium ionic currents. Conductance-based models of HH type are higher-dimensional extensions of the classical HH model. They include a number of supplementary state variables associated with other ionic current types, and are able to describe additional phenomena such as sub-threshold oscillations, mixed-mode oscillations (subthreshold oscillations interspersed with spikes), clustering and bursting. In this manuscript we discuss biophysically plausible and phenomenological reduced models that preserve the biophysical and/or dynamic description of models of HH type and the ability to produce complex phenomena, but the number of effective dimensions (state variables) is lower. We describe several representative models. We also describe systematic and heuristic methods of deriving reduced models from models of HH type.", "published": "2022-09-29T13:07:21Z", "version": 3}, {"aid": "2209.14778", "authors": ["Randall Balestriero", "Richard G. Baraniuk"], "title": "Batch Normalization Explained", "url": "http://arxiv.org/pdf/2209.14778v1", "summary": "A critically important, ubiquitous, and yet poorly understood ingredient in modern deep networks (DNs) is batch normalization (BN), which centers and normalizes the feature maps. To date, only limited progress has been made understanding why BN boosts DN learning and inference performance; work has focused exclusively on showing that BN smooths a DN's loss landscape. In this paper, we study BN theoretically from the perspective of function approximation; we exploit the fact that most of today's state-of-the-art DNs are continuous piecewise affine (CPA) splines that fit a predictor to the training data via affine mappings defined over a partition of the input space (the so-called \"linear regions\"). {\\em We demonstrate that BN is an unsupervised learning technique that -- independent of the DN's weights or gradient-based learning -- adapts the geometry of a DN's spline partition to match the data.} BN provides a \"smart initialization\" that boosts the performance of DN learning, because it adapts even a DN initialized with random weights to align its spline partition with the data. We also show that the variation of BN statistics between mini-batches introduces a dropout-like random perturbation to the partition boundaries and hence the decision boundary for classification problems. This per mini-batch perturbation reduces overfitting and improves generalization by increasing the margin between the training samples and the decision boundary.", "published": "2022-09-29T13:41:27Z", "version": 1}, {"aid": "2209.14855", "authors": ["Yuan Yin", "Matthieu Kirchmeyer", "Jean-Yves Franceschi", "Alain Rakotomamonjy", "Patrick Gallinari"], "title": "Continuous PDE Dynamics Forecasting with Implicit Neural Representations", "url": "http://arxiv.org/pdf/2209.14855v2", "summary": "Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by introducing a new data-driven approach, DINo, that models a PDE's flow with continuous-time dynamics of spatially continuous functions. This is achieved by embedding spatial observations independently of their discretization via Implicit Neural Representations in a small latent space temporally driven by a learned ODE. This separate and flexible treatment of time and space makes DINo the first data-driven model to combine the following advantages. It extrapolates at arbitrary spatial and temporal locations; it can learn from sparse irregular grids or manifolds; at test time, it generalizes to new grids or resolutions. DINo outperforms alternative neural PDE forecasters in a variety of challenging generalization scenarios on representative PDE systems.", "published": "2022-09-29T15:17:50Z", "version": 2}, {"aid": "2209.14988", "authors": ["Ben Poole", "Ajay Jain", "Jonathan T. Barron", "Ben Mildenhall"], "title": "DreamFusion: Text-to-3D using 2D Diffusion", "url": "http://arxiv.org/pdf/2209.14988v1", "summary": "Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors.", "published": "2022-09-29T17:50:40Z", "version": 1}, {"aid": "2209.15001", "authors": ["Ali Hassani", "Humphrey Shi"], "title": "Dilated Neighborhood Attention Transformer", "url": "http://arxiv.org/pdf/2209.15001v3", "summary": "Transformers are quickly becoming one of the most heavily applied deep learning architectures across modalities, domains, and tasks. In vision, on top of ongoing efforts into plain transformers, hierarchical transformers have also gained significant attention, thanks to their performance and easy integration into existing frameworks. These models typically employ localized attention mechanisms, such as the sliding-window Neighborhood Attention (NA) or Swin Transformer's Shifted Window Self Attention. While effective at reducing self attention's quadratic complexity, local attention weakens two of the most desirable properties of self attention: long range inter-dependency modeling, and global receptive field. In this paper, we introduce Dilated Neighborhood Attention (DiNA), a natural, flexible and efficient extension to NA that can capture more global context and expand receptive fields exponentially at no additional cost. NA's local attention and DiNA's sparse global attention complement each other, and therefore we introduce Dilated Neighborhood Attention Transformer (DiNAT), a new hierarchical vision transformer built upon both. DiNAT variants enjoy significant improvements over strong baselines such as NAT, Swin, and ConvNeXt. Our large model is faster and ahead of its Swin counterpart by 1.6% box AP in COCO object detection, 1.4% mask AP in COCO instance segmentation, and 1.4% mIoU in ADE20K semantic segmentation. Paired with new frameworks, our large variant is the new state of the art panoptic segmentation model on COCO (58.5 PQ) and ADE20K (49.4 PQ), and instance segmentation model on Cityscapes (45.1 AP) and ADE20K (35.4 AP) (no extra data). It also matches the state of the art specialized semantic segmentation models on ADE20K (58.1 mIoU), and ranks second on Cityscapes (84.5 mIoU) (no extra data).", "published": "2022-09-29T17:57:08Z", "version": 3}, {"aid": "2209.15179", "authors": ["Hui Wei", "Hao Tang", "Xuemei Jia", "Zhixiang Wang", "Hanxun Yu", "Zhubo Li", "Shin'ichi Satoh", "Luc Van Gool", "Zheng Wang"], "title": "Physical Adversarial Attack meets Computer Vision: A Decade Survey", "url": "http://arxiv.org/pdf/2209.15179v4", "summary": "Despite the impressive achievements of Deep Neural Networks (DNNs) in computer vision, their vulnerability to adversarial attacks remains a critical concern. Extensive research has demonstrated that incorporating sophisticated perturbations into input images can lead to a catastrophic degradation in DNNs' performance. This perplexing phenomenon not only exists in the digital space but also in the physical world. Consequently, it becomes imperative to evaluate the security of DNNs-based systems to ensure their safe deployment in real-world scenarios, particularly in security-sensitive applications. To facilitate a profound understanding of this topic, this paper presents a comprehensive overview of physical adversarial attacks. Firstly, we distill four general steps for launching physical adversarial attacks. Building upon this foundation, we uncover the pervasive role of artifacts carrying adversarial perturbations in the physical world. These artifacts influence each step. To denote them, we introduce a new term: adversarial medium. Then, we take the first step to systematically evaluate the performance of physical adversarial attacks, taking the adversarial medium as a first attempt. Our proposed evaluation metric, hiPAA, comprises six perspectives: Effectiveness, Stealthiness, Robustness, Practicability, Aesthetics, and Economics. We also provide comparative results across task categories, together with insightful observations and suggestions for future research directions.", "published": "2022-09-30T01:59:53Z", "version": 4}, {"aid": "2209.15246", "authors": ["Mohammad Azizmalayeri", "Arshia Soltani Moakhar", "Arman Zarei", "Reihaneh Zohrabi", "Mohammad Taghi Manzuri", "Mohammad Hossein Rohban"], "title": "Your Out-of-Distribution Detection Method is Not Robust!", "url": "http://arxiv.org/pdf/2209.15246v1", "summary": "Out-of-distribution (OOD) detection has recently gained substantial attention due to the importance of identifying out-of-domain samples in reliability and safety. Although OOD detection methods have advanced by a great deal, they are still susceptible to adversarial examples, which is a violation of their purpose. To mitigate this issue, several defenses have recently been proposed. Nevertheless, these efforts remained ineffective, as their evaluations are based on either small perturbation sizes, or weak attacks. In this work, we re-examine these defenses against an end-to-end PGD attack on in/out data with larger perturbation sizes, e.g. up to commonly used $\\epsilon=8/255$ for the CIFAR-10 dataset. Surprisingly, almost all of these defenses perform worse than a random detection under the adversarial setting. Next, we aim to provide a robust OOD detection method. In an ideal defense, the training should expose the model to almost all possible adversarial perturbations, which can be achieved through adversarial training. That is, such training perturbations should based on both in- and out-of-distribution samples. Therefore, unlike OOD detection in the standard setting, access to OOD, as well as in-distribution, samples sounds necessary in the adversarial training setup. These tips lead us to adopt generative OOD detection methods, such as OpenGAN, as a baseline. We subsequently propose the Adversarially Trained Discriminator (ATD), which utilizes a pre-trained robust model to extract robust features, and a generator model to create OOD samples. Using ATD with CIFAR-10 and CIFAR-100 as the in-distribution data, we could significantly outperform all previous methods in the robust AUROC while maintaining high standard AUROC and classification accuracy. The code repository is available at https://github.com/rohban-lab/ATD .", "published": "2022-09-30T05:49:00Z", "version": 1}, {"aid": "2209.15261", "authors": ["Yubei Chen", "Zeyu Yun", "Yi Ma", "Bruno Olshausen", "Yann LeCun"], "title": "Minimalistic Unsupervised Learning with the Sparse Manifold Transform", "url": "http://arxiv.org/pdf/2209.15261v2", "summary": "We describe a minimalistic and interpretable method for unsupervised learning, without resorting to data augmentation, hyperparameter tuning, or other engineering designs, that achieves performance close to the SOTA SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic sparse manifold transform, one can achieve 99.3% KNN top-1 accuracy on MNIST, 81.1% KNN top-1 accuracy on CIFAR-10 and 53.2% on CIFAR-100. With a simple gray-scale augmentation, the model gets 83.2% KNN top-1 accuracy on CIFAR-10 and 57% on CIFAR-100. These results significantly close the gap between simplistic \"white-box\" methods and the SOTA methods. Additionally, we provide visualization to explain how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though there remains a small performance gap between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised learning.", "published": "2022-09-30T06:38:30Z", "version": 2}, {"aid": "2209.15605", "authors": ["Maan Qraitem", "Kate Saenko", "Bryan A. Plummer"], "title": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation", "url": "http://arxiv.org/pdf/2209.15605v8", "summary": "Prior work has shown that Visual Recognition datasets frequently underrepresent bias groups $B$ (\\eg Female) within class labels $Y$ (\\eg Programmers). This dataset bias can lead to models that learn spurious correlations between class labels and bias groups such as age, gender, or race. Most recent methods that address this problem require significant architectural changes or additional loss functions requiring more hyper-parameter tuning. Alternatively, data sampling baselines from the class imbalance literature (\\eg Undersampling, Upweighting), which can often be implemented in a single line of code and often have no hyperparameters, offer a cheaper and more efficient solution. However, these methods suffer from significant shortcomings. For example, Undersampling drops a significant part of the input distribution per epoch while Oversampling repeats samples, causing overfitting. To address these shortcomings, we introduce a new class-conditioned sampling method: Bias Mimicking. The method is based on the observation that if a class $c$ bias distribution, \\ie $P_D(B|Y=c)$ is mimicked across every $c^{\\prime}\\neq c$, then $Y$ and $B$ are statistically independent. Using this notion, BM, through a novel training procedure, ensures that the model is exposed to the entire distribution per epoch without repeating samples. Consequently, Bias Mimicking improves underrepresented groups' accuracy of sampling methods by 3\\% over four benchmarks while maintaining and sometimes improving performance over nonsampling methods. Code: \\url{https://github.com/mqraitem/Bias-Mimicking}", "published": "2022-09-30T17:33:00Z", "version": 8}, {"aid": "2210.00038", "authors": ["Zhiqi Bu", "Yu-Xiang Wang", "Sheng Zha", "George Karypis"], "title": "Differentially Private Optimization on Large Model at Small Cost", "url": "http://arxiv.org/pdf/2210.00038v2", "summary": "Differentially private (DP) optimization is the standard paradigm to learn large neural networks that are accurate and privacy-preserving. The computational cost for DP deep learning, however, is notoriously heavy due to the per-sample gradient clipping. Existing DP implementations are 2-1000X more costly in time and space complexity than the standard (non-private) training. In this work, we develop a novel Book-Keeping (BK) technique that implements existing DP optimizers (thus achieving the same accuracy), with a substantial improvement on the computational cost. Specifically, BK enables DP training on large models and high dimensional data to be roughly as fast and memory-saving as the standard training, whereas previous DP algorithms can be inefficient or incapable of training due to memory error. The computational advantage of BK is supported by the complexity analysis as well as extensive experiments on vision and language tasks. Our implementation achieves state-of-the-art (SOTA) accuracy with very small extra cost: on GPT2 and at almost the same memory cost (<1% overhead), BK has 1.03X the time complexity of the standard training (0.83X training speed in practice), and 0.61X the time complexity of the most efficient DP implementation (1.36X training speed in practice). We open-source the codebase for the BK algorithm at the FastDP library (https://github.com/awslabs/fast-differential-privacy).", "published": "2022-09-30T18:38:53Z", "version": 2}, {"aid": "2210.01797", "authors": ["Sanjay Chawla", "Preslav Nakov", "Ahmed Ali", "Wendy Hall", "Issa Khalil", "Xiaosong Ma", "Husrev Taha Sencar", "Ingmar Weber", "Michael Wooldridge", "Ting Yu"], "title": "Ten Years after ImageNet: A 360\u00b0 Perspective on AI", "url": "http://arxiv.org/pdf/2210.01797v1", "summary": "It is ten years since neural networks made their spectacular comeback. Prompted by this anniversary, we take a holistic perspective on Artificial Intelligence (AI). Supervised Learning for cognitive tasks is effectively solved - provided we have enough high-quality labeled data. However, deep neural network models are not easily interpretable, and thus the debate between blackbox and whitebox modeling has come to the fore. The rise of attention networks, self-supervised learning, generative modeling, and graph neural networks has widened the application space of AI. Deep Learning has also propelled the return of reinforcement learning as a core building block of autonomous decision making systems. The possible harms made possible by new AI technologies have raised socio-technical issues such as transparency, fairness, and accountability. The dominance of AI by Big-Tech who control talent, computing resources, and most importantly, data may lead to an extreme AI divide. Failure to meet high expectations in high profile, and much heralded flagship projects like self-driving vehicles could trigger another AI winter.", "published": "2022-10-01T01:41:17Z", "version": 1}, {"aid": "2210.00379", "authors": ["Kyle Gao", "Yina Gao", "Hongjie He", "Dening Lu", "Linlin Xu", "Jonathan Li"], "title": "NeRF: Neural Radiance Field in 3D Vision: A Comprehensive Review (Updated Post-Gaussian Splatting)", "url": "http://arxiv.org/pdf/2210.00379v7", "summary": "In March 2020, Neural Radiance Field (NeRF) revolutionized Computer Vision, allowing for implicit, neural network-based scene representation and novel view synthesis. NeRF models have found diverse applications in robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, and more. In August 2023, Gaussian Splatting, a direct competitor to the NeRF-based framework, was proposed, gaining tremendous momentum and overtaking NeRF-based research in terms of interest as the dominant framework for novel view synthesis. We present a comprehensive survey of NeRF papers from the past five years (2020-2025). These include papers from the pre-Gaussian Splatting era, where NeRF dominated the field for novel view synthesis and 3D implicit and hybrid representation neural field learning. We also include works from the post-Gaussian Splatting era where NeRF and implicit/hybrid neural fields found more niche applications.   Our survey is organized into architecture and application-based taxonomies in the pre-Gaussian Splatting era, as well as a categorization of active research areas for NeRF, neural field, and implicit/hybrid neural representation methods. We provide an introduction to the theory of NeRF and its training via differentiable volume rendering. We also present a benchmark comparison of the performance and speed of classical NeRF, implicit and hybrid neural representation, and neural field models, and an overview of key datasets.", "published": "2022-10-01T21:35:11Z", "version": 7}, {"aid": "2210.00405", "authors": ["Bin Xia", "Yulun Zhang", "Yitong Wang", "Yapeng Tian", "Wenming Yang", "Radu Timofte", "Luc Van Gool"], "title": "Basic Binary Convolution Unit for Binarized Image Restoration Network", "url": "http://arxiv.org/pdf/2210.00405v2", "summary": "Lighter and faster image restoration (IR) models are crucial for the deployment on resource-limited devices. Binary neural network (BNN), one of the most promising model compression methods, can dramatically reduce the computations and parameters of full-precision convolutional neural networks (CNN). However, there are different properties between BNN and full-precision CNN, and we can hardly use the experience of designing CNN to develop BNN. In this study, we reconsider components in binary convolution, such as residual connection, BatchNorm, activation function, and structure, for IR tasks. We conduct systematic analyses to explain each component's role in binary convolution and discuss the pitfalls. Specifically, we find that residual connection can reduce the information loss caused by binarization; BatchNorm can solve the value range gap between residual connection and binary convolution; The position of the activation function dramatically affects the performance of BNN. Based on our findings and analyses, we design a simple yet efficient basic binary convolution unit (BBCU). Furthermore, we divide IR networks into four parts and specially design variants of BBCU for each part to explore the benefit of binarizing these parts. We conduct experiments on different IR tasks, and our BBCU significantly outperforms other BNNs and lightweight models, which shows that BBCU can serve as a basic unit for binarized IR networks. All codes and models will be released.", "published": "2022-10-02T01:54:40Z", "version": 2}, {"aid": "2210.00479", "authors": ["Siddharth Roheda", "Ashkan Panahi", "Hamid Krim"], "title": "Fast OT for Latent Domain Adaptation", "url": "http://arxiv.org/pdf/2210.00479v1", "summary": "In this paper, we address the problem of unsupervised Domain Adaptation. The need for such an adaptation arises when the distribution of the target data differs from that which is used to develop the model and the ground truth information of the target data is unknown. We propose an algorithm that uses optimal transport theory with a verifiably efficient and implementable solution to learn the best latent feature representation. This is achieved by minimizing the cost of transporting the samples from the target domain to the distribution of the source domain.", "published": "2022-10-02T10:25:12Z", "version": 1}, {"aid": "2210.00545", "authors": ["Jiahuan Ren", "Zhao Zhang", "Richang Hong", "Mingliang Xu", "Yi Yang", "Shuicheng Yan"], "title": "Seeing Through the Noisy Dark: Towards Real-world Low-Light Image Enhancement and Denoising", "url": "http://arxiv.org/pdf/2210.00545v3", "summary": "Low-light image enhancement (LLIE) aims at improving the illumination and visibility of dark images with lighting noise. To handle the real-world low-light images often with heavy and complex noise, some efforts have been made for joint LLIE and denoising, which however only achieve inferior restoration performance. We attribute it to two challenges: 1) in real-world low-light images, noise is somewhat covered by low-lighting and the left noise after denoising would be inevitably amplified during enhancement; 2) conversion of raw data to sRGB would cause information loss and also more noise, and hence prior LLIE methods trained on raw data are unsuitable for more common sRGB images. In this work, we propose a novel Low-light Enhancement & Denoising Network for real-world low-light images (RLED-Net) in the sRGB color space. In RLED-Net, we apply a plug-and-play differentiable Latent Subspace Reconstruction Block (LSRB) to embed the real-world images into low-rank subspaces to suppress the noise and rectify the errors, such that the impact of noise during enhancement can be effectively shrunk. We then present an efficient Crossed-channel & Shift-window Transformer (CST) layer with two branches to calculate the window and channel attentions to resist the degradation (e.g., speckle noise and blur) caused by the noise in input images. Based on the CST layers, we further present a U-structure network CSTNet as backbone for deep feature recovery, and construct a feature refine block to refine the final features. Extensive experiments on both real noisy images and public image databases well verify the effectiveness of the proposed RLED-Net for RLLIE and denoising simultaneously.", "published": "2022-10-02T14:57:23Z", "version": 3}, {"aid": "2210.00752", "authors": ["Xiaoming Li", "Chaofeng Chen", "Xianhui Lin", "Wangmeng Zuo", "Lei Zhang"], "title": "From Face to Natural Image: Learning Real Degradation for Blind Image Super-Resolution", "url": "http://arxiv.org/pdf/2210.00752v2", "summary": "How to design proper training pairs is critical for super-resolving real-world low-quality (LQ) images, which suffers from the difficulties in either acquiring paired ground-truth high-quality (HQ) images or synthesizing photo-realistic degraded LQ observations. Recent works mainly focus on modeling the degradation with handcrafted or estimated degradation parameters, which are however incapable to model complicated real-world degradation types, resulting in limited quality improvement. Notably, LQ face images, which may have the same degradation process as natural images, can be robustly restored with photo-realistic textures by exploiting their strong structural priors. This motivates us to use the real-world LQ face images and their restored HQ counterparts to model the complex real-world degradation (namely ReDegNet), and then transfer it to HQ natural images to synthesize their realistic LQ counterparts. By taking these paired HQ-LQ face images as inputs to explicitly predict the degradation-aware and content-independent representations, we could control the degraded image generation, and subsequently transfer these degradation representations from face to natural images to synthesize the degraded LQ natural images. Experiments show that our ReDegNet can well learn the real degradation process from face images. The restoration network trained with our synthetic pairs performs favorably against SOTAs. More importantly, our method provides a new way to handle the real-world complex scenarios by learning their degradation representations from the facial portions, which can be used to significantly improve the quality of non-facial areas. The source code is available at https://github.com/csxmli2016/ReDegNet.", "published": "2022-10-03T08:09:21Z", "version": 2}, {"aid": "2210.01802", "authors": ["Haixiang Sun", "Ye Shi", "Jingya Wang", "Hoang Duong Tuan", "H. Vincent Poor", "Dacheng Tao"], "title": "Alternating Differentiation for Optimization Layers", "url": "http://arxiv.org/pdf/2210.01802v2", "summary": "The idea of embedding optimization problems into deep neural networks as optimization layers to encode constraints and inductive priors has taken hold in recent years. Most existing methods focus on implicitly differentiating Karush-Kuhn-Tucker (KKT) conditions in a way that requires expensive computations on the Jacobian matrix, which can be slow and memory-intensive. In this paper, we developed a new framework, named Alternating Differentiation (Alt-Diff), that differentiates optimization problems (here, specifically in the form of convex optimization problems with polyhedral constraints) in a fast and recursive way. Alt-Diff decouples the differentiation procedure into a primal update and a dual update in an alternating way. Accordingly, Alt-Diff substantially decreases the dimensions of the Jacobian matrix especially for optimization with large-scale constraints and thus increases the computational speed of implicit differentiation. We show that the gradients obtained by Alt-Diff are consistent with those obtained by differentiating KKT conditions. In addition, we propose to truncate Alt-Diff to further accelerate the computational speed. Under some standard assumptions, we show that the truncation error of gradients is upper bounded by the same order of variables' estimation error. Therefore, Alt-Diff can be truncated to further increase computational speed without sacrificing much accuracy. A series of comprehensive experiments validate the superiority of Alt-Diff.", "published": "2022-10-03T11:32:13Z", "version": 2}, {"aid": "2210.02192", "authors": ["Jinxin Zhou", "Chong You", "Xiao Li", "Kangning Liu", "Sheng Liu", "Qing Qu", "Zhihui Zhu"], "title": "Are All Losses Created Equal: A Neural Collapse Perspective", "url": "http://arxiv.org/pdf/2210.02192v2", "summary": "While cross entropy (CE) is the most commonly used loss to train deep neural networks for classification tasks, many alternative losses have been developed to obtain better empirical performance. Among them, which one is the best to use is still a mystery, because there seem to be multiple factors affecting the answer, such as properties of the dataset, the choice of network architecture, and so on. This paper studies the choice of loss function by examining the last-layer features of deep networks, drawing inspiration from a recent line work showing that the global optimal solution of CE and mean-square-error (MSE) losses exhibits a Neural Collapse phenomenon. That is, for sufficiently large networks trained until convergence, (i) all features of the same class collapse to the corresponding class mean and (ii) the means associated with different classes are in a configuration where their pairwise distances are all equal and maximized. We extend such results and show through global solution and landscape analyses that a broad family of loss functions including commonly used label smoothing (LS) and focal loss (FL) exhibits Neural Collapse. Hence, all relevant losses(i.e., CE, LS, FL, MSE) produce equivalent features on training data. Based on the unconstrained feature model assumption, we provide either the global landscape analysis for LS loss or the local landscape analysis for FL loss and show that the (only!) global minimizers are neural collapse solutions, while all other critical points are strict saddles whose Hessian exhibit negative curvature directions either in the global scope for LS loss or in the local scope for FL loss near the optimal solution. The experiments further show that Neural Collapse features obtained from all relevant losses lead to largely identical performance on test data as well, provided that the network is sufficiently large and trained until convergence.", "published": "2022-10-04T00:36:45Z", "version": 2}, {"aid": "2210.01820", "authors": ["Chenglin Yang", "Siyuan Qiao", "Qihang Yu", "Xiaoding Yuan", "Yukun Zhu", "Alan Yuille", "Hartwig Adam", "Liang-Chieh Chen"], "title": "MOAT: Alternating Mobile Convolution and Attention Brings Strong Vision Models", "url": "http://arxiv.org/pdf/2210.01820v2", "summary": "This paper presents MOAT, a family of neural networks that build on top of MObile convolution (i.e., inverted residual blocks) and ATtention. Unlike the current works that stack separate mobile convolution and transformer blocks, we effectively merge them into a MOAT block. Starting with a standard Transformer block, we replace its multi-layer perceptron with a mobile convolution block, and further reorder it before the self-attention operation. The mobile convolution block not only enhances the network representation capacity, but also produces better downsampled features. Our conceptually simple MOAT networks are surprisingly effective, achieving 89.1% / 81.5% top-1 accuracy on ImageNet-1K / ImageNet-1K-V2 with ImageNet22K pretraining. Additionally, MOAT can be seamlessly applied to downstream tasks that require large resolution inputs by simply converting the global attention to window attention. Thanks to the mobile convolution that effectively exchanges local information between pixels (and thus cross-windows), MOAT does not need the extra window-shifting mechanism. As a result, on COCO object detection, MOAT achieves 59.2% box AP with 227M model parameters (single-scale inference, and hard NMS), and on ADE20K semantic segmentation, MOAT attains 57.6% mIoU with 496M model parameters (single-scale inference). Finally, the tiny-MOAT family, obtained by simply reducing the channel sizes, also surprisingly outperforms several mobile-specific transformer-based models on ImageNet. The tiny-MOAT family is also benchmarked on downstream tasks, serving as a baseline for the community. We hope our simple yet effective MOAT will inspire more seamless integration of convolution and self-attention. Code is publicly available.", "published": "2022-10-04T18:00:06Z", "version": 2}, {"aid": "2210.01941", "authors": ["Kareem Ahmed", "Zhe Zeng", "Mathias Niepert", "Guy Van den Broeck"], "title": "SIMPLE: A Gradient Estimator for $k$-Subset Sampling", "url": "http://arxiv.org/pdf/2210.01941v2", "summary": "$k$-subset sampling is ubiquitous in machine learning, enabling regularization and interpretability through sparsity. The challenge lies in rendering $k$-subset sampling amenable to end-to-end learning. This has typically involved relaxing the reparameterized samples to allow for backpropagation, with the risk of introducing high bias and high variance. In this work, we fall back to discrete $k$-subset sampling on the forward pass. This is coupled with using the gradient with respect to the exact marginals, computed efficiently, as a proxy for the true gradient. We show that our gradient estimator, SIMPLE, exhibits lower bias and variance compared to state-of-the-art estimators, including the straight-through Gumbel estimator when $k = 1$. Empirical results show improved performance on learning to explain and sparse linear regression. We provide an algorithm for computing the exact ELBO for the $k$-subset distribution, obtaining significantly lower loss compared to SOTA.", "published": "2022-10-04T22:33:16Z", "version": 2}, {"aid": "2210.01986", "authors": ["Yue-Ting Pan", "Jing-Lun Chou", "Chun-Shu Wei"], "title": "MAtt: A Manifold Attention Network for EEG Decoding", "url": "http://arxiv.org/pdf/2210.01986v1", "summary": "Recognition of electroencephalographic (EEG) signals highly affect the efficiency of non-invasive brain-computer interfaces (BCIs). While recent advances of deep-learning (DL)-based EEG decoders offer improved performances, the development of geometric learning (GL) has attracted much attention for offering exceptional robustness in decoding noisy EEG data. However, there is a lack of studies on the merged use of deep neural networks (DNNs) and geometric learning for EEG decoding. We herein propose a manifold attention network (mAtt), a novel geometric deep learning (GDL)-based model, featuring a manifold attention mechanism that characterizes spatiotemporal representations of EEG data fully on a Riemannian symmetric positive definite (SPD) manifold. The evaluation of the proposed MAtt on both time-synchronous and -asyncronous EEG datasets suggests its superiority over other leading DL methods for general EEG decoding. Furthermore, analysis of model interpretation reveals the capability of MAtt in capturing informative EEG features and handling the non-stationarity of brain dynamics.", "published": "2022-10-05T02:26:31Z", "version": 1}, {"aid": "2210.02303", "authors": ["Jonathan Ho", "William Chan", "Chitwan Saharia", "Jay Whang", "Ruiqi Gao", "Alexey Gritsenko", "Diederik P. Kingma", "Ben Poole", "Mohammad Norouzi", "David J. Fleet", "Tim Salimans"], "title": "Imagen Video: High Definition Video Generation with Diffusion Models", "url": "http://arxiv.org/pdf/2210.02303v1", "summary": "We present Imagen Video, a text-conditional video generation system based on a cascade of video diffusion models. Given a text prompt, Imagen Video generates high definition videos using a base video generation model and a sequence of interleaved spatial and temporal video super-resolution models. We describe how we scale up the system as a high definition text-to-video model including design decisions such as the choice of fully-convolutional temporal and spatial super-resolution models at certain resolutions, and the choice of the v-parameterization of diffusion models. In addition, we confirm and transfer findings from previous work on diffusion-based image generation to the video generation setting. Finally, we apply progressive distillation to our video models with classifier-free guidance for fast, high quality sampling. We find Imagen Video not only capable of generating videos of high fidelity, but also having a high degree of controllability and world knowledge, including the ability to generate diverse videos and text animations in various artistic styles and with 3D object understanding. See https://imagen.research.google/video/ for samples.", "published": "2022-10-05T14:41:38Z", "version": 1}, {"aid": "2210.02382", "authors": ["Mathias Vetsch", "Sandro Lombardi", "Marc Pollefeys", "Martin R. Oswald"], "title": "NeuralMeshing: Differentiable Meshing of Implicit Neural Representations", "url": "http://arxiv.org/pdf/2210.02382v1", "summary": "The generation of triangle meshes from point clouds, i.e. meshing, is a core task in computer graphics and computer vision. Traditional techniques directly construct a surface mesh using local decision heuristics, while some recent methods based on neural implicit representations try to leverage data-driven approaches for this meshing process. However, it is challenging to define a learnable representation for triangle meshes of unknown topology and size and for this reason, neural implicit representations rely on non-differentiable post-processing in order to extract the final triangle mesh. In this work, we propose a novel differentiable meshing algorithm for extracting surface meshes from neural implicit representations. Our method produces the mesh in an iterative fashion, which makes it applicable to shapes of various scales and adaptive to the local curvature of the shape. Furthermore, our method produces meshes with regular tessellation patterns and fewer triangle faces compared to existing methods. Experiments demonstrate the comparable reconstruction performance and favorable mesh properties over baselines.", "published": "2022-10-05T16:52:25Z", "version": 1}, {"aid": "2210.02579", "authors": ["Gwangbin Bae", "Martin de La Gorce", "Tadas Baltrusaitis", "Charlie Hewitt", "Dong Chen", "Julien Valentin", "Roberto Cipolla", "Jingjing Shen"], "title": "DigiFace-1M: 1 Million Digital Face Images for Face Recognition", "url": "http://arxiv.org/pdf/2210.02579v1", "summary": "State-of-the-art face recognition models show impressive accuracy, achieving over 99.8% on Labeled Faces in the Wild (LFW) dataset. Such models are trained on large-scale datasets that contain millions of real human face images collected from the internet. Web-crawled face images are severely biased (in terms of race, lighting, make-up, etc) and often contain label noise. More importantly, the face images are collected without explicit consent, raising ethical concerns. To avoid such problems, we introduce a large-scale synthetic dataset for face recognition, obtained by rendering digital faces using a computer graphics pipeline. We first demonstrate that aggressive data augmentation can significantly reduce the synthetic-to-real domain gap. Having full control over the rendering pipeline, we also study how each attribute (e.g., variation in facial pose, accessories and textures) affects the accuracy. Compared to SynFace, a recent method trained on GAN-generated synthetic faces, we reduce the error rate on LFW by 52.5% (accuracy from 91.93% to 96.17%). By fine-tuning the network on a smaller number of real face images that could reasonably be obtained with consent, we achieve accuracy that is comparable to the methods trained on millions of real face images.", "published": "2022-10-05T22:02:48Z", "version": 1}, {"aid": "2210.03158", "authors": ["Yan Zheng", "Lemeng Wu", "Xingchao Liu", "Zhen Chen", "Qiang Liu", "Qixing Huang"], "title": "Neural Volumetric Mesh Generator", "url": "http://arxiv.org/pdf/2210.03158v1", "summary": "Deep generative models have shown success in generating 3D shapes with different representations. In this work, we propose Neural Volumetric Mesh Generator(NVMG) which can generate novel and high-quality volumetric meshes. Unlike the previous 3D generative model for point cloud, voxel, and implicit surface, the volumetric mesh representation is a ready-to-use representation in industry with details on both the surface and interior. Generating this such highly-structured data thus brings a significant challenge. We first propose a diffusion-based generative model to tackle this problem by generating voxelized shapes with close-to-reality outlines and structures. We can simply obtain a tetrahedral mesh as a template with the voxelized shape. Further, we use a voxel-conditional neural network to predict the smooth implicit surface conditioned on the voxels, and progressively project the tetrahedral mesh to the predicted surface under regularizations. The regularization terms are carefully designed so that they can (1) get rid of the defects like flipping and high distortion; (2) force the regularity of the interior and surface structure during the deformation procedure for a high-quality final mesh. As shown in the experiments, our pipeline can generate high-quality artifact-free volumetric and surface meshes from random noise or a reference image without any post-processing. Compared with the state-of-the-art voxel-to-mesh deformation method, we show more robustness and better performance when taking generated voxels as input.", "published": "2022-10-06T18:46:51Z", "version": 1}, {"aid": "2210.03204", "authors": ["Zhongnan Qu"], "title": "Enabling Deep Learning on Edge Devices", "url": "http://arxiv.org/pdf/2210.03204v1", "summary": "Deep neural networks (DNNs) have succeeded in many different perception tasks, e.g., computer vision, natural language processing, reinforcement learning, etc. The high-performed DNNs heavily rely on intensive resource consumption. For example, training a DNN requires high dynamic memory, a large-scale dataset, and a large number of computations (a long training time); even inference with a DNN also demands a large amount of static storage, computations (a long inference time), and energy. Therefore, state-of-the-art DNNs are often deployed on a cloud server with a large number of super-computers, a high-bandwidth communication bus, a shared storage infrastructure, and a high power supplement.   Recently, some new emerging intelligent applications, e.g., AR/VR, mobile assistants, Internet of Things, require us to deploy DNNs on resource-constrained edge devices. Compare to a cloud server, edge devices often have a rather small amount of resources. To deploy DNNs on edge devices, we need to reduce the size of DNNs, i.e., we target a better trade-off between resource consumption and model accuracy.   In this dissertation, we studied four edge intelligence scenarios, i.e., Inference on Edge Devices, Adaptation on Edge Devices, Learning on Edge Devices, and Edge-Server Systems, and developed different methodologies to enable deep learning in each scenario. Since current DNNs are often over-parameterized, our goal is to find and reduce the redundancy of the DNNs in each scenario.", "published": "2022-10-06T20:52:57Z", "version": 1}, {"aid": "2210.03301", "authors": ["Yuan Lan", "Liang Qin", "Zhaoyi Sun", "Yang Xiang", "Jie Sun"], "title": "GOLLIC: Learning Global Context beyond Patches for Lossless High-Resolution Image Compression", "url": "http://arxiv.org/pdf/2210.03301v1", "summary": "Neural-network-based approaches recently emerged in the field of data compression and have already led to significant progress in image compression, especially in achieving a higher compression ratio. In the lossless image compression scenario, however, existing methods often struggle to learn a probability model of full-size high-resolution images due to the limitation of the computation source. The current strategy is to crop high-resolution images into multiple non-overlapping patches and process them independently. This strategy ignores long-term dependencies beyond patches, thus limiting modeling performance. To address this problem, we propose a hierarchical latent variable model with a global context to capture the long-term dependencies of high-resolution images. Besides the latent variable unique to each patch, we introduce shared latent variables between patches to construct the global context. The shared latent variables are extracted by a self-supervised clustering module inside the model's encoder. This clustering module assigns each patch the confidence that it belongs to any cluster. Later, shared latent variables are learned according to latent variables of patches and their confidence, which reflects the similarity of patches in the same cluster and benefits the global context modeling. Experimental results show that our global context model improves compression ratio compared to the engineered codecs and deep learning models on three benchmark high-resolution image datasets, DIV2K, CLIC.pro, and CLIC.mobile.", "published": "2022-10-07T03:15:02Z", "version": 1}, {"aid": "2210.03310", "authors": ["Mengye Ren", "Simon Kornblith", "Renjie Liao", "Geoffrey Hinton"], "title": "Scaling Forward Gradient With Local Losses", "url": "http://arxiv.org/pdf/2210.03310v3", "summary": "Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. However, the standard forward gradient algorithm, when applied naively, suffers from high variance when the number of parameters to be learned is large. In this paper, we propose a series of architectural and algorithmic modifications that together make forward gradient learning practical for standard deep learning benchmark tasks. We show that it is possible to substantially reduce the variance of the forward gradient estimator by applying perturbations to activations rather than weights. We further improve the scalability of forward gradient by introducing a large number of local greedy loss functions, each of which involves only a small number of learnable parameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more suitable for local learning. Our approach matches backprop on MNIST and CIFAR-10 and significantly outperforms previously proposed backprop-free algorithms on ImageNet.", "published": "2022-10-07T03:52:27Z", "version": 3}, {"aid": "2210.03586", "authors": ["Xi Weng", "Lei Huang", "Lei Zhao", "Rao Muhammad Anwer", "Salman Khan", "Fahad Shahbaz Khan"], "title": "An Investigation into Whitening Loss for Self-supervised Learning", "url": "http://arxiv.org/pdf/2210.03586v1", "summary": "A desirable objective in self-supervised learning (SSL) is to avoid feature collapse. Whitening loss guarantees collapse avoidance by minimizing the distance between embeddings of positive pairs under the conditioning that the embeddings from different views are whitened. In this paper, we propose a framework with an informative indicator to analyze whitening loss, which provides a clue to demystify several interesting phenomena as well as a pivoting point connecting to other SSL methods. We reveal that batch whitening (BW) based methods do not impose whitening constraints on the embedding, but they only require the embedding to be full-rank. This full-rank constraint is also sufficient to avoid dimensional collapse. Based on our analysis, we propose channel whitening with random group partition (CW-RGP), which exploits the advantages of BW-based methods in preventing collapse and avoids their disadvantages requiring large batch size. Experimental results on ImageNet classification and COCO object detection reveal that the proposed CW-RGP possesses a promising potential for learning good representations. The code is available at https://github.com/winci-ai/CW-RGP.", "published": "2022-10-07T14:43:29Z", "version": 1}, {"aid": "2210.03651", "authors": ["Asher Trockman", "Devin Willmott", "J. Zico Kolter"], "title": "Understanding the Covariance Structure of Convolutional Filters", "url": "http://arxiv.org/pdf/2210.03651v1", "summary": "Neural network weights are typically initialized at random from univariate distributions, controlling just the variance of individual weights even in highly-structured operations like convolutions. Recent ViT-inspired convolutional networks such as ConvMixer and ConvNeXt use large-kernel depthwise convolutions whose learned filters have notable structure; this presents an opportunity to study their empirical covariances. In this work, we first observe that such learned filters have highly-structured covariance matrices, and moreover, we find that covariances calculated from small networks may be used to effectively initialize a variety of larger networks of different depths, widths, patch sizes, and kernel sizes, indicating a degree of model-independence to the covariance structure. Motivated by these findings, we then propose a learning-free multivariate initialization scheme for convolutional filters using a simple, closed-form construction of their covariance. Models using our initialization outperform those using traditional univariate initializations, and typically meet or exceed the performance of those initialized from the covariances of learned filters; in some cases, this improvement can be achieved without training the depthwise convolutional filters at all.", "published": "2022-10-07T15:59:13Z", "version": 1}, {"aid": "2210.03689", "authors": ["Xuejing Lei", "Wei Wang", "C. -C. Jay Kuo"], "title": "GENHOP: An Image Generation Method Based on Successive Subspace Learning", "url": "http://arxiv.org/pdf/2210.03689v1", "summary": "Being different from deep-learning-based (DL-based) image generation methods, a new image generative model built upon successive subspace learning principle is proposed and named GenHop (an acronym of Generative PixelHop) in this work. GenHop consists of three modules: 1) high-to-low dimension reduction, 2) seed image generation, and 3) low-to-high dimension expansion. In the first module, it builds a sequence of high-to-low dimensional subspaces through a sequence of whitening processes, each of which contains samples of joint-spatial-spectral representation. In the second module, it generates samples in the lowest dimensional subspace. In the third module, it finds a proper high-dimensional sample for a seed image by adding details back via locally linear embedding (LLE) and a sequence of coloring processes. Experiments show that GenHop can generate visually pleasant images whose FID scores are comparable or even better than those of DL-based generative models for MNIST, Fashion-MNIST and CelebA datasets.", "published": "2022-10-07T16:51:24Z", "version": 1}, {"aid": "2210.05559", "authors": ["Chen Henry Wu", "Fernando De la Torre"], "title": "Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance", "url": "http://arxiv.org/pdf/2210.05559v2", "summary": "Diffusion models have achieved unprecedented performance in generative modeling. The commonly-adopted formulation of the latent code of diffusion models is a sequence of gradually denoised samples, as opposed to the simpler (e.g., Gaussian) latent space of GANs, VAEs, and normalizing flows. This paper provides an alternative, Gaussian formulation of the latent space of various diffusion models, as well as an invertible DPM-Encoder that maps images into the latent space. While our formulation is purely based on the definition of diffusion models, we demonstrate several intriguing consequences. (1) Empirically, we observe that a common latent space emerges from two diffusion models trained independently on related domains. In light of this finding, we propose CycleDiffusion, which uses DPM-Encoder for unpaired image-to-image translation. Furthermore, applying CycleDiffusion to text-to-image diffusion models, we show that large-scale text-to-image diffusion models can be used as zero-shot image-to-image editors. (2) One can guide pre-trained diffusion models and GANs by controlling the latent codes in a unified, plug-and-play formulation based on energy-based models. Using the CLIP model and a face recognition model as guidance, we demonstrate that diffusion models have better coverage of low-density sub-populations and individuals than GANs. The code is publicly available at https://github.com/ChenWu98/cycle-diffusion.", "published": "2022-10-11T15:53:52Z", "version": 2}, {"aid": "2210.05635", "authors": ["Claudio Ravasio", "Lyndon Da Cruz", "Christos Bergeles"], "title": "Oflib: Facilitating Operations with and on Optical Flow Fields in Python", "url": "http://arxiv.org/pdf/2210.05635v2", "summary": "We present a robust theoretical framework for the characterisation and manipulation of optical flow, i.e 2D vector fields, in the context of their use in motion estimation algorithms and beyond. The definition of two frames of reference guides the mathematical derivation of flow field application, inversion, evaluation, and composition operations. This structured approach is then used as the foundation for an implementation in Python 3, with the fully differentiable PyTorch version oflibpytorch supporting back-propagation as required for deep learning. We verify the flow composition method empirically and provide a working example for its application to optical flow ground truth in synthetic training data creation. All code is publicly available.", "published": "2022-10-11T17:28:10Z", "version": 2}, {"aid": "2210.05834", "authors": ["Nidhin Harilal", "Rohan Patil"], "title": "Effectiveness of the Recent Advances in Capsule Networks", "url": "http://arxiv.org/pdf/2210.05834v1", "summary": "Convolutional neural networks (CNNs) have revolutionized the field of deep neural networks. However, recent research has shown that CNNs fail to generalize under various conditions and hence the idea of capsules was introduced in 2011, though the real surge of research started from 2017. In this paper, we present an overview of the recent advances in capsule architecture and routing mechanisms. In addition, we find that the relative focus in recent literature is on modifying routing procedure or architecture as a whole but the study of other finer components, specifically, squash function is wanting. Thus, we also present some new insights regarding the effect of squash functions in performance of the capsule networks. Finally, we conclude by discussing and proposing possible opportunities in the field of capsule networks.", "published": "2022-10-11T23:30:12Z", "version": 1}, {"aid": "2210.05988", "authors": ["Pin-Hua Lai", "Bo-Shan Wang", "Wei-Chun Yang", "Hsiang-Chieh Tsou", "Chun-Shu Wei"], "title": "CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG Reconstruction", "url": "http://arxiv.org/pdf/2210.05988v2", "summary": "Human electroencephalography (EEG) is a brain monitoring modality that senses cortical neuroelectrophysiological activity in high-temporal resolution. One of the greatest challenges posed in applications of EEG is the unstable signal quality susceptible to inevitable artifacts during recordings. To date, most existing techniques for EEG artifact removal and reconstruction are applicable to offline analysis solely, or require individualized training data to facilitate online reconstruction. We have proposed CLEEGN, a novel convolutional neural network for plug-and-play automatic EEG reconstruction. CLEEGN is based on a subject-independent pre-trained model using existing data and can operate on a new user without any further calibration. The performance of CLEEGN was validated using multiple evaluations including waveform observation, reconstruction error assessment, and decoding accuracy on well-studied labeled datasets. The results of simulated online validation suggest that, even without any calibration, CLEEGN can largely preserve inherent brain activity and outperforms leading online/offline artifact removal methods in the decoding accuracy of reconstructed EEG data. In addition, visualization of model parameters and latent features exhibit the model behavior and reveal explainable insights related to existing knowledge of neuroscience. We foresee pervasive applications of CLEEGN in prospective works of online plug-and-play EEG decoding and analysis.", "published": "2022-10-12T07:56:09Z", "version": 2}, {"aid": "2210.06002", "authors": ["Chenggong Zhang", "Zhilei Liu"], "title": "Face Super-Resolution with Progressive Embedding of Multi-scale Face Priors", "url": "http://arxiv.org/pdf/2210.06002v1", "summary": "The face super-resolution (FSR) task is to reconstruct high-resolution face images from low-resolution inputs. Recent works have achieved success on this task by utilizing facial priors such as facial landmarks. Most existing methods pay more attention to global shape and structure information, but less to local texture information, which makes them cannot recover local details well. In this paper, we propose a novel recurrent convolutional network based framework for face super-resolution, which progressively introduces both global shape and local texture information. We take full advantage of the intermediate outputs of the recurrent network, and landmarks information and facial action units (AUs) information are extracted in the output of the first and second steps respectively, rather than low-resolution input. Moreover, we introduced AU classification results as a novel quantitative metric for facial details restoration. Extensive experiments show that our proposed method significantly outperforms state-of-the-art FSR methods in terms of image quality and facial details restoration.", "published": "2022-10-12T08:16:52Z", "version": 1}, {"aid": "2210.06201", "authors": ["Pedro Sanchez", "Xiao Liu", "Alison Q O'Neil", "Sotirios A. Tsaftaris"], "title": "Diffusion Models for Causal Discovery via Topological Ordering", "url": "http://arxiv.org/pdf/2210.06201v2", "summary": "Discovering causal relations from observational data becomes possible with additional assumptions such as considering the functional relations to be constrained as nonlinear with additive noise (ANM). Even with strong assumptions, causal discovery involves an expensive search problem over the space of directed acyclic graphs (DAGs). \\emph{Topological ordering} approaches reduce the optimisation space of causal discovery by searching over a permutation rather than graph space. For ANMs, the \\emph{Hessian} of the data log-likelihood can be used for finding leaf nodes in a causal graph, allowing its topological ordering. However, existing computational methods for obtaining the Hessian still do not scale as the number of variables and the number of samples increase. Therefore, inspired by recent innovations in diffusion probabilistic models (DPMs), we propose \\emph{DiffAN}\\footnote{Implementation is available at \\url{https://github.com/vios-s/DiffAN} .}, a topological ordering algorithm that leverages DPMs for learning a Hessian function. We introduce theory for updating the learned Hessian without re-training the neural network, and we show that computing with a subset of samples gives an accurate approximation of the ordering, which allows scaling to datasets with more samples and variables. We show empirically that our method scales exceptionally well to datasets with up to $500$ nodes and up to $10^5$ samples while still performing on par over small datasets with state-of-the-art causal discovery methods. Implementation is available at https://github.com/vios-s/DiffAN .", "published": "2022-10-12T13:36:29Z", "version": 2}, {"aid": "2210.06223", "authors": ["Yizeng Han", "Zhihang Yuan", "Yifan Pu", "Chenhao Xue", "Shiji Song", "Guangyu Sun", "Gao Huang"], "title": "Latency-aware Spatial-wise Dynamic Networks", "url": "http://arxiv.org/pdf/2210.06223v1", "summary": "Spatial-wise dynamic convolution has become a promising approach to improving the inference efficiency of deep networks. By allocating more computation to the most informative pixels, such an adaptive inference paradigm reduces the spatial redundancy in image features and saves a considerable amount of unnecessary computation. However, the theoretical efficiency achieved by previous methods can hardly translate into a realistic speedup, especially on the multi-core processors (e.g. GPUs). The key challenge is that the existing literature has only focused on designing algorithms with minimal computation, ignoring the fact that the practical latency can also be influenced by scheduling strategies and hardware properties. To bridge the gap between theoretical computation and practical efficiency, we propose a latency-aware spatial-wise dynamic network (LASNet), which performs coarse-grained spatially adaptive inference under the guidance of a novel latency prediction model. The latency prediction model can efficiently estimate the inference latency of dynamic networks by simultaneously considering algorithms, scheduling strategies, and hardware properties. We use the latency predictor to guide both the algorithm design and the scheduling optimization on various hardware platforms. Experiments on image classification, object detection and instance segmentation demonstrate that the proposed framework significantly improves the practical inference efficiency of deep networks. For example, the average latency of a ResNet-101 on the ImageNet validation set could be reduced by 36% and 46% on a server GPU (Nvidia Tesla-V100) and an edge device (Nvidia Jetson TX2 GPU) respectively without sacrificing the accuracy. Code is available at https://github.com/LeapLabTHU/LASNet.", "published": "2022-10-12T14:09:27Z", "version": 1}, {"aid": "2210.06705", "authors": ["Satyen Kale", "Jason D. Lee", "Chris De Sa", "Ayush Sekhari", "Karthik Sridharan"], "title": "From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent", "url": "http://arxiv.org/pdf/2210.06705v1", "summary": "Stochastic Gradient Descent (SGD) has been the method of choice for learning large-scale non-convex models. While a general analysis of when SGD works has been elusive, there has been a lot of recent progress in understanding the convergence of Gradient Flow (GF) on the population loss, partly due to the simplicity that a continuous-time analysis buys us. An overarching theme of our paper is providing general conditions under which SGD converges, assuming that GF on the population loss converges. Our main tool to establish this connection is a general converse Lyapunov like theorem, which implies the existence of a Lyapunov potential under mild assumptions on the rates of convergence of GF. In fact, using these potentials, we show a one-to-one correspondence between rates of convergence of GF and geometrical properties of the underlying objective. When these potentials further satisfy certain self-bounding properties, we show that they can be used to provide a convergence guarantee for Gradient Descent (GD) and SGD (even when the paths of GF and GD/SGD are quite far apart). It turns out that these self-bounding assumptions are in a sense also necessary for GD/SGD to work. Using our framework, we provide a unified analysis for GD/SGD not only for classical settings like convex losses, or objectives that satisfy PL / KL properties, but also for more complex problems including Phase Retrieval and Matrix sq-root, and extending the results in the recent work of Chatterjee 2022.", "published": "2022-10-13T03:55:04Z", "version": 1}, {"aid": "2210.06932", "authors": ["Chang Liu", "Yuwen Yang", "Yue Ding", "Hongtao Lu"], "title": "NoMorelization: Building Normalizer-Free Models from a Sample's Perspective", "url": "http://arxiv.org/pdf/2210.06932v1", "summary": "The normalizing layer has become one of the basic configurations of deep learning models, but it still suffers from computational inefficiency, interpretability difficulties, and low generality. After gaining a deeper understanding of the recent normalization and normalizer-free research works from a sample's perspective, we reveal the fact that the problem lies in the sampling noise and the inappropriate prior assumption. In this paper, we propose a simple and effective alternative to normalization, which is called \"NoMorelization\". NoMorelization is composed of two trainable scalars and a zero-centered noise injector. Experimental results demonstrate that NoMorelization is a general component for deep learning and is suitable for different model paradigms (e.g., convolution-based and attention-based models) to tackle different tasks (e.g., discriminative and generative tasks). Compared with existing mainstream normalizers (e.g., BN, LN, and IN) and state-of-the-art normalizer-free methods, NoMorelization shows the best speed-accuracy trade-off.", "published": "2022-10-13T12:04:24Z", "version": 1}, {"aid": "2210.06965", "authors": ["Cristina Vasconcelos", "Cengiz Oztireli", "Mark Matthews", "Milad Hashemi", "Kevin Swersky", "Andrea Tagliasacchi"], "title": "CUF: Continuous Upsampling Filters", "url": "http://arxiv.org/pdf/2210.06965v2", "summary": "Neural fields have rapidly been adopted for representing 3D signals, but their application to more classical 2D image-processing has been relatively limited. In this paper, we consider one of the most important operations in image processing: upsampling. In deep learning, learnable upsampling layers have extensively been used for single image super-resolution. We propose to parameterize upsampling kernels as neural fields. This parameterization leads to a compact architecture that obtains a 40-fold reduction in the number of parameters when compared with competing arbitrary-scale super-resolution architectures. When upsampling images of size 256x256 we show that our architecture is 2x-10x more efficient than competing arbitrary-scale super-resolution architectures, and more efficient than sub-pixel convolutions when instantiated to a single-scale model. In the general setting, these gains grow polynomially with the square of the target scale. We validate our method on standard benchmarks showing such efficiency gains can be achieved without sacrifices in super-resolution performance.", "published": "2022-10-13T12:45:51Z", "version": 2}, {"aid": "2210.07069", "authors": ["Veronika Koren", "Stefano Panzeri"], "title": "Biologically plausible solutions for spiking networks with efficient coding", "url": "http://arxiv.org/pdf/2210.07069v2", "summary": "Understanding how the dynamics of neural networks is shaped by the computations they perform is a fundamental question in neuroscience. Recently, the framework of efficient coding proposed a theory of how spiking neural networks can compute low-dimensional stimulus signals with high efficiency. Efficient spiking networks are based on time-dependent minimization of a loss function related to information coding with spikes. To inform the understanding of the function and dynamics of biological networks in the brain, however, the mathematical models have to be informed by biology and obey the same constraints as biological networks. Currently, spiking network models of efficient coding have been extended to include some features of biological plausibility, such as architectures with excitatory and inhibitory neurons. However, biological realism of efficient coding theories is still limited to simple cases and does not include single neuron and network properties that are known to be key in biological circuits. Here, we revisit the theory of efficient coding with spikes to develop spiking neural networks that are closer to biological circuits. Namely, we find a biologically plausible spiking model realizing efficient coding in the case of a generalized leaky integrate-and-fire network with excitatory and inhibitory units, equipped with fast and slow synaptic currents, local homeostatic currents such as spike-triggered adaptation, hyperpolarization-activated rebound current, heterogeneous firing thresholds and resets, heterogeneous postsynaptic potentials, and structured, low-rank connectivity. We show how the complexity of E-E connectivity matrix shapes network responses.", "published": "2022-10-13T14:49:51Z", "version": 2}, {"aid": "2210.07906", "authors": ["Cecilia Latotzke", "Batuhan Balim", "Tobias Gemmeke"], "title": "Post-Training Quantization for Energy Efficient Realization of Deep Neural Networks", "url": "http://arxiv.org/pdf/2210.07906v1", "summary": "The biggest challenge for the deployment of Deep Neural Networks (DNNs) close to the generated data on edge devices is their size, i.e., memory footprint and computational complexity. Both are significantly reduced with quantization. With the resulting lower word-length, the energy efficiency of DNNs increases proportionally. However, lower word-length typically causes accuracy degradation. To counteract this effect, the quantized DNN is retrained. Unfortunately, training costs up to 5000x more energy than the inference of the quantized DNN. To address this issue, we propose a post-training quantization flow without the need for retraining. For this, we investigated different quantization options. Furthermore, our analysis systematically assesses the impact of reduced word-lengths of weights and activations revealing a clear trend for the choice of word-length. Both aspects have not been systematically investigated so far. Our results are independent of the depth of the DNNs and apply to uniform quantization, allowing fast quantization of a given pre-trained DNN. We excel state-of-the-art for 6 bit by 2.2% Top-1 accuracy for ImageNet. Without retraining, our quantization to 8 bit surpasses floating-point accuracy.", "published": "2022-10-14T15:43:57Z", "version": 1}, {"aid": "2210.08772", "authors": ["Dejia Xu", "Peihao Wang", "Yifan Jiang", "Zhiwen Fan", "Zhangyang Wang"], "title": "Signal Processing for Implicit Neural Representations", "url": "http://arxiv.org/pdf/2210.08772v3", "summary": "Implicit Neural Representations (INRs) encoding continuous multi-media data via multi-layer perceptrons has shown undebatable promise in various computer vision tasks. Despite many successful applications, editing and processing an INR remains intractable as signals are represented by latent parameters of a neural network. Existing works manipulate such continuous representations via processing on their discretized instance, which breaks down the compactness and continuous nature of INR. In this work, we present a pilot study on the question: how to directly modify an INR without explicit decoding? We answer this question by proposing an implicit neural signal processing network, dubbed INSP-Net, via differential operators on INR. Our key insight is that spatial gradients of neural networks can be computed analytically and are invariant to translation, while mathematically we show that any continuous convolution filter can be uniformly approximated by a linear combination of high-order differential operators. With these two knobs, INSP-Net instantiates the signal processing operator as a weighted composition of computational graphs corresponding to the high-order derivatives of INRs, where the weighting parameters can be data-driven learned. Based on our proposed INSP-Net, we further build the first Convolutional Neural Network (CNN) that implicitly runs on INRs, named INSP-ConvNet. Our experiments validate the expressiveness of INSP-Net and INSP-ConvNet in fitting low-level image and geometry processing kernels (e.g. blurring, deblurring, denoising, inpainting, and smoothening) as well as for high-level tasks on implicit fields such as image classification.", "published": "2022-10-17T06:29:07Z", "version": 3}, {"aid": "2210.09446", "authors": ["Stefano B. Blumberg", "Daniele Rav\u00ed", "Mou-Cheng Xu", "Matteo Figini", "Iasonas Kokkinos", "Daniel C. Alexander"], "title": "Deformably-Scaled Transposed Convolution", "url": "http://arxiv.org/pdf/2210.09446v1", "summary": "Transposed convolution is crucial for generating high-resolution outputs, yet has received little attention compared to convolution layers. In this work we revisit transposed convolution and introduce a novel layer that allows us to place information in the image selectively and choose the `stroke breadth' at which the image is synthesized, whilst incurring a small additional parameter cost. For this we introduce three ideas: firstly, we regress offsets to the positions where the transpose convolution results are placed; secondly we broadcast the offset weight locations over a learnable neighborhood; and thirdly we use a compact parametrization to share weights and restrict offsets. We show that simply substituting upsampling operators with our novel layer produces substantial improvements across tasks as diverse as instance segmentation, object detection, semantic segmentation, generative image modeling, and 3D magnetic resonance image enhancement, while outperforming all existing variants of transposed convolutions. Our novel layer can be used as a drop-in replacement for 2D and 3D upsampling operators and the code will be publicly available.", "published": "2022-10-17T21:35:29Z", "version": 1}, {"aid": "2210.09486", "authors": ["Md Mahmudur Rahman", "Rameswar Panda", "Mohammad Arif Ul Alam"], "title": "Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous Learning", "url": "http://arxiv.org/pdf/2210.09486v1", "summary": "We present a new semi-supervised domain adaptation framework that combines a novel auto-encoder-based domain adaptation model with a simultaneous learning scheme providing stable improvements over state-of-the-art domain adaptation models. Our framework holds strong distribution matching property by training both source and target auto-encoders using a novel simultaneous learning scheme on a single graph with an optimally modified MMD loss objective function. Additionally, we design a semi-supervised classification approach by transferring the aligned domain invariant feature spaces from source domain to the target domain. We evaluate on three datasets and show proof that our framework can effectively solve both fragile convergence (adversarial) and weak distribution matching problems between source and target feature space (discrepancy) with a high `speed' of adaptation requiring a very low number of iterations.", "published": "2022-10-18T00:10:11Z", "version": 1}, {"aid": "2210.09655", "authors": ["Chaewon Kim", "Seung-Jun Moon", "Gyeong-Moon Park"], "title": "WINE: Wavelet-Guided GAN Inversion and Editing for High-Fidelity Refinement", "url": "http://arxiv.org/pdf/2210.09655v2", "summary": "Recent advanced GAN inversion models aim to convey high-fidelity information from original images to generators through methods using generator tuning or high-dimensional feature learning. Despite these efforts, accurately reconstructing image-specific details remains as a challenge due to the inherent limitations both in terms of training and structural aspects, leading to a bias towards low-frequency information. In this paper, we look into the widely used pixel loss in GAN inversion, revealing its predominant focus on the reconstruction of low-frequency features. We then propose WINE, a Wavelet-guided GAN Inversion aNd Editing model, which transfers the high-frequency information through wavelet coefficients via newly proposed wavelet loss and wavelet fusion scheme. Notably, WINE is the first attempt to interpret GAN inversion in the frequency domain. Our experimental results showcase the precision of WINE in preserving high-frequency details and enhancing image quality. Even in editing scenarios, WINE outperforms existing state-of-the-art GAN inversion models with a fine balance between editability and reconstruction quality.", "published": "2022-10-18T07:48:59Z", "version": 2}, {"aid": "2210.09765", "authors": ["Fernando Alonso-Fernandez", "Reuben A. Farrugia", "Josef Bigun"], "title": "Very Low-Resolution Iris Recognition Via Eigen-Patch Super-Resolution and Matcher Fusion", "url": "http://arxiv.org/pdf/2210.09765v1", "summary": "Current research in iris recognition is moving towards enabling more relaxed acquisition conditions. This has effects on the quality of acquired images, with low resolution being a predominant issue. Here, we evaluate a super-resolution algorithm used to reconstruct iris images based on Eigen-transformation of local image patches. Each patch is reconstructed separately, allowing better quality of enhanced images by preserving local information. Contrast enhancement is used to improve the reconstruction quality, while matcher fusion has been adopted to improve iris recognition performance. We validate the system using a database of 1,872 near-infrared iris images. The presented approach is superior to bilinear or bicubic interpolation, especially at lower resolutions, and the fusion of the two systems pushes the EER to below 5% for down-sampling factors up to a image size of only 13x13.", "published": "2022-10-18T11:25:19Z", "version": 1}, {"aid": "2210.09879", "authors": ["Jan Niklas B\u00f6hm", "Philipp Berens", "Dmitry Kobak"], "title": "Unsupervised visualization of image datasets using contrastive learning", "url": "http://arxiv.org/pdf/2210.09879v3", "summary": "Visualization methods based on the nearest neighbor graph, such as t-SNE or UMAP, are widely used for visualizing high-dimensional data. Yet, these approaches only produce meaningful results if the nearest neighbors themselves are meaningful. For images represented in pixel space this is not the case, as distances in pixel space are often not capturing our sense of similarity and therefore neighbors are not semantically close. This problem can be circumvented by self-supervised approaches based on contrastive learning, such as SimCLR, relying on data augmentation to generate implicit neighbors, but these methods do not produce two-dimensional embeddings suitable for visualization. Here, we present a new method, called t-SimCNE, for unsupervised visualization of image data. T-SimCNE combines ideas from contrastive learning and neighbor embeddings, and trains a parametric mapping from the high-dimensional pixel space into two dimensions. We show that the resulting 2D embeddings achieve classification accuracy comparable to the state-of-the-art high-dimensional SimCLR representations, thus faithfully capturing semantic relationships. Using t-SimCNE, we obtain informative visualizations of the CIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and highlighting artifacts and outliers.", "published": "2022-10-18T14:13:20Z", "version": 3}, {"aid": "2210.09962", "authors": ["Harshan Baskar", "Anirudh S Chakravarthy", "Prateek Garg", "Divyam Goel", "Abhijith S Raj", "Kshitij Kumar", "Lakshya", "Ravichandra Parvatham", "V Sushant", "Bijay Kumar Rout"], "title": "Nighttime Dehaze-Enhancement", "url": "http://arxiv.org/pdf/2210.09962v1", "summary": "In this paper, we introduce a new computer vision task called nighttime dehaze-enhancement. This task aims to jointly perform dehazing and lightness enhancement. Our task fundamentally differs from nighttime dehazing -- our goal is to jointly dehaze and enhance scenes, while nighttime dehazing aims to dehaze scenes under a nighttime setting. In order to facilitate further research on this task, we release a new benchmark dataset called Reside-$\\beta$ Night dataset, consisting of 4122 nighttime hazed images from 2061 scenes and 2061 ground truth images. Moreover, we also propose a new network called NDENet (Nighttime Dehaze-Enhancement Network), which jointly performs dehazing and low-light enhancement in an end-to-end manner. We evaluate our method on the proposed benchmark and achieve SSIM of 0.8962 and PSNR of 26.25. We also compare our network with other baseline networks on our benchmark to demonstrate the effectiveness of our approach. We believe that nighttime dehaze-enhancement is an essential task particularly for autonomous navigation applications, and hope that our work will open up new frontiers in research. Our dataset and code will be made publicly available upon acceptance of our paper.", "published": "2022-10-18T16:19:25Z", "version": 1}, {"aid": "2210.10107", "authors": ["George F R Ellis"], "title": "Physical Time and Human Time", "url": "http://arxiv.org/pdf/2210.10107v4", "summary": "This is a comment on both Gruber et al (2022) and Bunamano and Rovelli (2022), which discuss the relation between physical time and human time. I claim here, contrary to many views discussed there, that there is no foundational conflict between the way physics views the passage of time and the way the mind/brain perceives it. The problem rather resides in a number of misconceptions leading to the representation of spacetime as a timeless Block Universe. The physical expanding universe is in fact an Evolving Block Universe with a time-dependent future boundary. This establishes a global direction of time that determines local arrows of time. Furthermore time passes when quantum wave function collapse takes place; during this process, information is lost. The mind/brain acts as an imperfect clock, which coarse-grains the physical passage of time along a world line to determine the experienced passage of time, because neuronal processes take time to occur. This happens in a contextual way, so experienced time is not linearly related to physical time in general. Finally I point out that the Universe is never infinitely old: its future endpoint always lies infinitely faraway in the future", "published": "2022-10-18T19:09:05Z", "version": 4}, {"aid": "2210.10205", "authors": ["Eric Luhman", "Troy Luhman"], "title": "Optimizing Hierarchical Image VAEs for Sample Quality", "url": "http://arxiv.org/pdf/2210.10205v1", "summary": "While hierarchical variational autoencoders (VAEs) have achieved great density estimation on image modeling tasks, samples from their prior tend to look less convincing than models with similar log-likelihood. We attribute this to learned representations that over-emphasize compressing imperceptible details of the image. To address this, we introduce a KL-reweighting strategy to control the amount of infor mation in each latent group, and employ a Gaussian output layer to reduce sharpness in the learning objective. To trade off image diversity for fidelity, we additionally introduce a classifier-free guidance strategy for hierarchical VAEs. We demonstrate the effectiveness of these techniques in our experiments. Code is available at https://github.com/tcl9876/visual-vae.", "published": "2022-10-18T23:10:58Z", "version": 1}, {"aid": "2210.10275", "authors": ["Sean Kulinski", "David I. Inouye"], "title": "Towards Explaining Distribution Shifts", "url": "http://arxiv.org/pdf/2210.10275v2", "summary": "A distribution shift can have fundamental consequences such as signaling a change in the operating environment or significantly reducing the accuracy of downstream models. Thus, understanding distribution shifts is critical for examining and hopefully mitigating the effect of such a shift. Most prior work focuses on merely detecting if a shift has occurred and assumes any detected shift can be understood and handled appropriately by a human operator. We hope to aid in these manual mitigation tasks by explaining the distribution shift using interpretable transportation maps from the original distribution to the shifted one. We derive our interpretable mappings from a relaxation of optimal transport, where the candidate mappings are restricted to a set of interpretable mappings. We then inspect multiple quintessential use-cases of distribution shift in real-world tabular, text, and image datasets to showcase how our explanatory mappings provide a better balance between detail and interpretability than baseline explanations by both visual inspection and our PercentExplained metric.", "published": "2022-10-19T03:38:57Z", "version": 2}, {"aid": "2210.10413", "authors": ["Rao Muhammad Umer", "Christian Micheloni"], "title": "Real Image Super-Resolution using GAN through modeling of LR and HR process", "url": "http://arxiv.org/pdf/2210.10413v1", "summary": "The current existing deep image super-resolution methods usually assume that a Low Resolution (LR) image is bicubicly downscaled of a High Resolution (HR) image. However, such an ideal bicubic downsampling process is different from the real LR degradations, which usually come from complicated combinations of different degradation processes, such as camera blur, sensor noise, sharpening artifacts, JPEG compression, and further image editing, and several times image transmission over the internet and unpredictable noises. It leads to the highly ill-posed nature of the inverse upscaling problem. To address these issues, we propose a GAN-based SR approach with learnable adaptive sinusoidal nonlinearities incorporated in LR and SR models by directly learn degradation distributions and then synthesize paired LR/HR training data to train the generalized SR model to real image degradations. We demonstrate the effectiveness of our proposed approach in quantitative and qualitative experiments.", "published": "2022-10-19T09:23:37Z", "version": 1}, {"aid": "2210.10605", "authors": ["Charles Laroche", "Andr\u00e9s Almansa", "Eva Coupet\u00e9", "Matias Tassano"], "title": "Provably Convergent Plug & Play Linearized ADMM, applied to Deblurring Spatially Varying Kernels", "url": "http://arxiv.org/pdf/2210.10605v3", "summary": "Plug & Play methods combine proximal algorithms with denoiser priors to solve inverse problems. These methods rely on the computability of the proximal operator of the data fidelity term. In this paper, we propose a Plug & Play framework based on linearized ADMM that allows us to bypass the computation of intractable proximal operators. We demonstrate the convergence of the algorithm and provide results on restoration tasks such as super-resolution and deblurring with non-uniform blur.", "published": "2022-10-19T14:51:44Z", "version": 3}, {"aid": "2210.10960", "authors": ["Mingi Kwon", "Jaeseok Jeong", "Youngjung Uh"], "title": "Diffusion Models already have a Semantic Latent Space", "url": "http://arxiv.org/pdf/2210.10960v2", "summary": "Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic latent space in frozen pretrained diffusion models. Our semantic latent space, named h-space, has nice properties for accommodating semantic image manipulation: homogeneity, linearity, robustness, and consistency across timesteps. In addition, we introduce a principled design of the generative process for versatile editing and quality boost ing by quantifiable measures: editing strength of an interval and quality deficiency at a timestep. Our method is applicable to various architectures (DDPM++, iD- DPM, and ADM) and datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN- bedroom, and METFACES). Project page: https://kwonminki.github.io/Asyrp/", "published": "2022-10-20T02:07:23Z", "version": 2}, {"aid": "2210.11549", "authors": ["Ziyue Xiang", "Paolo Bestagini", "Stefano Tubaro", "Edward J. Delp"], "title": "H4VDM: H.264 Video Device Matching", "url": "http://arxiv.org/pdf/2210.11549v3", "summary": "Methods that can determine if two given video sequences are captured by the same device (e.g., mobile telephone or digital camera) can be used in many forensics tasks. In this paper we refer to this as \"video device matching\". In open-set video forensics scenarios it is easier to determine if two video sequences were captured with the same device than identifying the specific device. In this paper, we propose a technique for open-set video device matching. Given two H.264 compressed video sequences, our method can determine if they are captured by the same device, even if our method has never encountered the device in training. We denote our proposed technique as H.264 Video Device Matching (H4VDM). H4VDM uses H.264 compression information extracted from video sequences to make decisions. It is more robust against artifacts that alter camera sensor fingerprints, and it can be used to analyze relatively small fragments of the H.264 sequence. We trained and tested our method on a publicly available video forensics dataset consisting of 35 devices, where our proposed method demonstrated good performance.", "published": "2022-10-20T19:31:23Z", "version": 3}, {"aid": "2210.11672", "authors": ["Kyungsu Lee", "Jaeseung Yang", "Haeyun Lee", "Jae Youn Hwang"], "title": "Stochastic Adaptive Activation Function", "url": "http://arxiv.org/pdf/2210.11672v1", "summary": "The simulation of human neurons and neurotransmission mechanisms has been realized in deep neural networks based on the theoretical implementations of activation functions. However, recent studies have reported that the threshold potential of neurons exhibits different values according to the locations and types of individual neurons, and that the activation functions have limitations in terms of representing this variability. Therefore, this study proposes a simple yet effective activation function that facilitates different thresholds and adaptive activations according to the positions of units and the contexts of inputs. Furthermore, the proposed activation function mathematically exhibits a more generalized form of Swish activation function, and thus we denoted it as Adaptive SwisH (ASH). ASH highlights informative features that exhibit large values in the top percentiles in an input, whereas it rectifies low values. Most importantly, ASH exhibits trainable, adaptive, and context-aware properties compared to other activation functions. Furthermore, ASH represents general formula of the previously studied activation function and provides a reasonable mathematical background for the superior performance. To validate the effectiveness and robustness of ASH, we implemented ASH into many deep learning models for various tasks, including classification, detection, segmentation, and image generation. Experimental analysis demonstrates that our activation function can provide the benefits of more accurate prediction and earlier convergence in many deep learning applications.", "published": "2022-10-21T01:57:25Z", "version": 1}, {"aid": "2210.11675", "authors": ["Shuyin Xia", "Xiaoyu Lian", "Guoyin Wang", "Xinbo Gao", "Yabin Shao"], "title": "Granular-Ball Fuzzy Set and Its Implementation in SVM", "url": "http://arxiv.org/pdf/2210.11675v2", "summary": "Most existing fuzzy set methods use points as their input, which is the finest granularity from the perspective of granular computing. Consequently, these methods are neither efficient nor robust to label noise. Therefore, we propose a frame-work called granular-ball fuzzy set by introducing granular-ball computing into fuzzy set. The computational framework is based on the granular-balls input rather than points; therefore, it is more efficient and robust than traditional fuzzy methods, and can be used in various fields of fuzzy data processing according to its extensibility. Furthermore, the framework is extended to the classifier fuzzy support vector machine (FSVM), to derive the granular ball fuzzy SVM (GBFSVM). The experimental results demonstrate the effectiveness and efficiency of GBFSVM.", "published": "2022-10-21T02:03:52Z", "version": 2}, {"aid": "2210.11707", "authors": ["Mayu Otani", "Yale Song", "Yang Wang"], "title": "Video Summarization Overview", "url": "http://arxiv.org/pdf/2210.11707v1", "summary": "With the broad growth of video capturing devices and applications on the web, it is more demanding to provide desired video content for users efficiently. Video summarization facilitates quickly grasping video content by creating a compact summary of videos. Much effort has been devoted to automatic video summarization, and various problem settings and approaches have been proposed. Our goal is to provide an overview of this field. This survey covers early studies as well as recent approaches which take advantage of deep learning techniques. We describe video summarization approaches and their underlying concepts. We also discuss benchmarks and evaluations. We overview how prior work addressed evaluation and detail the pros and cons of the evaluation protocols. Last but not least, we discuss open challenges in this field.", "published": "2022-10-21T03:29:31Z", "version": 1}, {"aid": "2210.12254", "authors": ["Vikram Voleti", "Christopher Pal", "Adam Oberman"], "title": "Score-based Denoising Diffusion with Non-Isotropic Gaussian Noise Models", "url": "http://arxiv.org/pdf/2210.12254v2", "summary": "Generative models based on denoising diffusion techniques have led to an unprecedented increase in the quality and diversity of imagery that is now possible to create with neural generative models. However, most contemporary state-of-the-art methods are derived from a standard isotropic Gaussian formulation. In this work we examine the situation where non-isotropic Gaussian distributions are used. We present the key mathematical derivations for creating denoising diffusion models using an underlying non-isotropic Gaussian noise model. We also provide initial experiments with the CIFAR-10 dataset to help verify empirically that this more general modeling approach can also yield high-quality samples.", "published": "2022-10-21T21:16:46Z", "version": 2}, {"aid": "2210.12523", "authors": ["Athiya Deviyani", "Efe Sinan Hoplamaz", "Alan Savio Paul"], "title": "How Real is Real: Evaluating the Robustness of Real-World Super Resolution", "url": "http://arxiv.org/pdf/2210.12523v1", "summary": "Image super-resolution (SR) is a field in computer vision that focuses on reconstructing high-resolution images from the respective low-resolution image. However, super-resolution is a well-known ill-posed problem as most methods rely on the downsampling method performed on the high-resolution image to form the low-resolution image to be known. Unfortunately, this is not something that is available in real-life super-resolution applications such as increasing the quality of a photo taken on a mobile phone. In this paper we will evaluate multiple state-of-the-art super-resolution methods and gauge their performance when presented with various types of real-life images and discuss the benefits and drawbacks of each method. We also introduce a novel dataset, WideRealSR, containing real images from a wide variety of sources. Finally, through careful experimentation and evaluation, we will present a potential solution to alleviate the generalization problem which is imminent in most state-of-the-art super-resolution models.", "published": "2022-10-22T18:53:45Z", "version": 1}, {"aid": "2210.13461", "authors": ["Rajesh P. N. Rao", "Dimitrios C. Gklezakos", "Vishwas Sathish"], "title": "Active Predictive Coding: A Unified Neural Framework for Learning Hierarchical World Models for Perception and Planning", "url": "http://arxiv.org/pdf/2210.13461v1", "summary": "Predictive coding has emerged as a prominent model of how the brain learns through predictions, anticipating the importance accorded to predictive learning in recent AI architectures such as transformers. Here we propose a new framework for predictive coding called active predictive coding which can learn hierarchical world models and solve two radically different open problems in AI: (1) how do we learn compositional representations, e.g., part-whole hierarchies, for equivariant vision? and (2) how do we solve large-scale planning problems, which are hard for traditional reinforcement learning, by composing complex action sequences from primitive policies? Our approach exploits hypernetworks, self-supervised learning and reinforcement learning to learn hierarchical world models that combine task-invariant state transition networks and task-dependent policy networks at multiple abstraction levels. We demonstrate the viability of our approach on a variety of vision datasets (MNIST, FashionMNIST, Omniglot) as well as on a scalable hierarchical planning problem. Our results represent, to our knowledge, the first demonstration of a unified solution to the part-whole learning problem posed by Hinton, the nested reference frames problem posed by Hawkins, and the integrated state-action hierarchy learning problem in reinforcement learning.", "published": "2022-10-23T05:44:22Z", "version": 1}, {"aid": "2210.12746", "authors": ["Rozenn Dahyot"], "title": "Principal Component Classification", "url": "http://arxiv.org/pdf/2210.12746v2", "summary": "We propose to directly compute classification estimates by learning features encoded with their class scores using PCA. Our resulting model has a encoder-decoder structure suitable for supervised learning, it is computationally efficient and performs well for classification on several datasets.", "published": "2022-10-23T15:05:14Z", "version": 2}, {"aid": "2210.12761", "authors": ["Karl Friston", "Lancelot Da Costa", "Dalton A. R. Sakthivadivel", "Conor Heins", "Grigorios A. Pavliotis", "Maxwell Ramstead", "Thomas Parr"], "title": "Path integrals, particular kinds, and strange things", "url": "http://arxiv.org/pdf/2210.12761v3", "summary": "This paper describes a path integral formulation of the free energy principle. The ensuing account expresses the paths or trajectories that a particle takes as it evolves over time. The main results are a method or principle of least action that can be used to emulate the behaviour of particles in open exchange with their external milieu. Particles are defined by a particular partition, in which internal states are individuated from external states by active and sensory blanket states. The variational principle at hand allows one to interpret internal dynamics - of certain kinds of particles - as inferring external states that are hidden behind blanket states. We consider different kinds of particles, and to what extent they can be imbued with an elementary form of inference or sentience. Specifically, we consider the distinction between dissipative and conservative particles, inert and active particles and, finally, ordinary and strange particles. Strange particles can be described as inferring their own actions, endowing them with apparent autonomy or agency. In short - of the kinds of particles afforded by a particular partition - strange kinds may be apt for describing sentient behaviour.", "published": "2022-10-23T16:01:16Z", "version": 3}, {"aid": "2210.13545", "authors": ["Julius Ott", "Lorenzo Servadei", "Jose Arjona-Medina", "Enrico Rinaldi", "Gianfranco Mauro", "Daniela S\u00e1nchez Lopera", "Michael Stephan", "Thomas Stadelmayer", "Avik Santra", "Robert Wille"], "title": "MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling", "url": "http://arxiv.org/pdf/2210.13545v2", "summary": "Data selection is essential for any data-based optimization technique, such as Reinforcement Learning. State-of-the-art sampling strategies for the experience replay buffer improve the performance of the Reinforcement Learning agent. However, they do not incorporate uncertainty in the Q-Value estimation. Consequently, they cannot adapt the sampling strategies, including exploration and exploitation of transitions, to the complexity of the task. To address this, this paper proposes a new sampling strategy that leverages the exploration-exploitation trade-off. This is enabled by the uncertainty estimation of the Q-Value function, which guides the sampling to explore more significant transitions and, thus, learn a more efficient policy. Experiments on classical control environments demonstrate stable results across various environments. They show that the proposed method outperforms state-of-the-art sampling strategies for dense rewards w.r.t. convergence and peak performance by 26% on average.", "published": "2022-10-24T18:55:41Z", "version": 2}, {"aid": "2210.13564", "authors": ["Alfonso Nieto-Castanon"], "title": "Preparing fMRI Data for Statistical Analysis", "url": "http://arxiv.org/pdf/2210.13564v1", "summary": "This chapter describes several procedures used to prepare fMRI data for statistical analyses. It includes the description of common preprocessing steps, such as spatial realignment, coregistration, and spatial normalization, aimed at the spatial alignment of all fMRI data within- and between- subjects, as well as several denoising procedures aimed at minimizing the impact of common noise sources, including physiological and residual subject motion effects, on the BOLD signal time series. The chapter ends with a description of quality control procedures recommended for detecting potential problems in the fMRI data and evaluating its suitability for subsequent statistical analyses.", "published": "2022-10-24T19:38:45Z", "version": 1}, {"aid": "2210.14219", "authors": ["Pavol Harar", "Dennis Elbr\u00e4chter", "Monika D\u00f6rfler", "Kory D. Johnson"], "title": "Redistributor: Transforming Empirical Data Distributions", "url": "http://arxiv.org/pdf/2210.14219v2", "summary": "We present an algorithm and package, Redistributor, which forces a collection of scalar samples to follow a desired distribution. When given independent and identically distributed samples of some random variable $S$ and the continuous cumulative distribution function of some desired target $T$, it provably produces a consistent estimator of the transformation $R$ which satisfies $R(S)=T$ in distribution. As the distribution of $S$ or $T$ may be unknown, we also include algorithms for efficiently estimating these distributions from samples. This allows for various interesting use cases in image processing, where Redistributor serves as a remarkably simple and easy-to-use tool that is capable of producing visually appealing results. For color correction it outperforms other model-based methods and excels in achieving photorealistic style transfer, surpassing deep learning methods in content preservation. The package is implemented in Python and is optimized to efficiently handle large datasets, making it also suitable as a preprocessing step in machine learning. The source code is available at https://github.com/paloha/redistributor.", "published": "2022-10-25T17:59:03Z", "version": 2}, {"aid": "2210.14907", "authors": ["Pouria Mistani", "Samira Pakravan", "Rajesh Ilango", "Sanjay Choudhry", "Frederic Gibou"], "title": "Neuro-symbolic partial differential equation solver", "url": "http://arxiv.org/pdf/2210.14907v1", "summary": "We present a highly scalable strategy for developing mesh-free neuro-symbolic partial differential equation solvers from existing numerical discretizations found in scientific computing. This strategy is unique in that it can be used to efficiently train neural network surrogate models for the solution functions and the differential operators, while retaining the accuracy and convergence properties of state-of-the-art numerical solvers. This neural bootstrapping method is based on minimizing residuals of discretized differential systems on a set of random collocation points with respect to the trainable parameters of the neural network, achieving unprecedented resolution and optimal scaling for solving physical and biological systems.", "published": "2022-10-25T22:56:43Z", "version": 1}, {"aid": "2210.14491", "authors": ["Hana Hebishima", "Mina Arakaki", "Chikako Dozono", "Hanna Frolova", "Shinichi Inage"], "title": "Mathematical definition of public language, and modeling of will and consciousness based on the public language", "url": "http://arxiv.org/pdf/2210.14491v1", "summary": "To propose a mathematical model of consciousness and will, we first simulated the inverted qualia with a toy model of a neural network. As a result, we confirmed that there can be an inverted qualia on the neural network. In other words, the qualia were individual-dependent and considered difficult as an indicator of consciousness and will. To solve that difficulty, we introduce a probability space and a random variable into a set of qualia and define a public language for events. Based on this idea of public language, consciousness and will are modeled. In this proposal, future actions are randomly selected from the comparison between \"recognition of events\" by external observation and past episodic memory, and the actual \"recognition of actions\" is regarded as the occurrence of consciousness. The basic formula is also derived. This proposal is compared with other past philosophical discussions.", "published": "2022-10-26T05:32:27Z", "version": 1}, {"aid": "2211.08408", "authors": ["Nikolay Manchev", "Michael Spratling"], "title": "On the biological plausibility of orthogonal initialisation for solving gradient instability in deep neural networks", "url": "http://arxiv.org/pdf/2211.08408v1", "summary": "Initialising the synaptic weights of artificial neural networks (ANNs) with orthogonal matrices is known to alleviate vanishing and exploding gradient problems. A major objection against such initialisation schemes is that they are deemed biologically implausible as they mandate factorization techniques that are difficult to attribute to a neurobiological process. This paper presents two initialisation schemes that allow a network to naturally evolve its weights to form orthogonal matrices, provides theoretical analysis that pre-training orthogonalisation always converges, and empirically confirms that the proposed schemes outperform randomly initialised recurrent and feedforward networks.", "published": "2022-10-27T06:08:06Z", "version": 1}, {"aid": "2211.05567", "authors": ["Shudong Huang", "Wentao Feng", "Chenwei Tang", "Jiancheng Lv"], "title": "Partial Differential Equations Meet Deep Neural Networks: A Survey", "url": "http://arxiv.org/pdf/2211.05567v2", "summary": "Many problems in science and engineering can be represented by a set of partial differential equations (PDEs) through mathematical modeling. Mechanism-based computation following PDEs has long been an essential paradigm for studying topics such as computational fluid dynamics, multiphysics simulation, molecular dynamics, or even dynamical systems. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. At the same time, solving PDEs efficiently has been a long-standing challenge. Generally, except for a few differential equations for which analytical solutions are directly available, many more equations must rely on numerical approaches such as the finite difference method, finite element method, finite volume method, and boundary element method to be solved approximately. These numerical methods usually divide a continuous problem domain into discrete points and then concentrate on solving the system at each of those points. Though the effectiveness of these traditional numerical methods, the vast number of iterative operations accompanying each step forward significantly reduces the efficiency. Recently, another equally important paradigm, data-based computation represented by deep learning, has emerged as an effective means of solving PDEs. Surprisingly, a comprehensive review for this interesting subfield is still lacking. This survey aims to categorize and review the current progress on Deep Neural Networks (DNNs) for PDEs. We discuss the literature published in this subfield over the past decades and present them in a common taxonomy, followed by an overview and classification of applications of these related methods in scientific research and engineering scenarios. The origin, developing history, character, sort, as well as the future trends in each potential direction of this subfield are also introduced.", "published": "2022-10-27T07:01:56Z", "version": 2}, {"aid": "2210.15818", "authors": ["Salman Mohamadi", "Gianfranco Doretto", "Donald A. Adjeroh"], "title": "FUSSL: Fuzzy Uncertain Self Supervised Learning", "url": "http://arxiv.org/pdf/2210.15818v1", "summary": "Self supervised learning (SSL) has become a very successful technique to harness the power of unlabeled data, with no annotation effort. A number of developed approaches are evolving with the goal of outperforming supervised alternatives, which have been relatively successful. One main issue in SSL is robustness of the approaches under different settings. In this paper, for the first time, we recognize the fundamental limits of SSL coming from the use of a single-supervisory signal. To address this limitation, we leverage the power of uncertainty representation to devise a robust and general standard hierarchical learning/training protocol for any SSL baseline, regardless of their assumptions and approaches. Essentially, using the information bottleneck principle, we decompose feature learning into a two-stage training procedure, each with a distinct supervision signal. This double supervision approach is captured in two key steps: 1) invariance enforcement to data augmentation, and 2) fuzzy pseudo labeling (both hard and soft annotation). This simple, yet, effective protocol which enables cross-class/cluster feature learning, is instantiated via an initial training of an ensemble of models through invariance enforcement to data augmentation as first training phase, and then assigning fuzzy labels to the original samples for the second training phase. We consider multiple alternative scenarios with double supervision and evaluate the effectiveness of our approach on recent baselines, covering four different SSL paradigms, including geometrical, contrastive, non-contrastive, and hard/soft whitening (redundancy reduction) baselines. Extensive experiments under multiple settings show that the proposed training protocol consistently improves the performance of the former baselines, independent of their respective underlying principles.", "published": "2022-10-28T01:06:10Z", "version": 1}, {"aid": "2210.15957", "authors": ["Gagan Acharya", "Sebastian F. Ruf", "Erfan Nozari"], "title": "Brain Modeling for Control: A Review", "url": "http://arxiv.org/pdf/2210.15957v1", "summary": "Neurostimulation technologies have seen a recent surge in interest from the neuroscience and controls communities alike due to their proven potential to treat conditions such as Parkinson's Disease, and depression. The provided stimulation can be of different types, such as electric, and optogenetic, and is generally applied to a specific region of the brain in order to drive the local and/or global dynamics to a desired state of (in)activity. However, an underlying theoretical understanding of the efficacy of neurostimulation is still lacking. From a control-theoretic perspective, it is important to understand how each stimulus modality interacts with the complex brain network in order to assess the controllability of the system and develop neurophysiologically relevant computational models that can be used to design the stimulation profile in a closed-loop manner. In this paper, we review the computational modeling studies of (i) deep brain stimulation, (ii) transcranial magnetic stimulation, (iii) direct current stimulation, (iv) transcranial electrical stimulation, and (v) optogenetics as five of the most popular neurostimulation technologies in research and clinical settings. For each technology, we split the reviewed studies into (a)theory-driven biophysical models capturing the low-level physics of the interactions between the stimulation source and neuronal tissue, (b) data-driven stimulus-response models which capture the end-to-end effects of stimulation on various biomarkers of interest and (c) data-driven dynamical system models that extract the precise dynamics of the brain's response to neurostimulation from neural data. While our focus is particularly on the latter category due to their greater utility in control design, we review key works in the former two categories as the basis and context in which dynamical system models have been and will be developed.", "published": "2022-10-28T07:23:31Z", "version": 1}, {"aid": "2210.16046", "authors": ["Masakazu Yoshimura", "Junji Otsuka", "Atsushi Irie", "Takeshi Ohashi"], "title": "Rawgment: Noise-Accounted RAW Augmentation Enables Recognition in a Wide Variety of Environments", "url": "http://arxiv.org/pdf/2210.16046v2", "summary": "Image recognition models that work in challenging environments (e.g., extremely dark, blurry, or high dynamic range conditions) must be useful. However, creating training datasets for such environments is expensive and hard due to the difficulties of data collection and annotation. It is desirable if we could get a robust model without the need for hard-to-obtain datasets. One simple approach is to apply data augmentation such as color jitter and blur to standard RGB (sRGB) images in simple scenes. Unfortunately, this approach struggles to yield realistic images in terms of pixel intensity and noise distribution due to not considering the non-linearity of Image Signal Processors (ISPs) and noise characteristics of image sensors. Instead, we propose a noise-accounted RAW image augmentation method. In essence, color jitter and blur augmentation are applied to a RAW image before applying non-linear ISP, resulting in realistic intensity. Furthermore, we introduce a noise amount alignment method that calibrates the domain gap in the noise property caused by the augmentation. We show that our proposed noise-accounted RAW augmentation method doubles the image recognition accuracy in challenging environments only with simple training data.", "published": "2022-10-28T10:33:45Z", "version": 2}, {"aid": "2211.01177", "authors": ["Gautam Singh", "Yeongbin Kim", "Sungjin Ahn"], "title": "Neural Systematic Binder", "url": "http://arxiv.org/pdf/2211.01177v3", "summary": "The key to high-level cognition is believed to be the ability to systematically manipulate and compose knowledge pieces. While token-like structured knowledge representations are naturally provided in text, it is elusive how to obtain them for unstructured modalities such as scene images. In this paper, we propose a neural mechanism called Neural Systematic Binder or SysBinder for constructing a novel structured representation called Block-Slot Representation. In Block-Slot Representation, object-centric representations known as slots are constructed by composing a set of independent factor representations called blocks, to facilitate systematic generalization. SysBinder obtains this structure in an unsupervised way by alternatingly applying two different binding principles: spatial binding for spatial modularity across the full scene and factor binding for factor modularity within an object. SysBinder is a simple, deterministic, and general-purpose layer that can be applied as a drop-in module in any arbitrary neural network and on any modality. In experiments, we find that SysBinder provides significantly better factor disentanglement within the slots than the conventional object-centric methods, including, for the first time, in visually complex scene images such as CLEVR-Tex. Furthermore, we demonstrate factor-level systematicity in controlled scene generation by decoding unseen factor combinations.", "published": "2022-11-02T14:53:07Z", "version": 3}, {"aid": "2211.02144", "authors": ["Pablo Barcel\u00f3", "Mauricio Duarte", "Crist\u00f3bal Rojas", "Tomasz Steifer"], "title": "No Agreement Without Loss: Learning and Social Choice in Peer Review", "url": "http://arxiv.org/pdf/2211.02144v2", "summary": "In peer review systems, reviewers are often asked to evaluate various features of submissions, such as technical quality or novelty. A score is given to each of the predefined features and based on these the reviewer has to provide an overall quantitative recommendation. It may be assumed that each reviewer has her own mapping from the set of features to a recommendation, and that different reviewers have different mappings in mind. This introduces an element of arbitrariness known as commensuration bias. In this paper we discuss a framework, introduced by Noothigattu, Shah and Procaccia, and then applied by the organizers of the AAAI 2022 conference. Noothigattu, Shah and Procaccia proposed to aggregate reviewer's mapping by minimizing certain loss functions, and studied axiomatic properties of this approach, in the sense of social choice theory. We challenge several of the results and assumptions used in their work and report a number of negative results. On the one hand, we study a trade-off between some of the axioms proposed and the ability of the method to properly capture agreements of the majority of reviewers. On the other hand, we show that dropping a certain unrealistic assumption has dramatic effects, including causing the method to be discontinuous.", "published": "2022-11-03T21:03:23Z", "version": 2}, {"aid": "2211.02255", "authors": ["Kaiwen Hou", "Guillaume Rabusseau"], "title": "Spectral Regularization: an Inductive Bias for Sequence Modeling", "url": "http://arxiv.org/pdf/2211.02255v1", "summary": "Various forms of regularization in learning tasks strive for different notions of simplicity. This paper presents a spectral regularization technique, which attaches a unique inductive bias to sequence modeling based on an intuitive concept of simplicity defined in the Chomsky hierarchy. From fundamental connections between Hankel matrices and regular grammars, we propose to use the trace norm of the Hankel matrix, the tightest convex relaxation of its rank, as the spectral regularizer. To cope with the fact that the Hankel matrix is bi-infinite, we propose an unbiased stochastic estimator for its trace norm. Ultimately, we demonstrate experimental results on Tomita grammars, which exhibit the potential benefits of spectral regularization and validate the proposed stochastic estimator.", "published": "2022-11-04T04:07:05Z", "version": 1}, {"aid": "2211.02272", "authors": ["Ali Borji"], "title": "Logits are predictive of network type", "url": "http://arxiv.org/pdf/2211.02272v1", "summary": "We show that it is possible to predict which deep network has generated a given logit vector with accuracy well above chance. We utilize a number of networks on a dataset, initialized with random weights or pretrained weights, as well as fine-tuned networks. A classifier is then trained on the logit vectors of the trained set of this dataset to map the logit vector to the network index that has generated it. The classifier is then evaluated on the test set of the dataset. Results are better with randomly initialized networks, but also generalize to pretrained networks as well as fine-tuned ones. Classification accuracy is higher using unnormalized logits than normalized ones. We find that there is little transfer when applying a classifier to the same networks but with different sets of weights. In addition to help better understand deep networks and the way they encode uncertainty, we anticipate our finding to be useful in some applications (e.g. tailoring an adversarial attack for a certain type of network). Code is available at https://github.com/aliborji/logits.", "published": "2022-11-04T05:53:27Z", "version": 1}, {"aid": "2211.02386", "authors": ["Xinxin Wang", "Guanzhong Wang", "Qingqing Dang", "Yi Liu", "Xiaoguang Hu", "Dianhai Yu"], "title": "PP-YOLOE-R: An Efficient Anchor-Free Rotated Object Detector", "url": "http://arxiv.org/pdf/2211.02386v1", "summary": "Arbitrary-oriented object detection is a fundamental task in visual scenes involving aerial images and scene text. In this report, we present PP-YOLOE-R, an efficient anchor-free rotated object detector based on PP-YOLOE. We introduce a bag of useful tricks in PP-YOLOE-R to improve detection precision with marginal extra parameters and computational cost. As a result, PP-YOLOE-R-l and PP-YOLOE-R-x achieve 78.14 and 78.28 mAP respectively on DOTA 1.0 dataset with single-scale training and testing, which outperform almost all other rotated object detectors. With multi-scale training and testing, PP-YOLOE-R-l and PP-YOLOE-R-x further improve the detection precision to 80.02 and 80.73 mAP. In this case, PP-YOLOE-R-x surpasses all anchor-free methods and demonstrates competitive performance to state-of-the-art anchor-based two-stage models. Further, PP-YOLOE-R is deployment friendly and PP-YOLOE-R-s/m/l/x can reach 69.8/55.1/48.3/37.1 FPS respectively on RTX 2080 Ti with TensorRT and FP16-precision. Source code and pre-trained models are available at https://github.com/PaddlePaddle/PaddleDetection, which is powered by https://github.com/PaddlePaddle/Paddle.", "published": "2022-11-04T11:38:30Z", "version": 1}, {"aid": "2211.02578", "authors": ["Luis Oala", "Marco Aversa", "Gabriel Nobis", "Kurt Willis", "Yoan Neuenschwander", "Mich\u00e8le Buck", "Christian Matek", "Jerome Extermann", "Enrico Pomarico", "Wojciech Samek", "Roderick Murray-Smith", "Christoph Clausen", "Bruno Sanguinetti"], "title": "Data Models for Dataset Drift Controls in Machine Learning With Optical Images", "url": "http://arxiv.org/pdf/2211.02578v3", "summary": "Camera images are ubiquitous in machine learning research. They also play a central role in the delivery of important services spanning medicine and environmental surveying. However, the application of machine learning models in these domains has been limited because of robustness concerns. A primary failure mode are performance drops due to differences between the training and deployment data. While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, existing approaches do not account for explicit models of the primary object of interest: the data. This limits our ability to study and understand the relationship between data generation and downstream machine learning model performance in a physically accurate manner. In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can be constructed for image data and used to control downstream machine learning model performance related to dataset drift. The findings are distilled into three applications. First, drift synthesis enables the controlled generation of physically faithful drift test cases to power model selection and targeted generalization. Second, the gradient connection between machine learning task model and data model allows advanced, precise tolerancing of task model sensitivity to changes in the data generation. These drift forensics can be used to precisely specify the acceptable data environments in which a task model may be run. Third, drift optimization opens up the possibility to create drifts that can help the task model learn better faster, effectively optimizing the data generating process itself. A guide to access the open code and datasets is available at https://github.com/aiaudit-org/raw2logit.", "published": "2022-11-04T16:50:10Z", "version": 3}, {"aid": "2211.02633", "authors": ["Gyuhak Kim", "Changnan Xiao", "Tatsuya Konishi", "Zixuan Ke", "Bing Liu"], "title": "A Theoretical Study on Solving Continual Learning", "url": "http://arxiv.org/pdf/2211.02633v1", "summary": "Continual learning (CL) learns a sequence of tasks incrementally. There are two popular CL settings, class incremental learning (CIL) and task incremental learning (TIL). A major challenge of CL is catastrophic forgetting (CF). While a number of techniques are already available to effectively overcome CF for TIL, CIL remains to be highly challenging. So far, little theoretical study has been done to provide a principled guidance on how to solve the CIL problem. This paper performs such a study. It first shows that probabilistically, the CIL problem can be decomposed into two sub-problems: Within-task Prediction (WP) and Task-id Prediction (TP). It further proves that TP is correlated with out-of-distribution (OOD) detection, which connects CIL and OOD detection. The key conclusion of this study is that regardless of whether WP and TP or OOD detection are defined explicitly or implicitly by a CIL algorithm, good WP and good TP or OOD detection are necessary and sufficient for good CIL performances. Additionally, TIL is simply WP. Based on the theoretical result, new CIL methods are also designed, which outperform strong baselines in both CIL and TIL settings by a large margin.", "published": "2022-11-04T17:45:55Z", "version": 1}, {"aid": "2211.02695", "authors": ["Hadi Salman", "Caleb Parks", "Shi Yin Hong", "Justin Zhan"], "title": "WaveNets: Wavelet Channel Attention Networks", "url": "http://arxiv.org/pdf/2211.02695v2", "summary": "Channel Attention reigns supreme as an effective technique in the field of computer vision. However, the proposed channel attention by SENet suffers from information loss in feature learning caused by the use of Global Average Pooling (GAP) to represent channels as scalars. Thus, designing effective channel attention mechanisms requires finding a solution to enhance features preservation in modeling channel inter-dependencies. In this work, we utilize Wavelet transform compression as a solution to the channel representation problem. We first test wavelet transform as an Auto-Encoder model equipped with conventional channel attention module. Next, we test wavelet transform as a standalone channel compression method. We prove that global average pooling is equivalent to the recursive approximate Haar wavelet transform. With this proof, we generalize channel attention using Wavelet compression and name it WaveNet. Implementation of our method can be embedded within existing channel attention methods with a couple of lines of code. We test our proposed method using ImageNet dataset for image classification task. Our method outperforms the baseline SENet, and achieves the state-of-the-art results. Our code implementation is publicly available at https://github.com/hady1011/WaveNet-C.", "published": "2022-11-04T18:26:47Z", "version": 2}, {"aid": "2211.02831", "authors": ["Tao Wang", "Kaihao Zhang", "Jiankang Deng", "Tong Lu", "Wei Liu", "Stefanos Zafeiriou"], "title": "Deep Face Restoration: A Survey", "url": "http://arxiv.org/pdf/2211.02831v2", "summary": "Face Restoration (FR) aims to restore High-Quality (HQ) faces from Low-Quality (LQ) input images, which is a domain-specific image restoration problem in the low-level computer vision area. The early face restoration methods mainly use statistical priors and degradation models, which are difficult to meet the requirements of real-world applications in practice. In recent years, face restoration has witnessed great progress after stepping into the deep learning era. However, there are few works to systematically study the deep learning based face restoration methods. Thus, in this paper, we provide a comprehensive survey of recent advances in deep learning techniques for face restoration. Specifically, we first summarize different problem formulations and analyze the characteristics of face images. Second, we discuss the challenges of face restoration. With regard to these challenges, we present a comprehensive review of recent FR methods, including prior-based methods and deep-learning methods. Then, we explore developed techniques in the task of FR covering network architectures, loss functions, and benchmark datasets. We also conduct a systematic benchmark evaluation on representative methods. Finally, we discuss the future directions including network designs, metrics, benchmark datasets, applications, etc. We also provide an open source repository for all the discussed methods, which is available at https://github.com/TaoWangzj/Awesome-Face-Restoration.", "published": "2022-11-05T07:08:15Z", "version": 2}, {"aid": "2211.02947", "authors": ["Sanchar Palit", "Biplab Banerjee", "Subhasis Chaudhuri"], "title": "Prototypical quadruplet for few-shot class incremental learning", "url": "http://arxiv.org/pdf/2211.02947v3", "summary": "Scarcity of data and incremental learning of new tasks pose two major bottlenecks for many modern computer vision algorithms. The phenomenon of catastrophic forgetting, i.e., the model's inability to classify previously learned data after training with new batches of data, is a major challenge. Conventional methods address catastrophic forgetting while compromising the current session's training. Generative replay-based approaches, such as generative adversarial networks (GANs), have been proposed to mitigate catastrophic forgetting, but training GANs with few samples may lead to instability. To address these challenges, we propose a novel method that improves classification robustness by identifying a better embedding space using an improved contrasting loss. Our approach retains previously acquired knowledge in the embedding space, even when trained with new classes, by updating previous session class prototypes to represent the true class mean, which is crucial for our nearest class mean classification strategy. We demonstrate the effectiveness of our method by showing that the embedding space remains intact after training the model with new classes and outperforms existing state-of-the-art algorithms in terms of accuracy across different sessions.", "published": "2022-11-05T17:19:14Z", "version": 3}, {"aid": "2211.03019", "authors": ["Dennis Fedorishin", "Deen Dayal Mohan", "Bhavin Jawade", "Srirangaraj Setlur", "Venu Govindaraju"], "title": "Hear The Flow: Optical Flow-Based Self-Supervised Visual Sound Source Localization", "url": "http://arxiv.org/pdf/2211.03019v1", "summary": "Learning to localize the sound source in videos without explicit annotations is a novel area of audio-visual research. Existing work in this area focuses on creating attention maps to capture the correlation between the two modalities to localize the source of the sound. In a video, oftentimes, the objects exhibiting movement are the ones generating the sound. In this work, we capture this characteristic by modeling the optical flow in a video as a prior to better aid in localizing the sound source. We further demonstrate that the addition of flow-based attention substantially improves visual sound source localization. Finally, we benchmark our method on standard sound source localization datasets and achieve state-of-the-art performance on the Soundnet Flickr and VGG Sound Source datasets. Code: https://github.com/denfed/heartheflow.", "published": "2022-11-06T03:48:45Z", "version": 1}, {"aid": "2211.03989", "authors": ["Yifei Zhou", "Zilu Li", "Abhinav Shrivastava", "Hengshuang Zhao", "Antonio Torralba", "Taipeng Tian", "Ser-Nam Lim"], "title": "$BT^2$: Backward-compatible Training with Basis Transformation", "url": "http://arxiv.org/pdf/2211.03989v3", "summary": "Modern retrieval system often requires recomputing the representation of every piece of data in the gallery when updating to a better representation model. This process is known as backfilling and can be especially costly in the real world where the gallery often contains billions of samples. Recently, researchers have proposed the idea of Backward Compatible Training (BCT) where the new representation model can be trained with an auxiliary loss to make it backward compatible with the old representation. In this way, the new representation can be directly compared with the old representation, in principle avoiding the need for any backfilling. However, followup work shows that there is an inherent tradeoff where a backward compatible representation model cannot simultaneously maintain the performance of the new model itself. This paper reports our ``not-so-surprising'' finding that adding extra dimensions to the representation can help here. However, we also found that naively increasing the dimension of the representation did not work. To deal with this, we propose Backward-compatible Training with a novel Basis Transformation ($BT^2$). A basis transformation (BT) is basically a learnable set of parameters that applies an orthonormal transformation. Such a transformation possesses an important property whereby the original information contained in its input is retained in its output. We show in this paper how a BT can be utilized to add only the necessary amount of additional dimensions. We empirically verify the advantage of $BT^2$ over other state-of-the-art methods in a wide range of settings. We then further extend $BT^2$ to other challenging yet more practical settings, including significant change in model architecture (CNN to Transformers), modality change, and even a series of updates in the model architecture mimicking the evolution of deep learning models.", "published": "2022-11-08T04:00:23Z", "version": 3}, {"aid": "2211.04049", "authors": ["Moritz Schubotz", "Ankit Satpute", "Andre Greiner-Petter", "Akiko Aizawa", "Bela Gipp"], "title": "Caching and Reproducibility: Making Data Science experiments faster and FAIRer", "url": "http://arxiv.org/pdf/2211.04049v2", "summary": "Small to medium-scale data science experiments often rely on research software developed ad-hoc by individual scientists or small teams. Often there is no time to make the research software fast, reusable, and open access. The consequence is twofold. First, subsequent researchers must spend significant work hours building upon the proposed hypotheses or experimental framework. In the worst case, others cannot reproduce the experiment and reuse the findings for subsequent research. Second, suppose the ad-hoc research software fails during often long-running computationally expensive experiments. In that case, the overall effort to iteratively improve the software and rerun the experiments creates significant time pressure on the researchers. We suggest making caching an integral part of the research software development process, even before the first line of code is written. This article outlines caching recommendations for developing research software in data science projects. Our recommendations provide a perspective to circumvent common problems such as propriety dependence, speed, etc. At the same time, caching contributes to the reproducibility of experiments in the open science workflow. Concerning the four guiding principles, i.e., Findability, Accessibility, Interoperability, and Reusability (FAIR), we foresee that including the proposed recommendation in a research software development will make the data related to that software FAIRer for both machines and humans. We exhibit the usefulness of some of the proposed recommendations on our recently completed research software project in mathematical information retrieval.", "published": "2022-11-08T07:11:02Z", "version": 2}, {"aid": "2211.04700", "authors": ["Zhao Zhang", "Suiyi Zhao", "Xiaojie Jin", "Mingliang Xu", "Yi Yang", "Shuicheng Yan", "Meng Wang"], "title": "Noise Self-Regression: A New Learning Paradigm to Enhance Low-Light Images Without Task-Related Data", "url": "http://arxiv.org/pdf/2211.04700v3", "summary": "Deep learning-based low-light image enhancement (LLIE) is a task of leveraging deep neural networks to enhance the image illumination while keeping the image content unchanged. From the perspective of training data, existing methods complete the LLIE task driven by one of the following three data types: paired data, unpaired data and zero-reference data. Each type of these data-driven methods has its own advantages, e.g., zero-reference data-based methods have very low requirements on training data and can meet the human needs in many scenarios. In this paper, we leverage pure Gaussian noise to complete the LLIE task, which further reduces the requirements for training data in LLIE tasks and can be used as another alternative in practical use. Specifically, we propose Noise SElf-Regression (NoiSER) without access to any task-related data, simply learns a convolutional neural network equipped with an instance-normalization layer by taking a random noise image, $\\mathcal{N}(0,\\sigma^2)$ for each pixel, as both input and output for each training pair, and then the low-light image is fed to the trained network for predicting the normal-light image. Technically, an intuitive explanation for its effectiveness is as follows: 1) the self-regression reconstructs the contrast between adjacent pixels of the input image, 2) the instance-normalization layer may naturally remediate the overall magnitude/lighting of the input image, and 3) the $\\mathcal{N}(0,\\sigma^2)$ assumption for each pixel enforces the output image to follow the well-known gray-world hypothesis when the image size is big enough. Compared to current state-of-the-art LLIE methods with access to different task-related data, NoiSER is highly competitive in enhancement quality, yet with a much smaller model size, and much lower training and inference cost. Besides, NoiSER also excels in mitigating overexposure and handling joint tasks.", "published": "2022-11-09T06:18:18Z", "version": 3}, {"aid": "2211.05018", "authors": ["Matthew Aquilina", "Keith George Ciantar", "Christian Galea", "Kenneth P. Camilleri", "Reuben A. Farrugia", "John Abela"], "title": "The Best of Both Worlds: a Framework for Combining Degradation Prediction with High Performance Super-Resolution Networks", "url": "http://arxiv.org/pdf/2211.05018v1", "summary": "To date, the best-performing blind super-resolution (SR) techniques follow one of two paradigms: A) generate and train a standard SR network on synthetic low-resolution - high-resolution (LR - HR) pairs or B) attempt to predict the degradations an LR image has suffered and use these to inform a customised SR network. Despite significant progress, subscribers to the former miss out on useful degradation information that could be used to improve the SR process. On the other hand, followers of the latter rely on weaker SR networks, which are significantly outperformed by the latest architectural advancements. In this work, we present a framework for combining any blind SR prediction mechanism with any deep SR network, using a metadata insertion block to insert prediction vectors into SR network feature maps. Through comprehensive testing, we prove that state-of-the-art contrastive and iterative prediction schemes can be successfully combined with high-performance SR networks such as RCAN and HAN within our framework. We show that our hybrid models consistently achieve stronger SR performance than both their non-blind and blind counterparts. Furthermore, we demonstrate our framework's robustness by predicting degradations and super-resolving images from a complex pipeline of blurring, noise and compression.", "published": "2022-11-09T16:49:35Z", "version": 1}, {"aid": "2211.12421", "authors": ["Jiaxing Xu", "Yunhan Yang", "David Tse Jung Huang", "Sophi Shilpa Gururajapathy", "Yiping Ke", "Miao Qiao", "Alan Wang", "Haribalan Kumar", "Josh McGeown", "Eryn Kwon"], "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark", "url": "http://arxiv.org/pdf/2211.12421v6", "summary": "This paper presents a comprehensive and quality collection of functional human brain network data for potential research in the intersection of neuroscience, machine learning, and graph analytics. Anatomical and functional MRI images have been used to understand the functional connectivity of the human brain and are particularly important in identifying underlying neurodegenerative conditions such as Alzheimer's, Parkinson's, and Autism. Recently, the study of the brain in the form of brain networks using machine learning and graph analytics has become increasingly popular, especially to predict the early onset of these conditions. A brain network, represented as a graph, retains rich structural and positional information that traditional examination methods are unable to capture. However, the lack of publicly accessible brain network data prevents researchers from data-driven explorations. One of the main difficulties lies in the complicated domain-specific preprocessing steps and the exhaustive computation required to convert the data from MRI images into brain networks. We bridge this gap by collecting a large amount of MRI images from public databases and a private source, working with domain experts to make sensible design choices, and preprocessing the MRI images to produce a collection of brain network datasets. The datasets originate from 6 different sources, cover 4 brain conditions, and consist of a total of 2,702 subjects. We test our graph datasets on 12 machine learning models to provide baselines and validate the data quality on a recent graph analysis model. To lower the barrier to entry and promote the research in this interdisciplinary field, we release our brain network data and complete preprocessing details including codes at https://doi.org/10.17608/k6.auckland.21397377 and https://github.com/brainnetuoa/data_driven_network_neuroscience.", "published": "2022-11-11T02:14:28Z", "version": 6}, {"aid": "2211.06009", "authors": ["Na Lei", "Zezeng Li", "Zebin Xu", "Ying Li", "Xianfeng Gu"], "title": "What's the Situation with Intelligent Mesh Generation: A Survey and Perspectives", "url": "http://arxiv.org/pdf/2211.06009v3", "summary": "Intelligent Mesh Generation (IMG) represents a novel and promising field of research, utilizing machine learning techniques to generate meshes. Despite its relative infancy, IMG has significantly broadened the adaptability and practicality of mesh generation techniques, delivering numerous breakthroughs and unveiling potential future pathways. However, a noticeable void exists in the contemporary literature concerning comprehensive surveys of IMG methods. This paper endeavors to fill this gap by providing a systematic and thorough survey of the current IMG landscape. With a focus on 113 preliminary IMG methods, we undertake a meticulous analysis from various angles, encompassing core algorithm techniques and their application scope, agent learning objectives, data types, targeted challenges, as well as advantages and limitations. We have curated and categorized the literature, proposing three unique taxonomies based on key techniques, output mesh unit elements, and relevant input data types. This paper also underscores several promising future research directions and challenges in IMG. To augment reader accessibility, a dedicated IMG project page is available at \\url{https://github.com/xzb030/IMG_Survey}.", "published": "2022-11-11T05:24:16Z", "version": 3}, {"aid": "2211.06163", "authors": ["Longbin Yan", "Yunxiao Qin", "Shumin Liu", "Jie Chen"], "title": "Dual Complementary Dynamic Convolution for Image Recognition", "url": "http://arxiv.org/pdf/2211.06163v1", "summary": "As a powerful engine, vanilla convolution has promoted huge breakthroughs in various computer tasks. However, it often suffers from sample and content agnostic problems, which limits the representation capacities of the convolutional neural networks (CNNs). In this paper, we for the first time model the scene features as a combination of the local spatial-adaptive parts owned by the individual and the global shift-invariant parts shared to all individuals, and then propose a novel two-branch dual complementary dynamic convolution (DCDC) operator to flexibly deal with these two types of features. The DCDC operator overcomes the limitations of vanilla convolution and most existing dynamic convolutions who capture only spatial-adaptive features, and thus markedly boosts the representation capacities of CNNs. Experiments show that the DCDC operator based ResNets (DCDC-ResNets) significantly outperform vanilla ResNets and most state-of-the-art dynamic convolutional networks on image classification, as well as downstream tasks including object detection, instance and panoptic segmentation tasks, while with lower FLOPs and parameters.", "published": "2022-11-11T12:32:12Z", "version": 1}, {"aid": "2211.06262", "authors": ["Yi Ren", "Yanyang Xiao", "Guo-Qiang Bi", "Pek-Ming Lau"], "title": "Principles for generation of reverberation", "url": "http://arxiv.org/pdf/2211.06262v2", "summary": "In modern neuroscience, memory has been postulated to stored in neural circuits as sequential spike train and Reverberation is one of the specific example.Former research has made much progress on phenomenon description. However, the mechanism of reverberation has been unclear yet.   In this study, combining electrophysiological record and numerical simulation, we confirmed a formerly unrealized neuron property that is necessary for the burst generation in reverberation.   Secondly, we find out the mechanism of sequential pattern generation which clearly explained by network topology and asynchronous neurotransmitter release. In addition, we also developed a pipeline that could design the network fire in manually set order.   Thirdly, we explored the dynamics of STDP learning and chased down the effects of STDP Rule in reverberation. With these understandings, we developed a STDP based learning rule which could drive the network to remember any presupposed sequence.   These results indicated that neuron circuit can remember malformation through STDP rule. Those information are stored in synapse connections. By this way, animals remember information as spike sequence pattern.", "published": "2022-11-11T15:10:53Z", "version": 2}, {"aid": "2211.06291", "authors": ["Mrinank Sharma", "Sebastian Farquhar", "Eric Nalisnick", "Tom Rainforth"], "title": "Do Bayesian Neural Networks Need To Be Fully Stochastic?", "url": "http://arxiv.org/pdf/2211.06291v2", "summary": "We investigate the benefit of treating all the parameters in a Bayesian neural network stochastically and find compelling theoretical and empirical evidence that this standard construction may be unnecessary. To this end, we prove that expressive predictive distributions require only small amounts of stochasticity. In particular, partially stochastic networks with only $n$ stochastic biases are universal probabilistic predictors for $n$-dimensional predictive problems. In empirical investigations, we find no systematic benefit of full stochasticity across four different inference modalities and eight datasets; partially stochastic networks can match and sometimes even outperform fully stochastic networks, despite their reduced memory costs.", "published": "2022-11-11T16:00:21Z", "version": 2}, {"aid": "2211.07036", "authors": ["Ted Moskovitz", "Kevin Miller", "Maneesh Sahani", "Matthew M. Botvinick"], "title": "A Unified Theory of Dual-Process Control", "url": "http://arxiv.org/pdf/2211.07036v3", "summary": "Dual-process theories play a central role in both psychology and neuroscience, figuring prominently in fields ranging from executive control to reward-based learning to judgment and decision making. In each of these domains, two mechanisms appear to operate concurrently, one relatively high in computational complexity, the other relatively simple. Why is neural information processing organized in this way? We propose an answer to this question based on the notion of compression. The key insight is that dual-process structure can enhance adaptive behavior by allowing an agent to minimize the description length of its own behavior. We apply a single model based on this observation to findings from research on executive control, reward-based learning, and judgment and decision making, showing that seemingly diverse dual-process phenomena can be understood as domain-specific consequences of a single underlying set of computational principles.", "published": "2022-11-13T22:43:58Z", "version": 3}, {"aid": "2211.07077", "authors": ["Byungho Jo", "Donghyeon Cho", "In Kyu Park", "Sungeun Hong"], "title": "IFQA: Interpretable Face Quality Assessment", "url": "http://arxiv.org/pdf/2211.07077v2", "summary": "Existing face restoration models have relied on general assessment metrics that do not consider the characteristics of facial regions. Recent works have therefore assessed their methods using human studies, which is not scalable and involves significant effort. This paper proposes a novel face-centric metric based on an adversarial framework where a generator simulates face restoration and a discriminator assesses image quality. Specifically, our per-pixel discriminator enables interpretable evaluation that cannot be provided by traditional metrics. Moreover, our metric emphasizes facial primary regions considering that even minor changes to the eyes, nose, and mouth significantly affect human cognition. Our face-oriented metric consistently surpasses existing general or facial image quality assessment metrics by impressive margins. We demonstrate the generalizability of the proposed strategy in various architectural designs and challenging scenarios. Interestingly, we find that our IFQA can lead to performance improvement as an objective function.", "published": "2022-11-14T03:04:38Z", "version": 2}, {"aid": "2211.08030", "authors": ["Johannes Merkle", "Christian Rathgeb", "Benjamin Tams", "Dhay-Parn Lou", "Andr\u00e9 D\u00f6rsch", "Pawel Drozdowski"], "title": "State of the Art of Quality Assessment of Facial Images", "url": "http://arxiv.org/pdf/2211.08030v1", "summary": "The goal of the project \"Facial Metrics for EES\" is to develop, implement and publish an open source algorithm for the quality assessment of facial images (OFIQ) for face recognition, in particular for border control scenarios.1 In order to stimulate the harmonization of the requirements and practices applied for QA for facial images, the insights gained and algorithms developed in the project will be contributed to the current (2022) revision of the ISO/IEC 29794-5 standard. Furthermore, the implemented quality metrics and algorithms will consider the recommendations and requirements from other relevant standards, in particular ISO/IEC 19794-5:2011, ISO/IEC 29794-5:2010, ISO/IEC 39794-5:2019 and Version 5.2 of the BSI Technical Guideline TR-03121 Part 3 Volume 1. In order to establish an informed basis for the selection of quality metrics and the development of corresponding quality assessment algorithms, the state of the art of methods and algorithms (defining a metric), implementations and datasets for quality assessment for facial images is surveyed. For all relevant quality aspects, this document summarizes the requirements of the aforementioned standards, known results on their impact on face recognition performance, publicly available datasets, proposed methods and algorithms and open source software implementations.", "published": "2022-11-15T10:30:58Z", "version": 1}, {"aid": "2211.08332", "authors": ["Xingqian Xu", "Zhangyang Wang", "Eric Zhang", "Kai Wang", "Humphrey Shi"], "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion Model", "url": "http://arxiv.org/pdf/2211.08332v4", "summary": "Recent advances in diffusion models have set an impressive milestone in many generation tasks, and trending works such as DALL-E2, Imagen, and Stable Diffusion have attracted great interest. Despite the rapid landscape changes, recent new approaches focus on extensions and performance rather than capacity, thus requiring separate models for separate tasks. In this work, we expand the existing single-flow diffusion pipeline into a multi-task multimodal network, dubbed Versatile Diffusion (VD), that handles multiple flows of text-to-image, image-to-text, and variations in one unified model. The pipeline design of VD instantiates a unified multi-flow diffusion framework, consisting of sharable and swappable layer modules that enable the crossmodal generality beyond images and text. Through extensive experiments, we demonstrate that VD successfully achieves the following: a) VD outperforms the baseline approaches and handles all its base tasks with competitive quality; b) VD enables novel extensions such as disentanglement of style and semantics, dual- and multi-context blending, etc.; c) The success of our multi-flow multimodal framework over images and text may inspire further diffusion-based universal AI research. Our code and models are open-sourced at https://github.com/SHI-Labs/Versatile-Diffusion.", "published": "2022-11-15T17:44:05Z", "version": 4}, {"aid": "2211.08403", "authors": ["Keller Jordan", "Hanie Sedghi", "Olga Saukh", "Rahim Entezari", "Behnam Neyshabur"], "title": "REPAIR: REnormalizing Permuted Activations for Interpolation Repair", "url": "http://arxiv.org/pdf/2211.08403v3", "summary": "In this paper we look into the conjecture of Entezari et al. (2021) which states that if the permutation invariance of neural networks is taken into account, then there is likely no loss barrier to the linear interpolation between SGD solutions. First, we observe that neuron alignment methods alone are insufficient to establish low-barrier linear connectivity between SGD solutions due to a phenomenon we call variance collapse: interpolated deep networks suffer a collapse in the variance of their activations, causing poor performance. Next, we propose REPAIR (REnormalizing Permuted Activations for Interpolation Repair) which mitigates variance collapse by rescaling the preactivations of such interpolated networks. We explore the interaction between our method and the choice of normalization layer, network width, and depth, and demonstrate that using REPAIR on top of neuron alignment methods leads to 60%-100% relative barrier reduction across a wide variety of architecture families and tasks. In particular, we report a 74% barrier reduction for ResNet50 on ImageNet and 90% barrier reduction for ResNet18 on CIFAR10.", "published": "2022-11-15T18:45:26Z", "version": 3}, {"aid": "2211.11747", "authors": ["Jorg Bornschein", "Alexandre Galashov", "Ross Hemsley", "Amal Rannen-Triki", "Yutian Chen", "Arslan Chaudhry", "Xu Owen He", "Arthur Douillard", "Massimo Caccia", "Qixuang Feng", "Jiajun Shen", "Sylvestre-Alvise Rebuffi", "Kitty Stacpoole", "Diego de las Casas", "Will Hawkins", "Angeliki Lazaridou", "Yee Whye Teh", "Andrei A. Rusu", "Razvan Pascanu", "Marc'Aurelio Ranzato"], "title": "NEVIS'22: A Stream of 100 Tasks Sampled from 30 Years of Computer Vision Research", "url": "http://arxiv.org/pdf/2211.11747v2", "summary": "A shared goal of several machine learning communities like continual learning, meta-learning and transfer learning, is to design algorithms and models that efficiently and robustly adapt to unseen tasks. An even more ambitious goal is to build models that never stop adapting, and that become increasingly more efficient through time by suitably transferring the accrued knowledge. Beyond the study of the actual learning algorithm and model architecture, there are several hurdles towards our quest to build such models, such as the choice of learning protocol, metric of success and data needed to validate research hypotheses. In this work, we introduce the Never-Ending VIsual-classification Stream (NEVIS'22), a benchmark consisting of a stream of over 100 visual classification tasks, sorted chronologically and extracted from papers sampled uniformly from computer vision proceedings spanning the last three decades. The resulting stream reflects what the research community thought was meaningful at any point in time, and it serves as an ideal test bed to assess how well models can adapt to new tasks, and do so better and more efficiently as time goes by. Despite being limited to classification, the resulting stream has a rich diversity of tasks from OCR, to texture analysis, scene recognition, and so forth. The diversity is also reflected in the wide range of dataset sizes, spanning over four orders of magnitude. Overall, NEVIS'22 poses an unprecedented challenge for current sequential learning approaches due to the scale and diversity of tasks, yet with a low entry barrier as it is limited to a single modality and well understood supervised learning problems. Moreover, we provide a reference implementation including strong baselines and an evaluation protocol to compare methods in terms of their trade-off between accuracy and compute.", "published": "2022-11-15T18:57:46Z", "version": 2}, {"aid": "2211.08460", "authors": ["Laura Nicol\u00e1s-S\u00e1enz", "Agapito Ledezma", "Javier Pascau", "Arrate Mu\u00f1oz-Barrutia"], "title": "ABANICCO: A New Color Space for Multi-Label Pixel Classification and Color Segmentation", "url": "http://arxiv.org/pdf/2211.08460v1", "summary": "In any computer vision task involving color images, a necessary step is classifying pixels according to color and segmenting the respective areas. However, the development of methods able to successfully complete this task has proven challenging, mainly due to the gap between human color perception, linguistic color terms, and digital representation. In this paper, we propose a novel method combining geometric analysis of color theory, fuzzy color spaces, and multi-label systems for the automatic classification of pixels according to 12 standard color categories (Green, Yellow, Light Orange, Deep Orange, Red, Pink, Purple, Ultramarine, Blue, Teal, Brown, and Neutral). Moreover, we present a robust, unsupervised, unbiased strategy for color naming based on statistics and color theory. ABANICCO was tested against the state of the art in color classification and with the standarized ISCC-NBS color system, providing accurate classification and a standard, easily understandable alternative for hue naming recognizable by humans and machines. We expect this solution to become the base to successfully tackle a myriad of problems in all fields of computer vision, such as region characterization, histopathology analysis, fire detection, product quality prediction, object description, and hyperspectral imaging.", "published": "2022-11-15T19:26:51Z", "version": 1}, {"aid": "2211.08486", "authors": ["Chuqin Geng", "Xiaojie Xu", "Haolin Ye", "Xujie Si"], "title": "Scalar Invariant Networks with Zero Bias", "url": "http://arxiv.org/pdf/2211.08486v4", "summary": "Just like weights, bias terms are the learnable parameters of many popular machine learning models, including neural networks. Biases are thought to enhance the representational power of neural networks, enabling them to solve a variety of tasks in computer vision. However, we argue that biases can be disregarded for some image-related tasks such as image classification, by considering the intrinsic distribution of images in the input space and desired model properties from first principles. Our findings suggest that zero-bias neural networks can perform comparably to biased networks for practical image classification tasks. We demonstrate that zero-bias neural networks possess a valuable property called scalar (multiplication) invariance. This means that the prediction of the network remains unchanged when the contrast of the input image is altered. We extend scalar invariance to more general cases, enabling formal verification of certain convex regions of the input space. Additionally, we prove that zero-bias neural networks are fair in predicting the zero image. Unlike state-of-the-art models that may exhibit bias toward certain labels, zero-bias networks have uniform belief in all labels. We believe dropping bias terms can be considered as a geometric prior in designing neural network architecture for image classification, which shares the spirit of adapting convolutions as the transnational invariance prior. The robustness and fairness advantages of zero-bias neural networks may also indicate a promising path towards trustworthy and ethical AI.", "published": "2022-11-15T20:26:07Z", "version": 4}, {"aid": "2211.08892", "authors": ["Tianze Luo", "Zhanfeng Mo", "Sinno Jialin Pan"], "title": "Fast Graph Generation via Spectral Diffusion", "url": "http://arxiv.org/pdf/2211.08892v2", "summary": "Generating graph-structured data is a challenging problem, which requires learning the underlying distribution of graphs. Various models such as graph VAE, graph GANs, and graph diffusion models have been proposed to generate meaningful and reliable graphs, among which the diffusion models have achieved state-of-the-art performance. In this paper, we argue that running full-rank diffusion SDEs on the whole graph adjacency matrix space hinders diffusion models from learning graph topology generation, and hence significantly deteriorates the quality of generated graph data. To address this limitation, we propose an efficient yet effective Graph Spectral Diffusion Model (GSDM), which is driven by low-rank diffusion SDEs on the graph spectrum space. Our spectral diffusion model is further proven to enjoy a substantially stronger theoretical guarantee than standard diffusion models. Extensive experiments across various datasets demonstrate that, our proposed GSDM turns out to be the SOTA model, by exhibiting both significantly higher generation quality and much less computational consumption than the baselines.", "published": "2022-11-16T12:56:32Z", "version": 2}, {"aid": "2211.09788", "authors": ["Shoufa Chen", "Peize Sun", "Yibing Song", "Ping Luo"], "title": "DiffusionDet: Diffusion Model for Object Detection", "url": "http://arxiv.org/pdf/2211.09788v2", "summary": "We propose DiffusionDet, a new framework that formulates object detection as a denoising diffusion process from noisy boxes to object boxes. During the training stage, object boxes diffuse from ground-truth boxes to random distribution, and the model learns to reverse this noising process. In inference, the model refines a set of randomly generated boxes to the output results in a progressive way. Our work possesses an appealing property of flexibility, which enables the dynamic number of boxes and iterative evaluation. The extensive experiments on the standard benchmarks show that DiffusionDet achieves favorable performance compared to previous well-established detectors. For example, DiffusionDet achieves 5.3 AP and 4.8 AP gains when evaluated with more boxes and iteration steps, under a zero-shot transfer setting from COCO to CrowdHuman. Our code is available at https://github.com/ShoufaChen/DiffusionDet.", "published": "2022-11-17T18:56:19Z", "version": 2}, {"aid": "2211.09869", "authors": ["Titas Anciukevi\u010dius", "Zexiang Xu", "Matthew Fisher", "Paul Henderson", "Hakan Bilen", "Niloy J. Mitra", "Paul Guerrero"], "title": "RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation", "url": "http://arxiv.org/pdf/2211.09869v4", "summary": "Diffusion models currently achieve state-of-the-art performance for both conditional and unconditional image generation. However, so far, image diffusion models do not support tasks required for 3D understanding, such as view-consistent 3D generation or single-view object reconstruction. In this paper, we present RenderDiffusion, the first diffusion model for 3D generation and inference, trained using only monocular 2D supervision. Central to our method is a novel image denoising architecture that generates and renders an intermediate three-dimensional representation of a scene in each denoising step. This enforces a strong inductive structure within the diffusion process, providing a 3D consistent representation while only requiring 2D supervision. The resulting 3D representation can be rendered from any view. We evaluate RenderDiffusion on FFHQ, AFHQ, ShapeNet and CLEVR datasets, showing competitive performance for generation of 3D scenes and inference of 3D scenes from 2D images. Additionally, our diffusion-based approach allows us to use 2D inpainting to edit 3D scenes.", "published": "2022-11-17T20:17:04Z", "version": 4}, {"aid": "2211.09906", "authors": ["Ciaran Murphy-Royal", "ShiNung Ching", "Thomas Papouin"], "title": "Contextual guidance: An integrated theory for astrocytes function in brain circuits and behavior", "url": "http://arxiv.org/pdf/2211.09906v1", "summary": "The participation of astrocytes in brain computation was formally hypothesized in 1992, coinciding with the discovery that these glial cells display a complex form of Ca2+ excitability. This fostered conceptual advances centered on the notion of reciprocal interactions between neurons and astrocytes, which permitted a critical leap forward in uncovering many roles of astrocytes in brain circuits, and signaled the rise of a major new force in neuroscience: that of glial biology. In the past decade, a multitude of unconventional and disparate functions of astrocytes have been documented that are not predicted by these canonical models and that are challenging to piece together into a holistic and parsimonious picture. This highlights a disconnect between the rapidly evolving field of astrocyte biology and the conceptual frameworks guiding it, and emphasizes the need for a careful reconsideration of how we theorize the functional position of astrocytes in brain circuitry. Here, we propose a unifying, highly transferable, data-driven, and computationally-relevant conceptual framework for astrocyte biology, which we coin contextual guidance. It describes astrocytes as contextual gates that decode multiple environmental factors to shape neural circuitry in an adaptive, state-dependent fashion. This paradigm is organically inclusive of all fundamental features of astrocytes, many of which have remained unaccounted for in previous theories. We find that this new concept provides an intuitive and powerful theoretical space to improve our understanding of brain function and computational models thereof across scales because it depicts astrocytes as a hub for circumstantial inputs into relevant specialized circuits that permits adaptive behaviors at the network and organism level.", "published": "2022-11-17T21:38:00Z", "version": 1}, {"aid": "2211.10085", "authors": ["Mingyu Kang", "Duxin Chen", "Ning Meng", "Gang Yan", "Wenwu Yu"], "title": "Identifying Unique Spatial-Temporal Bayesian Network without Markov Equivalence", "url": "http://arxiv.org/pdf/2211.10085v4", "summary": "Identifying vanilla Bayesian network to model spatial-temporal causality can be a critical yet challenging task. Different Markovian-equivalent directed acyclic graphs would be identified if the identifiability is not satisfied. To address this issue, Directed Cyclic Graph is proposed to drop the directed acyclic constraint. But it does not always hold, and cannot model dynamical time-series process. Then, Full Time Graph is proposed with introducing high-order time delay. Full Time Graph has no Markov equivalence class by assuming no instantaneous effects. But, it also assumes that the causality is invariant with varying time, that is not always satisfied in the spatio-temporal scenarios. Thus, in this work, a Spatial-Temporal Bayesian Network (STBN) is proposed to theoretically model the spatial-temporal causality from the perspective of information transfer. STBN explains the disappearance of network structure $X\\rightarrow Z \\rightarrow Y$ and $X\\leftarrow Z \\leftarrow Y$ by the principle of information path blocking. And finally, the uniqueness of STBN is proved. Based on this, a High-order Causal Entropy (HCE) algorithm is also proposed to uniquely identify STBN under time complexity $\\mathcal{O}(n^3\\tau_{max})$, where $n$ is the number of variables and $\\tau_{max}$ is the maximum time delay. Numerical experiments are conducted with comparison to other baseline algorithms. The results show that HCE algorithm obtains state-of-the-art identification accuracy. The code is available at https://github.com/KMY-SEU/HCE.", "published": "2022-11-18T08:28:54Z", "version": 4}, {"aid": "2211.10564", "authors": ["Mahmoud Salem", "Mohamed Osama Ahmed", "Frederick Tung", "Gabriel Oliveira"], "title": "Gumbel-Softmax Selective Networks", "url": "http://arxiv.org/pdf/2211.10564v1", "summary": "ML models often operate within the context of a larger system that can adapt its response when the ML model is uncertain, such as falling back on safe defaults or a human in the loop. This commonly encountered operational context calls for principled techniques for training ML models with the option to abstain from predicting when uncertain. Selective neural networks are trained with an integrated option to abstain, allowing them to learn to recognize and optimize for the subset of the data distribution for which confident predictions can be made. However, optimizing selective networks is challenging due to the non-differentiability of the binary selection function (the discrete decision of whether to predict or abstain). This paper presents a general method for training selective networks that leverages the Gumbel-softmax reparameterization trick to enable selection within an end-to-end differentiable training framework. Experiments on public datasets demonstrate the potential of Gumbel-softmax selective networks for selective regression and classification.", "published": "2022-11-19T02:20:14Z", "version": 1}, {"aid": "2211.10655", "authors": ["Hyungjin Chung", "Dohoon Ryu", "Michael T. McCann", "Marc L. Klasky", "Jong Chul Ye"], "title": "Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models", "url": "http://arxiv.org/pdf/2211.10655v1", "summary": "Diffusion models have emerged as the new state-of-the-art generative model with high quality samples, with intriguing properties such as mode coverage and high flexibility. They have also been shown to be effective inverse problem solvers, acting as the prior of the distribution, while the information of the forward model can be granted at the sampling stage. Nonetheless, as the generative process remains in the same high dimensional (i.e. identical to data dimension) space, the models have not been extended to 3D inverse problems due to the extremely high memory and computational cost. In this paper, we combine the ideas from the conventional model-based iterative reconstruction with the modern diffusion models, which leads to a highly effective method for solving 3D medical image reconstruction tasks such as sparse-view tomography, limited angle tomography, compressed sensing MRI from pre-trained 2D diffusion models. In essence, we propose to augment the 2D diffusion prior with a model-based prior in the remaining direction at test time, such that one can achieve coherent reconstructions across all dimensions. Our method can be run in a single commodity GPU, and establishes the new state-of-the-art, showing that the proposed method can perform reconstructions of high fidelity and accuracy even in the most extreme cases (e.g. 2-view 3D tomography). We further reveal that the generalization capacity of the proposed method is surprisingly high, and can be used to reconstruct volumes that are entirely different from the training dataset.", "published": "2022-11-19T10:32:21Z", "version": 1}, {"aid": "2211.11751", "authors": ["Chenkang Zhang", "Lei Luo", "Bin Gu"], "title": "Denoising Multi-Similarity Formulation: A Self-paced Curriculum-Driven Approach for Robust Metric Learning", "url": "http://arxiv.org/pdf/2211.11751v2", "summary": "Deep Metric Learning (DML) is a group of techniques that aim to measure the similarity between objects through the neural network. Although the number of DML methods has rapidly increased in recent years, most previous studies cannot effectively handle noisy data, which commonly exists in practical applications and often leads to serious performance deterioration. To overcome this limitation, in this paper, we build a connection between noisy samples and hard samples in the framework of self-paced learning, and propose a \\underline{B}alanced \\underline{S}elf-\\underline{P}aced \\underline{M}etric \\underline{L}earning (BSPML) algorithm with a denoising multi-similarity formulation, where noisy samples are treated as extremely hard samples and adaptively excluded from the model training by sample weighting. Especially, due to the pairwise relationship and a new balance regularization term, the sub-problem \\emph{w.r.t.} sample weights is a nonconvex quadratic function. To efficiently solve this nonconvex quadratic problem, we propose a doubly stochastic projection coordinate gradient algorithm. Importantly, we theoretically prove the convergence not only for the doubly stochastic projection coordinate gradient algorithm, but also for our BSPML algorithm. Experimental results on several standard data sets demonstrate that our BSPML algorithm has better generalization ability and robustness than the state-of-the-art robust DML approaches.", "published": "2022-11-19T15:28:19Z", "version": 2}, {"aid": "2211.10851", "authors": ["Thomas J. Ringstrom"], "title": "Reward is not Necessary: How to Create a Modular & Compositional Self-Preserving Agent for Life-Long Learning", "url": "http://arxiv.org/pdf/2211.10851v4", "summary": "Reinforcement Learning views the maximization of rewards and avoidance of punishments as central to explaining goal-directed behavior. However, over a life, organisms will need to learn about many different aspects of the world's structure: the states of the world and state-vector transition dynamics. The number of combinations of states grows exponentially as an agent incorporates new knowledge, and there is no obvious weighted combination of pre-existing rewards or costs defined for a given combination of states, as such a weighting would need to encode information about good and bad combinations prior to an agent's experience in the world. Therefore, we must develop more naturalistic accounts of behavior and motivation in large state-spaces. We show that it is possible to use only the intrinsic motivation metric of empowerment, which measures the agent's capacity to realize many possible futures under a transition operator. We propose to scale empowerment to hierarchical state-spaces by using Operator Bellman Equations. These equations produce state-time feasibility functions, which are compositional hierarchical state-time transition operators that map an initial state and time when an agent begins a policy to the final states and times of completing a goal. Because these functions are hierarchical operators we can define hierarchical empowerment measures on them. An agent can then optimize plans to distant states and times to maximize its hierarchical empowerment-gain, allowing it to discover goals that bring about a more favorable coupling of its internal structure (physiological states) to its external environment (world structure & spatial state). Life-long agents could therefore be primarily animated by principles of compositionality and empowerment, exhibiting self-concern for the growth & maintenance of their own structural integrity without recourse to reward-maximization.", "published": "2022-11-20T02:48:01Z", "version": 4}, {"aid": "2211.11665", "authors": ["Lyndon R. Duong", "Jingyang Zhou", "Josue Nassar", "Jules Berman", "Jeroen Olieslagers", "Alex H. Williams"], "title": "Representational dissimilarity metric spaces for stochastic neural networks", "url": "http://arxiv.org/pdf/2211.11665v2", "summary": "Quantifying similarity between neural representations -- e.g. hidden layer activation vectors -- is a perennial problem in deep learning and neuroscience research. Existing methods compare deterministic responses (e.g. artificial networks that lack stochastic layers) or averaged responses (e.g., trial-averaged firing rates in biological data). However, these measures of _deterministic_ representational similarity ignore the scale and geometric structure of noise, both of which play important roles in neural computation. To rectify this, we generalize previously proposed shape metrics (Williams et al. 2021) to quantify differences in _stochastic_ representations. These new distances satisfy the triangle inequality, and thus can be used as a rigorous basis for many supervised and unsupervised analyses. Leveraging this novel framework, we find that the stochastic geometries of neurobiological representations of oriented visual gratings and naturalistic scenes respectively resemble untrained and trained deep network representations. Further, we are able to more accurately predict certain network attributes (e.g. training hyperparameters) from its position in stochastic (versus deterministic) shape space.", "published": "2022-11-21T17:32:40Z", "version": 2}, {"aid": "2211.12047", "authors": ["Alexander Ororbia", "Ankur Mali"], "title": "Convolutional Neural Generative Coding: Scaling Predictive Coding to Natural Images", "url": "http://arxiv.org/pdf/2211.12047v2", "summary": "In this work, we develop convolutional neural generative coding (Conv-NGC), a generalization of predictive coding to the case of convolution/deconvolution-based computation. Specifically, we concretely implement a flexible neurobiologically-motivated algorithm that progressively refines latent state feature maps in order to dynamically form a more accurate internal representation/reconstruction model of natural images. The performance of the resulting sensory processing system is evaluated on complex datasets such as Color-MNIST, CIFAR-10, and Street House View Numbers (SVHN). We study the effectiveness of our brain-inspired model on the tasks of reconstruction and image denoising and find that it is competitive with convolutional auto-encoding systems trained by backpropagation of errors and outperforms them with respect to out-of-distribution reconstruction (including the full 90k CINIC-10 test set).", "published": "2022-11-22T06:42:41Z", "version": 2}, {"aid": "2211.12082", "authors": ["Ramy Hussein", "David Shin", "Moss Zhao", "Jia Guo", "Guido Davidzon", "Michael Moseley", "Greg Zaharchuk"], "title": "Brain MRI-to-PET Synthesis using 3D Convolutional Attention Networks", "url": "http://arxiv.org/pdf/2211.12082v1", "summary": "Accurate quantification of cerebral blood flow (CBF) is essential for the diagnosis and assessment of a wide range of neurological diseases. Positron emission tomography (PET) with radiolabeled water (15O-water) is considered the gold-standard for the measurement of CBF in humans. PET imaging, however, is not widely available because of its prohibitive costs and use of short-lived radiopharmaceutical tracers that typically require onsite cyclotron production. Magnetic resonance imaging (MRI), in contrast, is more readily accessible and does not involve ionizing radiation. This study presents a convolutional encoder-decoder network with attention mechanisms to predict gold-standard 15O-water PET CBF from multi-sequence MRI scans, thereby eliminating the need for radioactive tracers. Inputs to the prediction model include several commonly used MRI sequences (T1-weighted, T2-FLAIR, and arterial spin labeling). The model was trained and validated using 5-fold cross-validation in a group of 126 subjects consisting of healthy controls and cerebrovascular disease patients, all of whom underwent simultaneous $15O-water PET/MRI. The results show that such a model can successfully synthesize high-quality PET CBF measurements (with an average SSIM of 0.924 and PSNR of 38.8 dB) and is more accurate compared to concurrent and previous PET synthesis methods. We also demonstrate the clinical significance of the proposed algorithm by evaluating the agreement for identifying the vascular territories with abnormally low CBF. Such methods may enable more widespread and accurate CBF evaluation in larger cohorts who cannot undergo PET imaging due to radiation concerns, lack of access, or logistic challenges.", "published": "2022-11-22T08:25:44Z", "version": 1}, {"aid": "2211.12117", "authors": ["Pengcheng Lei", "Faming Fang", "Guixu Zhang"], "title": "Flow Guidance Deformable Compensation Network for Video Frame Interpolation", "url": "http://arxiv.org/pdf/2211.12117v1", "summary": "Motion-based video frame interpolation (VFI) methods have made remarkable progress with the development of deep convolutional networks over the past years. While their performance is often jeopardized by the inaccuracy of flow map estimation, especially in the case of large motion and occlusion. In this paper, we propose a flow guidance deformable compensation network (FGDCN) to overcome the drawbacks of existing motion-based methods. FGDCN decomposes the frame sampling process into two steps: a flow step and a deformation step. Specifically, the flow step utilizes a coarse-to-fine flow estimation network to directly estimate the intermediate flows and synthesizes an anchor frame simultaneously. To ensure the accuracy of the estimated flow, a distillation loss and a task-oriented loss are jointly employed in this step. Under the guidance of the flow priors learned in step one, the deformation step designs a pyramid deformable compensation network to compensate for the missing details of the flow step. In addition, a pyramid loss is proposed to supervise the model in both the image and frequency domain. Experimental results show that the proposed algorithm achieves excellent performance on various datasets with fewer parameters.", "published": "2022-11-22T09:35:14Z", "version": 1}, {"aid": "2211.12698", "authors": ["Chun Bao", "Jie Cao", "Yaqian Ning", "Yang Cheng", "Qun Hao"], "title": "Rega-Net:Retina Gabor Attention for Deep Convolutional Neural Networks", "url": "http://arxiv.org/pdf/2211.12698v2", "summary": "Extensive research works demonstrate that the attention mechanism in convolutional neural networks (CNNs) effectively improves accuracy. Nevertheless, few works design attention mechanisms using large receptive fields. In this work, we propose a novel attention method named Rega-net to increase CNN accuracy by enlarging the receptive field. Inspired by the mechanism of the human retina, we design convolutional kernels to resemble the non-uniformly distributed structure of the human retina. Then, we sample variable-resolution values in the Gabor function distribution and fill these values in retina-like kernels. This distribution allows essential features to be more visible in the center position of the receptive field. We further design an attention module including these retina-like kernels. Experiments demonstrate that our Rega-Net achieves 79.96% top-1 accuracy on ImageNet-1K classification and 43.1% mAP on COCO2017 object detection. The mAP of the Rega-Net increased by up to 3.5% compared to baseline networks.", "published": "2022-11-23T04:24:21Z", "version": 2}, {"aid": "2211.13524", "authors": ["Yinhuai Wang", "Yujie Hu", "Jiwen Yu", "Jian Zhang"], "title": "GAN Prior based Null-Space Learning for Consistent Super-Resolution", "url": "http://arxiv.org/pdf/2211.13524v1", "summary": "Consistency and realness have always been the two critical issues of image super-resolution. While the realness has been dramatically improved with the use of GAN prior, the state-of-the-art methods still suffer inconsistencies in local structures and colors (e.g., tooth and eyes). In this paper, we show that these inconsistencies can be analytically eliminated by learning only the null-space component while fixing the range-space part. Further, we design a pooling-based decomposition (PD), a universal range-null space decomposition for super-resolution tasks, which is concise, fast, and parameter-free. PD can be easily applied to state-of-the-art GAN Prior based SR methods to eliminate their inconsistencies, neither compromising the realness nor bringing extra parameters or computational costs. Besides, our ablation studies reveal that PD can replace pixel-wise losses for training and achieve better generalization performance when facing unseen downsamplings or even real-world degradation. Experiments show that the use of PD refreshes state-of-the-art SR performance and speeds up the convergence of training up to 2~10 times.", "published": "2022-11-24T10:45:15Z", "version": 1}, {"aid": "2211.13676", "authors": ["Seung Ho Park", "Young Su Moon", "Nam Ik Cho"], "title": "Perception-Oriented Single Image Super-Resolution using Optimal Objective Estimation", "url": "http://arxiv.org/pdf/2211.13676v3", "summary": "Single-image super-resolution (SISR) networks trained with perceptual and adversarial losses provide high-contrast outputs compared to those of networks trained with distortion-oriented losses, such as L1 or L2. However, it has been shown that using a single perceptual loss is insufficient for accurately restoring locally varying diverse shapes in images, often generating undesirable artifacts or unnatural details. For this reason, combinations of various losses, such as perceptual, adversarial, and distortion losses, have been attempted, yet it remains challenging to find optimal combinations. Hence, in this paper, we propose a new SISR framework that applies optimal objectives for each region to generate plausible results in overall areas of high-resolution outputs. Specifically, the framework comprises two models: a predictive model that infers an optimal objective map for a given low-resolution (LR) input and a generative model that applies a target objective map to produce the corresponding SR output. The generative model is trained over our proposed objective trajectory representing a set of essential objectives, which enables the single network to learn various SR results corresponding to combined losses on the trajectory. The predictive model is trained using pairs of LR images and corresponding optimal objective maps searched from the objective trajectory. Experimental results on five benchmarks show that the proposed method outperforms state-of-the-art perception-driven SR methods in LPIPS, DISTS, PSNR, and SSIM metrics. The visual results also demonstrate the superiority of our method in perception-oriented reconstruction. The code and models are available at https://github.com/seungho-snu/SROOE.", "published": "2022-11-24T15:45:03Z", "version": 3}, {"aid": "2211.13724", "authors": ["Ali Harakeh", "Jordan Hu", "Naiqing Guan", "Steven L. Waslander", "Liam Paull"], "title": "Estimating Regression Predictive Distributions with Sample Networks", "url": "http://arxiv.org/pdf/2211.13724v1", "summary": "Estimating the uncertainty in deep neural network predictions is crucial for many real-world applications. A common approach to model uncertainty is to choose a parametric distribution and fit the data to it using maximum likelihood estimation. The chosen parametric form can be a poor fit to the data-generating distribution, resulting in unreliable uncertainty estimates. In this work, we propose SampleNet, a flexible and scalable architecture for modeling uncertainty that avoids specifying a parametric form on the output distribution. SampleNets do so by defining an empirical distribution using samples that are learned with the Energy Score and regularized with the Sinkhorn Divergence. SampleNets are shown to be able to well-fit a wide range of distributions and to outperform baselines on large-scale real-world regression tasks.", "published": "2022-11-24T17:23:29Z", "version": 1}, {"aid": "2211.13757", "authors": ["Gene Chou", "Yuval Bahat", "Felix Heide"], "title": "Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions", "url": "http://arxiv.org/pdf/2211.13757v2", "summary": "Probabilistic diffusion models have achieved state-of-the-art results for image synthesis, inpainting, and text-to-image tasks. However, they are still in the early stages of generating complex 3D shapes. This work proposes Diffusion-SDF, a generative model for shape completion, single-view reconstruction, and reconstruction of real-scanned point clouds. We use neural signed distance functions (SDFs) as our 3D representation to parameterize the geometry of various signals (e.g., point clouds, 2D images) through neural networks. Neural SDFs are implicit functions and diffusing them amounts to learning the reversal of their neural network weights, which we solve using a custom modulation module. Extensive experiments show that our method is capable of both realistic unconditional generation and conditional generation from partial inputs. This work expands the domain of diffusion models from learning 2D, explicit representations, to 3D, implicit representations.", "published": "2022-11-24T18:59:01Z", "version": 2}, {"aid": "2211.14794", "authors": ["Guangrun Wang", "Philip H. S. Torr"], "title": "Traditional Classification Neural Networks are Good Generators: They are Competitive with DDPMs and GANs", "url": "http://arxiv.org/pdf/2211.14794v2", "summary": "Classifiers and generators have long been separated. We break down this separation and showcase that conventional neural network classifiers can generate high-quality images of a large number of categories, being comparable to the state-of-the-art generative models (e.g., DDPMs and GANs). We achieve this by computing the partial derivative of the classification loss function with respect to the input to optimize the input to produce an image. Since it is widely known that directly optimizing the inputs is similar to targeted adversarial attacks incapable of generating human-meaningful images, we propose a mask-based stochastic reconstruction module to make the gradients semantic-aware to synthesize plausible images. We further propose a progressive-resolution technique to guarantee fidelity, which produces photorealistic images. Furthermore, we introduce a distance metric loss and a non-trivial distribution loss to ensure classification neural networks can synthesize diverse and high-fidelity images. Using traditional neural network classifiers, we can generate good-quality images of 256$\\times$256 resolution on ImageNet. Intriguingly, our method is also applicable to text-to-image generation by regarding image-text foundation models as generalized classifiers.   Proving that classifiers have learned the data distribution and are ready for image generation has far-reaching implications, for classifiers are much easier to train than generative models like DDPMs and GANs. We don't even need to train classification models because tons of public ones are available for download. Also, this holds great potential for the interpretability and robustness of classifiers. Project page is at \\url{https://classifier-as-generator.github.io/}.", "published": "2022-11-27T11:25:35Z", "version": 2}, {"aid": "2211.17106", "authors": ["Xingyi Yang", "Daquan Zhou", "Jiashi Feng", "Xinchao Wang"], "title": "Diffusion Probabilistic Model Made Slim", "url": "http://arxiv.org/pdf/2211.17106v1", "summary": "Despite the recent visually-pleasing results achieved, the massive computational cost has been a long-standing flaw for diffusion probabilistic models (DPMs), which, in turn, greatly limits their applications on resource-limited platforms. Prior methods towards efficient DPM, however, have largely focused on accelerating the testing yet overlooked their huge complexity and sizes. In this paper, we make a dedicated attempt to lighten DPM while striving to preserve its favourable performance. We start by training a small-sized latent diffusion model (LDM) from scratch, but observe a significant fidelity drop in the synthetic images. Through a thorough assessment, we find that DPM is intrinsically biased against high-frequency generation, and learns to recover different frequency components at different time-steps. These properties make compact networks unable to represent frequency dynamics with accurate high-frequency estimation. Towards this end, we introduce a customized design for slim DPM, which we term as Spectral Diffusion (SD), for light-weight image synthesis. SD incorporates wavelet gating in its architecture to enable frequency dynamic feature extraction at every reverse steps, and conducts spectrum-aware distillation to promote high-frequency recovery by inverse weighting the objective based on spectrum magni tudes. Experimental results demonstrate that, SD achieves 8-18x computational complexity reduction as compared to the latent diffusion models on a series of conditional and unconditional image generation tasks while retaining competitive image fidelity.", "published": "2022-11-27T16:27:28Z", "version": 1}, {"aid": "2212.02226", "authors": ["Xueqing Liu", "Tao Tu", "Paul Sajda"], "title": "Inferring latent neural sources via deep transcoding of simultaneously acquired EEG and fMRI", "url": "http://arxiv.org/pdf/2212.02226v1", "summary": "Simultaneous EEG-fMRI is a multi-modal neuroimaging technique that provides complementary spatial and temporal resolution. Challenging has been developing principled and interpretable approaches for fusing the modalities, specifically approaches enabling inference of latent source spaces representative of neural activity. In this paper, we address this inference problem within the framework of transcoding -- mapping from a specific encoding (modality) to a decoding (the latent source space) and then encoding the latent source space to the other modality. Specifically, we develop a symmetric method consisting of a cyclic convolutional transcoder that transcodes EEG to fMRI and vice versa. Without any prior knowledge of either the hemodynamic response function or lead field matrix, the complete data-driven method exploits the temporal and spatial relationships between the modalities and latent source spaces to learn these mappings. We quantify, for both the simulated and real EEG-fMRI data, how well the modalities can be transcoded from one to another as well as the source spaces that are recovered, all evaluated on unseen data. In addition to enabling a new way to symmetrically infer a latent source space, the method can also be seen as low-cost computational neuroimaging -- i.e. generating an 'expensive' fMRI BOLD image from 'low cost' EEG data.", "published": "2022-11-27T23:44:16Z", "version": 1}, {"aid": "2211.15115", "authors": ["Wenbin An", "Feng Tian", "Qinghua Zheng", "Wei Ding", "QianYing Wang", "Ping Chen"], "title": "Generalized Category Discovery with Decoupled Prototypical Network", "url": "http://arxiv.org/pdf/2211.15115v2", "summary": "Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN.", "published": "2022-11-28T08:05:45Z", "version": 2}, {"aid": "2211.15736", "authors": ["Yuzhang Shang", "Zhihang Yuan", "Bin Xie", "Bingzhe Wu", "Yan Yan"], "title": "Post-training Quantization on Diffusion Models", "url": "http://arxiv.org/pdf/2211.15736v3", "summary": "Denoising diffusion (score-based) generative models have recently achieved significant accomplishments in generating realistic and diverse data. These approaches define a forward diffusion process for transforming data into noise and a backward denoising process for sampling data from noise. Unfortunately, the generation process of current denoising diffusion models is notoriously slow due to the lengthy iterative noise estimations, which rely on cumbersome neural networks. It prevents the diffusion models from being widely deployed, especially on edge devices. Previous works accelerate the generation process of diffusion model (DM) via finding shorter yet effective sampling trajectories. However, they overlook the cost of noise estimation with a heavy network in every iteration. In this work, we accelerate generation from the perspective of compressing the noise estimation network. Due to the difficulty of retraining DMs, we exclude mainstream training-aware compression paradigms and introduce post-training quantization (PTQ) into DM acceleration. However, the output distributions of noise estimation networks change with time-step, making previous PTQ methods fail in DMs since they are designed for single-time step scenarios. To devise a DM-specific PTQ method, we explore PTQ on DM in three aspects: quantized operations, calibration dataset, and calibration metric. We summarize and use several observations derived from all-inclusive investigations to formulate our method, which especially targets the unique multi-time-step structure of DMs. Experimentally, our method can directly quantize full-precision DMs into 8-bit models while maintaining or even improving their performance in a training-free manner. Importantly, our method can serve as a plug-and-play module on other fast-sampling methods, e.g., DDIM. The code is available at https://github.com/42Shawn/PTQ4DM .", "published": "2022-11-28T19:33:39Z", "version": 3}, {"aid": "2211.17091", "authors": ["Dongjun Kim", "Yeongmin Kim", "Se Jung Kwon", "Wanmo Kang", "Il-Chul Moon"], "title": "Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models", "url": "http://arxiv.org/pdf/2211.17091v4", "summary": "The proposed method, Discriminator Guidance, aims to improve sample generation of pre-trained diffusion models. The approach introduces a discriminator that gives explicit supervision to a denoising sample path whether it is realistic or not. Unlike GANs, our approach does not require joint training of score and discriminator networks. Instead, we train the discriminator after score training, making discriminator training stable and fast to converge. In sample generation, we add an auxiliary term to the pre-trained score to deceive the discriminator. This term corrects the model score to the data score at the optimal discriminator, which implies that the discriminator helps better score estimation in a complementary way. Using our algorithm, we achive state-of-the-art results on ImageNet 256x256 with FID 1.83 and recall 0.64, similar to the validation data's FID (1.68) and recall (0.66). We release the code at https://github.com/alsdudrla10/DG.", "published": "2022-11-28T20:04:12Z", "version": 4}, {"aid": "2211.16032", "authors": ["Han Zhang", "Ruili Feng", "Zhantao Yang", "Lianghua Huang", "Yu Liu", "Yifei Zhang", "Yujun Shen", "Deli Zhao", "Jingren Zhou", "Fan Cheng"], "title": "Dimensionality-Varying Diffusion Process", "url": "http://arxiv.org/pdf/2211.16032v1", "summary": "Diffusion models, which learn to reverse a signal destruction process to generate new data, typically require the signal at each step to have the same dimension. We argue that, considering the spatial redundancy in image signals, there is no need to maintain a high dimensionality in the evolution process, especially in the early generation phase. To this end, we make a theoretical generalization of the forward diffusion process via signal decomposition. Concretely, we manage to decompose an image into multiple orthogonal components and control the attenuation of each component when perturbing the image. That way, along with the noise strength increasing, we are able to diminish those inconsequential components and thus use a lower-dimensional signal to represent the source, barely losing information. Such a reformulation allows to vary dimensions in both training and inference of diffusion models. Extensive experiments on a range of datasets suggest that our approach substantially reduces the computational cost and achieves on-par or even better synthesis performance compared to baseline methods. We also show that our strategy facilitates high-resolution image synthesis and improves FID of diffusion model trained on FFHQ at $1024\\times1024$ resolution from 52.40 to 10.46. Code and models will be made publicly available.", "published": "2022-11-29T09:05:55Z", "version": 1}, {"aid": "2211.16095", "authors": ["Seong-Woong Kim", "Dong-Wan Choi"], "title": "Better Generalized Few-Shot Learning Even Without Base Data", "url": "http://arxiv.org/pdf/2211.16095v2", "summary": "This paper introduces and studies zero-base generalized few-shot learning (zero-base GFSL), which is an extreme yet practical version of few-shot learning problem. Motivated by the cases where base data is not available due to privacy or ethical issues, the goal of zero-base GFSL is to newly incorporate the knowledge of few samples of novel classes into a pretrained model without any samples of base classes. According to our analysis, we discover the fact that both mean and variance of the weight distribution of novel classes are not properly established, compared to those of base classes. The existing GFSL methods attempt to make the weight norms balanced, which we find helps only the variance part, but discard the importance of mean of weights particularly for novel classes, leading to the limited performance in the GFSL problem even with base data. In this paper, we overcome this limitation by proposing a simple yet effective normalization method that can effectively control both mean and variance of the weight distribution of novel classes without using any base samples and thereby achieve a satisfactory performance on both novel and base classes. Our experimental results somewhat surprisingly show that the proposed zero-base GFSL method that does not utilize any base samples even outperforms the existing GFSL methods that make the best use of base data. Our implementation is available at: https://github.com/bigdata-inha/Zero-Base-GFSL.", "published": "2022-11-29T11:10:40Z", "version": 2}, {"aid": "2211.16135", "authors": ["Sicong Liu", "Xiaochen Li", "Zimu Zhou", "Bin Guo", "Meng Zhang", "Haochen Shen", "Zhiwen Yu"], "title": "AdaEnlight: Energy-aware Low-light Video Stream Enhancement on Mobile Devices", "url": "http://arxiv.org/pdf/2211.16135v2", "summary": "The ubiquity of camera-embedded devices and the advances in deep learning have stimulated various intelligent mobile video applications. These applications often demand on-device processing of video streams to deliver real-time, high-quality services for privacy and robustness concerns. However, the performance of these applications is constrained by the raw video streams, which tend to be taken with small-aperture cameras of ubiquitous mobile platforms in dim light. Despite extensive low-light video enhancement solutions, they are unfit for deployment to mobile devices due to their complex models and and ignorance of system dynamics like energy budgets. In this paper, we propose AdaEnlight, an energy-aware low-light video stream enhancement system on mobile devices. It achieves real-time video enhancement with competitive visual quality while allowing runtime behavior adaptation to the platform-imposed dynamic energy budgets. We report extensive experiments on diverse datasets, scenarios, and platforms and demonstrate the superiority of AdaEnlight compared with state-of-the-art low-light image and video enhancement solutions.", "published": "2022-11-29T12:12:34Z", "version": 2}, {"aid": "2211.16246", "authors": ["Debo Cheng", "Ziqi Xu", "Jiuyong Li", "Lin Liu", "Jixue Liu", "Thuc Duy Le"], "title": "Causal Inference with Conditional Instruments using Deep Generative Models", "url": "http://arxiv.org/pdf/2211.16246v1", "summary": "The instrumental variable (IV) approach is a widely used way to estimate the causal effects of a treatment on an outcome of interest from observational data with latent confounders. A standard IV is expected to be related to the treatment variable and independent of all other variables in the system. However, it is challenging to search for a standard IV from data directly due to the strict conditions. The conditional IV (CIV) method has been proposed to allow a variable to be an instrument conditioning on a set of variables, allowing a wider choice of possible IVs and enabling broader practical applications of the IV approach. Nevertheless, there is not a data-driven method to discover a CIV and its conditioning set directly from data. To fill this gap, in this paper, we propose to learn the representations of the information of a CIV and its conditioning set from data with latent confounders for average causal effect estimation. By taking advantage of deep generative models, we develop a novel data-driven approach for simultaneously learning the representation of a CIV from measured variables and generating the representation of its conditioning set given measured variables. Extensive experiments on synthetic and real-world datasets show that our method outperforms the existing IV methods.", "published": "2022-11-29T14:31:54Z", "version": 1}, {"aid": "2211.16356", "authors": ["Runjia Li", "Yang Yu", "Charlie Haywood"], "title": "Real-time Blind Deblurring Based on Lightweight Deep-Wiener-Network", "url": "http://arxiv.org/pdf/2211.16356v3", "summary": "In this paper, we address the problem of blind deblurring with high efficiency. We propose a set of lightweight deep-wiener-network to finish the task with real-time speed. The Network contains a deep neural network for estimating parameters of wiener networks and a wiener network for deblurring. Experimental evaluations show that our approaches have an edge on State of the Art in terms of inference times and numbers of parameters. Two of our models can reach a speed of 100 images per second, which is qualified for real-time deblurring. Further research may focus on some real-world applications of deblurring with our models.", "published": "2022-11-29T16:42:01Z", "version": 3}, {"aid": "2211.16678", "authors": ["Kyoungwan Woo", "Achyuta Rajaram"], "title": "FREDSR: Fourier Residual Efficient Diffusive GAN for Single Image Super Resolution", "url": "http://arxiv.org/pdf/2211.16678v1", "summary": "FREDSR is a GAN variant that aims to outperform traditional GAN models in specific tasks such as Single Image Super Resolution with extreme parameter efficiency at the cost of per-dataset generalizeability. FREDSR integrates fast Fourier transformation, residual prediction, diffusive discriminators, etc to achieve strong performance in comparisons to other models on the UHDSR4K dataset for Single Image 3x Super Resolution from 360p and 720p with only 37000 parameters. The model follows the characteristics of the given dataset, resulting in lower generalizeability but higher performance on tasks such as real time up-scaling.", "published": "2022-11-30T01:58:52Z", "version": 1}, {"aid": "2211.16780", "authors": ["Quyen Tran", "Hoang Phan", "Khoat Than", "Dinh Phung", "Trung Le"], "title": "Continual Learning with Optimal Transport based Mixture Model", "url": "http://arxiv.org/pdf/2211.16780v2", "summary": "Online Class Incremental learning (CIL) is a challenging setting in Continual Learning (CL), wherein data of new tasks arrive in incoming streams and online learning models need to handle incoming data streams without revisiting previous ones. Existing works used a single centroid adapted with incoming data streams to characterize a class. This approach possibly exposes limitations when the incoming data stream of a class is naturally multimodal. To address this issue, in this work, we first propose an online mixture model learning approach based on nice properties of the mature optimal transport theory (OT-MM). Specifically, the centroids and covariance matrices of the mixture model are adapted incrementally according to incoming data streams. The advantages are two-fold: (i) we can characterize more accurately complex data streams and (ii) by using centroids for each class produced by OT-MM, we can estimate the similarity of an unseen example to each class more reasonably when doing inference. Moreover, to combat the catastrophic forgetting in the CIL scenario, we further propose Dynamic Preservation. Particularly, after performing the dynamic preservation technique across data streams, the latent representations of the classes in the old and new tasks become more condensed themselves and more separate from each other. Together with a contraction feature extractor, this technique facilitates the model in mitigating the catastrophic forgetting. The experimental results on real-world datasets show that our proposed method can significantly outperform the current state-of-the-art baselines.", "published": "2022-11-30T06:40:29Z", "version": 2}, {"aid": "2211.17115", "authors": ["Giannis Daras", "Alexandros G. Dimakis"], "title": "Multiresolution Textual Inversion", "url": "http://arxiv.org/pdf/2211.17115v1", "summary": "We extend Textual Inversion to learn pseudo-words that represent a concept at different resolutions. This allows us to generate images that use the concept with different levels of detail and also to manipulate different resolutions using language. Once learned, the user can generate images at different levels of agreement to the original concept; \"A photo of $S^*(0)$\" produces the exact object while the prompt \"A photo of $S^*(0.8)$\" only matches the rough outlines and colors. Our framework allows us to generate images that use different resolutions of an image (e.g. details, textures, styles) as separate pseudo-words that can be composed in various ways. We open-soure our code in the following URL: https://github.com/giannisdaras/multires_textual_inversion", "published": "2022-11-30T15:57:56Z", "version": 1}, {"aid": "2212.00490", "authors": ["Yinhuai Wang", "Jiwen Yu", "Jian Zhang"], "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model", "url": "http://arxiv.org/pdf/2212.00490v2", "summary": "Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration.", "published": "2022-12-01T13:33:47Z", "version": 2}, {"aid": "2212.01354", "authors": ["Karl J Friston", "Maxwell J D Ramstead", "Alex B Kiefer", "Alexander Tschantz", "Christopher L Buckley", "Mahault Albarracin", "Riddhi J Pitliya", "Conor Heins", "Brennan Klein", "Beren Millidge", "Dalton A R Sakthivadivel", "Toby St Clere Smithe", "Magnus Koudahl", "Safae Essafi Tremblay", "Capm Petersen", "Kaiser Fung", "Jason G Fox", "Steven Swanson", "Dan Mapes", "Gabriel Ren\u00e9"], "title": "Designing Ecosystems of Intelligence from First Principles", "url": "http://arxiv.org/pdf/2212.01354v2", "summary": "This white paper lays out a vision of research and development in the field of artificial intelligence for the next decade (and beyond). Its denouement is a cyber-physical ecosystem of natural and synthetic sense-making, in which humans are integral participants -- what we call ''shared intelligence''. This vision is premised on active inference, a formulation of adaptive behavior that can be read as a physics of intelligence, and which inherits from the physics of self-organization. In this context, we understand intelligence as the capacity to accumulate evidence for a generative model of one's sensed world -- also known as self-evidencing. Formally, this corresponds to maximizing (Bayesian) model evidence, via belief updating over several scales: i.e., inference, learning, and model selection. Operationally, this self-evidencing can be realized via (variational) message passing or belief propagation on a factor graph. Crucially, active inference foregrounds an existential imperative of intelligent systems; namely, curiosity or the resolution of uncertainty. This same imperative underwrites belief sharing in ensembles of agents, in which certain aspects (i.e., factors) of each agent's generative world model provide a common ground or frame of reference. Active inference plays a foundational role in this ecology of belief sharing -- leading to a formal account of collective intelligence that rests on shared narratives and goals. We also consider the kinds of communication protocols that must be developed to enable such an ecosystem of intelligences and motivate the development of a shared hyper-spatial modeling language and transaction protocol, as a first -- and key -- step towards such an ecology.", "published": "2022-12-02T18:24:06Z", "version": 2}, {"aid": "2212.01433", "authors": ["Sheng Liu", "Xu Zhang", "Nitesh Sekhar", "Yue Wu", "Prateek Singhal", "Carlos Fernandez-Granda"], "title": "Avoiding spurious correlations via logit correction", "url": "http://arxiv.org/pdf/2212.01433v2", "summary": "Empirical studies suggest that machine learning models trained with empirical risk minimization (ERM) often rely on attributes that may be spuriously correlated with the class labels. Such models typically lead to poor performance during inference for data lacking such correlations. In this work, we explicitly consider a situation where potential spurious correlations are present in the majority of training data. In contrast with existing approaches, which use the ERM model outputs to detect the samples without spurious correlations and either heuristically upweight or upsample those samples, we propose the logit correction (LC) loss, a simple yet effective improvement on the softmax cross-entropy loss, to correct the sample logit. We demonstrate that minimizing the LC loss is equivalent to maximizing the group-balanced accuracy, so the proposed LC could mitigate the negative impacts of spurious correlations. Our extensive experimental results further reveal that the proposed LC loss outperforms state-of-the-art solutions on multiple popular benchmarks by a large margin, an average 5.5\\% absolute improvement, without access to spurious attribute labels. LC is also competitive with oracle methods that make use of the attribute labels. Code is available at https://github.com/shengliu66/LC.", "published": "2022-12-02T20:30:59Z", "version": 2}, {"aid": "2212.01508", "authors": ["Rajkumar Vasudeva Raju", "J. Swaroop Guntupalli", "Guangyao Zhou", "Miguel L\u00e1zaro-Gredilla", "Dileep George"], "title": "Space is a latent sequence: Structured sequence learning as a unified theory of representation in the hippocampus", "url": "http://arxiv.org/pdf/2212.01508v1", "summary": "Fascinating and puzzling phenomena, such as landmark vector cells, splitter cells, and event-specific representations to name a few, are regularly discovered in the hippocampus. Without a unifying principle that can explain these divergent observations, each experiment seemingly discovers a new anomaly or coding type. Here, we provide a unifying principle that the mental representation of space is an emergent property of latent higher-order sequence learning. Treating space as a sequence resolves myriad phenomena, and suggests that the place-field mapping methodology where sequential neuron responses are interpreted in spatial and Euclidean terms might itself be a source of anomalies. Our model, called Clone-structured Causal Graph (CSCG), uses a specific higher-order graph scaffolding to learn latent representations by mapping sensory inputs to unique contexts. Learning to compress sequential and episodic experiences using CSCGs result in the emergence of cognitive maps - mental representations of spatial and conceptual relationships in an environment that are suited for planning, introspection, consolidation, and abstraction. We demonstrate that over a dozen different hippocampal phenomena, ranging from those reported in classic experiments to the most recent ones, are succinctly and mechanistically explained by our model.", "published": "2022-12-03T02:00:56Z", "version": 1}, {"aid": "2212.01624", "authors": ["Feng Li", "Yixuan Wu", "Huihui Bai", "Weisi Lin", "Runmin Cong", "Yao Zhao"], "title": "Learning Detail-Structure Alternative Optimization for Blind Super-Resolution", "url": "http://arxiv.org/pdf/2212.01624v1", "summary": "Existing convolutional neural networks (CNN) based image super-resolution (SR) methods have achieved impressive performance on bicubic kernel, which is not valid to handle unknown degradations in real-world applications. Recent blind SR methods suggest to reconstruct SR images relying on blur kernel estimation. However, their results still remain visible artifacts and detail distortion due to the estimation errors. To alleviate these problems, in this paper, we propose an effective and kernel-free network, namely DSSR, which enables recurrent detail-structure alternative optimization without blur kernel prior incorporation for blind SR. Specifically, in our DSSR, a detail-structure modulation module (DSMM) is built to exploit the interaction and collaboration of image details and structures. The DSMM consists of two components: a detail restoration unit (DRU) and a structure modulation unit (SMU). The former aims at regressing the intermediate HR detail reconstruction from LR structural contexts, and the latter performs structural contexts modulation conditioned on the learned detail maps at both HR and LR spaces. Besides, we use the output of DSMM as the hidden state and design our DSSR architecture from a recurrent convolutional neural network (RCNN) view. In this way, the network can alternatively optimize the image details and structural contexts, achieving co-optimization across time. Moreover, equipped with the recurrent connection, our DSSR allows low- and high-level feature representations complementary by observing previous HR details and contexts at every unrolling time. Extensive experiments on synthetic datasets and real-world images demonstrate that our method achieves the state-of-the-art against existing methods. The source code can be found at https://github.com/Arcananana/DSSR.", "published": "2022-12-03T14:44:17Z", "version": 1}, {"aid": "2212.01735", "authors": ["Zhijie Wu", "Yuhe Jin", "Kwang Moo Yi"], "title": "Neural Fourier Filter Bank", "url": "http://arxiv.org/pdf/2212.01735v4", "summary": "We present a novel method to provide efficient and highly detailed reconstructions. Inspired by wavelets, we learn a neural field that decompose the signal both spatially and frequency-wise. We follow the recent grid-based paradigm for spatial decomposition, but unlike existing work, encourage specific frequencies to be stored in each grid via Fourier features encodings. We then apply a multi-layer perceptron with sine activations, taking these Fourier encoded features in at appropriate layers so that higher-frequency components are accumulated on top of lower-frequency components sequentially, which we sum up to form the final output. We demonstrate that our method outperforms the state of the art regarding model compactness and convergence speed on multiple tasks: 2D image fitting, 3D shape reconstruction, and neural radiance fields. Our code is available at https://github.com/ubc-vision/NFFB.", "published": "2022-12-04T03:45:08Z", "version": 4}, {"aid": "2212.02936", "authors": ["Samuel Weinbach", "Marco Bellagente", "Constantin Eichenberg", "Andrew Dai", "Robert Baldock", "Souradeep Nanda", "Bj\u00f6rn Deiseroth", "Koen Oostermeijer", "Hannah Teufel", "Andres Felipe Cruz-Salinas"], "title": "M-VADER: A Model for Diffusion with Multimodal Context", "url": "http://arxiv.org/pdf/2212.02936v2", "summary": "We introduce M-VADER: a diffusion model (DM) for image generation where the output can be specified using arbitrary combinations of images and text. We show how M-VADER enables the generation of images specified using combinations of image and text, and combinations of multiple images. Previously, a number of successful DM image generation algorithms have been introduced that make it possible to specify the output image using a text prompt. Inspired by the success of those models, and led by the notion that language was already developed to describe the elements of visual contexts that humans find most important, we introduce an embedding model closely related to a vision-language model. Specifically, we introduce the embedding model S-MAGMA: a 13 billion parameter multimodal decoder combining components from an autoregressive vision-language model MAGMA and biases finetuned for semantic search.", "published": "2022-12-06T12:45:21Z", "version": 2}, {"aid": "2212.03293", "authors": ["Muheng Li", "Yueqi Duan", "Jie Zhou", "Jiwen Lu"], "title": "Diffusion-SDF: Text-to-Shape via Voxelized Diffusion", "url": "http://arxiv.org/pdf/2212.03293v2", "summary": "With the rising industrial attention to 3D virtual modeling technology, generating novel 3D content based on specified conditions (e.g. text) has become a hot issue. In this paper, we propose a new generative 3D modeling framework called Diffusion-SDF for the challenging task of text-to-shape synthesis. Previous approaches lack flexibility in both 3D data representation and shape generation, thereby failing to generate highly diversified 3D shapes conforming to the given text descriptions. To address this, we propose a SDF autoencoder together with the Voxelized Diffusion model to learn and generate representations for voxelized signed distance fields (SDFs) of 3D shapes. Specifically, we design a novel UinU-Net architecture that implants a local-focused inner network inside the standard U-Net architecture, which enables better reconstruction of patch-independent SDF representations. We extend our approach to further text-to-shape tasks including text-conditioned shape completion and manipulation. Experimental results show that Diffusion-SDF generates both higher quality and more diversified 3D shapes that conform well to given text descriptions when compared to previous approaches. Code is available at: https://github.com/ttlmh/Diffusion-SDF", "published": "2022-12-06T19:46:47Z", "version": 2}, {"aid": "2212.03306", "authors": ["Yao Su", "Zhentian Qian", "Lifang He", "Xiangnan Kong"], "title": "ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data", "url": "http://arxiv.org/pdf/2212.03306v1", "summary": "Brain extraction and registration are important preprocessing steps in neuroimaging data analysis, where the goal is to extract the brain regions from MRI scans (i.e., extraction step) and align them with a target brain image (i.e., registration step). Conventional research mainly focuses on developing methods for the extraction and registration tasks separately under supervised settings. The performance of these methods highly depends on the amount of training samples and visual inspections performed by experts for error correction. However, in many medical studies, collecting voxel-level labels and conducting manual quality control in high-dimensional neuroimages (e.g., 3D MRI) are very expensive and time-consuming. Moreover, brain extraction and registration are highly related tasks in neuroimaging data and should be solved collectively. In this paper, we study the problem of unsupervised collective extraction and registration in neuroimaging data. We propose a unified end-to-end framework, called ERNet (Extraction-Registration Network), to jointly optimize the extraction and registration tasks, allowing feedback between them. Specifically, we use a pair of multi-stage extraction and registration modules to learn the extraction mask and transformation, where the extraction network improves the extraction accuracy incrementally and the registration network successively warps the extracted image until it is well-aligned with the target image. Experiment results on real-world datasets show that our proposed method can effectively improve the performance on extraction and registration tasks in neuroimaging data. Our code and data can be found at https://github.com/ERNetERNet/ERNet", "published": "2022-12-06T20:12:54Z", "version": 1}, {"aid": "2212.03361", "authors": ["Tsiry Mayet", "Simon Bernard", "Clement Chatelain", "Romain Herault"], "title": "Domain Translation via Latent Space Mapping", "url": "http://arxiv.org/pdf/2212.03361v1", "summary": "In this paper, we investigate the problem of multi-domain translation: given an element $a$ of domain $A$, we would like to generate a corresponding $b$ sample in another domain $B$, and vice versa. Acquiring supervision in multiple domains can be a tedious task, also we propose to learn this translation from one domain to another when supervision is available as a pair $(a,b)\\sim A\\times B$ and leveraging possible unpaired data when only $a\\sim A$ or only $b\\sim B$ is available. We introduce a new unified framework called Latent Space Mapping (\\model) that exploits the manifold assumption in order to learn, from each domain, a latent space. Unlike existing approaches, we propose to further regularize each latent space using available domains by learning each dependency between pairs of domains. We evaluate our approach in three tasks performing i) synthetic dataset with image translation, ii) real-world task of semantic segmentation for medical images, and iii) real-world task of facial landmark detection.", "published": "2022-12-06T23:09:40Z", "version": 1}, {"aid": "2212.04247", "authors": ["Chengwei Zheng", "Wenbin Lin", "Feng Xu"], "title": "EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points", "url": "http://arxiv.org/pdf/2212.04247v2", "summary": "Neural radiance fields (NeRF) achieve highly photo-realistic novel-view synthesis, but it's a challenging problem to edit the scenes modeled by NeRF-based methods, especially for dynamic scenes. We propose editable neural radiance fields that enable end-users to easily edit dynamic scenes and even support topological changes. Input with an image sequence from a single camera, our network is trained fully automatically and models topologically varying dynamics using our picked-out surface key points. Then end-users can edit the scene by easily dragging the key points to desired new positions. To achieve this, we propose a scene analysis method to detect and initialize key points by considering the dynamics in the scene, and a weighted key points strategy to model topologically varying dynamics by joint key points and weights optimization. Our method supports intuitive multi-dimensional (up to 3D) editing and can generate novel scenes that are unseen in the input sequence. Experiments demonstrate that our method achieves high-quality editing on various dynamic scenes and outperforms the state-of-the-art. Our code and captured data are available at https://chengwei-zheng.github.io/EditableNeRF/.", "published": "2022-12-07T06:08:03Z", "version": 2}, {"aid": "2212.04195", "authors": ["Zi-Xuan Zhou", "Xi-Nian Zuo"], "title": "A Paradigm Shift in Neuroscience Driven by Big Data: State of art, Challenges, and Proof of Concept", "url": "http://arxiv.org/pdf/2212.04195v2", "summary": "A recent editorial in Nature noted that cognitive neuroscience is at a crossroads where it is a thorny issue to reliably reveal brain-behavior associations. This commentary sketches a big data science way out for cognitive neuroscience, namely population neuroscience. In terms of design, analysis, and interpretations, population neuroscience research takes the design control to an unprecedented level, greatly expands the dimensions of the data analysis space, and paves a paradigm shift for exploring mechanisms on brain-behavior associations.", "published": "2022-12-08T11:23:07Z", "version": 2}, {"aid": "2212.04316", "authors": ["Francesco L\u00e4ssig", "Pau Vilimelis Aceituno", "Martino Sorbaro", "Benjamin F. Grewe"], "title": "Bio-Inspired, Task-Free Continual Learning through Activity Regularization", "url": "http://arxiv.org/pdf/2212.04316v1", "summary": "The ability to sequentially learn multiple tasks without forgetting is a key skill of biological brains, whereas it represents a major challenge to the field of deep learning. To avoid catastrophic forgetting, various continual learning (CL) approaches have been devised. However, these usually require discrete task boundaries. This requirement seems biologically implausible and often limits the application of CL methods in the real world where tasks are not always well defined. Here, we take inspiration from neuroscience, where sparse, non-overlapping neuronal representations have been suggested to prevent catastrophic forgetting. As in the brain, we argue that these sparse representations should be chosen on the basis of feed forward (stimulus-specific) as well as top-down (context-specific) information. To implement such selective sparsity, we use a bio-plausible form of hierarchical credit assignment known as Deep Feedback Control (DFC) and combine it with a winner-take-all sparsity mechanism. In addition to sparsity, we introduce lateral recurrent connections within each layer to further protect previously learned representations. We evaluate the new sparse-recurrent version of DFC on the split-MNIST computer vision benchmark and show that only the combination of sparsity and intra-layer recurrent connections improves CL performance with respect to standard backpropagation. Our method achieves similar performance to well-known CL methods, such as Elastic Weight Consolidation and Synaptic Intelligence, without requiring information about task boundaries. Overall, we showcase the idea of adopting computational principles from the brain to derive new, task-free learning algorithms for CL.", "published": "2022-12-08T15:14:20Z", "version": 1}, {"aid": "2212.04319", "authors": ["Seongmin Hong", "Inbum Park", "Se Young Chun"], "title": "On the Robustness of Normalizing Flows for Inverse Problems in Imaging", "url": "http://arxiv.org/pdf/2212.04319v2", "summary": "Conditional normalizing flows can generate diverse image samples for solving inverse problems. Most normalizing flows for inverse problems in imaging employ the conditional affine coupling layer that can generate diverse images quickly. However, unintended severe artifacts are occasionally observed in the output of them. In this work, we address this critical issue by investigating the origins of these artifacts and proposing the conditions to avoid them. First of all, we empirically and theoretically reveal that these problems are caused by \"exploding inverse\" in the conditional affine coupling layer for certain out-of-distribution (OOD) conditional inputs. Then, we further validated that the probability of causing erroneous artifacts in pixels is highly correlated with a Mahalanobis distance-based OOD score for inverse problems in imaging. Lastly, based on our investigations, we propose a remark to avoid exploding inverse and then based on it, we suggest a simple remedy that substitutes the affine coupling layers with the modified rational quadratic spline coupling layers in normalizing flows, to encourage the robustness of generated image samples. Our experimental results demonstrated that our suggested methods effectively suppressed critical artifacts occurring in normalizing flows for super-resolution space generation and low-light image enhancement.", "published": "2022-12-08T15:18:28Z", "version": 2}, {"aid": "2212.04362", "authors": ["Jiezhang Cao", "Qin Wang", "Yongqin Xian", "Yawei Li", "Bingbing Ni", "Zhiming Pi", "Kai Zhang", "Yulun Zhang", "Radu Timofte", "Luc Van Gool"], "title": "CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution", "url": "http://arxiv.org/pdf/2212.04362v3", "summary": "Learning continuous image representations is recently gaining popularity for image super-resolution (SR) because of its ability to reconstruct high-resolution images with arbitrary scales from low-resolution inputs. Existing methods mostly ensemble nearby features to predict the new pixel at any queried coordinate in the SR image. Such a local ensemble suffers from some limitations: i) it has no learnable parameters and it neglects the similarity of the visual features; ii) it has a limited receptive field and cannot ensemble relevant features in a large field which are important in an image. To address these issues, this paper proposes a continuous implicit attention-in-attention network, called CiaoSR. We explicitly design an implicit attention network to learn the ensemble weights for the nearby local features. Furthermore, we embed a scale-aware attention in this implicit attention network to exploit additional non-local information. Extensive experiments on benchmark datasets demonstrate CiaoSR significantly outperforms the existing single image SR methods with the same backbone. In addition, CiaoSR also achieves the state-of-the-art performance on the arbitrary-scale SR task. The effectiveness of the method is also demonstrated on the real-world SR setting. More importantly, CiaoSR can be flexibly integrated into any backbone to improve the SR performance.", "published": "2022-12-08T15:57:46Z", "version": 3}, {"aid": "2212.04705", "authors": ["Youming Deng", "Xueting Li", "Sifei Liu", "Ming-Hsuan Yang"], "title": "Physics-based Indirect Illumination for Inverse Rendering", "url": "http://arxiv.org/pdf/2212.04705v2", "summary": "We present a physics-based inverse rendering method that learns the illumination, geometry, and materials of a scene from posed multi-view RGB images. To model the illumination of a scene, existing inverse rendering works either completely ignore the indirect illumination or model it by coarse approximations, leading to sub-optimal illumination, geometry, and material prediction of the scene. In this work, we propose a physics-based illumination model that first locates surface points through an efficient refined sphere tracing algorithm, then explicitly traces the incoming indirect lights at each surface point based on reflection. Then, we estimate each identified indirect light through an efficient neural network. Moreover, we utilize the Leibniz's integral rule to resolve non-differentiability in the proposed illumination model caused by boundary lights inspired by differentiable irradiance in computer graphics. As a result, the proposed differentiable illumination model can be learned end-to-end together with geometry and materials estimation. As a side product, our physics-based inverse rendering model also facilitates flexible and realistic material editing as well as relighting. Extensive experiments on synthetic and real-world datasets demonstrate that the proposed method performs favorably against existing inverse rendering methods on novel view synthesis and inverse rendering.", "published": "2022-12-09T07:33:49Z", "version": 2}, {"aid": "2212.04780", "authors": ["Yongkweon Jeon", "Chungman Lee", "Ho-young Kim"], "title": "Genie: Show Me the Data for Quantization", "url": "http://arxiv.org/pdf/2212.04780v3", "summary": "Zero-shot quantization is a promising approach for developing lightweight deep neural networks when data is inaccessible owing to various reasons, including cost and issues related to privacy. By exploiting the learned parameters ($\\mu$ and $\\sigma$) of batch normalization layers in an FP32-pre-trained model, zero-shot quantization schemes focus on generating synthetic data. Subsequently, they distill knowledge from the pre-trained model (teacher) to the quantized model (student) such that the quantized model can be optimized with the synthetic dataset. However, thus far, zero-shot quantization has primarily been discussed in the context of quantization-aware training methods, which require task-specific losses and long-term optimization as much as retraining. We thus introduce a post-training quantization scheme for zero-shot quantization that produces high-quality quantized networks within a few hours. Furthermore, we propose a framework called Genie~that generates data suited for quantization. With the data synthesized by Genie, we can produce robust quantized models without real datasets, which is comparable to few-shot quantization. We also propose a post-training quantization algorithm to enhance the performance of quantized models. By combining them, we can bridge the gap between zero-shot and few-shot quantization while significantly improving the quantization performance compared to that of existing approaches. In other words, we can obtain a unique state-of-the-art zero-shot quantization approach. The code is available at \\url{https://github.com/SamsungLabs/Genie}.", "published": "2022-12-09T11:18:40Z", "version": 3}, {"aid": "2212.05895", "authors": ["Haibin He", "Xinyuan Chen", "Chaoyue Wang", "Juhua Liu", "Bo Du", "Dacheng Tao", "Yu Qiao"], "title": "Diff-Font: Diffusion Model for Robust One-Shot Font Generation", "url": "http://arxiv.org/pdf/2212.05895v3", "summary": "Font generation is a difficult and time-consuming task, especially in those languages using ideograms that have complicated structures with a large number of characters, such as Chinese. To solve this problem, few-shot font generation and even one-shot font generation have attracted a lot of attention. However, most existing font generation methods may still suffer from (i) large cross-font gap challenge; (ii) subtle cross-font variation problem; and (iii) incorrect generation of complicated characters. In this paper, we propose a novel one-shot font generation method based on a diffusion model, named Diff-Font, which can be stably trained on large datasets. The proposed model aims to generate the entire font library by giving only one sample as the reference. Specifically, a large stroke-wise dataset is constructed, and a stroke-wise diffusion model is proposed to preserve the structure and the completion of each generated character. To our best knowledge, the proposed Diff-Font is the first work that developed diffusion models to handle the font generation task. The well-trained Diff-Font is not only robust to font gap and font variation, but also achieved promising performance on difficult character generation. Compared to previous font generation methods, our model reaches state-of-the-art performance both qualitatively and quantitatively.", "published": "2022-12-12T13:51:50Z", "version": 3}, {"aid": "2212.06339", "authors": ["Hongteng Xu", "Minjie Cheng"], "title": "Regularized Optimal Transport Layers for Generalized Global Pooling Operations", "url": "http://arxiv.org/pdf/2212.06339v1", "summary": "Global pooling is one of the most significant operations in many machine learning models and tasks, which works for information fusion and structured data (like sets and graphs) representation. However, without solid mathematical fundamentals, its practical implementations often depend on empirical mechanisms and thus lead to sub-optimal, even unsatisfactory performance. In this work, we develop a novel and generalized global pooling framework through the lens of optimal transport. The proposed framework is interpretable from the perspective of expectation-maximization. Essentially, it aims at learning an optimal transport across sample indices and feature dimensions, making the corresponding pooling operation maximize the conditional expectation of input data. We demonstrate that most existing pooling methods are equivalent to solving a regularized optimal transport (ROT) problem with different specializations, and more sophisticated pooling operations can be implemented by hierarchically solving multiple ROT problems. Making the parameters of the ROT problem learnable, we develop a family of regularized optimal transport pooling (ROTP) layers. We implement the ROTP layers as a new kind of deep implicit layer. Their model architectures correspond to different optimization algorithms. We test our ROTP layers in several representative set-level machine learning scenarios, including multi-instance learning (MIL), graph classification, graph set representation, and image classification. Experimental results show that applying our ROTP layers can reduce the difficulty of the design and selection of global pooling -- our ROTP layers may either imitate some existing global pooling methods or lead to some new pooling layers fitting data better. The code is available at \\url{https://github.com/SDS-Lab/ROT-Pooling}.", "published": "2022-12-13T02:46:36Z", "version": 1}, {"aid": "2212.08420", "authors": ["Mert Bulent Sariyildiz", "Karteek Alahari", "Diane Larlus", "Yannis Kalantidis"], "title": "Fake it till you make it: Learning transferable representations from synthetic ImageNet clones", "url": "http://arxiv.org/pdf/2212.08420v2", "summary": "Recent image generation models such as Stable Diffusion have exhibited an impressive ability to generate fairly realistic images starting from a simple text prompt. Could such models render real images obsolete for training image prediction models? In this paper, we answer part of this provocative question by investigating the need for real images when training models for ImageNet classification. Provided only with the class names that have been used to build the dataset, we explore the ability of Stable Diffusion to generate synthetic clones of ImageNet and measure how useful these are for training classification models from scratch. We show that with minimal and class-agnostic prompt engineering, ImageNet clones are able to close a large part of the gap between models produced by synthetic images and models trained with real images, for the several standard classification benchmarks that we consider in this study. More importantly, we show that models trained on synthetic images exhibit strong generalization properties and perform on par with models trained on real data for transfer. Project page: https://europe.naverlabs.com/imagenet-sd/", "published": "2022-12-16T11:44:01Z", "version": 2}, {"aid": "2212.10602", "authors": ["Alexander Gorsky"], "title": "Page time and the order parameter for a consciousness state", "url": "http://arxiv.org/pdf/2212.10602v2", "summary": "In this short note using the analogy with the recent resolution of the black hole information paradox we conjecture the order parameter for the state of consciousness based on the notion of the Page curve and the Page time. The entanglement between the state of the brain and time series of neuronal firing as well as the non-orthogonality of the functional connectomes play a key role.", "published": "2022-12-18T18:31:50Z", "version": 2}, {"aid": "2212.13912", "authors": ["Sarah Boufelja Y.", "Anthony Quinn", "Martin Corless", "Robert Shorten"], "title": "Fully Probabilistic Design for Optimal Transport", "url": "http://arxiv.org/pdf/2212.13912v1", "summary": "The goal of this paper is to introduce a new theoretical framework for Optimal Transport (OT), using the terminology and techniques of Fully Probabilistic Design (FPD). Optimal Transport is the canonical method for comparing probability measures and has been successfully applied in a wide range of areas (computer vision Rubner et al. [2004], computer graphics Solomon et al. [2015], natural language processing Kusner et al. [2015], etc.). However, we argue that the current OT framework suffers from two shortcomings: first, it is hard to induce generic constraints and probabilistic knowledge in the OT problem; second, the current formalism does not address the question of uncertainty in the marginals, lacking therefore the mechanisms to design robust solutions. By viewing the OT problem as the optimal design of a probability density function with marginal constraints, we prove that OT is an instance of the more generic FPD framework. In this new setting, we can furnish the OT framework with the necessary mechanisms for processing probabilistic constraints and deriving uncertainty quantifiers, hence establishing a new extended framework, called FPD-OT. Our main contribution in this paper is to establish the connection between OT and FPD, providing new theoretical insights for both. This will lay the foundations for the application of FPD-OT in a subsequent work, notably in processing more sophisticated knowledge constraints, as well as in designing robust solutions in the case of uncertain marginals.", "published": "2022-12-19T12:52:47Z", "version": 1}, {"aid": "2212.10048", "authors": ["Yang Jiao", "Kai Yang", "Tiancheng Wu", "Dongjin Song", "Chengtao Jian"], "title": "Asynchronous Distributed Bilevel Optimization", "url": "http://arxiv.org/pdf/2212.10048v3", "summary": "Bilevel optimization plays an essential role in many machine learning tasks, ranging from hyperparameter optimization to meta-learning. Existing studies on bilevel optimization, however, focus on either centralized or synchronous distributed setting. The centralized bilevel optimization approaches require collecting massive amount of data to a single server, which inevitably incur significant communication expenses and may give rise to data privacy risks. Synchronous distributed bilevel optimization algorithms, on the other hand, often face the straggler problem and will immediately stop working if a few workers fail to respond. As a remedy, we propose Asynchronous Distributed Bilevel Optimization (ADBO) algorithm. The proposed ADBO can tackle bilevel optimization problems with both nonconvex upper-level and lower-level objective functions, and its convergence is theoretically guaranteed. Furthermore, it is revealed through theoretic analysis that the iteration complexity of ADBO to obtain the $\\epsilon$-stationary point is upper bounded by $\\mathcal{O}(\\frac{1}{{{\\epsilon ^2}}})$. Thorough empirical studies on public datasets have been conducted to elucidate the effectiveness and efficiency of the proposed ADBO.", "published": "2022-12-20T07:44:48Z", "version": 3}, {"aid": "2212.10772", "authors": ["Shen Zheng", "Yiling Ma", "Jinqian Pan", "Changjie Lu", "Gaurav Gupta"], "title": "Low-Light Image and Video Enhancement: A Comprehensive Survey and Beyond", "url": "http://arxiv.org/pdf/2212.10772v5", "summary": "This paper presents a comprehensive survey of low-light image and video enhancement, addressing two primary challenges in the field. The first challenge is the prevalence of mixed over-/under-exposed images, which are not adequately addressed by existing methods. In response, this work introduces two enhanced variants of the SICE dataset: SICE_Grad and SICE_Mix, designed to better represent these complexities. The second challenge is the scarcity of suitable low-light video datasets for training and testing. To address this, the paper introduces the Night Wenzhou dataset, a large-scale, high-resolution video collection that features challenging fast-moving aerial scenes and streetscapes with varied illuminations and degradation. This study also conducts an extensive analysis of key techniques and performs comparative experiments using the proposed and current benchmark datasets. The survey concludes by highlighting emerging applications, discussing unresolved challenges, and suggesting future research directions within the LLIE community. The datasets are available at https://github.com/ShenZheng2000/LLIE_Survey.", "published": "2022-12-21T05:08:37Z", "version": 5}, {"aid": "2212.11870", "authors": ["Blair Bilodeau", "Natasha Jaques", "Pang Wei Koh", "Been Kim"], "title": "Impossibility Theorems for Feature Attribution", "url": "http://arxiv.org/pdf/2212.11870v3", "summary": "Despite a sea of interpretability methods that can produce plausible explanations, the field has also empirically seen many failure cases of such methods. In light of these results, it remains unclear for practitioners how to use these methods and choose between them in a principled way. In this paper, we show that for moderately rich model classes (easily satisfied by neural networks), any feature attribution method that is complete and linear -- for example, Integrated Gradients and SHAP -- can provably fail to improve on random guessing for inferring model behaviour. Our results apply to common end-tasks such as characterizing local model behaviour, identifying spurious features, and algorithmic recourse. One takeaway from our work is the importance of concretely defining end-tasks: once such an end-task is defined, a simple and direct approach of repeated model evaluations can outperform many other complex feature attribution methods.", "published": "2022-12-22T17:03:57Z", "version": 3}, {"aid": "2212.12538", "authors": ["Toby St Clere Smithe"], "title": "Mathematical Foundations for a Compositional Account of the Bayesian Brain", "url": "http://arxiv.org/pdf/2212.12538v3", "summary": "This dissertation reports some first steps towards a compositional account of active inference and the Bayesian brain. Specifically, we use the tools of contemporary applied category theory to supply functorial semantics for approximate inference. To do so, we define on the `syntactic' side the new notion of Bayesian lens and show that Bayesian updating composes according to the compositional lens pattern. Using Bayesian lenses, and inspired by compositional game theory, we define fibrations of statistical games and classify various problems of statistical inference as corresponding sections: the chain rule of the relative entropy is formalized as a strict section, while maximum likelihood estimation and the free energy give lax sections. In the process, we introduce a new notion of `copy-composition'.   On the `semantic' side, we present a new formalization of general open dynamical systems (particularly: deterministic, stochastic, and random; and discrete- and continuous-time) as certain coalgebras of polynomial functors, which we show collect into monoidal opindexed categories (or, alternatively, into algebras for multicategories of generalized polynomial functors). We use these opindexed categories to define monoidal bicategories of cilia: dynamical systems which control lenses, and which supply the target for our functorial semantics. Accordingly, we construct functors which explain the bidirectional compositional structure of predictive coding neural circuits under the free energy principle, thereby giving a formal mathematical underpinning to the bidirectionality observed in the cortex. Along the way, we explain how to compose rate-coded neural circuits using an algebra for a multicategory of linear circuit diagrams, showing subsequently that this is subsumed by lenses and polynomial functors.", "published": "2022-12-23T18:58:17Z", "version": 3}, {"aid": "2212.12552", "authors": ["Xu Ma", "Huan Wang", "Can Qin", "Kunpeng Li", "Xingchen Zhao", "Jie Fu", "Yun Fu"], "title": "A Close Look at Spatial Modeling: From Attention to Convolution", "url": "http://arxiv.org/pdf/2212.12552v1", "summary": "Vision Transformers have shown great promise recently for many vision tasks due to the insightful architecture design and attention mechanism. By revisiting the self-attention responses in Transformers, we empirically observe two interesting issues. First, Vision Transformers present a queryirrelevant behavior at deep layers, where the attention maps exhibit nearly consistent contexts in global scope, regardless of the query patch position (also head-irrelevant). Second, the attention maps are intrinsically sparse, few tokens dominate the attention weights; introducing the knowledge from ConvNets would largely smooth the attention and enhance the performance. Motivated by above observations, we generalize self-attention formulation to abstract a queryirrelevant global context directly and further integrate the global context into convolutions. The resulting model, a Fully Convolutional Vision Transformer (i.e., FCViT), purely consists of convolutional layers and firmly inherits the merits of both attention mechanism and convolutions, including dynamic property, weight sharing, and short- and long-range feature modeling, etc. Experimental results demonstrate the effectiveness of FCViT. With less than 14M parameters, our FCViT-S12 outperforms related work ResT-Lite by 3.7% top1 accuracy on ImageNet-1K. When scaling FCViT to larger models, we still perform better than previous state-of-the-art ConvNeXt with even fewer parameters. FCViT-based models also demonstrate promising transferability to downstream tasks, like object detection, instance segmentation, and semantic segmentation. Codes and models are made available at: https://github.com/ma-xu/FCViT.", "published": "2022-12-23T19:13:43Z", "version": 1}, {"aid": "2212.12653", "authors": ["Dan Liu", "Xi Chen", "Chen Ma", "Xue Liu"], "title": "Hyperspherical Quantization: Toward Smaller and More Accurate Models", "url": "http://arxiv.org/pdf/2212.12653v1", "summary": "Model quantization enables the deployment of deep neural networks under resource-constrained devices. Vector quantization aims at reducing the model size by indexing model weights with full-precision embeddings, i.e., codewords, while the index needs to be restored to 32-bit during computation. Binary and other low-precision quantization methods can reduce the model size up to 32$\\times$, however, at the cost of a considerable accuracy drop. In this paper, we propose an efficient framework for ternary quantization to produce smaller and more accurate compressed models. By integrating hyperspherical learning, pruning and reinitialization, our proposed Hyperspherical Quantization (HQ) method reduces the cosine distance between the full-precision and ternary weights, thus reducing the bias of the straight-through gradient estimator during ternary quantization. Compared with existing work at similar compression levels ($\\sim$30$\\times$, $\\sim$40$\\times$), our method significantly improves the test accuracy and reduces the model size.", "published": "2022-12-24T04:42:15Z", "version": 1}, {"aid": "2212.12749", "authors": ["Linqi Zhou", "Michael Poli", "Winnie Xu", "Stefano Massaroli", "Stefano Ermon"], "title": "Deep Latent State Space Models for Time-Series Generation", "url": "http://arxiv.org/pdf/2212.12749v3", "summary": "Methods based on ordinary differential equations (ODEs) are widely used to build generative models of time-series. In addition to high computational overhead due to explicitly computing hidden states recurrence, existing ODE-based models fall short in learning sequence data with sharp transitions - common in many real-world systems - due to numerical challenges during optimization. In this work, we propose LS4, a generative model for sequences with latent variables evolving according to a state space ODE to increase modeling capacity. Inspired by recent deep state space models (S4), we achieve speedups by leveraging a convolutional representation of LS4 which bypasses the explicit evaluation of hidden states. We show that LS4 significantly outperforms previous continuous-time generative models in terms of marginal distribution, classification, and prediction scores on real-world datasets in the Monash Forecasting Repository, and is capable of modeling highly stochastic data with sharp temporal transitions. LS4 sets state-of-the-art for continuous-time latent generative models, with significant improvement of mean squared error and tighter variational lower bounds on irregularly-sampled datasets, while also being x100 faster than other baselines on long sequences.", "published": "2022-12-24T15:17:42Z", "version": 3}, {"aid": "2212.12795", "authors": ["Diederik Aerts", "Jonito Aerts Argu\u00eblles", "Lester Beltran", "Sandro Sozzo"], "title": "Development of a Thermodynamics of Human Cognition and Human Culture", "url": "http://arxiv.org/pdf/2212.12795v2", "summary": "Inspired by foundational studies in classical and quantum physics, and by information retrieval studies in quantum information theory, we prove that the notions of 'energy' and 'entropy' can be consistently introduced in human language and, more generally, in human culture. More explicitly, if energy is attributed to words according to their frequency of appearance in a text, then the ensuing energy levels are distributed non-classically, namely, they obey Bose-Einstein, rather than Maxwell-Boltzmann, statistics, as a consequence of the genuinely 'quantum indistinguishability' of the words that appear in the text. Secondly, the 'quantum entanglement' due to the way meaning is carried by a text reduces the (von Neumann) entropy of the words that appear in the text, a behaviour which cannot be explained within classical (thermodynamic or information) entropy. We claim here that this 'quantum-type behaviour is valid in general in human language', namely, any text is conceptually more concrete than the words composing it, which entails that the entropy of the overall text decreases. In addition, we provide examples taken from cognition, where quantization of energy appears in categorical perception, and from culture, where entities collaborate, thus 'entangle', to decrease overall entropy. We use these findings to propose the development of a new 'non-classical thermodynamic theory' for human cognition, which also covers broad parts of human culture and its artefacts and bridges concepts with quantum physics entities.", "published": "2022-12-24T18:19:05Z", "version": 2}, {"aid": "2212.13038", "authors": ["Xinyi Wang", "Jianteng Peng", "Sufang Zhang", "Bihui Chen", "Yi Wang", "Yandong Guo"], "title": "A Survey of Face Recognition", "url": "http://arxiv.org/pdf/2212.13038v1", "summary": "Recent years witnessed the breakthrough of face recognition with deep convolutional neural networks. Dozens of papers in the field of FR are published every year. Some of them were applied in the industrial community and played an important role in human life such as device unlock, mobile payment, and so on. This paper provides an introduction to face recognition, including its history, pipeline, algorithms based on conventional manually designed features or deep learning, mainstream training, evaluation datasets, and related applications. We have analyzed and compared state-of-the-art works as many as possible, and also carefully designed a set of experiments to find the effect of backbone size and data distribution. This survey is a material of the tutorial named The Practical Face Recognition Technology in the Industrial World in the FG2023.", "published": "2022-12-26T08:36:58Z", "version": 1}, {"aid": "2212.13185", "authors": ["Tong Wei", "Yash Patel", "Alexander Shekhovtsov", "Jiri Matas", "Daniel Barath"], "title": "Generalized Differentiable RANSAC", "url": "http://arxiv.org/pdf/2212.13185v3", "summary": "We propose $\\nabla$-RANSAC, a generalized differentiable RANSAC that allows learning the entire randomized robust estimation pipeline. The proposed approach enables the use of relaxation techniques for estimating the gradients in the sampling distribution, which are then propagated through a differentiable solver. The trainable quality function marginalizes over the scores from all the models estimated within $\\nabla$-RANSAC to guide the network learning accurate and useful inlier probabilities or to train feature detection and matching networks. Our method directly maximizes the probability of drawing a good hypothesis, allowing us to learn better sampling distributions. We test $\\nabla$-RANSAC on various real-world scenarios on fundamental and essential matrix estimation, and 3D point cloud registration, outdoors and indoors, with handcrafted and learning-based features. It is superior to the state-of-the-art in terms of accuracy while running at a similar speed to its less accurate alternatives. The code and trained models are available at https://github.com/weitong8591/differentiable_ransac.", "published": "2022-12-26T15:13:13Z", "version": 3}, {"aid": "2212.13350", "authors": ["Xiaoxin He", "Bryan Hooi", "Thomas Laurent", "Adam Perold", "Yann LeCun", "Xavier Bresson"], "title": "A Generalization of ViT/MLP-Mixer to Graphs", "url": "http://arxiv.org/pdf/2212.13350v2", "summary": "Graph Neural Networks (GNNs) have shown great potential in the field of graph representation learning. Standard GNNs define a local message-passing mechanism which propagates information over the whole graph domain by stacking multiple layers. This paradigm suffers from two major limitations, over-squashing and poor long-range dependencies, that can be solved using global attention but significantly increases the computational cost to quadratic complexity. In this work, we propose an alternative approach to overcome these structural limitations by leveraging the ViT/MLP-Mixer architectures introduced in computer vision. We introduce a new class of GNNs, called Graph ViT/MLP-Mixer, that holds three key properties. First, they capture long-range dependency and mitigate the issue of over-squashing as demonstrated on Long Range Graph Benchmark and TreeNeighbourMatch datasets. Second, they offer better speed and memory efficiency with a complexity linear to the number of nodes and edges, surpassing the related Graph Transformer and expressive GNN models. Third, they show high expressivity in terms of graph isomorphism as they can distinguish at least 3-WL non-isomorphic graphs. We test our architecture on 4 simulated datasets and 7 real-world benchmarks, and show highly competitive results on all of them. The source code is available for reproducibility at: \\url{https://github.com/XiaoxinHe/Graph-ViT-MLPMixer}.", "published": "2022-12-27T03:27:46Z", "version": 2}, {"aid": "2301.00265", "authors": ["Yuqi Fang", "Pew-Thian Yap", "Weili Lin", "Hongtu Zhu", "Mingxia Liu"], "title": "Source-Free Unsupervised Domain Adaptation: A Survey", "url": "http://arxiv.org/pdf/2301.00265v2", "summary": "Unsupervised domain adaptation (UDA) via deep learning has attracted appealing attention for tackling domain-shift problems caused by distribution discrepancy across different domains. Existing UDA approaches highly depend on the accessibility of source domain data, which is usually limited in practical scenarios due to privacy protection, data storage and transmission cost, and computation burden. To tackle this issue, many source-free unsupervised domain adaptation (SFUDA) methods have been proposed recently, which perform knowledge transfer from a pre-trained source model to unlabeled target domain with source data inaccessible. A comprehensive review of these works on SFUDA is of great significance. In this paper, we provide a timely and systematic literature review of existing SFUDA approaches from a technical perspective. Specifically, we categorize current SFUDA studies into two groups, i.e., white-box SFUDA and black-box SFUDA, and further divide them into finer subcategories based on different learning strategies they use. We also investigate the challenges of methods in each subcategory, discuss the advantages/disadvantages of white-box and black-box SFUDA methods, conclude the commonly used benchmark datasets, and summarize the popular techniques for improved generalizability of models learned without using source data. We finally discuss several promising future directions in this field.", "published": "2022-12-31T18:44:45Z", "version": 2}, {"aid": "2301.05187", "authors": ["Vishwanath Saragadam", "Daniel LeJeune", "Jasper Tan", "Guha Balakrishnan", "Ashok Veeraraghavan", "Richard G. Baraniuk"], "title": "WIRE: Wavelet Implicit Neural Representations", "url": "http://arxiv.org/pdf/2301.05187v1", "summary": "Implicit neural representations (INRs) have recently advanced numerous vision-related areas. INR performance depends strongly on the choice of the nonlinear activation function employed in its multilayer perceptron (MLP) network. A wide range of nonlinearities have been explored, but, unfortunately, current INRs designed to have high accuracy also suffer from poor robustness (to signal noise, parameter variation, etc.). Inspired by harmonic analysis, we develop a new, highly accurate and robust INR that does not exhibit this tradeoff. Wavelet Implicit neural REpresentation (WIRE) uses a continuous complex Gabor wavelet activation function that is well-known to be optimally concentrated in space-frequency and to have excellent biases for representing images. A wide range of experiments (image denoising, image inpainting, super-resolution, computed tomography reconstruction, image overfitting, and novel view synthesis with neural radiance fields) demonstrate that WIRE defines the new state of the art in INR accuracy, training time, and robustness.", "published": "2023-01-05T20:24:56Z", "version": 1}, {"aid": "2301.02328", "authors": ["Divyansh Garg", "Joey Hejna", "Matthieu Geist", "Stefano Ermon"], "title": "Extreme Q-Learning: MaxEnt RL without Entropy", "url": "http://arxiv.org/pdf/2301.02328v2", "summary": "Modern Deep Reinforcement Learning (RL) algorithms require estimates of the maximal Q-value, which are difficult to compute in continuous domains with an infinite number of possible actions. In this work, we introduce a new update rule for online and offline RL which directly models the maximal value using Extreme Value Theory (EVT), drawing inspiration from economics. By doing so, we avoid computing Q-values using out-of-distribution actions which is often a substantial source of error. Our key insight is to introduce an objective that directly estimates the optimal soft-value functions (LogSumExp) in the maximum entropy RL setting without needing to sample from a policy. Using EVT, we derive our \\emph{Extreme Q-Learning} framework and consequently online and, for the first time, offline MaxEnt Q-learning algorithms, that do not explicitly require access to a policy or its entropy. Our method obtains consistently strong performance in the D4RL benchmark, outperforming prior works by \\emph{10+ points} on the challenging Franka Kitchen tasks while offering moderate improvements over SAC and TD3 on online DM Control tasks. Visualizations and code can be found on our website at https://div99.github.io/XQL/.", "published": "2023-01-05T23:14:38Z", "version": 2}, {"aid": "2301.02610", "authors": ["Marco Kemmerling"], "title": "Feedback-Gated Rectified Linear Units", "url": "http://arxiv.org/pdf/2301.02610v1", "summary": "Feedback connections play a prominent role in the human brain but have not received much attention in artificial neural network research. Here, a biologically inspired feedback mechanism which gates rectified linear units is proposed. On the MNIST dataset, autoencoders with feedback show faster convergence, better performance, and more robustness to noise compared to their counterparts without feedback. Some benefits, although less pronounced and less consistent, can be observed when networks with feedback are applied on the CIFAR-10 dataset.", "published": "2023-01-06T17:14:11Z", "version": 1}, {"aid": "2301.03019", "authors": ["Patrick Kr\u00fcger", "Hanno Gottschalk"], "title": "Equivariant and Steerable Neural Networks: A review with special emphasis on the symmetric group", "url": "http://arxiv.org/pdf/2301.03019v1", "summary": "Convolutional neural networks revolutionized computer vision and natrual language processing. Their efficiency, as compared to fully connected neural networks, has its origin in the architecture, where convolutions reflect the translation invariance in space and time in pattern or speech recognition tasks. Recently, Cohen and Welling have put this in the broader perspective of invariance under symmetry groups, which leads to the concept of group equivaiant neural networks and more generally steerable neural networks. In this article, we review the architecture of such networks including equivariant layers and filter banks, activation with capsules and group pooling. We apply this formalism to the symmetric group, for which we work out a number of details on representations and capsules that are not found in the literature.", "published": "2023-01-08T11:05:31Z", "version": 1}, {"aid": "2301.03362", "authors": ["Michael Elad", "Bahjat Kawar", "Gregory Vaksman"], "title": "Image Denoising: The Deep Learning Revolution and Beyond -- A Survey Paper --", "url": "http://arxiv.org/pdf/2301.03362v1", "summary": "Image denoising (removal of additive white Gaussian noise from an image) is one of the oldest and most studied problems in image processing. An extensive work over several decades has led to thousands of papers on this subject, and to many well-performing algorithms for this task. Indeed, 10 years ago, these achievements have led some researchers to suspect that \"Denoising is Dead\", in the sense that all that can be achieved in this domain has already been obtained. However, this turned out to be far from the truth, with the penetration of deep learning (DL) into image processing. The era of DL brought a revolution to image denoising, both by taking the lead in today's ability for noise removal in images, and by broadening the scope of denoising problems being treated. Our paper starts by describing this evolution, highlighting in particular the tension and synergy that exist between classical approaches and modern DL-based alternatives in design of image denoisers.   The recent transitions in the field of image denoising go far beyond the ability to design better denoisers. In the 2nd part of this paper we focus on recently discovered abilities and prospects of image denoisers. We expose the possibility of using denoisers to serve other problems, such as regularizing general inverse problems and serving as the prime engine in diffusion-based image synthesis. We also unveil the idea that denoising and other inverse problems might not have a unique solution as common algorithms would have us believe. Instead, we describe constructive ways to produce randomized and diverse high quality results for inverse problems, all fueled by the progress that DL brought to image denoising.   This survey paper aims to provide a broad view of the history of image denoising and closely related topics. Our aim is to give a better context to recent discoveries, and to the influence of DL in our domain.", "published": "2023-01-09T14:16:40Z", "version": 1}, {"aid": "2301.04333", "authors": ["Sheo Yon Jhin", "Minju Jo", "Seungji Kook", "Noseong Park", "Sungpil Woo", "Sunhwan Lim"], "title": "Learnable Path in Neural Controlled Differential Equations", "url": "http://arxiv.org/pdf/2301.04333v1", "summary": "Neural controlled differential equations (NCDEs), which are continuous analogues to recurrent neural networks (RNNs), are a specialized model in (irregular) time-series processing. In comparison with similar models, e.g., neural ordinary differential equations (NODEs), the key distinctive characteristics of NCDEs are i) the adoption of the continuous path created by an interpolation algorithm from each raw discrete time-series sample and ii) the adoption of the Riemann--Stieltjes integral. It is the continuous path which makes NCDEs be analogues to continuous RNNs. However, NCDEs use existing interpolation algorithms to create the path, which is unclear whether they can create an optimal path. To this end, we present a method to generate another latent path (rather than relying on existing interpolation algorithms), which is identical to learning an appropriate interpolation method. We design an encoder-decoder module based on NCDEs and NODEs, and a special training method for it. Our method shows the best performance in both time-series classification and forecasting.", "published": "2023-01-11T07:05:27Z", "version": 1}, {"aid": "2301.05832", "authors": ["Tadahiro Taniguchi", "Shingo Murata", "Masahiro Suzuki", "Dimitri Ognibene", "Pablo Lanillos", "Emre Ugur", "Lorenzo Jamone", "Tomoaki Nakamura", "Alejandra Ciria", "Bruno Lara", "Giovanni Pezzulo"], "title": "World Models and Predictive Coding for Cognitive and Developmental Robotics: Frontiers and Challenges", "url": "http://arxiv.org/pdf/2301.05832v1", "summary": "Creating autonomous robots that can actively explore the environment, acquire knowledge and learn skills continuously is the ultimate achievement envisioned in cognitive and developmental robotics. Their learning processes should be based on interactions with their physical and social world in the manner of human learning and cognitive development. Based on this context, in this paper, we focus on the two concepts of world models and predictive coding. Recently, world models have attracted renewed attention as a topic of considerable interest in artificial intelligence. Cognitive systems learn world models to better predict future sensory observations and optimize their policies, i.e., controllers. Alternatively, in neuroscience, predictive coding proposes that the brain continuously predicts its inputs and adapts to model its own dynamics and control behavior in its environment. Both ideas may be considered as underpinning the cognitive development of robots and humans capable of continual or lifelong learning. Although many studies have been conducted on predictive coding in cognitive robotics and neurorobotics, the relationship between world model-based approaches in AI and predictive coding in robotics has rarely been discussed. Therefore, in this paper, we clarify the definitions, relationships, and status of current research on these topics, as well as missing pieces of world models and predictive coding in conjunction with crucially related concepts such as the free-energy principle and active inference in the context of cognitive and developmental robotics. Furthermore, we outline the frontiers and challenges involved in world models and predictive coding toward the further integration of AI and robotics, as well as the creation of robots with real cognitive and developmental capabilities in the future.", "published": "2023-01-14T06:38:14Z", "version": 1}, {"aid": "2301.05993", "authors": ["Iv\u00e1n Vall\u00e9s-P\u00e9rez", "Emilio Soria-Olivas", "Marcelino Mart\u00ednez-Sober", "Antonio J. Serrano-L\u00f3pez", "Joan Vila-Franc\u00e9s", "Juan G\u00f3mez-Sanch\u00eds"], "title": "Empirical study of the modulus as activation function in computer vision applications", "url": "http://arxiv.org/pdf/2301.05993v1", "summary": "In this work we propose a new non-monotonic activation function: the modulus. The majority of the reported research on nonlinearities is focused on monotonic functions. We empirically demonstrate how by using the modulus activation function on computer vision tasks the models generalize better than with other nonlinearities - up to a 15% accuracy increase in CIFAR100 and 4% in CIFAR10, relative to the best of the benchmark activations tested. With the proposed activation function the vanishing gradient and dying neurons problems disappear, because the derivative of the activation function is always 1 or -1. The simplicity of the proposed function and its derivative make this solution specially suitable for TinyML and hardware applications.", "published": "2023-01-15T00:32:03Z", "version": 1}, {"aid": "2301.05994", "authors": ["Gangli Liu"], "title": "Min-Max-Jump distance and its applications", "url": "http://arxiv.org/pdf/2301.05994v6", "summary": "We explore three applications of Min-Max-Jump distance (MMJ distance). MMJ-based K-means revises K-means with MMJ distance. MMJ-based Silhouette coefficient revises Silhouette coefficient with MMJ distance. We also tested the Clustering with Neural Network and Index (CNNI) model with MMJ-based Silhouette coefficient. In the last application, we tested using Min-Max-Jump distance for predicting labels of new points, after a clustering analysis of data. Result shows Min-Max-Jump distance achieves good performances in all the three proposed applications. In addition, we devise several algorithms for calculating or estimating the distance.", "published": "2023-01-15T00:55:40Z", "version": 6}, {"aid": "2301.06030", "authors": ["Zhenglong Zhou", "Geshi Yeung", "Anna C. Schapiro"], "title": "Self-recovery of memory via generative replay", "url": "http://arxiv.org/pdf/2301.06030v1", "summary": "A remarkable capacity of the brain is its ability to autonomously reorganize memories during offline periods. Memory replay, a mechanism hypothesized to underlie biological offline learning, has inspired offline methods for reducing forgetting in artificial neural networks in continual learning settings. A memory-efficient and neurally-plausible method is generative replay, which achieves state of the art performance on continual learning benchmarks. However, unlike the brain, standard generative replay does not self-reorganize memories when trained offline on its own replay samples. We propose a novel architecture that augments generative replay with an adaptive, brain-like capacity to autonomously recover memories. We demonstrate this capacity of the architecture across several continual learning tasks and environments.", "published": "2023-01-15T07:28:14Z", "version": 1}, {"aid": "2301.06158", "authors": ["T. M. Kamsma", "W. Q. Boon", "T. ter Rele", "C. Spitoni", "R. van Roij"], "title": "Iontronic Neuromorphic Signaling with Conical Microfluidic Memristors", "url": "http://arxiv.org/pdf/2301.06158v2", "summary": "Experiments have shown that the conductance of conical channels, filled with an aqueous electrolyte, can strongly depend on the history of the applied voltage. These channels hence have a memory and are promising elements in brain-inspired (iontronic) circuits. We show here that the memory of such channels stems from transient concentration polarization over the ionic diffusion time. We derive an analytic approximation for these dynamics which shows good agreement with full finite-element calculations. Using our analytic approximation, we propose an experimentally realisable Hodgkin-Huxley iontronic circuit where micrometer cones take on the role of sodium and potassium channels. Our proposed circuit exhibits key features of neuronal communication such as all-or-none action potentials upon a pulse stimulus and a spike train upon a sustained stimulus.", "published": "2023-01-15T18:46:16Z", "version": 2}, {"aid": "2301.06907", "authors": ["Gabriel Turinici"], "title": "Deep Conditional Measure Quantization", "url": "http://arxiv.org/pdf/2301.06907v2", "summary": "Quantization of a probability measure means representing it with a finite set of Dirac masses that approximates the input distribution well enough (in some metric space of probability measures). Various methods exists to do so, but the situation of quantizing a conditional law has been less explored. We propose a method, called DCMQ, involving a Huber-energy kernel-based approach coupled with a deep neural network architecture. The method is tested on several examples and obtains promising results.", "published": "2023-01-17T14:18:17Z", "version": 2}, {"aid": "2301.07016", "authors": ["V. A. Aksyuk"], "title": "Consciousness is entailed by compositional learning of new causal structures in deep predictive processing systems", "url": "http://arxiv.org/pdf/2301.07016v3", "summary": "Machine learning algorithms have achieved superhuman performance in specific complex domains. However, learning online from few examples and compositional learning for efficient generalization across domains remain elusive. In humans, such learning includes specific declarative memory formation and is closely associated with consciousness. Predictive processing has been advanced as a principled Bayesian framework for understanding the cortex as implementing deep generative models for both sensory perception and action control. However, predictive processing offers little direct insight into fast compositional learning or of the separation between conscious and unconscious contents. Here, propose that access consciousness arises as a consequence of a particular learning mechanism operating within a predictive processing system. We extend predictive processing by adding online, single-example new structure learning via hierarchical binding of unpredicted inferences. This system learns new causes by quickly connecting together novel combinations of perceptions, which manifests as working memories that can become short- and long-term declarative memories retrievable by associative recall. The contents of such bound representations are unified yet differentiated, can be maintained by selective attention and are globally available. The proposed learning process explains contrast and masking manipulations, postdictive perceptual integration, and other paradigm cases of consciousness research. 'Phenomenal conscious experience' is how the learning system transparently models its own functioning, giving rise to perceptual illusions underlying the meta-problem of consciousness. Our proposal naturally unifies the feature binding, recurrent processing, predictive processing, and global workspace theories of consciousness.", "published": "2023-01-17T17:06:48Z", "version": 3}, {"aid": "2301.07455", "authors": ["O. R. Kirubeswaran", "Katherine R. Storrs"], "title": "Inconsistent illusory motion in predictive coding deep neural networks", "url": "http://arxiv.org/pdf/2301.07455v2", "summary": "Why do we perceive illusory motion in some static images? Several accounts have been proposed based on eye movements, response latencies to different image elements, or interactions between image patterns and motion energy detectors. Recently, PredNet, a recurrent deep neural network (DNN) based on predictive coding principles, was reported to reproduce the \"Rotating Snakes\" illusion, suggesting a role for predictive coding in illusory motion. We replicate this finding and then use a series of \"in silico psychophysics\" experiments to examine whether PredNet behaves consistently with human observers for simplified variants of the illusory stimuli. We also measure response latencies to individual elements of the Rotating Snakes pattern by probing internal units in the network. A pretrained PredNet model predicted illusory motion for all subcomponents of the Rotating Snakes stimulus, consistent with human observers. However, we found no simple response delays in internal units, as found in physiological data. The PredNet model's detection of motion in gradients was based on contrast, not luminance, as it is in human perception. Finally, we tested the robustness of the illusion on 10 identical PredNets trained on the same video data; we found a large variation in the ability of the network to reproduce the illusion and predict motion for simplified variants of the illusion. Also, unlike human observers, none of the networks predicted illusory motion for greyscale variants of the pattern. Even when a DNN successfully reproduces some idiosyncrasy of human vision, a more detailed investigation can reveal inconsistencies between humans and the network and between different instances of the same network. The inconsistency of the Rotating Snakes illusion in PredNets trained from different initializations suggests that predictive coding does not reliably lead to human-like illusory motion.", "published": "2023-01-18T11:56:24Z", "version": 2}, {"aid": "2301.07581", "authors": ["Jan Flusser", "Matej Lebl", "Matteo Pedone", "Filip Sroubek", "Jitka Kostkova"], "title": "Blur Invariants for Image Recognition", "url": "http://arxiv.org/pdf/2301.07581v1", "summary": "Blur is an image degradation that is difficult to remove. Invariants with respect to blur offer an alternative way of a~description and recognition of blurred images without any deblurring. In this paper, we present an original unified theory of blur invariants. Unlike all previous attempts, the new theory does not require any prior knowledge of the blur type. The invariants are constructed in the Fourier domain by means of orthogonal projection operators and moment expansion is used for efficient and stable computation. It is shown that all blur invariants published earlier are just particular cases of this approach. Experimental comparison to concurrent approaches shows the advantages of the proposed theory.", "published": "2023-01-18T14:58:32Z", "version": 1}, {"aid": "2301.07733", "authors": ["Aaron Defazio", "Konstantin Mishchenko"], "title": "Learning-Rate-Free Learning by D-Adaptation", "url": "http://arxiv.org/pdf/2301.07733v5", "summary": "D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.   An open-source implementation is available.", "published": "2023-01-18T19:00:50Z", "version": 5}, {"aid": "2301.08113", "authors": ["Christoph Dalitz"], "title": "Soft Thresholding for Visual Image Enhancement", "url": "http://arxiv.org/pdf/2301.08113v1", "summary": "Thresholding converts a greyscale image into a binary image, and is thus often a necessary segmentation step in image processing. For a human viewer however, thresholding usually has a negative impact on the legibility of document images. This report describes a simple method for \"smearing out\" the threshold and transforming the greyscale image into a different greyscale image. The method is similar to fuzzy thresholding, but is discussed here in the simpler context of greyscale transformations and, unlike fuzzy thresholding, it is independent from the method for finding the threshold. A simple formula is presented for automatically determining the width of the threshold spread. The method can be used, e.g., for enhancing images for the presentation in online facsimile repositories.", "published": "2023-01-19T15:05:13Z", "version": 1}, {"aid": "2301.08187", "authors": ["Fabian Falck", "Christopher Williams", "Dominic Danks", "George Deligiannidis", "Christopher Yau", "Chris Holmes", "Arnaud Doucet", "Matthew Willetts"], "title": "A Multi-Resolution Framework for U-Nets with Applications to Hierarchical VAEs", "url": "http://arxiv.org/pdf/2301.08187v1", "summary": "U-Net architectures are ubiquitous in state-of-the-art deep learning, however their regularisation properties and relationship to wavelets are understudied. In this paper, we formulate a multi-resolution framework which identifies U-Nets as finite-dimensional truncations of models on an infinite-dimensional function space. We provide theoretical results which prove that average pooling corresponds to projection within the space of square-integrable functions and show that U-Nets with average pooling implicitly learn a Haar wavelet basis representation of the data. We then leverage our framework to identify state-of-the-art hierarchical VAEs (HVAEs), which have a U-Net architecture, as a type of two-step forward Euler discretisation of multi-resolution diffusion processes which flow from a point mass, introducing sampling instabilities. We also demonstrate that HVAEs learn a representation of time which allows for improved parameter efficiency through weight-sharing. We use this observation to achieve state-of-the-art HVAE performance with half the number of parameters of existing models, exploiting the properties of our continuous-time formulation.", "published": "2023-01-19T17:33:48Z", "version": 1}, {"aid": "2301.08210", "authors": ["Petar Veli\u010dkovi\u0107"], "title": "Everything is Connected: Graph Neural Networks", "url": "http://arxiv.org/pdf/2301.08210v1", "summary": "In many ways, graphs are the main modality of data we receive from nature. This is due to the fact that most of the patterns we see, both in natural and artificial systems, are elegantly representable using the language of graph structures. Prominent examples include molecules (represented as graphs of atoms and bonds), social networks and transportation networks. This potential has already been seen by key scientific and industrial groups, with already-impacted application areas including traffic forecasting, drug discovery, social network analysis and recommender systems. Further, some of the most successful domains of application for machine learning in previous years -- images, text and speech processing -- can be seen as special cases of graph representation learning, and consequently there has been significant exchange of information between these areas. The main aim of this short survey is to enable the reader to assimilate the key concepts in the area, and position graph representation learning in a proper context with related fields.", "published": "2023-01-19T18:09:43Z", "version": 1}, {"aid": "2301.08284", "authors": ["Lukas Gonon", "Robin Graeber", "Arnulf Jentzen"], "title": "The necessity of depth for artificial neural networks to approximate certain classes of smooth and bounded functions without the curse of dimensionality", "url": "http://arxiv.org/pdf/2301.08284v1", "summary": "In this article we study high-dimensional approximation capacities of shallow and deep artificial neural networks (ANNs) with the rectified linear unit (ReLU) activation. In particular, it is a key contribution of this work to reveal that for all $a,b\\in\\mathbb{R}$ with $b-a\\geq 7$ we have that the functions $[a,b]^d\\ni x=(x_1,\\dots,x_d)\\mapsto\\prod_{i=1}^d x_i\\in\\mathbb{R}$ for $d\\in\\mathbb{N}$ as well as the functions $[a,b]^d\\ni x =(x_1,\\dots, x_d)\\mapsto\\sin(\\prod_{i=1}^d x_i) \\in \\mathbb{R} $ for $ d \\in \\mathbb{N} $ can neither be approximated without the curse of dimensionality by means of shallow ANNs nor insufficiently deep ANNs with ReLU activation but can be approximated without the curse of dimensionality by sufficiently deep ANNs with ReLU activation. We show that the product functions and the sine of the product functions are polynomially tractable approximation problems among the approximating class of deep ReLU ANNs with the number of hidden layers being allowed to grow in the dimension $ d \\in \\mathbb{N} $. We establish the above outlined statements not only for the product functions and the sine of the product functions but also for other classes of target functions, in particular, for classes of uniformly globally bounded $ C^{ \\infty } $-functions with compact support on any $[a,b]^d$ with $a\\in\\mathbb{R}$, $b\\in(a,\\infty)$. Roughly speaking, in this work we lay open that simple approximation problems such as approximating the sine or cosine of products cannot be solved in standard implementation frameworks by shallow or insufficiently deep ANNs with ReLU activation in polynomial time, but can be approximated by sufficiently deep ReLU ANNs with the number of parameters growing at most polynomially.", "published": "2023-01-19T19:52:41Z", "version": 1}, {"aid": "2301.08727", "authors": ["Colin White", "Mahmoud Safari", "Rhea Sukthanker", "Binxin Ru", "Thomas Elsken", "Arber Zela", "Debadeepta Dey", "Frank Hutter"], "title": "Neural Architecture Search: Insights from 1000 Papers", "url": "http://arxiv.org/pdf/2301.08727v2", "summary": "In the past decade, advances in deep learning have resulted in breakthroughs in a variety of areas, including computer vision, natural language understanding, speech recognition, and reinforcement learning. Specialized, high-performing neural architectures are crucial to the success of deep learning in these areas. Neural architecture search (NAS), the process of automating the design of neural architectures for a given task, is an inevitable next step in automating machine learning and has already outpaced the best human-designed architectures on many tasks. In the past few years, research in NAS has been progressing rapidly, with over 1000 papers released since 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized and comprehensive guide to neural architecture search. We give a taxonomy of search spaces, algorithms, and speedup techniques, and we discuss resources such as benchmarks, best practices, other surveys, and open-source libraries.", "published": "2023-01-20T18:47:24Z", "version": 2}, {"aid": "2301.08846", "authors": ["Xu Tan", "Tao Qin", "Jiang Bian", "Tie-Yan Liu", "Yoshua Bengio"], "title": "Regeneration Learning: A Learning Paradigm for Data Generation", "url": "http://arxiv.org/pdf/2301.08846v1", "summary": "Machine learning methods for conditional data generation usually build a mapping from source conditional data X to target data Y. The target Y (e.g., text, speech, music, image, video) is usually high-dimensional and complex, and contains information that does not exist in source data, which hinders effective and efficient learning on the source-target mapping. In this paper, we present a learning paradigm called regeneration learning for data generation, which first generates Y' (an abstraction/representation of Y) from X and then generates Y from Y'. During training, Y' is obtained from Y through either handcrafted rules or self-supervised learning and is used to learn X-->Y' and Y'-->Y. Regeneration learning extends the concept of representation learning to data generation tasks, and can be regarded as a counterpart of traditional representation learning, since 1) regeneration learning handles the abstraction (Y') of the target data Y for data generation while traditional representation learning handles the abstraction (X') of source data X for data understanding; 2) both the processes of Y'-->Y in regeneration learning and X-->X' in representation learning can be learned in a self-supervised way (e.g., pre-training); 3) both the mappings from X to Y' in regeneration learning and from X' to Y in representation learning are simpler than the direct mapping from X to Y. We show that regeneration learning can be a widely-used paradigm for data generation (e.g., text generation, speech recognition, speech synthesis, music composition, image generation, and video generation) and can provide valuable insights into developing data generation methods.", "published": "2023-01-21T01:33:34Z", "version": 1}, {"aid": "2301.09245", "authors": ["Feng-Lei Fan", "Yingxin Li", "Hanchuan Peng", "Tieyong Zeng", "Fei Wang"], "title": "Towards NeuroAI: Introducing Neuronal Diversity into Artificial Neural Networks", "url": "http://arxiv.org/pdf/2301.09245v2", "summary": "Throughout history, the development of artificial intelligence, particularly artificial neural networks, has been open to and constantly inspired by the increasingly deepened understanding of the brain, such as the inspiration of neocognitron, which is the pioneering work of convolutional neural networks. Per the motives of the emerging field: NeuroAI, a great amount of neuroscience knowledge can help catalyze the next generation of AI by endowing a network with more powerful capabilities. As we know, the human brain has numerous morphologically and functionally different neurons, while artificial neural networks are almost exclusively built on a single neuron type. In the human brain, neuronal diversity is an enabling factor for all kinds of biological intelligent behaviors. Since an artificial network is a miniature of the human brain, introducing neuronal diversity should be valuable in terms of addressing those essential problems of artificial networks such as efficiency, interpretability, and memory. In this Primer, we first discuss the preliminaries of biological neuronal diversity and the characteristics of information transmission and processing in a biological neuron. Then, we review studies of designing new neurons for artificial networks. Next, we discuss what gains can neuronal diversity bring into artificial networks and exemplary applications in several important fields. Lastly, we discuss the challenges and future directions of neuronal diversity to explore the potential of NeuroAI.", "published": "2023-01-23T02:23:45Z", "version": 2}, {"aid": "2301.09299", "authors": ["Yinheng Li", "Han Ding", "Shaofei Wang"], "title": "Self-Supervised Image Representation Learning: Transcending Masking with Paired Image Overlay", "url": "http://arxiv.org/pdf/2301.09299v1", "summary": "Self-supervised learning has become a popular approach in recent years for its ability to learn meaningful representations without the need for data annotation. This paper proposes a novel image augmentation technique, overlaying images, which has not been widely applied in self-supervised learning. This method is designed to provide better guidance for the model to understand underlying information, resulting in more useful representations. The proposed method is evaluated using contrastive learning, a widely used self-supervised learning method that has shown solid performance in downstream tasks. The results demonstrate the effectiveness of the proposed augmentation technique in improving the performance of self-supervised models.", "published": "2023-01-23T07:00:04Z", "version": 1}, {"aid": "2301.09474", "authors": ["Qitian Wu", "Chenxiao Yang", "Wentao Zhao", "Yixuan He", "David Wipf", "Junchi Yan"], "title": "DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion", "url": "http://arxiv.org/pdf/2301.09474v4", "summary": "Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy constrained diffusion model which encodes a batch of instances from a dataset into evolutionary states that progressively incorporate other instances' information by their interactions. The diffusion process is constrained by descent criteria w.r.t.~a principled energy function that characterizes the global consistency of instance representations over latent structures. We provide rigorous theory that implies closed-form optimal estimates for the pairwise diffusion strength among arbitrary instance pairs, which gives rise to a new class of neural encoders, dubbed as DIFFormer (diffusion-based Transformers), with two instantiations: a simple version with linear complexity for prohibitive instance numbers, and an advanced version for learning complex structures. Experiments highlight the wide applicability of our model as a general-purpose encoder backbone with superior performance in various tasks, such as node classification on large graphs, semi-supervised image/text classification, and spatial-temporal dynamics prediction.", "published": "2023-01-23T15:18:54Z", "version": 4}, {"aid": "2301.09820", "authors": ["Zihao Fu", "Anthony Man-Cho So", "Nigel Collier"], "title": "A Stability Analysis of Fine-Tuning a Pre-Trained Model", "url": "http://arxiv.org/pdf/2301.09820v2", "summary": "Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT, etc.) has proven to be one of the most promising paradigms in recent NLP research. However, numerous recent works indicate that fine-tuning suffers from the instability problem, i.e., tuning the same model under the same setting results in significantly different performance. Many recent works have proposed different methods to solve this problem, but there is no theoretical understanding of why and how these methods work. In this paper, we propose a novel theoretical stability analysis of fine-tuning that focuses on two commonly used settings, namely, full fine-tuning and head tuning. We define the stability under each setting and prove the corresponding stability bounds. The theoretical bounds explain why and how several existing methods can stabilize the fine-tuning procedure. In addition to being able to explain most of the observed empirical discoveries, our proposed theoretical analysis framework can also help in the design of effective and provable methods. Based on our theory, we propose three novel strategies to stabilize the fine-tuning procedure, namely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self Unsupervised Re-Training (SURT). We extensively evaluate our proposed approaches on 11 widely used real-world benchmark datasets, as well as hundreds of synthetic classification datasets. The experiment results show that our proposed methods significantly stabilize the fine-tuning procedure and also corroborate our theoretical analysis.", "published": "2023-01-24T05:11:17Z", "version": 2}, {"aid": "2301.09858", "authors": ["Edouard Yvinec", "Arnaud Dapogny", "Matthieu Cord", "Kevin Bailly"], "title": "PowerQuant: Automorphism Search for Non-Uniform Quantization", "url": "http://arxiv.org/pdf/2301.09858v1", "summary": "Deep neural networks (DNNs) are nowadays ubiquitous in many domains such as computer vision. However, due to their high latency, the deployment of DNNs hinges on the development of compression techniques such as quantization which consists in lowering the number of bits used to encode the weights and activations. Growing concerns for privacy and security have motivated the development of data-free techniques, at the expanse of accuracy. In this paper, we identity the uniformity of the quantization operator as a limitation of existing approaches, and propose a data-free non-uniform method. More specifically, we argue that to be readily usable without dedicated hardware and implementation, non-uniform quantization shall not change the nature of the mathematical operations performed by the DNN. This leads to search among the continuous automorphisms of $(\\mathbb{R}_+^*,\\times)$, which boils down to the power functions defined by their exponent. To find this parameter, we propose to optimize the reconstruction error of each layer: in particular, we show that this procedure is locally convex and admits a unique solution. At inference time, we show that our approach, dubbed PowerQuant, only require simple modifications in the quantized DNN activation functions. As such, with only negligible overhead, it significantly outperforms existing methods in a variety of configurations.", "published": "2023-01-24T08:30:14Z", "version": 1}, {"aid": "2301.09939", "authors": ["T. R. F. Phillips", "C. E. Heaney", "C. Boyang", "A. G. Buchan", "C. C. Pain"], "title": "Solving the Discretised Neutron Diffusion Equations using Neural Networks", "url": "http://arxiv.org/pdf/2301.09939v1", "summary": "This paper presents a new approach which uses the tools within Artificial Intelligence (AI) software libraries as an alternative way of solving partial differential equations (PDEs) that have been discretised using standard numerical methods. In particular, we describe how to represent numerical discretisations arising from the finite volume and finite element methods by pre-determining the weights of convolutional layers within a neural network. As the weights are defined by the discretisation scheme, no training of the network is required and the solutions obtained are identical (accounting for solver tolerances) to those obtained with standard codes often written in Fortran or C++. We also explain how to implement the Jacobi method and a multigrid solver using the functions available in AI libraries. For the latter, we use a U-Net architecture which is able to represent a sawtooth multigrid method. A benefit of using AI libraries in this way is that one can exploit their power and their built-in technologies. For example, their executions are already optimised for different computer architectures, whether it be CPUs, GPUs or new-generation AI processors. In this article, we apply the proposed approach to eigenvalue problems in reactor physics where neutron transport is described by diffusion theory. For a fuel assembly benchmark, we demonstrate that the solution obtained from our new approach is the same (accounting for solver tolerances) as that obtained from the same discretisation coded in a standard way using Fortran. We then proceed to solve a reactor core benchmark using the new approach.", "published": "2023-01-24T11:46:09Z", "version": 1}, {"aid": "2301.10002", "authors": ["Ilias Rentzeperis", "Luca Calatroni", "Laurent Perrinet", "Dario Prandi"], "title": "Beyond $\\ell_1$ sparse coding in V1", "url": "http://arxiv.org/pdf/2301.10002v2", "summary": "Growing evidence indicates that only a sparse subset from a pool of sensory neurons is active for the encoding of visual stimuli at any instant in time. Traditionally, to replicate such biological sparsity, generative models have been using the $\\ell_1$ norm as a penalty due to its convexity, which makes it amenable to fast and simple algorithmic solvers. In this work, we use biological vision as a test-bed and show that the soft thresholding operation associated to the use of the $\\ell_1$ norm is highly suboptimal compared to other functions suited to approximating $\\ell_q$ with $0 \\leq q < 1 $ (including recently proposed Continuous Exact relaxations), both in terms of performance and in the production of features that are akin to signatures of the primary visual cortex. We show that $\\ell_1$ sparsity produces a denser code or employs a pool with more neurons, i.e. has a higher degree of overcompleteness, in order to maintain the same reconstruction error as the other methods considered. For all the penalty functions tested, a subset of the neurons develop orientation selectivity similarly to V1 neurons. When their code is sparse enough, the methods also develop receptive fields with varying functionalities, another signature of V1. Compared to other methods, soft thresholding achieves this level of sparsity at the expense of much degraded reconstruction performance, that more likely than not is not acceptable in biological vision. Our results indicate that V1 uses a sparsity inducing regularization that is closer to the $\\ell_0$ pseudo-norm rather than to the $\\ell_1$ norm.", "published": "2023-01-24T13:53:07Z", "version": 2}, {"aid": "2301.10297", "authors": ["Sebastian Michelmann", "Manoj Kumar", "Kenneth A. Norman", "Mariya Toneva"], "title": "Large language models can segment narrative events similarly to humans", "url": "http://arxiv.org/pdf/2301.10297v1", "summary": "Humans perceive discrete events such as \"restaurant visits\" and \"train rides\" in their continuous experience. One important prerequisite for studying human event perception is the ability of researchers to quantify when one event ends and another begins. Typically, this information is derived by aggregating behavioral annotations from several observers. Here we present an alternative computational approach where event boundaries are derived using a large language model, GPT-3, instead of using human annotations. We demonstrate that GPT-3 can segment continuous narrative text into events. GPT-3-annotated events are significantly correlated with human event annotations. Furthermore, these GPT-derived annotations achieve a good approximation of the \"consensus\" solution (obtained by averaging across human annotations); the boundaries identified by GPT-3 are closer to the consensus, on average, than boundaries identified by individual human annotators. This finding suggests that GPT-3 provides a feasible solution for automated event annotations, and it demonstrates a further parallel between human cognition and prediction in large language models. In the future, GPT-3 may thereby help to elucidate the principles underlying human event perception.", "published": "2023-01-24T20:34:37Z", "version": 1}, {"aid": "2301.11108", "authors": ["David McAllester"], "title": "On the Mathematics of Diffusion Models", "url": "http://arxiv.org/pdf/2301.11108v3", "summary": "This paper gives direct derivations of the differential equations and likelihood formulas of diffusion models assuming only knowledge of Gaussian distributions. A VAE analysis derives both forward and backward stochastic differential equations (SDEs) as well as non-variational integral expressions for likelihood formulas. A score-matching analysis derives the reverse diffusion ordinary differential equation (ODE) and a family of reverse-diffusion SDEs parameterized by noise level. The paper presents the mathematics directly with attributions saved for a final section.", "published": "2023-01-25T16:39:00Z", "version": 3}, {"aid": "2301.11706", "authors": ["Mang Ning", "Enver Sangineto", "Angelo Porrello", "Simone Calderara", "Rita Cucchiara"], "title": "Input Perturbation Reduces Exposure Bias in Diffusion Models", "url": "http://arxiv.org/pdf/2301.11706v3", "summary": "Denoising Diffusion Probabilistic Models have shown an impressive generation quality, although their long sampling chain leads to high computational costs. In this paper, we observe that a long sampling chain also leads to an error accumulation phenomenon, which is similar to the exposure bias problem in autoregressive text generation. Specifically, we note that there is a discrepancy between training and testing, since the former is conditioned on the ground truth samples, while the latter is conditioned on the previously generated results. To alleviate this problem, we propose a very simple but effective training regularization, consisting in perturbing the ground truth samples to simulate the inference time prediction errors. We empirically show that, without affecting the recall and precision, the proposed input perturbation leads to a significant improvement in the sample quality while reducing both the training and the inference times. For instance, on CelebA 64$\\times$64, we achieve a new state-of-the-art FID score of 1.27, while saving 37.5% of the training time. The code is publicly available at https://github.com/forever208/DDPM-IP", "published": "2023-01-27T13:34:54Z", "version": 3}, {"aid": "2301.12935", "authors": ["Shengmeng Li", "Luping Liu", "Zenghao Chai", "Runnan Li", "Xu Tan"], "title": "ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2301.12935v3", "summary": "Though denoising diffusion probabilistic models (DDPMs) have achieved remarkable generation results, the low sampling efficiency of DDPMs still limits further applications. Since DDPMs can be formulated as diffusion ordinary differential equations (ODEs), various fast sampling methods can be derived from solving diffusion ODEs. However, we notice that previous sampling methods with fixed analytical form are not robust with the error in the noise estimated from pretrained diffusion models. In this work, we construct an error-robust Adams solver (ERA-Solver), which utilizes the implicit Adams numerical method that consists of a predictor and a corrector. Different from the traditional predictor based on explicit Adams methods, we leverage a Lagrange interpolation function as the predictor, which is further enhanced with an error-robust strategy to adaptively select the Lagrange bases with lower error in the estimated noise. Experiments on Cifar10, LSUN-Church, and LSUN-Bedroom datasets demonstrate that our proposed ERA-Solver achieves 5.14, 9.42, and 9.69 Fenchel Inception Distance (FID) for image generation, with only 10 network evaluations.", "published": "2023-01-30T14:32:47Z", "version": 3}, {"aid": "2302.00487", "authors": ["Liyuan Wang", "Xingxing Zhang", "Hang Su", "Jun Zhu"], "title": "A Comprehensive Survey of Continual Learning: Theory, Method and Application", "url": "http://arxiv.org/pdf/2302.00487v3", "summary": "To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance degradation of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative methods address continual learning, and how they are adapted to particular challenges in realistic applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.", "published": "2023-01-31T11:34:56Z", "version": 3}, {"aid": "2302.00626", "authors": ["Chun-Wun Cheng", "Christina Runkel", "Lihao Liu", "Raymond H Chan", "Carola-Bibiane Sch\u00f6nlieb", "Angelica I Aviles-Rivero"], "title": "Continuous U-Net: Faster, Greater and Noiseless", "url": "http://arxiv.org/pdf/2302.00626v1", "summary": "Image segmentation is a fundamental task in image analysis and clinical practice. The current state-of-the-art techniques are based on U-shape type encoder-decoder networks with skip connections, called U-Net. Despite the powerful performance reported by existing U-Net type networks, they suffer from several major limitations. Issues include the hard coding of the receptive field size, compromising the performance and computational cost, as well as the fact that they do not account for inherent noise in the data. They have problems associated with discrete layers, and do not offer any theoretical underpinning. In this work we introduce continuous U-Net, a novel family of networks for image segmentation. Firstly, continuous U-Net is a continuous deep neural network that introduces new dynamic blocks modelled by second order ordinary differential equations. Secondly, we provide theoretical guarantees for our network demonstrating faster convergence, higher robustness and less sensitivity to noise. Thirdly, we derive qualitative measures to tailor-made segmentation tasks. We demonstrate, through extensive numerical and visual results, that our model outperforms existing U-Net blocks for several medical image segmentation benchmarking datasets.", "published": "2023-02-01T17:46:00Z", "version": 1}, {"aid": "2302.00670", "authors": ["Yilun Xu", "Shangyuan Tong", "Tommi Jaakkola"], "title": "Stable Target Field for Reduced Variance Score Estimation in Diffusion Models", "url": "http://arxiv.org/pdf/2302.00670v2", "summary": "Diffusion models generate samples by reversing a fixed forward diffusion process. Despite already providing impressive empirical results, these diffusion models algorithms can be further improved by reducing the variance of the training targets in their denoising score-matching objective. We argue that the source of such variance lies in the handling of intermediate noise-variance scales, where multiple modes in the data affect the direction of reverse paths. We propose to remedy the problem by incorporating a reference batch which we use to calculate weighted conditional scores as more stable training targets. We show that the procedure indeed helps in the challenging intermediate regime by reducing (the trace of) the covariance of training targets. The new stable targets can be seen as trading bias for reduced variance, where the bias vanishes with increasing reference batch size. Empirically, we show that the new objective improves the image quality, stability, and training speed of various popular diffusion models across datasets with both general ODE and SDE solvers. When used in combination with EDM, our method yields a current SOTA FID of 1.90 with 35 network evaluations on the unconditional CIFAR-10 generation task. The code is available at https://github.com/Newbeeer/stf", "published": "2023-02-01T18:57:01Z", "version": 2}, {"aid": "2302.00727", "authors": ["Sing-Yuan Yeh", "Fu-Chieh Chang", "Chang-Wei Yueh", "Pei-Yuan Wu", "Alberto Bernacchia", "Sattar Vakili"], "title": "Sample Complexity of Kernel-Based Q-Learning", "url": "http://arxiv.org/pdf/2302.00727v1", "summary": "Modern reinforcement learning (RL) often faces an enormous state-action space. Existing analytical results are typically for settings with a small number of state-actions, or simple models such as linearly modeled Q-functions. To derive statistically efficient RL policies handling large state-action spaces, with more general Q-functions, some recent works have considered nonlinear function approximation using kernel ridge regression. In this work, we derive sample complexities for kernel based Q-learning when a generative model exists. We propose a nonparametric Q-learning algorithm which finds an $\\epsilon$-optimal policy in an arbitrarily large scale discounted MDP. The sample complexity of the proposed algorithm is order optimal with respect to $\\epsilon$ and the complexity of the kernel (in terms of its information gain). To the best of our knowledge, this is the first result showing a finite sample complexity under such a general model.", "published": "2023-02-01T19:46:25Z", "version": 1}, {"aid": "2302.01404", "authors": ["Suhas Kotha", "Christopher Brix", "Zico Kolter", "Krishnamurthy Dvijotham", "Huan Zhang"], "title": "Provably Bounding Neural Network Preimages", "url": "http://arxiv.org/pdf/2302.01404v4", "summary": "Most work on the formal verification of neural networks has focused on bounding the set of outputs that correspond to a given set of inputs (for example, bounded perturbations of a nominal input). However, many use cases of neural network verification require solving the inverse problem, or over-approximating the set of inputs that lead to certain outputs. We present the INVPROP algorithm for verifying properties over the preimage of a linearly constrained output set, which can be combined with branch-and-bound to increase precision. Contrary to other approaches, our efficient algorithm is GPU-accelerated and does not require a linear programming solver. We demonstrate our algorithm for identifying safe control regions for a dynamical system via backward reachability analysis, verifying adversarial robustness, and detecting out-of-distribution inputs to a neural network. Our results show that in certain settings, we find over-approximations over 2500x tighter than prior work while being 2.5x faster. By strengthening robustness verification with output constraints, we consistently verify more properties than the previous state-of-the-art on multiple benchmarks, including a large model with 167k neurons in VNN-COMP 2023. Our algorithm has been incorporated into the $\\alpha,\\!\\beta$-CROWN verifier, available at https://abcrown.org.", "published": "2023-02-02T20:34:45Z", "version": 4}, {"aid": "2302.02234", "authors": ["Lingyan Ruan", "Mojtaba Bemana", "Hans-peter Seidel", "Karol Myszkowski", "Bin Chen"], "title": "Revisiting Image Deblurring with an Efficient ConvNet", "url": "http://arxiv.org/pdf/2302.02234v1", "summary": "Image deblurring aims to recover the latent sharp image from its blurry counterpart and has a wide range of applications in computer vision. The Convolution Neural Networks (CNNs) have performed well in this domain for many years, and until recently an alternative network architecture, namely Transformer, has demonstrated even stronger performance. One can attribute its superiority to the multi-head self-attention (MHSA) mechanism, which offers a larger receptive field and better input content adaptability than CNNs. However, as MHSA demands high computational costs that grow quadratically with respect to the input resolution, it becomes impractical for high-resolution image deblurring tasks. In this work, we propose a unified lightweight CNN network that features a large effective receptive field (ERF) and demonstrates comparable or even better performance than Transformers while bearing less computational costs. Our key design is an efficient CNN block dubbed LaKD, equipped with a large kernel depth-wise convolution and spatial-channel mixing structure, attaining comparable or larger ERF than Transformers but with a smaller parameter scale. Specifically, we achieve +0.17dB / +0.43dB PSNR over the state-of-the-art Restormer on defocus / motion deblurring benchmark datasets with 32% fewer parameters and 39% fewer MACs. Extensive experiments demonstrate the superior performance of our network and the effectiveness of each module. Furthermore, we propose a compact and intuitive ERFMeter metric that quantitatively characterizes ERF, and shows a high correlation to the network performance. We hope this work can inspire the research community to further explore the pros and cons of CNN and Transformer architectures beyond image deblurring tasks.", "published": "2023-02-04T20:42:46Z", "version": 1}, {"aid": "2302.10184", "authors": ["Zhongzhan Huang", "Mingfu Liang", "Shanshan Zhong", "Liang Lin"], "title": "AttNS: Attention-Inspired Numerical Solving For Limited Data Scenarios", "url": "http://arxiv.org/pdf/2302.10184v2", "summary": "We propose the attention-inspired numerical solver (AttNS), a concise method that helps the generalization and robustness issues faced by the AI-Hybrid numerical solver in solving differential equations due to limited data. AttNS is inspired by the effectiveness of attention modules in Residual Neural Networks (ResNet) in enhancing model generalization and robustness for conventional deep learning tasks. Drawing from the dynamical system perspective of ResNet, we seamlessly incorporate attention mechanisms into the design of numerical methods tailored for the characteristics of solving differential equations. Our results on benchmarks, ranging from high-dimensional problems to chaotic systems, showcases AttNS consistently enhancing various numerical solvers without any intricate model crafting. Finally, we analyze AttNS experimentally and theoretically, demonstrating its ability to achieve strong generalization and robustness while ensuring the convergence of the solver. This includes requiring less data compared to other advanced methods to achieve comparable generalization errors and better prevention of numerical explosion issues when solving differential equations.", "published": "2023-02-05T01:39:21Z", "version": 2}, {"aid": "2302.02334", "authors": ["Chenyu Zheng", "Guoqiang Wu", "Fan Bao", "Yue Cao", "Chongxuan Li", "Jun Zhu"], "title": "Revisiting Discriminative vs. Generative Classifiers: Theory and Implications", "url": "http://arxiv.org/pdf/2302.02334v2", "summary": "A large-scale deep model pre-trained on massive labeled or unlabeled data transfers well to downstream tasks. Linear evaluation freezes parameters in the pre-trained model and trains a linear classifier separately, which is efficient and attractive for transfer. However, little work has investigated the classifier in linear evaluation except for the default logistic regression. Inspired by the statistical efficiency of naive Bayes, the paper revisits the classical topic on discriminative vs. generative classifiers. Theoretically, the paper considers the surrogate loss instead of the zero-one loss in analyses and generalizes the classical results from binary cases to multiclass ones. We show that, under mild assumptions, multiclass naive Bayes requires $O(\\log n)$ samples to approach its asymptotic error while the corresponding multiclass logistic regression requires $O(n)$ samples, where $n$ is the feature dimension. To establish it, we present a multiclass $\\mathcal{H}$-consistency bound framework and an explicit bound for logistic loss, which are of independent interests. Simulation results on a mixture of Gaussian validate our theoretical findings. Experiments on various pre-trained deep vision models show that naive Bayes consistently converges faster as the number of data increases. Besides, naive Bayes shows promise in few-shot cases and we observe the \"two regimes\" phenomenon in pre-trained supervised models. Our code is available at https://github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers.", "published": "2023-02-05T08:30:42Z", "version": 2}, {"aid": "2302.03225", "authors": ["Yu-Neng Chuang", "Guanchu Wang", "Fan Yang", "Zirui Liu", "Xuanting Cai", "Mengnan Du", "Xia Hu"], "title": "Efficient XAI Techniques: A Taxonomic Survey", "url": "http://arxiv.org/pdf/2302.03225v2", "summary": "Recently, there has been a growing demand for the deployment of Explainable Artificial Intelligence (XAI) algorithms in real-world applications. However, traditional XAI methods typically suffer from a high computational complexity problem, which discourages the deployment of real-time systems to meet the time-demanding requirements of real-world scenarios. Although many approaches have been proposed to improve the efficiency of XAI methods, a comprehensive understanding of the achievements and challenges is still needed. To this end, in this paper we provide a review of efficient XAI. Specifically, we categorize existing techniques of XAI acceleration into efficient non-amortized and efficient amortized methods. The efficient non-amortized methods focus on data-centric or model-centric acceleration upon each individual instance. In contrast, amortized methods focus on learning a unified distribution of model explanations, following the predictive, generative, or reinforcement frameworks, to rapidly derive multiple model explanations. We also analyze the limitations of an efficient XAI pipeline from the perspectives of the training phase, the deployment phase, and the use scenarios. Finally, we summarize the challenges of deploying XAI acceleration methods to real-world scenarios, overcoming the trade-off between faithfulness and efficiency, and the selection of different acceleration methods.", "published": "2023-02-07T03:15:38Z", "version": 2}, {"aid": "2302.03686", "authors": ["Andy Shih", "Dorsa Sadigh", "Stefano Ermon"], "title": "Long Horizon Temperature Scaling", "url": "http://arxiv.org/pdf/2302.03686v2", "summary": "Temperature scaling is a popular technique for tuning the sharpness of a model distribution. It is used extensively for sampling likely generations and calibrating model uncertainty, and even features as a controllable parameter to many large language models in deployment. However, autoregressive models rely on myopic temperature scaling that greedily optimizes the next token. To address this, we propose Long Horizon Temperature Scaling (LHTS), a novel approach for sampling from temperature-scaled joint distributions. LHTS is compatible with all likelihood-based models, and optimizes for the long horizon likelihood of samples. We derive a temperature-dependent LHTS objective, and show that finetuning a model on a range of temperatures produces a single model capable of generation with a controllable long horizon temperature parameter. We experiment with LHTS on image diffusion models and character/language autoregressive models, demonstrating advantages over myopic temperature scaling in likelihood and sample quality, and showing improvements in accuracy on a multiple choice analogy task by $10\\%$.", "published": "2023-02-07T18:59:32Z", "version": 2}, {"aid": "2302.03750", "authors": ["Hao Liang", "Josue Ortega Caro", "Vikram Maheshri", "Ankit B. Patel", "Guha Balakrishnan"], "title": "Linking convolutional kernel size to generalization bias in face analysis CNNs", "url": "http://arxiv.org/pdf/2302.03750v2", "summary": "Training dataset biases are by far the most scrutinized factors when explaining algorithmic biases of neural networks. In contrast, hyperparameters related to the neural network architecture have largely been ignored even though different network parameterizations are known to induce different implicit biases over learned features. For example, convolutional kernel size is known to affect the frequency content of features learned in CNNs. In this work, we present a causal framework for linking an architectural hyperparameter to out-of-distribution algorithmic bias. Our framework is experimental, in that we train several versions of a network with an intervention to a specific hyperparameter, and measure the resulting causal effect of this choice on performance bias when a particular out-of-distribution image perturbation is applied. In our experiments, we focused on measuring the causal relationship between convolutional kernel size and face analysis classification bias across different subpopulations (race/gender), with respect to high-frequency image details. We show that modifying kernel size, even in one layer of a CNN, changes the frequency content of learned features significantly across data subgroups leading to biased generalization performance even in the presence of a balanced dataset.", "published": "2023-02-07T20:55:09Z", "version": 2}, {"aid": "2302.03763", "authors": ["Richard Gast", "Thomas R. Kn\u00f6sche", "Ann Kennedy"], "title": "PyRates -- A Code-Generation Tool for Dynamical Systems Modeling", "url": "http://arxiv.org/pdf/2302.03763v2", "summary": "Mathematical models allow us to gain a deeper understanding of real-world dynamical systems. One of the most powerful mathematical frameworks for modeling real-world phenomena are systems of differential equations. In the majority of fields that use differential equations, numerical methods are essential for conducting model-based research. Although many software solutions are available for the numerical study of differential equation systems, a common framework for implementing differential equation systems is lacking. This hinders progress in dynamical systems research and limits the shareability and reproducibility of results.   PyRates is a Python-based software for modeling and analyzing dynamical systems. It provides a user-friendly interface for defining models, which is based on a graph-based, hierarchical structure that mirrors the modular organization of real-world dynamical systems. This design allows users to leverage the hierarchical structure of their systems and create their models with minimal effort.   Importantly, the core of PyRates is a versatile code-generation system, which can translate user-defined models into \"backend\" implementations in various languages, including Python, Fortran, and Julia. This allows users to access a wide range of analysis methods for dynamical systems, eliminating the need for manual translation between code bases.   We demonstrate PyRates's capabilities in three use cases, where it generates NumPy code for numerical simulations, Fortran code for bifurcation analysis, and PyTorch code for neural network optimization. Finally, PyRates can be used as a model definition interface for the creation of new dynamical systems tools. We developed two such software packages, PyCoBi and RectiPy, as extensions of PyRates for specific dynamical systems modeling applications.", "published": "2023-02-07T21:43:40Z", "version": 2}, {"aid": "2302.03830", "authors": ["Mohammad Farazi", "Zhangsihao Yang", "Wenhui Zhu", "Peijie Qiu", "Yalin Wang"], "title": "TetCNN: Convolutional Neural Networks on Tetrahedral Meshes", "url": "http://arxiv.org/pdf/2302.03830v2", "summary": "Convolutional neural networks (CNN) have been broadly studied on images, videos, graphs, and triangular meshes. However, it has seldom been studied on tetrahedral meshes. Given the merits of using volumetric meshes in applications like brain image analysis, we introduce a novel interpretable graph CNN framework for the tetrahedral mesh structure. Inspired by ChebyNet, our model exploits the volumetric Laplace-Beltrami Operator (LBO) to define filters over commonly used graph Laplacian which lacks the Riemannian metric information of 3D manifolds. For pooling adaptation, we introduce new objective functions for localized minimum cuts in the Graclus algorithm based on the LBO. We employ a piece-wise constant approximation scheme that uses the clustering assignment matrix to estimate the LBO on sampled meshes after each pooling. Finally, adapting the Gradient-weighted Class Activation Mapping algorithm for tetrahedral meshes, we use the obtained heatmaps to visualize discovered regions-of-interest as biomarkers. We demonstrate the effectiveness of our model on cortical tetrahedral meshes from patients with Alzheimer's disease, as there is scientific evidence showing the correlation of cortical thickness to neurodegenerative disease progression. Our results show the superiority of our LBO-based convolution layer and adapted pooling over the conventionally used unitary cortical thickness, graph Laplacian, and point cloud representation.", "published": "2023-02-08T01:52:48Z", "version": 2}, {"aid": "2302.04304", "authors": ["Xiuyu Li", "Yijiang Liu", "Long Lian", "Huanrui Yang", "Zhen Dong", "Daniel Kang", "Shanghang Zhang", "Kurt Keutzer"], "title": "Q-Diffusion: Quantizing Diffusion Models", "url": "http://arxiv.org/pdf/2302.04304v3", "summary": "Diffusion models have achieved great success in image synthesis through iterative noise estimation using deep neural networks. However, the slow inference, high memory consumption, and computation intensity of the noise estimation model hinder the efficient adoption of diffusion models. Although post-training quantization (PTQ) is considered a go-to compression method for other tasks, it does not work out-of-the-box on diffusion models. We propose a novel PTQ method specifically tailored towards the unique multi-timestep pipeline and model architecture of the diffusion models, which compresses the noise estimation network to accelerate the generation process. We identify the key difficulty of diffusion model quantization as the changing output distributions of noise estimation networks over multiple time steps and the bimodal activation distribution of the shortcut layers within the noise estimation network. We tackle these challenges with timestep-aware calibration and split shortcut quantization in this work. Experimental results show that our proposed method is able to quantize full-precision unconditional diffusion models into 4-bit while maintaining comparable performance (small FID change of at most 2.34 compared to >100 for traditional PTQ) in a training-free manner. Our approach can also be applied to text-guided image generation, where we can run stable diffusion in 4-bit weights with high generation quality for the first time.", "published": "2023-02-08T19:38:59Z", "version": 3}, {"aid": "2302.05017", "authors": ["Bingnan Wang", "Fanjiang Xu", "Quan Zheng"], "title": "A survey on facial image deblurring", "url": "http://arxiv.org/pdf/2302.05017v2", "summary": "When a facial image is blurred, it significantly affects high-level vision tasks such as face recognition. The purpose of facial image deblurring is to recover a clear image from a blurry input image, which can improve the recognition accuracy, etc. However, general deblurring methods do not perform well on facial images. Therefore, some face deblurring methods have been proposed to improve performance by adding semantic or structural information as specific priors according to the characteristics of the facial images. In this paper, we survey and summarize recently published methods for facial image deblurring, most of which are based on deep learning. First, we provide a brief introduction to the modeling of image blurring. Next, we summarize face deblurring methods into two categories: model-based methods and deep learning-based methods. Furthermore, we summarize the datasets, loss functions, and performance evaluation metrics commonly used in the neural network training process. We show the performance of classical methods on these datasets and metrics and provide a brief discussion on the differences between model-based and learning-based methods. Finally, we discuss the current challenges and possible future research directions.", "published": "2023-02-10T02:24:56Z", "version": 2}, {"aid": "2302.05282", "authors": ["Daniele Paliotta", "Mathieu Alain", "B\u00e1lint M\u00e1t\u00e9", "Fran\u00e7ois Fleuret"], "title": "Graph Neural Networks Go Forward-Forward", "url": "http://arxiv.org/pdf/2302.05282v1", "summary": "We present the Graph Forward-Forward (GFF) algorithm, an extension of the Forward-Forward procedure to graphs, able to handle features distributed over a graph's nodes. This allows training graph neural networks with forward passes only, without backpropagation. Our method is agnostic to the message-passing scheme, and provides a more biologically plausible learning scheme than backpropagation, while also carrying computational advantages. With GFF, graph neural networks are trained greedily layer by layer, using both positive and negative samples. We run experiments on 11 standard graph property prediction tasks, showing how GFF provides an effective alternative to backpropagation for training graph neural networks. This shows in particular that this procedure is remarkably efficient in spite of combining the per-layer training with the locality of the processing in a GNN.", "published": "2023-02-10T14:45:36Z", "version": 1}, {"aid": "2302.05872", "authors": ["Guan-Horng Liu", "Arash Vahdat", "De-An Huang", "Evangelos A. Theodorou", "Weili Nie", "Anima Anandkumar"], "title": "I$^2$SB: Image-to-Image Schr\u00f6dinger Bridge", "url": "http://arxiv.org/pdf/2302.05872v3", "summary": "We propose Image-to-Image Schr\\\"odinger Bridge (I$^2$SB), a new class of conditional diffusion models that directly learn the nonlinear diffusion processes between two given distributions. These diffusion bridges are particularly useful for image restoration, as the degraded images are structurally informative priors for reconstructing the clean images. I$^2$SB belongs to a tractable class of Schr\\\"odinger bridge, the nonlinear extension to score-based models, whose marginal distributions can be computed analytically given boundary pairs. This results in a simulation-free framework for nonlinear diffusions, where the I$^2$SB training becomes scalable by adopting practical techniques used in standard diffusion models. We validate I$^2$SB in solving various image restoration tasks, including inpainting, super-resolution, deblurring, and JPEG restoration on ImageNet 256x256 and show that I$^2$SB surpasses standard conditional diffusion models with more interpretable generative processes. Moreover, I$^2$SB matches the performance of inverse methods that additionally require the knowledge of the corruption operators. Our work opens up new algorithmic opportunities for developing efficient nonlinear diffusion models on a large scale. scale. Project page and codes: https://i2sb.github.io/", "published": "2023-02-12T08:35:39Z", "version": 3}, {"aid": "2302.06403", "authors": ["Xu Ji", "Eric Elmoznino", "George Deane", "Axel Constant", "Guillaume Dumas", "Guillaume Lajoie", "Jonathan Simon", "Yoshua Bengio"], "title": "Sources of Richness and Ineffability for Phenomenally Conscious States", "url": "http://arxiv.org/pdf/2302.06403v5", "summary": "Conscious states (states that there is something it is like to be in) seem both rich or full of detail, and ineffable or hard to fully describe or recall. The problem of ineffability, in particular, is a longstanding issue in philosophy that partly motivates the explanatory gap: the belief that consciousness cannot be reduced to underlying physical processes. Here, we provide an information theoretic dynamical systems perspective on the richness and ineffability of consciousness. In our framework, the richness of conscious experience corresponds to the amount of information in a conscious state and ineffability corresponds to the amount of information lost at different stages of processing. We describe how attractor dynamics in working memory would induce impoverished recollections of our original experiences, how the discrete symbolic nature of language is insufficient for describing the rich and high-dimensional structure of experiences, and how similarity in the cognitive function of two individuals relates to improved communicability of their experiences to each other. While our model may not settle all questions relating to the explanatory gap, it makes progress toward a fully physicalist explanation of the richness and ineffability of conscious experience: two important aspects that seem to be part of what makes qualitative character so puzzling.", "published": "2023-02-13T14:41:04Z", "version": 5}, {"aid": "2302.06833", "authors": ["Kyle Sargent", "Jing Yu Koh", "Han Zhang", "Huiwen Chang", "Charles Herrmann", "Pratul Srinivasan", "Jiajun Wu", "Deqing Sun"], "title": "VQ3D: Learning a 3D-Aware Generative Model on ImageNet", "url": "http://arxiv.org/pdf/2302.06833v1", "summary": "Recent work has shown the possibility of training generative models of 3D content from 2D image collections on small datasets corresponding to a single object class, such as human faces, animal faces, or cars. However, these models struggle on larger, more complex datasets. To model diverse and unconstrained image collections such as ImageNet, we present VQ3D, which introduces a NeRF-based decoder into a two-stage vector-quantized autoencoder. Our Stage 1 allows for the reconstruction of an input image and the ability to change the camera position around the image, and our Stage 2 allows for the generation of new 3D scenes. VQ3D is capable of generating and reconstructing 3D-aware images from the 1000-class ImageNet dataset of 1.2 million training images. We achieve an ImageNet generation FID score of 16.8, compared to 69.8 for the next best baseline method.", "published": "2023-02-14T05:15:16Z", "version": 1}, {"aid": "2302.07167", "authors": ["Daniel Nyga", "Mareike Picklum", "Tom Schierenbeck", "Michael Beetz"], "title": "Joint Probability Trees", "url": "http://arxiv.org/pdf/2302.07167v1", "summary": "We introduce Joint Probability Trees (JPT), a novel approach that makes learning of and reasoning about joint probability distributions tractable for practical applications. JPTs support both symbolic and subsymbolic variables in a single hybrid model, and they do not rely on prior knowledge about variable dependencies or families of distributions. JPT representations build on tree structures that partition the problem space into relevant subregions that are elicited from the training data instead of postulating a rigid dependency model prior to learning. Learning and reasoning scale linearly in JPTs, and the tree structure allows white-box reasoning about any posterior probability $P(Q|E)$, such that interpretable explanations can be provided for any inference result. Our experiments showcase the practical applicability of JPTs in high-dimensional heterogeneous probability spaces with millions of training samples, making it a promising alternative to classic probabilistic graphical models.", "published": "2023-02-14T16:29:41Z", "version": 1}, {"aid": "2302.07238", "authors": ["Thamsanqa Mlotshwa", "Heinrich van Deventer", "Anna Sergeevna Bosman"], "title": "Cauchy Loss Function: Robustness Under Gaussian and Cauchy Noise", "url": "http://arxiv.org/pdf/2302.07238v1", "summary": "In supervised machine learning, the choice of loss function implicitly assumes a particular noise distribution over the data. For example, the frequently used mean squared error (MSE) loss assumes a Gaussian noise distribution. The choice of loss function during training and testing affects the performance of artificial neural networks (ANNs). It is known that MSE may yield substandard performance in the presence of outliers. The Cauchy loss function (CLF) assumes a Cauchy noise distribution, and is therefore potentially better suited for data with outliers. This papers aims to determine the extent of robustness and generalisability of the CLF as compared to MSE. CLF and MSE are assessed on a few handcrafted regression problems, and a real-world regression problem with artificially simulated outliers, in the context of ANN training. CLF yielded results that were either comparable to or better than the results yielded by MSE, with a few notable exceptions.", "published": "2023-02-14T18:34:44Z", "version": 1}, {"aid": "2302.07253", "authors": ["Benjamin Hoover", "Yuchen Liang", "Bao Pham", "Rameswar Panda", "Hendrik Strobelt", "Duen Horng Chau", "Mohammed J. Zaki", "Dmitry Krotov"], "title": "Energy Transformer", "url": "http://arxiv.org/pdf/2302.07253v2", "summary": "Our work combines aspects of three promising paradigms in machine learning, namely, attention mechanism, energy-based models, and associative memory. Attention is the power-house driving modern deep learning successes, but it lacks clear theoretical foundations. Energy-based models allow a principled approach to discriminative and generative tasks, but the design of the energy functional is not straightforward. At the same time, Dense Associative Memory models or Modern Hopfield Networks have a well-established theoretical foundation, and allow an intuitive design of the energy function. We propose a novel architecture, called the Energy Transformer (or ET for short), that uses a sequence of attention layers that are purposely designed to minimize a specifically engineered energy function, which is responsible for representing the relationships between the tokens. In this work, we introduce the theoretical foundations of ET, explore its empirical capabilities using the image completion task, and obtain strong quantitative results on the graph anomaly detection and graph classification tasks.", "published": "2023-02-14T18:51:22Z", "version": 2}, {"aid": "2302.07350", "authors": ["J. Swaroop Guntupalli", "Rajkumar Vasudeva Raju", "Shrinu Kushagra", "Carter Wendelken", "Danny Sawyer", "Ishan Deshpande", "Guangyao Zhou", "Miguel L\u00e1zaro-Gredilla", "Dileep George"], "title": "Graph schemas as abstractions for transfer learning, inference, and planning", "url": "http://arxiv.org/pdf/2302.07350v2", "summary": "Transferring latent structure from one environment or problem to another is a mechanism by which humans and animals generalize with very little data. Inspired by cognitive and neurobiological insights, we propose graph schemas as a mechanism of abstraction for transfer learning. Graph schemas start with latent graph learning where perceptually aliased observations are disambiguated in the latent space using contextual information. Latent graph learning is also emerging as a new computational model of the hippocampus to explain map learning and transitive inference. Our insight is that a latent graph can be treated as a flexible template -- a schema -- that models concepts and behaviors, with slots that bind groups of latent nodes to the specific observations or groundings. By treating learned latent graphs (schemas) as prior knowledge, new environments can be quickly learned as compositions of schemas and their newly learned bindings. We evaluate graph schemas on two previously published challenging tasks: the memory & planning game and one-shot StreetLearn, which are designed to test rapid task solving in novel environments. Graph schemas can be learned in far fewer episodes than previous baselines, and can model and plan in a few steps in novel variations of these tasks. We also demonstrate learning, matching, and reusing graph schemas in more challenging 2D and 3D environments with extensive perceptual aliasing and size variations, and show how different schemas can be composed to model larger and more complex environments. To summarize, our main contribution is a unified system, inspired and grounded in cognitive science, that facilitates rapid transfer learning of new environments using schemas via map-induction and composition that handles perceptual aliasing.", "published": "2023-02-14T21:23:22Z", "version": 2}, {"aid": "2302.07950", "authors": ["Kazuki Irie", "R\u00f3bert Csord\u00e1s", "J\u00fcrgen Schmidhuber"], "title": "Self-Organising Neural Discrete Representation Learning \u00e0 la Kohonen", "url": "http://arxiv.org/pdf/2302.07950v2", "summary": "Unsupervised learning of discrete representations in neural networks (NNs) from continuous ones is essential for many modern applications. Vector Quantisation (VQ) has become popular for this, in particular in the context of generative models, such as Variational Auto-Encoders (VAEs), where the exponential moving average-based VQ (EMA-VQ) algorithm is often used. Here, we study an alternative VQ algorithm based on Kohonen's learning rule for the Self-Organising Map (KSOM; 1982). EMA-VQ is a special case of KSOM. KSOM is known to offer two potential benefits: empirically, it converges faster than EMA-VQ, and KSOM-generated discrete representations form a topological structure on the grid whose nodes are the discrete symbols, resulting in an artificial version of the brain's topographic map. We revisit these properties by using KSOM in VQ-VAEs for image processing. In our experiments, the speed-up compared to well-configured EMA-VQ is only observable at the beginning of training, but KSOM is generally much more robust, e.g., w.r.t. the choice of initialisation schemes.", "published": "2023-02-15T21:04:04Z", "version": 2}, {"aid": "2302.08175", "authors": ["Frank Nielsen"], "title": "A numerical approximation method for the Fisher-Rao distance between multivariate normal distributions", "url": "http://arxiv.org/pdf/2302.08175v6", "summary": "We present a simple method to approximate Rao's distance between multivariate normal distributions based on discretizing curves joining normal distributions and approximating Rao's distances between successive nearby normal distributions on the curves by the square root of Jeffreys divergence, the symmetrized Kullback-Leibler divergence. We consider experimentally the linear interpolation curves in the ordinary, natural and expectation parameterizations of the normal distributions, and compare these curves with a curve derived from the Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal manifold into the cone of $(d+1)\\times (d+1)$ symmetric positive-definite matrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on our experiments and assess the quality of our approximation technique by comparing the numerical approximations with both lower and upper bounds. Finally, we present several information-geometric properties of the Calvo and Oller's isometric embedding.", "published": "2023-02-16T09:44:55Z", "version": 6}, {"aid": "2302.08183", "authors": ["Dan Meller", "Nicolas Berkouk"], "title": "Singular Value Representation: A New Graph Perspective On Neural Networks", "url": "http://arxiv.org/pdf/2302.08183v1", "summary": "We introduce the Singular Value Representation (SVR), a new method to represent the internal state of neural networks using SVD factorization of the weights. This construction yields a new weighted graph connecting what we call spectral neurons, that correspond to specific activation patterns of classical neurons. We derive a precise statistical framework to discriminate meaningful connections between spectral neurons for fully connected and convolutional layers.   To demonstrate the usefulness of our approach for machine learning research, we highlight two discoveries we made using the SVR. First, we highlight the emergence of a dominant connection in VGG networks that spans multiple deep layers. Second, we witness, without relying on any input data, that batch normalization can induce significant connections between near-kernels of deep layers, leading to a remarkable spontaneous sparsification phenomenon.", "published": "2023-02-16T10:10:31Z", "version": 1}, {"aid": "2302.08392", "authors": ["Christoph B\u00f6rgers"], "title": "Infinitesimal phase response functions can be misleading", "url": "http://arxiv.org/pdf/2302.08392v2", "summary": "Phase response functions are the central tool in the mathematical analysis of pulse-coupled oscillators. When an oscillator receives a brief input pulse, the phase response function specifies how its phase shifts as a function of the phase at which the input is received. When the pulse is weak, it is customary to linearize around zero pulse strength. The result is called the infinitesimal phase response function. These ideas have been used extensively in theoretical biology, and also in some areas of engineering. I give examples showing that the infinitesimal phase response function may predict that two oscillators, as they exchange pulses back and fourth, will converge to synchrony, yet this is false when the exact phase response function is used, for all positive interaction strengths. For short, the analogue of the Hartman-Grobman theorem that one might expect to hold at first sight is invalid. I give a condition under which the prediction derived using the infinitesimal phase response function does hold for the exact phase response function when interactions are sufficiently weak but positive. However, I argue that this condition may often fail to hold.", "published": "2023-02-16T16:11:21Z", "version": 2}, {"aid": "2302.08411", "authors": ["Martin Zach", "Thomas Pock", "Erich Kobler", "Antonin Chambolle"], "title": "Explicit Diffusion of Gaussian Mixture Model Based Image Priors", "url": "http://arxiv.org/pdf/2302.08411v1", "summary": "In this work we tackle the problem of estimating the density $f_X$ of a random variable $X$ by successive smoothing, such that the smoothed random variable $Y$ fulfills $(\\partial_t - \\Delta_1)f_Y(\\,\\cdot\\,, t) = 0$, $f_Y(\\,\\cdot\\,, 0) = f_X$. With a focus on image processing, we propose a product/fields of experts model with Gaussian mixture experts that admits an analytic expression for $f_Y (\\,\\cdot\\,, t)$ under an orthogonality constraint on the filters. This construction naturally allows the model to be trained simultaneously over the entire diffusion horizon using empirical Bayes. We show preliminary results on image denoising where our model leads to competitive results while being tractable, interpretable, and having only a small number of learnable parameters. As a byproduct, our model can be used for reliable noise estimation, allowing blind denoising of images corrupted by heteroscedastic noise.", "published": "2023-02-16T16:39:13Z", "version": 1}, {"aid": "2302.08458", "authors": ["Marcelo J. Rozenberg"], "title": "Solid State Neuroscience: Spiking Neural Networks as Time Matter", "url": "http://arxiv.org/pdf/2302.08458v1", "summary": "We aim at building a bridge between to {\\it a priori} disconnected fields: Neuroscience and Material Science. We construct an analogy based on identifying spikes events in time with the positions of particles of matter. We show that one may think of the dynamical states of spiking neurons and spiking neural networks as {\\it time-matter}. Namely, a structure of spike-events in time having analogue properties to that of ordinary matter. We can define for neural systems notions equivalent to the equations of state, phase diagrams and their phase transitions. For instance, the familiar Ideal Gas Law relation (P$v$ = constant) emerges as analogue of the Ideal Integrate and Fire neuron model relation ($I_{in}$ISI = constant). We define the neural analogue of the spatial structure correlation function, that can characterize spiking states with temporal long-range order, such as regular tonic spiking. We also define the ``neuro-compressibility'' response function in analogy to the lattice compressibility. We show that similarly to the case of ordinary matter, the anomalous behavior of the neuro-compressibility is a precursor effect that signals the onset of changes in spiking states. We propose that the notion of neuro-compressibility may open the way to develop novel medical tools for the early diagnose of diseases. It may allow to predict impending anomalous neural states, such as Parkinson's tremors, epileptic seizures, electric cardiopathies, and perhaps may even serve as a predictor of the likelihood of regaining consciousness.", "published": "2023-02-16T18:04:10Z", "version": 1}, {"aid": "2302.08478", "authors": ["Tomoki Yoshida", "Yuki Kondo", "Takahiro Maeda", "Kazutoshi Akita", "Norimichi Ukita"], "title": "Kernelized Back-Projection Networks for Blind Super Resolution", "url": "http://arxiv.org/pdf/2302.08478v3", "summary": "Since non-blind Super Resolution (SR) fails to super-resolve Low-Resolution (LR) images degraded by arbitrary degradations, SR with the degradation model is required. However, this paper reveals that non-blind SR that is trained simply with various blur kernels exhibits comparable performance as those with the degradation model for blind SR. This result motivates us to revisit high-performance non-blind SR and extend it to blind SR with blur kernels. This paper proposes two SR networks by integrating kernel estimation and SR branches in an iterative end-to-end manner. In the first model, which is called the Kernel Conditioned Back-Projection Network (KCBPN), the low-dimensional kernel representations are estimated for conditioning the SR branch. In our second model, the Kernelized BackProjection Network (KBPN), a raw kernel is estimated and directly employed for modeling the image degradation. The estimated kernel is employed not only for back-propagating its residual but also for forward-propagating the residual to iterative stages. This forward-propagation encourages these stages to learn a variety of different features in different stages by focusing on pixels with large residuals in each stage. Experimental results validate the effectiveness of our proposed networks for kernel estimation and SR. We will release the code for this work.", "published": "2023-02-16T18:35:39Z", "version": 3}, {"aid": "2302.08545", "authors": ["Minghao Li", "Ran Ben Basat", "Shay Vargaftik", "ChonLam Lao", "Kevin Xu", "Michael Mitzenmacher", "Minlan Yu"], "title": "THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic Compression", "url": "http://arxiv.org/pdf/2302.08545v2", "summary": "Deep neural networks (DNNs) are the de facto standard for essential use cases, such as image classification, computer vision, and natural language processing. As DNNs and datasets get larger, they require distributed training on increasingly larger clusters. A main bottleneck is the resulting communication overhead where workers exchange model updates (i.e., gradients) on a per-round basis. To address this bottleneck and accelerate training, a widely-deployed approach is compression. However, previous deployments often apply bi-directional compression schemes by simply using a uni-directional gradient compression scheme in each direction. This results in significant computational overheads at the parameter server and increased compression error, leading to longer training and lower accuracy. We introduce Tensor Homomorphic Compression (THC), a novel bi-directional compression framework that enables the direct aggregation of compressed values and thus eliminating the aforementioned computational overheads. Moreover, THC is compatible with in-network aggregation (INA), which allows for further acceleration. Our evaluation shows that training representative vision and language models with THC reaches target accuracy by 1.40x to 1.47x faster using INA and 1.28x to 1.33x faster using a software PS compared with state-of-the-art systems.", "published": "2023-02-16T19:48:20Z", "version": 2}, {"aid": "2302.09160", "authors": ["William T. Redman", "Juan M. Bello-Rivas", "Maria Fonoberova", "Ryan Mohr", "Ioannis G. Kevrekidis", "Igor Mezi\u0107"], "title": "Identifying Equivalent Training Dynamics", "url": "http://arxiv.org/pdf/2302.09160v3", "summary": "Study of the nonlinear evolution deep neural network (DNN) parameters undergo during training has uncovered regimes of distinct dynamical behavior. While a detailed understanding of these phenomena has the potential to advance improvements in training efficiency and robustness, the lack of methods for identifying when DNN models have equivalent dynamics limits the insight that can be gained from prior work. Topological conjugacy, a notion from dynamical systems theory, provides a precise definition of dynamical equivalence, offering a possible route to address this need. However, topological conjugacies have historically been challenging to compute. By leveraging advances in Koopman operator theory, we develop a framework for identifying conjugate and non-conjugate training dynamics. To validate our approach, we demonstrate that comparing Koopman eigenvalues can correctly identify a known equivalence between online mirror descent and online gradient descent. We then utilize our approach to: (a) identify non-conjugate training dynamics between shallow and wide fully connected neural networks; (b) characterize the early phase of training dynamics in convolutional neural networks; (c) uncover non-conjugate training dynamics in Transformers that do and do not undergo grokking. Our results, across a range of DNN architectures, illustrate the flexibility of our framework and highlight its potential for shedding new light on training dynamics.", "published": "2023-02-17T22:15:20Z", "version": 3}, {"aid": "2302.10163", "authors": ["Marc W. Howard", "Zahra G. Esfahani", "Bao Le", "Per B. Sederberg"], "title": "Learning temporal relationships between symbols with Laplace Neural Manifolds", "url": "http://arxiv.org/pdf/2302.10163v4", "summary": "Firing across populations of neurons in many regions of the mammalian brain maintains a temporal memory, a neural timeline of the recent past. Behavioral results demonstrate that people can both remember the past and anticipate the future over an analogous internal timeline. This paper presents a mathematical framework for building this timeline of the future. We assume that the input to the system is a time series of symbols--sparse tokenized representations of the present--in continuous time. The goal is to record pairwise temporal relationships between symbols over a wide range of time scales. We assume that the brain has access to a temporal memory in the form of the real Laplace transform. Hebbian associations with a diversity of synaptic time scales are formed between the past timeline and the present symbol. The associative memory stores the convolution between the past and the present. Knowing the temporal relationship between the past and the present allows one to infer relationships between the present and the future. With appropriate normalization, this Hebbian associative matrix can store a Laplace successor representation and a Laplace predecessor representation from which measures of temporal contingency can be evaluated. The diversity of synaptic time constants allows for learning of non-stationary statistics as well as joint statistics between triplets of symbols. This framework synthesizes a number of recent neuroscientific findings including results from dopamine neurons in the mesolimbic forebrain.", "published": "2023-02-20T18:49:34Z", "version": 4}, {"aid": "2302.10266", "authors": ["M. Amine Mahmoudi", "Aladine Chetouani", "Fatma Boufera", "Hedi Tabia"], "title": "Kernel function impact on convolutional neural networks", "url": "http://arxiv.org/pdf/2302.10266v1", "summary": "This paper investigates the usage of kernel functions at the different layers in a convolutional neural network. We carry out extensive studies of their impact on convolutional, pooling and fully-connected layers. We notice that the linear kernel may not be sufficiently effective to fit the input data distributions, whereas high order kernels prone to over-fitting. This leads to conclude that a trade-off between complexity and performance should be reached. We show how one can effectively leverage kernel functions, by introducing a more distortion aware pooling layers which reduces over-fitting while keeping track of the majority of the information fed into subsequent layers. We further propose Kernelized Dense Layers (KDL), which replace fully-connected layers, and capture higher order feature interactions. The experiments on conventional classification datasets i.e. MNIST, FASHION-MNIST and CIFAR-10, show that the proposed techniques improve the performance of the network compared to classical convolution, pooling and fully connected layers. Moreover, experiments on fine-grained classification i.e. facial expression databases, namely RAF-DB, FER2013 and ExpW demonstrate that the discriminative power of the network is boosted, since the proposed techniques improve the awareness to slight visual details and allows the network reaching state-of-the-art results.", "published": "2023-02-20T19:57:01Z", "version": 1}, {"aid": "2302.10392", "authors": ["Qi Lin", "Zifan Li", "John Lafferty", "Ilker Yildirim"], "title": "From seeing to remembering: Images with harder-to-reconstruct representations leave stronger memory traces", "url": "http://arxiv.org/pdf/2302.10392v1", "summary": "Much of what we remember is not due to intentional selection, but simply a by-product of perceiving. This raises a foundational question about the architecture of the mind: How does perception interface with and influence memory? Here, inspired by a classic proposal relating perceptual processing to memory durability, the level-of-processing theory, we present a sparse coding model for compressing feature embeddings of images, and show that the reconstruction residuals from this model predict how well images are encoded into memory. In an open memorability dataset of scene images, we show that reconstruction error not only explains memory accuracy but also response latencies during retrieval, subsuming, in the latter case, all of the variance explained by powerful vision-only models. We also confirm a prediction of this account with 'model-driven psychophysics'. This work establishes reconstruction error as a novel signal interfacing perception and memory, possibly through adaptive modulation of perceptual processing.", "published": "2023-02-21T01:40:32Z", "version": 1}, {"aid": "2302.10688", "authors": ["Tianyu Pang", "Cheng Lu", "Chao Du", "Min Lin", "Shuicheng Yan", "Zhijie Deng"], "title": "On Calibrating Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2302.10688v3", "summary": "Recently, diffusion probabilistic models (DPMs) have achieved promising results in diverse generative tasks. A typical DPM framework includes a forward process that gradually diffuses the data distribution and a reverse process that recovers the data distribution from time-dependent data scores. In this work, we observe that the stochastic reverse process of data scores is a martingale, from which concentration bounds and the optional stopping theorem for data scores can be derived. Then, we discover a simple way for calibrating an arbitrary pretrained DPM, with which the score matching loss can be reduced and the lower bounds of model likelihood can consequently be increased. We provide general calibration guidelines under various model parametrizations. Our calibration method is performed only once and the resulting models can be used repeatedly for sampling. We conduct experiments on multiple datasets to empirically validate our proposal. Our code is at https://github.com/thudzj/Calibrated-DPMs.", "published": "2023-02-21T14:14:40Z", "version": 3}, {"aid": "2303.01514", "authors": ["Chris Fields", "Filippo Fabrocini", "Karl Friston", "James F. Glazebrook", "Hananel Hazan", "Michael Levin", "Antonino Marciano"], "title": "Control flow in active inference systems", "url": "http://arxiv.org/pdf/2303.01514v1", "summary": "Living systems face both environmental complexity and limited access to free-energy resources. Survival under these conditions requires a control system that can activate, or deploy, available perception and action resources in a context specific way. We show here that when systems are described as executing active inference driven by the free-energy principle (and hence can be considered Bayesian prediction-error minimizers), their control flow systems can always be represented as tensor networks (TNs). We show how TNs as control systems can be implmented within the general framework of quantum topological neural networks, and discuss the implications of these results for modeling biological systems at multiple scales.", "published": "2023-02-25T02:31:47Z", "version": 1}, {"aid": "2303.04146", "authors": ["J. A. Scott Kelso"], "title": "The Critical Brain Hypothesis? Meet The Metastable Brain~Mind", "url": "http://arxiv.org/pdf/2303.04146v1", "summary": "In contrast to the critical brain hypothesis in which the brain tunes itself to a critical point between $states$ of chaos and order, analysis of Coordination Dynamics suggests that a vast repertoire of $coexisting$ $tendencies$ exists for regions of the brain to integrate and segregate at the same time. Rather than teetering between order and randomness, the brain~mind lives in an immense sea of metastability where it can create functional information.", "published": "2023-02-28T18:56:31Z", "version": 1}, {"aid": "2303.00848", "authors": ["Diederik P. Kingma", "Ruiqi Gao"], "title": "Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation", "url": "http://arxiv.org/pdf/2303.00848v7", "summary": "To achieve the highest perceptual quality, state-of-the-art diffusion models are optimized with objectives that typically look very different from the maximum likelihood and the Evidence Lower Bound (ELBO) objectives. In this work, we reveal that diffusion model objectives are actually closely related to the ELBO.   Specifically, we show that all commonly used diffusion model objectives equate to a weighted integral of ELBOs over different noise levels, where the weighting depends on the specific objective used. Under the condition of monotonic weighting, the connection is even closer: the diffusion objective then equals the ELBO, combined with simple data augmentation, namely Gaussian noise perturbation. We show that this condition holds for a number of state-of-the-art diffusion models.   In experiments, we explore new monotonic weightings and demonstrate their effectiveness, achieving state-of-the-art FID scores on the high-resolution ImageNet benchmark.", "published": "2023-03-01T22:36:05Z", "version": 7}, {"aid": "2303.00879", "authors": ["Stephanie Chen", "Juan Pablo Vigneaux"], "title": "Categorical magnitude and entropy", "url": "http://arxiv.org/pdf/2303.00879v2", "summary": "Given any finite set equipped with a probability measure, one may compute its Shannon entropy or information content. The entropy becomes the logarithm of the cardinality of the set when the uniform probability is used. Leinster introduced a notion of Euler characteristic for certain finite categories, also known as magnitude, that can be seen as a categorical generalization of cardinality. This paper aims to connect the two ideas by considering the extension of Shannon entropy to finite categories endowed with probability, in such a way that the magnitude is recovered when a certain choice of \"uniform\" probability is made.", "published": "2023-03-02T00:36:36Z", "version": 2}, {"aid": "2303.01505", "authors": ["Dan Liu", "Xue Liu"], "title": "Ternary Quantization: A Survey", "url": "http://arxiv.org/pdf/2303.01505v1", "summary": "Inference time, model size, and accuracy are critical for deploying deep neural network models. Numerous research efforts have been made to compress neural network models with faster inference and higher accuracy. Pruning and quantization are mainstream methods to this end. During model quantization, converting individual float values of layer weights to low-precision ones can substantially reduce the computational overhead and improve the inference speed. Many quantization methods have been studied, for example, vector quantization, low-bit quantization, and binary/ternary quantization. This survey focuses on ternary quantization. We review the evolution of ternary quantization and investigate the relationships among existing ternary quantization methods from the perspective of projection function and optimization methods.", "published": "2023-03-02T03:38:51Z", "version": 1}, {"aid": "2303.01506", "authors": ["Huiqi Deng", "Na Zou", "Mengnan Du", "Weifu Chen", "Guocan Feng", "Ziwei Yang", "Zheyang Li", "Quanshi Zhang"], "title": "Understanding and Unifying Fourteen Attribution Methods with Taylor Interactions", "url": "http://arxiv.org/pdf/2303.01506v2", "summary": "Various attribution methods have been developed to explain deep neural networks (DNNs) by inferring the attribution/importance/contribution score of each input variable to the final output. However, existing attribution methods are often built upon different heuristics. There remains a lack of a unified theoretical understanding of why these methods are effective and how they are related. To this end, for the first time, we formulate core mechanisms of fourteen attribution methods, which were designed on different heuristics, into the same mathematical system, i.e., the system of Taylor interactions. Specifically, we prove that attribution scores estimated by fourteen attribution methods can all be reformulated as the weighted sum of two types of effects, i.e., independent effects of each individual input variable and interaction effects between input variables. The essential difference among the fourteen attribution methods mainly lies in the weights of allocating different effects. Based on the above findings, we propose three principles for a fair allocation of effects to evaluate the faithfulness of the fourteen attribution methods.", "published": "2023-03-02T04:50:05Z", "version": 2}, {"aid": "2303.01509", "authors": ["Anik Mallik", "Haoxin Wang", "Jiang Xie", "Dawei Chen", "Kyungtae Han"], "title": "EPAM: A Predictive Energy Model for Mobile AI", "url": "http://arxiv.org/pdf/2303.01509v1", "summary": "Artificial intelligence (AI) has enabled a new paradigm of smart applications -- changing our way of living entirely. Many of these AI-enabled applications have very stringent latency requirements, especially for applications on mobile devices (e.g., smartphones, wearable devices, and vehicles). Hence, smaller and quantized deep neural network (DNN) models are developed for mobile devices, which provide faster and more energy-efficient computation for mobile AI applications. However, how AI models consume energy in a mobile device is still unexplored. Predicting the energy consumption of these models, along with their different applications, such as vision and non-vision, requires a thorough investigation of their behavior using various processing sources. In this paper, we introduce a comprehensive study of mobile AI applications considering different DNN models and processing sources, focusing on computational resource utilization, delay, and energy consumption. We measure the latency, energy consumption, and memory usage of all the models using four processing sources through extensive experiments. We explain the challenges in such investigations and how we propose to overcome them. Our study highlights important insights, such as how mobile AI behaves in different applications (vision and non-vision) using CPU, GPU, and NNAPI. Finally, we propose a novel Gaussian process regression-based general predictive energy model based on DNN structures, computation resources, and processors, which can predict the energy for each complete application cycle irrespective of device configuration and application. This study provides crucial facts and an energy prediction mechanism to the AI research community to help bring energy efficiency to mobile AI applications.", "published": "2023-03-02T09:11:23Z", "version": 1}, {"aid": "2303.01515", "authors": ["Wanyu Bian"], "title": "Optimization-Based Deep learning methods for Magnetic Resonance Imaging Reconstruction and Synthesis", "url": "http://arxiv.org/pdf/2303.01515v1", "summary": "This dissertation is devoted to provide advanced nonconvex nonsmooth variational models of (Magnetic Resonance Image) MRI reconstruction, efficient learnable image reconstruction algorithms and parameter training algorithms that improve the accuracy and robustness of the optimization-based deep learning methods for compressed sensing MRI reconstruction and synthesis. The first part introduces a novel optimization based deep neural network whose architecture is inspired by proximal gradient descent for solving a variational model. The second part is a substantial extension of the preliminary work in the first part by solving the calibration-free fast pMRI reconstruction problem in a discrete-time optimal control framework. The third part aims at developing a generalizable Magnetic Resonance Imaging (MRI) reconstruction method in the meta-learning framework. The last part aims to synthesize target modality of MRI by using partially scanned k-space data from source modalities instead of fully scanned data that is used in the state-of-the-art multimodal synthesis.", "published": "2023-03-02T18:59:44Z", "version": 1}, {"aid": "2303.01559", "authors": ["Haozhe Liu", "Wentian Zhang", "Bing Li", "Haoqian Wu", "Nanjun He", "Yawen Huang", "Yuexiang Li", "Bernard Ghanem", "Yefeng Zheng"], "title": "Improving GAN Training via Feature Space Shrinkage", "url": "http://arxiv.org/pdf/2303.01559v2", "summary": "Due to the outstanding capability for data generation, Generative Adversarial Networks (GANs) have attracted considerable attention in unsupervised learning. However, training GANs is difficult, since the training distribution is dynamic for the discriminator, leading to unstable image representation. In this paper, we address the problem of training GANs from a novel perspective, \\emph{i.e.,} robust image classification. Motivated by studies on robust image representation, we propose a simple yet effective module, namely AdaptiveMix, for GANs, which shrinks the regions of training data in the image representation space of the discriminator. Considering it is intractable to directly bound feature space, we propose to construct hard samples and narrow down the feature distance between hard and easy samples. The hard samples are constructed by mixing a pair of training images. We evaluate the effectiveness of our AdaptiveMix with widely-used and state-of-the-art GAN architectures. The evaluation results demonstrate that our AdaptiveMix can facilitate the training of GANs and effectively improve the image quality of generated samples. We also show that our AdaptiveMix can be further applied to image classification and Out-Of-Distribution (OOD) detection tasks, by equipping it with state-of-the-art methods. Extensive experiments on seven publicly available datasets show that our method effectively boosts the performance of baselines. The code is publicly available at https://github.com/WentianZhang-ML/AdaptiveMix.", "published": "2023-03-02T20:22:24Z", "version": 2}, {"aid": "2303.01567", "authors": ["Matthias Rath", "Alexandru Paul Condurache"], "title": "Deep Neural Networks with Efficient Guaranteed Invariances", "url": "http://arxiv.org/pdf/2303.01567v1", "summary": "We address the problem of improving the performance and in particular the sample complexity of deep neural networks by enforcing and guaranteeing invariances to symmetry transformations rather than learning them from data. Group-equivariant convolutions are a popular approach to obtain equivariant representations. The desired corresponding invariance is then imposed using pooling operations. For rotations, it has been shown that using invariant integration instead of pooling further improves the sample complexity. In this contribution, we first expand invariant integration beyond rotations to flips and scale transformations. We then address the problem of incorporating multiple desired invariances into a single network. For this purpose, we propose a multi-stream architecture, where each stream is invariant to a different transformation such that the network can simultaneously benefit from multiple invariances. We demonstrate our approach with successful experiments on Scaled-MNIST, SVHN, CIFAR-10 and STL-10.", "published": "2023-03-02T20:44:45Z", "version": 1}, {"aid": "2303.01618", "authors": ["Th\u00e9ophile Champion", "Marek Grze\u015b", "Lisa Bonheme", "Howard Bowman"], "title": "Deconstructing deep active inference", "url": "http://arxiv.org/pdf/2303.01618v2", "summary": "Active inference is a theory of perception, learning and decision making, which can be applied to neuroscience, robotics, and machine learning. Recently, reasearch has been taking place to scale up this framework using Monte-Carlo tree search and deep learning. The goal of this activity is to solve more complicated tasks using deep active inference. First, we review the existing literature, then, we progresively build a deep active inference agent. For two agents, we have experimented with five definitions of the expected free energy and three different action selection strategies. According to our experiments, the models able to solve the dSprites environment are the ones that maximise rewards. Finally, we compare the similarity of the representation learned by the layers of various agents using centered kernel alignment. Importantly, the agent maximising reward and the agent minimising expected free energy learn very similar representations except for the last layer of the critic network (reflecting the difference in learning objective), and the variance layers of the transition and encoder networks. We found that the reward maximising agent is a lot more certain than the agent minimising expected free energy. This is because the agent minimising expected free energy always picks the action down, and does not gather enough data for the other actions. In contrast, the agent maximising reward, keeps on selecting the actions left and right, enabling it to successfully solve the task. The only difference between those two agents is the epistemic value, which aims to make the outputs of the transition and encoder networks as close as possible. Thus, the agent minimising expected free energy picks a single action (down), and becomes an expert at predicting the future when selecting this action. This makes the KL divergence between the output of the transition and encoder networks small.", "published": "2023-03-02T22:39:56Z", "version": 2}, {"aid": "2303.01723", "authors": ["Nir Shlezinger", "Mengyuan Ma", "Ortal Lavi", "Nhan Thanh Nguyen", "Yonina C. Eldar", "Markku Juntti"], "title": "AI-Empowered Hybrid MIMO Beamforming", "url": "http://arxiv.org/pdf/2303.01723v1", "summary": "Hybrid multiple-input multiple-output (MIMO) is an attractive technology for realizing extreme massive MIMO systems envisioned for future wireless communications in a scalable and power-efficient manner. However, the fact that hybrid MIMO systems implement part of their beamforming in analog and part in digital makes the optimization of their beampattern notably more challenging compared with conventional fully digital MIMO. Consequently, recent years have witnessed a growing interest in using data-aided artificial intelligence (AI) tools for hybrid beamforming design. This article reviews candidate strategies to leverage data to improve real-time hybrid beamforming design. We discuss the architectural constraints and characterize the core challenges associated with hybrid beamforming optimization. We then present how these challenges are treated via conventional optimization, and identify different AI-aided design approaches. These can be roughly divided into purely data-driven deep learning models and different forms of deep unfolding techniques for combining AI with classical optimization.We provide a systematic comparative study between existing approaches including both numerical evaluations and qualitative measures. We conclude by presenting future research opportunities associated with the incorporation of AI in hybrid MIMO systems.", "published": "2023-03-03T06:04:20Z", "version": 1}, {"aid": "2303.01748", "authors": ["Kushagra Pandey", "Stephan Mandt"], "title": "A Complete Recipe for Diffusion Generative Models", "url": "http://arxiv.org/pdf/2303.01748v2", "summary": "Score-based Generative Models (SGMs) have demonstrated exceptional synthesis outcomes across various tasks. However, the current design landscape of the forward diffusion process remains largely untapped and often relies on physical heuristics or simplifying assumptions. Utilizing insights from the development of scalable Bayesian posterior samplers, we present a complete recipe for formulating forward processes in SGMs, ensuring convergence to the desired target distribution. Our approach reveals that several existing SGMs can be seen as specific manifestations of our framework. Building upon this method, we introduce Phase Space Langevin Diffusion (PSLD), which relies on score-based modeling within an augmented space enriched by auxiliary variables akin to physical phase space. Empirical results exhibit the superior sample quality and improved speed-quality trade-off of PSLD compared to various competing approaches on established image synthesis benchmarks. Remarkably, PSLD achieves sample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional CIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in conditional synthesis using pre-trained score networks, offering an appealing alternative as an SGM backbone for future advancements. Code and model checkpoints can be accessed at \\url{https://github.com/mandt-lab/PSLD}.", "published": "2023-03-03T07:20:58Z", "version": 2}, {"aid": "2303.01841", "authors": ["Edward De Brouwer", "Rahul G. Krishnan"], "title": "Anamnesic Neural Differential Equations with Orthogonal Polynomial Projections", "url": "http://arxiv.org/pdf/2303.01841v1", "summary": "Neural ordinary differential equations (Neural ODEs) are an effective framework for learning dynamical systems from irregularly sampled time series data. These models provide a continuous-time latent representation of the underlying dynamical system where new observations at arbitrary time points can be used to update the latent representation of the dynamical system. Existing parameterizations for the dynamics functions of Neural ODEs limit the ability of the model to retain global information about the time series; specifically, a piece-wise integration of the latent process between observations can result in a loss of memory on the dynamic patterns of previously observed data points. We propose PolyODE, a Neural ODE that models the latent continuous-time process as a projection onto a basis of orthogonal polynomials. This formulation enforces long-range memory and preserves a global representation of the underlying dynamical system. Our construction is backed by favourable theoretical guarantees and in a series of experiments, we demonstrate that it outperforms previous works in the reconstruction of past and future data, and in downstream prediction tasks.", "published": "2023-03-03T10:49:09Z", "version": 1}, {"aid": "2303.02045", "authors": ["Danruo Deng", "Guangyong Chen", "Yang Yu", "Furui Liu", "Pheng-Ann Heng"], "title": "Uncertainty Estimation by Fisher Information-based Evidential Deep Learning", "url": "http://arxiv.org/pdf/2303.02045v3", "summary": "Uncertainty estimation is a key factor that makes deep learning reliable in practical applications. Recently proposed evidential neural networks explicitly account for different uncertainties by treating the network's outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation. However, for high data uncertainty samples but annotated with the one-hot label, the evidence-learning process for those mislabeled classes is over-penalized and remains hindered. To address this problem, we propose a novel method, Fisher Information-based Evidential Deep Learning ($\\mathcal{I}$-EDL). In particular, we introduce Fisher Information Matrix (FIM) to measure the informativeness of evidence carried by each sample, according to which we can dynamically reweight the objective loss terms to make the network more focused on the representation learning of uncertain classes. The generalization ability of our network is further improved by optimizing the PAC-Bayesian bound. As demonstrated empirically, our proposed method consistently outperforms traditional EDL-related algorithms in multiple uncertainty estimation tasks, especially in the more challenging few-shot classification settings.", "published": "2023-03-03T16:12:59Z", "version": 3}, {"aid": "2303.02186", "authors": ["Jeroen Berrevoets", "Krzysztof Kacprzyk", "Zhaozhi Qian", "Mihaela van der Schaar"], "title": "Causal Deep Learning", "url": "http://arxiv.org/pdf/2303.02186v2", "summary": "Causality has the potential to truly transform the way we solve a large number of real-world problems. Yet, so far, its potential largely remains to be unlocked as causality often requires crucial assumptions which cannot be tested in practice. To address this challenge, we propose a new way of thinking about causality -- we call this causal deep learning. Our causal deep learning framework spans three dimensions: (1) a structural dimension, which incorporates partial yet testable causal knowledge rather than assuming either complete or no causal knowledge among the variables of interest; (2) a parametric dimension, which encompasses parametric forms that capture the type of relationships among the variables of interest; and (3) a temporal dimension, which captures exposure times or how the variables of interest interact (possibly causally) over time. Causal deep learning enables us to make progress on a variety of real-world problems by leveraging partial causal knowledge (including independencies among variables) and quantitatively characterising causal relationships among variables of interest (possibly over time). Our framework clearly identifies which assumptions are testable and which ones are not, such that the resulting solutions can be judiciously adopted in practice. Using our formulation we can combine or chain together causal representations to solve specific problems without losing track of which assumptions are required to build these solutions, pushing real-world impact in healthcare, economics and business, environmental sciences and education, through causal deep learning.", "published": "2023-03-03T19:19:18Z", "version": 2}, {"aid": "2303.02262", "authors": ["Avik Pal", "Alan Edelman", "Chris Rackauckas"], "title": "Locally Regularized Neural Differential Equations: Some Black Boxes Were Meant to Remain Closed!", "url": "http://arxiv.org/pdf/2303.02262v3", "summary": "Implicit layer deep learning techniques, like Neural Differential Equations, have become an important modeling framework due to their ability to adapt to new problems automatically. Training a neural differential equation is effectively a search over a space of plausible dynamical systems. However, controlling the computational cost for these models is difficult since it relies on the number of steps the adaptive solver takes. Most prior works have used higher-order methods to reduce prediction timings while greatly increasing training time or reducing both training and prediction timings by relying on specific training algorithms, which are harder to use as a drop-in replacement due to strict requirements on automatic differentiation. In this manuscript, we use internal cost heuristics of adaptive differential equation solvers at stochastic time points to guide the training toward learning a dynamical system that is easier to integrate. We \"close the black-box\" and allow the use of our method with any adjoint technique for gradient calculations of the differential equation solution. We perform experimental studies to compare our method to global regularization to show that we attain similar performance numbers without compromising the flexibility of implementation on ordinary differential equations (ODEs) and stochastic differential equations (SDEs). We develop two sampling strategies to trade off between performance and training time. Our method reduces the number of function evaluations to 0.556-0.733x and accelerates predictions by 1.3-2x.", "published": "2023-03-03T23:31:15Z", "version": 3}, {"aid": "2303.02328", "authors": ["Sangrok Lee", "Jongseong Bae", "Ha Young Kim"], "title": "Decompose, Adjust, Compose: Effective Normalization by Playing with Frequency for Domain Generalization", "url": "http://arxiv.org/pdf/2303.02328v3", "summary": "Domain generalization (DG) is a principal task to evaluate the robustness of computer vision models. Many previous studies have used normalization for DG. In normalization, statistics and normalized features are regarded as style and content, respectively. However, it has a content variation problem when removing style because the boundary between content and style is unclear. This study addresses this problem from the frequency domain perspective, where amplitude and phase are considered as style and content, respectively. First, we verify the quantitative phase variation of normalization through the mathematical derivation of the Fourier transform formula. Then, based on this, we propose a novel normalization method, PCNorm, which eliminates style only as the preserving content through spectral decomposition. Furthermore, we propose advanced PCNorm variants, CCNorm and SCNorm, which adjust the degrees of variations in content and style, respectively. Thus, they can learn domain-agnostic representations for DG. With the normalization methods, we propose ResNet-variant models, DAC-P and DAC-SC, which are robust to the domain gap. The proposed models outperform other recent DG methods. The DAC-SC achieves an average state-of-the-art performance of 65.6% on five datasets: PACS, VLCS, Office-Home, DomainNet, and TerraIncognita.", "published": "2023-03-04T05:23:11Z", "version": 3}, {"aid": "2303.02448", "authors": ["Wenqian Li", "Yinchuan Li", "Zhigang Li", "Jianye Hao", "Yan Pang"], "title": "DAG Matters! GFlowNets Enhanced Explainer For Graph Neural Networks", "url": "http://arxiv.org/pdf/2303.02448v1", "summary": "Uncovering rationales behind predictions of graph neural networks (GNNs) has received increasing attention over the years. Existing literature mainly focus on selecting a subgraph, through combinatorial optimization, to provide faithful explanations. However, the exponential size of candidate subgraphs limits the applicability of state-of-the-art methods to large-scale GNNs. We enhance on this through a different approach: by proposing a generative structure -- GFlowNets-based GNN Explainer (GFlowExplainer), we turn the optimization problem into a step-by-step generative problem. Our GFlowExplainer aims to learn a policy that generates a distribution of subgraphs for which the probability of a subgraph is proportional to its' reward. The proposed approach eliminates the influence of node sequence and thus does not need any pre-training strategies. We also propose a new cut vertex matrix to efficiently explore parent states for GFlowNets structure, thus making our approach applicable in a large-scale setting. We conduct extensive experiments on both synthetic and real datasets, and both qualitative and quantitative results show the superiority of our GFlowExplainer.", "published": "2023-03-04T16:15:25Z", "version": 1}, {"aid": "2303.02490", "authors": ["Binxu Wang", "John J. Vastola"], "title": "Diffusion Models Generate Images Like Painters: an Analytical Theory of Outline First, Details Later", "url": "http://arxiv.org/pdf/2303.02490v2", "summary": "How do diffusion generative models convert pure noise into meaningful images? In a variety of pretrained diffusion models (including conditional latent space models like Stable Diffusion), we observe that the reverse diffusion process that underlies image generation has the following properties: (i) individual trajectories tend to be low-dimensional and resemble 2D `rotations'; (ii) high-variance scene features like layout tend to emerge earlier, while low-variance details tend to emerge later; and (iii) early perturbations tend to have a greater impact on image content than later perturbations. To understand these phenomena, we derive and study a closed-form solution to the probability flow ODE for a Gaussian distribution, which shows that the reverse diffusion state rotates towards a gradually-specified target on the image manifold. It also shows that generation involves first committing to an outline, and then to finer and finer details. We find that this solution accurately describes the initial phase of image generation for pretrained models, and can in principle be used to make image generation more efficient by skipping reverse diffusion steps. Finally, we use our solution to characterize the image manifold in Stable Diffusion. Our viewpoint reveals an unexpected similarity between generation by GANs and diffusion and provides a conceptual link between diffusion and image retrieval.", "published": "2023-03-04T20:08:57Z", "version": 2}, {"aid": "2303.03887", "authors": ["Weili Zeng"], "title": "How to Construct Energy for Images? Denoising Autoencoder Can Be Energy Based Model", "url": "http://arxiv.org/pdf/2303.03887v1", "summary": "Energy-based models parameterize the unnormalized log-probability of data samples, but there is a lack of guidance on how to construct the \"energy\". In this paper, we propose a Denoising-EBM which decomposes the image energy into \"semantic energy\" and \"texture energy\". We define the \"semantic energy\" in the latent space of DAE to model the high-level representations, and define the pixel-level reconstruction error for denoising as \"texture energy\". Inspired by score-based model, our model utilizes multi-scale noisy samples for maximum-likelihood training and it outputs a vector instead of a scalar for exploring a larger set of functions during optimization. After training, the semantics are first synthesized by fast MCMC through \"semantic energy\", and then the pixel-level refinement of semantic image will be performed to generate perfect samples based on \"texture energy\". Ultimately, our model can outperform most EBMs in image generation. And we also demonstrate that Denoising-EBM has top performance among EBMs for out-of-distribution detection.", "published": "2023-03-05T05:35:55Z", "version": 1}, {"aid": "2303.02733", "authors": ["Alexander Detkov", "Mohammad Salameh", "Muhammad Fetrat Qharabagh", "Jialin Zhang", "Wei Lui", "Shangling Jui", "Di Niu"], "title": "Reparameterization through Spatial Gradient Scaling", "url": "http://arxiv.org/pdf/2303.02733v2", "summary": "Reparameterization aims to improve the generalization of deep neural networks by transforming convolutional layers into equivalent multi-branched structures during training. However, there exists a gap in understanding how reparameterization may change and benefit the learning process of neural networks. In this paper, we present a novel spatial gradient scaling method to redistribute learning focus among weights in convolutional networks. We prove that spatial gradient scaling achieves the same learning dynamics as a branched reparameterization yet without introducing structural changes into the network. We further propose an analytical approach that dynamically learns scalings for each convolutional layer based on the spatial characteristics of its input feature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100, and ImageNet show that without searching for reparameterized structures, our proposed scaling method outperforms the state-of-the-art reparameterization strategies at a lower computational cost.", "published": "2023-03-05T17:57:33Z", "version": 2}, {"aid": "2303.02165", "authors": ["Xuan Shen", "Yaohua Wang", "Ming Lin", "Yilun Huang", "Hao Tang", "Xiuyu Sun", "Yanzhi Wang"], "title": "DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural Network", "url": "http://arxiv.org/pdf/2303.02165v3", "summary": "The rapid advances in Vision Transformer (ViT) refresh the state-of-the-art performances in various vision tasks, overshadowing the conventional CNN-based models. This ignites a few recent striking-back research in the CNN world showing that pure CNN models can achieve as good performance as ViT models when carefully tuned. While encouraging, designing such high-performance CNN models is challenging, requiring non-trivial prior knowledge of network design. To this end, a novel framework termed Mathematical Architecture Design for Deep CNN (DeepMAD) is proposed to design high-performance CNN models in a principled way. In DeepMAD, a CNN network is modeled as an information processing system whose expressiveness and effectiveness can be analytically formulated by their structural parameters. Then a constrained mathematical programming (MP) problem is proposed to optimize these structural parameters. The MP problem can be easily solved by off-the-shelf MP solvers on CPUs with a small memory footprint. In addition, DeepMAD is a pure mathematical framework: no GPU or training data is required during network design. The superiority of DeepMAD is validated on multiple large-scale computer vision benchmark datasets. Notably on ImageNet-1k, only using conventional convolutional layers, DeepMAD achieves 0.7% and 1.5% higher top-1 accuracy than ConvNeXt and Swin on Tiny level, and 0.8% and 0.9% higher on Small level.", "published": "2023-03-05T21:31:49Z", "version": 3}, {"aid": "2303.03667", "authors": ["Jierun Chen", "Shiu-hong Kao", "Hao He", "Weipeng Zhuo", "Song Wen", "Chul-Ho Lee", "S. -H. Gary Chan"], "title": "Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks", "url": "http://arxiv.org/pdf/2303.03667v3", "summary": "To design fast neural networks, many works have been focusing on reducing the number of floating-point operations (FLOPs). We observe that such reduction in FLOPs, however, does not necessarily lead to a similar level of reduction in latency. This mainly stems from inefficiently low floating-point operations per second (FLOPS). To achieve faster networks, we revisit popular operators and demonstrate that such low FLOPS is mainly due to frequent memory access of the operators, especially the depthwise convolution. We hence propose a novel partial convolution (PConv) that extracts spatial features more efficiently, by cutting down redundant computation and memory access simultaneously. Building upon our PConv, we further propose FasterNet, a new family of neural networks, which attains substantially higher running speed than others on a wide range of devices, without compromising on accuracy for various vision tasks. For example, on ImageNet-1k, our tiny FasterNet-T0 is $2.8\\times$, $3.3\\times$, and $2.4\\times$ faster than MobileViT-XXS on GPU, CPU, and ARM processors, respectively, while being $2.9\\%$ more accurate. Our large FasterNet-L achieves impressive $83.5\\%$ top-1 accuracy, on par with the emerging Swin-B, while having $36\\%$ higher inference throughput on GPU, as well as saving $37\\%$ compute time on CPU. Code is available at \\url{https://github.com/JierunChen/FasterNet}.", "published": "2023-03-07T06:05:30Z", "version": 3}, {"aid": "2303.03758", "authors": ["Finn Behrendt", "Debayan Bhattacharya", "Julia Kr\u00fcger", "Roland Opfer", "Alexander Schlaefer"], "title": "Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI", "url": "http://arxiv.org/pdf/2303.03758v1", "summary": "The use of supervised deep learning techniques to detect pathologies in brain MRI scans can be challenging due to the diversity of brain anatomy and the need for annotated data sets. An alternative approach is to use unsupervised anomaly detection, which only requires sample-level labels of healthy brains to create a reference representation. This reference representation can then be compared to unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To accomplish this, generative models are needed to create anatomically consistent MRI scans of healthy brains. While recent diffusion models have shown promise in this task, accurately generating the complex structure of the human brain remains a challenge. In this paper, we propose a method that reformulates the generation task of diffusion models as a patch-based estimation of healthy brain anatomy, using spatial context to guide and improve reconstruction. We evaluate our approach on data of tumors and multiple sclerosis lesions and demonstrate a relative improvement of 25.1% compared to existing baselines.", "published": "2023-03-07T09:40:22Z", "version": 1}, {"aid": "2303.04001", "authors": ["Rodrigo Mello", "Filipe Calegario", "Geber Ramalho"], "title": "ELODIN: Naming Concepts in Embedding Spaces", "url": "http://arxiv.org/pdf/2303.04001v2", "summary": "Despite recent advancements, the field of text-to-image synthesis still suffers from lack of fine-grained control. Using only text, it remains challenging to deal with issues such as concept coherence and concept contamination. We propose a method to enhance control by generating specific concepts that can be reused throughout multiple images, effectively expanding natural language with new words that can be combined much like a painter's palette. Unlike previous contributions, our method does not copy visuals from input data and can generate concepts through text alone. We perform a set of comparisons that finds our method to be a significant improvement over text-only prompts.", "published": "2023-03-07T16:00:26Z", "version": 2}, {"aid": "2303.04336", "authors": ["Guillaume Berger", "Manik Dhingra", "Antoine Mercier", "Yashesh Savani", "Sunny Panchal", "Fatih Porikli"], "title": "QuickSRNet: Plain Single-Image Super-Resolution Architecture for Faster Inference on Mobile Platforms", "url": "http://arxiv.org/pdf/2303.04336v2", "summary": "In this work, we present QuickSRNet, an efficient super-resolution architecture for real-time applications on mobile platforms. Super-resolution clarifies, sharpens, and upscales an image to higher resolution. Applications such as gaming and video playback along with the ever-improving display capabilities of TVs, smartphones, and VR headsets are driving the need for efficient upscaling solutions. While existing deep learning-based super-resolution approaches achieve impressive results in terms of visual quality, enabling real-time DL-based super-resolution on mobile devices with compute, thermal, and power constraints is challenging. To address these challenges, we propose QuickSRNet, a simple yet effective architecture that provides better accuracy-to-latency trade-offs than existing neural architectures for single-image super resolution. We present training tricks to speed up existing residual-based super-resolution architectures while maintaining robustness to quantization. Our proposed architecture produces 1080p outputs via 2x upscaling in 2.2 ms on a modern smartphone, making it ideal for high-fps real-time applications.", "published": "2023-03-08T02:19:54Z", "version": 2}, {"aid": "2303.04571", "authors": ["Yang Yuan"], "title": "A Categorical Framework of General Intelligence", "url": "http://arxiv.org/pdf/2303.04571v2", "summary": "Can machines think? Since Alan Turing asked this question in 1950, nobody is able to give a direct answer, due to the lack of solid mathematical foundations for general intelligence. In this paper, we introduce a categorical framework towards this goal, with two main results. First, we investigate object representation through presheaves, introducing the notion of self-state awareness as a categorical analogue to self-consciousness, along with corresponding algorithms for its enforcement and evaluation. Secondly, we extend object representation to scenario representation using diagrams and limits, which then become building blocks for mathematical modeling, interpretability and AI safety. As an ancillary result, our framework introduces various categorical invariance properties that can serve as the alignment signals for model training.", "published": "2023-03-08T13:37:01Z", "version": 2}, {"aid": "2303.04589", "authors": ["Xiaoyu Ren", "Zhongying Deng", "Jin Ye", "Junjun He", "Dongxu Yang"], "title": "FCN+: Global Receptive Convolution Makes FCN Great Again", "url": "http://arxiv.org/pdf/2303.04589v2", "summary": "Fully convolutional network (FCN) is a seminal work for semantic segmentation. However, due to its limited receptive field, FCN cannot effectively capture global context information which is vital for semantic segmentation. As a result, it is beaten by state-of-the-art methods that leverage different filter sizes for larger receptive fields. However, such a strategy usually introduces more parameters and increases the computational cost. In this paper, we propose a novel global receptive convolution (GRC) to effectively increase the receptive field of FCN for context information extraction, which results in an improved FCN termed FCN+. The GRC provides the global receptive field for convolution without introducing any extra learnable parameters. The motivation of GRC is that different channels of a convolutional filter can have different grid sampling locations across the whole input feature map. Specifically, the GRC first divides the channels of the filter into two groups. The grid sampling locations of the first group are shifted to different spatial coordinates across the whole feature map, according to their channel indexes. This can help the convolutional filter capture the global context information. The grid sampling location of the second group remains unchanged to keep the original location information. By convolving using these two groups, the GRC can integrate the global context into the original location information of each pixel for better dense prediction results. With the GRC built in, FCN+ can achieve comparable performance to state-of-the-art methods for semantic segmentation tasks, as verified on PASCAL VOC 2012, Cityscapes, and ADE20K. Our code will be released at https://github.com/Zhongying-Deng/FCN_Plus.", "published": "2023-03-08T14:04:07Z", "version": 2}, {"aid": "2303.04923", "authors": ["Karthik Shetty", "Annette Birkhold", "Srikrishna Jaganathan", "Norbert Strobel", "Bernhard Egger", "Markus Kowarschik", "Andreas Maier"], "title": "BOSS: Bones, Organs and Skin Shape Model", "url": "http://arxiv.org/pdf/2303.04923v1", "summary": "Objective: A digital twin of a patient can be a valuable tool for enhancing clinical tasks such as workflow automation, patient-specific X-ray dose optimization, markerless tracking, positioning, and navigation assistance in image-guided interventions. However, it is crucial that the patient's surface and internal organs are of high quality for any pose and shape estimates. At present, the majority of statistical shape models (SSMs) are restricted to a small number of organs or bones or do not adequately represent the general population. Method: To address this, we propose a deformable human shape and pose model that combines skin, internal organs, and bones, learned from CT images. By modeling the statistical variations in a pose-normalized space using probabilistic PCA while also preserving joint kinematics, our approach offers a holistic representation of the body that can benefit various medical applications. Results: We assessed our model's performance on a registered dataset, utilizing the unified shape space, and noted an average error of 3.6 mm for bones and 8.8 mm for organs. To further verify our findings, we conducted additional tests on publicly available datasets with multi-part segmentations, which confirmed the effectiveness of our model. Conclusion: This works shows that anatomically parameterized statistical shape models can be created accurately and in a computationally efficient manner. Significance: The proposed approach enables the construction of shape models that can be directly applied to various medical applications, including biomechanics and reconstruction.", "published": "2023-03-08T22:31:24Z", "version": 1}, {"aid": "2303.04976", "authors": ["Umais Zahid", "Qinghai Guo", "Karl Friston", "Zafeirios Fountas"], "title": "Curvature-Sensitive Predictive Coding with Approximate Laplace Monte Carlo", "url": "http://arxiv.org/pdf/2303.04976v1", "summary": "Predictive coding (PC) accounts of perception now form one of the dominant computational theories of the brain, where they prescribe a general algorithm for inference and learning over hierarchical latent probabilistic models. Despite this, they have enjoyed little export to the broader field of machine learning, where comparative generative modelling techniques have flourished. In part, this has been due to the poor performance of models trained with PC when evaluated by both sample quality and marginal likelihood. By adopting the perspective of PC as a variational Bayes algorithm under the Laplace approximation, we identify the source of these deficits to lie in the exclusion of an associated Hessian term in the PC objective function, which would otherwise regularise the sharpness of the probability landscape and prevent over-certainty in the approximate posterior. To remedy this, we make three primary contributions: we begin by suggesting a simple Monte Carlo estimated evidence lower bound which relies on sampling from the Hessian-parameterised variational posterior. We then derive a novel block diagonal approximation to the full Hessian matrix that has lower memory requirements and favourable mathematical properties. Lastly, we present an algorithm that combines our method with standard PC to reduce memory complexity further. We evaluate models trained with our approach against the standard PC framework on image benchmark datasets. Our approach produces higher log-likelihoods and qualitatively better samples that more closely capture the diversity of the data-generating distribution.", "published": "2023-03-09T01:29:58Z", "version": 1}, {"aid": "2303.05125", "authors": ["Zhiheng Liu", "Ruili Feng", "Kai Zhu", "Yifei Zhang", "Kecheng Zheng", "Yu Liu", "Deli Zhao", "Jingren Zhou", "Yang Cao"], "title": "Cones: Concept Neurons in Diffusion Models for Customized Generation", "url": "http://arxiv.org/pdf/2303.05125v1", "summary": "Human brains respond to semantic features of presented stimuli with different neurons. It is then curious whether modern deep neural networks admit a similar behavior pattern. Specifically, this paper finds a small cluster of neurons in a diffusion model corresponding to a particular subject. We call those neurons the concept neurons. They can be identified by statistics of network gradients to a stimulation connected with the given subject. The concept neurons demonstrate magnetic properties in interpreting and manipulating generation results. Shutting them can directly yield the related subject contextualized in different scenes. Concatenating multiple clusters of concept neurons can vividly generate all related concepts in a single image. A few steps of further fine-tuning can enhance the multi-concept capability, which may be the first to manage to generate up to four different subjects in a single image. For large-scale applications, the concept neurons are environmentally friendly as we only need to store a sparse cluster of int index instead of dense float32 values of the parameters, which reduces storage consumption by 90\\% compared with previous subject-driven generation methods. Extensive qualitative and quantitative studies on diverse scenarios show the superiority of our method in interpreting and manipulating diffusion models.", "published": "2023-03-09T09:16:04Z", "version": 1}, {"aid": "2303.05848", "authors": ["Thom Badings", "Thiago D. Sim\u00e3o", "Marnix Suilen", "Nils Jansen"], "title": "Decision-Making Under Uncertainty: Beyond Probabilities", "url": "http://arxiv.org/pdf/2303.05848v1", "summary": "This position paper reflects on the state-of-the-art in decision-making under uncertainty. A classical assumption is that probabilities can sufficiently capture all uncertainty in a system. In this paper, the focus is on the uncertainty that goes beyond this classical interpretation, particularly by employing a clear distinction between aleatoric and epistemic uncertainty. The paper features an overview of Markov decision processes (MDPs) and extensions to account for partial observability and adversarial behavior. These models sufficiently capture aleatoric uncertainty but fail to account for epistemic uncertainty robustly. Consequently, we present a thorough overview of so-called uncertainty models that exhibit uncertainty in a more robust interpretation. We show several solution techniques for both discrete and continuous models, ranging from formal verification, over control-based abstractions, to reinforcement learning. As an integral part of this paper, we list and discuss several key challenges that arise when dealing with rich types of uncertainty in a model-based fashion.", "published": "2023-03-10T10:53:33Z", "version": 1}, {"aid": "2303.06164", "authors": ["Bryan Lim", "Manon Flageat", "Antoine Cully"], "title": "Understanding the Synergies between Quality-Diversity and Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/2303.06164v1", "summary": "The synergies between Quality-Diversity (QD) and Deep Reinforcement Learning (RL) have led to powerful hybrid QD-RL algorithms that have shown tremendous potential, and brings the best of both fields. However, only a single deep RL algorithm (TD3) has been used in prior hybrid methods despite notable progress made by other RL algorithms. Additionally, there are fundamental differences in the optimization procedures between QD and RL which would benefit from a more principled approach. We propose Generalized Actor-Critic QD-RL, a unified modular framework for actor-critic deep RL methods in the QD-RL setting. This framework provides a path to study insights from Deep RL in the QD-RL setting, which is an important and efficient way to make progress in QD-RL. We introduce two new algorithms, PGA-ME (SAC) and PGA-ME (DroQ) which apply recent advancements in Deep RL to the QD-RL setting, and solves the humanoid environment which was not possible using existing QD-RL algorithms. However, we also find that not all insights from Deep RL can be effectively translated to QD-RL. Critically, this work also demonstrates that the actor-critic models in QD-RL are generally insufficiently trained and performance gains can be achieved without any additional environment evaluations.", "published": "2023-03-10T19:02:42Z", "version": 1}, {"aid": "2303.06173", "authors": ["Xander Davies", "Lauro Langosco", "David Krueger"], "title": "Unifying Grokking and Double Descent", "url": "http://arxiv.org/pdf/2303.06173v1", "summary": "A principled understanding of generalization in deep learning may require unifying disparate observations under a single conceptual framework. Previous work has studied \\emph{grokking}, a training dynamic in which a sustained period of near-perfect training performance and near-chance test performance is eventually followed by generalization, as well as the superficially similar \\emph{double descent}. These topics have so far been studied in isolation. We hypothesize that grokking and double descent can be understood as instances of the same learning dynamics within a framework of pattern learning speeds. We propose that this framework also applies when varying model capacity instead of optimization steps, and provide the first demonstration of model-wise grokking.", "published": "2023-03-10T19:16:53Z", "version": 1}, {"aid": "2303.08080", "authors": ["Shimon Edelman"], "title": "Verbal behavior without syntactic structures: beyond Skinner and Chomsky", "url": "http://arxiv.org/pdf/2303.08080v1", "summary": "What does it mean to know language? Since the Chomskian revolution, one popular answer to this question has been: to possess a generative grammar that exclusively licenses certain syntactic structures. Decades later, not even an approximation to such a grammar, for any language, has been formulated; the idea that grammar is universal and innately specified has proved barren; and attempts to show how it could be learned from experience invariably come up short. To move on from this impasse, we must rediscover the extent to which language is like any other human behavior: dynamic, social, multimodal, patterned, and purposive, its purpose being to promote desirable actions (or thoughts) in others and self. Recent psychological, computational, neurobiological, and evolutionary insights into the shaping and structure of behavior may then point us toward a new, viable account of language.", "published": "2023-03-11T00:01:21Z", "version": 1}, {"aid": "2303.06298", "authors": ["Samir Mitha", "Seungho Choe", "Pejman Jahbedar Maralani", "Alan R. Moody", "April Khademi"], "title": "MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer", "url": "http://arxiv.org/pdf/2303.06298v1", "summary": "We propose a novel architecture called MLP-SRGAN, which is a single-dimension Super Resolution Generative Adversarial Network (SRGAN) that utilizes Multi-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to upsample in the slice direction. MLP-SRGAN is trained and validated using high resolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was applied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with low spatial resolution in the slice dimension to examine performance on held-out (unseen) clinical data. Upsampled results are compared to several state-of-the-art SR networks. For images with high resolution (HR) ground truths, peak-signal-to-noise-ratio (PSNR) and structural similarity index (SSIM) are used to measure upsampling performance. Several new structural, no-reference image quality metrics were proposed to quantify sharpness (edge strength), noise (entropy), and blurriness (low frequency information) in the absence of ground truths. Results show MLP-SRGAN results in sharper edges, less blurring, preserves more texture and fine-anatomical detail, with fewer parameters, faster training/evaluation time, and smaller model size than existing methods. Code for MLP-SRGAN training and inference, data generators, models and no-reference image quality metrics will be available at https://github.com/IAMLAB-Ryerson/MLP-SRGAN.", "published": "2023-03-11T04:05:57Z", "version": 1}, {"aid": "2303.06869", "authors": ["Biao Qian", "Yang Wang", "Richang Hong", "Meng Wang"], "title": "Adaptive Data-Free Quantization", "url": "http://arxiv.org/pdf/2303.06869v3", "summary": "Data-free quantization (DFQ) recovers the performance of quantized network (Q) without the original data, but generates the fake sample via a generator (G) by learning from full-precision network (P), which, however, is totally independent of Q, overlooking the adaptability of the knowledge from generated samples, i.e., informative or not to the learning process of Q, resulting into the overflow of generalization error. Building on this, several critical questions -- how to measure the sample adaptability to Q under varied bit-width scenarios? whether the largest adaptability is the best? how to generate the samples with adaptive adaptability to improve Q's generalization? To answer the above questions, in this paper, we propose an Adaptive Data-Free Quantization (AdaDFQ) method, which revisits DFQ from a zero-sum game perspective upon the sample adaptability between two players -- a generator and a quantized network. Following this viewpoint, we further define the disagreement and agreement samples to form two boundaries, where the margin is optimized to adaptively regulate the adaptability of generated samples to Q, so as to address the over-and-under fitting issues. Our AdaDFQ reveals: 1) the largest adaptability is NOT the best for sample generation to benefit Q's generalization; 2) the knowledge of the generated sample should not be informative to Q only, but also related to the category and distribution information of the training data for P. The theoretical and empirical analysis validate the advantages of AdaDFQ over the state-of-the-arts. Our code is available at https://github.com/hfutqian/AdaDFQ.", "published": "2023-03-13T05:37:40Z", "version": 3}, {"aid": "2303.07402", "authors": ["Zhinan Qiao", "Xiaohui Yuan"], "title": "Designing Deep Networks for Scene Recognition", "url": "http://arxiv.org/pdf/2303.07402v1", "summary": "Most deep learning backbones are evaluated on ImageNet. Using scenery images as an example, we conducted extensive experiments to demonstrate the widely accepted principles in network design may result in dramatic performance differences when the data is altered. Exploratory experiments are engaged to explain the underlining cause of the differences. Based on our observation, this paper presents a novel network design methodology: data-oriented network design. In other words, instead of designing universal backbones, the scheming of the networks should treat the characteristics of data as a crucial component. We further proposed a Deep-Narrow Network and Dilated Pooling module, which improved the scene recognition performance using less than half of the computational resources compared to the benchmark network architecture ResNets. The source code is publicly available on https://github.com/ZN-Qiao/Deep-Narrow-Network.", "published": "2023-03-13T18:28:06Z", "version": 1}, {"aid": "2303.07507", "authors": ["Zaheer Abbas", "Rosie Zhao", "Joseph Modayil", "Adam White", "Marlos C. Machado"], "title": "Loss of Plasticity in Continual Deep Reinforcement Learning", "url": "http://arxiv.org/pdf/2303.07507v1", "summary": "The ability to learn continually is essential in a complex and changing world. In this paper, we characterize the behavior of canonical value-based deep reinforcement learning (RL) approaches under varying degrees of non-stationarity. In particular, we demonstrate that deep RL agents lose their ability to learn good policies when they cycle through a sequence of Atari 2600 games. This phenomenon is alluded to in prior work under various guises -- e.g., loss of plasticity, implicit under-parameterization, primacy bias, and capacity loss. We investigate this phenomenon closely at scale and analyze how the weights, gradients, and activations change over time in several experiments with varying dimensions (e.g., similarity between games, number of games, number of frames per game), with some experiments spanning 50 days and 2 billion environment interactions. Our analysis shows that the activation footprint of the network becomes sparser, contributing to the diminishing gradients. We investigate a remarkably simple mitigation strategy -- Concatenated ReLUs (CReLUs) activation function -- and demonstrate its effectiveness in facilitating continual learning in a changing environment.", "published": "2023-03-13T22:37:15Z", "version": 1}, {"aid": "2303.07677", "authors": ["Hui Tang", "Yao Lu", "Qi Xuan"], "title": "SR-init: An interpretable layer pruning method", "url": "http://arxiv.org/pdf/2303.07677v2", "summary": "Despite the popularization of deep neural networks (DNNs) in many fields, it is still challenging to deploy state-of-the-art models to resource-constrained devices due to high computational overhead. Model pruning provides a feasible solution to the aforementioned challenges. However, the interpretation of existing pruning criteria is always overlooked. To counter this issue, we propose a novel layer pruning method by exploring the Stochastic Re-initialization. Our SR-init method is inspired by the discovery that the accuracy drop due to stochastic re-initialization of layer parameters differs in various layers. On the basis of this observation, we come up with a layer pruning criterion, i.e., those layers that are not sensitive to stochastic re-initialization (low accuracy drop) produce less contribution to the model and could be pruned with acceptable loss. Afterward, we experimentally verify the interpretability of SR-init via feature visualization. The visual explanation demonstrates that SR-init is theoretically feasible, thus we compare it with state-of-the-art methods to further evaluate its practicability. As for ResNet56 on CIFAR-10 and CIFAR-100, SR-init achieves a great reduction in parameters (63.98% and 37.71%) with an ignorable drop in top-1 accuracy (-0.56% and 0.8%). With ResNet50 on ImageNet, we achieve a 15.59% FLOPs reduction by removing 39.29% of the parameters, with only a drop of 0.6% in top-1 accuracy. Our code is available at https://github.com/huitang-zjut/SR-init.", "published": "2023-03-14T07:26:55Z", "version": 2}, {"aid": "2303.07683", "authors": ["Javier D\u00edaz", "Hiroyasu Ando", "GoEun Han", "Olga Malyshevskaya", "Xifang Hayashi", "Juan-Carlos Letelier", "Masashi Yanagisawa", "Kaspar E. Vogt"], "title": "Recovering Arrhythmic EEG Transients from Their Stochastic Interference", "url": "http://arxiv.org/pdf/2303.07683v1", "summary": "Traditionally, the neuronal dynamics underlying electroencephalograms (EEG) have been understood as arising from \\textit{rhythmic oscillators with varying degrees of synchronization}. This dominant metaphor employs frequency domain EEG analysis to identify the most prominent populations of neuronal current sources in terms of their frequency and spectral power. However, emerging perspectives on EEG highlight its arrhythmic nature, which is primarily inferred from broadband EEG properties like the ubiquitous $1/f$ spectrum. In the present study, we use an \\textit{arrhythmic superposition of pulses} as a metaphor to explain the origin of EEG. This conceptualization has a fundamental problem because the interference produced by the superpositions of pulses generates colored Gaussian noise, masking the temporal profile of the generating pulse. We solved this problem by developing a mathematical method involving the derivative of the autocovariance function to recover excellent approximations of the underlying pulses, significantly extending the analysis of this type of stochastic processes. When the method is applied to spontaneous mouse EEG sampled at $5$ kHz during the sleep-wake cycle, specific patterns -- called $\\Psi$-patterns -- characterizing NREM sleep, REM sleep, and wakefulness are revealed. $\\Psi$-patterns can be understood theoretically as \\textit{power density in the time domain} and correspond to combinations of generating pulses at different time scales. Remarkably, we report the first EEG wakefulness-specific feature, which corresponds to an ultra-fast ($\\sim 1$ ms) transient component of the observed patterns. By shifting the paradigm of EEG genesis from oscillators to random pulse generators, our theoretical framework pushes the boundaries of traditional Fourier-based EEG analysis, paving the way for new insights into the arrhythmic components of neural dynamics.", "published": "2023-03-14T07:53:28Z", "version": 1}, {"aid": "2303.07820", "authors": ["Yifan Pu", "Yiru Wang", "Zhuofan Xia", "Yizeng Han", "Yulin Wang", "Weihao Gan", "Zidong Wang", "Shiji Song", "Gao Huang"], "title": "Adaptive Rotated Convolution for Rotated Object Detection", "url": "http://arxiv.org/pdf/2303.07820v2", "summary": "Rotated object detection aims to identify and locate objects in images with arbitrary orientation. In this scenario, the oriented directions of objects vary considerably across different images, while multiple orientations of objects exist within an image. This intrinsic characteristic makes it challenging for standard backbone networks to extract high-quality features of these arbitrarily orientated objects. In this paper, we present Adaptive Rotated Convolution (ARC) module to handle the aforementioned challenges. In our ARC module, the convolution kernels rotate adaptively to extract object features with varying orientations in different images, and an efficient conditional computation mechanism is introduced to accommodate the large orientation variations of objects within an image. The two designs work seamlessly in rotated object detection problem. Moreover, ARC can conveniently serve as a plug-and-play module in various vision backbones to boost their representation ability to detect oriented objects accurately. Experiments on commonly used benchmarks (DOTA and HRSC2016) demonstrate that equipped with our proposed ARC module in the backbone network, the performance of multiple popular oriented object detectors is significantly improved (\\eg +3.03\\% mAP on Rotated RetinaNet and +4.16\\% on CFA). Combined with the highly competitive method Oriented R-CNN, the proposed approach achieves state-of-the-art performance on the DOTA dataset with 81.77\\% mAP. Code is available at \\url{https://github.com/LeapLabTHU/ARC}.", "published": "2023-03-14T11:53:12Z", "version": 2}, {"aid": "2303.08063", "authors": ["Weiyang Jin", "Yongpei Zhu", "Yuxi Peng"], "title": "Interpretable ODE-style Generative Diffusion Model via Force Field Construction", "url": "http://arxiv.org/pdf/2303.08063v3", "summary": "For a considerable time, researchers have focused on developing a method that establishes a deep connection between the generative diffusion model and mathematical physics. Despite previous efforts, progress has been limited to the pursuit of a single specialized method. In order to advance the interpretability of diffusion models and explore new research directions, it is essential to establish a unified ODE-style generative diffusion model. Such a model should draw inspiration from physical models and possess a clear geometric meaning. This paper aims to identify various physical models that are suitable for constructing ODE-style generative diffusion models accurately from a mathematical perspective. We then summarize these models into a unified method. Additionally, we perform a case study where we use the theoretical model identified by our method to develop a range of new diffusion model methods, and conduct experiments. Our experiments on CIFAR-10 demonstrate the effectiveness of our approach. We have constructed a computational framework that attains highly proficient results with regards to image generation speed, alongside an additional model that demonstrates exceptional performance in both Inception score and FID score. These results underscore the significance of our method in advancing the field of diffusion models.", "published": "2023-03-14T16:58:11Z", "version": 3}, {"aid": "2303.08085", "authors": ["Hagay Michaeli", "Tomer Michaeli", "Daniel Soudry"], "title": "Alias-Free Convnets: Fractional Shift Invariance via Polynomial Activations", "url": "http://arxiv.org/pdf/2303.08085v2", "summary": "Although CNNs are believed to be invariant to translations, recent works have shown this is not the case, due to aliasing effects that stem from downsampling layers. The existing architectural solutions to prevent aliasing are partial since they do not solve these effects, that originate in non-linearities. We propose an extended anti-aliasing method that tackles both downsampling and non-linear layers, thus creating truly alias-free, shift-invariant CNNs. We show that the presented model is invariant to integer as well as fractional (i.e., sub-pixel) translations, thus outperforming other shift-invariant methods in terms of robustness to adversarial translations.", "published": "2023-03-14T17:16:16Z", "version": 2}, {"aid": "2303.08133", "authors": ["Zhen Liu", "Yao Feng", "Michael J. Black", "Derek Nowrouzezahrai", "Liam Paull", "Weiyang Liu"], "title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling", "url": "http://arxiv.org/pdf/2303.08133v2", "summary": "We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectiveness of our model on multiple generative tasks.", "published": "2023-03-14T17:59:01Z", "version": 2}, {"aid": "2303.08134", "authors": ["Renrui Zhang", "Liuhui Wang", "Ziyu Guo", "Yali Wang", "Peng Gao", "Hongsheng Li", "Jianbo Shi"], "title": "Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis", "url": "http://arxiv.org/pdf/2303.08134v2", "summary": "We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions. Surprisingly, it performs well on various 3D tasks, requiring no parameters or training, and even surpasses existing fully trained models. Starting from this basic non-parametric model, we propose two extensions. First, Point-NN can serve as a base architectural framework to construct Parametric Networks by simply inserting linear layers on top. Given the superior non-parametric foundation, the derived Point-PN exhibits a high performance-efficiency trade-off with only a few learnable parameters. Second, Point-NN can be regarded as a plug-and-play module for the already trained 3D models during inference. Point-NN captures the complementary geometric knowledge and enhances existing methods for different 3D benchmarks without re-training. We hope our work may cast a light on the community for understanding 3D point clouds with non-parametric methods. Code is available at https://github.com/ZrrSkywalker/Point-NN.", "published": "2023-03-14T17:59:02Z", "version": 2}, {"aid": "2303.08320", "authors": ["Zhengxiong Luo", "Dayou Chen", "Yingya Zhang", "Yan Huang", "Liang Wang", "Yujun Shen", "Deli Zhao", "Jingren Zhou", "Tieniu Tan"], "title": "VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation", "url": "http://arxiv.org/pdf/2303.08320v4", "summary": "A diffusion probabilistic model (DPM), which constructs a forward diffusion process by gradually adding noise to data points and learns the reverse denoising process to generate new samples, has been shown to handle complex data distribution. Despite its recent success in image synthesis, applying DPMs to video generation is still challenging due to high-dimensional data spaces. Previous methods usually adopt a standard diffusion process, where frames in the same video clip are destroyed with independent noises, ignoring the content redundancy and temporal correlation. This work presents a decomposed diffusion process via resolving the per-frame noise into a base noise that is shared among all frames and a residual noise that varies along the time axis. The denoising pipeline employs two jointly-learned networks to match the noise decomposition accordingly. Experiments on various datasets confirm that our approach, termed as VideoFusion, surpasses both GAN-based and diffusion-based alternatives in high-quality video generation. We further show that our decomposed formulation can benefit from pre-trained image diffusion models and well-support text-conditioned video creation.", "published": "2023-03-15T02:16:39Z", "version": 4}, {"aid": "2303.08496", "authors": ["Jorge Vila-Tom\u00e1s", "Pablo Hern\u00e1ndez-C\u00e1mara", "Jes\u00fas Malo"], "title": "Psychophysics of Artificial Neural Networks Questions Classical Hue Cancellation Experiments", "url": "http://arxiv.org/pdf/2303.08496v2", "summary": "We show that classical hue cancellation experiments lead to human-like opponent curves even if the task is done by trivial (identity) artificial networks. Specifically, human-like opponent spectral sensitivities always emerge in artificial networks as long as (i) the retina converts the input radiation into any tristimulus-like representation, and (ii) the post-retinal network solves the standard hue cancellation task, e.g. the network looks for the weights of the cancelling lights so that every monochromatic stimulus plus the weighted cancelling lights match a grey reference in the (arbitrary) color representation used by the network. In fact, the specific cancellation lights (and not the network architecture) are key to obtain human-like curves: results show that the classical choice of the lights is the one that leads to the best (more human-like) result, and any other choices lead to progressively different spectral sensitivities. We show this in two ways: through artificial psychophysics using a range of networks with different architectures and a range of cancellation lights, and through a change-of-basis theoretical analogy of the experiments. This suggests that the opponent curves of the classical experiment are just a by-product of the front-end photoreceptors and of a very specific experimental choice but they do not inform about the downstream color representation. In fact, the architecture of the post-retinal network (signal recombination or internal color space) seems irrelevant for the emergence of the curves in the classical experiment. This result in artificial networks questions the conventional interpretation of the classical result in humans by Jameson and Hurvich.", "published": "2023-03-15T10:13:34Z", "version": 2}, {"aid": "2303.08714", "authors": ["Shuyao Shang", "Zhengyang Shan", "Guangxing Liu", "LunQian Wang", "XingHua Wang", "Zekai Zhang", "Jinglin Zhang"], "title": "ResDiff: Combining CNN and Diffusion Model for Image Super-Resolution", "url": "http://arxiv.org/pdf/2303.08714v3", "summary": "Adapting the Diffusion Probabilistic Model (DPM) for direct image super-resolution is wasteful, given that a simple Convolutional Neural Network (CNN) can recover the main low-frequency content. Therefore, we present ResDiff, a novel Diffusion Probabilistic Model based on Residual structure for Single Image Super-Resolution (SISR). ResDiff utilizes a combination of a CNN, which restores primary low-frequency components, and a DPM, which predicts the residual between the ground-truth image and the CNN predicted image. In contrast to the common diffusion-based methods that directly use LR images to guide the noise towards HR space, ResDiff utilizes the CNN's initial prediction to direct the noise towards the residual space between HR space and CNN-predicted space, which not only accelerates the generation process but also acquires superior sample quality. Additionally, a frequency-domain-based loss function for CNN is introduced to facilitate its restoration, and a frequency-domain guided diffusion is designed for DPM on behalf of predicting high-frequency details. The extensive experiments on multiple benchmark datasets demonstrate that ResDiff outperforms previous diffusion based methods in terms of shorter model convergence time, superior generation quality, and more diverse samples.", "published": "2023-03-15T15:50:11Z", "version": 3}, {"aid": "2303.09295", "authors": ["Zhendong Wang", "Jianmin Bao", "Wengang Zhou", "Weilun Wang", "Hezhen Hu", "Hong Chen", "Houqiang Li"], "title": "DIRE for Diffusion-Generated Image Detection", "url": "http://arxiv.org/pdf/2303.09295v1", "summary": "Diffusion models have shown remarkable success in visual synthesis, but have also raised concerns about potential abuse for malicious purposes. In this paper, we seek to build a detector for telling apart real images from diffusion-generated images. We find that existing detectors struggle to detect images generated by diffusion models, even if we include generated images from a specific diffusion model in their training data. To address this issue, we propose a novel image representation called DIffusion Reconstruction Error (DIRE), which measures the error between an input image and its reconstruction counterpart by a pre-trained diffusion model. We observe that diffusion-generated images can be approximately reconstructed by a diffusion model while real images cannot. It provides a hint that DIRE can serve as a bridge to distinguish generated and real images. DIRE provides an effective way to detect images generated by most diffusion models, and it is general for detecting generated images from unseen diffusion models and robust to various perturbations. Furthermore, we establish a comprehensive diffusion-generated benchmark including images generated by eight diffusion models to evaluate the performance of diffusion-generated image detectors. Extensive experiments on our collected benchmark demonstrate that DIRE exhibits superiority over previous generated-image detectors. The code and dataset are available at https://github.com/ZhendongWang6/DIRE.", "published": "2023-03-16T13:15:03Z", "version": 1}, {"aid": "2303.09556", "authors": ["Tiankai Hang", "Shuyang Gu", "Chen Li", "Jianmin Bao", "Dong Chen", "Han Hu", "Xin Geng", "Baining Guo"], "title": "Efficient Diffusion Training via Min-SNR Weighting Strategy", "url": "http://arxiv.org/pdf/2303.09556v3", "summary": "Denoising diffusion models have been a mainstream approach for image generation, however, training these models often suffers from slow convergence. In this paper, we discovered that the slow convergence is partly due to conflicting optimization directions between timesteps. To address this issue, we treat the diffusion training as a multi-task learning problem, and introduce a simple yet effective approach referred to as Min-SNR-$\\gamma$. This method adapts loss weights of timesteps based on clamped signal-to-noise ratios, which effectively balances the conflicts among timesteps. Our results demonstrate a significant improvement in converging speed, 3.4$\\times$ faster than previous weighting strategies. It is also more effective, achieving a new record FID score of 2.06 on the ImageNet $256\\times256$ benchmark using smaller architectures than that employed in previous state-of-the-art. The code is available at https://github.com/TiankaiHang/Min-SNR-Diffusion-Training.", "published": "2023-03-16T17:59:56Z", "version": 3}, {"aid": "2303.11934", "authors": ["Trenton Bricken", "Xander Davies", "Deepak Singh", "Dmitry Krotov", "Gabriel Kreiman"], "title": "Sparse Distributed Memory is a Continual Learner", "url": "http://arxiv.org/pdf/2303.11934v1", "summary": "Continual learning is a problem for artificial neural networks that their biological counterparts are adept at solving. Building on work using Sparse Distributed Memory (SDM) to connect a core neural circuit with the powerful Transformer model, we create a modified Multi-Layered Perceptron (MLP) that is a strong continual learner. We find that every component of our MLP variant translated from biology is necessary for continual learning. Our solution is also free from any memory replay or task information, and introduces novel methods to train sparse networks that may be broadly applicable.", "published": "2023-03-20T16:54:10Z", "version": 1}, {"aid": "2303.11435", "authors": ["Mauricio Delbracio", "Peyman Milanfar"], "title": "Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration", "url": "http://arxiv.org/pdf/2303.11435v5", "summary": "Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called \"regression to the mean\" effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models. Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality. While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising.", "published": "2023-03-20T20:28:17Z", "version": 5}, {"aid": "2303.13750", "authors": ["Qian Tao", "Zhen Wang", "Wenyuan Yu", "Yaliang Li", "Zhewei Wei"], "title": "LON-GNN: Spectral GNNs with Learnable Orthonormal Basis", "url": "http://arxiv.org/pdf/2303.13750v2", "summary": "In recent years, a plethora of spectral graph neural networks (GNN) methods have utilized polynomial basis with learnable coefficients to achieve top-tier performances on many node-level tasks. Although various kinds of polynomial bases have been explored, each such method adopts a fixed polynomial basis which might not be the optimal choice for the given graph. Besides, we identify the so-called over-passing issue of these methods and show that it is somewhat rooted in their less-principled regularization strategy and unnormalized basis. In this paper, we make the first attempts to address these two issues. Leveraging Jacobi polynomials, we design a novel spectral GNN, LON-GNN, with Learnable OrthoNormal bases and prove that regularizing coefficients becomes equivalent to regularizing the norm of learned filter function now. We conduct extensive experiments on diverse graph datasets to evaluate the fitting and generalization capability of LON-GNN, where the results imply its superiority.", "published": "2023-03-24T02:07:46Z", "version": 2}, {"aid": "2303.13826", "authors": ["Huantong Li", "Xiangmiao Wu", "Fanbing Lv", "Daihai Liao", "Thomas H. Li", "Yonggang Zhang", "Bo Han", "Mingkui Tan"], "title": "Hard Sample Matters a Lot in Zero-Shot Quantization", "url": "http://arxiv.org/pdf/2303.13826v1", "summary": "Zero-shot quantization (ZSQ) is promising for compressing and accelerating deep neural networks when the data for training full-precision models are inaccessible. In ZSQ, network quantization is performed using synthetic samples, thus, the performance of quantized models depends heavily on the quality of synthetic samples. Nonetheless, we find that the synthetic samples constructed in existing ZSQ methods can be easily fitted by models. Accordingly, quantized models obtained by these methods suffer from significant performance degradation on hard samples. To address this issue, we propose HArd sample Synthesizing and Training (HAST). Specifically, HAST pays more attention to hard samples when synthesizing samples and makes synthetic samples hard to fit when training quantized models. HAST aligns features extracted by full-precision and quantized models to ensure the similarity between features extracted by these two models. Extensive experiments show that HAST significantly outperforms existing ZSQ methods, achieving performance comparable to models that are quantized with real data.", "published": "2023-03-24T06:22:57Z", "version": 1}, {"aid": "2303.13896", "authors": ["Grigorios G Chrysos", "Bohan Wang", "Jiankang Deng", "Volkan Cevher"], "title": "Regularization of polynomial networks for image recognition", "url": "http://arxiv.org/pdf/2303.13896v1", "summary": "Deep Neural Networks (DNNs) have obtained impressive performance across tasks, however they still remain as black boxes, e.g., hard to theoretically analyze. At the same time, Polynomial Networks (PNs) have emerged as an alternative method with a promising performance and improved interpretability but have yet to reach the performance of the powerful DNN baselines. In this work, we aim to close this performance gap. We introduce a class of PNs, which are able to reach the performance of ResNet across a range of six benchmarks. We demonstrate that strong regularization is critical and conduct an extensive study of the exact regularization schemes required to match performance. To further motivate the regularization schemes, we introduce D-PolyNets that achieve a higher-degree of expansion than previously proposed polynomial networks. D-PolyNets are more parameter-efficient while achieving a similar performance as other polynomial networks. We expect that our new models can lead to an understanding of the role of elementwise activation functions (which are no longer required for training PNs). The source code is available at https://github.com/grigorisg9gr/regularized_polynomials.", "published": "2023-03-24T10:05:22Z", "version": 1}, {"aid": "2303.14341", "authors": ["Yifu Ding", "Haotong Qin", "Qinghua Yan", "Zhenhua Chai", "Junjie Liu", "Xiaolin Wei", "Xianglong Liu"], "title": "Towards Accurate Post-Training Quantization for Vision Transformer", "url": "http://arxiv.org/pdf/2303.14341v1", "summary": "Vision transformer emerges as a potential architecture for vision tasks. However, the intense computation and non-negligible delay hinder its application in the real world. As a widespread model compression technique, existing post-training quantization methods still cause severe performance drops. We find the main reasons lie in (1) the existing calibration metric is inaccurate in measuring the quantization influence for extremely low-bit representation, and (2) the existing quantization paradigm is unfriendly to the power-law distribution of Softmax. Based on these observations, we propose a novel Accurate Post-training Quantization framework for Vision Transformer, namely APQ-ViT. We first present a unified Bottom-elimination Blockwise Calibration scheme to optimize the calibration metric to perceive the overall quantization disturbance in a blockwise manner and prioritize the crucial quantization errors that influence more on the final output. Then, we design a Matthew-effect Preserving Quantization for Softmax to maintain the power-law character and keep the function of the attention mechanism. Comprehensive experiments on large-scale classification and detection datasets demonstrate that our APQ-ViT surpasses the existing post-training quantization methods by convincing margins, especially in lower bit-width settings (e.g., averagely up to 5.17% improvement for classification and 24.43% for detection on W4A4). We also highlight that APQ-ViT enjoys versatility and works well on diverse transformer variants.", "published": "2023-03-25T03:05:26Z", "version": 1}, {"aid": "2303.14389", "authors": ["Shanghua Gao", "Pan Zhou", "Ming-Ming Cheng", "Shuicheng Yan"], "title": "MDTv2: Masked Diffusion Transformer is a Strong Image Synthesizer", "url": "http://arxiv.org/pdf/2303.14389v2", "summary": "Despite its success in image synthesis, we observe that diffusion probabilistic models (DPMs) often lack contextual reasoning ability to learn the relations among object parts in an image, leading to a slow learning process. To solve this issue, we propose a Masked Diffusion Transformer (MDT) that introduces a mask latent modeling scheme to explicitly enhance the DPMs' ability to contextual relation learning among object semantic parts in an image. During training, MDT operates in the latent space to mask certain tokens. Then, an asymmetric diffusion transformer is designed to predict masked tokens from unmasked ones while maintaining the diffusion generation process. Our MDT can reconstruct the full information of an image from its incomplete contextual input, thus enabling it to learn the associated relations among image tokens. We further improve MDT with a more efficient macro network structure and training strategy, named MDTv2. Experimental results show that MDTv2 achieves superior image synthesis performance, e.g., a new SOTA FID score of 1.58 on the ImageNet dataset, and has more than 10x faster learning speed than the previous SOTA DiT. The source code is released at https://github.com/sail-sg/MDT.", "published": "2023-03-25T07:47:21Z", "version": 2}, {"aid": "2303.14448", "authors": ["Trevor McCourt", "Ila R. Fiete", "Isaac L. Chuang"], "title": "Noisy dynamical systems evolve error correcting codes and modularity", "url": "http://arxiv.org/pdf/2303.14448v2", "summary": "Noise is a ubiquitous feature of the physical world. As a result, the first prerequisite of life is fault tolerance: maintaining integrity of state despite external bombardment. Recent experimental advances have revealed that biological systems achieve fault tolerance by implementing mathematically intricate error-correcting codes and by organizing in a modular fashion that physically separates functionally distinct subsystems. These elaborate structures represent a vanishing volume in the massive genetic configuration space. How is it possible that the primitive process of evolution, by which all biological systems evolved, achieved such unusual results? In this work, through experiments in Boolean networks, we show that the simultaneous presence of error correction and modularity in biological systems is no coincidence. Rather, it is a typical co-occurrence in noisy dynamic systems undergoing evolution. From this, we deduce the principle of error correction enhanced evolvability: systems possessing error-correcting codes are more effectively improved by evolution than those without.", "published": "2023-03-25T11:54:18Z", "version": 2}, {"aid": "2303.16067", "authors": ["Aaron Pache", "Mark CW van Rossum"], "title": "Lazy learning: a biologically-inspired plasticity rule for fast and energy efficient synaptic plasticity", "url": "http://arxiv.org/pdf/2303.16067v1", "summary": "When training neural networks for classification tasks with backpropagation, parameters are updated on every trial, even if the sample is classified correctly. In contrast, humans concentrate their learning effort on errors. Inspired by human learning, we introduce lazy learning, which only learns on incorrect samples. Lazy learning can be implemented in a few lines of code and requires no hyperparameter tuning. Lazy learning achieves state-of-the-art performance and is particularly suited when datasets are large. For instance, it reaches 99.2% test accuracy on Extended MNIST using a single-layer MLP, and does so 7.6x faster than a matched backprop network", "published": "2023-03-26T16:17:04Z", "version": 1}, {"aid": "2303.15672", "authors": ["Guanghui Lan", "Alexander Shapiro"], "title": "Numerical Methods for Convex Multistage Stochastic Optimization", "url": "http://arxiv.org/pdf/2303.15672v1", "summary": "Optimization problems involving sequential decisions in a stochastic environment were studied in Stochastic Programming (SP), Stochastic Optimal Control (SOC) and Markov Decision Processes (MDP). In this paper we mainly concentrate on SP and SOC modelling approaches. In these frameworks there are natural situations when the considered problems are convex. Classical approach to sequential optimization is based on dynamic programming. It has the problem of the so-called ``Curse of Dimensionality\", in that its computational complexity increases exponentially with increase of dimension of state variables. Recent progress in solving convex multistage stochastic problems is based on cutting planes approximations of the cost-to-go (value) functions of dynamic programming equations. Cutting planes type algorithms in dynamical settings is one of the main topics of this paper. We also discuss Stochastic Approximation type methods applied to multistage stochastic optimization problems. From the computational complexity point of view, these two types of methods seem to be complimentary to each other. Cutting plane type methods can handle multistage problems with a large number of stages, but a relatively smaller number of state (decision) variables. On the other hand, stochastic approximation type methods can only deal with a small number of stages, but a large number of decision variables.", "published": "2023-03-28T01:30:40Z", "version": 1}, {"aid": "2303.15953", "authors": ["Matt Gorbett", "Darrell Whitley"], "title": "Randomly Initialized Subnetworks with Iterative Weight Recycling", "url": "http://arxiv.org/pdf/2303.15953v1", "summary": "The Multi-Prize Lottery Ticket Hypothesis posits that randomly initialized neural networks contain several subnetworks that achieve comparable accuracy to fully trained models of the same architecture. However, current methods require that the network is sufficiently overparameterized. In this work, we propose a modification to two state-of-the-art algorithms (Edge-Popup and Biprop) that finds high-accuracy subnetworks with no additional storage cost or scaling. The algorithm, Iterative Weight Recycling, identifies subsets of important weights within a randomly initialized network for intra-layer reuse. Empirically we show improvements on smaller network architectures and higher prune rates, finding that model sparsity can be increased through the \"recycling\" of existing weights. In addition to Iterative Weight Recycling, we complement the Multi-Prize Lottery Ticket Hypothesis with a reciprocal finding: high-accuracy, randomly initialized subnetwork's produce diverse masks, despite being generated with the same hyperparameter's and pruning strategy. We explore the landscapes of these masks, which show high variability.", "published": "2023-03-28T13:12:00Z", "version": 1}, {"aid": "2303.16001", "authors": ["Tim Elsner", "Victor Czech", "Julia Berger", "Zain Selman", "Isaak Lim", "Leif Kobbelt"], "title": "Adaptive Voronoi NeRFs", "url": "http://arxiv.org/pdf/2303.16001v2", "summary": "Neural Radiance Fields (NeRFs) learn to represent a 3D scene from just a set of registered images. Increasing sizes of a scene demands more complex functions, typically represented by neural networks, to capture all details. Training and inference then involves querying the neural network millions of times per image, which becomes impractically slow. Since such complex functions can be replaced by multiple simpler functions to improve speed, we show that a hierarchy of Voronoi diagrams is a suitable choice to partition the scene. By equipping each Voronoi cell with its own NeRF, our approach is able to quickly learn a scene representation. We propose an intuitive partitioning of the space that increases quality gains during training by distributing information evenly among the networks and avoids artifacts through a top-down adaptive refinement. Our framework is agnostic to the underlying NeRF method and easy to implement, which allows it to be applied to various NeRF variants for improved learning and rendering speeds.", "published": "2023-03-28T14:16:08Z", "version": 2}, {"aid": "2303.16258", "authors": ["Konstantin Klemm", "Anita Mehta", "Peter F. Stadler"], "title": "Optimisation via encodings: a renormalisation group perspective", "url": "http://arxiv.org/pdf/2303.16258v2", "summary": "Difficult, in particular NP-complete, optimization problems are traditionally solved approximately using search heuristics. These are usually slowed down by the rugged landscapes encountered, because local minima arrest the search process. Cover-encoding maps were devised to circumvent this problem by transforming the original landscape to one that is free of local minima and enriched in near-optimal solutions. By definition, these involve the mapping of the original (larger) search space into smaller subspaces, by processes that typically amount to a form of coarse-graining. In this paper, we explore the details of this coarse-graining using formal arguments, as well as concrete examples of cover-encoding maps, that are investigated analytically as well as computationally. Our results strongly suggest that the coarse-graining involved in cover-encoding maps bears a strong resemblance to that encountered in renormalisation group schemes. Given the apparently disparate nature of these two formalisms, these strong similarities are rather startling, and suggest deep mathematical underpinnings that await further exploration.", "published": "2023-03-28T19:07:33Z", "version": 2}, {"aid": "2303.16280", "authors": ["Dmitrii Torbunov", "Yi Huang", "Huan-Hsin Tseng", "Haiwang Yu", "Jin Huang", "Shinjae Yoo", "Meifeng Lin", "Brett Viren", "Yihui Ren"], "title": "UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image Translation", "url": "http://arxiv.org/pdf/2303.16280v3", "summary": "An unpaired image-to-image (I2I) translation technique seeks to find a mapping between two domains of data in a fully unsupervised manner. While initial solutions to the I2I problem were provided by generative adversarial neural networks (GANs), diffusion models (DMs) currently hold the state-of-the-art status on the I2I translation benchmarks in terms of Frechet inception distance (FID). Yet, DMs suffer from limitations, such as not using data from the source domain during the training or maintaining consistency of the source and translated images only via simple pixel-wise errors. This work improves a recent UVCGAN model and equips it with modern advancements in model architectures and training procedures. The resulting revised model significantly outperforms other advanced GAN- and DM-based competitors on a variety of benchmarks. In the case of Male-to-Female translation of CelebA, the model achieves more than 40% improvement in FID score compared to the state-of-the-art results. This work also demonstrates the ineffectiveness of the pixel-wise I2I translation faithfulness metrics and suggests their revision. The code and trained models are available at https://github.com/LS4GAN/uvcgan2", "published": "2023-03-28T19:46:34Z", "version": 3}, {"aid": "2303.16321", "authors": ["Aditya Dave", "Ioannis Faros", "Nishanth Venkatesh", "Andreas A. Malikopoulos"], "title": "Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon", "url": "http://arxiv.org/pdf/2303.16321v2", "summary": "Safety-critical cyber-physical systems require control strategies whose worst-case performance is robust against adversarial disturbances and modeling uncertainties. In this paper, we present a framework for approximate control and learning in partially observed systems to minimize the worst-case discounted cost over an infinite time horizon. We model disturbances to the system as finite-valued uncertain variables with unknown probability distributions. For problems with known system dynamics, we construct a dynamic programming (DP) decomposition to compute the optimal control strategy. Our first contribution is to define information states that improve the computational tractability of this DP without loss of optimality. Then, we describe a simplification for a class of problems where the incurred cost is observable at each time instance. Our second contribution is defining an approximate information state that can be constructed or learned directly from observed data for problems with observable costs. We derive bounds on the performance loss of the resulting approximate control strategy and illustrate the effectiveness of our approach in partially observed decision-making problems with a numerical example.", "published": "2023-03-28T21:40:06Z", "version": 2}, {"aid": "2303.16343", "authors": ["Michal Kosinski", "Poruz Khambatta", "Yilun Wang"], "title": "Facial recognition technology and human raters can predict political orientation from images of expressionless faces even when controlling for demographics and self-presentation", "url": "http://arxiv.org/pdf/2303.16343v4", "summary": "Carefully standardized facial images of 591 participants were taken in the laboratory, while controlling for self-presentation, facial expression, head orientation, and image properties. They were presented to human raters and a facial recognition algorithm: both humans (r=.21) and the algorithm (r=.22) could predict participants' scores on a political orientation scale (Cronbach's alpha=.94) decorrelated with age, gender, and ethnicity. These effects are on par with how well job interviews predict job success, or alcohol drives aggressiveness. Algorithm's predictive accuracy was even higher (r=.31) when it leveraged information on participants' age, gender, and ethnicity. Moreover, the associations between facial appearance and political orientation seem to generalize beyond our sample: The predictive model derived from standardized images (while controlling for age, gender, and ethnicity) could predict political orientation (r=.13) from naturalistic images of 3,401 politicians from the U.S., UK, and Canada. The analysis of facial features associated with political orientation revealed that conservatives tended to have larger lower faces. The predictability of political orientation from standardized images has critical implications for privacy, the regulation of facial recognition technology, and understanding the origins and consequences of political orientation.", "published": "2023-03-28T22:47:28Z", "version": 4}, {"aid": "2303.16411", "authors": ["Man Zhou", "Naishan Zheng", "Jie Huang", "Chunle Guo", "Chongyi Li"], "title": "Unlocking Masked Autoencoders as Loss Function for Image and Video Restoration", "url": "http://arxiv.org/pdf/2303.16411v1", "summary": "Image and video restoration has achieved a remarkable leap with the advent of deep learning. The success of deep learning paradigm lies in three key components: data, model, and loss. Currently, many efforts have been devoted to the first two while seldom study focuses on loss function. With the question ``are the de facto optimization functions e.g., $L_1$, $L_2$, and perceptual losses optimal?'', we explore the potential of loss and raise our belief ``learned loss function empowers the learning capability of neural networks for image and video restoration''.   Concretely, we stand on the shoulders of the masked Autoencoders (MAE) and formulate it as a `learned loss function', owing to the fact the pre-trained MAE innately inherits the prior of image reasoning. We investigate the efficacy of our belief from three perspectives: 1) from task-customized MAE to native MAE, 2) from image task to video task, and 3) from transformer structure to convolution neural network structure. Extensive experiments across multiple image and video tasks, including image denoising, image super-resolution, image enhancement, guided image super-resolution, video denoising, and video enhancement, demonstrate the consistent performance improvements introduced by the learned loss function. Besides, the learned loss function is preferable as it can be directly plugged into existing networks during training without involving computations in the inference stage. Code will be publicly available.", "published": "2023-03-29T02:41:08Z", "version": 1}, {"aid": "2303.16459", "authors": ["Stefan Abi-Karam", "Cong Hao"], "title": "GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization", "url": "http://arxiv.org/pdf/2303.16459v2", "summary": "There are plenty of graph neural network (GNN) accelerators being proposed. However, they highly rely on users' hardware expertise and are usually optimized for one specific GNN model, making them challenging for practical use. Therefore, in this work, we propose GNNBuilder, the first automated, generic, end-to-end GNN accelerator generation framework. It features four advantages: (1) GNNBuilder can automatically generate GNN accelerators for a wide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes standard PyTorch programming interface, introducing zero overhead for algorithm developers; (3) GNNBuilder supports end-to-end code generation, simulation, accelerator optimization, and hardware deployment, realizing a push-button fashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate performance models of its generated accelerator, enabling fast and flexible design space exploration (DSE). In the experiments, first, we show that our accelerator performance model has errors within $36\\%$ for latency prediction and $18\\%$ for BRAM count prediction. Second, we show that our generated accelerators can outperform CPU by $6.33\\times$ and GPU by $6.87\\times$. This framework is open-source, and the code is available at https://github.com/sharc-lab/gnn-builder.", "published": "2023-03-29T05:08:21Z", "version": 2}, {"aid": "2303.16491", "authors": ["Sicheng Gao", "Xuhui Liu", "Bohan Zeng", "Sheng Xu", "Yanjing Li", "Xiaoyan Luo", "Jianzhuang Liu", "Xiantong Zhen", "Baochang Zhang"], "title": "Implicit Diffusion Models for Continuous Super-Resolution", "url": "http://arxiv.org/pdf/2303.16491v2", "summary": "Image super-resolution (SR) has attracted increasing attention due to its wide applications. However, current SR methods generally suffer from over-smoothing and artifacts, and most work only with fixed magnifications. This paper introduces an Implicit Diffusion Model (IDM) for high-fidelity continuous image super-resolution. IDM integrates an implicit neural representation and a denoising diffusion model in a unified end-to-end framework, where the implicit neural representation is adopted in the decoding process to learn continuous-resolution representation. Furthermore, we design a scale-controllable conditioning mechanism that consists of a low-resolution (LR) conditioning network and a scaling factor. The scaling factor regulates the resolution and accordingly modulates the proportion of the LR information and generated features in the final output, which enables the model to accommodate the continuous-resolution requirement. Extensive experiments validate the effectiveness of our IDM and demonstrate its superior performance over prior arts.", "published": "2023-03-29T07:02:20Z", "version": 2}, {"aid": "2303.16513", "authors": ["Hao-Wei Chen", "Yu-Syuan Xu", "Min-Fong Hong", "Yi-Min Tsai", "Hsien-Kai Kuo", "Chun-Yi Lee"], "title": "Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution", "url": "http://arxiv.org/pdf/2303.16513v1", "summary": "Implicit neural representation has recently shown a promising ability in representing images with arbitrary resolutions. In this paper, we present a Local Implicit Transformer (LIT), which integrates the attention mechanism and frequency encoding technique into a local implicit image function. We design a cross-scale local attention block to effectively aggregate local features. To further improve representative power, we propose a Cascaded LIT (CLIT) that exploits multi-scale features, along with a cumulative training strategy that gradually increases the upsampling scales during training. We have conducted extensive experiments to validate the effectiveness of these components and analyze various training strategies. The qualitative and quantitative results demonstrate that LIT and CLIT achieve favorable results and outperform the prior works in arbitrary super-resolution tasks.", "published": "2023-03-29T07:41:56Z", "version": 1}, {"aid": "2303.16666", "authors": ["Pan Xiao", "Peijie Qiu", "Sungmin Ha", "Abdalla Bani", "Shuang Zhou", "Aristeidis Sotiras"], "title": "SC-VAE: Sparse Coding-based Variational Autoencoder with Learned ISTA", "url": "http://arxiv.org/pdf/2303.16666v2", "summary": "Learning rich data representations from unlabeled data is a key challenge towards applying deep learning algorithms in downstream tasks. Several variants of variational autoencoders (VAEs) have been proposed to learn compact data representations by encoding high-dimensional data in a lower dimensional space. Two main classes of VAEs methods may be distinguished depending on the characteristics of the meta-priors that are enforced in the representation learning step. The first class of methods derives a continuous encoding by assuming a static prior distribution in the latent space. The second class of methods learns instead a discrete latent representation using vector quantization (VQ) along with a codebook. However, both classes of methods suffer from certain challenges, which may lead to suboptimal image reconstruction results. The first class suffers from posterior collapse, whereas the second class suffers from codebook collapse. To address these challenges, we introduce a new VAE variant, termed sparse coding-based VAE with learned ISTA (SC-VAE), which integrates sparse coding within variational autoencoder framework. The proposed method learns sparse data representations that consist of a linear combination of a small number of predetermined orthogonal atoms. The sparse coding problem is solved using a learnable version of the iterative shrinkage thresholding algorithm (ISTA). Experiments on two image datasets demonstrate that our model achieves improved image reconstruction results compared to state-of-the-art methods. Moreover, we demonstrate that the use of learned sparse code vectors allows us to perform downstream tasks like image generation and unsupervised image segmentation through clustering image patches.", "published": "2023-03-29T13:18:33Z", "version": 2}, {"aid": "2303.17589", "authors": ["Qingyang Wang", "Michael A. Powell", "Ali Geisa", "Eric W. Bridgeford", "Joshua T. Vogelstein"], "title": "Polarity is all you need to learn and transfer faster", "url": "http://arxiv.org/pdf/2303.17589v2", "summary": "Natural intelligences (NIs) thrive in a dynamic world - they learn quickly, sometimes with only a few samples. In contrast, artificial intelligences (AIs) typically learn with a prohibitive number of training samples and computational power. What design principle difference between NI and AI could contribute to such a discrepancy? Here, we investigate the role of weight polarity: development processes initialize NIs with advantageous polarity configurations; as NIs grow and learn, synapse magnitudes update, yet polarities are largely kept unchanged. We demonstrate with simulation and image classification tasks that if weight polarities are adequately set a priori, then networks learn with less time and data. We also explicitly illustrate situations in which a priori setting the weight polarities is disadvantageous for networks. Our work illustrates the value of weight polarities from the perspective of statistical and computational efficiency during learning.", "published": "2023-03-29T14:43:04Z", "version": 2}, {"aid": "2303.16852", "authors": ["Yuyang Shi", "Valentin De Bortoli", "Andrew Campbell", "Arnaud Doucet"], "title": "Diffusion Schr\u00f6dinger Bridge Matching", "url": "http://arxiv.org/pdf/2303.16852v3", "summary": "Solving transport problems, i.e. finding a map transporting one given distribution to another, has numerous applications in machine learning. Novel mass transport methods motivated by generative modeling have recently been proposed, e.g. Denoising Diffusion Models (DDMs) and Flow Matching Models (FMMs) implement such a transport through a Stochastic Differential Equation (SDE) or an Ordinary Differential Equation (ODE). However, while it is desirable in many applications to approximate the deterministic dynamic Optimal Transport (OT) map which admits attractive properties, DDMs and FMMs are not guaranteed to provide transports close to the OT map. In contrast, Schr\\\"odinger bridges (SBs) compute stochastic dynamic mappings which recover entropy-regularized versions of OT. Unfortunately, existing numerical methods approximating SBs either scale poorly with dimension or accumulate errors across iterations. In this work, we introduce Iterative Markovian Fitting (IMF), a new methodology for solving SB problems, and Diffusion Schr\\\"odinger Bridge Matching (DSBM), a novel numerical algorithm for computing IMF iterates. DSBM significantly improves over previous SB numerics and recovers as special/limiting cases various recent transport methods. We demonstrate the performance of DSBM on a variety of problems.", "published": "2023-03-29T16:59:22Z", "version": 3}, {"aid": "2303.16947", "authors": ["Congpei Qiu", "Tong Zhang", "Wei Ke", "Mathieu Salzmann", "Sabine S\u00fcsstrunk"], "title": "De-coupling and De-positioning Dense Self-supervised Learning", "url": "http://arxiv.org/pdf/2303.16947v1", "summary": "Dense Self-Supervised Learning (SSL) methods address the limitations of using image-level feature representations when handling images with multiple objects. Although the dense features extracted by employing segmentation maps and bounding boxes allow networks to perform SSL for each object, we show that they suffer from coupling and positional bias, which arise from the receptive field increasing with layer depth and zero-padding. We address this by introducing three data augmentation strategies, and leveraging them in (i) a decoupling module that aims to robustify the network to variations in the object's surroundings, and (ii) a de-positioning module that encourages the network to discard positional object information. We demonstrate the benefits of our method on COCO and on a new challenging benchmark, OpenImage-MINI, for object classification, semantic segmentation, and object detection. Our extensive experiments evidence the better generalization of our method compared to the SOTA dense SSL methods", "published": "2023-03-29T18:07:25Z", "version": 1}, {"aid": "2303.17015", "authors": ["Ziya Erko\u00e7", "Fangchang Ma", "Qi Shan", "Matthias Nie\u00dfner", "Angela Dai"], "title": "HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion", "url": "http://arxiv.org/pdf/2303.17015v1", "summary": "Implicit neural fields, typically encoded by a multilayer perceptron (MLP) that maps from coordinates (e.g., xyz) to signals (e.g., signed distances), have shown remarkable promise as a high-fidelity and compact representation. However, the lack of a regular and explicit grid structure also makes it challenging to apply generative modeling directly on implicit neural fields in order to synthesize new data. To this end, we propose HyperDiffusion, a novel approach for unconditional generative modeling of implicit neural fields. HyperDiffusion operates directly on MLP weights and generates new neural implicit fields encoded by synthesized MLP parameters. Specifically, a collection of MLPs is first optimized to faithfully represent individual data samples. Subsequently, a diffusion process is trained in this MLP weight space to model the underlying distribution of neural implicit fields. HyperDiffusion enables diffusion modeling over a implicit, compact, and yet high-fidelity representation of complex signals across 3D shapes and 4D mesh animations within one single unified framework.", "published": "2023-03-29T20:44:42Z", "version": 1}, {"aid": "2303.17056", "authors": ["Shentong Mo", "Yapeng Tian"], "title": "Audio-Visual Grouping Network for Sound Localization from Mixtures", "url": "http://arxiv.org/pdf/2303.17056v1", "summary": "Sound source localization is a typical and challenging task that predicts the location of sound sources in a video. Previous single-source methods mainly used the audio-visual association as clues to localize sounding objects in each image. Due to the mixed property of multiple sound sources in the original space, there exist rare multi-source approaches to localizing multiple sources simultaneously, except for one recent work using a contrastive random walk in the graph with images and separated sound as nodes. Despite their promising performance, they can only handle a fixed number of sources, and they cannot learn compact class-aware representations for individual sources. To alleviate this shortcoming, in this paper, we propose a novel audio-visual grouping network, namely AVGN, that can directly learn category-wise semantic features for each source from the input audio mixture and image to localize multiple sources simultaneously. Specifically, our AVGN leverages learnable audio-visual class tokens to aggregate class-aware source features. Then, the aggregated semantic features for each source can be used as guidance to localize the corresponding visual regions. Compared to existing multi-source methods, our new framework can localize a flexible number of sources and disentangle category-aware audio-visual representations for individual sound sources. We conduct extensive experiments on MUSIC, VGGSound-Instruments, and VGG-Sound Sources benchmarks. The results demonstrate that the proposed AVGN can achieve state-of-the-art sounding object localization performance on both single-source and multi-source scenarios. Code is available at \\url{https://github.com/stoneMo/AVGN}.", "published": "2023-03-29T22:58:55Z", "version": 1}, {"aid": "2303.17075", "authors": ["Lenore Blum", "Manuel Blum"], "title": "Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence", "url": "http://arxiv.org/pdf/2303.17075v1", "summary": "We have defined the Conscious Turing Machine (CTM) for the purpose of investigating a Theoretical Computer Science (TCS) approach to consciousness. For this, we have hewn to the TCS demand for simplicity and understandability. The CTM is consequently and intentionally a simple machine. It is not a model of the brain, though its design has greatly benefited - and continues to benefit - from neuroscience and psychology. The CTM is a model of and for consciousness.   Although it is developed to understand consciousness, the CTM offers a thoughtful and novel guide to the creation of an Artificial General Intelligence (AGI). For example, the CTM has an enormous number of powerful processors, some with specialized expertise, others unspecialized but poised to develop an expertise. For whatever problem must be dealt with, the CTM has an excellent way to utilize those processors that have the required knowledge, ability, and time to work on the problem, even if it is not aware of which ones these may be.", "published": "2023-03-30T00:39:10Z", "version": 1}, {"aid": "2303.17076", "authors": ["Qinsheng Zhang", "Jiaming Song", "Xun Huang", "Yongxin Chen", "Ming-Yu Liu"], "title": "DiffCollage: Parallel Generation of Large Content with Diffusion Models", "url": "http://arxiv.org/pdf/2303.17076v1", "summary": "We present DiffCollage, a compositional diffusion model that can generate large content by leveraging diffusion models trained on generating pieces of the large content. Our approach is based on a factor graph representation where each factor node represents a portion of the content and a variable node represents their overlap. This representation allows us to aggregate intermediate outputs from diffusion models defined on individual nodes to generate content of arbitrary size and shape in parallel without resorting to an autoregressive generation procedure. We apply DiffCollage to various tasks, including infinite image generation, panorama image generation, and long-duration text-guided motion generation. Extensive experimental results with a comparison to strong autoregressive baselines verify the effectiveness of our approach.", "published": "2023-03-30T00:51:12Z", "version": 1}, {"aid": "2303.17127", "authors": ["Thalaiyasingam Ajanthan", "Matt Ma", "Anton van den Hengel", "Stephen Gould"], "title": "Adaptive Cross Batch Normalization for Metric Learning", "url": "http://arxiv.org/pdf/2303.17127v1", "summary": "Metric learning is a fundamental problem in computer vision whereby a model is trained to learn a semantically useful embedding space via ranking losses. Traditionally, the effectiveness of a ranking loss depends on the minibatch size, and is, therefore, inherently limited by the memory constraints of the underlying hardware. While simply accumulating the embeddings across minibatches has proved useful (Wang et al. [2020]), we show that it is equally important to ensure that the accumulated embeddings are up to date. In particular, it is necessary to circumvent the representational drift between the accumulated embeddings and the feature embeddings at the current training iteration as the learnable parameters are being updated. In this paper, we model representational drift as distribution misalignment and tackle it using moment matching. The result is a simple method for updating the stored embeddings to match the first and second moments of the current embeddings at each training iteration. Experiments on three popular image retrieval datasets, namely, SOP, In-Shop, and DeepFashion2, demonstrate that our approach significantly improves the performance in all scenarios.", "published": "2023-03-30T03:22:52Z", "version": 1}, {"aid": "2303.17583", "authors": ["Sachin Shah", "Sakshum Kulshrestha", "Christopher A. Metzler"], "title": "TiDy-PSFs: Computational Imaging with Time-Averaged Dynamic Point-Spread-Functions", "url": "http://arxiv.org/pdf/2303.17583v1", "summary": "Point-spread-function (PSF) engineering is a powerful computational imaging techniques wherein a custom phase mask is integrated into an optical system to encode additional information into captured images. Used in combination with deep learning, such systems now offer state-of-the-art performance at monocular depth estimation, extended depth-of-field imaging, lensless imaging, and other tasks. Inspired by recent advances in spatial light modulator (SLM) technology, this paper answers a natural question: Can one encode additional information and achieve superior performance by changing a phase mask dynamically over time? We first prove that the set of PSFs described by static phase masks is non-convex and that, as a result, time-averaged PSFs generated by dynamic phase masks are fundamentally more expressive. We then demonstrate, in simulation, that time-averaged dynamic (TiDy) phase masks can offer substantially improved monocular depth estimation and extended depth-of-field imaging performance.", "published": "2023-03-30T17:51:07Z", "version": 1}, {"aid": "2303.18242", "authors": ["Sam Bond-Taylor", "Chris G. Willcocks"], "title": "$\\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States", "url": "http://arxiv.org/pdf/2303.18242v2", "summary": "This paper introduces $\\infty$-Diff, a generative diffusion model defined in an infinite-dimensional Hilbert space, which can model infinite resolution data. By training on randomly sampled subsets of coordinates and denoising content only at those locations, we learn a continuous function for arbitrary resolution sampling. Unlike prior neural field-based infinite-dimensional models, which use point-wise functions requiring latent compression, our method employs non-local integral operators to map between Hilbert spaces, allowing spatial context aggregation. This is achieved with an efficient multi-scale function-space architecture that operates directly on raw sparse coordinates, coupled with a mollified diffusion process that smooths out irregularities. Through experiments on high-resolution datasets, we found that even at an $8\\times$ subsampling rate, our model retains high-quality diffusion. This leads to significant run-time and memory savings, delivers samples with lower FID scores, and scales beyond the training resolution while retaining detail.", "published": "2023-03-31T17:58:08Z", "version": 2}, {"aid": "2304.00306", "authors": ["Rahul Chand", "Rajat Arora", "K Ram Prabhakar", "R Venkatesh Babu"], "title": "CapsFlow: Optical Flow Estimation with Capsule Networks", "url": "http://arxiv.org/pdf/2304.00306v2", "summary": "We present a framework to use recently introduced Capsule Networks for solving the problem of Optical Flow, one of the fundamental computer vision tasks. Most of the existing state of the art deep architectures either uses a correlation oepration to match features from them. While correlation layer is sensitive to the choice of hyperparameters and does not put a prior on the underlying structure of the object, spatio temporal features will be limited by the network's receptive field. Also, we as humans look at moving objects as whole, something which cannot be encoded by correlation or spatio temporal features. Capsules, on the other hand, are specialized to model seperate entities and their pose as a continuous matrix. Thus, we show that a simpler linear operation over poses of the objects detected by the capsules in enough to model flow. We show reslts on a small toy dataset where we outperform FlowNetC and PWC-Net models.", "published": "2023-04-01T12:35:41Z", "version": 2}, {"aid": "2304.00424", "authors": ["Seokeon Choi", "Debasmit Das", "Sungha Choi", "Seunghan Yang", "Hyunsin Park", "Sungrack Yun"], "title": "Progressive Random Convolutions for Single Domain Generalization", "url": "http://arxiv.org/pdf/2304.00424v1", "summary": "Single domain generalization aims to train a generalizable model with only one source domain to perform well on arbitrary unseen target domains. Image augmentation based on Random Convolutions (RandConv), consisting of one convolution layer randomly initialized for each mini-batch, enables the model to learn generalizable visual representations by distorting local textures despite its simple and lightweight structure. However, RandConv has structural limitations in that the generated image easily loses semantics as the kernel size increases, and lacks the inherent diversity of a single convolution operation. To solve the problem, we propose a Progressive Random Convolution (Pro-RandConv) method that recursively stacks random convolution layers with a small kernel size instead of increasing the kernel size. This progressive approach can not only mitigate semantic distortions by reducing the influence of pixels away from the center in the theoretical receptive field, but also create more effective virtual domains by gradually increasing the style diversity. In addition, we develop a basic random convolution layer into a random convolution block including deformable offsets and affine transformation to support texture and contrast diversification, both of which are also randomly initialized. Without complex generators or adversarial learning, we demonstrate that our simple yet effective augmentation strategy outperforms state-of-the-art methods on single domain generalization benchmarks.", "published": "2023-04-02T01:42:51Z", "version": 1}, {"aid": "2304.01227", "authors": ["Samira Kabri", "Tim Roith", "Daniel Tenbrinck", "Martin Burger"], "title": "Resolution-Invariant Image Classification based on Fourier Neural Operators", "url": "http://arxiv.org/pdf/2304.01227v1", "summary": "In this paper we investigate the use of Fourier Neural Operators (FNOs) for image classification in comparison to standard Convolutional Neural Networks (CNNs). Neural operators are a discretization-invariant generalization of neural networks to approximate operators between infinite dimensional function spaces. FNOs - which are neural operators with a specific parametrization - have been applied successfully in the context of parametric PDEs. We derive the FNO architecture as an example for continuous and Fr\\'echet-differentiable neural operators on Lebesgue spaces. We further show how CNNs can be converted into FNOs and vice versa and propose an interpolation-equivariant adaptation of the architecture.", "published": "2023-04-02T10:23:36Z", "version": 1}, {"aid": "2304.01283", "authors": ["Steffen Lewitzka", "Vin\u00edcius Pinto"], "title": "Belief, knowledge and evidence", "url": "http://arxiv.org/pdf/2304.01283v1", "summary": "We present a logical system that combines the well-known classical epistemic concepts of belief and knowledge with a concept of evidence such that the intuitive principle \\textit{`evidence yields belief and knowledge'} is satisfied. Our approach relies on previous works of the first author \\cite{lewjlc2, lewigpl, lewapal} who introduced a modal system containing $S5$-style principles for the reasoning about intutionistic truth (i.e. \\textit{proof}) and, inspired by \\cite{artpro}, combined that system with concepts of \\textit{intuitionistic} belief and knowledge. We consider that combined system and replace the constructive concept of \\textit{proof} with a classical notion of \\textit{evidence}. This results in a logic that combines modal system $S5$ with classical epistemic principles where $\\square\\varphi$ reads as `$\\varphi$ is evident' in an epistemic sense. Inspired by \\cite{lewapal}, and in contrast to the usual possible worlds semantics found in the literature, we propose here a relational, frame-based semantics where belief and knowledge are not modeled via accessibility relations but directly as sets of propositions (sets of sets of worlds).", "published": "2023-04-03T18:20:02Z", "version": 1}, {"aid": "2304.01297", "authors": ["Jacob Piland", "Christopher Sweet", "Priscila Saboia", "Charles Vardeman II", "Adam Czajka"], "title": "Non-Generative Energy Based Models", "url": "http://arxiv.org/pdf/2304.01297v1", "summary": "Energy-based models (EBM) have become increasingly popular within computer vision. EBMs bring a probabilistic approach to training deep neural networks (DNN) and have been shown to enhance performance in areas such as calibration, out-of-distribution detection, and adversarial resistance. However, these advantages come at the cost of estimating input data probabilities, usually using a Langevin based method such as Stochastic Gradient Langevin Dynamics (SGLD), which bring additional computational costs, require parameterization, caching methods for efficiency, and can run into stability and scaling issues. EBMs use dynamical methods to draw samples from the probability density function (PDF) defined by the current state of the network and compare them to the training data using a maximum log likelihood approach to learn the correct PDF.   We propose a non-generative training approach, Non-Generative EBM (NG-EBM), that utilizes the {\\it{Approximate Mass}}, identified by Grathwohl et al., as a loss term to direct the training. We show that our NG-EBM training strategy retains many of the benefits of EBM in calibration, out-of-distribution detection, and adversarial resistance, but without the computational complexity and overhead of the traditional approaches. In particular, the NG-EBM approach improves the Expected Calibration Error by a factor of 2.5 for CIFAR10 and 7.5 times for CIFAR100, when compared to traditionally trained models.", "published": "2023-04-03T18:47:37Z", "version": 1}, {"aid": "2304.01406", "authors": ["Huzi Cheng", "Joshua W. Brown"], "title": "Learning with augmented target information: An alternative theory of Feedback Alignment", "url": "http://arxiv.org/pdf/2304.01406v1", "summary": "While error backpropagation (BP) has dominated the training of nearly all modern neural networks for a long time, it suffers from several biological plausibility issues such as the symmetric weight requirement and synchronous updates. Feedback Alignment (FA) was proposed as an alternative to BP to address those dilemmas and has been demonstrated to be effective on various tasks and network architectures. Despite its simplicity and effectiveness, a satisfying explanation of how FA works across different architectures is still lacking. Here we propose a novel, architecture-agnostic theory of how FA works through the lens of information theory: Instead of approximating gradients calculated by BP with the same parameter, FA learns effective representations by embedding target information into neural networks to be trained. We show this through the analysis of FA dynamics in idealized settings and then via a series of experiments. Based on the implications of this theory, we designed three variants of FA and show their comparable performance on several tasks. These variants also account for some phenomena and theories in neuroscience such as predictive coding and representational drift.", "published": "2023-04-03T22:44:03Z", "version": 1}, {"aid": "2304.01432", "authors": ["Zhaoyue Chen", "Yifan Sun"], "title": "Reducing Discretization Error in the Frank-Wolfe Method", "url": "http://arxiv.org/pdf/2304.01432v2", "summary": "The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. We view this as an artifact of discretization; that is to say, the Frank-Wolfe \\emph{flow}, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.", "published": "2023-04-04T00:43:05Z", "version": 2}, {"aid": "2304.01434", "authors": ["Jaeill Kim", "Suhyun Kang", "Duhun Hwang", "Jungwook Shin", "Wonjong Rhee"], "title": "VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution", "url": "http://arxiv.org/pdf/2304.01434v1", "summary": "Since the introduction of deep learning, a wide scope of representation properties, such as decorrelation, whitening, disentanglement, rank, isotropy, and mutual information, have been studied to improve the quality of representation. However, manipulating such properties can be challenging in terms of implementational effectiveness and general applicability. To address these limitations, we propose to regularize von Neumann entropy~(VNE) of representation. First, we demonstrate that the mathematical formulation of VNE is superior in effectively manipulating the eigenvalues of the representation autocorrelation matrix. Then, we demonstrate that it is widely applicable in improving state-of-the-art algorithms or popular benchmark algorithms by investigating domain-generalization, meta-learning, self-supervised learning, and generative models. In addition, we formally establish theoretical connections with rank, disentanglement, and isotropy of representation. Finally, we provide discussions on the dimension control of VNE and the relationship with Shannon entropy. Code is available at: https://github.com/jaeill/CVPR23-VNE.", "published": "2023-04-04T01:03:32Z", "version": 1}, {"aid": "2304.01585", "authors": ["Nilah Ravi Nair", "Fernando Moya Rueda", "Christopher Reining", "Gernot A. Fink"], "title": "Multi-Channel Time-Series Person and Soft-Biometric Identification", "url": "http://arxiv.org/pdf/2304.01585v1", "summary": "Multi-channel time-series datasets are popular in the context of human activity recognition (HAR). On-body device (OBD) recordings of human movements are often preferred for HAR applications not only for their reliability but as an approach for identity protection, e.g., in industrial settings. Contradictory, the gait activity is a biometric, as the cyclic movement is distinctive and collectable. In addition, the gait cycle has proven to contain soft-biometric information of human groups, such as age and height. Though general human movements have not been considered a biometric, they might contain identity information. This work investigates person and soft-biometrics identification from OBD recordings of humans performing different activities using deep architectures. Furthermore, we propose the use of attribute representation for soft-biometric identification. We evaluate the method on four datasets of multi-channel time-series HAR, measuring the performance of a person and soft-biometrics identification and its relation concerning performed activities. We find that person identification is not limited to gait activity. The impact of activities on the identification performance was found to be training and dataset specific. Soft-biometric based attribute representation shows promising results and emphasis the necessity of larger datasets.", "published": "2023-04-04T07:24:51Z", "version": 1}, {"aid": "2304.02473", "authors": ["Christopher Zach"], "title": "Fully Variational Noise-Contrastive Estimation", "url": "http://arxiv.org/pdf/2304.02473v1", "summary": "By using the underlying theory of proper scoring rules, we design a family of noise-contrastive estimation (NCE) methods that are tractable for latent variable models. Both terms in the underlying NCE loss, the one using data samples and the one using noise samples, can be lower-bounded as in variational Bayes, therefore we call this family of losses fully variational noise-contrastive estimation. Variational autoencoders are a particular example in this family and therefore can be also understood as separating real data from synthetic samples using an appropriate classification loss. We further discuss other instances in this family of fully variational NCE objectives and indicate differences in their empirical behavior.", "published": "2023-04-04T09:42:20Z", "version": 1}, {"aid": "2304.01834", "authors": ["Ntumba Elie Nsampi", "Adarsh Djeacoumar", "Hans-Peter Seidel", "Tobias Ritschel", "Thomas Leimk\u00fchler"], "title": "Neural Field Convolutions by Repeated Differentiation", "url": "http://arxiv.org/pdf/2304.01834v4", "summary": "Neural fields are evolving towards a general-purpose continuous representation for visual computing. Yet, despite their numerous appealing properties, they are hardly amenable to signal processing. As a remedy, we present a method to perform general continuous convolutions with general continuous signals such as neural fields. Observing that piecewise polynomial kernels reduce to a sparse set of Dirac deltas after repeated differentiation, we leverage convolution identities and train a repeated integral field to efficiently execute large-scale convolutions. We demonstrate our approach on a variety of data modalities and spatially-varying kernels.", "published": "2023-04-04T14:39:44Z", "version": 4}, {"aid": "2304.02008", "authors": ["R\u00e9mi Pautrat", "Iago Su\u00e1rez", "Yifan Yu", "Marc Pollefeys", "Viktor Larsson"], "title": "GlueStick: Robust Image Matching by Sticking Points and Lines Together", "url": "http://arxiv.org/pdf/2304.02008v3", "summary": "Line segments are powerful features complementary to points. They offer structural cues, robust to drastic viewpoint and illumination changes, and can be present even in texture-less areas. However, describing and matching them is more challenging compared to points due to partial occlusions, lack of texture, or repetitiveness. This paper introduces a new matching paradigm, where points, lines, and their descriptors are unified into a single wireframe structure. We propose GlueStick, a deep matching Graph Neural Network (GNN) that takes two wireframes from different images and leverages the connectivity information between nodes to better glue them together. In addition to the increased efficiency brought by the joint matching, we also demonstrate a large boost of performance when leveraging the complementary nature of these two features in a single architecture. We show that our matching strategy outperforms the state-of-the-art approaches independently matching line segments and points for a wide variety of datasets and tasks. The code is available at https://github.com/cvg/GlueStick.", "published": "2023-04-04T17:58:14Z", "version": 3}, {"aid": "2304.02049", "authors": ["Samuele Poppi", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "title": "Multi-Class Unlearning for Image Classification via Weight Filtering", "url": "http://arxiv.org/pdf/2304.02049v2", "summary": "Machine Unlearning is an emerging paradigm for selectively removing the impact of training datapoints from a network. Unlike existing methods that target a limited subset or a single class, our framework unlearns all classes in a single round. We achieve this by modulating the network's components using memory matrices, enabling the network to demonstrate selective unlearning behavior for any class after training. By discovering weights that are specific to each class, our approach also recovers a representation of the classes which is explainable by design. We test the proposed framework on small- and medium-scale image classification datasets, with both convolution- and Transformer-based backbones, showcasing the potential for explainable solutions through unlearning.", "published": "2023-04-04T18:01:59Z", "version": 2}, {"aid": "2304.02285", "authors": ["Xiaomeng Wu", "Yongqing Sun", "Akisato Kimura"], "title": "Deep Quantigraphic Image Enhancement via Comparametric Equations", "url": "http://arxiv.org/pdf/2304.02285v1", "summary": "Most recent methods of deep image enhancement can be generally classified into two types: decompose-and-enhance and illumination estimation-centric. The former is usually less efficient, and the latter is constrained by a strong assumption regarding image reflectance as the desired enhancement result. To alleviate this constraint while retaining high efficiency, we propose a novel trainable module that diversifies the conversion from the low-light image and illumination map to the enhanced image. It formulates image enhancement as a comparametric equation parameterized by a camera response function and an exposure compensation ratio. By incorporating this module in an illumination estimation-centric DNN, our method improves the flexibility of deep image enhancement, limits the computational burden to illumination estimation, and allows for fully unsupervised learning adaptable to the diverse demands of different tasks.", "published": "2023-04-05T08:14:41Z", "version": 1}, {"aid": "2304.02330", "authors": ["Sanghyeon Kim", "Eunbyung Park"], "title": "SMPConv: Self-moving Point Representations for Continuous Convolution", "url": "http://arxiv.org/pdf/2304.02330v1", "summary": "Continuous convolution has recently gained prominence due to its ability to handle irregularly sampled data and model long-term dependency. Also, the promising experimental results of using large convolutional kernels have catalyzed the development of continuous convolution since they can construct large kernels very efficiently. Leveraging neural networks, more specifically multilayer perceptrons (MLPs), is by far the most prevalent approach to implementing continuous convolution. However, there are a few drawbacks, such as high computational costs, complex hyperparameter tuning, and limited descriptive power of filters. This paper suggests an alternative approach to building a continuous convolution without neural networks, resulting in more computationally efficient and improved performance. We present self-moving point representations where weight parameters freely move, and interpolation schemes are used to implement continuous functions. When applied to construct convolutional kernels, the experimental results have shown improved performance with drop-in replacement in the existing frameworks. Due to its lightweight structure, we are first to demonstrate the effectiveness of continuous convolution in a large-scale setting, e.g., ImageNet, presenting the improvements over the prior arts. Our code is available on https://github.com/sangnekim/SMPConv", "published": "2023-04-05T09:36:30Z", "version": 1}, {"aid": "2304.02658", "authors": ["Umais Zahid", "Qinghai Guo", "Zafeirios Fountas"], "title": "Predictive Coding as a Neuromorphic Alternative to Backpropagation: A Critical Evaluation", "url": "http://arxiv.org/pdf/2304.02658v1", "summary": "Backpropagation has rapidly become the workhorse credit assignment algorithm for modern deep learning methods. Recently, modified forms of predictive coding (PC), an algorithm with origins in computational neuroscience, have been shown to result in approximately or exactly equal parameter updates to those under backpropagation. Due to this connection, it has been suggested that PC can act as an alternative to backpropagation with desirable properties that may facilitate implementation in neuromorphic systems. Here, we explore these claims using the different contemporary PC variants proposed in the literature. We obtain time complexity bounds for these PC variants which we show are lower-bounded by backpropagation. We also present key properties of these variants that have implications for neurobiological plausibility and their interpretations, particularly from the perspective of standard PC as a variational Bayes algorithm for latent probabilistic models. Our findings shed new light on the connection between the two learning frameworks and suggest that, in its current forms, PC may have more limited potential as a direct replacement of backpropagation than previously envisioned.", "published": "2023-04-05T11:48:47Z", "version": 1}, {"aid": "2304.02626", "authors": ["Sergey Prokudin", "Qianli Ma", "Maxime Raafat", "Julien Valentin", "Siyu Tang"], "title": "Dynamic Point Fields", "url": "http://arxiv.org/pdf/2304.02626v2", "summary": "Recent years have witnessed significant progress in the field of neural surface reconstruction. While the extensive focus was put on volumetric and implicit approaches, a number of works have shown that explicit graphics primitives such as point clouds can significantly reduce computational complexity, without sacrificing the reconstructed surface quality. However, less emphasis has been put on modeling dynamic surfaces with point primitives. In this work, we present a dynamic point field model that combines the representational benefits of explicit point-based graphics with implicit deformation networks to allow efficient modeling of non-rigid 3D surfaces. Using explicit surface primitives also allows us to easily incorporate well-established constraints such as-isometric-as-possible regularisation. While learning this deformation model is prone to local optima when trained in a fully unsupervised manner, we propose to additionally leverage semantic information such as keypoint dynamics to guide the deformation learning. We demonstrate our model with an example application of creating an expressive animatable human avatar from a collection of 3D scans. Here, previous methods mostly rely on variants of the linear blend skinning paradigm, which fundamentally limits the expressivity of such models when dealing with complex cloth appearances such as long skirts. We show the advantages of our dynamic point field framework in terms of its representational power, learning efficiency, and robustness to out-of-distribution novel poses.", "published": "2023-04-05T17:52:37Z", "version": 2}, {"aid": "2304.02628", "authors": ["Robert-Jan Bruintjes", "Tomasz Motyka", "Jan van Gemert"], "title": "What Affects Learned Equivariance in Deep Image Recognition Models?", "url": "http://arxiv.org/pdf/2304.02628v2", "summary": "Equivariance w.r.t. geometric transformations in neural networks improves data efficiency, parameter efficiency and robustness to out-of-domain perspective shifts. When equivariance is not designed into a neural network, the network can still learn equivariant functions from the data. We quantify this learned equivariance, by proposing an improved measure for equivariance. We find evidence for a correlation between learned translation equivariance and validation accuracy on ImageNet. We therefore investigate what can increase the learned equivariance in neural networks, and find that data augmentation, reduced model capacity and inductive bias in the form of convolutions induce higher learned equivariance in neural networks.", "published": "2023-04-05T17:54:25Z", "version": 2}, {"aid": "2304.02643", "authors": ["Alexander Kirillov", "Eric Mintun", "Nikhila Ravi", "Hanzi Mao", "Chloe Rolland", "Laura Gustafson", "Tete Xiao", "Spencer Whitehead", "Alexander C. Berg", "Wan-Yen Lo", "Piotr Doll\u00e1r", "Ross Girshick"], "title": "Segment Anything", "url": "http://arxiv.org/pdf/2304.02643v1", "summary": "We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.", "published": "2023-04-05T17:59:46Z", "version": 1}, {"aid": "2304.02695", "authors": ["Zhangyi Cheng", "Xiang Zhang", "Lei Yu", "Jianzhuang Liu", "Wen Yang", "Gui-Song Xia"], "title": "Recovering Continuous Scene Dynamics from A Single Blurry Image with Events", "url": "http://arxiv.org/pdf/2304.02695v1", "summary": "This paper aims at demystifying a single motion-blurred image with events and revealing temporally continuous scene dynamics encrypted behind motion blurs. To achieve this end, an Implicit Video Function (IVF) is learned to represent a single motion blurred image with concurrent events, enabling the latent sharp image restoration of arbitrary timestamps in the range of imaging exposures. Specifically, a dual attention transformer is proposed to efficiently leverage merits from both modalities, i.e., the high temporal resolution of event features and the smoothness of image features, alleviating temporal ambiguities while suppressing the event noise. The proposed network is trained only with the supervision of ground-truth images of limited referenced timestamps. Motion- and texture-guided supervisions are employed simultaneously to enhance restorations of the non-referenced timestamps and improve the overall sharpness. Experiments on synthetic, semi-synthetic, and real-world datasets demonstrate that our proposed method outperforms state-of-the-art methods by a large margin in terms of both objective PSNR and SSIM measurements and subjective evaluations.", "published": "2023-04-05T18:44:17Z", "version": 1}, {"aid": "2304.02847", "authors": ["Jonas Ngnawe", "Marianne Abemgnigni Njifon", "Jonathan Heek", "Yann Dauphin"], "title": "Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets", "url": "http://arxiv.org/pdf/2304.02847v2", "summary": "Deep networks have achieved impressive results on a range of well-curated benchmark datasets. Surprisingly, their performance remains sensitive to perturbations that have little effect on human performance. In this work, we propose a novel extension of Mixup called Robustmix that regularizes networks to classify based on lower-frequency spatial features. We show that this type of regularization improves robustness on a range of benchmarks such as Imagenet-C and Stylized Imagenet. It adds little computational overhead and, furthermore, does not require a priori knowledge of a large set of image transformations. We find that this approach further complements recent advances in model architecture and data augmentation, attaining a state-of-the-art mCE of 44.8 with an EfficientNet-B8 model and RandAugment, which is a reduction of 16 mCE compared to the baseline.", "published": "2023-04-06T03:24:00Z", "version": 2}, {"aid": "2304.02859", "authors": ["Zhengzhong Tu", "Peyman Milanfar", "Hossein Talebi"], "title": "MULLER: Multilayer Laplacian Resizer for Vision", "url": "http://arxiv.org/pdf/2304.02859v1", "summary": "Image resizing operation is a fundamental preprocessing module in modern computer vision. Throughout the deep learning revolution, researchers have overlooked the potential of alternative resizing methods beyond the commonly used resizers that are readily available, such as nearest-neighbors, bilinear, and bicubic. The key question of our interest is whether the front-end resizer affects the performance of deep vision models? In this paper, we present an extremely lightweight multilayer Laplacian resizer with only a handful of trainable parameters, dubbed MULLER resizer. MULLER has a bandpass nature in that it learns to boost details in certain frequency subbands that benefit the downstream recognition models. We show that MULLER can be easily plugged into various training pipelines, and it effectively boosts the performance of the underlying vision task with little to no extra cost. Specifically, we select a state-of-the-art vision Transformer, MaxViT, as the baseline, and show that, if trained with MULLER, MaxViT gains up to 0.6% top-1 accuracy, and meanwhile enjoys 36% inference cost saving to achieve similar top-1 accuracy on ImageNet-1k, as compared to the standard training scheme. Notably, MULLER's performance also scales with model size and training data size such as ImageNet-21k and JFT, and it is widely applicable to multiple vision tasks, including image classification, object detection and segmentation, as well as image quality assessment.", "published": "2023-04-06T04:39:21Z", "version": 1}, {"aid": "2304.02978", "authors": ["Yu Zhang", "Xiaoguang Di", "Junde Wu", "Rao Fu", "Yong Li", "Yue Wang", "Yanwu Xu", "Guohui Yang", "Chunhui Wang"], "title": "Simplifying Low-Light Image Enhancement Networks with Relative Loss Functions", "url": "http://arxiv.org/pdf/2304.02978v2", "summary": "Image enhancement is a common technique used to mitigate issues such as severe noise, low brightness, low contrast, and color deviation in low-light images. However, providing an optimal high-light image as a reference for low-light image enhancement tasks is impossible, which makes the learning process more difficult than other image processing tasks. As a result, although several low-light image enhancement methods have been proposed, most of them are either too complex or insufficient in addressing all the issues in low-light images. In this paper, to make the learning easier in low-light image enhancement, we introduce FLW-Net (Fast and LightWeight Network) and two relative loss functions. Specifically, we first recognize the challenges of the need for a large receptive field to obtain global contrast and the lack of an absolute reference, which limits the simplification of network structures in this task. Then, we propose an efficient global feature information extraction component and two loss functions based on relative information to overcome these challenges. Finally, we conducted comparative experiments to demonstrate the effectiveness of the proposed method, and the results confirm that the proposed method can significantly reduce the complexity of supervised low-light image enhancement networks while improving processing effect. The code is available at \\url{https://github.com/hitzhangyu/FLW-Net}.", "published": "2023-04-06T10:05:54Z", "version": 2}, {"aid": "2304.03156", "authors": ["Sri Charan Kattamuru", "Kshitij Agrawal", "Shyam Prasad Adhikari", "Abhishek Bose", "Hemant Misra"], "title": "Patch-wise Features for Blur Image Classification", "url": "http://arxiv.org/pdf/2304.03156v1", "summary": "Images captured through smartphone cameras often suffer from degradation, blur being one of the major ones, posing a challenge in processing these images for downstream tasks. In this paper we propose low-compute lightweight patch-wise features for image quality assessment. Using our method we can discriminate between blur vs sharp image degradation. To this end, we train a decision-tree based XGBoost model on various intuitive image features like gray level variance, first and second order gradients, texture features like local binary patterns. Experiments conducted on an open dataset show that the proposed low compute method results in 90.1% mean accuracy on the validation set, which is comparable to the accuracy of a compute-intensive VGG16 network with 94% mean accuracy fine-tuned to this task. To demonstrate the generalizability of our proposed features and model we test the model on BHBID dataset and an internal dataset where we attain accuracy of 98% and 91%, respectively. The proposed method is 10x faster than the VGG16 based model on CPU and scales linearly to the input image size making it suitable to be implemented on low compute edge devices.", "published": "2023-04-06T15:39:11Z", "version": 1}, {"aid": "2304.04555", "authors": ["Seongmin Hong", "Se Young Chun"], "title": "Neural Diffeomorphic Non-uniform B-spline Flows", "url": "http://arxiv.org/pdf/2304.04555v2", "summary": "Normalizing flows have been successfully modeling a complex probability distribution as an invertible transformation of a simple base distribution. However, there are often applications that require more than invertibility. For instance, the computation of energies and forces in physics requires the second derivatives of the transformation to be well-defined and continuous. Smooth normalizing flows employ infinitely differentiable transformation, but with the price of slow non-analytic inverse transforms. In this work, we propose diffeomorphic non-uniform B-spline flows that are at least twice continuously differentiable while bi-Lipschitz continuous, enabling efficient parametrization while retaining analytic inverse transforms based on a sufficient condition for diffeomorphism. Firstly, we investigate the sufficient condition for Ck-2-diffeomorphic non-uniform kth-order B-spline transformations. Then, we derive an analytic inverse transformation of the non-uniform cubic B-spline transformation for neural diffeomorphic non-uniform B-spline flows. Lastly, we performed experiments on solving the force matching problem in Boltzmann generators, demonstrating that our C2-diffeomorphic non-uniform B-spline flows yielded solutions better than previous spline flows and faster than smooth normalizing flows. Our source code is publicly available at https://github.com/smhongok/Non-uniform-B-spline-Flow.", "published": "2023-04-07T05:34:18Z", "version": 2}, {"aid": "2304.03486", "authors": ["Subin Sahayam", "John Zakkam", "Umarani Jayaraman"], "title": "Can we learn better with hard samples?", "url": "http://arxiv.org/pdf/2304.03486v1", "summary": "In deep learning, mini-batch training is commonly used to optimize network parameters. However, the traditional mini-batch method may not learn the under-represented samples and complex patterns in the data, leading to a longer time for generalization. To address this problem, a variant of the traditional algorithm has been proposed, which trains the network focusing on mini-batches with high loss. The study evaluates the effectiveness of the proposed training using various deep neural networks trained on three benchmark datasets (CIFAR-10, CIFAR-100, and STL-10). The deep neural networks used in the study are ResNet-18, ResNet-50, Efficient Net B4, EfficientNetV2-S, and MobilenetV3-S. The experimental results showed that the proposed method can significantly improve the test accuracy and speed up the convergence compared to the traditional mini-batch training method. Furthermore, we introduce a hyper-parameter delta ({\\delta}) that decides how many mini-batches are considered for training. Experiments on various values of {\\delta} found that the performance of the proposed method for smaller {\\delta} values generally results in similar test accuracy and faster generalization. We show that the proposed method generalizes in 26.47% less number of epochs than the traditional mini-batch method in EfficientNet-B4 on STL-10. The proposed method also improves the test top-1 accuracy by 7.26% in ResNet-18 on CIFAR-100.", "published": "2023-04-07T05:45:26Z", "version": 1}, {"aid": "2304.03532", "authors": ["Xinshun Wang", "Qiongjie Cui", "Chen Chen", "Shen Zhao", "Mengyuan Liu"], "title": "Graph-Guided MLP-Mixer for Skeleton-Based Human Motion Prediction", "url": "http://arxiv.org/pdf/2304.03532v2", "summary": "In recent years, Graph Convolutional Networks (GCNs) have been widely used in human motion prediction, but their performance remains unsatisfactory. Recently, MLP-Mixer, initially developed for vision tasks, has been leveraged into human motion prediction as a promising alternative to GCNs, which achieves both better performance and better efficiency than GCNs. Unlike GCNs, which can explicitly capture human skeleton's bone-joint structure by representing it as a graph with edges and nodes, MLP-Mixer relies on fully connected layers and thus cannot explicitly model such graph-like structure of human's. To break this limitation of MLP-Mixer's, we propose \\textit{Graph-Guided Mixer}, a novel approach that equips the original MLP-Mixer architecture with the capability to model graph structure. By incorporating graph guidance, our \\textit{Graph-Guided Mixer} can effectively capture and utilize the specific connectivity patterns within human skeleton's graph representation. In this paper, first we uncover a theoretical connection between MLP-Mixer and GCN that is unexplored in existing research. Building on this theoretical connection, next we present our proposed \\textit{Graph-Guided Mixer}, explaining how the original MLP-Mixer architecture is reinvented to incorporate guidance from graph structure. Then we conduct an extensive evaluation on the Human3.6M, AMASS, and 3DPW datasets, which shows that our method achieves state-of-the-art performance.", "published": "2023-04-07T08:11:16Z", "version": 2}, {"aid": "2304.03720", "authors": ["Peyman Morteza"], "title": "Representer Theorems for Metric and Preference Learning: A Geometric Perspective", "url": "http://arxiv.org/pdf/2304.03720v1", "summary": "We explore the metric and preference learning problem in Hilbert spaces. We obtain a novel representer theorem for the simultaneous task of metric and preference learning. Our key observation is that the representer theorem can be formulated with respect to the norm induced by the inner product inherent in the problem structure. Additionally, we demonstrate how our framework can be applied to the task of metric learning from triplet comparisons and show that it leads to a simple and self-contained representer theorem for this task. In the case of Reproducing Kernel Hilbert Spaces (RKHS), we demonstrate that the solution to the learning problem can be expressed using kernel terms, akin to classical representer theorems.", "published": "2023-04-07T16:34:25Z", "version": 1}, {"aid": "2304.03937", "authors": ["Yulin Liu", "Haoran Liu", "Yingda Yin", "Yang Wang", "Baoquan Chen", "He Wang"], "title": "Delving into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling", "url": "http://arxiv.org/pdf/2304.03937v1", "summary": "Normalizing flows (NFs) provide a powerful tool to construct an expressive distribution by a sequence of trackable transformations of a base distribution and form a probabilistic model of underlying data. Rotation, as an important quantity in computer vision, graphics, and robotics, can exhibit many ambiguities when occlusion and symmetry occur and thus demands such probabilistic models. Though much progress has been made for NFs in Euclidean space, there are no effective normalizing flows without discontinuity or many-to-one mapping tailored for SO(3) manifold. Given the unique non-Euclidean properties of the rotation manifold, adapting the existing NFs to SO(3) manifold is non-trivial. In this paper, we propose a novel normalizing flow on SO(3) by combining a Mobius transformation-based coupling layer and a quaternion affine transformation. With our proposed rotation normalizing flows, one can not only effectively express arbitrary distributions on SO(3), but also conditionally build the target distribution given input observations. Extensive experiments show that our rotation normalizing flows significantly outperform the baselines on both unconditional and conditional tasks.", "published": "2023-04-08T06:52:02Z", "version": 1}, {"aid": "2304.04048", "authors": ["Maxim Khomiakov", "Michael Riis Andersen", "Jes Frellsen"], "title": "Polygonizer: An auto-regressive building delineator", "url": "http://arxiv.org/pdf/2304.04048v1", "summary": "In geospatial planning, it is often essential to represent objects in a vectorized format, as this format easily translates to downstream tasks such as web development, graphics, or design. While these problems are frequently addressed using semantic segmentation, which requires additional post-processing to vectorize objects in a non-trivial way, we present an Image-to-Sequence model that allows for direct shape inference and is ready for vector-based workflows out of the box. We demonstrate the model's performance in various ways, including perturbations to the image input that correspond to variations or artifacts commonly encountered in remote sensing applications. Our model outperforms prior works when using ground truth bounding boxes (one object per image), achieving the lowest maximum tangent angle error.", "published": "2023-04-08T15:36:48Z", "version": 1}, {"aid": "2304.04271", "authors": ["Karan Aggarwal", "Jaideep Srivastava"], "title": "Embarrassingly Simple MixUp for Time-series", "url": "http://arxiv.org/pdf/2304.04271v1", "summary": "Labeling time series data is an expensive task because of domain expertise and dynamic nature of the data. Hence, we often have to deal with limited labeled data settings. Data augmentation techniques have been successfully deployed in domains like computer vision to exploit the use of existing labeled data. We adapt one of the most commonly used technique called MixUp, in the time series domain. Our proposed, MixUp++ and LatentMixUp++, use simple modifications to perform interpolation in raw time series and classification model's latent space, respectively. We also extend these methods with semi-supervised learning to exploit unlabeled data. We observe significant improvements of 1\\% - 15\\% on time series classification on two public datasets, for both low labeled data as well as high labeled data regimes, with LatentMixUp++.", "published": "2023-04-09T16:34:06Z", "version": 1}, {"aid": "2304.05361", "authors": ["Yusheng Huang", "Jiexing Qi", "Xinbing Wang", "Zhouhan Lin"], "title": "Asymmetric Polynomial Loss For Multi-Label Classification", "url": "http://arxiv.org/pdf/2304.05361v1", "summary": "Various tasks are reformulated as multi-label classification problems, in which the binary cross-entropy (BCE) loss is frequently utilized for optimizing well-designed models. However, the vanilla BCE loss cannot be tailored for diverse tasks, resulting in a suboptimal performance for different models. Besides, the imbalance between redundant negative samples and rare positive samples could degrade the model performance. In this paper, we propose an effective Asymmetric Polynomial Loss (APL) to mitigate the above issues. Specifically, we first perform Taylor expansion on BCE loss. Then we ameliorate the coefficients of polynomial functions. We further employ the asymmetric focusing mechanism to decouple the gradient contribution from the negative and positive samples. Moreover, we validate that the polynomial coefficients can recalibrate the asymmetric focusing hyperparameters. Experiments on relation extraction, text classification, and image classification show that our APL loss can consistently improve performance without extra training burden.", "published": "2023-04-10T14:35:47Z", "version": 1}, {"aid": "2304.04820", "authors": ["Ze Wang", "Jiang Wang", "Zicheng Liu", "Qiang Qiu"], "title": "Binary Latent Diffusion", "url": "http://arxiv.org/pdf/2304.04820v1", "summary": "In this paper, we show that a binary latent space can be explored for compact yet expressive image representations. We model the bi-directional mappings between an image and the corresponding latent binary representation by training an auto-encoder with a Bernoulli encoding distribution. On the one hand, the binary latent space provides a compact discrete image representation of which the distribution can be modeled more efficiently than pixels or continuous latent representations. On the other hand, we now represent each image patch as a binary vector instead of an index of a learned cookbook as in discrete image representations with vector quantization. In this way, we obtain binary latent representations that allow for better image quality and high-resolution image representations without any multi-stage hierarchy in the latent space. In this binary latent space, images can now be generated effectively using a binary latent diffusion model tailored specifically for modeling the prior over the binary image representations. We present both conditional and unconditional image generation experiments with multiple datasets, and show that the proposed method performs comparably to state-of-the-art methods while dramatically improving the sampling efficiency to as few as 16 steps without using any test-time acceleration. The proposed framework can also be seamlessly scaled to $1024 \\times 1024$ high-resolution image generation without resorting to latent hierarchy or multi-stage refinements.", "published": "2023-04-10T19:03:28Z", "version": 1}, {"aid": "2304.04824", "authors": ["Hanjing Wang", "Dhiraj Joshi", "Shiqiang Wang", "Qiang Ji"], "title": "Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning", "url": "http://arxiv.org/pdf/2304.04824v1", "summary": "Predictions made by deep learning models are prone to data perturbations, adversarial attacks, and out-of-distribution inputs. To build a trusted AI system, it is therefore critical to accurately quantify the prediction uncertainties. While current efforts focus on improving uncertainty quantification accuracy and efficiency, there is a need to identify uncertainty sources and take actions to mitigate their effects on predictions. Therefore, we propose to develop explainable and actionable Bayesian deep learning methods to not only perform accurate uncertainty quantification but also explain the uncertainties, identify their sources, and propose strategies to mitigate the uncertainty impacts. Specifically, we introduce a gradient-based uncertainty attribution method to identify the most problematic regions of the input that contribute to the prediction uncertainty. Compared to existing methods, the proposed UA-Backprop has competitive accuracy, relaxed assumptions, and high efficiency. Moreover, we propose an uncertainty mitigation strategy that leverages the attribution results as attention to further improve the model performance. Both qualitative and quantitative evaluations are conducted to demonstrate the effectiveness of our proposed methods.", "published": "2023-04-10T19:14:15Z", "version": 1}, {"aid": "2304.04970", "authors": ["Cheng Xin", "Soham Mukherjee", "Shreyas N. Samaga", "Tamal K. Dey"], "title": "GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning", "url": "http://arxiv.org/pdf/2304.04970v2", "summary": "$1$-parameter persistent homology, a cornerstone in Topological Data Analysis (TDA), studies the evolution of topological features such as connected components and cycles hidden in data. It has been applied to enhance the representation power of deep learning models, such as Graph Neural Networks (GNNs). To enrich the representations of topological features, here we propose to study $2$-parameter persistence modules induced by bi-filtration functions. In order to incorporate these representations into machine learning models, we introduce a novel vector representation called Generalized Rank Invariant Landscape (GRIL) for $2$-parameter persistence modules. We show that this vector representation is $1$-Lipschitz stable and differentiable with respect to underlying filtration functions and can be easily integrated into machine learning models to augment encoding topological features. We present an algorithm to compute the vector representation efficiently. We also test our methods on synthetic and benchmark graph datasets, and compare the results with previous vector representations of $1$-parameter and $2$-parameter persistence modules. Further, we augment GNNs with GRIL features and observe an increase in performance indicating that GRIL can capture additional features enriching GNNs. We make the complete code for the proposed method available at https://github.com/soham0209/mpml-graph.", "published": "2023-04-11T04:30:58Z", "version": 2}, {"aid": "2304.05055", "authors": ["Wei Ju", "Zheng Fang", "Yiyang Gu", "Zequn Liu", "Qingqing Long", "Ziyue Qiao", "Yifang Qin", "Jianhao Shen", "Fang Sun", "Zhiping Xiao", "Junwei Yang", "Jingyang Yuan", "Yusheng Zhao", "Yifan Wang", "Xiao Luo", "Ming Zhang"], "title": "A Comprehensive Survey on Deep Graph Representation Learning", "url": "http://arxiv.org/pdf/2304.05055v3", "summary": "Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages over shallow (traditional) methods, there exist a large number of deep graph representation learning techniques have been proposed in the past decade, especially graph neural networks. In this survey, we conduct a comprehensive survey on current deep graph representation learning algorithms by proposing a new taxonomy of existing state-of-the-art literature. Specifically, we systematically summarize the essential components of graph representation learning and categorize existing approaches by the ways of graph neural network architectures and the most recent advanced learning paradigms. Moreover, this survey also provides the practical and promising applications of deep graph representation learning. Last but not least, we state new perspectives and suggest challenging directions which deserve further investigations in the future.", "published": "2023-04-11T08:23:52Z", "version": 3}, {"aid": "2304.05077", "authors": ["Johannes Kleiner", "Tim Ludwig"], "title": "If consciousness is dynamically relevant, artificial intelligence isn't conscious", "url": "http://arxiv.org/pdf/2304.05077v2", "summary": "We demonstrate that if consciousness is relevant for the temporal evolution of a system's states--that is, if it is dynamically relevant--then AI systems cannot be conscious. That is because AI systems run on CPUs, GPUs, TPUs or other processors which have been designed and verified to adhere to computational dynamics that systematically preclude or suppress deviations. The design and verification preclude or suppress, in particular, potential consciousness-related dynamical effects, so that if consciousness is dynamically relevant, AI systems cannot be conscious.", "published": "2023-04-11T09:21:17Z", "version": 2}, {"aid": "2304.05187", "authors": ["Jeremy Bernstein", "Chris Mingard", "Kevin Huang", "Navid Azizan", "Yisong Yue"], "title": "Automatic Gradient Descent: Deep Learning without Hyperparameters", "url": "http://arxiv.org/pdf/2304.05187v1", "summary": "The architecture of a deep neural network is defined explicitly in terms of the number of layers, the width of each layer and the general network topology. Existing optimisation frameworks neglect this information in favour of implicit architectural information (e.g. second-order methods) or architecture-agnostic distance functions (e.g. mirror descent). Meanwhile, the most popular optimiser in practice, Adam, is based on heuristics. This paper builds a new framework for deriving optimisation algorithms that explicitly leverage neural architecture. The theory extends mirror descent to non-convex composite objective functions: the idea is to transform a Bregman divergence to account for the non-linear structure of neural architecture. Working through the details for deep fully-connected networks yields automatic gradient descent: a first-order optimiser without any hyperparameters. Automatic gradient descent trains both fully-connected and convolutional networks out-of-the-box and at ImageNet scale. A PyTorch implementation is available at https://github.com/jxbz/agd and also in Appendix B. Overall, the paper supplies a rigorous theoretical foundation for a next-generation of architecture-dependent optimisers that work automatically and without hyperparameters.", "published": "2023-04-11T12:45:52Z", "version": 1}, {"aid": "2304.05310", "authors": ["Qunxi Zhu", "Yao Guo", "Wei Lin"], "title": "Neural Delay Differential Equations: System Reconstruction and Image Classification", "url": "http://arxiv.org/pdf/2304.05310v1", "summary": "Neural Ordinary Differential Equations (NODEs), a framework of continuous-depth neural networks, have been widely applied, showing exceptional efficacy in coping with representative datasets. Recently, an augmented framework has been developed to overcome some limitations that emerged in the application of the original framework. In this paper, we propose a new class of continuous-depth neural networks with delay, named Neural Delay Differential Equations (NDDEs). To compute the corresponding gradients, we use the adjoint sensitivity method to obtain the delayed dynamics of the adjoint. Differential equations with delays are typically seen as dynamical systems of infinite dimension that possess more fruitful dynamics. Compared to NODEs, NDDEs have a stronger capacity of nonlinear representations. We use several illustrative examples to demonstrate this outstanding capacity. Firstly, we successfully model the delayed dynamics where the trajectories in the lower-dimensional phase space could be mutually intersected and even chaotic in a model-free or model-based manner. Traditional NODEs, without any argumentation, are not directly applicable for such modeling. Secondly, we achieve lower loss and higher accuracy not only for the data produced synthetically by complex models but also for the CIFAR10, a well-known image dataset. Our results on the NDDEs demonstrate that appropriately articulating the elements of dynamical systems into the network design is truly beneficial in promoting network performance.", "published": "2023-04-11T16:09:28Z", "version": 1}, {"aid": "2304.05676", "authors": ["Gr\u00e9gory Faye", "Guilhem Fouilh\u00e9", "Rufin VanRullen"], "title": "Mathematical derivation of wave propagation properties in hierarchical neural networks with predictive coding feedback dynamics", "url": "http://arxiv.org/pdf/2304.05676v1", "summary": "Sensory perception (e.g. vision) relies on a hierarchy of cortical areas, in which neural activity propagates in both directions, to convey information not only about sensory inputs but also about cognitive states, expectations and predictions. At the macroscopic scale, neurophysiological experiments have described the corresponding neural signals as both forward and backward-travelling waves, sometimes with characteristic oscillatory signatures. It remains unclear, however, how such activity patterns relate to specific functional properties of the perceptual apparatus. Here, we present a mathematical framework, inspired by neural network models of predictive coding, to systematically investigate neural dynamics in a hierarchical perceptual system. We show that stability of the system can be systematically derived from the values of hyper-parameters controlling the different signals (related to bottom-up inputs, top-down prediction and error correction). Similarly, it is possible to determine in which direction, and at what speed neural activity propagates in the system. Different neural assemblies (reflecting distinct eigenvectors of the connectivity matrices) can simultaneously and independently display different properties in terms of stability, propagation speed or direction. We also derive continuous-limit versions of the system, both in time and in neural space. Finally, we analyze the possible influence of transmission delays between layers, and reveal the emergence of oscillations at biologically plausible frequencies.", "published": "2023-04-12T07:53:22Z", "version": 1}, {"aid": "2304.05864", "authors": ["Thomas Wimmer", "Vladimir Golkov", "Hoai Nam Dang", "Moritz Zaiss", "Andreas Maier", "Daniel Cremers"], "title": "Scale-Equivariant Deep Learning for 3D Data", "url": "http://arxiv.org/pdf/2304.05864v1", "summary": "The ability of convolutional neural networks (CNNs) to recognize objects regardless of their position in the image is due to the translation-equivariance of the convolutional operation. Group-equivariant CNNs transfer this equivariance to other transformations of the input. Dealing appropriately with objects and object parts of different scale is challenging, and scale can vary for multiple reasons such as the underlying object size or the resolution of the imaging modality. In this paper, we propose a scale-equivariant convolutional network layer for three-dimensional data that guarantees scale-equivariance in 3D CNNs. Scale-equivariance lifts the burden of having to learn each possible scale separately, allowing the neural network to focus on higher-level learning goals, which leads to better results and better data-efficiency. We provide an overview of the theoretical foundations and scientific work on scale-equivariant neural networks in the two-dimensional domain. We then transfer the concepts from 2D to the three-dimensional space and create a scale-equivariant convolutional layer for 3D data. Using the proposed scale-equivariant layer, we create a scale-equivariant U-Net for medical image segmentation and compare it with a non-scale-equivariant baseline method. Our experiments demonstrate the effectiveness of the proposed method in achieving scale-equivariance for 3D medical image analysis. We publish our code at https://github.com/wimmerth/scale-equivariant-3d-convnet for further research and application.", "published": "2023-04-12T13:56:12Z", "version": 1}, {"aid": "2304.05919", "authors": ["Haochen Wang", "Kaiyou Song", "Junsong Fan", "Yuxi Wang", "Jin Xie", "Zhaoxiang Zhang"], "title": "Hard Patches Mining for Masked Image Modeling", "url": "http://arxiv.org/pdf/2304.05919v1", "summary": "Masked image modeling (MIM) has attracted much research attention due to its promising potential for learning scalable visual representations. In typical approaches, models usually focus on predicting specific contents of masked patches, and their performances are highly related to pre-defined mask strategies. Intuitively, this procedure can be considered as training a student (the model) on solving given problems (predict masked patches). However, we argue that the model should not only focus on solving given problems, but also stand in the shoes of a teacher to produce a more challenging problem by itself. To this end, we propose Hard Patches Mining (HPM), a brand-new framework for MIM pre-training. We observe that the reconstruction loss can naturally be the metric of the difficulty of the pre-training task. Therefore, we introduce an auxiliary loss predictor, predicting patch-wise losses first and deciding where to mask next. It adopts a relative relationship learning strategy to prevent overfitting to exact reconstruction loss values. Experiments under various settings demonstrate the effectiveness of HPM in constructing masked images. Furthermore, we empirically find that solely introducing the loss prediction objective leads to powerful representations, verifying the efficacy of the ability to be aware of where is hard to reconstruct.", "published": "2023-04-12T15:38:23Z", "version": 1}, {"aid": "2304.05939", "authors": ["Gustav Bredell", "Kyriakos Flouris", "Krishna Chaitanya", "Ertunc Erdil", "Ender Konukoglu"], "title": "Explicitly Minimizing the Blur Error of Variational Autoencoders", "url": "http://arxiv.org/pdf/2304.05939v1", "summary": "Variational autoencoders (VAEs) are powerful generative modelling methods, however they suffer from blurry generated samples and reconstructions compared to the images they have been trained on. Significant research effort has been spent to increase the generative capabilities by creating more flexible models but often flexibility comes at the cost of higher complexity and computational cost. Several works have focused on altering the reconstruction term of the evidence lower bound (ELBO), however, often at the expense of losing the mathematical link to maximizing the likelihood of the samples under the modeled distribution. Here we propose a new formulation of the reconstruction term for the VAE that specifically penalizes the generation of blurry images while at the same time still maximizing the ELBO under the modeled distribution. We show the potential of the proposed loss on three different data sets, where it outperforms several recently proposed reconstruction losses for VAEs.", "published": "2023-04-12T16:03:36Z", "version": 1}, {"aid": "2304.06729", "authors": ["Marcel Binz", "Ishita Dasgupta", "Akshay Jagadish", "Matthew Botvinick", "Jane X. Wang", "Eric Schulz"], "title": "Meta-Learned Models of Cognition", "url": "http://arxiv.org/pdf/2304.06729v1", "summary": "Meta-learning is a framework for learning learning algorithms through repeated interactions with an environment as opposed to designing them by hand. In recent years, this framework has established itself as a promising tool for building models of human cognition. Yet, a coherent research program around meta-learned models of cognition is still missing. The purpose of this article is to synthesize previous work in this field and establish such a research program. We rely on three key pillars to accomplish this goal. We first point out that meta-learning can be used to construct Bayes-optimal learning algorithms. This result not only implies that any behavioral phenomenon that can be explained by a Bayesian model can also be explained by a meta-learned model but also allows us to draw strong connections to the rational analysis of cognition. We then discuss several advantages of the meta-learning framework over traditional Bayesian methods. In particular, we argue that meta-learning can be applied to situations where Bayesian inference is impossible and that it enables us to make rational models of cognition more realistic, either by incorporating limited computational resources or neuroscientific knowledge. Finally, we reexamine prior studies from psychology and neuroscience that have applied meta-learning and put them into the context of these new insights. In summary, our work highlights that meta-learning considerably extends the scope of rational analysis and thereby of cognitive theories more generally.", "published": "2023-04-12T16:30:51Z", "version": 1}, {"aid": "2304.06345", "authors": ["Shanshan Zhong", "Zhongzhan Huang", "Wushao Wen", "Jinghui Qin", "Liang Lin"], "title": "ASR: Attention-alike Structural Re-parameterization", "url": "http://arxiv.org/pdf/2304.06345v3", "summary": "The structural re-parameterization (SRP) technique is a novel deep learning technique that achieves interconversion between different network architectures through equivalent parameter transformations. This technique enables the mitigation of the extra costs for performance improvement during training, such as parameter size and inference time, through these transformations during inference, and therefore SRP has great potential for industrial and practical applications. The existing SRP methods have successfully considered many commonly used architectures, such as normalizations, pooling methods, and multi-branch convolution. However, the widely used attention modules which drastically slow inference speed cannot be directly implemented by SRP due to these modules usually act on the backbone network in a multiplicative manner and the modules' output is input-dependent during inference, which limits the application scenarios of SRP. In this paper, we conduct extensive experiments from a statistical perspective and discover an interesting phenomenon Stripe Observation, which reveals that channel attention values quickly approach some constant vectors during training. This observation inspires us to propose a simple-yet-effective attention-alike structural re-parameterization (ASR) that allows us to achieve SRP for a given network while enjoying the effectiveness of the attention mechanism. Extensive experiments conducted on several standard benchmarks demonstrate the effectiveness of ASR in generally improving the performance of existing backbone networks, attention modules, and SRP methods without any elaborated model crafting. We also analyze the limitations and provide experimental and theoretical evidence for the strong robustness of the proposed ASR.", "published": "2023-04-13T08:52:34Z", "version": 3}, {"aid": "2304.06670", "authors": ["Chris Mingard", "Henry Rees", "Guillermo Valle-P\u00e9rez", "Ard A. Louis"], "title": "Deep neural networks have an inbuilt Occam's razor", "url": "http://arxiv.org/pdf/2304.06670v2", "summary": "The remarkable performance of overparameterized deep neural networks (DNNs) must arise from an interplay between network architecture, training algorithms, and structure in the data. To disentangle these three components, we apply a Bayesian picture, based on the functions expressed by a DNN, to supervised learning. The prior over functions is determined by the network, and is varied by exploiting a transition between ordered and chaotic regimes. For Boolean function classification, we approximate the likelihood using the error spectrum of functions on data. When combined with the prior, this accurately predicts the posterior, measured for DNNs trained with stochastic gradient descent. This analysis reveals that structured data, combined with an intrinsic Occam's razor-like inductive bias towards (Kolmogorov) simple functions that is strong enough to counteract the exponential growth of the number of functions with complexity, is a key to the success of DNNs.", "published": "2023-04-13T16:58:21Z", "version": 2}, {"aid": "2304.09751", "authors": ["Yichun Li", "Yi Li", "Rajesh Nair", "Syed Mohsen Naqvi"], "title": "Skeleton-based action analysis for ADHD diagnosis", "url": "http://arxiv.org/pdf/2304.09751v1", "summary": "Attention Deficit Hyperactivity Disorder (ADHD) is a common neurobehavioral disorder worldwide. While extensive research has focused on machine learning methods for ADHD diagnosis, most research relies on high-cost equipment, e.g., MRI machine and EEG patch. Therefore, low-cost diagnostic methods based on the action characteristics of ADHD are desired. Skeleton-based action recognition has gained attention due to the action-focused nature and robustness. In this work, we propose a novel ADHD diagnosis system with a skeleton-based action recognition framework, utilizing a real multi-modal ADHD dataset and state-of-the-art detection algorithms. Compared to conventional methods, the proposed method shows cost-efficiency and significant performance improvement, making it more accessible for a broad range of initial ADHD diagnoses. Through the experiment results, the proposed method outperforms the conventional methods in accuracy and AUC. Meanwhile, our method is widely applicable for mass screening.", "published": "2023-04-14T13:07:27Z", "version": 1}, {"aid": "2304.07689", "authors": ["Zhiyuan Li", "Ziru Liu", "Anna Zou", "Anca L. Ralescu"], "title": "Learning Empirical Bregman Divergence for Uncertain Distance Representation", "url": "http://arxiv.org/pdf/2304.07689v3", "summary": "Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognition problems.", "published": "2023-04-16T04:16:28Z", "version": 3}, {"aid": "2304.08914", "authors": ["Peifeng Gao", "Qianqian Xu", "Peisong Wen", "Huiyang Shao", "Zhiyong Yang", "Qingming Huang"], "title": "A Study of Neural Collapse Phenomenon: Grassmannian Frame, Symmetry and Generalization", "url": "http://arxiv.org/pdf/2304.08914v2", "summary": "In this paper, we extend original Neural Collapse Phenomenon by proving Generalized Neural Collapse hypothesis. We obtain Grassmannian Frame structure from the optimization and generalization of classification. This structure maximally separates features of every two classes on a sphere and does not require a larger feature dimension than the number of classes. Out of curiosity about the symmetry of Grassmannian Frame, we conduct experiments to explore if models with different Grassmannian Frames have different performance. As a result, we discover the Symmetric Generalization phenomenon. We provide a theorem to explain Symmetric Generalization of permutation. However, the question of why different directions of features can lead to such different generalization is still open for future investigation.", "published": "2023-04-18T11:35:14Z", "version": 2}, {"aid": "2304.09276", "authors": ["Jo\u00e3o Flach", "Alvaro F. Moreira", "Luis C. Lamb"], "title": "Towards a Neural Lambda Calculus: Neurosymbolic AI Applied to the Foundations of Functional Programming", "url": "http://arxiv.org/pdf/2304.09276v2", "summary": "Over the last decades, deep neural networks based-models became the dominant paradigm in machine learning. Further, the use of artificial neural networks in symbolic learning has been seen as increasingly relevant recently. To study the capabilities of neural networks in the symbolic AI domain, researchers have explored the ability of deep neural networks to learn mathematical constructions, such as addition and multiplication, logic inference, such as theorem provers, and even the execution of computer programs. The latter is known to be too complex a task for neural networks. Therefore, the results were not always successful, and often required the introduction of biased elements in the learning process, in addition to restricting the scope of possible programs to be executed. In this work, we will analyze the ability of neural networks to learn how to execute programs as a whole. To do so, we propose a different approach. Instead of using an imperative programming language, with complex structures, we use the Lambda Calculus ({\\lambda}-Calculus), a simple, but Turing-Complete mathematical formalism, which serves as the basis for modern functional programming languages and is at the heart of computability theory. We will introduce the use of integrated neural learning and lambda calculi formalization. Finally, we explore execution of a program in {\\lambda}-Calculus is based on reductions, we will show that it is enough to learn how to perform these reductions so that we can execute any program. Keywords: Machine Learning, Lambda Calculus, Neurosymbolic AI, Neural Networks, Transformer Model, Sequence-to-Sequence Models, Computational Models", "published": "2023-04-18T20:30:16Z", "version": 2}, {"aid": "2304.09856", "authors": ["Xianbiao Qi", "Jianan Wang", "Yihao Chen", "Yukai Shi", "Lei Zhang"], "title": "LipsFormer: Introducing Lipschitz Continuity to Vision Transformers", "url": "http://arxiv.org/pdf/2304.09856v1", "summary": "We present a Lipschitz continuous Transformer, called LipsFormer, to pursue training stability both theoretically and empirically for Transformer-based models. In contrast to previous practical tricks that address training instability by learning rate warmup, layer normalization, attention formulation, and weight initialization, we show that Lipschitz continuity is a more essential property to ensure training stability. In LipsFormer, we replace unstable Transformer component modules with Lipschitz continuous counterparts: CenterNorm instead of LayerNorm, spectral initialization instead of Xavier initialization, scaled cosine similarity attention instead of dot-product attention, and weighted residual shortcut. We prove that these introduced modules are Lipschitz continuous and derive an upper bound on the Lipschitz constant of LipsFormer. Our experiments show that LipsFormer allows stable training of deep Transformer architectures without the need of careful learning rate tuning such as warmup, yielding a faster convergence and better generalization. As a result, on the ImageNet 1K dataset, LipsFormer-Swin-Tiny based on Swin Transformer training for 300 epochs can obtain 82.7\\% without any learning rate warmup. Moreover, LipsFormer-CSwin-Tiny, based on CSwin, training for 300 epochs achieves a top-1 accuracy of 83.5\\% with 4.7G FLOPs and 24M parameters. The code will be released at \\url{https://github.com/IDEA-Research/LipsFormer}.", "published": "2023-04-19T17:59:39Z", "version": 1}, {"aid": "2304.13534", "authors": ["Benjamin J. Zhang", "Markos A. Katsoulakis"], "title": "A mean-field games laboratory for generative modeling", "url": "http://arxiv.org/pdf/2304.13534v5", "summary": "We demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. In generative flows, a Lagrangian formulation is used where each particle (generated sample) aims to minimize a loss function over its simulated path. The loss, however, is dependent on the paths of other particles, which leads to a competition among the population of particles. The asymptotic behavior of this competition yields a mean-field game. We establish connections between MFGs and major classes of generative flows and diffusions including continuous-time normalizing flows, score-based generative models (SGM), and Wasserstein gradient flows. Furthermore, we study the mathematical properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled forward-backward nonlinear partial differential equations. The mathematical structure described by the MFG optimality conditions identifies the inductive biases of generative flows. We investigate the well-posedness and structure of normalizing flows, unravel the mathematical structure of SGMs, and derive a MFG formulation of Wasserstein gradient flows. From an algorithmic perspective, the optimality conditions yields Hamilton-Jacobi-Bellman (HJB) regularizers for enhanced training of generative models. In particular, we propose and demonstrate an HJB-regularized SGM with improved performance over standard SGMs. We present this framework as an MFG laboratory which serves as a platform for revealing new avenues of experimentation and invention of generative models.", "published": "2023-04-26T13:08:50Z", "version": 5}, {"aid": "2306.01804", "authors": ["Felipe Nuti", "Tim Franzmeyer", "Jo\u00e3o F. Henriques"], "title": "Extracting Reward Functions from Diffusion Models", "url": "http://arxiv.org/pdf/2306.01804v2", "summary": "Diffusion models have achieved remarkable results in image generation, and have similarly been used to learn high-performing policies in sequential decision-making tasks. Decision-making diffusion models can be trained on lower-quality data, and then be steered with a reward function to generate near-optimal trajectories. We consider the problem of extracting a reward function by comparing a decision-making diffusion model that models low-reward behavior and one that models high-reward behavior; a setting related to inverse reinforcement learning. We first define the notion of a relative reward function of two diffusion models and show conditions under which it exists and is unique. We then devise a practical learning algorithm for extracting it by aligning the gradients of a reward function -- parametrized by a neural network -- to the difference in outputs of both diffusion models. Our method finds correct reward functions in navigation environments, and we demonstrate that steering the base model with the learned reward functions results in significantly increased performance in standard locomotion benchmarks. Finally, we demonstrate that our approach generalizes beyond sequential decision-making by learning a reward-like function from two large-scale image generation diffusion models. The extracted reward function successfully assigns lower rewards to harmful images.", "published": "2023-06-01T17:59:12Z", "version": 2}, {"aid": "2307.01050", "authors": ["Francisco Vargas", "Shreyas Padhy", "Denis Blessing", "Nikolas N\u00fcsken"], "title": "Transport meets Variational Inference: Controlled Monte Carlo Diffusions", "url": "http://arxiv.org/pdf/2307.01050v12", "summary": "Connecting optimal transport and variational inference, we present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of the \\emph{Controlled Monte Carlo Diffusion} sampler (CMCD) for Bayesian computation, a score-based annealing technique that crucially adapts both forward and backward dynamics in a diffusion model. On the way, we clarify the relationship between the EM-algorithm and iterative proportional fitting (IPF) for Schr{\\\"o}dinger bridges, deriving as well a regularised objective that bypasses the iterative bottleneck of standard IPF-updates. Finally, we show that CMCD has a strong foundation in the Jarzinsky and Crooks identities from statistical physics, and that it convincingly outperforms competing approaches across a wide array of experiments.", "published": "2023-07-03T14:28:36Z", "version": 12}, {"aid": "2309.14405", "authors": ["Yuan Gong", "Alexander H. Liu", "Hongyin Luo", "Leonid Karlinsky", "James Glass"], "title": "Joint Audio and Speech Understanding", "url": "http://arxiv.org/pdf/2309.14405v3", "summary": "Humans are surrounded by audio signals that include both speech and non-speech sounds. The recognition and understanding of speech and non-speech audio events, along with a profound comprehension of the relationship between them, constitute fundamental cognitive capabilities. For the first time, we build a machine learning model, called LTU-AS, that has a conceptually similar universal audio perception and advanced reasoning ability. Specifically, by integrating Whisper as a perception module and LLaMA as a reasoning module, LTU-AS can simultaneously recognize and jointly understand spoken text, speech paralinguistics, and non-speech audio events - almost everything perceivable from audio signals.", "published": "2023-09-25T17:59:05Z", "version": 3}, {"aid": "2309.16948", "authors": ["Linqi Zhou", "Aaron Lou", "Samar Khanna", "Stefano Ermon"], "title": "Denoising Diffusion Bridge Models", "url": "http://arxiv.org/pdf/2309.16948v3", "summary": "Diffusion models are powerful generative models that map noise to data using stochastic processes. However, for many applications such as image editing, the model input comes from a distribution that is not random noise. As such, diffusion models must rely on cumbersome methods like guidance or projected sampling to incorporate this information in the generative process. In our work, we propose Denoising Diffusion Bridge Models (DDBMs), a natural alternative to this paradigm based on diffusion bridges, a family of processes that interpolate between two paired distributions given as endpoints. Our method learns the score of the diffusion bridge from data and maps from one endpoint distribution to the other by solving a (stochastic) differential equation based on the learned score. Our method naturally unifies several classes of generative models, such as score-based diffusion models and OT-Flow-Matching, allowing us to adapt existing design and architectural choices to our more general problem. Empirically, we apply DDBMs to challenging image datasets in both pixel and latent space. On standard image translation problems, DDBMs achieve significant improvement over baseline methods, and, when we reduce the problem to image generation by setting the source distribution to random noise, DDBMs achieve comparable FID scores to state-of-the-art methods despite being built for a more general task.", "published": "2023-09-29T03:24:24Z", "version": 3}, {"aid": "2310.20360", "authors": ["Arnulf Jentzen", "Benno Kuckuck", "Philippe von Wurstemberger"], "title": "Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory", "url": "http://arxiv.org/pdf/2310.20360v3", "summary": "This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.", "published": "2023-10-31T11:01:23Z", "version": 3}, {"aid": "2311.01223", "authors": ["Zhengbang Zhu", "Hanye Zhao", "Haoran He", "Yichao Zhong", "Shenyu Zhang", "Haoquan Guo", "Tingting Chen", "Weinan Zhang"], "title": "Diffusion Models for Reinforcement Learning: A Survey", "url": "http://arxiv.org/pdf/2311.01223v4", "summary": "Diffusion models surpass previous generative models in sample quality and training stability. Recent works have shown the advantages of diffusion models in improving reinforcement learning (RL) solutions. This survey aims to provide an overview of this emerging field and hopes to inspire new avenues of research. First, we examine several challenges encountered by RL algorithms. Then, we present a taxonomy of existing methods based on the roles of diffusion models in RL and explore how the preceding challenges are addressed. We further outline successful applications of diffusion models in various RL-related tasks. Finally, we conclude the survey and offer insights into future research directions. We are actively maintaining a GitHub repository for papers and other related resources in utilizing diffusion models in RL: https://github.com/apexrl/Diff4RLSurvey.", "published": "2023-11-02T13:23:39Z", "version": 4}, {"aid": "2311.01412", "authors": ["Abdellah Rahmani", "Pascal Frossard"], "title": "Causal Temporal Regime Structure Learning", "url": "http://arxiv.org/pdf/2311.01412v3", "summary": "Understanding causal relationships in multivariate time series is essential for predicting and controlling dynamic systems in fields like economics, neuroscience, and climate science. However, existing causal discovery methods often assume stationarity, limiting their effectiveness when time series consist of sequential regimes, consecutive temporal segments with unknown boundaries and changing causal structures. In this work, we firstly introduce a framework to describe and model such time series. Then, we present CASTOR, a novel method that concurrently learns the Directed Acyclic Graph (DAG) for each regime while determining the number of regimes and their sequential arrangement. CASTOR optimizes the data log-likelihood using an expectation-maximization algorithm, alternating between assigning regime indices (expectation step) and inferring causal relationships in each regime (maximization step). We establish the identifiability of the regimes and DAGs within our framework. Extensive experiments show that CASTOR consistently outperforms existing causal discovery models in detecting different regimes and learning their DAGs across various settings, including linear and nonlinear causal relationships, on both synthetic and real world datasets.", "published": "2023-11-02T17:26:49Z", "version": 3}, {"aid": "2311.13694", "authors": ["Sreejith Sreekumar", "Mario Berta"], "title": "Limit Distribution Theory for Quantum Divergences", "url": "http://arxiv.org/pdf/2311.13694v3", "summary": "Estimation of quantum relative entropy and its R\\'{e}nyi generalizations is a fundamental statistical task in quantum information theory, physics, and beyond. While several estimators of these divergences have been proposed in the literature along with their computational complexities explored, a limit distribution theory which characterizes the asymptotic fluctuations of the estimation error is still premature. As our main contribution, we characterize these asymptotic distributions in terms of Fr\\'{e}chet derivatives of elementary operator-valued functions. We achieve this by leveraging an operator version of Taylor's theorem and identifying the regularity conditions needed. As an application of our results, we consider an estimator of quantum relative entropy based on Pauli tomography of quantum states and show that the resulting asymptotic distribution is a centered normal, with its variance characterized in terms of the Pauli operators and states. We utilize the knowledge of the aforementioned limit distribution to obtain asymptotic performance guarantees for a multi-hypothesis testing problem.", "published": "2023-11-22T21:06:41Z", "version": 3}, {"aid": "2311.17643", "authors": ["Alexander Becker", "Rodrigo Caye Daudt", "Dominik Narnhofer", "Torben Peters", "Nando Metzger", "Jan Dirk Wegner", "Konrad Schindler"], "title": "Thera: Aliasing-Free Arbitrary-Scale Super-Resolution with Neural Heat Fields", "url": "http://arxiv.org/pdf/2311.17643v3", "summary": "Recent approaches to arbitrary-scale single image super-resolution (ASR) use neural fields to represent continuous signals that can be sampled at arbitrary resolutions. However, point-wise queries of neural fields do not naturally match the point spread function (PSF) of pixels, which may cause aliasing in the super-resolved image. Existing methods attempt to mitigate this by approximating an integral version of the field at each scaling factor, compromising both fidelity and generalization. In this work, we introduce neural heat fields, a novel neural field formulation that inherently models a physically exact PSF. Our formulation enables analytically correct anti-aliasing at any desired output resolution, and -- unlike supersampling -- at no additional cost. Building on this foundation, we propose Thera, an end-to-end ASR method that substantially outperforms existing approaches, while being more parameter-efficient and offering strong theoretical guarantees. The project page is at https://therasr.github.io.", "published": "2023-11-29T14:01:28Z", "version": 3}, {"aid": "2312.07547", "authors": ["Karl J. Friston", "Tommaso Salvatori", "Takuya Isomura", "Alexander Tschantz", "Alex Kiefer", "Tim Verbelen", "Magnus Koudahl", "Aswin Paul", "Thomas Parr", "Adeel Razi", "Brett Kagan", "Christopher L. Buckley", "Maxwell J. D. Ramstead"], "title": "Active Inference and Intentional Behaviour", "url": "http://arxiv.org/pdf/2312.07547v2", "summary": "Recent advances in theoretical biology suggest that basal cognition and sentient behaviour are emergent properties of in vitro cell cultures and neuronal networks, respectively. Such neuronal networks spontaneously learn structured behaviours in the absence of reward or reinforcement. In this paper, we characterise this kind of self-organisation through the lens of the free energy principle, i.e., as self-evidencing. We do this by first discussing the definitions of reactive and sentient behaviour in the setting of active inference, which describes the behaviour of agents that model the consequences of their actions. We then introduce a formal account of intentional behaviour, that describes agents as driven by a preferred endpoint or goal in latent state-spaces. We then investigate these forms of (reactive, sentient, and intentional) behaviour using simulations. First, we simulate the aforementioned in vitro experiments, in which neuronal cultures spontaneously learn to play Pong, by implementing nested, free energy minimising processes. The simulations are then used to deconstruct the ensuing predictive behaviour, leading to the distinction between merely reactive, sentient, and intentional behaviour, with the latter formalised in terms of inductive planning. This distinction is further studied using simple machine learning benchmarks (navigation in a grid world and the Tower of Hanoi problem), that show how quickly and efficiently adaptive behaviour emerges under an inductive form of active inference.", "published": "2023-12-06T09:38:35Z", "version": 2}, {"aid": "2312.05290", "authors": ["Chen Li", "Bipin Rajendran"], "title": "Noise Adaptor in Spiking Neural Networks", "url": "http://arxiv.org/pdf/2312.05290v1", "summary": "Recent strides in low-latency spiking neural network (SNN) algorithms have drawn significant interest, particularly due to their event-driven computing nature and fast inference capability. One of the most efficient ways to construct a low-latency SNN is by converting a pre-trained, low-bit artificial neural network (ANN) into an SNN. However, this conversion process faces two main challenges: First, converting SNNs from low-bit ANNs can lead to ``occasional noise\" -- the phenomenon where occasional spikes are generated in spiking neurons where they should not be -- during inference, which significantly lowers SNN accuracy. Second, although low-latency SNNs initially show fast improvements in accuracy with time steps, these accuracy growths soon plateau, resulting in their peak accuracy lagging behind both full-precision ANNs and traditional ``long-latency SNNs'' that prioritize precision over speed.   In response to these two challenges, this paper introduces a novel technique named ``noise adaptor.'' Noise adaptor can model occasional noise during training and implicitly optimize SNN accuracy, particularly at high simulation times $T$. Our research utilizes the ResNet model for a comprehensive analysis of the impact of the noise adaptor on low-latency SNNs. The results demonstrate that our method outperforms the previously reported quant-ANN-to-SNN conversion technique. We achieved an accuracy of 95.95\\% within 4 time steps on CIFAR-10 using ResNet-18, and an accuracy of 74.37\\% within 64 time steps on ImageNet using ResNet-50. Remarkably, these results were obtained without resorting to any noise correction methods during SNN inference, such as negative spikes or two-stage SNN simulations. Our approach significantly boosts the peak accuracy of low-latency SNNs, bringing them on par with the accuracy of full-precision ANNs. Code will be open source.", "published": "2023-12-08T16:57:01Z", "version": 1}, {"aid": "2312.05431", "authors": ["Yuewei Yang", "Xiaoliang Dai", "Jialiang Wang", "Peizhao Zhang", "Hongbo Zhang"], "title": "Efficient Quantization Strategies for Latent Diffusion Models", "url": "http://arxiv.org/pdf/2312.05431v1", "summary": "Latent Diffusion Models (LDMs) capture the dynamic evolution of latent variables over time, blending patterns and multimodality in a generative system. Despite the proficiency of LDM in various applications, such as text-to-image generation, facilitated by robust text encoders and a variational autoencoder, the critical need to deploy large generative models on edge devices compels a search for more compact yet effective alternatives. Post Training Quantization (PTQ), a method to compress the operational size of deep learning models, encounters challenges when applied to LDM due to temporal and structural complexities. This study proposes a quantization strategy that efficiently quantize LDMs, leveraging Signal-to-Quantization-Noise Ratio (SQNR) as a pivotal metric for evaluation. By treating the quantization discrepancy as relative noise and identifying sensitive part(s) of a model, we propose an efficient quantization approach encompassing both global and local strategies. The global quantization process mitigates relative quantization noise by initiating higher-precision quantization on sensitive blocks, while local treatments address specific challenges in quantization-sensitive and time-sensitive modules. The outcomes of our experiments reveal that the implementation of both global and local treatments yields a highly efficient and effective Post Training Quantization (PTQ) of LDMs.", "published": "2023-12-09T01:47:16Z", "version": 1}, {"aid": "2312.05486", "authors": ["Bowen Sun", "Shibao Zheng"], "title": "FreeFlow: A Comprehensive Understanding on Diffusion Probabilistic Models via Optimal Transport", "url": "http://arxiv.org/pdf/2312.05486v1", "summary": "The blooming diffusion probabilistic models (DPMs) have garnered significant interest due to their impressive performance and the elegant inspiration they draw from physics. While earlier DPMs relied upon the Markovian assumption, recent methods based on differential equations have been rapidly applied to enhance the efficiency and capabilities of these models. However, a theoretical interpretation encapsulating these diverse algorithms is insufficient yet pressingly required to guide further development of DPMs. In response to this need, we present FreeFlow, a framework that provides a thorough explanation of the diffusion formula as time-dependent optimal transport, where the evolutionary pattern of probability density is given by the gradient flows of a functional defined in Wasserstein space. Crucially, our framework necessitates a unified description that not only clarifies the subtle mechanism of DPMs but also indicates the roots of some defects through creative involvement of Lagrangian and Eulerian views to understand the evolution of probability flow. We particularly demonstrate that the core equation of FreeFlow condenses all stochastic and deterministic DPMs into a single case, showcasing the expansibility of our method. Furthermore, the Riemannian geometry employed in our work has the potential to bridge broader subjects in mathematics, which enable the involvement of more profound tools for the establishment of more outstanding and generalized models in the future.", "published": "2023-12-09T07:24:40Z", "version": 1}, {"aid": "2312.05491", "authors": ["Vivek Miglani", "Aobo Yang", "Aram H. Markosyan", "Diego Garcia-Olano", "Narine Kokhlikyan"], "title": "Using Captum to Explain Generative Language Models", "url": "http://arxiv.org/pdf/2312.05491v1", "summary": "Captum is a comprehensive library for model explainability in PyTorch, offering a range of methods from the interpretability literature to enhance users' understanding of PyTorch models. In this paper, we introduce new features in Captum that are specifically designed to analyze the behavior of generative language models. We provide an overview of the available functionalities and example applications of their potential for understanding learned associations within generative language models.", "published": "2023-12-09T07:35:24Z", "version": 1}, {"aid": "2312.05583", "authors": ["Peiyan Hu", "Yue Wang", "Zhi-Ming Ma"], "title": "Better Neural PDE Solvers Through Data-Free Mesh Movers", "url": "http://arxiv.org/pdf/2312.05583v2", "summary": "Recently, neural networks have been extensively employed to solve partial differential equations (PDEs) in physical system modeling. While major studies focus on learning system evolution on predefined static mesh discretizations, some methods utilize reinforcement learning or supervised learning techniques to create adaptive and dynamic meshes, due to the dynamic nature of these systems. However, these approaches face two primary challenges: (1) the need for expensive optimal mesh data, and (2) the change of the solution space's degree of freedom and topology during mesh refinement. To address these challenges, this paper proposes a neural PDE solver with a neural mesh adapter. To begin with, we introduce a novel data-free neural mesh adaptor, called Data-free Mesh Mover (DMM), with two main innovations. Firstly, it is an operator that maps the solution to adaptive meshes and is trained using the Monge-Amp\\`ere equation without optimal mesh data. Secondly, it dynamically changes the mesh by moving existing nodes rather than adding or deleting nodes and edges. Theoretical analysis shows that meshes generated by DMM have the lowest interpolation error bound. Based on DMM, to efficiently and accurately model dynamic systems, we develop a moving mesh based neural PDE solver (MM-PDE) that embeds the moving mesh with a two-branch architecture and a learnable interpolation framework to preserve information within the data. Empirical experiments demonstrate that our method generates suitable meshes and considerably enhances accuracy when modeling widely considered PDE systems. The code can be found at: https://github.com/Peiyannn/MM-PDE.git.", "published": "2023-12-09T14:05:28Z", "version": 2}, {"aid": "2312.07243", "authors": ["Enshu Liu", "Xuefei Ning", "Huazhong Yang", "Yu Wang"], "title": "A Unified Sampling Framework for Solver Searching of Diffusion Probabilistic Models", "url": "http://arxiv.org/pdf/2312.07243v1", "summary": "Recent years have witnessed the rapid progress and broad application of diffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as solving an ordinary differential equation (ODE). Despite the promising performance, the generation of DPMs usually consumes much time due to the large number of function evaluations (NFE). Though recent works have accelerated the sampling to around 20 steps with high-order solvers, the sample quality with less than 10 NFE can still be improved. In this paper, we propose a unified sampling framework (USF) to study the optional strategies for solver. Under this framework, we further reveal that taking different solving strategies at different timesteps may help further decrease the truncation error, and a carefully designed \\emph{solver schedule} has the potential to improve the sample quality by a large margin. Therefore, we propose a new sampling framework based on the exponential integral formulation that allows free choices of solver strategy at each step and design specific decisions for the framework. Moreover, we propose $S^3$, a predictor-based search method that automatically optimizes the solver schedule to get a better time-quality trade-off of sampling. We demonstrate that $S^3$ can find outstanding solver schedules which outperform the state-of-the-art sampling methods on CIFAR-10, CelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID with 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA method significantly. We further apply $S^3$ to Stable-Diffusion model and get an acceleration ratio of 2$\\times$, showing the feasibility of sampling in very few steps without retraining the neural network.", "published": "2023-12-12T13:19:40Z", "version": 1}, {"aid": "2312.07971", "authors": ["Zhiyuan Ma", "zhihuan yu", "Jianjun Li", "Bowen Zhou"], "title": "LMD: Faster Image Reconstruction with Latent Masking Diffusion", "url": "http://arxiv.org/pdf/2312.07971v1", "summary": "As a class of fruitful approaches, diffusion probabilistic models (DPMs) have shown excellent advantages in high-resolution image reconstruction. On the other hand, masked autoencoders (MAEs), as popular self-supervised vision learners, have demonstrated simpler and more effective image reconstruction and transfer capabilities on downstream tasks. However, they all require extremely high training costs, either due to inherent high temporal-dependence (i.e., excessively long diffusion steps) or due to artificially low spatial-dependence (i.e., human-formulated high mask ratio, such as 0.75). To the end, this paper presents LMD, a faster image reconstruction framework with latent masking diffusion. First, we propose to project and reconstruct images in latent space through a pre-trained variational autoencoder, which is theoretically more efficient than in the pixel-based space. Then, we combine the advantages of MAEs and DPMs to design a progressive masking diffusion model, which gradually increases the masking proportion by three different schedulers and reconstructs the latent features from simple to difficult, without sequentially performing denoising diffusion as in DPMs or using fixed high masking ratio as in MAEs, so as to alleviate the high training time-consumption predicament. Our approach allows for learning high-capacity models and accelerate their training (by 3x or more) and barely reduces the original accuracy. Inference speed in downstream tasks also significantly outperforms the previous approaches.", "published": "2023-12-13T08:36:51Z", "version": 1}, {"aid": "2312.08107", "authors": ["Yorgos Felekis", "Fabio Massimo Zennaro", "Nicola Branchini", "Theodoros Damoulas"], "title": "Causal Optimal Transport of Abstractions", "url": "http://arxiv.org/pdf/2312.08107v1", "summary": "Causal abstraction (CA) theory establishes formal criteria for relating multiple structural causal models (SCMs) at different levels of granularity by defining maps between them. These maps have significant relevance for real-world challenges such as synthesizing causal evidence from multiple experimental environments, learning causally consistent representations at different resolutions, and linking interventions across multiple SCMs. In this work, we propose COTA, the first method to learn abstraction maps from observational and interventional data without assuming complete knowledge of the underlying SCMs. In particular, we introduce a multi-marginal Optimal Transport (OT) formulation that enforces do-calculus causal constraints, together with a cost function that relies on interventional information. We extensively evaluate COTA on synthetic and real world problems, and showcase its advantages over non-causal, independent and aggregated COTA formulations. Finally, we demonstrate the efficiency of our method as a data augmentation tool by comparing it against the state-of-the-art CA learning framework, which assumes fully specified SCMs, on a real-world downstream task.", "published": "2023-12-13T12:54:34Z", "version": 1}, {"aid": "2401.12736", "authors": ["Dachong Li", "Li Li", "Zhuangzhuang Chen", "Jianqiang Li"], "title": "$ShiftwiseConv:$ Small Convolutional Kernel with Large Kernel Effect", "url": "http://arxiv.org/pdf/2401.12736v2", "summary": "Large kernels make standard convolutional neural networks (CNNs) great again over transformer architectures in various vision tasks. Nonetheless, recent studies meticulously designed around increasing kernel size have shown diminishing returns or stagnation in performance. Thus, the hidden factors of large kernel convolution that affect model performance remain unexplored. In this paper, we reveal that the key hidden factors of large kernels can be summarized as two separate components: extracting features at a certain granularity and fusing features by multiple pathways. To this end, we leverage the multi-path long-distance sparse dependency relationship to enhance feature utilization via the proposed Shiftwise (SW) convolution operator with a pure CNN architecture. In a wide range of vision tasks such as classification, segmentation, and detection, SW surpasses state-of-the-art transformers and CNN architectures, including SLaK and UniRepLKNet. More importantly, our experiments demonstrate that $3 \\times 3$ convolutions can replace large convolutions in existing large kernel CNNs to achieve comparable effects, which may inspire follow-up works. Code and all the models at https://github.com/lidc54/shift-wiseConv.", "published": "2024-01-23T13:13:45Z", "version": 2}, {"aid": "2402.14327", "authors": ["Delong Chen", "Samuel Cahyawijaya", "Jianfeng Liu", "Baoyuan Wang", "Pascale Fung"], "title": "Subobject-level Image Tokenization", "url": "http://arxiv.org/pdf/2402.14327v3", "summary": "Patch-based image tokenization ignores the morphology of the visual world, limiting effective and efficient learning of image understanding. Inspired by subword tokenization, we introduce subobject-level adaptive token segmentation and explore several approaches, including superpixel, SAM, and a proposed Efficient and PanOptiC (EPOC) image tokenizer. Our EPOC combines boundary detection -- a simple task that can be handled well by a compact model -- with watershed segmentation, which inherently guarantees no pixels are left unsegmented. Intrinsic evaluations across 5 datasets demonstrate that EPOC's segmentation aligns well with human annotations of both object- and part-level visual morphology, producing more monosemantic tokens and offering substantial efficiency advantages. For extrinsic evaluation, we designed a token embedding that handles arbitrary-shaped tokens, and trained VLMs with different tokenizers on 4 datasets of object recognition and detailed captioning. The results reveal that subobject tokenization enables faster convergence and better generalization while using fewer visual tokens.", "published": "2024-02-22T06:47:44Z", "version": 3}, {"aid": "2403.08632", "authors": ["Zhuang Liu", "Kaiming He"], "title": "A Decade's Battle on Dataset Bias: Are We There Yet?", "url": "http://arxiv.org/pdf/2403.08632v2", "summary": "We revisit the \"dataset classification\" experiment suggested by Torralba & Efros (2011) a decade ago, in the new era with large-scale, diverse, and hopefully less biased datasets as well as more capable neural network architectures. Surprisingly, we observe that modern neural networks can achieve excellent accuracy in classifying which dataset an image is from: e.g., we report 84.7% accuracy on held-out validation data for the three-way classification problem consisting of the YFCC, CC, and DataComp datasets. Our further experiments show that such a dataset classifier could learn semantic features that are generalizable and transferable, which cannot be explained by memorization. We hope our discovery will inspire the community to rethink issues involving dataset bias.", "published": "2024-03-13T15:46:37Z", "version": 2}, {"aid": "2404.09032", "authors": ["Maria Manuel Clementino", "Dirk Hofmann", "Walter Tholen"], "title": "Cauchy convergence in V-normed categories", "url": "http://arxiv.org/pdf/2404.09032v3", "summary": "Building on the notion of normed category as suggested by Lawvere, we introduce notions of Cauchy convergence and cocompleteness which differ from proposals in previous works. Key to our approach is to treat them consequentially as categories enriched in the monoidal-closed category of normed sets. Our notions largely lead to the anticipated outcomes when considering individual metric spaces as small normed categories, but they can be challenging when considering some large categories, like those of semi-normed or normed vector spaces and all linear maps, or of generalized metric spaces and all mappings. These are the key example categories discussed in detail in this paper. Working with a general commutative quantale V as a value recipient for norms, rather than only with Lawvere's quantale of the extended real half-line, we observe that the categorically atypical structure gap between objects and morphisms in the example categories is already present in the underlying normed category of the enriching category of V-normed sets. To show that this normed category and, in fact, all presheaf categories over it, are Cauchy cocomplete, we assume the quantale V to satisfy a couple of light alternative extra properties. Of utmost importance to the general theory is the fact that our notion of normed colimit is subsumed by the notion of weighted colimit of enriched category theory. With this theory we are able to prove that all V-normed categories have correct-size Cauchy cocompletions. We also prove a Banach Fixed Point Theorem for contractive endofunctors of Cauchy cocomplete normed categories.", "published": "2024-04-13T16:03:09Z", "version": 3}, {"aid": "2405.05966", "authors": ["Juri Opitz", "Shira Wein", "Nathan Schneider"], "title": "Natural Language Processing RELIES on Linguistics", "url": "http://arxiv.org/pdf/2405.05966v4", "summary": "Large Language Models (LLMs) have become capable of generating highly fluent text in certain languages, without modules specially designed to capture grammar or semantic coherence. What does this mean for the future of linguistic expertise in NLP? We highlight several aspects in which NLP (still) relies on linguistics, or where linguistic thinking can illuminate new directions. We argue our case around the acronym RELIES that encapsulates six major facets where linguistics contributes to NLP: Resources, Evaluation, Low-resource settings, Interpretability, Explanation, and the Study of language. This list is not exhaustive, nor is linguistics the main point of reference for every effort under these themes; but at a macro level, these facets highlight the enduring importance of studying machine systems vis-\\`a-vis systems of human language.", "published": "2024-05-09T17:59:32Z", "version": 4}, {"aid": "2405.13731", "authors": ["Qijia Jiang", "David Nabergoj"], "title": "Control, Transport and Sampling: Towards Better Loss Design", "url": "http://arxiv.org/pdf/2405.13731v2", "summary": "Leveraging connections between diffusion-based sampling, optimal transport, and stochastic optimal control through their shared links to the Schr\\\"odinger bridge problem, we propose novel objective functions that can be used to transport $\\nu$ to $\\mu$, consequently sample from the target $\\mu$, via optimally controlled dynamics. We highlight the importance of the pathwise perspective and the role various optimality conditions on the path measure can play for the design of valid training losses, the careful choice of which offer numerical advantages in implementation. Basing the formalism on Schr\\\"odinger bridge comes with the additional practical capability of baking in inductive bias when it comes to Neural Network training.", "published": "2024-05-22T15:24:48Z", "version": 2}, {"aid": "2405.15885", "authors": ["Kaiwen Zheng", "Guande He", "Jianfei Chen", "Fan Bao", "Jun Zhu"], "title": "Diffusion Bridge Implicit Models", "url": "http://arxiv.org/pdf/2405.15885v6", "summary": "Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, give rise to generative processes ranging from stochastic to deterministic, and result in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks. Code is available at https://github.com/thu-ml/DiffusionBridge.", "published": "2024-05-24T19:08:30Z", "version": 6}, {"aid": "2405.15932", "authors": ["Soumyabrata Kundu", "Risi Kondor"], "title": "Steerable Transformers for Volumetric Data", "url": "http://arxiv.org/pdf/2405.15932v3", "summary": "We introduce Steerable Transformers, an extension of the Vision Transformer mechanism that maintains equivariance to the special Euclidean group $\\mathrm{SE}(d)$. We propose an equivariant attention mechanism that operates on features extracted by steerable convolutions. Operating in Fourier space, our network utilizes Fourier space non-linearities. Our experiments in both two and three dimensions show that adding steerable transformer layers to steerable convolutional networks enhances performance.", "published": "2024-05-24T20:43:19Z", "version": 3}, {"aid": "2405.20630", "authors": ["Byoungwoo Park", "Jungwon Choi", "Sungbin Lim", "Juho Lee"], "title": "Stochastic Optimal Control for Diffusion Bridges in Function Spaces", "url": "http://arxiv.org/pdf/2405.20630v5", "summary": "Recent advancements in diffusion models and diffusion bridges primarily focus on finite-dimensional spaces, yet many real-world problems necessitate operations in infinite-dimensional function spaces for more natural and interpretable formulations. In this paper, we present a theory of stochastic optimal control (SOC) tailored to infinite-dimensional spaces, aiming to extend diffusion-based algorithms to function spaces. Specifically, we demonstrate how Doob's $h$-transform, the fundamental tool for constructing diffusion bridges, can be derived from the SOC perspective and expanded to infinite dimensions. This expansion presents a challenge, as infinite-dimensional spaces typically lack closed-form densities. Leveraging our theory, we establish that solving the optimal control problem with a specific objective function choice is equivalent to learning diffusion-based generative models. We propose two applications: (1) learning bridges between two infinite-dimensional distributions and (2) generative models for sampling from an infinite-dimensional distribution. Our approach proves effective for diverse problems involving continuous function space representations, such as resolution-free images, time-series data, and probability density functions.", "published": "2024-05-31T05:42:47Z", "version": 5}, {"aid": "2406.04303", "authors": ["Benedikt Alkin", "Maximilian Beck", "Korbinian P\u00f6ppel", "Sepp Hochreiter", "Johannes Brandstetter"], "title": "Vision-LSTM: xLSTM as Generic Vision Backbone", "url": "http://arxiv.org/pdf/2406.04303v3", "summary": "Transformers are widely used as generic backbones in computer vision, despite initially introduced for natural language processing. Recently, the Long Short-Term Memory (LSTM) has been extended to a scalable and performant architecture - the xLSTM - which overcomes long-standing LSTM limitations via exponential gating and parallelizable matrix memory structure. In this report, we introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to computer vision. ViL comprises a stack of xLSTM blocks where odd blocks process the sequence of patch tokens from top to bottom while even blocks go from bottom to top. Experiments show that ViL holds promise to be further deployed as new generic backbone for computer vision architectures.", "published": "2024-06-06T17:49:21Z", "version": 3}, {"aid": "2406.09588", "authors": ["Yulong Yang", "Felix O'Mahony", "Christine Allen-Blanchette"], "title": "Learning Color Equivariant Representations", "url": "http://arxiv.org/pdf/2406.09588v6", "summary": "In this paper, we introduce group convolutional neural networks (GCNNs) equivariant to color variation. GCNNs have been designed for a variety of geometric transformations from 2D and 3D rotation groups, to semi-groups such as scale. Despite the improved interpretability, accuracy and generalizability of these architectures, GCNNs have seen limited application in the context of perceptual quantities. Notably, the recent CEConv network uses a GCNN to achieve equivariance to hue transformations by convolving input images with a hue rotated RGB filter. However, this approach leads to invalid RGB values which break equivariance and degrade performance. We resolve these issues with a lifting layer that transforms the input image directly, thereby circumventing the issue of invalid RGB values and improving equivariance error by over three orders of magnitude. Moreover, we extend the notion of color equivariance to include equivariance to saturation and luminance shift. Our hue-, saturation-, luminance- and color-equivariant networks achieve strong generalization to out-of-distribution perceptual variations and improved sample efficiency over conventional architectures. We demonstrate the utility of our approach on synthetic and real world datasets where we consistently outperform competitive baselines.", "published": "2024-06-13T21:02:03Z", "version": 6}, {"aid": "2406.13474", "authors": ["Junhan Kim", "Ho-young Kim", "Eulrang Cho", "Chungman Lee", "Joonyoung Kim", "Yongkweon Jeon"], "title": "BoA: Attention-aware Post-training Quantization without Backpropagation", "url": "http://arxiv.org/pdf/2406.13474v3", "summary": "Post-training quantization (PTQ) is a promising solution for deploying large language models (LLMs) on resource-constrained devices. Early methods developed for small-scale networks, such as ResNet, rely on gradient-based optimization, which becomes impractical for hyper-scale LLMs with billions of parameters. While recently proposed backpropagation-free or transformation-based methods alleviate this issue, they ignore inter-layer interactions or use the naive nearest-rounding-based quantized weight assignment to save the heavy computational cost of weight optimization. In this paper, we introduce a novel backpropagation-free PTQ algorithm that optimizes quantized weights by considering inter-layer dependencies. The key innovation is the development of attention-aware Hessian matrices that capture inter-layer interactions within the attention module. Extensive experiments demonstrate that our approach not only outperforms existing weight quantization methods but also shows good synergy with conventional methods to suppress activation outliers, leading to state-of-the-art weight-activation quantization performance. The code will be available at https://github.com/SamsungLabs/BoA.", "published": "2024-06-19T11:53:21Z", "version": 3}, {"aid": "2407.01163", "authors": ["Luca Pinchetti", "Chang Qi", "Oleh Lokshyn", "Gaspard Olivers", "Cornelius Emde", "Mufeng Tang", "Amine M'Charrak", "Simon Frieder", "Bayar Menzat", "Rafal Bogacz", "Thomas Lukasiewicz", "Tommaso Salvatori"], "title": "Benchmarking Predictive Coding Networks -- Made Simple", "url": "http://arxiv.org/pdf/2407.01163v2", "summary": "In this work, we tackle the problems of efficiency and scalability for predictive coding networks (PCNs) in machine learning. To do so, we propose a library, called PCX, that focuses on performance and simplicity, and use it to implement a large set of standard benchmarks for the community to use for their experiments. As most works in the field propose their own tasks and architectures, do not compare one against each other, and focus on small-scale tasks, a simple and fast open-source library and a comprehensive set of benchmarks would address all these concerns. Then, we perform extensive tests on such benchmarks using both existing algorithms for PCNs, as well as adaptations of other methods popular in the bio-plausible deep learning community. All this has allowed us to (i) test architectures much larger than commonly used in the literature, on more complex datasets; (ii)~reach new state-of-the-art results in all of the tasks and datasets provided; (iii)~clearly highlight what the current limitations of PCNs are, allowing us to state important future research directions. With the hope of galvanizing community efforts towards one of the main open problems in the field, scalability, we release code, tests, and benchmarks. Link to the library: https://github.com/liukidar/pcx", "published": "2024-07-01T10:33:44Z", "version": 2}, {"aid": "2408.13376", "authors": ["Georgios Bakirtzis", "Michail Savvas", "Ruihan Zhao", "Sandeep Chinchali", "Ufuk Topcu"], "title": "Reduce, Reuse, Recycle: Categories for Compositional Reinforcement Learning", "url": "http://arxiv.org/pdf/2408.13376v3", "summary": "In reinforcement learning, conducting task composition by forming cohesive, executable sequences from multiple tasks remains challenging. However, the ability to (de)compose tasks is a linchpin in developing robotic systems capable of learning complex behaviors. Yet, compositional reinforcement learning is beset with difficulties, including the high dimensionality of the problem space, scarcity of rewards, and absence of system robustness after task composition. To surmount these challenges, we view task composition through the prism of category theory -- a mathematical discipline exploring structures and their compositional relationships. The categorical properties of Markov decision processes untangle complex tasks into manageable sub-tasks, allowing for strategical reduction of dimensionality, facilitating more tractable reward structures, and bolstering system robustness. Experimental results support the categorical theory of reinforcement learning by enabling skill reduction, reuse, and recycling when learning complex robotic arm tasks.", "published": "2024-08-23T21:23:22Z", "version": 3}, {"aid": "2408.16916", "authors": ["Atsunobu Kotani", "Ren Ng"], "title": "A Computational Framework for Modeling Emergence of Color Vision in the Human Brain", "url": "http://arxiv.org/pdf/2408.16916v2", "summary": "It is a mystery how the brain decodes color vision purely from the optic nerve signals it receives, with a core inferential challenge being how it disentangles internal perception with the correct color dimensionality from the unknown encoding properties of the eye. In this paper, we introduce a computational framework for modeling this emergence of human color vision by simulating both the eye and the cortex. Existing research often overlooks how the cortex develops color vision or represents color space internally, assuming that the color dimensionality is known a priori; however, we argue that the visual cortex has the capability and the challenge of inferring the color dimensionality purely from fluctuations in the optic nerve signals. To validate our theory, we introduce a simulation engine for biological eyes based on established vision science and generate optic nerve signals resulting from looking at natural images. Further, we propose a bio-plausible model of cortical learning based on self-supervised prediction of optic nerve signal fluctuations under natural eye motions. We show that this model naturally learns to generate color vision by disentangling retinal invariants from the sensory signals. When the retina contains N types of color photoreceptors, our simulation shows that N-dimensional color vision naturally emerges, verified through formal colorimetry. Using this framework, we also present the first simulation work that successfully boosts the color dimensionality, as observed in gene therapy on squirrel monkeys, and demonstrates the possibility of enhancing human color vision from 3D to 4D.", "published": "2024-08-29T21:27:06Z", "version": 2}, {"aid": "2410.06424", "authors": ["Christopher Fifty", "Ronald G. Junkins", "Dennis Duan", "Aniketh Iyengar", "Jerry W. Liu", "Ehsan Amid", "Sebastian Thrun", "Christopher R\u00e9"], "title": "Restructuring Vector Quantization with the Rotation Trick", "url": "http://arxiv.org/pdf/2410.06424v2", "summary": "Vector Quantized Variational AutoEncoders (VQ-VAEs) are designed to compress a continuous input to a discrete latent space and reconstruct it with minimal distortion. They operate by maintaining a set of vectors -- often referred to as the codebook -- and quantizing each encoder output to the nearest vector in the codebook. However, as vector quantization is non-differentiable, the gradient to the encoder flows around the vector quantization layer rather than through it in a straight-through approximation. This approximation may be undesirable as all information from the vector quantization operation is lost. In this work, we propose a way to propagate gradients through the vector quantization layer of VQ-VAEs. We smoothly transform each encoder output into its corresponding codebook vector via a rotation and rescaling linear transformation that is treated as a constant during backpropagation. As a result, the relative magnitude and angle between encoder output and codebook vector becomes encoded into the gradient as it propagates through the vector quantization layer and back to the encoder. Across 11 different VQ-VAE training paradigms, we find this restructuring improves reconstruction metrics, codebook utilization, and quantization error. Our code is available at https://github.com/cfifty/rotation_trick.", "published": "2024-10-08T23:39:34Z", "version": 2}, {"aid": "2410.11112", "authors": ["Alan T. L. Bacellar", "Zachary Susskind", "Mauricio Breternitz Jr.", "Eugene John", "Lizy K. John", "Priscila M. V. Lima", "Felipe M. G. Fran\u00e7a"], "title": "Differentiable Weightless Neural Networks", "url": "http://arxiv.org/pdf/2410.11112v5", "summary": "We introduce the Differentiable Weightless Neural Network (DWN), a model based on interconnected lookup tables. Training of DWNs is enabled by a novel Extended Finite Difference technique for approximate differentiation of binary values. We propose Learnable Mapping, Learnable Reduction, and Spectral Regularization to further improve the accuracy and efficiency of these models. We evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware accelerator, where they demonstrate superior latency, throughput, energy efficiency, and model area compared to state-of-the-art solutions, (2) a low-power microcontroller, where they achieve preferable accuracy to XGBoost while subject to stringent memory constraints, and (3) ultra-low-cost chips, where they consistently outperform small models in both accuracy and projected hardware area. DWNs also compare favorably against leading approaches for tabular datasets, with higher average rank. Overall, our work positions DWNs as a pioneering solution for edge-compatible high-throughput neural networks.", "published": "2024-10-14T21:43:48Z", "version": 5}, {"aid": "2410.12346", "authors": ["Guanzhou Lan", "Qianli Ma", "Yuqi Yang", "Zhigang Wang", "Dong Wang", "Xuelong Li", "Bin Zhao"], "title": "Efficient Diffusion as Low Light Enhancer", "url": "http://arxiv.org/pdf/2410.12346v2", "summary": "The computational burden of the iterative sampling process remains a major challenge in diffusion-based Low-Light Image Enhancement (LLIE). Current acceleration methods, whether training-based or training-free, often lead to significant performance degradation, highlighting the trade-off between performance and efficiency. In this paper, we identify two primary factors contributing to performance degradation: fitting errors and the inference gap. Our key insight is that fitting errors can be mitigated by linearly extrapolating the incorrect score functions, while the inference gap can be reduced by shifting the Gaussian flow to a reflectance-aware residual space. Based on the above insights, we design Reflectance-Aware Trajectory Refinement (RATR) module, a simple yet effective module to refine the teacher trajectory using the reflectance component of images. Following this, we introduce \\textbf{Re}flectance-aware \\textbf{D}iffusion with \\textbf{Di}stilled \\textbf{T}rajectory (\\textbf{ReDDiT}), an efficient and flexible distillation framework tailored for LLIE. Our framework achieves comparable performance to previous diffusion-based methods with redundant steps in just 2 steps while establishing new state-of-the-art (SOTA) results with 8 or 4 steps. Comprehensive experimental evaluations on 10 benchmark datasets validate the effectiveness of our method, consistently outperforming existing SOTA methods.", "published": "2024-10-16T08:07:18Z", "version": 2}, {"aid": "2410.14634", "authors": ["Sandeep Nagar", "Girish Varma"], "title": "Parallel Backpropagation for Inverse of a Convolution with Application to Normalizing Flows", "url": "http://arxiv.org/pdf/2410.14634v3", "summary": "The inverse of an invertible convolution is an important operation that comes up in Normalizing Flows, Image Deblurring, etc. The naive algorithm for backpropagation of this operation using Gaussian elimination has running time $O(n^3)$ where $n$ is the number of pixels in the image. We give a fast parallel backpropagation algorithm with running time $O(\\sqrt{n})$ for a square image and provide a GPU implementation of the same. Inverse of Convolutions are usually used in Normalizing Flows in the sampling pass, making them slow. We propose to use the Inverse of Convolutions in the forward (image to latent vector) pass of the Normalizing flow. Since the sampling pass is the inverse of the forward pass, it will use convolutions only, resulting in efficient sampling times. We use our parallel backpropagation algorithm to optimize the inverse of the convolution layer, resulting in fast training times. We implement this approach in various Normalizing Flow backbones, resulting in our Inverse-Flow models. We benchmark Inverse-Flow on standard datasets and show significantly improved sampling times with similar bits per dimension compared to previous models.", "published": "2024-10-18T17:35:33Z", "version": 3}, {"aid": "2410.20587", "authors": ["Peter Holderrieth", "Marton Havasi", "Jason Yim", "Neta Shaul", "Itai Gat", "Tommi Jaakkola", "Brian Karrer", "Ricky T. Q. Chen", "Yaron Lipman"], "title": "Generator Matching: Generative modeling with arbitrary Markov processes", "url": "http://arxiv.org/pdf/2410.20587v3", "summary": "We introduce Generator Matching, a modality-agnostic framework for generative modeling using arbitrary Markov processes. Generators characterize the infinitesimal evolution of a Markov process, which we leverage for generative modeling in a similar vein to flow matching: we construct conditional generators which generate single data points, then learn to approximate the marginal generator which generates the full data distribution. We show that Generator Matching unifies various generative modeling methods, including diffusion models, flow matching and discrete diffusion models. Furthermore, it expands the design space to new and unexplored Markov processes such as jump processes. Finally, Generator Matching enables the construction of superpositions of Markov generative models and enables the construction of multimodal models in a rigorous manner. We empirically validate our method on image and multimodal generation, e.g. showing that superposition with a jump process improves performance.", "published": "2024-10-27T20:47:29Z", "version": 3}, {"aid": "2410.22494", "authors": ["Davide Barbarossa"], "title": "An excursion into Dialectica and Differentiation", "url": "http://arxiv.org/pdf/2410.22494v2", "summary": "G\\\"odel's Dialectica has been introduced and developed in the tradition of the so-called functional interpretations. Only recently has it been related with the a priori unrelated notion of differentiation, by taking a program-theoretic approach. We revisit the deep connection between these two notions in order to understand its structural reasons, as well as to express it in an arguably more natural way by following a geometric intuition. More specifically, we give a logical relation between a Dialectica transformed term and its reverse differential in a differential category and, then, we phrase the Dialectica program transformation in the language of lenses, often used indeed in Automatic Differentiation in order to model reverse differentiation. We illustrate how this clarifies why Dialectica behaves as a differentiable program transformation, and what the limits of this correspondence are.", "published": "2024-10-29T19:33:22Z", "version": 2}, {"aid": "2411.00201", "authors": ["Nidhal Jegham", "Chan Young Koh", "Marwan Abdelatti", "Abdeltawab Hendawi"], "title": "YOLO Evolution: A Comprehensive Benchmark and Architectural Review of YOLOv12, YOLO11, and Their Previous Versions", "url": "http://arxiv.org/pdf/2411.00201v4", "summary": "This study presents a comprehensive benchmark analysis of various YOLO (You Only Look Once) algorithms. It represents the first comprehensive experimental evaluation of YOLOv3 to the latest version, YOLOv12, on various object detection challenges. The challenges considered include varying object sizes, diverse aspect ratios, and small-sized objects of a single class, ensuring a comprehensive assessment across datasets with distinct challenges. To ensure a robust evaluation, we employ a comprehensive set of metrics, including Precision, Recall, Mean Average Precision (mAP), Processing Time, GFLOPs count, and Model Size. Our analysis highlights the distinctive strengths and limitations of each YOLO version. For example: YOLOv9 demonstrates substantial accuracy but struggles with detecting small objects and efficiency whereas YOLOv10 exhibits relatively lower accuracy due to architectural choices that affect its performance in overlapping object detection but excels in speed and efficiency. Additionally, the YOLO11 family consistently shows superior performance maintaining a remarkable balance of accuracy and efficiency. However, YOLOv12 delivered underwhelming results, with its complex architecture introducing computational overhead without significant performance gains. These results provide critical insights for both industry and academia, facilitating the selection of the most suitable YOLO algorithm for diverse applications and guiding future enhancements.", "published": "2024-10-31T20:45:00Z", "version": 4}, {"aid": "2411.17711", "authors": ["Yue Wang", "Xu Cao", "Yaojun Hu", "Haochao Ying", "Hongxia Xu", "Ruijia Wu", "James Matthew Rehg", "Jimeng Sun", "Jian Wu", "Jintai Chen"], "title": "AnyECG: Foundational Models for Multitask Cardiac Analysis in Real-World Settings", "url": "http://arxiv.org/pdf/2411.17711v2", "summary": "Electrocardiogram (ECG), a non-invasive and affordable tool for cardiac monitoring, is highly sensitive in detecting acute heart attacks. However, due to the lengthy nature of ECG recordings, numerous machine learning methods have been developed for automated heart disease detection to reduce human workload. Despite these efforts, performance remains suboptimal. A key obstacle is the inherent complexity of ECG data, which includes heterogeneity (e.g., varying sampling rates), high levels of noise, demographic-related pattern shifts, and intricate rhythm-event associations. To overcome these challenges, this paper introduces AnyECG, a foundational model designed to extract robust representations from any real-world ECG data. Specifically, a tailored ECG Tokenizer encodes each fixed-duration ECG fragment into a token and, guided by proxy tasks, converts noisy, continuous ECG features into discrete, compact, and clinically meaningful local rhythm codes. These codes encapsulate basic morphological, frequency, and demographic information (e.g., sex), effectively mitigating signal noise. We further pre-train the AnyECG to learn rhythmic pattern associations across ECG tokens, enabling the capture of cardiac event semantics. By being jointly pre-trained on diverse ECG data sources, AnyECG is capable of generalizing across a wide range of downstream tasks where ECG signals are recorded from various devices and scenarios. The experimental results show that AnyECG achieves an average performance improvement of 6% across four critical tasks-anomaly detection, arrhythmia classification, corrupted lead generation, and ultra-long ECG recognition. AnyECG learns common ECG rhythm from data and significantly outperforms state-of-the-art methods in each of these tasks.", "published": "2024-11-17T17:32:58Z", "version": 2}, {"aid": "2411.13625", "authors": ["Rebecca Maria Kuntz", "Heinrich von Campe", "Tobias R\u00f6spel", "Maximilian Philipp Herzog", "Bj\u00f6rn Malte Sch\u00e4fer"], "title": "Partition function approach to non-Gaussian likelihoods: information theory and state variables for Bayesian inference", "url": "http://arxiv.org/pdf/2411.13625v2", "summary": "The significance of statistical physics concepts such as entropy extends far beyond classical thermodynamics. We interpret the similarity between partitions in statistical mechanics and partitions in Bayesian inference as an articulation of a result by Jaynes (1957), who clarified that thermodynamics is in essence a theory of information. In this, every sampling process has a mechanical analogue. Consequently, the divide between ensembles of samplers in parameter space and sampling from a mechanical system in thermodynamic equilibrium would be artificial. Based on this realisation, we construct a continuous modelling of a Bayes update akin to a transition between thermodynamic ensembles. This leads to an information theoretic interpretation of Jazinsky's equality, relating the expenditure of work to the influence of data via the likelihood. We propose one way to transfer the vocabulary and the formalism of thermodynamics (energy, work, heat) and statistical mechanics (partition functions) to statistical inference, starting from Bayes' law. Different kinds of inference processes are discussed and relative entropies are shown to follow from suitably constructed partitions as an analytical formulation of sampling processes. Lastly, we propose an effective dimension as a measure of system complexity. A numerical example from cosmology is put forward to illustrate these results.", "published": "2024-11-20T13:59:28Z", "version": 2}, {"aid": "2411.13765", "authors": ["Andrei Zlotchevski", "Linan Chen"], "title": "Schr\u00f6dinger Bridge Problem for Jump Diffusions", "url": "http://arxiv.org/pdf/2411.13765v2", "summary": "The Schr\\\"odinger bridge problem (SBP) seeks to find the measure $\\hat{\\mathbf{P}}$ on a certain path space which interpolates between state-space distributions $\\rho_0$ at time $0$ and $\\rho_T$ at time $T$ while minimizing the KL divergence (relative entropy) to a reference path measure $\\mathbf{R}$. In this work, we tackle the SBP in the case when $\\mathbf{R}$ is the path measure of a jump diffusion. Under mild assumptions, with both the operator theory approach and the stochastic calculus techniques, we establish an $h$-transform theory for jump diffusions and devise an approximation method to achieve the jump-diffusion SBP solution $\\hat{\\mathbf{P}}$ as the strong-convergence limit of a sequence of harmonic $h$-transforms. To the best of our knowledge, these results are novel in the study of SBP. Moreover, the $h$-transform framework and the approximation method developed in this work are robust and applicable to a relatively general class of jump diffusions. In addition, we examine the SBP of particular types of jump diffusions under additional regularity conditions and extend the existing results on the SBP from the diffusion case to the jump-diffusion setting.", "published": "2024-11-21T00:28:59Z", "version": 2}, {"aid": "2411.14604", "authors": ["Salvatore Federico", "Fausto Gozzi", "Andrzej \u015awi\u0119ch"], "title": "On Mean Field Games in Infinite Dimension", "url": "http://arxiv.org/pdf/2411.14604v3", "summary": "We study a Mean Field Games (MFG) system in a real, separable infinite dimensional Hilbert space. The system consists of a second order parabolic type equation, called Hamilton-Jacobi-Bellman (HJB) equation in the paper, coupled with a nonlinear Fokker-Planck (FP) equation. Both equations contain a Kolmogorov operator. Solutions to the HJB equation are interpreted in the mild solution sense and solutions to the FP equation are interpreted in an appropriate weak sense. We prove well-posedness of the considered MFG system under certain conditions. The existence of a solution to the MFG system is proved using Tikhonov's fixed point theorem in a proper space. Uniqueness of solutions is obtained under typical separability and Lasry-Lions type monotonicity conditions.", "published": "2024-11-21T22:08:22Z", "version": 3}, {"aid": "2411.16155", "authors": ["Toyotaro Suzumura", "Hiroki Kanezashi", "Shotaro Akahori"], "title": "Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning", "url": "http://arxiv.org/pdf/2411.16155v2", "summary": "In diagnosing neurological disorders from electroencephalography (EEG) data, foundation models such as Transformers have been employed to capture temporal dynamics. Additionally, Graph Neural Networks (GNNs) are critical for representing the spatial relationships among EEG sensors. However, fine-tuning these large-scale models for both temporal and spatial features can be prohibitively large in computational cost, especially under the limited availability of labeled EEG datasets. We propose EEG-GraphAdapter (EGA), a parameter-efficient fine-tuning (PEFT) approach designed to address these challenges. EGA is integrated into a pre-trained temporal backbone model as a GNN-based module, freezing the backbone and allowing only the adapter to be fine-tuned. This enables the effective acquisition of EEG spatial representations, significantly reducing computational overhead and data requirements. Experimental evaluations on two healthcare-related downstream tasks-Major Depressive Disorder (MDD) and Abnormality Detection (TUAB)-show that EGA improves performance by up to 16.1% in F1-score compared with the backbone BENDR model, highlighting its potential for scalable and accurate EEG-based predictions.", "published": "2024-11-25T07:30:52Z", "version": 2}, {"aid": "2412.02482", "authors": ["Andreas C. Schneider", "Valentin Neuhaus", "David A. Ehrlich", "Abdullah Makkeh", "Alexander S. Ecker", "Viola Priesemann", "Michael Wibral"], "title": "What should a neuron aim for? Designing local objective functions based on information theory", "url": "http://arxiv.org/pdf/2412.02482v4", "summary": "In modern deep neural networks, the learning dynamics of the individual neurons is often obscure, as the networks are trained via global optimization. Conversely, biological systems build on self-organized, local learning, achieving robustness and efficiency with limited global information. We here show how self-organization between individual artificial neurons can be achieved by designing abstract bio-inspired local learning goals. These goals are parameterized using a recent extension of information theory, Partial Information Decomposition (PID), which decomposes the information that a set of information sources holds about an outcome into unique, redundant and synergistic contributions. Our framework enables neurons to locally shape the integration of information from various input classes, i.e. feedforward, feedback, and lateral, by selecting which of the three inputs should contribute uniquely, redundantly or synergistically to the output. This selection is expressed as a weighted sum of PID terms, which, for a given problem, can be directly derived from intuitive reasoning or via numerical optimization, offering a window into understanding task-relevant local information processing. Achieving neuron-level interpretability while enabling strong performance using local learning, our work advances a principled information-theoretic foundation for local learning strategies.", "published": "2024-12-03T14:45:46Z", "version": 4}, {"aid": "2412.02865", "authors": ["Trung-Anh Dang", "Vincent Nguyen", "Ngoc-Son Vu", "Christel Vrain"], "title": "Memory-efficient Continual Learning with Neural Collapse Contrastive", "url": "http://arxiv.org/pdf/2412.02865v3", "summary": "Contrastive learning has significantly improved representation quality, enhancing knowledge transfer across tasks in continual learning (CL). However, catastrophic forgetting remains a key challenge, as contrastive based methods primarily focus on \"soft relationships\" or \"softness\" between samples, which shift with changing data distributions and lead to representation overlap across tasks. Recently, the newly identified Neural Collapse phenomenon has shown promise in CL by focusing on \"hard relationships\" or \"hardness\" between samples and fixed prototypes. However, this approach overlooks \"softness\", crucial for capturing intra-class variability, and this rigid focus can also pull old class representations toward current ones, increasing forgetting. Building on these insights, we propose Focal Neural Collapse Contrastive (FNC^2), a novel representation learning loss that effectively balances both soft and hard relationships. Additionally, we introduce the Hardness-Softness Distillation (HSD) loss to progressively preserve the knowledge gained from these relationships across tasks. Our method outperforms state-of-the-art approaches, particularly in minimizing memory reliance. Remarkably, even without the use of memory, our approach rivals rehearsal-based methods, offering a compelling solution for data privacy concerns.", "published": "2024-12-03T22:00:12Z", "version": 3}, {"aid": "2412.05343", "authors": ["Marien Renaud", "Arthur Leclaire", "Nicolas Papadakis"], "title": "Equivariant Denoisers for Image Restoration", "url": "http://arxiv.org/pdf/2412.05343v2", "summary": "One key ingredient of image restoration is to define a realistic prior on clean images to complete the missing information in the observation. State-of-the-art restoration methods rely on a neural network to encode this prior. Moreover, typical image distributions are invariant to some set of transformations, such as rotations or flips. However, most deep architectures are not designed to represent an invariant image distribution. Recent works have proposed to overcome this difficulty by including equivariance properties within a Plug-and-Play paradigm. In this work, we propose a unified framework named Equivariant Regularization by Denoising (ERED) based on equivariant denoisers and stochastic optimization. We analyze the convergence of this algorithm and discuss its practical benefit.", "published": "2024-12-06T10:22:00Z", "version": 2}, {"aid": "2412.07904", "authors": ["Stephen Robbins"], "title": "Score Change of Variables", "url": "http://arxiv.org/pdf/2412.07904v3", "summary": "We derive a general change of variables formula for score functions, showing that for a smooth, invertible transformation $\\mathbf{y} = \\phi(\\mathbf{x})$, the transformed score function $\\nabla_{\\mathbf{y}} \\log q(\\mathbf{y})$ can be expressed directly in terms of $\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})$. Using this result, we develop two applications: First, we establish a reverse-time It\\^o lemma for score-based diffusion models, allowing the use of $\\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x})$ to reverse an SDE in the transformed space without directly learning $\\nabla_{\\mathbf{y}} \\log q_t(\\mathbf{y})$. This approach enables training diffusion models in one space but sampling in another, effectively decoupling the forward and reverse processes. Second, we introduce generalized sliced score matching, extending traditional sliced score matching from linear projections to arbitrary smooth transformations. This provides greater flexibility in high-dimensional density estimation. We demonstrate these theoretical advances through applications to diffusion on the probability simplex and empirically compare our generalized score matching approach against traditional sliced score matching methods.", "published": "2024-12-10T20:27:15Z", "version": 3}, {"aid": "2412.10958", "authors": ["Hao Chen", "Ze Wang", "Xiang Li", "Ximeng Sun", "Fangyi Chen", "Jiang Liu", "Jindong Wang", "Bhiksha Raj", "Zicheng Liu", "Emad Barsoum"], "title": "SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer", "url": "http://arxiv.org/pdf/2412.10958v3", "summary": "Efficient image tokenization with high compression ratios remains a critical challenge for training generative models. We present SoftVQ-VAE, a continuous image tokenizer that leverages soft categorical posteriors to aggregate multiple codewords into each latent token, substantially increasing the representation capacity of the latent space. When applied to Transformer-based architectures, our approach compresses 256x256 and 512x512 images using as few as 32 or 64 1-dimensional tokens. Not only does SoftVQ-VAE show consistent and high-quality reconstruction, more importantly, it also achieves state-of-the-art and significantly faster image generation results across different denoising-based generative models. Remarkably, SoftVQ-VAE improves inference throughput by up to 18x for generating 256x256 images and 55x for 512x512 images while achieving competitive FID scores of 1.78 and 2.21 for SiT-XL. It also improves the training efficiency of the generative models by reducing the number of training iterations by 2.3x while maintaining comparable performance. With its fully-differentiable design and semantic-rich latent space, our experiment demonstrates that SoftVQ-VAE achieves efficient tokenization without compromising generation quality, paving the way for more efficient generative models. Code and model are released.", "published": "2024-12-14T20:29:29Z", "version": 3}, {"aid": "2412.13148", "authors": ["Chao Ma", "Wenbo Gong", "Meyer Scetbon", "Edward Meeds"], "title": "SWAN: SGD with Normalization and Whitening Enables Stateless LLM Training", "url": "http://arxiv.org/pdf/2412.13148v3", "summary": "Adaptive optimizers such as Adam (Kingma & Ba, 2015) have been central to the success of large language models. However, they often require to maintain optimizer states throughout training, which can result in memory requirements several times greater than the model footprint. This overhead imposes constraints on scalability and computational efficiency. Stochastic Gradient Descent (SGD), in contrast, is a stateless optimizer, as it does not track state variables during training. Consequently, it achieves optimal memory efficiency. However, its capability in LLM training is limited (Zhao et al., 2024b). In this work, we show that pre-processing SGD in a stateless manner can achieve the same performance as the Adam optimizer for LLM training, while drastically reducing the memory cost. Specifically, we propose to pre-process the instantaneous stochastic gradients using normalization and whitening. We show that normalization stabilizes gradient distributions, and whitening counteracts the local curvature of the loss landscape. This results in SWAN (SGD with Whitening And Normalization), a stochastic optimizer that eliminates the need to store any optimizer states. Empirically, SWAN has the same memory footprint as SGD, achieving $\\approx 50\\%$ reduction on total end-to-end memory compared to Adam. In language modeling tasks, SWAN demonstrates comparable or even better performance than Adam: when pre-training the LLaMA model with 350M and 1.3B parameters, SWAN achieves a 2x speedup by reaching the same evaluation perplexity using half as many tokens.", "published": "2024-12-17T18:13:18Z", "version": 3}, {"aid": "2501.02950", "authors": ["Samuel J. Gershman", "Ila Fiete", "Kazuki Irie"], "title": "Key-value memory in the brain", "url": "http://arxiv.org/pdf/2501.02950v2", "summary": "Classical models of memory in psychology and neuroscience rely on similarity-based retrieval of stored patterns, where similarity is a function of retrieval cues and the stored patterns. While parsimonious, these models do not allow distinct representations for storage and retrieval, despite their distinct computational demands. Key-value memory systems, in contrast, distinguish representations used for storage (values) and those used for retrieval (keys). This allows key-value memory systems to optimize simultaneously for fidelity in storage and discriminability in retrieval. We review the computational foundations of key-value memory, its role in modern machine learning systems, related ideas from psychology and neuroscience, applications to a number of empirical puzzles, and possible biological implementations.", "published": "2025-01-06T11:46:40Z", "version": 2}, {"aid": "2501.09038", "authors": ["Saman Motamed", "Laura Culp", "Kevin Swersky", "Priyank Jaini", "Robert Geirhos"], "title": "Do generative video models understand physical principles?", "url": "http://arxiv.org/pdf/2501.09038v3", "summary": "AI video generation is undergoing a revolution, with quality and realism advancing rapidly. These advances have led to a passionate scientific debate: Do video models learn \"world models\" that discover laws of physics -- or, alternatively, are they merely sophisticated pixel predictors that achieve visual realism without understanding the physical principles of reality? We address this question by developing Physics-IQ, a comprehensive benchmark dataset that can only be solved by acquiring a deep understanding of various physical principles, like fluid dynamics, optics, solid mechanics, magnetism and thermodynamics. We find that across a range of current models (Sora, Runway, Pika, Lumiere, Stable Video Diffusion, and VideoPoet), physical understanding is severely limited, and unrelated to visual realism. At the same time, some test cases can already be successfully solved. This indicates that acquiring certain physical principles from observation alone may be possible, but significant challenges remain. While we expect rapid advances ahead, our work demonstrates that visual realism does not imply physical understanding. Our project page is at https://physics-iq.github.io; code at https://github.com/google-deepmind/physics-IQ-benchmark.", "published": "2025-01-14T20:59:37Z", "version": 3}, {"aid": "2501.10091", "authors": ["Christian Rahe", "Walid Maalej"], "title": "How Do Programming Students Use Generative AI?", "url": "http://arxiv.org/pdf/2501.10091v2", "summary": "Programming students have a widespread access to powerful Generative AI tools like ChatGPT. While this can help understand the learning material and assist with exercises, educators are voicing more and more concerns about an overreliance on generated outputs and lack of critical thinking skills. It is thus important to understand how students actually use generative AI and what impact this could have on their learning behavior. To this end, we conducted a study including an exploratory experiment with 37 programming students, giving them monitored access to ChatGPT while solving a code authoring exercise. The task was not directly solvable by ChatGPT and required code comprehension and reasoning. While only 23 of the students actually opted to use the chatbot, the majority of those eventually prompted it to simply generate a full solution. We observed two prevalent usage strategies: to seek knowledge about general concepts and to directly generate solutions. Instead of using the bot to comprehend the code and their own mistakes, students often got trapped in a vicious cycle of submitting wrong generated code and then asking the bot for a fix. Those who self-reported using generative AI regularly were more likely to prompt the bot to generate a solution. Our findings indicate that concerns about potential decrease in programmers' agency and productivity with Generative AI are justified. We discuss how researchers and educators can respond to the potential risk of students uncritically over-relying on Generative AI. We also discuss potential modifications to our study design for large-scale replications.", "published": "2025-01-17T10:25:41Z", "version": 2}, {"aid": "2501.11566", "authors": ["Arthur Dehgan", "Hamza Abdelhedi", "Vanessa Hadid", "Irina Rish", "Karim Jerbi"], "title": "Artificial Neural Networks for Magnetoencephalography: A review of an emerging field", "url": "http://arxiv.org/pdf/2501.11566v4", "summary": "Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that measures the intricate brain dynamics underlying cognitive processes with an unparalleled combination of high temporal and spatial precision. MEG data analytics has always relied on advanced signal processing and mathematical and statistical tools for various tasks ranging from data cleaning to probing the signals' rich dynamics and estimating the neural sources underlying the surface-level recordings. Like in most domains, the surge in Artificial Intelligence (AI) has led to the increased use of Machine Learning (ML) methods for MEG data classification. More recently, an emerging trend in this field is using Artificial Neural Networks (ANNs) to address many MEG-related tasks. This review provides a comprehensive overview of how ANNs are being used with MEG data from three vantage points: First, we review work that employs ANNs for MEG signal classification, i.e., for brain decoding. Second, we report on work that has used ANNs as putative models of information processing in the human brain. Finally, we examine studies that use ANNs as techniques to tackle methodological questions in MEG, including artifact correction and source estimation. Furthermore, we assess the current strengths and limitations of using ANNs with MEG and discuss future challenges and opportunities in this field. Finally, by establishing a detailed portrait of the field and providing practical recommendations for the future, this review seeks to provide a helpful reference for both seasoned MEG researchers and newcomers to the field who are interested in using ANNs to enhance the exploration of the complex dynamics of the human brain with MEG.", "published": "2025-01-20T16:17:12Z", "version": 4}, {"aid": "2502.05749", "authors": ["Kaizhen Zhu", "Mokai Pan", "Yuexin Ma", "Yanwei Fu", "Jingyi Yu", "Jingya Wang", "Ye Shi"], "title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control", "url": "http://arxiv.org/pdf/2502.05749v5", "summary": "Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at https://github.com/UniDB-SOC/UniDB/.", "published": "2025-02-09T02:43:57Z", "version": 5}, {"aid": "2502.06034", "authors": ["Mozes Jacobs", "Roberto C. Budzinski", "Lyle Muller", "Demba Ba", "T. Anderson Keller"], "title": "Traveling Waves Integrate Spatial Information Through Time", "url": "http://arxiv.org/pdf/2502.06034v4", "summary": "Traveling waves of neural activity are widely observed in the brain, but their precise computational function remains unclear. One prominent hypothesis is that they enable the transfer and integration of spatial information across neural populations. However, few computational models have explored how traveling waves might be harnessed to perform such integrative processing. Drawing inspiration from the famous \"Can one hear the shape of a drum?\" problem -- which highlights how normal modes of wave dynamics encode geometric information -- we investigate whether similar principles can be leveraged in artificial neural networks. Specifically, we introduce convolutional recurrent neural networks that learn to produce traveling waves in their hidden states in response to visual stimuli, enabling spatial integration. By then treating these wave-like activation sequences as visual representations themselves, we obtain a powerful representational space that outperforms local feed-forward networks on tasks requiring global spatial context. In particular, we observe that traveling waves effectively expand the receptive field of locally connected neurons, supporting long-range encoding and communication of information. We demonstrate that models equipped with this mechanism solve visual semantic segmentation tasks demanding global integration, significantly outperforming local feed-forward models and rivaling non-local U-Net models with fewer parameters. As a first step toward traveling-wave-based communication and visual representation in artificial networks, our findings suggest wave-dynamics may provide efficiency and training stability benefits, while simultaneously offering a new framework for connecting models to biological recordings of neural activity.", "published": "2025-02-09T21:14:27Z", "version": 4}, {"aid": "2502.06910", "authors": ["Songtao Huang", "Zhen Zhao", "Can Li", "Lei Bai"], "title": "TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting", "url": "http://arxiv.org/pdf/2502.06910v2", "summary": "Real-world time series often have multiple frequency components that are intertwined with each other, making accurate time series forecasting challenging. Decomposing the mixed frequency components into multiple single frequency components is a natural choice. However, the information density of patterns varies across different frequencies, and employing a uniform modeling approach for different frequency components can lead to inaccurate characterization. To address this challenges, inspired by the flexibility of the recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency Decomposition Learning architecture (TimeKAN) to address the complex forecasting challenges caused by multiple frequency mixtures. Specifically, TimeKAN mainly consists of three components: Cascaded Frequency Decomposition (CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and Frequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to obtain series representations for each frequency band. Benefiting from the high flexibility of KAN, we design a novel M-KAN block to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks is used to recombine the frequency bands into the original format. Extensive experimental results across multiple real-world time series datasets demonstrate that TimeKAN achieves state-of-the-art performance as an extremely lightweight architecture. Code is available at https://github.com/huangst21/TimeKAN.", "published": "2025-02-10T03:51:26Z", "version": 2}, {"aid": "2502.17460", "authors": ["B\u00e1lint T\u00f3th", "Dominik Senti", "Thorir Mar Ingolfsson", "Jeffrey Zweidler", "Alexandre Elsig", "Luca Benini", "Yawei Li"], "title": "Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation", "url": "http://arxiv.org/pdf/2502.17460v1", "summary": "Blood pressure (BP) is a key indicator of cardiovascular health. As hypertension remains a global cause of morbidity and mortality, accurate, continuous, and non-invasive BP monitoring is therefore of paramount importance. Photoplethysmography (PPG) and electrocardiography (ECG) can potentially enable continuous BP monitoring, yet training accurate and robust machine learning (ML) models remains challenging due to variability in data quality and patient-specific factors. Recently, multiple research groups explored Electroencephalographic (EEG)--based foundation models and demonstrated their exceptional ability to learn rich temporal resolution. Considering the morphological similarities between different biosignals, the question arises of whether a model pre-trained on one modality can effectively be exploited to improve the accuracy of a different signal type. In this work, we take an initial step towards generalized biosignal foundation models by investigating whether model representations learned from abundant EEG data can effectively be transferred to ECG/PPG data solely with fine-tuning, without the need for large-scale additional pre-training, for the BP estimation task. Evaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach achieves near state-of-the-art accuracy for diastolic BP (mean absolute error of 1.57 mmHg) and surpasses by 1.5x the accuracy of prior works for systolic BP (mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8 quantization, reducing the smallest model size by over 3.5x (from 13.73 MB down to 3.83 MB) while preserving performance, thereby enabling unobtrusive, real-time BP monitoring on resource-constrained wearable devices.", "published": "2025-02-10T13:33:12Z", "version": 1}, {"aid": "2502.17462", "authors": ["Francesco Stefano Carzaniga", "Gary Tom Hoppeler", "Michael Hersche", "Kaspar Anton Schindler", "Abbas Rahimi"], "title": "The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG", "url": "http://arxiv.org/pdf/2502.17462v1", "summary": "All data modalities are not created equal, even when the signal they measure comes from the same source. In the case of the brain, two of the most important data modalities are the scalp electroencephalogram (EEG), and the intracranial electroencephalogram (iEEG). They are used by human experts, supported by deep learning (DL) models, to accomplish a variety of tasks, such as seizure detection and motor imagery classification. Although the differences between EEG and iEEG are well understood by human experts, the performance of DL models across these two modalities remains under-explored. To help characterize the importance of clean data on the performance of DL models, we propose BrainCodec, a high-fidelity EEG and iEEG neural compressor. We find that training BrainCodec on iEEG and then transferring to EEG yields higher reconstruction quality than training on EEG directly. In addition, we also find that training BrainCodec on both EEG and iEEG improves fidelity when reconstructing EEG. Our work indicates that data sources with higher SNR, such as iEEG, provide better performance across the board also in the medical time-series domain. BrainCodec also achieves up to a 64x compression on iEEG and EEG without a notable decrease in quality. BrainCodec markedly surpasses current state-of-the-art compression models both in final compression ratio and in reconstruction fidelity. We also evaluate the fidelity of the compressed signals objectively on a seizure detection and a motor imagery task performed by standard DL models. Here, we find that BrainCodec achieves a reconstruction fidelity high enough to ensure no performance degradation on the downstream tasks. Finally, we collect the subjective assessment of an expert neurologist, that confirms the high reconstruction quality of BrainCodec in a realistic scenario. The code is available at https://github.com/IBM/eeg-ieeg-brain-compressor.", "published": "2025-02-10T15:05:06Z", "version": 1}, {"aid": "2502.07828", "authors": ["Herbert Roitblat"], "title": "Some things to know about achieving artificial general intelligence", "url": "http://arxiv.org/pdf/2502.07828v1", "summary": "Current and foreseeable GenAI models are not capable of achieving artificial general intelligence because they are burdened with anthropogenic debt. They depend heavily on human input to provide well-structured problems, architecture, and training data. They cast every problem as a language pattern learning problem and are thus not capable of the kind of autonomy needed to achieve artificial general intelligence. Current models succeed at their tasks because people solve most of the problems to which these models are directed, leaving only simple computations for the model to perform, such as gradient descent. Another barrier is the need to recognize that there are multiple kinds of problems, some of which cannot be solved by available computational methods (for example, \"insight problems\"). Current methods for evaluating models (benchmarks and tests) are not adequate to identify the generality of the solutions, because it is impossible to infer the means by which a problem was solved from the fact of its solution. A test could be passed, for example, by a test-specific or a test-general method. It is a logical fallacy (affirming the consequent) to infer a method of solution from the observation of success.", "published": "2025-02-10T20:10:26Z", "version": 1}, {"aid": "2502.07247", "authors": ["Nir Lahav", "Zachariah A. Neemeh"], "title": "A Relativistic Theory of Consciousness (shortened version)", "url": "http://arxiv.org/pdf/2502.07247v3", "summary": "This paper is a shortened version of the full paper that was published in the journal Frontiers of Psychology in May 2022. In recent decades, the scientific study of consciousness has significantly increased our understanding of this elusive phenomenon. Yet, despite critical development in our understanding of the functional side of consciousness, we still lack a fundamental theory regarding its phenomenal aspect. The phenomenal aspect of consciousness is the first-person answer to what it is like question, and it has thus far proved recalcitrant to direct scientific investigation. The question of how the brain, or any cognitive system, can create conscious experience out of neural representations poses a great conundrum to science. Naturalistic dualists argue that it is composed of a primitive, private, nonreductive element of reality. Illusionists, on the other hand, argue that it is merely a cognitive illusion. We contend that both the dualist and illusionist positions are flawed because they tacitly assume consciousness to be an absolute property that does not depend on the observer. We developed a conceptual and a mathematical argument for a relativistic theory of consciousness in which a system either has or does not have phenomenal consciousness with respect to some observer. According to the theory, Phenomenal consciousness is neither private nor delusional, just relativistic. In the frame of reference of the cognitive system, it will be observable (first-person perspective) and in other frame of reference it will not (third-person perspective). These two cognitive frames of reference are both correct, just as in the case of an observer that claims to be at rest while another will claim that the observer has constant velocity. Neither observer position can be privileged, as they both describe the same underlying reality.", "published": "2025-02-11T04:29:43Z", "version": 3}, {"aid": "2502.09885", "authors": ["YongKyung Oh", "Seungsu Kam", "Jonghun Lee", "Dong-Young Lim", "Sungil Kim", "Alex Bui"], "title": "Comprehensive Review of Neural Differential Equations for Time Series Analysis", "url": "http://arxiv.org/pdf/2502.09885v2", "summary": "Time series modeling and analysis have become critical in various domains. Conventional methods such as RNNs and Transformers, while effective for discrete-time and regularly sampled data, face significant challenges in capturing the continuous dynamics and irregular sampling patterns inherent in real-world scenarios. Neural Differential Equations (NDEs) represent a paradigm shift by combining the flexibility of neural networks with the mathematical rigor of differential equations. This paper presents a comprehensive review of NDE-based methods for time series analysis, including neural ordinary differential equations, neural controlled differential equations, and neural stochastic differential equations. We provide a detailed discussion of their mathematical formulations, numerical methods, and applications, highlighting their ability to model continuous-time dynamics. Furthermore, we address key challenges and future research directions. This survey serves as a foundation for researchers and practitioners seeking to leverage NDEs for advanced time series analysis.", "published": "2025-02-14T03:21:04Z", "version": 2}, {"aid": "2502.09956", "authors": ["Belinda Mo", "Kyssen Yu", "Joshua Kazdan", "Proud Mpala", "Lisa Yu", "Chris Cundy", "Charilaos Kanatsoulis", "Sanmi Koyejo"], "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "url": "http://arxiv.org/pdf/2502.09956v1", "summary": "Recent interest in building foundation models for KGs has highlighted a fundamental challenge: knowledge-graph data is relatively scarce. The best-known KGs are primarily human-labeled, created by pattern-matching, or extracted using early NLP techniques. While human-generated KGs are in short supply, automatically extracted KGs are of questionable quality. We present a solution to this data scarcity problem in the form of a text-to-KG generator (KGGen), a package that uses language models to create high-quality graphs from plaintext. Unlike other KG extractors, KGGen clusters related entities to reduce sparsity in extracted KGs. KGGen is available as a Python library (\\texttt{pip install kg-gen}), making it accessible to everyone. Along with KGGen, we release the first benchmark, Measure of of Information in Nodes and Edges (MINE), that tests an extractor's ability to produce a useful KG from plain text. We benchmark our new tool against existing extractors and demonstrate far superior performance.", "published": "2025-02-14T07:28:08Z", "version": 1}, {"aid": "2502.10368", "authors": ["John H. Selby", "Maria E. Stasinou", "Matt Wilson", "Bob Coecke"], "title": "Generalised Process Theories", "url": "http://arxiv.org/pdf/2502.10368v2", "summary": "Process theories provide a powerful framework for describing compositional structures across diverse fields, from quantum mechanics to computational linguistics. Traditionally, they have been formalized using symmetric monoidal categories (SMCs). However, various generalizations, including time-neutral, higher-order, and enriched process theories, do not naturally conform to this structure. In this work, we propose an alternative formalization using operad algebras, motivated by recent results connecting SMCs to operadic structures, which captures a broader class of process theories. By leveraging the string-diagrammatic language, we provide an accessible yet rigorous formulation that unifies and extends traditional process-theoretic approaches. Our operadic framework not only recovers standard process theories as a special case but also enables new insights into quantum foundations and compositional structures. This work paves the way for further investigations into the algebraic and operational properties of generalised process theories within an operadic setting.", "published": "2025-02-14T18:47:07Z", "version": 2}, {"aid": "2502.11089", "authors": ["Jingyang Yuan", "Huazuo Gao", "Damai Dai", "Junyu Luo", "Liang Zhao", "Zhengyan Zhang", "Zhenda Xie", "Y. X. Wei", "Lean Wang", "Zhiping Xiao", "Yuqing Wang", "Chong Ruan", "Ming Zhang", "Wenfeng Liang", "Wangding Zeng"], "title": "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention", "url": "http://arxiv.org/pdf/2502.11089v2", "summary": "Long-context modeling is crucial for next-generation language models, yet the high computational cost of standard attention mechanisms poses significant computational challenges. Sparse attention offers a promising direction for improving efficiency while maintaining model capabilities. We present NSA, a Natively trainable Sparse Attention mechanism that integrates algorithmic innovations with hardware-aligned optimizations to achieve efficient long-context modeling. NSA employs a dynamic hierarchical sparse strategy, combining coarse-grained token compression with fine-grained token selection to preserve both global context awareness and local precision. Our approach advances sparse attention design with two key innovations: (1) We achieve substantial speedups through arithmetic intensity-balanced algorithm design, with implementation optimizations for modern hardware. (2) We enable end-to-end training, reducing pretraining computation without sacrificing model performance. As shown in Figure 1, experiments show the model pretrained with NSA maintains or exceeds Full Attention models across general benchmarks, long-context tasks, and instruction-based reasoning. Meanwhile, NSA achieves substantial speedups over Full Attention on 64k-length sequences across decoding, forward propagation, and backward propagation, validating its efficiency throughout the model lifecycle.", "published": "2025-02-16T11:53:44Z", "version": 2}, {"aid": "2502.13161", "authors": ["Maxwell J. D. Ramstead", "Candice Pattisapu", "Jason Fox", "Jeff Beck"], "title": "Noumenal Labs White Paper: How To Build A Brain", "url": "http://arxiv.org/pdf/2502.13161v1", "summary": "This white paper describes some of the design principles for artificial or machine intelligence that guide efforts at Noumenal Labs. These principles are drawn from both nature and from the means by which we come to represent and understand it. The end goal of research and development in this field should be to design machine intelligences that augment our understanding of the world and enhance our ability to act in it, without replacing us. In the first two sections, we examine the core motivation for our approach: resolving the grounding problem. We argue that the solution to the grounding problem rests in the design of models grounded in the world that we inhabit, not mere word models. A machine super intelligence that is capable of significantly enhancing our understanding of the human world must represent the world as we do and be capable of generating new knowledge, building on what we already know. In other words, it must be properly grounded and explicitly designed for rational, empirical inquiry, modeled after the scientific method. A primary implication of this design principle is that agents must be capable of engaging autonomously in causal physics discovery. We discuss the pragmatic implications of this approach, and in particular, the use cases in realistic 3D world modeling and multimodal, multidimensional time series analysis.", "published": "2025-02-16T18:15:37Z", "version": 1}, {"aid": "2502.11492", "authors": ["Kung-Hsiang Huang", "Can Qin", "Haoyi Qiu", "Philippe Laban", "Shafiq Joty", "Caiming Xiong", "Chien-Sheng Wu"], "title": "Why Vision Language Models Struggle with Visual Arithmetic? Towards Enhanced Chart and Geometry Understanding", "url": "http://arxiv.org/pdf/2502.11492v3", "summary": "Vision Language Models (VLMs) have achieved remarkable progress in multimodal tasks, yet they often struggle with visual arithmetic, seemingly simple capabilities like object counting or length comparison, which are essential for relevant complex tasks like chart understanding and geometric reasoning. In this work, we first investigate the root causes of this deficiency through a suite of probing tasks focusing on basic visual arithmetic. Our analysis reveals that while pre-trained vision encoders typically capture sufficient information, the text decoder often fails to decode it correctly for arithmetic reasoning. To address this, we propose CogAlign, a novel post-training strategy inspired by Piaget's theory of cognitive development. CogAlign trains VLMs to recognize invariant properties under visual transformations. We demonstrate that this approach significantly improves the performance of three diverse VLMs on our proposed probing tasks. Furthermore, CogAlign enhances performance by an average of 4.6% on CHOCOLATE and 2.9% on MATH-VISION, outperforming or matching supervised fine-tuning methods while requiring only 60% less training data. These results highlight the effectiveness and generalizability of CogAlign in improving fundamental visual arithmetic capabilities and their transfer to downstream tasks.", "published": "2025-02-17T06:54:49Z", "version": 3}, {"aid": "2502.12048", "authors": ["Shreya Shukla", "Jose Torres", "Abhijit Mishra", "Jacek Gwizdka", "Shounak Roychowdhury"], "title": "A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond", "url": "http://arxiv.org/pdf/2502.12048v2", "summary": "Integration of Brain-Computer Interfaces (BCIs) and Generative Artificial Intelligence (GenAI) has opened new frontiers in brain signal decoding, enabling assistive communication, neural representation learning, and multimodal integration. BCIs, particularly those leveraging Electroencephalography (EEG), provide a non-invasive means of translating neural activity into meaningful outputs. Recent advances in deep learning, including Generative Adversarial Networks (GANs) and Transformer-based Large Language Models (LLMs), have significantly improved EEG-based generation of images, text, and speech. This paper provides a literature review of the state-of-the-art in EEG-based multimodal generation, focusing on (i) EEG-to-image generation through GANs, Variational Autoencoders (VAEs), and Diffusion Models, and (ii) EEG-to-text generation leveraging Transformer based language models and contrastive learning methods. Additionally, we discuss the emerging domain of EEG-to-speech synthesis, an evolving multimodal frontier. We highlight key datasets, use cases, challenges, and EEG feature encoding methods that underpin generative approaches. By providing a structured overview of EEG-based generative AI, this survey aims to equip researchers and practitioners with insights to advance neural decoding, enhance assistive technologies, and expand the frontiers of brain-computer interaction.", "published": "2025-02-17T17:16:41Z", "version": 2}, {"aid": "2502.12298", "authors": ["Aditya Ranganath", "Mukesh Singhal", "Roummel Marcia"], "title": "Symmetric Rank-One Quasi-Newton Methods for Deep Learning Using Cubic Regularization", "url": "http://arxiv.org/pdf/2502.12298v1", "summary": "Stochastic gradient descent and other first-order variants, such as Adam and AdaGrad, are commonly used in the field of deep learning due to their computational efficiency and low-storage memory requirements. However, these methods do not exploit curvature information. Consequently, iterates can converge to saddle points or poor local minima. On the other hand, Quasi-Newton methods compute Hessian approximations which exploit this information with a comparable computational budget. Quasi-Newton methods re-use previously computed iterates and gradients to compute a low-rank structured update. The most widely used quasi-Newton update is the L-BFGS, which guarantees a positive semi-definite Hessian approximation, making it suitable in a line search setting. However, the loss functions in DNNs are non-convex, where the Hessian is potentially non-positive definite. In this paper, we propose using a limited-memory symmetric rank-one quasi-Newton approach which allows for indefinite Hessian approximations, enabling directions of negative curvature to be exploited. Furthermore, we use a modified adaptive regularized cubics approach, which generates a sequence of cubic subproblems that have closed-form solutions with suitable regularization choices. We investigate the performance of our proposed method on autoencoders and feed-forward neural network models and compare our approach to state-of-the-art first-order adaptive stochastic methods as well as other quasi-Newton methods.x", "published": "2025-02-17T20:20:11Z", "version": 1}, {"aid": "2502.12524", "authors": ["Yunjie Tian", "Qixiang Ye", "David Doermann"], "title": "YOLOv12: Attention-Centric Real-Time Object Detectors", "url": "http://arxiv.org/pdf/2502.12524v1", "summary": "Enhancing the network architecture of the YOLO framework has been crucial for a long time, but has focused on CNN-based improvements despite the proven superiority of attention mechanisms in modeling capabilities. This is because attention-based models cannot match the speed of CNN-based models. This paper proposes an attention-centric YOLO framework, namely YOLOv12, that matches the speed of previous CNN-based ones while harnessing the performance benefits of attention mechanisms. YOLOv12 surpasses all popular real-time object detectors in accuracy with competitive speed. For example, YOLOv12-N achieves 40.6% mAP with an inference latency of 1.64 ms on a T4 GPU, outperforming advanced YOLOv10-N / YOLOv11-N by 2.1%/1.2% mAP with a comparable speed. This advantage extends to other model scales. YOLOv12 also surpasses end-to-end real-time detectors that improve DETR, such as RT-DETR / RT-DETRv2: YOLOv12-S beats RT-DETR-R18 / RT-DETRv2-R18 while running 42% faster, using only 36% of the computation and 45% of the parameters. More comparisons are shown in Figure 1.", "published": "2025-02-18T04:20:14Z", "version": 1}, {"aid": "2502.12567", "authors": ["Chao Yang", "Yong Fan", "Qichao Zhang", "Cheng Lu", "Zhijing Yang"], "title": "DeltaDiff: Reality-Driven Diffusion with AnchorResiduals for Faithful SR", "url": "http://arxiv.org/pdf/2502.12567v2", "summary": "Recently, the transfer application of diffusion models in super-resolu-tion tasks has faced the problem ofdecreased fidelity. Due to the inherent randomsampling characteristics ofdiffusion models, direct application in super-resolu-tion tasks can result in generated details deviating from the true distribution ofhigh-resolution images. To address this, we propose DeltaDiff, a novel frame.work that constrains the difusion process, its essence is to establish a determin-istic mapping path between HR and LR, rather than the random noise disturbanceprocess oftraditional difusion models. Theoretical analysis demonstrates a 25%reduction in diffusion entropy in the residual space compared to pixel-space diffiusion, effectively suppressing irrelevant noise interference. The experimentalresults show that our method surpasses state-of-the-art models and generates re-sults with better fidelity. This work establishes a new low-rank constrained par-adigm for applying diffusion models to image reconstruction tasks, balancingstochastic generation with structural fidelity. Our code and model are publiclyavailable at https://github.com/continueyang/DeltaDiff .", "published": "2025-02-18T06:07:14Z", "version": 2}, {"aid": "2502.13200", "authors": ["Alana Santana", "Paula P. Costa", "Esther L. Colombini"], "title": "Learning To Explore With Predictive World Model Via Self-Supervised Learning", "url": "http://arxiv.org/pdf/2502.13200v1", "summary": "Autonomous artificial agents must be able to learn behaviors in complex environments without humans to design tasks and rewards. Designing these functions for each environment is not feasible, thus, motivating the development of intrinsic reward functions. In this paper, we propose using several cognitive elements that have been neglected for a long time to build an internal world model for an intrinsically motivated agent. Our agent performs satisfactory iterations with the environment, learning complex behaviors without needing previously designed reward functions. We used 18 Atari games to evaluate what cognitive skills emerge in games that require reactive and deliberative behaviors. Our results show superior performance compared to the state-of-the-art in many test cases with dense and sparse rewards.", "published": "2025-02-18T18:39:23Z", "version": 1}, {"aid": "2502.13128", "authors": ["Zihan Liu", "Shuangrui Ding", "Zhixiong Zhang", "Xiaoyi Dong", "Pan Zhang", "Yuhang Zang", "Yuhang Cao", "Dahua Lin", "Jiaqi Wang"], "title": "SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation", "url": "http://arxiv.org/pdf/2502.13128v2", "summary": "Text-to-song generation, the task of creating vocals and accompaniment from textual inputs, poses significant challenges due to domain complexity and data scarcity. Existing approaches often employ multi-stage generation procedures, leading to cumbersome training and inference pipelines, as well as suboptimal overall generation quality due to error accumulation across stages. In this paper, we propose SongGen, a fully open-source, single-stage auto-regressive transformer designed for controllable song generation. The proposed model facilitates fine-grained control over diverse musical attributes, including lyrics and textual descriptions of instrumentation, genre, mood, and timbre, while also offering an optional three-second reference clip for voice cloning. Within a unified auto-regressive framework, SongGen supports two output modes: mixed mode, which generates a mixture of vocals and accompaniment directly, and dual-track mode, which synthesizes them separately for greater flexibility in downstream applications. We explore diverse token pattern strategies for each mode, leading to notable improvements and valuable insights. Furthermore, we design an automated data preprocessing pipeline with effective quality control. To foster community engagement and future research, we will release our model weights, training code, annotated data, and preprocessing pipeline. The code is available at https://github.com/LiuZH-19/SongGen.", "published": "2025-02-18T18:52:21Z", "version": 2}, {"aid": "2502.13729", "authors": ["Takashi Morita"], "title": "Emergence of the Primacy Effect in Structured State-Space Models", "url": "http://arxiv.org/pdf/2502.13729v4", "summary": "Human and animal memory for sequentially presented items is well-documented to be more accurate for those at the beginning and end of the sequence, phenomena known as the primacy and recency effects, respectively. By contrast, artificial neural network (ANN) models are typically designed with a memory that decays monotonically over time. Accordingly, ANNs are expected to show the recency effect but not the primacy effect. Contrary to this theoretical expectation, however, the present study reveals a counterintuitive finding: a recently developed ANN architecture, called structured state-space models, exhibits the primacy effect when trained and evaluated on a synthetic task that mirrors psychological memory experiments. Given that this model was originally designed for recovering neuronal activity patterns observed in biological brains, this result provides a novel perspective on the psychological primacy effect while also posing a non-trivial puzzle for the current theories in machine learning.", "published": "2025-02-19T13:55:32Z", "version": 4}, {"aid": "2502.13810", "authors": ["Matthew Pugh", "Jo Grundy", "Corina Cirstea", "Nick Harris"], "title": "Learning Is a Kan Extension", "url": "http://arxiv.org/pdf/2502.13810v1", "summary": "Previous work has demonstrated that efficient algorithms exist for computing Kan extensions and that some Kan extensions have interesting similarities to various machine learning algorithms. This paper closes the gap by proving that all error minimisation algorithms may be presented as a Kan extension. This result provides a foundation for future work to investigate the optimisation of machine learning algorithms through their presentation as Kan extensions. A corollary of this representation of error-minimising algorithms is a presentation of error from the perspective of lossy and lossless transformations of data.", "published": "2025-02-19T15:25:44Z", "version": 1}, {"aid": "2502.14941", "authors": ["Mika Bohinen", "Paolo Perrone"], "title": "Categorical algebra of conditional probability", "url": "http://arxiv.org/pdf/2502.14941v1", "summary": "In the field of categorical probability, one uses concepts and techniques from category theory, such as monads and monoidal categories, to study the structures of probability and statistics. In this paper, we connect some ideas from categorical algebra, namely weakly cartesian functors and natural transformations, to the idea of conditioning in probability theory, using Markov categories and probability monads. First of all, we show that under some conditions, the monad associated to a Markov category with conditionals has a weakly cartesian functor and weakly cartesian multiplication (a condition known as Beck-Chevalley, or BC). In particular, we show that this is the case for the Giry monad on standard Borel spaces. We then connect this theory to existing results on statistical experiments. We show that for deterministic statistical experiments, the so-called standard measure construction (which can be seen as a generalization of the \"hyper-normalizations\" introduced by Jacobs) satisfies a universal property, allowing an equivalent definition which does not rely on the existence of conditionals.", "published": "2025-02-20T17:33:55Z", "version": 1}, {"aid": "2502.14831", "authors": ["Ivan Skorokhodov", "Sharath Girish", "Benran Hu", "Willi Menapace", "Yanyu Li", "Rameen Abdal", "Sergey Tulyakov", "Aliaksandr Siarohin"], "title": "Improving the Diffusability of Autoencoders", "url": "http://arxiv.org/pdf/2502.14831v3", "summary": "Latent diffusion models have emerged as the leading approach for generating high-quality images and videos, utilizing compressed latent representations to reduce the computational burden of the diffusion process. While recent advancements have primarily focused on scaling diffusion backbones and improving autoencoder reconstruction quality, the interaction between these components has received comparatively less attention. In this work, we perform a spectral analysis of modern autoencoders and identify inordinate high-frequency components in their latent spaces, which are especially pronounced in the autoencoders with a large bottleneck channel size. We hypothesize that this high-frequency component interferes with the coarse-to-fine nature of the diffusion synthesis process and hinders the generation quality. To mitigate the issue, we propose scale equivariance: a simple regularization strategy that aligns latent and RGB spaces across frequencies by enforcing scale equivariance in the decoder. It requires minimal code changes and only up to 20K autoencoder fine-tuning steps, yet significantly improves generation quality, reducing FID by 19% for image generation on ImageNet-1K $256^2$ and FVD by at least 44% for video generation on Kinetics-700 $17 \\times 256^2$. The source code is available at https://github.com/snap-research/diffusability.", "published": "2025-02-20T18:45:44Z", "version": 3}, {"aid": "2502.14993", "authors": ["Aaron David Fairbanks", "Peter Selinger"], "title": "On Traces in Categories of Contractions", "url": "http://arxiv.org/pdf/2502.14993v2", "summary": "Traced monoidal categories are used to model processes that can feed their outputs back to their own inputs, abstracting iteration. The category of finite dimensional Hilbert spaces with the direct sum tensor is not traced. But surprisingly, in 2014, Bartha showed that the monoidal subcategory of isometries is traced. The same holds for coisometries, unitary maps, and contractions. This suggests the possibility of feeding outputs of quantum processes back to their own inputs, analogous to iteration. In this paper, we show that Bartha's result is not specifically tied to Hilbert spaces, but works in any dagger additive category with Moore-Penrose pseudoinverses (a natural dagger-categorical generalization of inverses).", "published": "2025-02-20T19:34:03Z", "version": 2}, {"aid": "2502.15276", "authors": ["Aaron D. Ames", "Joe Moeller", "Paulo Tabuada"], "title": "Categorical Lyapunov Theory I: Stability of Flows", "url": "http://arxiv.org/pdf/2502.15276v2", "summary": "Lyapunov's theorem provides a fundamental characterization of the stability of dynamical systems. This paper presents a categorical framework for Lyapunov theory, generalizing stability analysis with Lyapunov functions categorically. Core to our approach is the set of axioms underlying a setting for stability, which give the necessary ingredients for ``doing Lyapunov theory'' in a category of interest. With these minimal assumptions, we define the stability of equilibria, formulate Lyapunov morphisms, and demonstrate that the existence of Lyapunov morphisms is necessary and sufficient for establishing the stability of flows. To illustrate these constructions, we show how classical notions of stability, e.g., for continuous and discrete time dynamical systems, are captured by this categorical framework for Lyapunov theory. Finally, to demonstrate the extensibility of our framework, we illustrate how enriched categories, e.g., Lawvere metric spaces, yield settings for stability enabling one to ``do Lyapunov theory'' in enriched categories.", "published": "2025-02-21T08:04:57Z", "version": 2}, {"aid": "2502.15503", "authors": ["Haidong Wang", "Pengfei Xiao", "Ao Liu", "Jianhua Zhang", "Qia Shan"], "title": "BAN: Neuroanatomical Aligning in Auditory Recognition between Artificial Neural Network and Human Cortex", "url": "http://arxiv.org/pdf/2502.15503v1", "summary": "Drawing inspiration from neurosciences, artificial neural networks (ANNs) have evolved from shallow architectures to highly complex, deep structures, yielding exceptional performance in auditory recognition tasks. However, traditional ANNs often struggle to align with brain regions due to their excessive depth and lack of biologically realistic features, like recurrent connection. To address this, a brain-like auditory network (BAN) is introduced, which incorporates four neuroanatomically mapped areas and recurrent connection, guided by a novel metric called the brain-like auditory score (BAS). BAS serves as a benchmark for evaluating the similarity between BAN and human auditory recognition pathway. We further propose that specific areas in the cerebral cortex, mainly the middle and medial superior temporal (T2/T3) areas, correspond to the designed network structure, drawing parallels with the brain's auditory perception pathway. Our findings suggest that the neuroanatomical similarity in the cortex and auditory classification abilities of the ANN are well-aligned. In addition to delivering excellent performance on a music genre classification task, the BAN demonstrates a high BAS score. In conclusion, this study presents BAN as a recurrent, brain-inspired ANN, representing the first model that mirrors the cortical pathway of auditory recognition.", "published": "2025-02-21T14:57:01Z", "version": 1}, {"aid": "2502.15681", "authors": ["Yilun Xu", "Weili Nie", "Arash Vahdat"], "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching", "url": "http://arxiv.org/pdf/2502.15681v2", "summary": "Sampling from diffusion models involves a slow iterative process that hinders their practical deployment, especially for interactive applications. To accelerate generation speed, recent approaches distill a multi-step diffusion model into a single-step student generator via variational score distillation, which matches the distribution of samples generated by the student to the teacher's distribution. However, these approaches use the reverse Kullback-Leibler (KL) divergence for distribution matching which is known to be mode seeking. In this paper, we generalize the distribution matching approach using a novel $f$-divergence minimization framework, termed $f$-distill, that covers different divergences with different trade-offs in terms of mode coverage and training variance. We derive the gradient of the $f$-divergence between the teacher and student distributions and show that it is expressed as the product of their score differences and a weighting function determined by their density ratio. This weighting function naturally emphasizes samples with higher density in the teacher distribution, when using a less mode-seeking divergence. We observe that the popular variational score distillation approach using the reverse-KL divergence is a special case within our framework. Empirically, we demonstrate that alternative $f$-divergences, such as forward-KL and Jensen-Shannon divergences, outperform the current best variational score distillation methods across image generation tasks. In particular, when using Jensen-Shannon divergence, $f$-distill achieves current state-of-the-art one-step generation performance on ImageNet64 and zero-shot text-to-image generation on MS-COCO. Project page: https://research.nvidia.com/labs/genair/f-distill", "published": "2025-02-21T18:59:20Z", "version": 2}, {"aid": "2502.18516", "authors": ["Runze Jiang", "Pengjian Shang"], "title": "Gradient entropy (GradEn): The two dimensional version of slope entropy for image analysis", "url": "http://arxiv.org/pdf/2502.18516v2", "summary": "Information theory and Shannon entropy are essential for quantifying irregularity in complex systems or signals. Recently, two-dimensional entropy methods, such as two-dimensional sample entropy, distribution entropy, and permutation entropy, have been proposed for analyzing 2D texture or image data. This paper introduces Gradient entropy (GradEn), an extension of slope entropy to 2D, which considers both symbolic patterns and amplitude information, enabling better feature extraction from image data. We evaluate GradEn with simulated data, including 2D colored noise, 2D mixed processes, and the logistic map. Results show the ability of GradEn to distinguish images with various characteristics while maintaining low computational cost. Real-world datasets, consist of texture, fault gear, and railway corrugation signals, demonstrate the superior performance of GradEn in classification tasks compared to other 2D entropy methods. In conclusion, GradEn is an effective tool for image characterization, offering a novel approach for image processing and recognition.", "published": "2025-02-23T02:05:01Z", "version": 2}, {"aid": "2502.16861", "authors": ["Weiyu Guo", "Guoying Sun", "JianXiang He", "Tong Shao", "Shaoguang Wang", "Ziyang Chen", "Meisheng Hong", "Ying Sun", "Hui Xiong"], "title": "A Survey of fMRI to Image Reconstruction", "url": "http://arxiv.org/pdf/2502.16861v1", "summary": "Functional magnetic resonance imaging (fMRI) based image reconstruction plays a pivotal role in decoding human perception, with applications in neuroscience and brain-computer interfaces. While recent advancements in deep learning and large-scale datasets have driven progress, challenges such as data scarcity, cross-subject variability, and low semantic consistency persist. To address these issues, we introduce the concept of fMRI-to-Image Learning (fMRI2Image) and present the first systematic review in this field. This review highlights key challenges, categorizes methodologies such as fMRI signal encoding, feature mapping, and image generator. Finally, promising research directions are proposed to advance this emerging frontier, providing a reference for future studies.", "published": "2025-02-24T05:53:04Z", "version": 1}, {"aid": "2502.17327", "authors": ["Inbar Gat", "Sigal Raab", "Guy Tevet", "Yuval Reshef", "Amit H. Bermano", "Daniel Cohen-Or"], "title": "AnyTop: Character Animation Diffusion with Any Topology", "url": "http://arxiv.org/pdf/2502.17327v2", "summary": "Generating motion for arbitrary skeletons is a longstanding challenge in computer graphics, remaining largely unexplored due to the scarcity of diverse datasets and the irregular nature of the data. In this work, we introduce AnyTop, a diffusion model that generates motions for diverse characters with distinct motion dynamics, using only their skeletal structure as input. Our work features a transformer-based denoising network, tailored for arbitrary skeleton learning, integrating topology information into the traditional attention mechanism. Additionally, by incorporating textual joint descriptions into the latent feature representation, AnyTop learns semantic correspondences between joints across diverse skeletons. Our evaluation demonstrates that AnyTop generalizes well, even with as few as three training examples per topology, and can produce motions for unseen skeletons as well. Furthermore, our model's latent space is highly informative, enabling downstream tasks such as joint correspondence, temporal segmentation and motion editing. Our webpage, https://anytop2025.github.io/Anytop-page, includes links to videos and code.", "published": "2025-02-24T17:00:36Z", "version": 2}, {"aid": "2502.18553", "authors": ["Zohar Ringel", "Noa Rubin", "Edo Mor", "Moritz Helias", "Inbar Seroussi"], "title": "Applications of Statistical Field Theory in Deep Learning", "url": "http://arxiv.org/pdf/2502.18553v3", "summary": "Deep learning algorithms have made incredible strides in the past decade, yet due to their complexity, the science of deep learning remains in its early stages. Being an experimentally driven field, it is natural to seek a theory of deep learning within the physics paradigm. As deep learning is largely about learning functions and distributions over functions, statistical field theory, a rich and versatile toolbox for tackling complex distributions over functions (fields) is an obvious choice of formalism. Research efforts carried out in the past few years have demonstrated the ability of field theory to provide useful insights on generalization, implicit bias, and feature learning effects. Here we provide a pedagogical review of this emerging line of research.", "published": "2025-02-25T18:19:06Z", "version": 3}, {"aid": "2502.20272", "authors": ["Qingsen Yan", "Yixu Feng", "Cheng Zhang", "Guansong Pang", "Kangbiao Shi", "Peng Wu", "Wei Dong", "Jinqiu Sun", "Yanning Zhang"], "title": "HVI: A New Color Space for Low-light Image Enhancement", "url": "http://arxiv.org/pdf/2502.20272v2", "summary": "Low-Light Image Enhancement (LLIE) is a crucial computer vision task that aims to restore detailed visual information from corrupted low-light images. Many existing LLIE methods are based on standard RGB (sRGB) space, which often produce color bias and brightness artifacts due to inherent high color sensitivity in sRGB. While converting the images using Hue, Saturation and Value (HSV) color space helps resolve the brightness issue, it introduces significant red and black noise artifacts. To address this issue, we propose a new color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by polarized HS maps and learnable intensity. The former enforces small distances for red coordinates to remove the red artifacts, while the latter compresses the low-light regions to remove the black artifacts. To fully leverage the chromatic and intensity information, a novel Color and Intensity Decoupling Network (CIDNet) is further introduced to learn accurate photometric mapping function under different lighting conditions in the HVI space. Comprehensive results from benchmark and ablation experiments show that the proposed HVI color space with CIDNet outperforms the state-of-the-art methods on 10 datasets. The code is available at https://github.com/Fediory/HVI-CIDNet.", "published": "2025-02-27T16:59:51Z", "version": 2}, {"aid": "2503.00240", "authors": ["Marius F. R. Juston", "William R. Norris", "Dustin Nottage", "Ahmet Soylemezoglu"], "title": "1-Lipschitz Network Initialization for Certifiably Robust Classification Applications: A Decay Problem", "url": "http://arxiv.org/pdf/2503.00240v1", "summary": "This paper discusses the weight parametrization of two standard 1-Lipschitz network structure methodologies, the Almost-Orthogonal-Layers (AOL) and the SDP-based Lipschitz Layers (SLL), and derives their impact on the initialization for deep 1-Lipschitz feedforward networks in addition to discussing underlying issues surrounding this initialization. These networks are mainly used in certifiably robust classification applications to combat adversarial attacks by limiting the effects of perturbations on the output classification result. An exact and an upper bound for the parameterized weight variance was calculated assuming a standard Normal distribution initialization; additionally, an upper bound was computed assuming a Generalized Normal Distribution, generalizing the proof for Uniform, Laplace, and Normal distribution weight initializations. It is demonstrated that the weight variance holds no bearing on the output variance distribution and that only the dimension of the weight matrices matters. Additionally, this paper demonstrates that the weight initialization always causes deep 1-Lipschitz networks to decay to zero.", "published": "2025-02-28T23:02:04Z", "version": 1}, {"aid": "2503.00301", "authors": ["Zihan Huang", "Wei Fang", "Tong Bu", "Peng Xue", "Zecheng Hao", "Wenxuan Liu", "Yuanhong Tang", "Zhaofei Yu", "Tiejun Huang"], "title": "Differential Coding for Training-Free ANN-to-SNN Conversion", "url": "http://arxiv.org/pdf/2503.00301v3", "summary": "Spiking Neural Networks (SNNs) exhibit significant potential due to their low energy consumption. Converting Artificial Neural Networks (ANNs) to SNNs is an efficient way to achieve high-performance SNNs. However, many conversion methods are based on rate coding, which requires numerous spikes and longer time-steps compared to directly trained SNNs, leading to increased energy consumption and latency. This article introduces differential coding for ANN-to-SNN conversion, a novel coding scheme that reduces spike counts and energy consumption by transmitting changes in rate information rather than rates directly, and explores its application across various layers. Additionally, the threshold iteration method is proposed to optimize thresholds based on activation distribution when converting Rectified Linear Units (ReLUs) to spiking neurons. Experimental results on various Convolutional Neural Networks (CNNs) and Transformers demonstrate that the proposed differential coding significantly improves accuracy while reducing energy consumption, particularly when combined with the threshold iteration method, achieving state-of-the-art performance. The source codes of the proposed method are available at https://github.com/h-z-h-cell/ANN-to-SNN-DCGS.", "published": "2025-03-01T02:17:35Z", "version": 3}, {"aid": "2503.00511", "authors": ["Manuel Baltieri", "Martin Biehl", "Matteo Capucci", "Nathaniel Virgo"], "title": "A Bayesian Interpretation of the Internal Model Principle", "url": "http://arxiv.org/pdf/2503.00511v2", "summary": "The internal model principle, originally proposed in the theory of control of linear systems, nowadays represents a more general class of results in control theory and cybernetics. The central claim of these results is that, under suitable assumptions, if a system (a controller) can regulate against a class of external inputs (from the environment), it is because the system contains a model of the system causing these inputs, which can be used to generate signals counteracting them. Similar claims on the role of internal models appear also in cognitive science, especially in modern Bayesian treatments of cognitive agents, often suggesting that a system (a human subject, or some other agent) models its environment to adapt against disturbances and perform goal-directed behaviour. It is however unclear whether the Bayesian internal models discussed in cognitive science bear any formal relation to the internal models invoked in standard treatments of control theory. Here, we first review the internal model principle and present a precise formulation of it using concepts inspired by categorical systems theory. This leads to a formal definition of ``model'' generalising its use in the internal model principle. Although this notion of model is not a priori related to the notion of Bayesian reasoning, we show that it can be seen as a special case of possibilistic Bayesian filtering. This result is based on a recent line of work formalising, using Markov categories, a notion of ``interpretation'', describing when a system can be interpreted as performing Bayesian filtering on an outside world in a consistent way.", "published": "2025-03-01T14:29:39Z", "version": 2}, {"aid": "2503.01115", "authors": ["Zhipeng Huang", "Shaobin Zhuang", "Canmiao Fu", "Binxin Yang", "Ying Zhang", "Chong Sun", "Zhizheng Zhang", "Yali Wang", "Chen Li", "Zheng-Jun Zha"], "title": "WeGen: A Unified Model for Interactive Multimodal Generation as We Chat", "url": "http://arxiv.org/pdf/2503.01115v2", "summary": "Existing multimodal generative models fall short as qualified design copilots, as they often struggle to generate imaginative outputs once instructions are less detailed or lack the ability to maintain consistency with the provided references. In this work, we introduce WeGen, a model that unifies multimodal generation and understanding, and promotes their interplay in iterative generation. It can generate diverse results with high creativity for less detailed instructions. And it can progressively refine prior generation results or integrating specific contents from references following the instructions in its chat with users. During this process, it is capable of preserving consistency in the parts that the user is already satisfied with. To this end, we curate a large-scale dataset, extracted from Internet videos, containing rich object dynamics and auto-labeled dynamics descriptions by advanced foundation models to date. These two information are interleaved into a single sequence to enable WeGen to learn consistency-aware generation where the specified dynamics are generated while the consistency of unspecified content is preserved aligned with instructions. Besides, we introduce a prompt self-rewriting mechanism to enhance generation diversity. Extensive experiments demonstrate the effectiveness of unifying multimodal understanding and generation in WeGen and show it achieves state-of-the-art performance across various visual generation benchmarks. These also demonstrate the potential of WeGen as a user-friendly design copilot as desired. The code and models will be available at https://github.com/hzphzp/WeGen.", "published": "2025-03-03T02:50:07Z", "version": 2}, {"aid": "2503.01565", "authors": ["Yuheng Xu", "Shijie Yang", "Xin Liu", "Jie Liu", "Jie Tang", "Gangshan Wu"], "title": "AutoLUT: LUT-Based Image Super-Resolution with Automatic Sampling and Adaptive Residual Learning", "url": "http://arxiv.org/pdf/2503.01565v2", "summary": "In recent years, the increasing popularity of Hi-DPI screens has driven a rising demand for high-resolution images. However, the limited computational power of edge devices poses a challenge in deploying complex super-resolution neural networks, highlighting the need for efficient methods. While prior works have made significant progress, they have not fully exploited pixel-level information. Moreover, their reliance on fixed sampling patterns limits both accuracy and the ability to capture fine details in low-resolution images. To address these challenges, we introduce two plug-and-play modules designed to capture and leverage pixel information effectively in Look-Up Table (LUT) based super-resolution networks. Our method introduces Automatic Sampling (AutoSample), a flexible LUT sampling approach where sampling weights are automatically learned during training to adapt to pixel variations and expand the receptive field without added inference cost. We also incorporate Adaptive Residual Learning (AdaRL) to enhance inter-layer connections, enabling detailed information flow and improving the network's ability to reconstruct fine details. Our method achieves significant performance improvements on both MuLUT and SPF-LUT while maintaining similar storage sizes. Specifically, for MuLUT, we achieve a PSNR improvement of approximately +0.20 dB improvement on average across five datasets. For SPF-LUT, with more than a 50% reduction in storage space and about a 2/3 reduction in inference time, our method still maintains performance comparable to the original. The code is available at https://github.com/SuperKenVery/AutoLUT.", "published": "2025-03-03T14:09:36Z", "version": 2}, {"aid": "2503.01776", "authors": ["Tiansheng Wen", "Yifei Wang", "Zequn Zeng", "Zhong Peng", "Yudi Su", "Xinyang Liu", "Bo Chen", "Hongwei Liu", "Stefanie Jegelka", "Chenyu You"], "title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation", "url": "http://arxiv.org/pdf/2503.01776v5", "summary": "Many large-scale systems rely on high-quality deep representations (embeddings) to facilitate tasks like retrieval, search, and generative modeling. Matryoshka Representation Learning (MRL) recently emerged as a solution for adaptive embedding lengths, but it requires full model retraining and suffers from noticeable performance degradations at short lengths. In this paper, we show that sparse coding offers a compelling alternative for achieving adaptive representation with minimal overhead and higher fidelity. We propose Contrastive Sparse Representation (CSR), a method that sparsifies pre-trained embeddings into a high-dimensional but selectively activated feature space. By leveraging lightweight autoencoding and task-aware contrastive objectives, CSR preserves semantic quality while allowing flexible, cost-effective inference at different sparsity levels. Extensive experiments on image, text, and multimodal benchmarks demonstrate that CSR consistently outperforms MRL in terms of both accuracy and retrieval speed-often by large margins-while also cutting training time to a fraction of that required by MRL. Our results establish sparse coding as a powerful paradigm for adaptive representation learning in real-world applications where efficiency and fidelity are both paramount. Code is available at https://github.com/neilwen987/CSR_Adaptive_Rep", "published": "2025-03-03T17:59:48Z", "version": 5}, {"aid": "2503.02477", "authors": ["Dario Stein"], "title": "Random Variables, Conditional Independence and Categories of Abstract Sample Spaces", "url": "http://arxiv.org/pdf/2503.02477v2", "summary": "Two high-level \"pictures\" of probability theory have emerged: one that takes as central the notion of random variable, and one that focuses on distributions and probability channels (Markov kernels). While the channel-based picture has been successfully axiomatized, and widely generalized, using the notion of Markov category, the categorical semantics of the random variable picture remain less clear. Simpson's probability sheaves are a recent approach, in which probabilistic concepts like random variables are allowed vary over a site of sample spaces. Simpson has identified rich structure on these sites, most notably an abstract notion of conditional independence, and given examples ranging from probability over databases to nominal sets. We aim bring this development together with the generality and abstraction of Markov categories: We show that for any suitable Markov category, a category of sample spaces can be defined which satisfies Simpson's axioms, and that a theory of probability sheaves can be developed purely synthetically in this setting. We recover Simpson's examples in a uniform fashion from well-known Markov categories, and consider further generalizations.", "published": "2025-03-04T10:42:00Z", "version": 2}, {"aid": "2503.07641", "authors": ["Niklas M. Melton", "Leonardo Enzo Brito da Silva", "Sasha Petrenko", "Donald. C. Wunsch II"], "title": "Deep ARTMAP: Generalized Hierarchical Learning with Adaptive Resonance Theory", "url": "http://arxiv.org/pdf/2503.07641v1", "summary": "This paper presents Deep ARTMAP, a novel extension of the ARTMAP architecture that generalizes the self-consistent modular ART (SMART) architecture to enable hierarchical learning (supervised and unsupervised) across arbitrary transformations of data. The Deep ARTMAP framework operates as a divisive clustering mechanism, supporting an arbitrary number of modules with customizable granularity within each module. Inter-ART modules regulate the clustering at each layer, permitting unsupervised learning while enforcing a one-to-many mapping from clusters in one layer to the next. While Deep ARTMAP reduces to both ARTMAP and SMART in particular configurations, it offers significantly enhanced flexibility, accommodating a broader range of data transformations and learning modalities.", "published": "2025-03-05T22:23:17Z", "version": 1}, {"aid": "2503.06242", "authors": ["\u0141ukasz Struski", "Micha\u0142 B. Bednarczyk", "Igor T. Podolak", "Jacek Tabor"], "title": "LapSum -- One Method to Differentiate Them All: Ranking, Sorting and Top-k Selection", "url": "http://arxiv.org/pdf/2503.06242v2", "summary": "We present a novel technique for constructing differentiable order-type operations, including soft ranking, soft top-k selection, and soft permutations. Our approach leverages an efficient closed-form formula for the inverse of the function LapSum, defined as the sum of Laplace distributions. This formulation ensures low computational and memory complexity in selecting the highest activations, enabling losses and gradients to be computed in $O(n\\log{}n)$ time. Through extensive experiments, we demonstrate that our method outperforms state-of-the-art techniques for high-dimensional vectors and large $k$ values. Furthermore, we provide efficient implementations for both CPU and CUDA environments, underscoring the practicality and scalability of our method for large-scale ranking and differentiable ordering problems.", "published": "2025-03-08T14:53:36Z", "version": 2}, {"aid": "2503.07565", "authors": ["Linqi Zhou", "Stefano Ermon", "Jiaming Song"], "title": "Inductive Moment Matching", "url": "http://arxiv.org/pdf/2503.07565v7", "summary": "Diffusion models and Flow Matching generate high-quality samples but are slow at inference, and distilling them into few-step models often leads to instability and extensive tuning. To resolve these trade-offs, we propose Inductive Moment Matching (IMM), a new class of generative models for one- or few-step sampling with a single-stage training procedure. Unlike distillation, IMM does not require pre-training initialization and optimization of two networks; and unlike Consistency Models, IMM guarantees distribution-level convergence and remains stable under various hyperparameters and standard model architectures. IMM surpasses diffusion models on ImageNet-256x256 with 1.99 FID using only 8 inference steps and achieves state-of-the-art 2-step FID of 1.98 on CIFAR-10 for a model trained from scratch.", "published": "2025-03-10T17:37:39Z", "version": 7}, {"aid": "2503.09817", "authors": ["Jesse Farebrother", "Matteo Pirotta", "Andrea Tirinzoni", "R\u00e9mi Munos", "Alessandro Lazaric", "Ahmed Touati"], "title": "Temporal Difference Flows", "url": "http://arxiv.org/pdf/2503.09817v1", "summary": "Predictive models of the future are fundamental for an agent's ability to reason and plan. A common strategy learns a world model and unrolls it step-by-step at inference, where small errors can rapidly compound. Geometric Horizon Models (GHMs) offer a compelling alternative by directly making predictions of future states, avoiding cumulative inference errors. While GHMs can be conveniently learned by a generative analog to temporal difference (TD) learning, existing methods are negatively affected by bootstrapping predictions at train time and struggle to generate high-quality predictions at long horizons. This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods. Theoretically, we establish a new convergence result and primarily attribute TD-Flow's efficacy to reduced gradient variance during training. We further show that similar arguments can be extended to diffusion-based methods. Empirically, we validate TD-Flow across a diverse set of domains on both generative metrics and downstream tasks including policy evaluation. Moreover, integrating TD-Flow with recent behavior foundation models for planning over pre-trained policies demonstrates substantial performance gains, underscoring its promise for long-horizon decision-making.", "published": "2025-03-12T20:30:07Z", "version": 1}, {"aid": "2503.10144", "authors": ["Han Kim", "Hyungjoon Soh", "Vipul Periwal", "Junghyo Jo"], "title": "Multiplicative Learning", "url": "http://arxiv.org/pdf/2503.10144v1", "summary": "Efficient training of artificial neural networks remains a key challenge in deep learning. Backpropagation (BP), the standard learning algorithm, relies on gradient descent and typically requires numerous iterations for convergence. In this study, we introduce Expectation Reflection (ER), a novel learning approach that updates weights multiplicatively based on the ratio of observed to predicted outputs. Unlike traditional methods, ER maintains consistency without requiring ad hoc loss functions or learning rate hyperparameters. We extend ER to multilayer networks and demonstrate its effectiveness in performing image classification tasks. Notably, ER achieves optimal weight updates in a single iteration. Additionally, we reinterpret ER as a modified form of gradient descent incorporating the inverse mapping of target propagation. These findings suggest that ER provides an efficient and scalable alternative for training neural networks.", "published": "2025-03-13T08:14:00Z", "version": 1}, {"aid": "2503.11718", "authors": ["Gabriele D'Acunto", "Claudio Battiloro"], "title": "The Relativity of Causal Knowledge", "url": "http://arxiv.org/pdf/2503.11718v2", "summary": "Recent advances in artificial intelligence reveal the limits of purely predictive systems and call for a shift toward causal and collaborative reasoning. Drawing inspiration from the revolution of Grothendieck in mathematics, we introduce the relativity of causal knowledge, which posits structural causal models (SCMs) are inherently imperfect, subjective representations embedded within networks of relationships. By leveraging category theory, we arrange SCMs into a functor category and show that their observational and interventional probability measures naturally form convex structures. This result allows us to encode non-intervened SCMs with convex spaces of probability measures. Next, using sheaf theory, we construct the network sheaf and cosheaf of causal knowledge. These structures enable the transfer of causal knowledge across the network while incorporating interventional consistency and the perspective of the subjects, ultimately leading to the formal, mathematical definition of relative causal knowledge.", "published": "2025-03-13T16:24:48Z", "version": 2}, {"aid": "2503.10518", "authors": ["Andrew Knight"], "title": "Why the Brain Cannot Be a Digital Computer: History-Dependence and the Computational Limits of Consciousness", "url": "http://arxiv.org/pdf/2503.10518v1", "summary": "This paper presents a novel information-theoretic proof demonstrating that the human brain as currently understood cannot function as a classical digital computer. Through systematic quantification of distinguishable conscious states and their historical dependencies, we establish that the minimum information required to specify a conscious state exceeds the physical information capacity of the human brain by a significant factor. Our analysis calculates the bit-length requirements for representing consciously distinguishable sensory \"stimulus frames\" and demonstrates that consciousness exhibits mandatory temporal-historical dependencies that multiply these requirements beyond the brain's storage capabilities. This mathematical approach offers new insights into the fundamental limitations of computational models of consciousness and suggests that non-classical information processing mechanisms may be necessary to account for conscious experience.", "published": "2025-03-13T16:27:42Z", "version": 1}, {"aid": "2503.10522", "authors": ["Zeyue Tian", "Yizhu Jin", "Zhaoyang Liu", "Ruibin Yuan", "Xu Tan", "Qifeng Chen", "Wei Xue", "Yike Guo"], "title": "AudioX: Diffusion Transformer for Anything-to-Audio Generation", "url": "http://arxiv.org/pdf/2503.10522v2", "summary": "Audio and music generation have emerged as crucial tasks in many applications, yet existing approaches face significant limitations: they operate in isolation without unified capabilities across modalities, suffer from scarce high-quality, multi-modal training data, and struggle to effectively integrate diverse inputs. In this work, we propose AudioX, a unified Diffusion Transformer model for Anything-to-Audio and Music Generation. Unlike previous domain-specific models, AudioX can generate both general audio and music with high quality, while offering flexible natural language control and seamless processing of various modalities including text, video, image, music, and audio. Its key innovation is a multi-modal masked training strategy that masks inputs across modalities and forces the model to learn from masked inputs, yielding robust and unified cross-modal representations. To address data scarcity, we curate two comprehensive datasets: vggsound-caps with 190K audio captions based on the VGGSound dataset, and V2M-caps with 6 million music captions derived from the V2M dataset. Extensive experiments demonstrate that AudioX not only matches or outperforms state-of-the-art specialized models, but also offers remarkable versatility in handling diverse input modalities and generation tasks within a unified architecture. The code and datasets will be available at https://zeyuet.github.io/AudioX/", "published": "2025-03-13T16:30:59Z", "version": 2}, {"aid": "2503.10868", "authors": ["Niyousha Najmaei", "Niels van der Weide", "Benedikt Ahrens", "Paige Randall North"], "title": "A Type Theory for Comprehension Categories with Applications to Subtyping", "url": "http://arxiv.org/pdf/2503.10868v1", "summary": "In this paper we develop a type theory that we show is an internal language for comprehension categories. This type theory is closely related to Martin-L\\\"of type theory (MLTT). Indeed, semantics of MLTT are often given in comprehension categories, albeit usually only in discrete or full ones. As we explain, requiring a comprehension category to be full or discrete can be understood as removing one `dimension' of morphisms. Thus, in our syntax, we recover this extra dimension. We show that this extra dimension can be used to encode subtyping in a natural way. Important instances of non-full comprehension categories include ones used for constructive or univalent intensional models of MLTT and directed type theory, and so our syntax is a more faithful internal language for these than is MLTT.", "published": "2025-03-13T20:34:37Z", "version": 1}, {"aid": "2503.10875", "authors": ["Hai-Vy Nguyen", "Fabrice Gamboa", "Sixin Zhang", "Reda Chhaibi", "Serge Gratton", "Thierry Giaccone"], "title": "Convolutional Rectangular Attention Module", "url": "http://arxiv.org/pdf/2503.10875v2", "summary": "In this paper, we introduce a novel spatial attention module that can be easily integrated to any convolutional network. This module guides the model to pay attention to the most discriminative part of an image. This enables the model to attain a better performance by an end-to-end training. In conventional approaches, a spatial attention map is typically generated in a position-wise manner. Thus, it is often resulting in irregular boundaries and so can hamper generalization to new samples. In our method, the attention region is constrained to be rectangular. This rectangle is parametrized by only 5 parameters, allowing for a better stability and generalization to new samples. In our experiments, our method systematically outperforms the position-wise counterpart. So that, we provide a novel useful spatial attention mechanism for convolutional models. Besides, our module also provides the interpretability regarding the \\textit{where to look} question, as it helps to know the part of the input on which the model focuses to produce the prediction.", "published": "2025-03-13T20:41:36Z", "version": 2}, {"aid": "2503.10963", "authors": ["Tom de Jong", "Nicolai Kraus", "Simona Paoli", "Sti\u00e9phen Pradal"], "title": "A study of Kock's fat Delta", "url": "http://arxiv.org/pdf/2503.10963v1", "summary": "Motivated by the study of weak identity structures in higher category theory we explore the fat Delta category, a modification of the simplex category introduced by J. Kock. We provide a comprehensive study of fat Delta via the theory of monads with arities, and use these results to show that fat Delta is a hypermoment category in the sense of C. Berger. Specifically, by proving that the free relative semicategory monad is strongly cartesian and identifying a dense generator, the theory of monads with arities immediately gives rise to the nerve theorem. We characterise the essential image of the nerve via the Segal condition, and show that fat Delta possesses an active-inert factorisation system. Building on these results, we also establish an isomorphism between two presentations of fat Delta and show that it is a strongly unital and extensional hypermoment category.", "published": "2025-03-14T00:14:04Z", "version": 1}, {"aid": "2503.11224", "authors": ["Xingtai Lv", "Youbang Sun", "Kaiyan Zhang", "Shang Qu", "Xuekai Zhu", "Yuchen Fan", "Yi Wu", "Ermo Hua", "Xinwei Long", "Ning Ding", "Bowen Zhou"], "title": "Technologies on Effectiveness and Efficiency: A Survey of State Spaces Models", "url": "http://arxiv.org/pdf/2503.11224v1", "summary": "State Space Models (SSMs) have emerged as a promising alternative to the popular transformer-based models and have been increasingly gaining attention. Compared to transformers, SSMs excel at tasks with sequential data or longer contexts, demonstrating comparable performances with significant efficiency gains. In this survey, we provide a coherent and systematic overview for SSMs, including their theoretical motivations, mathematical formulations, comparison with existing model classes, and various applications. We divide the SSM series into three main sections, providing a detailed introduction to the original SSM, the structured SSM represented by S4, and the selective SSM typified by Mamba. We put an emphasis on technicality, and highlight the various key techniques introduced to address the effectiveness and efficiency of SSMs. We hope this manuscript serves as an introduction for researchers to explore the theoretical foundations of SSMs.", "published": "2025-03-14T09:20:31Z", "version": 1}, {"aid": "2503.13051", "authors": ["Kai Uwe Barthel", "Florian Barthel", "Peter Eisert"], "title": "Permutation Learning with Only N Parameters: From SoftSort to Self-Organizing Gaussians", "url": "http://arxiv.org/pdf/2503.13051v2", "summary": "Sorting and permutation learning are key concepts in optimization and machine learning, especially when organizing high-dimensional data into meaningful spatial layouts. The Gumbel-Sinkhorn method, while effective, requires N*N parameters to determine a full permutation matrix, making it computationally expensive for large datasets. Low-rank matrix factorization approximations reduce memory requirements to 2NM (with M << N), but they still struggle with very large problems. SoftSort, by providing a continuous relaxation of the argsort operator, allows differentiable 1D sorting, but it faces challenges with multidimensional data and complex permutations. In this paper, we present a novel method for learning permutations using only N parameters, which dramatically reduces storage costs. Our method extends SoftSort by iteratively shuffling the N indices of the elements and applying a few SoftSort optimization steps per iteration. This modification significantly improves sorting quality, especially for multidimensional data and complex optimization criteria, and outperforms pure SoftSort. Our method offers improved memory efficiency and scalability compared to existing approaches, while maintaining high-quality permutation learning. Its dramatically reduced memory requirements make it particularly well-suited for large-scale optimization tasks, such as \"Self-Organizing Gaussians\", where efficient and scalable permutation learning is critical.", "published": "2025-03-17T10:55:55Z", "version": 2}, {"aid": "2503.14376", "authors": ["Maximilian Beck", "Korbinian P\u00f6ppel", "Phillip Lippe", "Sepp Hochreiter"], "title": "Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels", "url": "http://arxiv.org/pdf/2503.14376v2", "summary": "Linear RNNs with gating recently demonstrated competitive performance compared to Transformers in language modeling. Although their linear compute scaling in sequence length offers theoretical runtime advantages over Transformers, realizing these benefits in practice requires optimized custom kernels, as Transformers rely on the highly efficient Flash Attention kernels (Dao, 2024). Leveraging the chunkwise-parallel formulation of linear RNNs, Flash Linear Attention (FLA) (Yang & Zhang, 2024) shows that linear RNN kernels are faster than Flash Attention, by parallelizing over chunks of the input sequence. However, since the chunk size of FLA is limited, many intermediate states must be materialized in GPU memory. This leads to low arithmetic intensity and causes high memory consumption and IO cost, especially for long-context pre-training. In this work, we present Tiled Flash Linear Attention (TFLA), a novel kernel algorithm for linear RNNs, that enables arbitrary large chunk sizes and high arithmetic intensity by introducing an additional level of sequence parallelization within each chunk. First, we apply TFLA to the xLSTM with matrix memory, the mLSTM (Beck et al., 2024). Second, we propose an mLSTM variant with sigmoid input gate and reduced computation for even faster kernel runtimes at equal language modeling performance. In our speed benchmarks, we show that our new mLSTM kernels based on TFLA outperform highly optimized Flash Attention, Linear Attention and Mamba kernels, setting a new state of the art for efficient long-context sequence modeling primitives.", "published": "2025-03-18T16:09:47Z", "version": 2}, {"aid": "2503.17513", "authors": ["Giuseppe Franco", "Pablo Monteagudo-Lago", "Ian Colbert", "Nicholas Fraser", "Michaela Blott"], "title": "Improving Quantization with Post-Training Model Expansion", "url": "http://arxiv.org/pdf/2503.17513v2", "summary": "The size of a model has been a strong predictor of its quality, as well as its cost. As such, the trade-off between model cost and quality has been well-studied. Post-training optimizations like quantization and pruning have typically focused on reducing the overall volume of pre-trained models to reduce inference costs while maintaining model quality. However, recent advancements have introduced optimization techniques that, interestingly, expand models post-training, increasing model size to improve quality when reducing volume. For instance, to enable 4-bit weight and activation quantization, incoherence processing often necessitates inserting online Hadamard rotations in the compute graph, and preserving highly sensitive weights often calls for additional higher precision computations. However, if application requirements cannot be met, the prevailing solution is to relax quantization constraints. In contrast, we demonstrate post-training model expansion is a viable strategy to improve model quality within a quantization co-design space, and provide theoretical justification. We show it is possible to progressively and selectively expand the size of a pre-trained large language model (LLM) to improve model quality without end-to-end retraining. In particular, when quantizing the weights and activations to 4 bits for Llama3 1B, we reduce the gap to full-precision perplexity by an average of 9% relative to both QuaRot and SpinQuant with only 5% more parameters, which is still a 3.8% reduction in volume relative to a BF16 reference model.", "published": "2025-03-21T19:56:59Z", "version": 2}, {"aid": "2505.10571", "authors": ["Jen-tse Huang", "Kaiser Sun", "Wenxuan Wang", "Mark Dredze"], "title": "Language Models Do Not Have Human-Like Working Memory", "url": "http://arxiv.org/pdf/2505.10571v2", "summary": "While Large Language Models (LLMs) exhibit remarkable reasoning abilities, we demonstrate that they fundamentally lack a core aspect of human cognition: working memory. Human working memory is an active cognitive system that enables not only the temporary storage of information but also its processing and utilization. Without working memory, individuals may produce unreal conversations, exhibit self-contradiction, and struggle with tasks requiring mental reasoning. Existing evaluations using N-back or context-dependent tasks fail as they allow LLMs to exploit accessible context rather than retain latent information. We introduce three novel tasks, (1) Number Guessing, (2) Yes-No Deduction, and Math Magic, that isolate internal representation from external context. Across seventeen frontier models spanning four major model families, we consistently observe irrational or contradictory behaviors, highlighting LLMs' inability to retain and manipulate latent information. Our work establishes a new benchmark for evaluating working memory in LLMs and identifies this deficit as a critical obstacle to artificial general intelligence. Code and prompts for the experiments are available at https://github.com/penguinnnnn/LLM-Working-Memory.", "published": "2025-04-30T16:18:39Z", "version": 2}, {"aid": "2505.12097", "authors": ["Ricardo Baptista", "Panagiota Birmpa", "Markos A. Katsoulakis", "Luc Rey-Bellet", "Benjamin J. Zhang"], "title": "Proximal optimal transport divergences", "url": "http://arxiv.org/pdf/2505.12097v2", "summary": "We introduce the proximal optimal transport divergence, a novel discrepancy measure that interpolates between information divergences and optimal transport distances via an infimal convolution formulation. This divergence provides a principled foundation for optimal transport proximals and proximal optimization methods frequently used in generative modeling. We explore its mathematical properties, including smoothness, boundedness, and computational tractability, and establish connections to primal-dual formulations and adversarial learning. The proximal operator associated with the proximal optimal transport divergence can be interpreted as a transport map that pushes a reference distribution toward the optimal generative distribution, which approximates the target distribution that is only accessible through data samples. Building on the Benamou-Brenier dynamic formulation of classical optimal transport, we also establish a dynamic formulation for proximal OT divergences. The resulting dynamic formulation is a first order mean-field game whose optimality conditions are governed by a pair of nonlinear partial differential equations: a backward Hamilton-Jacobi equation and a forward continuity equation. Our framework generalizes existing approaches while offering new insights and computational tools for generative modeling, distributionally robust optimization, and gradient-based learning in probability spaces.", "published": "2025-05-17T17:48:11Z", "version": 2}, {"aid": "2505.21528", "authors": ["Mokai Pan", "Kaizhen Zhu", "Yuexin Ma", "Yanwei Fu", "Jingyi Yu", "Jingya Wang", "Ye Shi"], "title": "UniDB++: Fast Sampling of Unified Diffusion Bridge", "url": "http://arxiv.org/pdf/2505.21528v1", "summary": "Diffusion Bridges enable transitions between arbitrary distributions, with the Unified Diffusion Bridge (UniDB) framework achieving high-fidelity image generation via a Stochastic Optimal Control (SOC) formulation. However, UniDB's reliance on iterative Euler sampling methods results in slow, computationally expensive inference, while existing acceleration techniques for diffusion or diffusion bridge models fail to address its unique challenges: missing terminal mean constraints and SOC-specific penalty coefficients in its SDEs. We present UniDB++, a training-free sampling algorithm that significantly improves upon these limitations. The method's key advancement comes from deriving exact closed-form solutions for UniDB's reverse-time SDEs, effectively reducing the error accumulation inherent in Euler approximations and enabling high-quality generation with up to 20$\\times$ fewer sampling steps. This method is further complemented by replacing conventional noise prediction with a more stable data prediction model, along with an SDE-Corrector mechanism that maintains perceptual quality for low-step regimes (5-10 steps). Additionally, we demonstrate that UniDB++ aligns with existing diffusion bridge acceleration methods by evaluating their update rules, and UniDB++ can recover DBIMs as special cases under some theoretical conditions. Experiments demonstrate UniDB++'s state-of-the-art performance in image restoration tasks, outperforming Euler-based methods in fidelity and speed while reducing inference time significantly. This work bridges the gap between theoretical generality and practical efficiency in SOC-driven diffusion bridge models. Our code is available at https://github.com/2769433owo/UniDB-plusplus.", "published": "2025-05-23T15:03:02Z", "version": 1}, {"aid": "2509.00031", "authors": ["Qitao Tan", "Xiaoying Song", "Jin Lu", "Guoming Li", "Jun Liu", "Lingzi Hong", "Caiwen Ding", "Jundong Li", "Xiaoming Zhai", "Shaoyi Huang", "Wei Niu", "Geng Yuan"], "title": "ZeroQAT: Your Quantization-aware Training but Efficient", "url": "http://arxiv.org/pdf/2509.00031v1", "summary": "Quantization is an effective technique to reduce the deployment cost of large language models (LLMs), and post-training quantization (PTQ) has been widely studied due to its efficiency. However, existing low-bit PTQ methods suffer from accuracy degradation because their layer-wise optimization introduces cumulative error propagation and misalignment between local reconstruction objectives and downstream performance. While quantization-aware training (QAT) provides a principled solution, its reliance on backpropagation incurs prohibitive data, time, and memory costs, limiting its practicality. To address these challenges, we propose ZeroQAT, a zeroth-order optimization-based QAT framework. ZeroQAT leverages forward-only gradient estimation to eliminate the need for backpropagation, significantly reducing computational and memory overhead while retaining the benefits of end-to-end optimization. Moreover, ZeroQAT jointly learns quantized weights, weight clipping thresholds, and equivalent transformations to mitigate quantization error and handle activation outliers. Experiments demonstrate that ZeroQAT achieves the efficiency of PTQ while retaining the accuracy of QAT, offering a practical solution for high-quality low-bit quantization of LLMs.", "published": "2025-08-21T01:18:27Z", "version": 1}, {"aid": "2508.16877", "authors": ["Manuel Baltieri", "Filippo Torresan", "Tomoya Nakai"], "title": "A coalgebraic perspective on predictive processing", "url": "http://arxiv.org/pdf/2508.16877v1", "summary": "Predictive processing and active inference posit that the brain is a system performing Bayesian inference on the environment. By virtue of this, a prominent interpretation of predictive processing states that the generative model (a POMDP) encoded by the brain synchronises with the generative process (another POMDP) representing the environment while trying to explain what hidden properties of the world generated its sensory input. In this view, the brain is thought to become a copy of the environment. This claim has however been disputed, stressing the fact that a structural copy, or isomorphism as it is at times invoked to be, is not an accurate description of this process since the environment is necessarily more complex than the brain, and what matters is not the capacity to exactly recapitulate the veridical causal structure of the world. In this work, we make parts of this counterargument formal by using ideas from the theory of coalgebras, an abstract mathematical framework for dynamical systems that brings together work from automata theory, concurrency theory, probabilistic processes and other fields. To do so, we cast generative model and process, in the form of POMDPs, as coalgebras, and use maps between them to describe a form of consistency that goes beyond mere structural similarity, giving the necessary mathematical background to describe how different processes can be seen as behaviourally, rather than structurally, equivalent, i.e. how they can be seen as emitting the same observations, and thus minimise prediction error, over time without strict assumptions about structural similarity. In particular, we will introduce three standard notions of equivalence from the literature on coalgebras, evaluating them in the context of predictive processing and identifying the one closest to claims made by proponents of this framework.", "published": "2025-08-23T02:26:50Z", "version": 1}, {"aid": "2508.17561", "authors": ["Sridhar Mahadevan"], "title": "Consciousness as a Functor", "url": "http://arxiv.org/pdf/2508.17561v1", "summary": "We propose a novel theory of consciousness as a functor (CF) that receives and transmits contents from unconscious memory into conscious memory. Our CF framework can be seen as a categorial formulation of the Global Workspace Theory proposed by Baars. CF models the ensemble of unconscious processes as a topos category of coalgebras. The internal language of thought in CF is defined as a Multi-modal Universal Mitchell-Benabou Language Embedding (MUMBLE). We model the transmission of information from conscious short-term working memory to long-term unconscious memory using our recently proposed Universal Reinforcement Learning (URL) framework. To model the transmission of information from unconscious long-term memory into resource-constrained short-term memory, we propose a network economic model.", "published": "2025-08-25T00:06:52Z", "version": 1}, {"aid": "2508.17872", "authors": ["Yanghao Qin", "Bo Zhou", "Guangliang Pan", "Qihui Wu", "Meixia Tao"], "title": "Spectrum Prediction in the Fractional Fourier Domain with Adaptive Filtering", "url": "http://arxiv.org/pdf/2508.17872v1", "summary": "Accurate spectrum prediction is crucial for dynamic spectrum access (DSA) and resource allocation. However, due to the unique characteristics of spectrum data, existing methods based on the time or frequency domain often struggle to separate predictable patterns from noise. To address this, we propose the Spectral Fractional Filtering and Prediction (SFFP) framework. SFFP first employs an adaptive fractional Fourier transform (FrFT) module to transform spectrum data into a suitable fractional Fourier domain, enhancing the separability of predictable trends from noise. Subsequently, an adaptive Filter module selectively suppresses noise while preserving critical predictive features within this domain. Finally, a prediction module, leveraging a complex-valued neural network, learns and forecasts these filtered trend components. Experiments on real-world spectrum data show that the SFFP outperforms leading spectrum and general forecasting methods.", "published": "2025-08-25T10:26:52Z", "version": 1}, {"aid": "2508.18408", "authors": ["Ricardo Borsoi", "Konstantin Usevich", "Marianne Clausel"], "title": "Low-Rank Tensor Decompositions for the Theory of Neural Networks", "url": "http://arxiv.org/pdf/2508.18408v1", "summary": "The groundbreaking performance of deep neural networks (NNs) promoted a surge of interest in providing a mathematical basis to deep learning theory. Low-rank tensor decompositions are specially befitting for this task due to their close connection to NNs and their rich theoretical results. Different tensor decompositions have strong uniqueness guarantees, which allow for a direct interpretation of their factors, and polynomial time algorithms have been proposed to compute them. Through the connections between tensors and NNs, such results supported many important advances in the theory of NNs. In this review, we show how low-rank tensor methods--which have been a core tool in the signal processing and machine learning communities--play a fundamental role in theoretically explaining different aspects of the performance of deep NNs, including their expressivity, algorithmic learnability and computational hardness, generalization, and identifiability. Our goal is to give an accessible overview of existing approaches (developed by different communities, ranging from computer science to mathematics) in a coherent and unified way, and to open a broader perspective on the use of low-rank tensor decompositions for the theory of deep NNs.", "published": "2025-08-25T18:50:45Z", "version": 1}, {"aid": "2508.18510", "authors": ["Valentin Leplat", "Sergio Mayorga", "Roland Hildebrand", "Alexander Gasnikov"], "title": "Norm-Constrained Flows and Sign-Based Optimization: Theory and Algorithms", "url": "http://arxiv.org/pdf/2508.18510v1", "summary": "Sign Gradient Descent (SignGD) is a simple yet robust optimization method, widely used in machine learning for its resilience to gradient noise and compatibility with low-precision computations. While its empirical performance is well established, its theoretical understanding remains limited. In this work, we revisit SignGD from a continuous-time perspective, showing that it arises as an Euler discretization of a norm-constrained gradient flow. This viewpoint reveals a trust-region interpretation and connects SignGD to a broader class of methods defined by different norm constraints, such as normalized gradient descent and greedy coordinate descent.   We further study the discontinuous nature of the underlying dynamics using Filippov's differential inclusion framework, which allows us to derive new algorithmic variants, such as the convex-combination sliding update for the $\\ell_1$-constrained flow, that faithfully approximate Filippov solutions even at discontinuity points. While we do not provide convergence guarantees for these variants, we demonstrate that they preserve descent properties and perform well empirically. We also introduce an accelerated version of SignGD based on a momentum-augmented discretization of the sign-gradient flow, and show its effectiveness in practice. Finally, we establish provable convergence guarantees for standard SignGD in the setting of strongly convex optimization. Our results provide new geometric, algorithmic, and analytical insights into SignGD and its norm-constrained extensions.", "published": "2025-08-25T21:31:20Z", "version": 1}, {"aid": "2508.18764", "authors": ["Valentin Leplat"], "title": "The Geometry of Constrained Optimization: Constrained Gradient Flows via Reparameterization: A-Stable Implicit Schemes, KKT from Stationarity, and Geometry-Respecting Algorithms", "url": "http://arxiv.org/pdf/2508.18764v2", "summary": "Gradient-flow (GF) viewpoints unify and illuminate optimization algorithms, yet most GF analyses focus on unconstrained settings. We develop a geometry-respecting framework for constrained problems by (i) reparameterizing feasible sets with maps whose Jacobians vanish on the boundary (orthant/box) or have rank $n-1$ on the simplex (the Fisher--Shahshahani operator), (ii) deriving flows in parameter space that induce feasible primal dynamics, (iii) discretizing with A-stable implicit schemes (backward Euler on vector domains; feasible Cayley on Stiefel) solved by robust inner loops (modified Gauss--Newton or a KL-prox/negative-entropy Newton--KKT solver), and (iv) proving that stationarity of the dynamics implies KKT, with complementary slackness arising from a simple kinematic mechanism (zero normal speed induced by a vanishing Jacobian or by the Fisher--Shahshahani operator on the simplex). We also treat the Stiefel manifold, where Riemannian stationarity coincides with KKT. The theory yields efficient, geometry-respecting algorithms for each constraint class, with monotone descent and no step-size cap. We include a brief A-stability discussion and present numerical tests (NNLS, simplex- and box-constrained least squares, and Stiefel) demonstrating stability, accuracy, and runtime efficiency of the implicit schemes.", "published": "2025-08-26T07:45:47Z", "version": 2}, {"aid": "2508.20280", "authors": ["Brian K. Tran", "Ben S. Southworth", "David B. Cavender", "Sam Olivier", "Syed A. Shah", "Tommaso Buvoli"], "title": "Nonlinear Splitting for Gradient-Based Unconstrained and Adjoint Optimization", "url": "http://arxiv.org/pdf/2508.20280v1", "summary": "High dimensional and/or nonconvex optimization remains a challenging and important problem across a wide range of fields, such as machine learning, data assimilation, and partial differential equation (PDE) constrained optimization. Here we consider gradient-based methods for solving unconstrained and constrained optimization problems, and introduce the concept of nonlinear splitting to improve accuracy and efficiency. For unconstrained optimization, we consider splittings of the gradient to depend on two arguments, leading to semi-implicit gradient optimization algorithms. In the context of adjoint-based constrained optimization, we propose a splitting of the constraint $F(\\mathbf{x},\\theta)$, effectively expanding the space on which we can evaluate the ``gradient''. In both cases, the formalism further allows natural coupling of nonlinearly split optimization methods with acceleration techniques, such as Nesterov or Anderson acceleration. The framework is demonstrated to outperform existing methods in terms of accuracy and/or runtime on a handful of diverse optimization problems. This includes low-dimensional analytic nonconvex functions, high-dimensional nonlinear least squares in quantum tomography, and PDE-constrained optimization of kinetic equations, where the total number of high-dimensional kinetic solves is reduced by a factor of three compared with standard adjoint optimization.", "published": "2025-08-27T21:22:44Z", "version": 1}, {"aid": "2508.20293", "authors": ["Shihao Zhang", "Rayan Saab"], "title": "Beacon: Post-Training Quantization with Integrated Grid Selection", "url": "http://arxiv.org/pdf/2508.20293v2", "summary": "Quantization is a widely used compression technique for reducing the memory and computation costs of large pre-trained models. A key challenge in per-channel post-training quantization (PTQ) is selecting appropriate scaling factors to replace weight values with values from a scaled integer grid. Existing methods typically fix the scale at the outset via heuristic tuning or grid search. We propose Beacon, a simple and effective algorithm that eliminates the need for such manual tuning. Beacon performs per-channel PTQ directly using an unscaled grid and automatically determines the optimal scaling factors by exploiting the geometry of scalar quantization. It does not rely on back-propagation or large calibration sets. Despite its simplicity and tuning-free nature, Beacon achieves competitive performance compared to state-of-the-art methods, making it a practical solution for efficient model deployment.", "published": "2025-08-27T22:00:18Z", "version": 2}, {"aid": "2508.20441", "authors": ["Ruben Solozabal", "Velibor Bojkovic", "Hilal AlQuabeh", "Kentaro Inui", "Martin Tak\u00e1\u010d"], "title": "Uncovering the Spectral Bias in Diagonal State Space Models", "url": "http://arxiv.org/pdf/2508.20441v1", "summary": "Current methods for initializing state space models (SSMs) parameters mainly rely on the \\textit{HiPPO framework}, which is based on an online approximation of orthogonal polynomials. Recently, diagonal alternatives have shown to reach a similar level of performance while being significantly more efficient due to the simplification in the kernel computation. However, the \\textit{HiPPO framework} does not explicitly study the role of its diagonal variants. In this paper, we take a further step to investigate the role of diagonal SSM initialization schemes from the frequency perspective. Our work seeks to systematically understand how to parameterize these models and uncover the learning biases inherent in such diagonal state-space models. Based on our observations, we propose a diagonal initialization on the discrete Fourier domain \\textit{S4D-DFouT}. The insights in the role of pole placing in the initialization enable us to further scale them and achieve state-of-the-art results on the Long Range Arena benchmark, allowing us to train from scratch on very large datasets as PathX-256.", "published": "2025-08-28T05:39:04Z", "version": 1}, {"aid": "2508.20555", "authors": ["Tom Leinster"], "title": "Equivalence via surjections", "url": "http://arxiv.org/pdf/2508.20555v1", "summary": "Many types of categorical structure obey the following principle: the natural notion of equivalence is generated, as an equivalence relation, by identifying $A$ with $B$ when there exists a strictly structure-preserving map $A \\to B$ that is genuinely (not just essentially) surjective in each dimension and faithful in the top dimension. We prove this principle for four types of structure: categories, monoidal categories, bicategories and double categories. The last of these theorems suggests that the right notion of equivalence between double categories is Campbell's gregarious double equivalence, a conclusion also reached for different reasons in recent work of Moser, Sarazola and Verdugo.", "published": "2025-08-28T08:47:09Z", "version": 1}, {"aid": "2509.01744", "authors": ["Matthew Lorig"], "title": "A Calculus of Variations Approach to Stochastic Control", "url": "http://arxiv.org/pdf/2509.01744v1", "summary": "We use classical tools from calculus of variations to formally derive necessary conditions for a Markov control to be optimal in a standard finite time horizon stochastic control problem. As an example, we solve the well-known Merton portfolio optimization problem.", "published": "2025-09-01T19:52:32Z", "version": 1}, {"aid": "2509.02349", "authors": ["Lu Wang", "Hao Chen", "Siyu Wu", "Zhiyue Wu", "Hao Zhou", "Chengfeng Zhang", "Ting Wang", "Haodi Zhang"], "title": "AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation", "url": "http://arxiv.org/pdf/2509.02349v2", "summary": "Multimodal Large Language Models (MLLMs) have been widely applied in speech and music. This tendency has led to a focus on audio tokenization for Large Models (LMs). Unlike semantic-only text tokens, audio tokens must both capture global semantic content and preserve fine-grained acoustic details. Moreover, they provide a discrete method for speech and music that can be effectively integrated into MLLMs. However, existing research is unsuitable in the definitions of semantic tokens and acoustic tokens. In addition, the evaluation of different codecs typically concentrates on specific domains or tasks, such as reconstruction or Automatic Speech Recognition (ASR) task, which prevents fair and comprehensive comparisons. To address these problems, this paper provides suitable definitions for semantic and acoustic tokens and introduces a systematic evaluation framework. This framework allows for a comprehensive assessment of codecs' capabilities which evaluate across four dimensions: audio reconstruction metric, codebook index (ID) stability, decoder-only transformer perplexity, and performance on downstream probe tasks. Our results show the correctness of the provided suitable definitions and the correlation among reconstruction metrics, codebook ID stability, downstream probe tasks and perplexity.", "published": "2025-09-02T14:15:22Z", "version": 2}, {"aid": "2509.03055", "authors": ["Jonathan A. Mavroforas", "Anthony H. Dooley"], "title": "Rough Path Approaches to Stochastic Control, Filtering, and Stopping", "url": "http://arxiv.org/pdf/2509.03055v1", "summary": "This paper presents a unified exposition of rough path methods applied to optimal control, robust filtering, and optimal stopping, addressing a notable gap in the existing literature where no single treatment covers all three areas. By bringing together key elements from Lyons' theory of rough paths, Gubinelli's controlled rough paths, and related developments, we recast these classical problems within a deterministic, pathwise framework. Particular emphasis is placed on providing detailed proofs and explanations where these have been absent or incomplete, culminating in a proof of the central verification theorem, which is another key contribution of this paper. This result establishes the rigorous connection between candidate solutions to optimal control problems and the Hamilton-Jacobi-Bellman equation in the rough path setting. Alongside these contributions, we identify several theoretical challenges -- most notably, extending the verification theorem and associated results to general p-variation with -- and outline promising directions for future research. The paper is intended as a self-contained reference for researchers seeking to apply rough path theory to decision-making problems in stochastic analysis, mathematical finance, and engineering.", "published": "2025-09-03T06:38:10Z", "version": 1}, {"aid": "2509.04154", "authors": ["Peter Racioppo"], "title": "Attention as an Adaptive Filter", "url": "http://arxiv.org/pdf/2509.04154v1", "summary": "We introduce Adaptive Filter Attention (AFA), a novel attention mechanism that incorporates a learnable dynamics model directly into the computation of attention weights. Rather than comparing queries and keys directly, we model the input sequence as discrete observations of a linear stochastic differential equation (SDE). By imposing a linear dynamics model with simultaneously diagonalizable state matrices and noise covariances, we can make use of a closed-form solution to the differential Lyapunov equation to efficiently propagate pairwise uncertainties through the dynamics. Attention naturally arises as the maximum likelihood solution for this linear SDE, with attention weights corresponding to robust residual-based reweightings of the propagated pairwise precisions. Imposing an additional constraint on the state matrix's eigenvalues leads to a simplified variant with the same computational and memory complexity as standard attention. In the limit of vanishing dynamics and process noise, and using a small-angle approximation, we recover ordinary dot-product attention.", "published": "2025-09-04T12:29:14Z", "version": 1}, {"aid": "2509.04424", "authors": ["Caio Kalil Lauand", "Sean Meyn"], "title": "Global Convergence and Acceleration for Single Observation Gradient Free Optimization", "url": "http://arxiv.org/pdf/2509.04424v1", "summary": "Simultaneous perturbation stochastic approximation (SPSA) is an approach to gradient-free optimization introduced by Spall as a simplification of the approach of Kiefer and Wolfowitz. In many cases the most attractive option is the single-sample version known as 1SPSA, which is the focus of the present paper, containing two major contributions: a modification of the algorithm designed to ensure convergence from arbitrary initial condition, and a new approach to exploration to dramatically accelerate the rate of convergence. Examples are provided to illustrate the theory, and to demonstrate that estimates from unmodified 1SPSA may diverge even for a quadratic objective function.", "published": "2025-09-04T17:45:54Z", "version": 1}]